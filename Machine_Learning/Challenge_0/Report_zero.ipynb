{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Report on 50 Startups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This report analyzes 50 startups using a machine learning model, specifically Logistic Regression. Logistic Regression is chosen due to its capability for binary classification, making it suitable for this analysis. The target variables are categorical and indicate the location of the startups: California and Florida. The objective is to understand the impact of various factors on predicting startup success in these locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Through initial analysis, the dataset reveals four predictor variables: R&D Spend, Administration, Marketing Spend, and Profit, each with 33 data points.\n",
    "- The dataset is split into 75% for training and 25% for testing. An initial logistic regression model, termed *Initial_log*, is implemented using sklearn. This baseline model achieves an accuracy of 33.33%, specificity (Measure of True negatives out of all negatives) of 0% and and sensitivity (Measure of True Positives out of all positives) of 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Challenge_zero](Confusion_Matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use of Ridge, Lasso and Elastic Net:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A confusion matrix reveals that *Initial_log* is good at only identifying those in California 3 out 9 times while Florida nothing.\n",
    "- To address this, various regularization techniques are applied (trying to minimize the Loss):\n",
    "    - Ridge Regression: $\\lambda = 0.001$, learning rate = 0.1.\n",
    "    - Lasso Regression: $\\lambda = 0.001$, learning rate = 1.\n",
    "    - Elastic Net: $\\lambda = 0.001$, learning rate = 1, $\\alpha = 0.5$ (equal balance of L1 (Lasso) and L2 (Ridge) penalties).\n",
    "    - (Where $\\lambda$ applies a penalty to introduce a small bias as to better fit the logistic curve to unknown data)\n",
    "\n",
    "- After regularization, the accuracy remains 33.33%, but there are improvements in other metrics:\n",
    "    - Precision (measure of True Positives out of all True Positives and False Positives): decreases to 20% from 33% for California and increases to 50% for Florida from 0.\n",
    "    - Sensitivity: increases to 33% from 0 for Florida and decreases to 33% from 100% for California .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Challenge_zero](Loss_vs_Iteration_ElasticNet.png)\n",
    "![Challenge_zero](Loss_vs_Iteration_Lasso.png)\n",
    "![Challenge_zero](Loss_vs_Iteration_Ridge.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The ROC curves for both *Initial_log* and the regularized models are plotted below. Both models perform below the classifier baseline, indicating poor predictive power and that the data may lead to incorrect predictions most of the time as suggested by the low accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Challenge_zero](ROC_Original.png)\n",
    "![Challenge_zero](ROC_ElasticNet.png)\n",
    "![Challenge_zero](ROC_Lasso.png)\n",
    "![Challenge_zero](ROC_Ridge.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The analysis demonstrates that while logistic regression is suitable for binary classification, the dataset's characteristics significantly limit model performance. Regularization improves some metrics, but the overall accuracy remains unchanged. As such, one should consider:\n",
    "    - Collecting more balanced data.\n",
    "    - Exploring other models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
