{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fadhla Mohamed\n",
    "# Mutua\n",
    "# SM3201434"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Analysis of Supervised and Unsupervised Learning on UCI Dataset (ID: 267)**  \n",
    "\n",
    "## **1. Data Pretreatment**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **1.1 Data Loading and Inspection**  \n",
    "The dataset was obtained from the UCI Machine Learning Repository using `fetch_ucirepo(id=267)`. After loading the data, we examined its structure, including the number of samples , features, and class distribution. From the repository we have:\n",
    "1. The data has no missing value\n",
    "2. The class distribution (the target) is already encoded (either 1 or 0)\n",
    "3. There are 1372 samples and 4 features\n",
    "4. The four features are continuos\n",
    "\n",
    "data: [1372 rows x 5 columns]\n",
    "| variance | skewness | curtosis | entropy  | targets |\n",
    "|----------|----------|----------|----------|---------|\n",
    "| 3.62160  | 8.66610  | -2.8073  | -0.44699 | 0       |\n",
    "| 4.54590  | 8.16740  | -2.4586  | -1.46210 | 0       |\n",
    "| 3.86600  | -2.63830 | 1.9242   | 0.10645  | 0       |\n",
    "| 3.45660  | 9.52280  | -4.0112  | -3.59440 | 0       |\n",
    "| 0.32924  | -4.45520 | 4.5718   | -0.98880 | 0       |\n",
    "| ...      | ...      | ...      | ...      | ...     |\n",
    "| 0.40614  | 1.34920  | -1.4501  | -0.55949 | 1       |\n",
    "| -1.38870 | -4.87730 | 6.4774   | 0.34179  | 1       |\n",
    "| -3.75030 | -13.45860| 17.5932  | -2.77710 | 1       |\n",
    "| -3.56370 | -8.38270 | 12.3930  | -1.28230 | 1       |\n",
    "| -2.54190 | -0.65804 | 2.6842   | 1.19520  | 1       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **1.2 Scaling, Normalization and Sorting Issues in the Dataset** \n",
    "The dataset consists of numerical features, but their values are on different scales. To ensure proper model training and clustering, **feature scaling** was applied using standardization (z-score normalization). I.e.\n",
    "- Max of all features = 17.9274 while the Min is -13.7731\n",
    "\n",
    "The data was immediately split into train and test sets, rescaled, and then reassembled for models that require the full dataset.\n",
    "\n",
    "full dataset randomized and scaled: [1372 rows x 5 columns]\n",
    "| variance | skewness | curtosis | entropy  | targets |\n",
    "|----------|----------|----------|----------|---------|\n",
    "| 0.904618 | 1.601126 | -1.265374 | -1.495569 | 0.0     |\n",
    "| 1.532814 | -0.691013 | -0.000450 | 0.973356 | 0.0     |\n",
    "| -0.367168 | -1.662094 | 1.257462 | 0.697353 | 1.0     |\n",
    "| -2.299623 | 1.344148 | -0.419396 | -2.767430 | 1.0     |\n",
    "| -0.539056 | -0.520896 | 0.148416 | 0.520688 | 1.0     |\n",
    "| ...      | ...      | ...      | ...      | ...     |\n",
    "| 0.706408 | 0.908746 | -0.465262 | 0.769656 | 0.0     |\n",
    "| 1.130878 | 0.958700 | -0.751494 | 0.639514 | 0.0     |\n",
    "| -1.804741 | 0.344855 | -0.217882 | -0.196042 | 1.0     |\n",
    "| -0.369069 | -0.631649 | -0.471420 | 0.563440 | 1.0     |\n",
    "| 1.394944 | -1.047881 | 0.753370 | 1.083987 | 0.0     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **2. Unsupervised Learning**  \n",
    "\n",
    "### **2.1 PCA for Visualization**  \n",
    "**Principal Component Analysis (PCA)** was applied to reduce the dataset to two dimensions for visualization. The first two principal components were plotted, with points colored by their actual class labels.\n",
    "\n",
    "**Observations (from plot):**  \n",
    "- The classes are **not linearly separable** in this reduced space.  \n",
    "- Some overlap between clusters suggests that linear models might struggle with classification.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PCA](PCA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2 K-Means Clustering**  \n",
    "**K-Means clustering** was applied with `k=2` (assuming two clusters).  \n",
    "\n",
    "**Results:**  \n",
    "- When using **only the first two PCA components**, k-means **misclassified several points**, showing that a 2D projection may not contain enough information.  \n",
    "- When using **all features**, clustering improved but misclassifications persisted.   \n",
    "\n",
    "We also obtain the following table:\n",
    "| Metric        | 0.0  | 1.0  | Macro Avg | Weighted Avg | Accuracy |\n",
    "|--------------|------|------|-----------|--------------|----------|\n",
    "| Precision    | 0.50 | 0.38 | 0.44      | 0.45         |   -   |\n",
    "| Recall       | 0.46 | 0.42 | 0.44      | 0.44         |    -      |\n",
    "| F1-Score     | 0.48 | 0.40 | 0.44      | 0.44         |    -      |\n",
    "| Support      | 762  | 610  | 1372      | 1372         |   -       |\n",
    "| Accuracy      | -  | -  | -      | -         |   0.44       |\n",
    "\n",
    "From which:\n",
    "1. Precision\n",
    "    - For class 0.0, the model's precision is 0.50, meaning that when it predicts class 0, it is correct 50% of the time.\n",
    "    - For class 1.0, the precision is 0.38, so when it predicts class 1, it is correct 38% of the time.\n",
    "\n",
    "2. Recall:\n",
    "    - For class 0.0, recall is 0.46, meaning the model correctly identifies 46% of actual class 0 instances.\n",
    "    - For class 1.0, recall is 0.42, meaning it correctly identifies 42% of actual class 1 instances.\n",
    "\n",
    "3. F1-Score:\n",
    "    - For class 0.0, the F1-score is 0.48, indicating a balance between precision and recall.\n",
    "    - For class 1.0, the F1-score is 0.40, showing lower performance in predicting this class.\n",
    "\n",
    "The model correctly classifies 44% of the total samples.\n",
    "\n",
    "comparing it to the table that takes the full data set:\n",
    "| Metric        | 0.0  | 1.0  | Accuracy | Macro Avg | Weighted Avg |\n",
    "|--------------|------|------|----------|-----------|--------------|\n",
    "| Precision    | 0.61 | 0.50 | -     | 0.56      | 0.56         |\n",
    "| Recall       | 0.55 | 0.57 |   -   | 0.56      | 0.56         |\n",
    "| F1-Score     | 0.58 | 0.53 |   -   | 0.56      | 0.56         |\n",
    "| Support      | 762  | 610  |   -   | 1372      | 1372         |\n",
    "| Accuracy      | -  | -  | 0.56      | -         |   -       |\n",
    "\n",
    "From which it is clear that PCA results in information loss as all metrics increase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2_nn_PCA](2_nn_PCA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2_nn_full](2_nn_full.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.3 t-SNE for Nonlinear Projection**  \n",
    "We used **t-SNE** for dimensionality reduction and visualized the data in 2D.  \n",
    "\n",
    "**Observations:**  \n",
    "- t-SNE provided a **better separation** than PCA, suggesting some non-linear class structure.  \n",
    "- The class distributions are still somewhat mixed, indicating potential challenges for clustering algorithms.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![t_SNE](t_SNE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.4 DBSCAN Clustering**  \n",
    "We applied **DBSCAN**, a density-based clustering algorithm.  \n",
    "\n",
    "**Results:**   \n",
    "- It identified core clusters but also **classified some points as noise**.  \n",
    "- The results depended significantly on hyperparameters `eps` and `min_samples`, of which eps is based on `n_neighbors` = 50.\n",
    "\n",
    "### DBSCAN Metrics with noise removed\n",
    "\n",
    "| Cluster | Precision | Recall | F1-Score | Support | **Accuracy** |\n",
    "|---------|-----------|--------|----------|---------|---------|\n",
    "| **0.0** | 1.00     | 0.83   | 0.91     | 521     | -  |\n",
    "| **1.0** | 0.96     | 0.80   | 0.88     | 369     |-     |\n",
    "| **2.0** | 0.00     | 0.00   | 0.00     | 0       |-     |\n",
    "| **3.0** | 0.00     | 0.00   | 0.00     | 0       |-     |\n",
    "| **Accuracy**  | -  | -  | - | - |**0.82**     |\n",
    "| **Macro Avg** | 0.49 | 0.41 | 0.45 | 890 |-     |\n",
    "| **Weighted Avg** | 0.99 | 0.82 | 0.90 | 890 |-     |\n",
    "\n",
    "From which:\n",
    "The table shows three clusters (0.0, 1.0, and 2.0), but clusters 2.0 and 3.0 have zero support, meaning no data points were assigned to them.\n",
    "The majority of the data points are assigned to clusters 0.0 and 1.0.\n",
    "\n",
    "1. Precision:\n",
    "    - Cluster 0.0 has a precision of 1.00, meaning all points assigned to this cluster were correctly grouped (no false positives).\n",
    "    - Cluster 1.0 has a precision of 0.96, indicating that most points were correctly assigned, but a few may have been misclassified.\n",
    "\n",
    "2. Recall:\n",
    "    - Cluster 0.0 has a recall of 0.83, meaning 83% of the actual members of this cluster were successfully identified.\n",
    "    - Cluster 1.0 has a recall of 0.80, meaning 80% of the actual points belonging to this cluster were captured.\n",
    "    - Since DBSCAN removes noise points, recall is slightly lower, as some valid points may have been left unclustered.\n",
    "\n",
    "3. F1-Score:\n",
    "    - Cluster 0.0: 0.91 (high, meaning both precision and recall are strong).\n",
    "    - Cluster 1.0: 0.88 (also high, but slightly lower than cluster 0.0).\n",
    "\n",
    "And given accuracy of 0.82, we have that 82% of points were correctly assigned to their respective clusters.\n",
    "\n",
    "- Macro Average: The unweighted mean of precision, recall, and F1-score across clusters. Since clusters 2.0 and 3.0 have zero support, their presence lowers the macro average.\n",
    "- Noise points were removed, improving the accuracy but slightly lowering recall (since some actual points were left out).\n",
    "- Weighted Average: Averages the scores while considering the number of points in each cluster. The weighted values are high because the meaningful clusters (0.0 and 1.0) have strong performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Best_epsilon](Best_epsilon.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DBSCAN](DBSCAN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **3. Supervised Learning**  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.1 Logistic Regression** \n",
    "- From the model we find a high accuracy of 0.9770 and by analyzing the confusion matrix, it is observed that the model makes incorrect predictions for only 23 out of 1372 instances.\n",
    "- Evaluating the effect of **regularization** using cross-validation finds the best parameter as.\n",
    "\n",
    "| Metric      | Best Score | Parameters                          |\n",
    "|------------|-----------|------------------------------------|\n",
    "| Accuracy   | 0.9900    | {'penalty': 'l1', 'C': 2.1544}   |\n",
    "| Precision  | 0.9901    | {'penalty': 'l1', 'C': 10.0}     |\n",
    "| Recall     | 0.9906    | {'penalty': 'l1', 'C': 2.1544}   |\n",
    "| F1-Score   | 0.9898    | {'penalty': 'l1', 'C': 2.1544}   |\n",
    "\n",
    "- So we have that the logistic model performed well using training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![confusion_matrix](confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **3.2 Decision Tree (ID3 Algorithm)**  \n",
    "- Greedy algorithm for tree construction.  \n",
    "- Hyperparameters (depth, minimum samples per leaf) were optimized via cross-validation. \n",
    "\n",
    "From the algorithim we get an accuracy of 0.9470 for the training data.\n",
    "\n",
    "Performing cross Validation we get:\n",
    "- Mean Accuracy: 0.9410\n",
    "- Best Accuracy: 0.9599\n",
    "- Best Tree:\n",
    "\n",
    "    - variance <= 0.0827  \n",
    "    - skewness <= -0.2305 → **1.0**  \n",
    "    - skewness > -0.2305  \n",
    "        - skewness <= 0.3693 → **1.0**  \n",
    "        - skewness > 0.3693  \n",
    "        - variance <= -0.7789  \n",
    "            - skewness <= 1.0834 → **1.0**  \n",
    "            - skewness > 1.0834 → **0.0**  \n",
    "        - variance > -0.7789 → **0.0**  \n",
    "    - variance > 0.0827  \n",
    "    - variance <= 0.9059  \n",
    "        - curtosis <= -0.3654  \n",
    "        - skewness <= 0.8130 → **1.0**  \n",
    "        - skewness > 0.8130 → **0.0**  \n",
    "        - curtosis > -0.3654 → **0.0**  \n",
    "    - variance > 0.9059 → **0.0** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **3.3 Naive Bayes Classifier**  \n",
    "- Assumes feature independence.  \n",
    "- Performed well in some cases but had lower accuracy due to its strong assumptions.\n",
    "\n",
    "From the Gaussian Naive Bayes Classifier we get 0.8421 accuracy and performing cross-validation we get:\n",
    "- Mean Accuracy: 0.8382\n",
    "- Best Accuracy: 0.8978\n",
    "\n",
    "- Best parameters:\n",
    " \n",
    "| Parameter       | Value |\n",
    "|----------------|----------------------------------------------------------------------------------|\n",
    "| n_labels       | 2 |\n",
    "| unique_labels  | [0., 1.] |\n",
    "| n_classes      | 2 |\n",
    "| mean           | [[ 0.7461,  0.4655, -0.2144, -0.0412,  0. ], [-0.6915, -0.4813,  0.1274, -0.0640,  1. ]] |\n",
    "| variance       | [[0.5237, 0.8054, 0.6522, 1.0811, 1e-9], [0.4388, 0.9101, 1.7591, 0.9921, 1e-9]] |\n",
    "| prior          | [-0.6161, -0.7767] |\n",
    "| Score          | 0.8978 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **3.4 k-Nearest Neighbors (k-NN)**  \n",
    "- Hyperparameter `k` was tuned via cross-validation.  \n",
    "- Performed well but computationally expensive.\n",
    "\n",
    "Assuming p = 2 and 5 clusters then we have an accuracy of 0.9900\n",
    "\n",
    "Performing cross-validation we get:\n",
    "- Best Hyperparameters: k=2, distance=euclidean, p=1\n",
    "- Best Cross-Validation Accuracy: 0.9985\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **3.3 Performance Comparison**  \n",
    "Analyzing **accuracy, precision, recall, and F1-score** on the test set for supervised.  \n",
    "\n",
    "| Model                | Accuracy | Precision | Recall | F1-Score | Support |\n",
    "|----------------------|----------|-----------|--------|----------|----------|\n",
    "| Naive Bayes | 0.8422      | **0**: 0.8486 <br> **1**: 0.8329       | **0**: 0.8785 <br> **1**: 0.7945    | **0**: 0.8633 <br> **1**: 0.8132      |**0**: 568 <br> **1**: 433      |\n",
    "| Decision Tree       | 0.9471      | **0**: 0.9813 <br> **1**: 0.9077       | **0**: 0.9243 <br> **1**: 0.9769    | **0**: 0.9519 <br> **1**: 0.9410      |**0**: 568 <br> **1**: 433      |\n",
    "|    k-NN      | 0.9970      | **0**: 1.0000 <br> **1**: 0.9931       | **0**: 0.9947 <br> **1**: 1.0000    | **0**: 0.9974 <br> **1**: 0.9965      |**0**: 568 <br> **1**: 433      |\n",
    "|  Logistic Regression  | 0.9770      | **0**: 0.9964 <br> **1**: 0.9535       | **0**: 0.9630 <br> **1**: 0.9954    | **0**: 0.9794 <br> **1**: 0.9740      |**0**: 568 <br> **1**: 433      |\n",
    "\n",
    "1. k-NN achieves the highest accuracy (0.9970) with near-perfect precision, recall, and F1-score for both classes, making it the best-performing model. However, k-NN can be sensitive to noisy data and computationally expensive for large datasets.\n",
    "\n",
    "2. Decision Tree also performs well (0.9471 accuracy) but is slightly weaker than k-NN. It has high precision and recall but may be prone to overfitting, depending on the depth of the tree.\n",
    "\n",
    "3. Logistic Regression performs slightly better than Decision Tree, with 0.9770 accuracy. It has high precision and recall but is slightly less effective for class 1, which may indicate some bias toward class 0.\n",
    "\n",
    "4. Naive Bayes has the lowest accuracy (0.8422) among the models, with slightly lower recall for class 1. This suggests it makes more false negatives for class 1, potentially due to its assumption of feature independence.\n",
    "\n",
    "\n",
    "Analyzing **accuracy, precision, recall, and F1-score** on the test set for unsupervised.\n",
    "| Model                | Accuracy | Precision | Recall | F1-Score | Support |\n",
    "|----------------------|----------|-----------|--------|----------|----------|\n",
    "|  k-means  | 0.44      | **0**: 0.50 <br> **1**: 0.38       | **0**: 0.46 <br> **1**: 0.42    | **0**: 0.48 <br> **1**: 0.40     |**0**: 762 <br> **1**: 610     |\n",
    "|  k-means (full data)  | 0.56      | **0**: 0.61 <br> **1**: 0.50       | **0**: 0.55 <br> **1**: 0.57    | **0**: 0.58 <br> **1**: 0.53      |**0**: 762 <br> **1**: 610      |\n",
    "|  DBSCAN (no Noise)  | 0.82      | **0**: 1.00 <br> **1**: 0.96       | **0**: 0.83 <br> **1**: 0.80    | **0**: 0.91 <br> **1**: 0.88      |**0**: 521 <br> **1**: 369      |\n",
    "\n",
    "\n",
    "The first set of models (Naïve Bayes, Decision Tree, k-NN, Logistic Regression) achieves strong accuracy scores, ranging from 84.22% to 99.70%, while the second set (k-means, k-means Full Data, DBSCAN without Noise) performs significantly worse, with accuracy ranging from 44% to 82%.\n",
    "\n",
    "This suggests that the first set of models is well-suited for the classification task, while the second set struggles with distinguishing between classes effectively\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **4.Recommendations**  \n",
    "\n",
    "1. **Feature Engineering:**  \n",
    "   - Use polynomial features to capture non-linear relationships or kernel methods for better class separation.  \n",
    "2. **Ensemble Methods:**  \n",
    "   - Use **Random Forest** or **Gradient Boosting** for better generalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
