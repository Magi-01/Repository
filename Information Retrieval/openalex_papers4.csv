id,title,abstract,year,concepts,abstract_text
https://openalex.org/W2122410182,Artificial intelligence: a modern approach,"{'The': [0], 'long-anticipated': [1], 'revision': [2], 'of': [3, 13, 22], 'this': [4], '#1': [5], 'selling': [6], 'book': [7], 'offers': [8], 'the': [9, 14, 18], 'most': [10], 'comprehensive,': [11], 'state': [12], 'art': [15], 'introduction': [16], 'to': [17], 'theory': [19], 'and': [20, 59, 96], 'practice': [21], 'artificial': [23, 101], 'intelligence': [24], 'for': [25], 'modern': [26], 'applications.': [27], 'Intelligent': [28], 'Agents.': [29], 'Solving': [30], 'Problems': [31], 'by': [32], 'Searching.': [33], 'Informed': [34], 'Search': [35], 'Methods.': [36], 'Game': [37], 'Playing.': [38], 'Agents': [39, 83], 'that': [40, 84], 'Reason': [41], 'Logically.': [42], 'First-order': [43], 'Logic.': [44, 52], 'Building': [45], 'a': [46], 'Knowledge': [47, 80], 'Base.': [48], 'Inference': [49], 'in': [50, 81, 88, 100], 'First-Order': [51], 'Logical': [53], 'Reasoning': [54, 63], 'Systems.': [55, 64], 'Practical': [56, 86], 'Planning.': [57], 'Planning': [58], 'Acting.': [60], 'Uncertainty.': [61], 'Probabilistic': [62], 'Making': [65, 68], 'Simple': [66], 'Decisions.': [67, 70], 'Complex': [69], 'Learning': [71, 74], 'from': [72], 'Observations.': [73], 'with': [75], 'Neural': [76], 'Networks.': [77], 'Reinforcement': [78], 'Learning.': [79, 82], 'Communicate.': [85], 'Communication': [87], 'English.': [89], 'Perception.': [90], 'Robotics.': [91], 'For': [92], 'computer': [93], 'professionals,': [94], 'linguists,': [95], 'cognitive': [97], 'scientists': [98], 'interested': [99], 'intelligence.': [102]}",1995,"['Artificial intelligence', 'Computer science', 'Inference', 'Artificial intelligence, situated approach', 'Probabilistic logic', 'Cognitive robotics', 'Symbolic artificial intelligence', 'Reinforcement learning', 'Cognitive science', 'Robot', 'Psychology']","The long-anticipated revision of this #1 selling book offers the most comprehensive, state of the art introduction to the theory and practice of artificial intelligence for modern applications. Intelligent Agents. Solving Problems by Searching. Informed Search Methods. Game Playing. Agents that Reason Logically. First-order Logic. Building a Knowledge Base. Inference in First-Order Logic. Logical Reasoning Systems. Practical Planning. Planning and Acting. Uncertainty. Probabilistic Reasoning Systems. Making Simple Decisions. Making Complex Decisions. Learning from Observations. Learning with Neural Networks. Reinforcement Learning. Knowledge in Learning. Agents that Communicate. Practical Communication in English. Perception. Robotics. For computer professionals, linguists, and cognitive scientists interested in artificial intelligence."
https://openalex.org/W2664267452,"Artificial intelligence in healthcare: past, present and future","{'Artificial': [0], 'intelligence': [1], '(AI)': [2], 'aims': [3], 'to': [4, 15, 48], 'mimic': [5], 'human': [6], 'cognitive': [7], 'functions.': [8], 'It': [9], 'is': [10], 'bringing': [11], 'a': [12], 'paradigm': [13], 'shift': [14], 'healthcare,': [16], 'powered': [17], 'by': [18], 'increasing': [19], 'availability': [20], 'of': [21, 27, 35, 51, 119, 150], 'healthcare': [22, 39, 52], 'data': [23, 53], 'and': [24, 40, 55, 74, 77, 101, 122, 130, 145], 'rapid': [25], 'progress': [26], 'analytics': [28], 'techniques.': [29], 'We': [30, 103, 133], 'survey': [31], 'the': [32, 69, 78, 109, 115], 'current': [33], 'status': [34], 'AI': [36, 44, 58, 96, 110, 139], 'applications': [37, 111], 'in': [38, 106, 112, 114], 'discuss': [41], 'its': [42], 'future.': [43], 'can': [45], 'be': [46], 'applied': [47], 'various': [49], 'types': [50], '(structured': [54], 'unstructured).': [56], 'Popular': [57], 'techniques': [59], 'include': [60, 98], 'machine': [61, 73], 'learning': [62], 'methods': [63], 'for': [64, 88, 147], 'structured': [65], 'data,': [66], 'such': [67, 141], 'as': [68, 82, 84, 125, 127, 142], 'classical': [70], 'support': [71], 'vector': [72], 'neural': [75], 'network,': [76], 'modern': [79], 'deep': [80], 'learning,': [81], 'well': [83, 126], 'natural': [85], 'language': [86], 'processing': [87], 'unstructured': [89], 'data.': [90], 'Major': [91], 'disease': [92], 'areas': [93, 118], 'that': [94], 'use': [95], 'tools': [97], 'cancer,': [99], 'neurology': [100], 'cardiology.': [102], 'then': [104], 'review': [105], 'more': [107], 'details': [108], 'stroke,': [113], 'three': [116], 'major': [117], 'early': [120], 'detection': [121], 'diagnosis,': [123], 'treatment,': [124], 'outcome': [128], 'prediction': [129], 'prognosis': [131], 'evaluation.': [132], 'conclude': [134], 'with': [135], 'discussion': [136], 'about': [137], 'pioneer': [138], 'systems,': [140], 'IBM': [143], 'Watson,': [144], 'hurdles': [146], 'real-life': [148], 'deployment': [149], 'AI.': [151]}",2017,"['Cognitive computing', 'Health care', 'Data science', 'Artificial intelligence', 'Computer science', 'Software deployment', 'Unstructured data', 'Watson', 'Applications of artificial intelligence', 'Big data', 'Analytics', 'IBM', 'Deep learning', 'Predictive analytics', 'Machine learning', 'Cognition', 'Medicine', 'Software engineering', 'Data mining', 'Materials science', 'Psychiatry', 'Economic growth', 'Economics', 'Nanotechnology']","Artificial intelligence (AI) aims to mimic human cognitive functions. It is bringing a paradigm shift to healthcare, powered by increasing availability of healthcare data and rapid progress of analytics techniques. We survey the current status of AI applications in healthcare and discuss its future. AI can be applied to various types of healthcare data (structured and unstructured). Popular AI techniques include machine learning methods for structured data, such as the classical support vector machine and neural network, and the modern deep learning, as well as natural language processing for unstructured data. Major disease areas that use AI tools include cancer, neurology and cardiology. We then review in more details the AI applications in stroke, in the three major areas of early detection and diagnosis, treatment, as well as outcome prediction and prognosis evaluation. We conclude with discussion about pioneer AI systems, such as IBM Watson, and hurdles for real-life deployment of AI."
https://openalex.org/W2891503716,Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI),"{'At': [0], 'the': [1, 4, 28, 45, 57, 101, 130, 142, 145, 149, 153], 'dawn': [2], 'of': [3, 16, 47, 60, 94, 129, 136, 144], 'fourth': [5], 'industrial': [6], 'revolution,': [7], 'we': [8, 147], 'are': [9], 'witnessing': [10], 'a': [11, 31, 41, 76], 'fast': [12], 'and': [13, 92, 123, 132, 160], 'widespread': [14], 'adoption': [15], 'artificial': [17], 'intelligence': [18], '(AI)': [19], 'in': [20], 'our': [21], 'daily': [22], 'life,': [23], 'which': [24], 'contributes': [25], 'to': [26, 44, 107, 125, 139], 'accelerating': [27], 'shift': [29], 'towards': [30], 'more': [32], 'algorithmic': [33], 'society.': [34], 'However,': [35], 'even': [36], 'with': [37], 'such': [38], 'unprecedented': [39], 'advancements,': [40], 'key': [42, 127], 'impediment': [43], 'use': [46], 'AI-based': [48, 95], 'systems': [49, 62], 'is': [50, 98], 'that': [51], 'they': [52], 'often': [53], 'lack': [54], 'transparency.': [55], 'Indeed,': [56], 'black-box': [58], 'nature': [59], 'these': [61], 'allows': [63], 'powerful': [64], 'predictions,': [65], 'but': [66], 'it': [67], 'cannot': [68], 'be': [69], 'directly': [70], 'explained.': [71], 'This': [72, 114], 'issue': [73], 'has': [74], 'triggered': [75], 'new': [77], 'debate': [78], 'on': [79], 'explainable': [80], 'AI': [81, 106], '(XAI).': [82], 'A': [83], 'research': [84, 137, 163], 'field': [85], 'holds': [86], 'substantial': [87], 'promise': [88], 'for': [89, 105, 120], 'improving': [90], 'trust': [91], 'transparency': [93], 'systems.': [96], 'It': [97], 'recognized': [99], 'as': [100], 'sine': [102], 'qua': [103], 'non': [104], 'continue': [108], 'making': [109], 'steady': [110], 'progress': [111], 'without': [112], 'disruption.': [113], 'survey': [115], 'provides': [116], 'an': [117], 'entry': [118], 'point': [119], 'interested': [121], 'researchers': [122], 'practitioners': [124], 'learn': [126], 'aspects': [128], 'young': [131], 'rapidly': [133], 'growing': [134], 'body': [135], 'related': [138], 'XAI.': [140], 'Through': [141], 'lens': [143], 'literature,': [146], 'review': [148], 'existing': [150], 'approaches': [151], 'regarding': [152], 'topic,': [154], 'discuss': [155], 'trends': [156], 'surrounding': [157], 'its': [158], 'sphere,': [159], 'present': [161], 'major': [162], 'trajectories.': [164]}",2018,"['Transparency (behavior)', 'Sine qua non', 'Computer science', 'Black box', 'Field (mathematics)', 'Data science', 'Key (lock)', 'Artificial intelligence', 'Operations research', 'Political science', 'Computer security', 'Engineering', 'Law', 'Mathematics', 'Pure mathematics']","At the dawn of the fourth industrial revolution, we are witnessing a fast and widespread adoption of artificial intelligence (AI) in our daily life, which contributes to accelerating the shift towards a more algorithmic society. However, even with such unprecedented advancements, a key impediment to the use of AI-based systems is that they often lack transparency. Indeed, the black-box nature of these systems allows powerful predictions, but it cannot be directly explained. This issue has triggered a new debate on explainable AI (XAI). A research field holds substantial promise for improving trust and transparency of AI-based systems. It is recognized as the sine qua non for AI to continue making steady progress without disruption. This survey provides an entry point for interested researchers and practitioners to learn key aspects of the young and rapidly growing body of research related to XAI. Through the lens of the literature, we review the existing approaches regarding the topic, discuss trends surrounding its sphere, and present major research trajectories."
https://openalex.org/W3017131514,Artificial Intelligence in Education: A Review,"{'The': [0, 110], 'purpose': [1], 'of': [2, 10, 32, 42, 56, 72, 81, 135, 154, 164, 249], 'this': [3], 'study': [4, 34, 74, 82, 111], 'was': [5, 35, 65], 'to': [6, 37, 142, 170, 187], 'assess': [7], 'the': [8, 30, 33, 38, 54, 70, 73, 84, 133, 152, 162, 212, 216], 'impact': [9], 'Artificial': [11, 76], 'Intelligence': [12], '(AI)': [13], 'on': [14, 17], 'education.': [15], 'Premised': [16], 'a': [18, 27, 60, 79], 'narrative': [19], 'and': [20, 40, 47, 63, 67, 83, 87, 95, 107, 119, 137, 144, 149, 167, 174, 195, 201, 203, 221, 224, 229, 240, 246], 'framework': [21], 'for': [22], 'assessing': [23], 'AI': [24, 43, 114, 130], 'identified': [25], 'from': [26], 'preliminary': [28], 'analysis,': [29], 'scope': [31], 'limited': [36], 'application': [39], 'effects': [41], 'in': [44, 92, 121, 127, 207, 231], 'administration,': [45], 'instruction,': [46], 'learning.': [48, 250], 'A': [49], 'qualitative': [50], 'research': [51, 61], 'approach,': [52], 'leveraging': [53], 'use': [55, 153, 163], 'literature': [57], 'review': [58], 'as': [59, 193], 'design': [62], 'approach': [64], 'used': [66, 120], 'effectively': [68, 200], 'facilitated': [69], 'realization': [71], 'purpose.': [75], 'intelligence': [77, 100], 'is': [78], 'field': [80], 'resulting': [85], 'innovations': [86], 'developments': [88], 'that': [89, 113], 'have': [90, 184], 'culminated': [91], 'computers,': [93], 'machines,': [94], 'other': [96, 160, 213], 'artifacts': [97], 'having': [98], 'human-like': [99], 'characterized': [101], 'by': [102, 124], 'cognitive': [103], 'abilities,': [104], 'learning,': [105], 'adaptability,': [106, 222], 'decision-making': [108], 'capabilities.': [109], 'ascertained': [112], 'has': [115, 226, 237], 'extensively': [116], 'been': [117, 185, 227], 'adopted': [118], 'education,': [122], 'particularly': [123], 'education': [125, 147], 'institutions,': [126], 'different': [128, 189], 'forms.': [129], 'initially': [131], 'took': [132], 'form': [134], 'computer': [136, 138, 156], 'related': [139], 'technologies,': [140, 161], 'transitioning': [141], 'web-based': [143, 168], 'online': [145], 'intelligent': [146], 'systems,': [148, 157], 'ultimately': [150], 'with': [151, 159, 178, 233], 'embedded': [155], 'together': [158], 'humanoid': [165], 'robots': [166], 'chatbots': [169], 'perform': [171, 188], ""instructors'"": [172], 'duties': [173], 'functions': [175], 'independently': [176], 'or': [177], 'instructors.': [179], 'Using': [180], 'these': [181], 'platforms,': [182], 'instructors': [183], 'able': [186], 'administrative': [190], 'functions,': [191], 'such': [192], 'reviewing': [194], 'grading': [196], ""students'"": [197, 234], 'assignments': [198], 'more': [199], 'efficiently,': [202], 'achieve': [204], 'higher': [205], 'quality': [206, 248], 'their': [208], 'teaching': [209], 'activities.': [210], 'On': [211], 'hand,': [214], 'because': [215], 'systems': [217], 'leverage': [218], 'machine': [219], 'learning': [220], 'curriculum': [223], 'content': [225], 'customized': [228], 'personalized': [230], 'line': [232], 'needs,': [235], 'which': [236], 'fostered': [238], 'uptake': [239], 'retention,': [241], 'thereby': [242], 'improving': [243], 'learners': [244], 'experience': [245], 'overall': [247]}",2020,"['Computer science', 'Adaptability', 'Personalized learning', 'Artificial intelligence', 'Curriculum', 'Knowledge management', 'Multimedia', 'Teaching method', 'Open learning', 'Cooperative learning', 'Mathematics education', 'Psychology', 'Biology', 'Ecology', 'Pedagogy']","The purpose of this study was to assess the impact of Artificial Intelligence (AI) on education. Premised on a narrative and framework for assessing AI identified from a preliminary analysis, the scope of the study was limited to the application and effects of AI in administration, instruction, and learning. A qualitative research approach, leveraging the use of literature review as a research design and approach was used and effectively facilitated the realization of the study purpose. Artificial intelligence is a field of study and the resulting innovations and developments that have culminated in computers, machines, and other artifacts having human-like intelligence characterized by cognitive abilities, learning, adaptability, and decision-making capabilities. The study ascertained that AI has extensively been adopted and used in education, particularly by education institutions, in different forms. AI initially took the form of computer and computer related technologies, transitioning to web-based and online intelligent education systems, and ultimately with the use of embedded computer systems, together with other technologies, the use of humanoid robots and web-based chatbots to perform instructors' duties and functions independently or with instructors. Using these platforms, instructors have been able to perform different administrative functions, such as reviewing and grading students' assignments more effectively and efficiently, and achieve higher quality in their teaching activities. On the other hand, because the systems leverage machine learning and adaptability, curriculum and content has been customized and personalized in line with students' needs, which has fostered uptake and retention, thereby improving learners experience and overall quality of learning."
https://openalex.org/W1543659671,Artificial Intelligence: A Guide to Intelligent Systems,"{'From': [0], 'the': [1, 4, 12, 60, 76, 87, 95, 118, 151, 154], 'Publisher:\r\nVirtually': [2], 'all': [3], 'literature': [5], 'on': [6, 29], 'artificial': [7], 'intelligence': [8], 'is': [9, 137], 'expressed': [10], 'in': [11, 75, 156], 'jargon': [13], 'of': [14, 57, 68, 97, 153], 'commuter': [15], 'science,': [16, 129], 'crowded': [17], 'with': [18, 54, 66], 'complex': [19], 'matrix': [20], 'algebra': [21], 'and': [22, 43, 59, 159, 167], 'differential': [23], 'equations.': [24], 'Unlike': [25], 'many': [26], 'other': [27], 'books': [28], 'computer': [30, 98, 128], 'intelligence,': [31, 99], 'this': [32], 'one': [33], 'demonstrates': [34], 'that': [35], 'most': [36], 'ideas': [37], 'behind': [38], 'intelligent': [39, 111], 'systems': [40, 131, 158], 'are': [41], 'simple': [42], 'straightforward.': [44], 'The': [45, 72, 135], 'book': [46, 77, 90, 119, 136], 'has': [47], 'evolved': [48], 'from': [49], 'lectures': [50], 'given': [51, 85], 'to': [52, 94, 150], 'students': [53], 'little': [55], 'knowledge': [56, 67], 'calculus,': [58], 'reader': [61], 'needs': [62], 'no': [63], 'prerequisites': [64], 'associated': [65], 'any': [69], 'programming': [70], 'language.': [71], 'methods': [73], 'used': [74, 122], 'have': [78], 'been': [79], 'extensively': [80], 'tested': [81], 'through': [82], 'several': [83], 'courses': [84], 'by': [86], 'author.': [88], '\r\n\r\nThe': [89], 'provides': [91], 'an': [92, 124], 'introduction': [93], 'field': [96], 'covering': [100], '\r\n\r\nrule-based': [101], 'expert': [102, 104, 106], 'systems,\r\nfuzzy': [103], 'systems,\r\nframe-based': [105], 'systems,\r\nartificail': [107], 'neural': [108], 'networks,\r\nevolutionary': [109], 'computation,\r\nhybrid': [110], 'systems,\r\nknowledge': [112], 'engineering,\r\ndata': [113], 'mining.\r\n\r\n\r\nIn': [114], 'a': [115, 141], 'university': [116], 'setting': [117], 'can': [120, 174], 'be': [121], 'as': [123, 140], 'introductory': [125], 'course': [126], 'within': [127], 'information': [130], 'or': [132], 'engineering': [133], 'departments.': [134], 'also': [138], 'suitable': [139], 'self-study': [142], 'guide': [143], 'for': [144], 'non-computer': [145], 'science': [146], 'professionals,': [147], 'giving': [148], 'access': [149], 'state': [152], 'art': [155], 'knowledge-based': [157], 'computational': [160], 'intelligence.': [161], 'Everyone': [162], 'who': [163], 'faces': [164], 'challenging': [165], 'problems': [166], 'cannot': [168], 'solve': [169], 'them': [170], 'using': [171], 'traditional': [172], 'approaches': [173], 'benefit': [175]}",2001,"['Computer science', 'Jargon', 'Expert system', 'Intelligent decision support system', 'Computational intelligence', 'Artificial intelligence', 'Applications of artificial intelligence', 'Simple (philosophy)', 'Field (mathematics)', 'Data science', 'Mathematics', 'Epistemology', 'Pure mathematics', 'Linguistics', 'Philosophy']","From the Publisher:
Virtually all the literature on artificial intelligence is expressed in the jargon of commuter science, crowded with complex matrix algebra and differential equations. Unlike many other books on computer intelligence, this one demonstrates that most ideas behind intelligent systems are simple and straightforward. The book has evolved from lectures given to students with little knowledge of calculus, and the reader needs no prerequisites associated with knowledge of any programming language. The methods used in the book have been extensively tested through several courses given by the author. 

The book provides an introduction to the field of computer intelligence, covering 

rule-based expert systems,
fuzzy expert systems,
frame-based expert systems,
artificail neural networks,
evolutionary computation,
hybrid intelligent systems,
knowledge engineering,
data mining.


In a university setting the book can be used as an introductory course within computer science, information systems or engineering departments. The book is also suitable as a self-study guide for non-computer science professionals, giving access to the state of the art in knowledge-based systems and computational intelligence. Everyone who faces challenging problems and cannot solve them using traditional approaches can benefit"
https://openalex.org/W3021909058,Artificial Intelligence: A Modern Approach,"{'&lt;p&gt;Humankind': [0], 'has': [1, 91, 205, 216, 328, 447], 'given': [2], 'itself': [3], 'the': [4, 9, 111, 136, 145, 192, 201, 209, 214, 222, 236, 246, 272, 294, 306, 324, 342, 371, 375, 394, 420, 436, 442, 445, 518, 526], 'scientific': [5], 'name': [6, 247], 'homo': [7], 'sapiens--man': [8], 'wise--because': [10], 'our': [11, 18, 22, 131], 'mental': [12, 382], 'capacities': [13], 'are': [14, 56, 82, 187, 462], 'so': [15], 'important': [16], 'to': [17, 34, 41, 45, 62, 73, 161, 217, 224, 278, 352, 434, 450, 490, 522, 544, 548], 'everyday': [19, 132], 'lives': [20, 133], 'and': [21, 53, 84, 95, 134, 165, 171, 305, 308, 358, 388, 430, 459, 467, 487, 502, 520, 524], 'sense': [23], 'of': [24, 28, 139, 144, 228, 235, 314, 336, 341, 367, 428, 439, 441, 479, 551], 'self.': [25], 'The': [26, 334, 365], 'field': [27], 'artificial': [29, 513], 'intelligence,': [30, 429, 514], 'or': [31, 159, 197, 361], 'AI,': [32, 322], 'attempts': [33], 'understand': [35, 69, 353], 'intelligent': [36, 64, 80, 230, 418], 'entities.': [37], 'Thus,': [38], 'one': [39, 108, 143, 234, 317, 340], 'reason': [40, 72], 'study': [42, 74, 315, 335], 'it': [43, 115, 150, 267, 310, 558], 'is': [44, 76, 116, 149, 211, 219, 233, 268, 338, 559], 'learn': [46], 'more': [47, 172, 452, 465, 468], 'about': [48, 180, 260], 'ourselves.': [49], 'But': [50, 408], 'unlike': [51, 191], 'philosophy': [52], 'psychology,': [54], 'which': [55, 530], 'also': [57, 339], 'concerned': [58], 'with': [59, 120, 183, 264], 'AI': [60, 75, 90, 141, 204, 232, 473, 541], 'strives': [61], 'build': [63], 'entities': [65, 81], 'as': [66, 68, 271, 409, 411, 470, 485, 494], 'well': [67, 410], 'them.': [70], 'Another': [71], 'that': [77, 118, 208, 252, 292, 309, 393], 'these': [78, 381], 'constructed': [79], 'interesting': [83, 469], 'useful': [85], 'in': [86, 103, 113, 203, 221, 243, 282, 287, 370, 507, 540], 'their': [87, 536, 546], 'own': [88], 'right.': [89], 'produced': [92], 'many': [93, 312, 431, 455], 'significant': [94], 'impressive': [96], 'products': [97], 'even': [98], 'at': [99, 251, 456], 'this': [100, 556], 'early': [101, 372], 'stage': [102], 'its': [104], 'development.': [105], 'Although': [106], 'no': [107], 'can': [109, 318, 542], 'predict': [110], 'future': [112, 137], 'detail,': [114], 'clear': [117], 'computers': [119, 369], 'human-level': [121], 'intelligence': [122, 337], '(or': [123], 'better)': [124], 'would': [125, 275], 'have': [126, 297, 350, 532], 'a': [127, 153, 167, 331, 385, 405, 413, 423, 471, 476, 561], 'huge': [128, 477], 'impact': [129], 'on': [130, 135, 323, 529], 'course': [138], 'civilization.': [140], 'addresses': [142], 'ultimate': [146], 'puzzles.': [147], 'How': [148, 176], 'possible': [151], 'for': [152, 194, 259, 330, 400, 415, 425], 'slow,': [154], 'tiny': [155], 'brain{brain},': [156], 'whether': [157], 'biological': [158], 'electronic,': [160], 'perceive,': [162], 'understand,': [163], 'predict,': [164], 'manipulate': [166], 'world': [168], 'far': [169], 'larger': [170], 'complicated': [173], 'than': [174, 454], 'itself?': [175], 'do': [177, 218], 'we': [178], 'go': [179], 'making': [181], 'something': [182], 'those': [184], 'properties?': [185], 'These': [186], 'hard': [188], 'questions,': [189], 'but': [190, 377], 'search': [193], 'faster-than-light': [195], 'travel': [196], 'an': [198, 226, 229], 'antigravity': [199], 'device,': [200], 'researcher': [202, 215], 'solid': [206], 'evidence': [207], 'quest': [210], 'possible.': [212], 'All': [213], 'look': [220], 'mirror': [223], 'see': [225], 'example': [227], 'system.': [231], 'newest': [237], 'disciplines.': [238, 284, 344], 'It': [239], 'was': [240, 248], 'formally': [241], 'initiated': [242], '1956,': [244], 'when': [245], 'coined,': [249], 'although': [250], 'point': [253], 'work': [254], 'had': [255], 'been': [256, 299, 533], 'under': [257], 'way': [258], 'five': [261], 'years.': [262], 'Along': [263], 'modern': [265, 460], 'genetics,': [266], 'regularly': [269], 'cited': [270], '``field': [273], 'I': [274], 'most': [276], 'like': [277], 'be': [279, 363, 451], ""in''by"": [280], 'scientists': [281, 506], 'other': [283, 325, 508], 'A': [285], 'student': [286], 'physics': [288], 'might': [289], 'reasonably': [290], 'feel': [291], 'all': [293, 535], 'good': [295], 'ideas': [296, 461], 'already': [298], 'taken': [300], 'by': [301], 'Galileo,': [302], 'Newton,': [303], 'Einstein,': [304], 'rest,': [307], 'takes': [311], 'years': [313], 'before': [316], 'contribute': [319], 'new': [320, 395], 'ideas.': [321], 'hand,': [326], 'still': [327], 'openings': [329], 'full-time': [332], 'Einstein.': [333], 'oldest': [343], 'For': [345], 'over': [346], '2000': [347], 'years,': [348], 'philosophers': [349], 'tried': [351], 'how': [354], 'seeing,': [355], 'learning,': [356], 'remembering,': [357], 'reasoning': [359], 'could,': [360], 'should,': [362], 'done.': [364], 'advent': [366], 'usable': [368], '1950s': [373], 'turned': [374, 448], 'learned': [376], 'armchair': [378], 'speculation': [379], 'concerning': [380], 'faculties': [383], 'into': [384, 444, 512], 'real': [386], 'experimental': [387], 'theoretical': [389], 'discipline.': [390], 'Many': [391], 'felt': [392], '``Electronic': [396], ""Super-Brains''had"": [397], 'unlimited': [398], 'potential': [399], 'intelligence.': [401], '``Faster': [402], 'Than': [403], ""Einstein''was"": [404], 'typical': [406], 'headline.': [407], 'providing': [412], 'vehicle': [414], 'creating': [416], 'artificially': [417], 'entities,': [419], 'computer': [421], 'provides': [422], 'tool': [424], 'testing': [426], 'theories': [427, 432], 'failed': [433], 'withstand': [435], 'test--a': [437], 'case': [438], '``out': [440], 'armchair,': [443], ""fire.''AI"": [446], 'out': [449], 'difficult': [453], 'first': [457], 'imagined,': [458], 'much': [463], 'richer,': [464], 'subtle,': [466], 'result.': [472], 'currently': [474], 'encompasses': [475], 'variety': [478], 'subfields,': [480], 'from': [481], 'general-purpose': [482], 'areas': [483], 'such': [484, 493], 'perception': [486], 'logical': [488], 'reasoning,': [489], 'specific': [491], 'tasks': [492, 528], 'playing': [495], 'chess,': [496], 'proving': [497], 'mathematical': [498], 'theorems,': [499], 'writing': [500], 'poetry{poetry},': [501], 'diagnosing': [503], 'diseases.': [504], 'Often,': [505], 'fields': [509], 'move': [510], 'gradually': [511], 'where': [515], 'they': [516, 531], 'find': [517], 'tools': [519], 'vocabulary': [521], 'systematize': [523], 'automate': [525], 'intellectual': [527, 553], 'working': [534], 'lives.': [537], 'Similarly,': [538], 'workers': [539], 'choose': [543], 'apply': [545], 'methods': [547], 'any': [549], 'area': [550], 'human': [552], 'endeavor.': [554], 'In': [555], 'sense,': [557], 'truly': [560], 'universal': [562], 'field.': [563], '&lt;/p&gt;': [564]}",1995,"['Artificial general intelligence', 'Cognitive science', 'Computer science', 'Civilization', 'Field (mathematics)', 'Everyday life', 'Artificial intelligence', 'Human intelligence', 'Epistemology', 'Psychology', 'Data science', 'Philosophy', 'History', 'Pure mathematics', 'Archaeology', 'Mathematics']","&lt;p&gt;Humankind has given itself the scientific name homo sapiens--man the wise--because our mental capacities are so important to our everyday lives and our sense of self. The field of artificial intelligence, or AI, attempts to understand intelligent entities. Thus, one reason to study it is to learn more about ourselves. But unlike philosophy and psychology, which are also concerned with AI strives to build intelligent entities as well as understand them. Another reason to study AI is that these constructed intelligent entities are interesting and useful in their own right. AI has produced many significant and impressive products even at this early stage in its development. Although no one can predict the future in detail, it is clear that computers with human-level intelligence (or better) would have a huge impact on our everyday lives and on the future course of civilization. AI addresses one of the ultimate puzzles. How is it possible for a slow, tiny brain{brain}, whether biological or electronic, to perceive, understand, predict, and manipulate a world far larger and more complicated than itself? How do we go about making something with those properties? These are hard questions, but unlike the search for faster-than-light travel or an antigravity device, the researcher in AI has solid evidence that the quest is possible. All the researcher has to do is look in the mirror to see an example of an intelligent system. AI is one of the newest disciplines. It was formally initiated in 1956, when the name was coined, although at that point work had been under way for about five years. Along with modern genetics, it is regularly cited as the ``field I would most like to be in''by scientists in other disciplines. A student in physics might reasonably feel that all the good ideas have already been taken by Galileo, Newton, Einstein, and the rest, and that it takes many years of study before one can contribute new ideas. AI, on the other hand, still has openings for a full-time Einstein. The study of intelligence is also one of the oldest disciplines. For over 2000 years, philosophers have tried to understand how seeing, learning, remembering, and reasoning could, or should, be done. The advent of usable computers in the early 1950s turned the learned but armchair speculation concerning these mental faculties into a real experimental and theoretical discipline. Many felt that the new ``Electronic Super-Brains''had unlimited potential for intelligence. ``Faster Than Einstein''was a typical headline. But as well as providing a vehicle for creating artificially intelligent entities, the computer provides a tool for testing theories of intelligence, and many theories failed to withstand the test--a case of ``out of the armchair, into the fire.''AI has turned out to be more difficult than many at first imagined, and modern ideas are much richer, more subtle, and more interesting as a result. AI currently encompasses a huge variety of subfields, from general-purpose areas such as perception and logical reasoning, to specific tasks such as playing chess, proving mathematical theorems, writing poetry{poetry}, and diagnosing diseases. Often, scientists in other fields move gradually into artificial intelligence, where they find the tools and vocabulary to systematize and automate the intellectual tasks on which they have been working all their lives. Similarly, workers in AI can choose to apply their methods to any area of human intellectual endeavor. In this sense, it is truly a universal field. &lt;/p&gt;"
https://openalex.org/W2979906316,How artificial intelligence will change the future of marketing,"{'Abstract': [0], 'In': [1], 'the': [2, 30, 38, 74, 93, 108], 'future,': [3, 94], 'artificial': [4], 'intelligence': [5, 43], '(AI)': [6], 'is': [7, 50], 'likely': [8], 'to': [9, 102], 'substantially': [10], 'change': [11, 91], 'both': [12], 'marketing': [13, 85], 'strategies': [14, 86], 'and': [15, 47, 87, 105], 'customer': [16, 88], 'behaviors.': [17], 'Building': [18], 'from': [19], 'not': [20, 82], 'only': [21, 83], 'extant': [22], 'research': [23, 56, 78], 'but': [24, 95], 'also': [25, 96], 'extensive': [26], 'interactions': [27], 'with': [28], 'practice,': [29], 'authors': [31, 75, 109], 'propose': [32, 76], 'a': [33, 53, 59, 70, 77], 'multidimensional': [34], 'framework': [35], 'for': [36], 'understanding': [37], 'impact': [39], 'of': [40, 61], 'AI': [41, 49, 111], 'involving': [42], 'levels,': [44], 'task': [45], 'types,': [46], 'whether': [48], 'embedded': [51], 'in': [52, 92], 'robot.': [54], 'Prior': [55], 'typically': [57], 'addresses': [58, 81], 'subset': [60], 'these': [62], 'dimensions;': [63], 'this': [64], 'paper': [65], 'integrates': [66], 'all': [67], 'three': [68], 'into': [69], 'single': [71], 'framework.': [72], 'Next,': [73], 'agenda': [79], 'that': [80], 'how': [84], 'behaviors': [89], 'will': [90, 112], 'highlights': [97], 'important': [98], 'policy': [99], 'questions': [100], 'relating': [101], 'privacy,': [103], 'bias': [104], 'ethics.': [106], 'Finally,': [107], 'suggest': [110], 'be': [113], 'more': [114], 'effective': [115], 'if': [116], 'it': [117], 'augments': [118], '(rather': [119], 'than': [120], 'replaces)': [121], 'human': [122], 'managers.': [123]}",2019,"['Extant taxon', 'Task (project management)', 'Computer science', 'Marketing', 'Marketing research', 'Knowledge management', 'Artificial intelligence', 'Data science', 'Business', 'Management', 'Economics', 'Evolutionary biology', 'Biology']","Abstract In the future, artificial intelligence (AI) is likely to substantially change both marketing strategies and customer behaviors. Building from not only extant research but also extensive interactions with practice, the authors propose a multidimensional framework for understanding the impact of AI involving intelligence levels, task types, and whether AI is embedded in a robot. Prior research typically addresses a subset of these dimensions; this paper integrates all three into a single framework. Next, the authors propose a research agenda that addresses not only how marketing strategies and customer behaviors will change in the future, but also highlights important policy questions relating to privacy, bias and ethics. Finally, the authors suggest AI will be more effective if it augments (rather than replaces) human managers."
https://openalex.org/W4382987554,ARTIFICIAL INTELLIGENCE FOR THE REAL WORLD,"{'Artificial': [0], 'intelligence': [1, 22, 68], '(A.I.)': [2], 'is': [3, 24, 28], 'a': [4, 25, 48], 'multidisciplinary': [5], 'field': [6], 'aimed': [7], 'at': [8], 'automating': [9], 'tasks': [10], 'that': [11, 27], 'currently': [12], 'need': [13], 'human': [14], 'intelligence.Despite': [15], 'its': [16], 'lack': [17], 'of': [18, 32], 'general': [19], 'familiarity,': [20], 'artificial': [21, 67], '(AI)': [23, 69], 'technology': [26], 'revolutionizing': [29], 'every': [30], 'aspect': [31], 'life.This': [33], 'article': [34], 'aims': [35], 'to': [36, 44, 53], 'educate': [37], 'laypeople': [38], 'about': [39], 'AI': [40], 'and': [41, 61, 74], 'encourage': [42], 'them': [43], 'utilize': [45], 'it': [46, 72, 76], 'as': [47], 'tool': [49], 'in': [50, 80, 84], 'many': [51], 'disciplines': [52], 'rethink': [54], 'how': [55, 71, 75], 'we': [56], 'combine': [57], 'data,': [58], 'analyze': [59], 'it,': [60], 'make': [62], 'choices.We': [63], 'quickly': [64], 'covered': [65], 'what': [66], 'is,': [70], 'works,': [73], 'may': [77], 'be': [78], 'applied': [79], 'our': [81], 'daily': [82], 'lives': [83], 'this': [85], 'article.': [86]}",2023,"['Computer science', 'Artificial intelligence']","Artificial intelligence (A.I.) is a multidisciplinary field aimed at automating tasks that currently need human intelligence.Despite its lack of general familiarity, artificial intelligence (AI) is a technology that is revolutionizing every aspect of life.This article aims to educate laypeople about AI and encourage them to utilize it as a tool in many disciplines to rethink how we combine data, analyze it, and make choices.We quickly covered what artificial intelligence (AI) is, how it works, and how it may be applied in our daily lives in this article."
https://openalex.org/W2927351257,Causability and explainability of artificial intelligence in medicine,"{'Explainable': [0, 53], 'artificial': [1], 'intelligence': [2], '(AI)': [3], 'is': [4, 15, 77, 150, 156, 163, 171, 179], 'attracting': [5], 'much': [6], 'interest': [7], 'in': [8, 32, 142, 160], 'medicine.': [9], 'Technically,': [10], 'the': [11, 37, 41, 57, 96, 104, 112, 151], 'problem': [12], 'of': [13, 36, 43, 59, 63, 89, 106, 114, 135, 139, 147, 153, 166, 174, 184], 'explainability': [14, 127, 159, 170], 'as': [16, 18, 130, 132], 'old': [17], 'AI': [19, 23, 54], 'itself': [20], 'and': [21, 61, 128, 138, 186, 191], 'classic': [22], 'represented': [24], 'comprehensible': [25], 'retraceable': [26], 'approaches.': [27], 'However,': [28], 'their': [29], 'weakness': [30], 'was': [31], 'dealing': [33], 'with': [34, 56], 'uncertainties': [35], 'real': [38], 'world.': [39], 'Through': [40], 'introduction': [42], 'probabilistic': [44], 'learning,': [45], 'applications': [46], 'became': [47], 'increasingly': [48, 51], 'successful,': [49], 'but': [50], 'opaque.': [52], 'deals': [55], 'implementation': [58], 'transparency': [60], 'traceability': [62], 'statistical': [64], 'black‐box': [65], 'machine': [66], 'learning': [67, 71], 'methods,': [68], 'particularly': [69], 'deep': [70], '(DL).': [72], 'We': [73], 'argue': [74], 'that': [75, 99, 161], 'there': [76], 'a': [78, 87, 133, 164, 167, 172, 175], 'need': [79, 93], 'to': [80, 124], 'go': [81], 'beyond': [82], 'explainable': [83, 90], 'AI.': [84], 'To': [85], 'reach': [86], 'level': [88], 'medicine': [91], 'we': [92, 119], 'causability.': [94], 'In': [95, 116], 'same': [97], 'way': [98], 'usability': [100], 'encompasses': [101, 109], 'measurements': [102, 110], 'for': [103, 111], 'quality': [105, 113], 'use,': [107], 'causability': [108, 129, 162], 'explanations.': [115], 'this': [117, 148], 'article,': [118], 'provide': [120], 'some': [121], 'necessary': [122], 'definitions': [123], 'discriminate': [125], 'between': [126], 'well': [131], 'use‐case': [134], 'DL': [136], 'interpretation': [137], 'human': [140], 'explanation': [141], 'histopathology.': [143], 'The': [144], 'main': [145], 'contribution': [146], 'article': [149, 178], 'notion': [152], 'causability,': [154], 'which': [155], 'differentiated': [157], 'from': [158], 'property': [165, 173], 'person,': [168], 'while': [169], 'system': [176], 'This': [177], 'categorized': [180], 'under:': [181], 'Fundamental': [182], 'Concepts': [183], 'Data': [185], 'Knowledge': [187], '&gt;': [188], 'Human': [189], 'Centricity': [190], 'User': [192], 'Interaction': [193]}",2019,"['Transparency (behavior)', 'Artificial intelligence', 'Computer science', 'Usability', 'Probabilistic logic', 'Property (philosophy)', 'Quality (philosophy)', 'Traceability', 'Data science', 'Machine learning', 'Human–computer interaction', 'Epistemology', 'Software engineering', 'Computer security', 'Philosophy']","Explainable artificial intelligence (AI) is attracting much interest in medicine. Technically, the problem of explainability is as old as AI itself and classic AI represented comprehensible retraceable approaches. However, their weakness was in dealing with uncertainties of the real world. Through the introduction of probabilistic learning, applications became increasingly successful, but increasingly opaque. Explainable AI deals with the implementation of transparency and traceability of statistical black‐box machine learning methods, particularly deep learning (DL). We argue that there is a need to go beyond explainable AI. To reach a level of explainable medicine we need causability. In the same way that usability encompasses measurements for the quality of use, causability encompasses measurements for the quality of explanations. In this article, we provide some necessary definitions to discriminate between explainability and causability as well as a use‐case of DL interpretation and of human explanation in histopathology. The main contribution of this article is the notion of causability, which is differentiated from explainability in that causability is a property of a person, while explainability is a property of a system This article is categorized under: Fundamental Concepts of Data and Knowledge &gt; Human Centricity and User Interaction"
https://openalex.org/W2950865323,Edge Intelligence: Paving the Last Mile of Artificial Intelligence With Edge Computing,"{'With': [0], 'the': [1, 6, 33, 52, 60, 74, 78, 86, 89, 109, 113, 159, 169, 184, 194, 202, 211, 226], 'breakthroughs': [2], 'in': [3, 149], 'deep': [4, 220], 'learning,': [5], 'recent': [7, 160, 185], 'years': [8], 'have': [9], 'witnessed': [10], 'a': [11, 121, 138, 154, 180], 'booming': [12], 'of': [13, 35, 40, 44, 57, 88, 141, 162, 183, 210], 'artificial': [14], 'intelligence': [15, 132], '(AI)': [16], 'applications': [17], 'and': [18, 38, 46, 106, 153, 172, 196, 215, 249], 'services,': [19], 'spanning': [20], 'from': [21, 108], 'personal': [22], 'assistant': [23], 'to': [24, 27, 51, 72, 77, 83, 112, 136], 'recommendation': [25], 'systems': [26], 'video/audio': [28], 'surveillance.': [29], 'More': [30], 'recently,': [31], 'with': [32], 'proliferation': [34], 'mobile': [36, 45], 'computing': [37, 104], 'Internet': [39], 'Things': [41], '(IoT),': [42], 'billions': [43], 'IoT': [47], 'devices': [48], 'are': [49], 'connected': [50], 'Internet,': [53], 'generating': [54], 'zillions': [55], 'bytes': [56], 'data': [58], 'at': [59, 201, 225], 'network': [61, 79, 110, 114, 203, 227], 'edge.': [62, 204, 228], 'Driving': [63], 'by': [64, 167], 'this': [65, 95, 176, 240], 'trend,': [66], 'there': [67], 'is': [68, 134, 147, 164], 'an': [69, 99, 208], 'urgent': [70], 'need': [71], 'push': [73], 'AI': [75, 129, 173, 199], 'frontiers': [76], 'edge': [80, 90, 97, 128, 131], 'so': [81], 'as': [82, 120], 'fully': [84], 'unleash': [85], 'potential': [87], 'big': [91], 'data.': [92], 'To': [93, 175], 'meet': [94], 'demand,': [96], 'computing,': [98], 'emerging': [100, 216], 'paradigm': [101], 'that': [102, 239], 'pushes': [103], 'tasks': [105], 'services': [107], 'core': [111], 'edge,': [115], 'has': [116], 'been': [117], 'widely': [118], 'recognized': [119], 'promising': [122], 'solution.': [123], 'The': [124], 'resulted': [125], 'new': [126], 'interdiscipline,': [127], 'or': [130], '(EI),': [133], 'beginning': [135], 'receive': [137], 'tremendous': [139], 'amount': [140], 'interest.': [142], 'However,': [143], 'research': [144, 186, 233, 252], 'on': [145, 188, 235, 254], 'EI': [146, 163], 'still': [148], 'its': [150], 'infancy': [151], 'stage,': [152], 'dedicated': [155], 'venue': [156], 'for': [157, 198, 219], 'exchanging': [158], 'advances': [161], 'highly': [165], 'desired': [166], 'both': [168], 'computer': [170], 'system': [171], 'communities.': [174], 'end,': [177], 'we': [178, 191, 230], 'conduct': [179], 'comprehensive': [181], 'survey': [182, 241], 'efforts': [187], 'EI.': [189, 236, 255], 'Specifically,': [190], 'first': [192], 'review': [193], 'background': [195], 'motivation': [197], 'running': [200], 'We': [205, 237], 'then': [206], 'provide': [207], 'overview': [209], 'overarching': [212], 'architectures,': [213], 'frameworks,': [214], 'key': [217], 'technologies': [218], 'learning': [221], 'model': [222], 'toward': [223], 'training/inference': [224], 'Finally,': [229], 'discuss': [231], 'future': [232], 'opportunities': [234], 'believe': [238], 'will': [242], 'elicit': [243], 'escalating': [244], 'attentions,': [245], 'stimulate': [246], 'fruitful': [247], 'discussions,': [248], 'inspire': [250], 'further': [251], 'ideas': [253]}",2019,"['Edge computing', 'Edge device', 'Computer science', 'Enhanced Data Rates for GSM Evolution', 'Data science', 'Deep learning', 'Applications of artificial intelligence', 'Big data', 'The Internet', 'Artificial intelligence', 'Mobile edge computing', 'Multimedia', 'Cloud computing', 'World Wide Web', 'Data mining', 'Operating system']","With the breakthroughs in deep learning, the recent years have witnessed a booming of artificial intelligence (AI) applications and services, spanning from personal assistant to recommendation systems to video/audio surveillance. More recently, with the proliferation of mobile computing and Internet of Things (IoT), billions of mobile and IoT devices are connected to the Internet, generating zillions bytes of data at the network edge. Driving by this trend, there is an urgent need to push the AI frontiers to the network edge so as to fully unleash the potential of the edge big data. To meet this demand, edge computing, an emerging paradigm that pushes computing tasks and services from the network core to the network edge, has been widely recognized as a promising solution. The resulted new interdiscipline, edge AI or edge intelligence (EI), is beginning to receive a tremendous amount of interest. However, research on EI is still in its infancy stage, and a dedicated venue for exchanging the recent advances of EI is highly desired by both the computer system and AI communities. To this end, we conduct a comprehensive survey of the recent research efforts on EI. Specifically, we first review the background and motivation for AI running at the network edge. We then provide an overview of the overarching architectures, frameworks, and emerging key technologies for deep learning model toward training/inference at the network edge. Finally, we discuss future research opportunities on EI. We believe that this survey will elicit escalating attentions, stimulate fruitful discussions, and inspire further research ideas on EI."
https://openalex.org/W2911605224,Artificial intelligence in cancer imaging: Clinical challenges and applications,"{'Abstract': [0], 'Judgement,': [1], 'as': [2, 199], 'one': [3], 'of': [4, 8, 14, 37, 50, 71, 78, 88, 111, 120, 125, 137, 142, 145, 160, 167, 197, 204], 'the': [5, 12, 41, 47, 65, 86, 108, 126, 143, 157, 164, 191, 194, 246], 'core': [6], 'tenets': [7], 'medicine,': [9], 'relies': [10, 82], 'upon': [11, 83], 'integration': [13], 'multilayered': [15], 'data': [16], 'with': [17, 35], 'nuanced': [18], 'decision': [19], 'making.': [20], 'Cancer': [21], 'offers': [22], 'a': [23, 184], 'unique': [24], 'context': [25], 'for': [26, 242], 'medical': [27, 202], 'decisions': [28, 171], 'given': [29], 'not': [30, 175, 238], 'only': [31], 'its': [32, 133], 'variegated': [33], 'forms': [34], 'evolution': [36], 'disease': [38, 79, 146], 'but': [39], 'also': [40], 'need': [42], 'to': [43, 54, 60, 103, 176, 183, 186, 201, 218, 235, 257, 261], 'take': [44], 'into': [45], 'account': [46], 'individual': [48], 'condition': [49], 'patients,': [51], 'their': [52, 58], 'ability': [53], 'receive': [55], 'treatment,': [56], 'and': [57, 69, 129, 140, 147, 162, 180, 206, 216, 244, 260], 'responses': [59], 'treatment.': [61], 'Challenges': [62], 'remain': [63], 'in': [64, 107, 156, 209, 233, 253, 265], 'accurate': [66], 'detection,': [67, 169], 'characterization,': [68], 'monitoring': [70], 'cancers': [72], 'despite': [73], 'improved': [74], 'technologies.': [75], 'Radiographic': [76], 'assessment': [77, 141], 'most': [80, 228], 'commonly': [81], 'visual': [84], 'evaluations,': [85], 'interpretations': [87], 'which': [89], 'may': [90, 153], 'be': [91, 187], 'augmented': [92], 'by': [93, 114], 'advanced': [94], 'computational': [95], 'analyses.': [96], 'In': [97], 'particular,': [98], 'artificial': [99], 'intelligence': [100], '(AI)': [101], 'promises': [102], 'make': [104], 'great': [105], 'strides': [106], 'qualitative': [109], 'interpretation': [110, 159], 'cancer': [112, 205, 266], 'imaging': [113, 203], 'expert': [115], 'clinicians,': [116], 'including': [117], 'volumetric': [118], 'delineation': [119], 'tumors': [121], 'over': [122], 'time,': [123], 'extrapolation': [124], 'tumor': [127, 211], 'genotype': [128], 'biological': [130], 'course': [131], 'from': [132], 'radiographic': [134, 168], 'phenotype,': [135], 'prediction': [136], 'clinical': [138, 165, 222, 258], 'outcome,': [139], 'impact': [144, 262], 'treatment': [148], 'on': [149, 172], 'adjacent': [150], 'organs.': [151], 'AI': [152, 198, 231, 255], 'automate': [154], 'processes': [155], 'initial': [158], 'images': [161], 'shift': [163], 'workflow': [166], 'management': [170], 'whether': [173], 'or': [174], 'administer': [177], 'an': [178], 'intervention,': [179], 'subsequent': [181], 'observation': [182], 'yet': [185], 'envisioned': [188], 'paradigm.': [189], 'Here,': [190], 'authors': [192], 'review': [193], 'current': [195], 'state': [196], 'applied': [200], 'describe': [207], 'advances': [208], '4': [210], 'types': [212], '(lung,': [213], 'brain,': [214], 'breast,': [215], 'prostate)': [217], 'illustrate': [219], 'how': [220], 'common': [221], 'problems': [223], 'are': [224], 'being': [225], 'addressed.': [226], 'Although': [227], 'studies': [229], 'evaluating': [230], 'applications': [232], 'oncology': [234], 'date': [236], 'have': [237], 'been': [239], 'vigorously': [240], 'validated': [241], 'reproducibility': [243], 'generalizability,': [245], 'results': [247], 'do': [248], 'highlight': [249], 'increasingly': [250], 'concerted': [251], 'efforts': [252], 'pushing': [254], 'technology': [256], 'use': [259], 'future': [263], 'directions': [264], 'care.': [267]}",2019,"['Medicine', 'Context (archaeology)', 'Workflow', 'Generalizability theory', 'Medical physics', 'Precision medicine', 'Disease', 'Medical imaging', 'Artificial intelligence', 'Pathology', 'Radiology', 'Computer science', 'Psychology', 'Database', 'Developmental psychology', 'Biology', 'Paleontology']","Abstract Judgement, as one of the core tenets of medicine, relies upon the integration of multilayered data with nuanced decision making. Cancer offers a unique context for medical decisions given not only its variegated forms with evolution of disease but also the need to take into account the individual condition of patients, their ability to receive treatment, and their responses to treatment. Challenges remain in the accurate detection, characterization, and monitoring of cancers despite improved technologies. Radiographic assessment of disease most commonly relies upon visual evaluations, the interpretations of which may be augmented by advanced computational analyses. In particular, artificial intelligence (AI) promises to make great strides in the qualitative interpretation of cancer imaging by expert clinicians, including volumetric delineation of tumors over time, extrapolation of the tumor genotype and biological course from its radiographic phenotype, prediction of clinical outcome, and assessment of the impact of disease and treatment on adjacent organs. AI may automate processes in the initial interpretation of images and shift the clinical workflow of radiographic detection, management decisions on whether or not to administer an intervention, and subsequent observation to a yet to be envisioned paradigm. Here, the authors review the current state of AI as applied to medical imaging of cancer and describe advances in 4 tumor types (lung, brain, breast, and prostate) to illustrate how common clinical problems are being addressed. Although most studies evaluating AI applications in oncology to date have not been vigorously validated for reproducibility and generalizability, the results do highlight increasingly concerted efforts in pushing AI technology to clinical use and to impact future directions in cancer care."
https://openalex.org/W2807593075,Artificial Intelligence in Cardiology,"{'Artificial': [0], 'intelligence': [1, 37, 59], 'and': [2, 16, 38, 51, 79, 95, 101, 112, 126, 130, 143], 'machine': [3, 39], 'learning': [4, 94, 111], 'are': [5], 'poised': [6], 'to': [7, 22, 49, 73, 139], 'influence': [8], 'nearly': [9], 'every': [10], 'aspect': [11], 'of': [12, 35, 44, 109], 'the': [13, 61, 65, 107], 'human': [14], 'condition,': [15], 'cardiology': [17, 48, 74, 100, 142], 'is': [18], 'not': [19], 'an': [20], 'exception': [21], 'this': [23], 'trend.': [24], 'This': [25], 'paper': [26, 66], 'provides': [27, 119], 'a': [28], 'guide': [29], 'for': [30], 'clinicians': [31], 'on': [32], 'relevant': [33, 72], 'aspects': [34], 'artificial': [36, 58], 'learning,': [40, 118], 'reviews': [41, 68, 96], 'selected': [42, 97], 'applications': [43, 98], 'these': [45, 134], 'methods': [46, 114, 135], 'in': [47, 60, 92, 99, 123, 127], 'date,': [50], 'identifies': [52], 'how': [53, 133], 'cardiovascular': [54, 128], 'medicine': [55, 125], 'could': [56, 136], 'incorporate': [57], 'future.': [62], 'In': [63], 'particular,': [64], 'first': [67], 'predictive': [69], 'modeling': [70], 'concepts': [71], 'such': [75, 82], 'as': [76, 83], 'feature': [77], 'selection': [78], 'frequent': [80], 'pitfalls': [81], 'improper': [84], 'dichotomization.': [85], 'Second,': [86], 'it': [87, 105], 'discusses': [88], 'common': [89], 'algorithms': [90], 'used': [91], 'supervised': [93], 'related': [102, 113], 'disciplines.': [103], 'Third,': [104], 'describes': [106], 'advent': [108], 'deep': [110], 'collectively': [115], 'called': [116], 'unsupervised': [117], 'contextual': [120], 'examples': [121], 'both': [122], 'general': [124], 'medicine,': [129], 'then': [131], 'explains': [132], 'be': [137], 'applied': [138], 'enable': [140], 'precision': [141], 'improve': [144], 'patient': [145], 'outcomes.': [146]}",2018,"['Artificial intelligence', 'Medicine', 'Machine learning', 'Internal medicine', 'Cardiology', 'Deep learning', 'Feature selection', 'Precision medicine', 'Clinical cardiology', 'Computer science', 'Pathology']","Artificial intelligence and machine learning are poised to influence nearly every aspect of the human condition, and cardiology is not an exception to this trend. This paper provides a guide for clinicians on relevant aspects of artificial intelligence and machine learning, reviews selected applications of these methods in cardiology to date, and identifies how cardiovascular medicine could incorporate artificial intelligence in the future. In particular, the paper first reviews predictive modeling concepts relevant to cardiology such as feature selection and frequent pitfalls such as improper dichotomization. Second, it discusses common algorithms used in supervised learning and reviews selected applications in cardiology and related disciplines. Third, it describes the advent of deep learning and related methods collectively called unsupervised learning, provides contextual examples both in general medicine and in cardiovascular medicine, and then explains how these methods could be applied to enable precision cardiology and improve patient outcomes."
https://openalex.org/W2958089299,A Survey on Explainable Artificial Intelligence (XAI): Toward Medical XAI,"{'Recently,': [0], 'artificial': [1], 'intelligence': [2], 'and': [3, 41, 51, 63, 98, 117, 158, 180, 189], 'machine': [4, 61, 100], 'learning': [5, 28], 'in': [6, 12, 126, 149], 'general': [7], 'have': [8, 35], 'demonstrated': [9], 'remarkable': [10], 'performances': [11], 'many': [13, 38, 99], 'tasks,': [14], 'from': [15, 129], 'image': [16], 'processing': [17], 'to': [18, 68, 81, 136, 147, 183], 'natural': [19], 'language': [20], 'processing,': [21], 'especially': [22], 'with': [23, 31, 165, 174], 'the': [24, 56, 83, 86, 89, 93, 137, 144], 'advent': [25], 'of': [26, 44, 49, 92, 139], 'deep': [27], '(DL).': [29], 'Along': [30], 'research': [32, 115], 'progress,': [33], 'they': [34], 'encroached': [36], 'upon': [37], 'different': [39, 114, 121, 124], 'fields': [40], 'disciplines.': [42], 'Some': [43], 'them': [45], 'require': [46], 'high': [47], 'level': [48], 'accountability': [50], 'thus': [52, 66], 'transparency,': [53], 'for': [54, 60, 177], 'example,': [55], 'medical': [57, 150, 178, 192], 'sector.': [58], 'Explanations': [59], 'decisions': [62, 101], 'predictions': [64], 'are': [65, 102, 194], 'needed': [67], 'justify': [69], 'their': [70], 'reliability.': [71], 'This': [72], 'requires': [73], 'greater': [74], 'interpretability,': [75], 'which': [76], 'often': [77], 'means': [78], 'we': [79], 'need': [80], 'understand': [82], 'mechanism': [84], 'underlying': [85], 'algorithms.': [87], 'Unfortunately,': [88], 'blackbox': [90], 'nature': [91], 'DL': [94], 'is': [95, 153], 'still': [96, 103], 'unresolved,': [97], 'poorly': [104], 'understood.': [105], 'We': [106], 'provide': [107, 132], 'a': [108], 'review': [109], 'on': [110], 'interpretabilities': [111], 'suggested': [112], 'by': [113], 'works': [116], 'categorize': [118], 'them.': [119], 'The': [120], 'categories': [122], 'show': [123], 'dimensions': [125], 'interpretability': [127, 148, 170], 'research,': [128, 151], 'approaches': [130], 'that': [131], '""obviously""': [133], 'interpretable': [134], 'information': [135], 'studies': [138], 'complex': [140], 'patterns.': [141], 'By': [142], 'applying': [143], 'same': [145], 'categorization': [146], 'it': [152], 'hoped': [154], 'that:': [155], '1)': [156], 'clinicians': [157], 'practitioners': [159], 'can': [160], 'subsequently': [161], 'approach': [162], 'these': [163], 'methods': [164], 'caution;': [166], '2)': [167], 'insight': [168], 'into': [169], 'will': [171], 'be': [172], 'born': [173], 'more': [175], 'considerations': [176], 'practices;': [179], '3)': [181], 'initiatives': [182], 'push': [184], 'forward': [185], 'data-based,': [186], 'mathematically': [187], 'grounded,': [188], 'technically': [190], 'grounded': [191], 'education': [193], 'encouraged.': [195]}",2020,"['Croatian', 'Linguistics', 'Philosophy']","Recently, artificial intelligence and machine learning in general have demonstrated remarkable performances in many tasks, from image processing to natural language processing, especially with the advent of deep learning (DL). Along with research progress, they have encroached upon many different fields and disciplines. Some of them require high level of accountability and thus transparency, for example, the medical sector. Explanations for machine decisions and predictions are thus needed to justify their reliability. This requires greater interpretability, which often means we need to understand the mechanism underlying the algorithms. Unfortunately, the blackbox nature of the DL is still unresolved, and many machine decisions are still poorly understood. We provide a review on interpretabilities suggested by different research works and categorize them. The different categories show different dimensions in interpretability research, from approaches that provide ""obviously"" interpretable information to the studies of complex patterns. By applying the same categorization to interpretability in medical research, it is hoped that: 1) clinicians and practitioners can subsequently approach these methods with caution; 2) insight into interpretability will be born with more considerations for medical practices; and 3) initiatives to push forward data-based, mathematically grounded, and technically grounded medical education are encouraged."
https://openalex.org/W2898192966,Artificial Intelligence and Deep Learning in Ophthalmology,"{'Artificial': [0], 'intelligence': [1], '(AI)': [2], 'based': [3], 'on': [4, 36], 'deep': [5], 'learning': [6], '(DL)': [7], 'has': [8, 17, 41], 'sparked': [9], 'tremendous': [10], 'global': [11], 'interest': [12], 'in': [13, 21, 57, 77, 83, 101, 116, 148, 167], 'recent': [14], 'years.': [15], 'DL': [16, 40, 76, 114, 140, 159], 'been': [18, 42], 'widely': [19], 'adopted': [20], 'image': [22], 'recognition,': [23], 'speech': [24], 'recognition': [25], 'and': [26, 50, 63, 72, 94, 104, 120, 130, 132, 170], 'natural': [27], 'language': [28], 'processing,': [29], 'but': [30], 'is': [31, 146], 'only': [32], 'beginning': [33], 'to': [34, 44, 91], 'impact': [35], 'healthcare.': [37], 'In': [38], 'ophthalmology,': [39, 117], 'applied': [43], 'fundus': [45], 'photographs,': [46], 'optical': [47], 'coherence': [48], 'tomography': [49], 'visual': [51], 'fields,': [52], 'achieving': [53], 'robust': [54], 'classification': [55], 'performance': [56], 'the': [58, 67, 125, 136, 149, 157, 171], 'detection': [59], 'of': [60, 65, 124, 135, 156], 'diabetic': [61], 'retinopathy': [62, 64], 'prematurity,': [66], 'glaucoma-like': [68], 'disc,': [69], 'macular': [70, 74], 'oedema': [71], 'age-related': [73], 'degeneration.': [75], 'ocular': [78], 'imaging': [79], 'may': [80], 'be': [81], 'used': [82], 'conjunction': [84], 'with': [85, 113], 'telemedicine': [86], 'as': [87], 'a': [88, 154], 'possible': [89], 'solution': [90], 'screen,': [92], 'diagnose': [93], 'monitor': [95], 'major': [96], 'eye': [97], 'diseases': [98], 'for': [99, 162], 'patients': [100], 'primary': [102], 'care': [103], 'community': [105], 'settings.': [106], 'Nonetheless,': [107], 'there': [108], 'are': [109], 'also': [110], 'potential': [111, 165], 'challenges': [112, 166], 'application': [115], 'including': [118], 'clinical': [119, 168], 'technical': [121], 'challenges,': [122], 'explainability': [123], 'algorithm': [126], 'results,': [127], 'medicolegal': [128], 'issues,': [129], 'physician': [131], 'patient': [133], 'acceptance': [134], 'AI': [137], '‘black-box’': [138], 'algorithms.': [139], 'could': [141], 'potentially': [142], 'revolutionise': [143], 'how': [144], 'ophthalmology': [145], 'practised': [147], 'future.': [150], 'This': [151], 'review': [152], 'provides': [153], 'summary': [155], 'state-of-the-art': [158], 'systems': [160], 'described': [161], 'ophthalmic': [163], 'applications,': [164], 'deployment': [169], 'path': [172], 'forward.': [173]}",2022,"['Medicine', 'Diabetic retinopathy', 'Optometry', 'Reimbursement', 'Glaucoma', 'Artificial intelligence', 'Macular degeneration', 'Ophthalmology', 'Health care', 'Computer science', 'Diabetes mellitus', 'Political science', 'Law', 'Endocrinology']","Artificial intelligence (AI) based on deep learning (DL) has sparked tremendous global interest in recent years. DL has been widely adopted in image recognition, speech recognition and natural language processing, but is only beginning to impact on healthcare. In ophthalmology, DL has been applied to fundus photographs, optical coherence tomography and visual fields, achieving robust classification performance in the detection of diabetic retinopathy and retinopathy of prematurity, the glaucoma-like disc, macular oedema and age-related macular degeneration. DL in ocular imaging may be used in conjunction with telemedicine as a possible solution to screen, diagnose and monitor major eye diseases for patients in primary care and community settings. Nonetheless, there are also potential challenges with DL application in ophthalmology, including clinical and technical challenges, explainability of the algorithm results, medicolegal issues, and physician and patient acceptance of the AI ‘black-box’ algorithms. DL could potentially revolutionise how ophthalmology is practised in the future. This review provides a summary of the state-of-the-art DL systems described for ophthalmic applications, potential challenges in clinical deployment and the path forward."
https://openalex.org/W3210165781,Artificial intelligence: A powerful paradigm for scientific research,"{'\\n': [0], 'Contains': [1], 'fulltext': [2], ':\\n': [3], '246467.pdf': [4], '(Publisher’s': [5], 'version': [6], ')': [7], '(Open': [8], 'Access)\\n': [9]}",2021,"['Cognitive science', 'Computer science', 'Data science', 'Psychology', 'Artificial intelligence', 'Engineering ethics', 'Management science', 'Engineering']",\n Contains fulltext :\n 246467.pdf (Publisher’s version ) (Open Access)\n
https://openalex.org/W3094793347,A strategic framework for artificial intelligence in marketing,"{'Abstract': [0], 'The': [1], 'authors': [2], 'develop': [3], 'a': [4], 'three-stage': [5], 'framework': [6, 45, 142], 'for': [7, 19, 28, 38, 55, 76, 81, 87, 101, 107, 114, 128, 132, 137], 'strategic': [8, 155], 'marketing': [9, 22, 56, 68, 92, 120, 150], 'planning,': [10], 'incorporating': [11], 'multiple': [12], 'artificial': [13], 'intelligence': [14], '(AI)': [15], 'benefits:': [16], 'mechanical': [17, 71, 96, 123], 'AI': [18, 27, 37, 51, 72, 80, 86, 97, 106, 113, 124, 131, 136], 'automating': [20], 'repetitive': [21], 'functions': [23], 'and': [24, 35, 41, 61, 64, 84, 111, 134], 'activities,': [25], 'thinking': [26, 79, 105, 130], 'processing': [29], 'data': [30, 77], 'to': [31, 143, 152], 'arrive': [32], 'at': [33], 'decisions,': [34], 'feeling': [36, 85, 112, 135], 'analyzing': [39], 'interactions': [40], 'human': [42], 'emotions.': [43], 'This': [44], 'lays': [46], 'out': [47], 'the': [48, 67, 91, 119, 154], 'ways': [49], 'that': [50], 'can': [52, 73, 98, 125], 'be': [53, 74, 99, 126], 'used': [54, 75, 100, 127], 'research,': [57], 'strategy': [58, 93], '(segmentation,': [59], 'targeting,': [60], 'positioning,': [62], 'STP),': [63], 'actions.': [65], 'At': [66, 90, 118], 'research': [69], 'stage,': [70, 95, 122], 'collection,': [78], 'market': [82], 'analysis,': [83], 'customer': [88], 'understanding.': [89], '(STP)': [94], 'segmentation': [102], '(segment': [103, 109, 116], 'recognition),': [104], 'targeting': [108], 'recommendation),': [110], 'positioning': [115], 'resonance).': [117], 'action': [121], 'standardization,': [129], 'personalization,': [133], 'relationalization.': [138], 'We': [139], 'apply': [140], 'this': [141], 'various': [144], 'areas': [145], 'of': [146, 157], 'marketing,': [147], 'organized': [148], 'by': [149], '4Ps/4Cs,': [151], 'illustrate': [153], 'use': [156], 'AI.': [158]}",2020,"['Personalization', 'Feeling', 'Market segmentation', 'Marketing research', 'Marketing and artificial intelligence', 'Marketing', 'Computer science', 'Marketing strategy', 'Artificial intelligence', 'Personalized marketing', 'Marketing management', 'Standardization', 'Knowledge management', 'Business', 'Return on marketing investment', 'Psychology', 'Business-to-government', 'Social psychology', 'Intelligent decision support system', 'Operating system']","Abstract The authors develop a three-stage framework for strategic marketing planning, incorporating multiple artificial intelligence (AI) benefits: mechanical AI for automating repetitive marketing functions and activities, thinking AI for processing data to arrive at decisions, and feeling AI for analyzing interactions and human emotions. This framework lays out the ways that AI can be used for marketing research, strategy (segmentation, targeting, and positioning, STP), and actions. At the marketing research stage, mechanical AI can be used for data collection, thinking AI for market analysis, and feeling AI for customer understanding. At the marketing strategy (STP) stage, mechanical AI can be used for segmentation (segment recognition), thinking AI for targeting (segment recommendation), and feeling AI for positioning (segment resonance). At the marketing action stage, mechanical AI can be used for standardization, thinking AI for personalization, and feeling AI for relationalization. We apply this framework to various areas of marketing, organized by marketing 4Ps/4Cs, to illustrate the strategic use of AI."
https://openalex.org/W1997866278,Artificial intelligence in medicine,"{'Artificial': [0], 'intelligence': [1], 'techniques': [2, 29], 'have': [3], 'the': [4, 33], 'potential': [5], 'to': [6], 'be': [7], 'applied': [8], 'in': [9, 32], 'almost': [10], 'every': [11], 'field': [12], 'of': [13], 'medicine.': [14], 'There': [15], 'is': [16], 'need': [17], 'for': [18], 'further': [19], 'clinical': [20, 35], 'trials': [21], 'which': [22], 'are': [23], 'appropriately': [24], 'designed': [25], 'before': [26], 'these': [27], 'emergent': [28], 'find': [30], 'application': [31], 'real': [34], 'setting.': [36]}",2004,"['Computer science', 'Artificial intelligence', 'Field (mathematics)', 'Artificial neural network', 'Machine learning', 'Intelligent decision support system', 'Expert system', 'Set (abstract data type)', 'Exploit', 'Key (lock)', 'Pure mathematics', 'Programming language', 'Mathematics', 'Computer security']",Artificial intelligence techniques have the potential to be applied in almost every field of medicine. There is need for further clinical trials which are appropriately designed before these emergent techniques find application in the real clinical setting.
https://openalex.org/W2966555834,Overview of artificial intelligence in medicine,"{'AI': [0], 'promises': [1], 'to': [2, 25, 35, 47], 'change': [3], 'the': [4, 48], 'practice': [5], 'of': [6, 14], 'medicine': [7], 'in': [8, 20], 'hitherto': [9], 'unknown': [10], 'ways,': [11], 'but': [12], 'many': [13], 'its': [15], 'practical': [16], 'applications': [17], 'are': [18], 'still': [19], 'their': [21], 'infancy': [22], 'and': [23, 28, 37], 'need': [24, 34], 'be': [26], 'explored': [27], 'developed': [29], 'better.': [30], 'Medical': [31], 'professionals': [32], 'also': [33], 'understand': [36], 'acclimatize': [38], 'themselves': [39], 'with': [40], 'these': [41], 'advances': [42], 'for': [43], 'better': [44], 'healthcare': [45], 'delivery': [46], 'masses.': [49]}",2019,"['Applications of artificial intelligence', 'Artificial intelligence', 'Medicine', 'Field (mathematics)', 'Key (lock)', 'Term (time)', 'Engineering ethics', 'Computer science', 'Data science', 'Pure mathematics', 'Computer security', 'Quantum mechanics', 'Physics', 'Engineering', 'Mathematics']","AI promises to change the practice of medicine in hitherto unknown ways, but many of its practical applications are still in their infancy and need to be explored and developed better. Medical professionals also need to understand and acclimatize themselves with these advances for better healthcare delivery to the masses."
https://openalex.org/W4247155454,Artificial Intelligence and Management: The Automation–Augmentation Paradox,"{'Taking': [0, 46], 'three': [1, 51], 'recent': [2], 'business': [3, 136], 'books': [4, 52], 'on': [5, 140, 154], 'artificial': [6], 'intelligence': [7], '(AI)': [8], 'as': [9], 'a': [10, 31, 44, 47, 65, 96, 117, 165], 'starting': [11], 'point,': [12], 'we': [13, 71, 143], 'explore': [14], 'the': [15, 21, 50, 75, 129, 155], 'automation': [16, 25, 103, 122], 'and': [17, 93, 110, 123, 131, 137, 183], 'augmentation': [18, 34, 78, 101], 'concepts': [19], 'in': [20, 74, 152, 159, 170, 177], 'management': [22, 76, 146], 'domain.': [23], 'Whereas': [24], 'implies': [26], 'that': [27, 36, 134, 145, 164], 'machines': [28, 41], 'take': [29], 'over': [30], 'human': [32], 'task,': [33], 'means': [35], 'humans': [37], 'collaborate': [38], 'closely': [39], 'with': [40, 107, 128, 187], 'to': [42, 55, 61, 149, 179, 184], 'perform': [43], 'task.': [45], 'normative': [48], 'stance,': [49], 'advise': [53], 'organizations': [54, 115], 'prioritize': [56], 'augmentation,': [57, 124], 'which': [58], 'they': [59, 125], 'relate': [60], 'superior': [62], 'performance.': [63], 'Using': [64], 'more': [66], 'comprehensive': [67], 'paradox': [68], 'theory': [69, 182], 'perspective,': [70], 'argue': [72, 163], 'that,': [73], 'domain,': [77], 'cannot': [79], 'be': [80, 150], 'neatly': [81], 'separated': [82], 'from': [83], 'automation.': [84], 'These': [85], 'dual': [86], 'AI': [87, 158, 172], 'applications': [88], 'are': [89], 'interdependent': [90], 'across': [91], 'time': [92], 'space,': [94], 'creating': [95], 'paradoxical': [97], 'tension.': [98], 'Overemphasizing': [99], 'either': [100], 'or': [102], 'fuels': [104], 'reinforcing': [105], 'cycles': [106], 'negative': [108], 'organizational': [109], 'societal': [111], 'outcomes.': [112], 'However,': [113], 'if': [114], 'adopt': [116], 'broader': [118], 'perspective': [119], 'comprising': [120], 'both': [121], 'could': [126], 'deal': [127], 'tension': [130], 'achieve': [132], 'complementarities': [133], 'benefit': [135], 'society.': [138], 'Drawing': [139], 'our': [141], 'insights,': [142], 'conclude': [144], 'scholars': [147], 'need': [148], 'involved': [151], 'research': [153, 173], 'use': [156], 'of': [157], 'organizations.': [160], 'We': [161], 'also': [162], 'substantial': [166], 'change': [167], 'is': [168, 174], 'required': [169], 'how': [171], 'currently': [175], 'conducted': [176], 'order': [178], 'develop': [180], 'meaningful': [181], 'provide': [185], 'practice': [186], 'sound': [188], 'advice.': [189]}",2021,"['Automation', 'Task (project management)', 'Interdependence', 'Normative', 'Knowledge management', 'Perspective (graphical)', 'Computer science', 'Order (exchange)', 'Domain (mathematical analysis)', 'Sociology', 'Management science', 'Management', 'Epistemology', 'Artificial intelligence', 'Business', 'Economics', 'Engineering', 'Social science', 'Mathematics', 'Philosophy', 'Mechanical engineering', 'Finance', 'Mathematical analysis']","Taking three recent business books on artificial intelligence (AI) as a starting point, we explore the automation and augmentation concepts in the management domain. Whereas automation implies that machines take over a human task, augmentation means that humans collaborate closely with machines to perform a task. Taking a normative stance, the three books advise organizations to prioritize augmentation, which they relate to superior performance. Using a more comprehensive paradox theory perspective, we argue that, in the management domain, augmentation cannot be neatly separated from automation. These dual AI applications are interdependent across time and space, creating a paradoxical tension. Overemphasizing either augmentation or automation fuels reinforcing cycles with negative organizational and societal outcomes. However, if organizations adopt a broader perspective comprising both automation and augmentation, they could deal with the tension and achieve complementarities that benefit business and society. Drawing on our insights, we conclude that management scholars need to be involved in research on the use of AI in organizations. We also argue that a substantial change is required in how AI research is currently conducted in order to develop meaningful theory and to provide practice with sound advice."
https://openalex.org/W4365143687,Foundation models for generalist medical artificial intelligence,"{'The': [0], 'exceptionally': [1], 'rapid': [2], 'development': [3], 'of': [4, 43, 49, 72, 116, 160], 'highly': [5], 'flexible,': [6], 'reusable': [7], 'artificial': [8], 'intelligence': [9], '(AI)': [10], 'models': [11, 39], 'is': [12], 'likely': [13], 'to': [14, 32, 132], 'usher': [15], 'in': [16, 19, 91], 'newfound': [17], 'capabilities': [18, 127], 'medicine.': [20], 'We': [21, 135], 'propose': [22], 'a': [23, 46, 114], 'new': [24], 'paradigm': [25], 'for': [26, 120, 144, 150], 'medical': [27, 35, 73, 87, 108, 162], 'AI,': [28], 'which': [29], 'we': [30, 112], 'refer': [31], 'as': [33, 97], 'generalist': [34], 'AI': [36, 148], '(GMAI).': [37], 'GMAI': [38, 66, 121], 'will': [40, 67, 90, 140, 153], 'be': [41], 'capable': [42], 'carrying': [44], 'out': [45, 124], 'diverse': [47, 64], 'set': [48, 115], 'tasks': [50], 'using': [51], 'very': [52], 'little': [53], 'or': [54, 86, 102], 'no': [55], 'task-specific': [56], 'labelled': [57], 'data.': [58], 'Built': [59], 'through': [60], 'self-supervision': [61], 'on': [62], 'large,': [63], 'datasets,': [65], 'flexibly': [68], 'interpret': [69], 'different': [70], 'combinations': [71], 'modalities,': [74], 'including': [75], 'data': [76], 'from': [77], 'imaging,': [78], 'electronic': [79], 'health': [80], 'records,': [81], 'laboratory': [82], 'results,': [83], 'genomics,': [84], 'graphs': [85], 'text.': [88], 'Models': [89], 'turn': [92], 'produce': [93], 'expressive': [94], 'outputs': [95], 'such': [96], 'free-text': [98], 'explanations,': [99], 'spoken': [100], 'recommendations': [101], 'image': [103], 'annotations': [104], 'that': [105, 137], 'demonstrate': [106], 'advanced': [107], 'reasoning': [109], 'abilities.': [110], 'Here': [111], 'identify': [113], 'high-impact': [117], 'potential': [118], 'applications': [119, 139], 'and': [122, 128, 146, 152], 'lay': [123], 'specific': [125], 'technical': [126], 'training': [129], 'datasets': [130], 'necessary': [131], 'enable': [133], 'them.': [134], 'expect': [136], 'GMAI-enabled': [138], 'challenge': [141], 'current': [142], 'strategies': [143], 'regulating': [145], 'validating': [147], 'devices': [149], 'medicine': [151], 'shift': [154], 'practices': [155], 'associated': [156], 'with': [157], 'the': [158], 'collection': [159], 'large': [161], 'datasets.': [163]}",2023,"['Computer science', 'Set (abstract data type)', 'Artificial intelligence', 'Modalities', 'Task (project management)', 'Data science', 'Machine learning', 'Economics', 'Management', 'Social science', 'Programming language', 'Sociology']","The exceptionally rapid development of highly flexible, reusable artificial intelligence (AI) models is likely to usher in newfound capabilities in medicine. We propose a new paradigm for medical AI, which we refer to as generalist medical AI (GMAI). GMAI models will be capable of carrying out a diverse set of tasks using very little or no task-specific labelled data. Built through self-supervision on large, diverse datasets, GMAI will flexibly interpret different combinations of medical modalities, including data from imaging, electronic health records, laboratory results, genomics, graphs or medical text. Models will in turn produce expressive outputs such as free-text explanations, spoken recommendations or image annotations that demonstrate advanced medical reasoning abilities. Here we identify a set of high-impact potential applications for GMAI and lay out specific technical capabilities and training datasets necessary to enable them. We expect that GMAI-enabled applications will challenge current strategies for regulating and validating AI devices for medicine and will shift practices associated with the collection of large medical datasets."
https://openalex.org/W3186209406,Artificial intelligence in healthcare: transforming the practice of medicine,"{'Artificial': [0], 'intelligence': [1], '(AI)': [2], 'is': [3], 'a': [4, 43], 'powerful': [5], 'and': [6, 22, 49, 53], 'disruptive': [7], 'area': [8], 'of': [9, 20, 25, 38, 59], 'computer': [10], 'science,': [11], 'with': [12], 'the': [13, 18, 23, 36, 55], 'potential': [14], 'to': [15, 45], 'fundamentally': [16], 'transform': [17], 'practice': [19], 'medicine': [21], 'delivery': [24], 'healthcare.': [26], 'In': [27], 'this': [28], 'review': [29], 'article,': [30], 'we': [31], 'outline': [32], 'recent': [33], 'breakthroughs': [34], 'in': [35, 40], 'application': [37], 'AI': [39, 51, 60], 'healthcare,': [41], 'describe': [42], 'roadmap': [44], 'building': [46], 'effective,': [47], 'reliable': [48], 'safe': [50], 'systems,': [52], 'discuss': [54], 'possible': [56], 'future': [57], 'direction': [58], 'augmented': [61], 'healthcare': [62], 'systems.': [63]}",2021,"['Health care', 'Medicine', 'Political science', 'Law']","Artificial intelligence (AI) is a powerful and disruptive area of computer science, with the potential to fundamentally transform the practice of medicine and the delivery of healthcare. In this review article, we outline recent breakthroughs in the application of AI in healthcare, describe a roadmap to building effective, reliable and safe AI systems, and discuss the possible future direction of AI augmented healthcare systems."
https://openalex.org/W2770717476,Exploring the impact of artificial intelligence on teaching and learning in higher education,"{'This': [0], 'paper': [1], 'explores': [2], 'the': [3, 6, 9, 29, 43, 59, 74, 92], 'phenomena': [4], 'of': [5, 8, 11, 25, 46, 62, 73, 76, 85, 94], 'emergence': [7], 'use': [10], 'artificial': [12, 69], 'intelligence': [13, 70], 'in': [14, 18, 50, 55, 65, 91], 'teaching': [15], 'and': [16, 33, 37, 42, 88, 102, 104], 'learning': [17, 90], 'higher': [19, 51, 63, 86], 'education.': [20], 'It': [21], 'investigates': [22], 'educational': [23], 'implications': [24], 'emerging': [26], 'technologies': [27, 49, 96], 'on': [28], 'way': [30], 'students': [31], 'learn': [32], 'how': [34], 'institutions': [35, 84], 'teach': [36], 'evolve.': [38], 'Recent': [39], 'technological': [40], 'advancements': [41], 'increasing': [44], 'speed': [45], 'adopting': [47], 'new': [48], 'education': [52, 64, 87], 'are': [53], 'explored': [54], 'order': [56], 'to': [57], 'predict': [58], 'future': [60], 'nature': [61], 'a': [66], 'world': [67], 'where': [68], 'is': [71], 'part': [72], 'fabric': [75], 'our': [77], 'universities.': [78], 'We': [79], 'pinpoint': [80], 'some': [81], 'challenges': [82], 'for': [83, 97, 108], 'student': [89, 100], 'adoption': [93], 'these': [95], 'teaching,': [98], 'learning,': [99], 'support,': [101], 'administration': [103], 'explore': [105], 'further': [106], 'directions': [107], 'research.': [109]}",2017,"['Higher education', 'Educational technology', 'Order (exchange)', 'Emerging technologies', 'Mathematics education', 'Computer science', 'Knowledge management', 'Engineering ethics', 'Psychology', 'Artificial intelligence', 'Engineering', 'Political science', 'Business', 'Finance', 'Law']","This paper explores the phenomena of the emergence of the use of artificial intelligence in teaching and learning in higher education. It investigates educational implications of emerging technologies on the way students learn and how institutions teach and evolve. Recent technological advancements and the increasing speed of adopting new technologies in higher education are explored in order to predict the future nature of higher education in a world where artificial intelligence is part of the fabric of our universities. We pinpoint some challenges for institutions of higher education and student learning in the adoption of these technologies for teaching, learning, student support, and administration and explore further directions for research."
https://openalex.org/W2954503794,DARPA's Explainable Artificial Intelligence Program,"{'Dramatic': [0], 'success': [1], 'in': [2, 155], 'machine': [3], 'learning': [4, 66], 'has': [5], 'led': [6], 'to': [7, 32, 42, 125, 141], 'a': [8, 131, 159], 'new': [9], 'wave': [10], 'of': [11, 123, 151, 161], 'AI': [12, 44], 'applications': [13], '(for': [14], 'example,': [15], 'transportation,': [16], 'security,': [17], 'medicine,': [18], 'finance,': [19], 'defense)': [20], 'that': [21], 'offer': [22], 'tremendous': [23], 'benefits': [24], 'but': [25], 'cannot': [26], 'explain': [27], 'their': [28, 143, 171], 'decisions': [29, 50], 'and': [30, 49, 54, 74, 96, 100, 119, 180], 'actions': [31], 'human': [33], 'users.': [34, 59], ""DARPA's"": [35], 'explainable': [36, 68], 'artificial': [37], 'intelligence': [38], '(XAI)': [39], 'program': [40, 154], 'endeavors': [41], 'create': [43], 'systems': [45], 'whose': [46], 'learned': [47], 'models': [48], 'can': [51], 'be': [52], 'understood': [53], 'appropriately': [55], 'trusted': [56], 'by': [57, 92, 116], 'end': [58], 'Realizing': [60], 'this': [61, 152], 'goal': [62], 'requires': [63], 'methods': [64], 'for': [65, 79, 104], 'more': [67], 'models,': [69], 'designing': [70], 'effective': [71, 80, 106], 'explanation': [72, 124], 'interfaces,': [73], 'understanding': [75], 'the': [76, 88, 113, 127, 136, 149, 164], 'psychologic': [77, 121], 'requirements': [78], 'explanations.': [81, 107], 'The': [82, 145], 'XAI': [83, 109, 128, 146], 'developer': [84, 137, 165], 'teams': [85, 138, 147, 166], 'are': [86, 167], 'addressing': [87, 112], 'first': [89, 150], 'two': [90], 'challenges': [91], 'creating': [93], 'ML': [94], 'techniques': [95, 103], 'developing': [97], 'principles,': [98], 'strategies,': [99], 'human‐computer': [101], 'interaction': [102], 'generating': [105], 'Another': [108], 'team': [110], 'is': [111], 'third': [114], 'challenge': [115], 'summarizing,': [117], 'extending,': [118], 'applying': [120], 'theories': [122], 'help': [126], 'evaluator': [129], 'define': [130], 'suitable': [132], 'evaluation': [133], 'framework,': [134], 'which': [135], 'will': [139], 'use': [140], 'test': [142], 'systems.': [144], 'completed': [148], '4‐year': [153], 'May': [156], '2018.': [157], 'In': [158], 'series': [160], 'ongoing': [162], 'evaluations,': [163], 'assessing': [168], 'how': [169], 'well': [170], 'XAM': [172], ""systems'"": [173], 'explanations': [174], 'improve': [175], 'user': [176, 178, 181], 'understanding,': [177], 'trust,': [179], 'task': [182], 'performance.': [183]}",2019,"['Computer science', 'Task (project management)', 'Artificial intelligence', 'Knowledge management', 'Management science', 'Engineering', 'Systems engineering']","Dramatic success in machine learning has led to a new wave of AI applications (for example, transportation, security, medicine, finance, defense) that offer tremendous benefits but cannot explain their decisions and actions to human users. DARPA's explainable artificial intelligence (XAI) program endeavors to create AI systems whose learned models and decisions can be understood and appropriately trusted by end users. Realizing this goal requires methods for learning more explainable models, designing effective explanation interfaces, and understanding the psychologic requirements for effective explanations. The XAI developer teams are addressing the first two challenges by creating ML techniques and developing principles, strategies, and human‐computer interaction techniques for generating effective explanations. Another XAI team is addressing the third challenge by summarizing, extending, and applying psychologic theories of explanation to help the XAI evaluator define a suitable evaluation framework, which the developer teams will use to test their systems. The XAI teams completed the first of this 4‐year program in May 2018. In a series of ongoing evaluations, the developer teams are assessing how well their XAM systems' explanations improve user understanding, user trust, and user task performance."
https://openalex.org/W3016417837,Artificial Intelligence in Dentistry: Chances and Challenges,"{'The': [0], 'term': [1], '“artificial': [2], 'intelligence”': [3], '(AI)': [4], 'refers': [5], 'to': [6, 32, 136, 185, 212, 222, 243, 262, 280], 'the': [7, 63, 98, 159, 246, 267, 282, 293], 'idea': [8], 'of': [9, 13, 19, 69, 163, 188, 194, 248, 284], 'machines': [10], 'being': [11], 'capable': [12], 'performing': [14], 'human': [15, 250], 'tasks.': [16], 'A': [17], 'subdomain': [18], 'AI': [20, 124, 172, 240, 270, 286], 'is': [21, 41], 'machine': [22], 'learning': [23, 40, 50, 224], '(ML),': [24], 'which': [25], '“learns”': [26], 'intrinsic': [27], 'statistical': [28], 'patterns': [29], 'in': [30, 151, 174, 255, 292], 'data': [31, 55, 139], 'eventually': [33, 115], 'cast': [34], 'predictions': [35], 'on': [36, 53], 'unseen': [37], 'data.': [38], 'Deep': [39], 'a': [42, 111, 218], 'ML': [43], 'technique': [44], 'using': [45], 'multi-layer': [46], 'mathematical': [47], 'operations': [48], 'for': [49, 77, 110, 181], 'and': [51, 66, 75, 90, 114, 120, 143, 149, 155, 161, 169, 186, 192, 197, 209, 216, 231, 236, 252, 265], 'inferring': [52], 'complex': [54], 'like': [56], 'imagery.': [57], 'This': [58], 'succinct': [59], 'narrative': [60], 'review': [61], 'describes': [62], 'application,': [64], 'limitations': [65], 'possible': [67], 'future': [68, 294], 'AI-based': [70, 92], 'dental': [71, 88, 99, 132, 239, 295], 'diagnostics,': [72], 'treatment': [73], 'planning,': [74], 'conduct,': [76], 'example,': [78, 182], 'image': [79], 'analysis,': [80], 'prediction': [81], 'making,': [82], 'record': [83], 'keeping,': [84], 'as': [85, 87], 'well': [86], 'research': [89], 'discovery.': [91], 'applications': [93], 'will': [94, 272, 278], 'streamline': [95], 'care,': [96, 189], 'relieving': [97], 'workforce': [100], 'from': [101, 220], 'laborious': [102], 'routine': [103, 131], 'tasks,': [104], 'increasing': [105, 190, 204], 'health': [106], 'at': [107], 'lower': [108], 'costs': [109], 'broader': [112], 'population,': [113], 'facilitate': [116], 'personalized,': [117], 'predictive,': [118], 'preventive,': [119], 'participatory': [121], 'dentistry.': [122], 'However,': [123], 'solutions': [125, 241, 271, 287], 'have': [126], 'not': [127], 'by': [128, 288], 'large': [129], 'entered': [130], 'practice,': [133], 'mainly': [134], 'due': [135], '1)': [137], 'limited': [138], 'availability,': [140], 'accessibility,': [141], 'structure,': [142], 'comprehensiveness,': [144], '2)': [145], 'lacking': [146], 'methodological': [147], 'rigor': [148], 'standards': [150, 253], 'their': [152], 'development,': [153], '3)': [154], 'practical': [156], 'questions': [157], 'around': [158], 'value': [160, 179], 'usefulness': [162], 'these': [164], 'solutions,': [165], 'but': [166], 'also': [167], 'ethics': [168], 'responsibility.': [170], 'Any': [171], 'application': [173], 'dentistry': [175, 257], 'should': [176, 258], 'demonstrate': [177], 'tangible': [178], 'by,': [180], 'improving': [183, 229], 'access': [184], 'quality': [187], 'efficiency': [191], 'safety': [193], 'services,': [195], 'empowering': [196], 'enabling': [198], 'patients,': [199], 'supporting': [200], 'medical': [201], 'research,': [202], 'or': [203], 'sustainability.': [205], 'Individual': [206], 'privacy,': [207], 'rights,': [208], 'autonomy': [210], 'need': [211, 242, 279], 'be': [213, 244, 259], 'put': [214], 'front': [215], 'center;': [217], 'shift': [219], 'centralized': [221], 'distributed/federated': [223], 'may': [225], 'address': [226], 'this': [227], 'while': [228], 'scalability': [230], 'robustness.': [232], 'Lastly,': [233], 'trustworthiness': [234], 'into,': [235], 'generalizability': [237], 'of,': [238], 'guaranteed;': [245], 'implementation': [247], 'continuous': [249], 'oversight': [251], 'grounded': [254], 'evidence-based': [256], 'expected.': [260], 'Methods': [261], 'visualize,': [263], 'interpret,': [264], 'explain': [266], 'logic': [268], 'behind': [269], 'contribute': [273], '(“explainable': [274], 'AI”).': [275], 'Dental': [276], 'education': [277], 'accompany': [281], 'introduction': [283], 'clinical': [285], 'fostering': [289], 'digital': [290], 'literacy': [291], 'workforce.': [296]}",2020,"['Computer science', 'Artificial intelligence', 'Population', 'Deep learning', 'Health care', 'Generalizability theory', 'Data science', 'Machine learning', 'Medicine', 'Psychology', 'Environmental health', 'Developmental psychology', 'Economics', 'Economic growth']","The term “artificial intelligence” (AI) refers to the idea of machines being capable of performing human tasks. A subdomain of AI is machine learning (ML), which “learns” intrinsic statistical patterns in data to eventually cast predictions on unseen data. Deep learning is a ML technique using multi-layer mathematical operations for learning and inferring on complex data like imagery. This succinct narrative review describes the application, limitations and possible future of AI-based dental diagnostics, treatment planning, and conduct, for example, image analysis, prediction making, record keeping, as well as dental research and discovery. AI-based applications will streamline care, relieving the dental workforce from laborious routine tasks, increasing health at lower costs for a broader population, and eventually facilitate personalized, predictive, preventive, and participatory dentistry. However, AI solutions have not by large entered routine dental practice, mainly due to 1) limited data availability, accessibility, structure, and comprehensiveness, 2) lacking methodological rigor and standards in their development, 3) and practical questions around the value and usefulness of these solutions, but also ethics and responsibility. Any AI application in dentistry should demonstrate tangible value by, for example, improving access to and quality of care, increasing efficiency and safety of services, empowering and enabling patients, supporting medical research, or increasing sustainability. Individual privacy, rights, and autonomy need to be put front and center; a shift from centralized to distributed/federated learning may address this while improving scalability and robustness. Lastly, trustworthiness into, and generalizability of, dental AI solutions need to be guaranteed; the implementation of continuous human oversight and standards grounded in evidence-based dentistry should be expected. Methods to visualize, interpret, and explain the logic behind AI solutions will contribute (“explainable AI”). Dental education will need to accompany the introduction of clinical AI solutions by fostering digital literacy in the future dental workforce."
https://openalex.org/W2886801379,Artificial intelligence in retina,"{'Major': [0], 'advances': [1], 'in': [2, 32, 60, 111, 117, 182], 'diagnostic': [3, 143], 'technologies': [4], 'are': [5, 51, 106], 'offering': [6], 'unprecedented': [7], 'insight': [8], 'into': [9], 'the': [10, 13, 72, 75, 177, 199, 210], 'condition': [11], 'of': [12, 23, 74, 83, 102, 132, 139, 149, 154, 159, 164, 180, 212], 'retina': [14, 183], 'and': [15, 28, 46, 56, 64, 108, 115, 120, 162, 172, 196, 206], 'beyond': [16], 'ocular': [17], 'disease.': [18, 66], 'Digital': [19], 'images': [20], 'providing': [21], 'millions': [22], 'morphological': [24], 'datasets': [25, 119], 'can': [26], 'fast': [27], 'non-invasively': [29], 'be': [30], 'analyzed': [31], 'a': [33], 'comprehensive': [34], 'manner': [35], 'using': [36], 'artificial': [37], 'intelligence': [38], '(AI).': [39], 'Methods': [40], 'based': [41], 'on': [42], 'machine': [43], 'learning': [44, 49, 82], '(ML)': [45], 'particularly': [47], 'deep': [48], '(DL)': [50], 'able': [52], 'to': [53, 201], 'identify,': [54], 'localize': [55], 'quantify': [57], 'pathological': [58, 84], 'features': [59, 85], 'almost': [61], 'every': [62], 'macular': [63], 'retinal': [65, 104], 'Convolutional': [67], 'neural': [68], 'networks': [69], 'thereby': [70], 'mimic': [71], 'path': [73], 'human': [76], 'brain': [77], 'for': [78, 130, 167], 'object': [79], 'recognition': [80], 'through': [81], 'from': [86, 94], 'training': [87], 'sets,': [88], 'supervised': [89], 'ML,': [90], 'or': [91], 'even': [92], 'extrapolation': [93], 'patterns': [95], 'recognized': [96], 'independently,': [97], 'unsupervised': [98], 'ML.': [99], 'The': [100, 136], 'methods': [101], 'AI-based': [103, 124], 'analyses': [105], 'diverse': [107], 'differ': [109], 'widely': [110], 'their': [112], 'applicability,': [113], 'interpretability': [114], 'reliability': [116], 'different': [118], 'diseases.': [121], 'Fully': [122], 'automated': [123, 152], 'systems': [125], 'have': [126], 'recently': [127], 'been': [128], 'approved': [129], 'screening': [131], 'diabetic': [133], 'retinopathy': [134], '(DR).': [135], 'overall': [137], 'potential': [138, 178], 'ML/DL': [140], 'includes': [141], 'screening,': [142], 'grading': [144], 'as': [145, 147, 190, 192], 'well': [146, 191], 'guidance': [148], 'therapy': [150], 'with': [151, 209], 'detection': [153], 'disease': [155], 'activity,': [156], 'recurrences,': [157], 'quantification': [158], 'therapeutic': [160, 169], 'effects': [161], 'identification': [163], 'relevant': [165], 'targets': [166], 'novel': [168], 'approaches.': [170], 'Prediction': [171], 'prognostic': [173], 'conclusions': [174], 'further': [175], 'expand': [176], 'benefit': [179], 'AI': [181], 'which': [184], 'will': [185, 197], 'enable': [186], 'personalized': [187], 'health': [188], 'care': [189], 'large': [193], 'scale': [194], 'management': [195], 'empower': [198], 'ophthalmologist': [200], 'provide': [202], 'high': [203], 'quality': [204], 'diagnosis/therapy': [205], 'successfully': [207], 'deal': [208], 'complexity': [211], '21st': [213], 'century': [214], 'ophthalmology.': [215]}",2018,"['Artificial intelligence', 'Interpretability', 'Computer science', 'Machine learning', 'Convolutional neural network', 'Deep learning', 'Medicine']","Major advances in diagnostic technologies are offering unprecedented insight into the condition of the retina and beyond ocular disease. Digital images providing millions of morphological datasets can fast and non-invasively be analyzed in a comprehensive manner using artificial intelligence (AI). Methods based on machine learning (ML) and particularly deep learning (DL) are able to identify, localize and quantify pathological features in almost every macular and retinal disease. Convolutional neural networks thereby mimic the path of the human brain for object recognition through learning of pathological features from training sets, supervised ML, or even extrapolation from patterns recognized independently, unsupervised ML. The methods of AI-based retinal analyses are diverse and differ widely in their applicability, interpretability and reliability in different datasets and diseases. Fully automated AI-based systems have recently been approved for screening of diabetic retinopathy (DR). The overall potential of ML/DL includes screening, diagnostic grading as well as guidance of therapy with automated detection of disease activity, recurrences, quantification of therapeutic effects and identification of relevant targets for novel therapeutic approaches. Prediction and prognostic conclusions further expand the potential benefit of AI in retina which will enable personalized health care as well as large scale management and will empower the ophthalmologist to provide high quality diagnosis/therapy and successfully deal with the complexity of 21st century ophthalmology."
https://openalex.org/W2971544482,Edge Intelligence: The Confluence of Edge Computing and Artificial Intelligence,"{'Along': [0], 'with': [1, 31, 109], 'the': [2, 9, 11, 32, 38, 49, 110, 118, 125, 137, 152, 156, 161], 'rapid': [3], 'developments': [4], 'in': [5, 23, 34, 106, 168], 'communication': [6], 'technologies': [7], 'and': [8, 37, 57, 69, 89, 114, 134, 155], 'surge\\nin': [10], 'use': [12], 'of': [13, 44, 112], 'mobile': [14], 'devices,': [15], 'a': [16, 62, 148], 'brand-new': [17], 'computation': [18], 'paradigm,': [19], 'Edge': [20, 67, 74, 81, 87, 107, 169], 'Computing,\\nis': [21], 'surging': [22], 'popularity.': [24], 'Meanwhile,': [25], 'Artificial': [26], 'Intelligence': [27, 82], '(AI)': [28], 'applications\\nare': [29], 'thriving': [30], 'breakthroughs': [33], 'deep': [35], 'learning': [36], 'many': [39], 'improvements\\nin': [40], 'hardware': [41], 'architectures.': [42], 'Billions': [43], 'data': [45, 55], 'bytes,': [46], 'generated': [47], 'at': [48], 'network\\nedge,': [50], 'put': [51], 'massive': [52], 'demands': [53], 'on': [54, 91, 94, 99, 136], 'processing': [56], 'structural': [58], 'optimization.': [59], 'Thus,\\nthere': [60], 'exists': [61], 'strong': [63], 'demand': [64], 'to': [65, 73, 122], 'integrate': [66], 'Computing': [68, 108], 'AI,': [70], 'which': [71], 'gives\\nbirth': [72], 'Intelligence.': [75], 'In': [76], 'this': [77, 143], 'paper,': [78], 'we': [79], 'divide': [80], 'into': [83, 142], 'AI\\nfor': [84], 'edge': [85, 92], '(Intelligence-enabled': [86], 'Computing)': [88], 'AI': [90, 129], '(Artificial\\nIntelligence': [93], 'Edge).': [95], 'The': [96], 'former': [97], 'focuses': [98], 'providing': [100], 'more': [101], 'optimal': [102], 'solutions\\nto': [103], 'key': [104], 'problems': [105], 'help': [111], 'popular': [113], 'effective': [115], 'AI\\ntechnologies': [116], 'while': [117], 'latter': [119], 'studies': [120], 'how': [121], 'carry': [123], 'out': [124], 'entire': [126], 'process': [127], 'of\\nbuilding': [128], 'models,': [130], 'i.e.,': [131], 'model': [132], 'training': [133], 'inference,': [135], 'edge.': [138], 'This': [139], 'paper\\nprovides': [140], 'insights': [141], 'new': [144], 'inter-disciplinary': [145], 'field': [146], 'from': [147], 'broader\\nperspective.': [149], 'It': [150], 'discusses': [151], 'core': [153], 'concepts': [154], 'research': [157], 'road-map,': [158], 'which\\nshould': [159], 'provide': [160], 'necessary': [162], 'background': [163], 'for': [164], 'potential': [165], 'future': [166], 'research\\ninitiatives': [167], 'Intelligence.\\n': [170]}",2020,"['Confluence', 'Computer science', 'Enhanced Data Rates for GSM Evolution', 'Artificial intelligence', 'Edge computing', 'Programming language']","Along with the rapid developments in communication technologies and the surge\nin the use of mobile devices, a brand-new computation paradigm, Edge Computing,\nis surging in popularity. Meanwhile, Artificial Intelligence (AI) applications\nare thriving with the breakthroughs in deep learning and the many improvements\nin hardware architectures. Billions of data bytes, generated at the network\nedge, put massive demands on data processing and structural optimization. Thus,\nthere exists a strong demand to integrate Edge Computing and AI, which gives\nbirth to Edge Intelligence. In this paper, we divide Edge Intelligence into AI\nfor edge (Intelligence-enabled Edge Computing) and AI on edge (Artificial\nIntelligence on Edge). The former focuses on providing more optimal solutions\nto key problems in Edge Computing with the help of popular and effective AI\ntechnologies while the latter studies how to carry out the entire process of\nbuilding AI models, i.e., model training and inference, on the edge. This paper\nprovides insights into this new inter-disciplinary field from a broader\nperspective. It discusses the core concepts and the research road-map, which\nshould provide the necessary background for potential future research\ninitiatives in Edge Intelligence.\n"
https://openalex.org/W4367310920,Comparing Physician and Artificial Intelligence Chatbot Responses to Patient Questions Posted to a Public Social Media Forum,"{'Importance': [0], 'The': [1, 141, 297, 363], 'rapid': [2], 'expansion': [3], 'of': [4, 52, 84, 161, 177, 252, 283, 299, 335, 365, 402, 433], 'virtual': [5], 'health': [6, 22, 163], 'care': [7, 23, 164], 'has': [8], 'caused': [9], 'a': [10, 79, 87, 105, 110, 123, 159, 222, 416], 'surge': [11], 'in': [12, 32, 59, 132, 156, 247, 427, 438], 'patient': [13, 36, 69, 424, 470], 'messages': [14], 'concomitant': [15], 'with': [16, 145], 'more': [17, 351], 'work': [18], 'and': [19, 65, 73, 81, 138, 147, 151, 172, 194, 213, 227, 231, 238, 420, 468], 'burnout': [20], 'among': [21], 'professionals.': [24, 165], 'Artificial': [25], 'intelligence': [26], '(AI)': [27], 'assistants': [28, 461], 'could': [29, 42, 450, 455], 'potentially': [30], 'aid': [31], 'creating': [33], 'answers': [34], 'to': [35, 62, 68, 96, 109, 224, 244, 330, 397, 423, 445], 'questions': [37, 85, 128, 237, 425], 'by': [38, 45, 117, 158], 'drafting': [39], 'responses': [40, 67, 114, 153, 243, 246, 259, 265, 280, 289, 300, 341, 346, 355, 366, 407, 422, 447], 'that': [41, 448], 'be': [43], 'reviewed': [44], 'clinicians.': [46], 'Objective': [47], 'To': [48], 'evaluate': [49], 'the': [50, 119, 133, 235, 253, 343, 409], 'ability': [51], 'an': [53, 428], 'AI': [54, 460], 'chatbot': [55, 152, 230, 242, 264, 315, 376, 417, 444], 'assistant': [56], '(ChatGPT),': [57], 'released': [58], 'November': [60], '2022,': [61], 'provide': [63], 'quality': [64, 176, 286, 307, 340, 419], 'empathetic': [66, 203, 206, 209, 211, 215, 352, 368, 371, 403, 406, 421], 'questions.': [70], 'Design,': [71], 'Setting,': [72], 'Participants': [74], 'In': [75, 412], 'this': [76, 413, 434], 'cross-sectional': [77, 414], 'study,': [78, 415], 'public': [80, 88, 111], 'nonidentifiable': [82], 'database': [83], 'from': [86, 101], 'social': [89], 'media': [90], 'forum': [91], '(Reddit’s': [92], 'r/AskDocs)': [93], 'was': [94, 170, 312, 373], 'used': [95], 'randomly': [97, 148], 'draw': [98], '195': [99, 236], 'exchanges': [100], 'October': [102], '2022': [103], 'where': [104], 'verified': [106], 'physician': [107, 150, 245, 258, 288, 354], 'responded': [108], 'question.': [112], 'Chatbot': [113, 279, 345], 'were': [115, 154, 219, 260, 281, 347], 'generated': [116, 418], 'entering': [118], 'original': [120, 142], 'question': [121, 143], 'into': [122], 'fresh': [124], 'session': [125], '(without': [126], 'prior': [127], 'having': [129], 'been': [130], 'asked': [131], 'session)': [134], 'on': [135, 221], 'December': [136], '22': [137], '23,': [139], '2022.': [140], 'along': [144], 'anonymized': [146], 'ordered': [149, 220], 'evaluated': [155], 'triplicate': [157], 'team': [160], 'licensed': [162], 'Evaluators': [166], 'chose': [167], '“which': [168], 'response': [169], 'better”': [171], 'judged': [173], 'both': [174], '“the': [175, 195], 'information': [178], 'provided”': [179, 200], '(': [180, 201, 290, 356], 'very': [181, 191, 214, 305, 338, 370, 405], 'poor': [182, 184], ',': [183, 185, 187, 189, 204, 207, 210, 212], 'acceptable': [186], 'good': [188, 192, 303, 306, 336, 339], 'or': [190, 197, 304, 337, 369, 404], ')': [193], 'empathy': [196], 'bedside': [198], 'manner': [199], 'not': [202], 'slightly': [205], 'moderately': [208], ').': [216], 'Mean': [217, 256], 'outcomes': [218], '1': [223], '5': [225], 'scale': [226], 'compared': [228], 'between': [229], 'physicians.': [232], 'Results': [233], 'Of': [234], 'responses,': [239, 464], 'evaluators': [240], 'preferred': [241], '78.6%': [248], '(95%': [249], 'CI,': [250, 321, 326, 383, 388, 393], '75.0%-81.8%)': [251], '585': [254], 'evaluations.': [255], '(IQR)': [257], 'significantly': [261, 284, 350], 'shorter': [262], 'than': [263, 287, 316, 353, 377], '(52': [266], '[17-62]': [267], 'words': [268], 'vs': [269], '211': [270], '[168-245]': [271], 'words;': [272], 't': [273, 291, 357], '=': [274, 292, 358], '25.4;': [275], 'P': [276, 294, 360], '&amp;amp;lt;': [277, 295, 361], '.001).': [278, 296, 362], 'rated': [282, 301, 349, 367], 'higher': [285, 313, 333, 374, 400], '13.3;': [293], 'proportion': [298, 364], 'as': [302, 442], '(≥': [308], '4),': [309], 'for': [310, 314, 342, 375, 378, 408], 'instance,': [311], 'physicians': [317, 379, 449], '(chatbot:': [318], '78.5%,': [319], '95%': [320, 325, 382, 387, 392], '72.3%-84.1%;': [322], 'physicians:': [323, 390], '22.1%,': [324], '16.4%-28.2%;).': [327], 'This': [328, 395], 'amounted': [329, 396], '3.6': [331], 'times': [332, 399], 'prevalence': [334, 401], 'chatbot.': [344, 410], 'also': [348], '18.9;': [359], '(≥4)': [372], '(physicians:': [380], '4.6%,': [381, 391], '2.1%-7.7%;': [384], 'chatbot:': [385], '45.1%,': [386], '38.5%-51.8%;': [389], '2.1%-7.7%).': [394], '9.8': [398], 'Conclusions': [411], 'posed': [426], 'online': [429], 'forum.': [430], 'Further': [431], 'exploration': [432], 'technology': [435], 'is': [436], 'warranted': [437], 'clinical': [439], 'settings,': [440], 'such': [441], 'using': [443, 459], 'draft': [446], 'then': [451], 'edit.': [452], 'Randomized': [453], 'trials': [454], 'assess': [456], 'further': [457], 'if': [458], 'might': [462], 'improve': [463, 469], 'lower': [465], 'clinician': [466], 'burnout,': [467], 'outcomes.': [471]}",2023,"['Chatbot', 'Medicine', 'Empathy', 'Session (web analytics)', 'Social media', 'Nursing', 'Medical education', 'Family medicine', 'World Wide Web', 'Psychiatry', 'Computer science']","Importance The rapid expansion of virtual health care has caused a surge in patient messages concomitant with more work and burnout among health care professionals. Artificial intelligence (AI) assistants could potentially aid in creating answers to patient questions by drafting responses that could be reviewed by clinicians. Objective To evaluate the ability of an AI chatbot assistant (ChatGPT), released in November 2022, to provide quality and empathetic responses to patient questions. Design, Setting, and Participants In this cross-sectional study, a public and nonidentifiable database of questions from a public social media forum (Reddit’s r/AskDocs) was used to randomly draw 195 exchanges from October 2022 where a verified physician responded to a public question. Chatbot responses were generated by entering the original question into a fresh session (without prior questions having been asked in the session) on December 22 and 23, 2022. The original question along with anonymized and randomly ordered physician and chatbot responses were evaluated in triplicate by a team of licensed health care professionals. Evaluators chose “which response was better” and judged both “the quality of information provided” ( very poor , poor , acceptable , good , or very good ) and “the empathy or bedside manner provided” ( not empathetic , slightly empathetic , moderately empathetic , empathetic , and very empathetic ). Mean outcomes were ordered on a 1 to 5 scale and compared between chatbot and physicians. Results Of the 195 questions and responses, evaluators preferred chatbot responses to physician responses in 78.6% (95% CI, 75.0%-81.8%) of the 585 evaluations. Mean (IQR) physician responses were significantly shorter than chatbot responses (52 [17-62] words vs 211 [168-245] words; t = 25.4; P &amp;amp;lt; .001). Chatbot responses were rated of significantly higher quality than physician responses ( t = 13.3; P &amp;amp;lt; .001). The proportion of responses rated as good or very good quality (≥ 4), for instance, was higher for chatbot than physicians (chatbot: 78.5%, 95% CI, 72.3%-84.1%; physicians: 22.1%, 95% CI, 16.4%-28.2%;). This amounted to 3.6 times higher prevalence of good or very good quality responses for the chatbot. Chatbot responses were also rated significantly more empathetic than physician responses ( t = 18.9; P &amp;amp;lt; .001). The proportion of responses rated empathetic or very empathetic (≥4) was higher for chatbot than for physicians (physicians: 4.6%, 95% CI, 2.1%-7.7%; chatbot: 45.1%, 95% CI, 38.5%-51.8%; physicians: 4.6%, 95% CI, 2.1%-7.7%). This amounted to 9.8 times higher prevalence of empathetic or very empathetic responses for the chatbot. Conclusions In this cross-sectional study, a chatbot generated quality and empathetic responses to patient questions posed in an online forum. Further exploration of this technology is warranted in clinical settings, such as using chatbot to draft responses that physicians could then edit. Randomized trials could assess further if using AI assistants might improve responses, lower clinician burnout, and improve patient outcomes."
https://openalex.org/W3081261125,Consumers and Artificial Intelligence: An Experiential Perspective,"{'Artificial': [0], 'intelligence': [1], '(AI)': [2], 'helps': [3], 'companies': [4], 'offer': [5], 'important': [6], 'benefits': [7], 'to': [8, 44, 71, 94, 110, 151, 157, 166, 175], 'consumers,': [9], 'such': [10], 'as': [11, 40], 'health': [12], 'monitoring': [13], 'with': [14, 18, 24, 30, 121, 134], 'wearable': [15], 'devices,': [16], 'advice': [17], 'recommender': [19], 'systems,': [20], 'peace': [21], 'of': [22, 113, 131], 'mind': [23], 'smart': [25], 'household': [26], 'products,': [27], 'and': [28, 49, 58, 90, 104, 107, 143, 154, 174], 'convenience': [29], 'voice-activated': [31], 'virtual': [32], 'assistants.': [33], 'However,': [34], 'although': [35], 'AI': [36, 65, 86, 173], 'can': [37, 62, 92], 'be': [38, 45], 'seen': [39], 'a': [41], 'neutral': [42], 'tool': [43], 'evaluated': [46], 'on': [47, 76, 103], 'efficiency': [48], 'accuracy,': [50], 'this': [51], 'approach': [52, 147], 'does': [53], 'not': [54], 'consider': [55], 'the': [56, 79, 82, 97, 100, 114, 126, 149, 159], 'social': [57], 'individual': [59], 'challenges': [60], 'that': [61, 84], 'occur': [63], 'when': [64], 'is': [66], 'deployed.': [67], 'This': [68, 146], 'research': [69], 'aims': [70], 'bridge': [72], 'these': [73], 'two': [74], 'perspectives:': [75], 'one': [77], 'side,': [78, 99], 'authors': [80, 101, 127, 150], 'acknowledge': [81], 'value': [83, 168], 'embedding': [85], 'technology': [87], 'into': [88, 172], 'products': [89], 'services': [91], 'provide': [93], 'consumers.': [95], 'On': [96], 'other': [98], 'build': [102], 'integrate': [105], 'sociological': [106], 'psychological': [108], 'scholarship': [109], 'examine': [111], 'some': [112], 'costs': [115], 'consumers': [116, 163], 'experience': [117, 167], 'in': [118, 161, 169], 'their': [119], 'interactions': [120], 'AI.': [122], 'In': [123], 'doing': [124], 'so,': [125], 'identify': [128], 'four': [129], 'types': [130], 'consumer': [132], 'experiences': [133], 'AI:': [135], '(1)': [136], 'data': [137], 'capture,': [138], '(2)': [139], 'classification,': [140], '(3)': [141], 'delegation,': [142], '(4)': [144], 'social.': [145], 'allows': [148], 'discuss': [152], 'policy': [153], 'managerial': [155], 'avenues': [156], 'address': [158], 'ways': [160], 'which': [162], 'may': [164], 'fail': [165], 'organizations’': [170], 'investments': [171], 'lay': [176], 'out': [177], 'an': [178], 'agenda': [179], 'for': [180], 'future': [181], 'research.': [182]}",2020,"['Value (mathematics)', 'Experiential learning', 'Scholarship', 'Perspective (graphical)', 'Bridge (graph theory)', 'Marketing', 'Computer science', 'Knowledge management', 'Sociology', 'Business', 'Artificial intelligence', 'Economics', 'Medicine', 'Machine learning', 'Economic growth', 'Pedagogy', 'Internal medicine']","Artificial intelligence (AI) helps companies offer important benefits to consumers, such as health monitoring with wearable devices, advice with recommender systems, peace of mind with smart household products, and convenience with voice-activated virtual assistants. However, although AI can be seen as a neutral tool to be evaluated on efficiency and accuracy, this approach does not consider the social and individual challenges that can occur when AI is deployed. This research aims to bridge these two perspectives: on one side, the authors acknowledge the value that embedding AI technology into products and services can provide to consumers. On the other side, the authors build on and integrate sociological and psychological scholarship to examine some of the costs consumers experience in their interactions with AI. In doing so, the authors identify four types of consumer experiences with AI: (1) data capture, (2) classification, (3) delegation, and (4) social. This approach allows the authors to discuss policy and managerial avenues to address the ways in which consumers may fail to experience value in organizations’ investments into AI and to lay out an agenda for future research."
https://openalex.org/W2910707576,"Artificial intelligence, bias and clinical safety","{'This': [0], 'is': [1], 'the': [2, 14], 'final': [3], 'version.': [4], 'Available': [5], 'on': [6], 'open': [7], 'access': [8], 'from': [9], 'BMJ': [10], 'Publishing': [11], 'group': [12], 'via': [13], 'DOI': [15], 'in': [16], 'this': [17], 'record': [18]}",2019,"['Medicine', 'Patient safety', 'MEDLINE', 'Medical emergency', 'Data science', 'Health care', 'Computer science', 'Economic growth', 'Economics', 'Law', 'Political science']",This is the final version. Available on open access from BMJ Publishing group via the DOI in this record
https://openalex.org/W4304943299,Ethical principles for artificial intelligence in education,"{'Abstract': [0], 'The': [1, 179], 'advancement': [2], 'of': [3, 21, 30, 40, 52, 76, 145, 182, 203, 214], 'artificial': [4], 'intelligence': [5], 'in': [6, 128, 198, 218], 'education': [7, 129], '(AIED)': [8], 'has': [9, 54], 'the': [10, 14, 19, 28, 50, 73, 83, 87, 123, 199, 219], 'potential': [11, 131], 'to': [12, 36, 56, 96, 139, 187, 192], 'transform': [13], 'educational': [15, 168, 196], 'landscape': [16], 'and': [17, 43, 47, 60, 69, 80, 109, 115, 130, 141, 150, 155, 163, 176, 194, 201, 205], 'influence': [18], 'role': [20], 'all': [22], 'involved': [23], 'stakeholders.': [24], 'In': [25, 117], 'recent': [26, 74], 'years,': [27], 'applications': [29], 'AIED': [31, 53, 106, 207], 'have': [32], 'been': [33], 'gradually': [34], 'adopted': [35], 'progress': [37], 'our': [38], 'understanding': [39], 'students’': [41], 'learning': [42, 45], 'enhance': [44], 'performance': [46], 'experience.': [48], 'However,': [49], 'adoption': [51], 'led': [55], 'increasing': [57], 'ethical': [58, 79, 91, 105, 132, 146, 153, 183, 204], 'risks': [59], 'concerns': [61], 'regarding': [62], 'several': [63], 'aspects': [64], 'such': [65], 'as': [66, 189, 208, 210], 'personal': [67], 'data': [68], 'learner': [70], 'autonomy.': [71], 'Despite': [72], 'announcement': [75], 'guidelines': [77, 156], 'for': [78, 157, 166], 'trustworthy': [81, 206], 'AIED,': [82], 'debate': [84], 'revolves': [85], 'around': [86], 'key': [88], 'principles': [89, 147, 184], 'underpinning': [90], 'AIED.': [92, 158], 'This': [93], 'paper': [94], 'aims': [95], 'explore': [97], 'whether': [98], 'there': [99], 'is': [100, 185], 'a': [101, 143, 190], 'global': [102], 'consensus': [103], 'on': [104], 'by': [107, 126, 148], 'mapping': [108], 'analyzing': [110], 'international': [111], 'organizations’': [112], 'current': [113], 'policies': [114, 154], 'guidelines.': [116], 'this': [118], 'paper,': [119], 'we': [120], 'first': [121], 'introduce': [122], 'opportunities': [124], 'offered': [125], 'AI': [127], 'issues.': [133], 'Then,': [134], 'thematic': [135], 'analysis': [136], 'was': [137], 'conducted': [138], 'conceptualize': [140], 'establish': [142], 'set': [144, 181], 'examining': [149], 'synthesizing': [151], 'relevant': [152, 167], 'We': [159], 'discuss': [160], 'each': [161], 'principle': [162], 'associated': [164], 'implications': [165], 'stakeholders,': [169], 'including': [170], 'students,': [171], 'teachers,': [172], 'technology': [173], 'developers,': [174], 'policymakers,': [175], 'institutional': [177], 'decision-makers.': [178], 'proposed': [180], 'expected': [186], 'serve': [188], 'framework': [191], 'inform': [193], 'guide': [195], 'stakeholders': [197], 'development': [200, 213], 'deployment': [202], 'well': [209], 'catalyze': [211], 'future': [212], 'related': [215], 'impact': [216], 'studies': [217], 'field.': [220]}",2022,"['Autonomy', 'Engineering ethics', 'Underpinning', 'Trustworthiness', 'Set (abstract data type)', 'Thematic analysis', 'Psychology', 'Knowledge management', 'Public relations', 'Political science', 'Sociology', 'Computer science', 'Qualitative research', 'Engineering', 'Social psychology', 'Social science', 'Law', 'Civil engineering', 'Programming language']","Abstract The advancement of artificial intelligence in education (AIED) has the potential to transform the educational landscape and influence the role of all involved stakeholders. In recent years, the applications of AIED have been gradually adopted to progress our understanding of students’ learning and enhance learning performance and experience. However, the adoption of AIED has led to increasing ethical risks and concerns regarding several aspects such as personal data and learner autonomy. Despite the recent announcement of guidelines for ethical and trustworthy AIED, the debate revolves around the key principles underpinning ethical AIED. This paper aims to explore whether there is a global consensus on ethical AIED by mapping and analyzing international organizations’ current policies and guidelines. In this paper, we first introduce the opportunities offered by AI in education and potential ethical issues. Then, thematic analysis was conducted to conceptualize and establish a set of ethical principles by examining and synthesizing relevant ethical policies and guidelines for AIED. We discuss each principle and associated implications for relevant educational stakeholders, including students, teachers, technology developers, policymakers, and institutional decision-makers. The proposed set of ethical principles is expected to serve as a framework to inform and guide educational stakeholders in the development and deployment of ethical and trustworthy AIED as well as catalyze future development of related impact studies in the field."
https://openalex.org/W3011149445,Using Artificial Intelligence to Detect COVID-19 and Community-acquired Pneumonia Based on Pulmonary CT: Evaluation of the Diagnostic Accuracy,"{'Background': [0], 'Coronavirus': [1], 'disease': [2], '2019': [3, 270], '(COVID-19)': [4], 'has': [5], 'widely': [6], 'spread': [7], 'all': [8], 'over': [9], 'the': [10, 13, 61, 79, 97, 100, 120, 123, 179, 210, 229, 250], 'world': [11], 'since': [12], 'beginning': [14], 'of': [15, 26, 81, 85, 99, 136, 192, 202, 215, 236, 242, 255], '2020.': [16, 114], 'It': [17], 'is': [18, 287], 'desirable': [19], 'to': [20, 38, 69, 95], 'develop': [21, 33], 'automatic': [22, 36], 'and': [23, 44, 49, 54, 89, 112, 129, 155, 173, 195, 223, 239, 271, 277], 'accurate': [24], 'detection': [25, 63, 80], 'COVID-19': [27, 40, 62, 177], 'using': [28, 41], 'chest': [29, 42, 75, 138], 'CT.': [30], 'Purpose': [31], 'To': [32], 'a': [34, 57], 'fully': [35], 'framework': [37], 'detect': [39, 268], 'CT': [43, 76, 83, 139], 'evaluate': [45], 'its': [46], 'performance.': [47], 'Materials': [48], 'Methods': [50], 'In': [51], 'this': [52, 290], 'retrospective': [53], 'multicenter': [55], 'study,': [56], 'deep': [58, 263], 'learning': [59, 264], 'model,': [60], 'neural': [64], 'network': [65], '(COVNet),': [66], 'was': [67, 117, 150, 183, 233], 'developed': [68], 'extract': [70], 'visual': [71], 'features': [72], 'from': [73, 106, 141, 274], 'volumetric': [74], 'scans': [77, 84, 140], 'for': [78, 175, 225, 289], 'COVID-19.': [82], 'community-acquired': [86, 275], 'pneumonia': [87, 276], '(CAP)': [88], 'other': [90, 278], 'non-pneumonia': [91], 'abnormalities': [92], 'were': [93, 104, 157], 'included': [94], 'test': [96, 181, 231], 'robustness': [98], 'model.': [101], 'The': [102, 132, 144, 170, 220], 'datasets': [103], 'collected': [105, 133], 'six': [107], 'hospitals': [108], 'between': [109], 'August': [110], '2016': [111], 'February': [113], 'Diagnostic': [115], 'performance': [116], 'assessed': [118], 'with': [119, 206, 246], 'area': [121, 208, 248], 'under': [122, 209, 249], 'receiver': [124, 211, 251], 'operating': [125, 212, 252], 'characteristic': [126, 213, 253], 'curve,': [127], 'sensitivity,': [128], 'specificity.': [130], 'Results': [131], 'dataset': [134], 'consisted': [135], '4352': [137], '3322': [142], 'patients.': [143], 'average': [145], 'patient': [146], 'age': [147], '(±standard': [148], 'deviation)': [149], '49': [151], 'years': [152], '±': [153], '15,': [154], 'there': [156], 'slightly': [158], 'more': [159], 'men': [160], 'than': [161], 'women': [162], '(1838': [163], 'vs': [164], '1484,': [165], 'respectively;': [166], '<i>P</i>': [167], '=': [168], '.29).': [169], 'per-scan': [171, 221], 'sensitivity': [172, 222], 'specificity': [174, 224], 'detecting': [176, 226], 'in': [178, 228], 'independent': [180, 230], 'set': [182, 232], '90%': [184], '(95%': [185, 197, 257], 'confidence': [186], 'interval': [187], '[CI]:': [188], '83%,': [189], '94%;': [190], '114': [191], '127': [193], 'scans)': [194, 238], '96%': [196], 'CI:': [198, 258], '93%,': [199], '98%;': [200], '294': [201], '307': [203], 'scans),': [204, 244], 'respectively,': [205, 245], 'an': [207, 247], 'curve': [214, 254], '0.96': [216], '(<i>P</i>': [217], '<': [218], '.001).': [219], 'CAP': [227], '87%': [234], '(152': [235], '175': [237], '92%': [240], '(239': [241], '259': [243], '0.95': [256], '0.93,': [259], '0.97).': [260], 'Conclusion': [261], 'A': [262], 'model': [265], 'can': [266], 'accurately': [267], 'coronavirus': [269], 'differentiate': [272], 'it': [273], 'lung': [279], 'conditions.': [280], '©': [281], 'RSNA,': [282], '2020': [283], '<i>Online': [284], 'supplemental': [285], 'material': [286], 'available': [288], 'article.</i>': [291]}",2020,"['Medicine', 'Receiver operating characteristic', 'Coronavirus disease 2019 (COVID-19)', 'Pneumonia', 'Confidence interval', 'Radiology', 'Community-acquired pneumonia', 'Area under the curve', 'Nuclear medicine', 'Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)', 'Area under curve', 'Computed tomography', 'Internal medicine', 'Disease', 'Infectious disease (medical specialty)', 'Pharmacokinetics']","Background Coronavirus disease 2019 (COVID-19) has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performance. Materials and Methods In this retrospective and multicenter study, a deep learning model, the COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT scans for the detection of COVID-19. CT scans of community-acquired pneumonia (CAP) and other non-pneumonia abnormalities were included to test the robustness of the model. The datasets were collected from six hospitals between August 2016 and February 2020. Diagnostic performance was assessed with the area under the receiver operating characteristic curve, sensitivity, and specificity. Results The collected dataset consisted of 4352 chest CT scans from 3322 patients. The average patient age (±standard deviation) was 49 years ± 15, and there were slightly more men than women (1838 vs 1484, respectively; <i>P</i> = .29). The per-scan sensitivity and specificity for detecting COVID-19 in the independent test set was 90% (95% confidence interval [CI]: 83%, 94%; 114 of 127 scans) and 96% (95% CI: 93%, 98%; 294 of 307 scans), respectively, with an area under the receiver operating characteristic curve of 0.96 (<i>P</i> < .001). The per-scan sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175 scans) and 92% (239 of 259 scans), respectively, with an area under the receiver operating characteristic curve of 0.95 (95% CI: 0.93, 0.97). Conclusion A deep learning model can accurately detect coronavirus 2019 and differentiate it from community-acquired pneumonia and other lung conditions. © RSNA, 2020 <i>Online supplemental material is available for this article.</i>"
https://openalex.org/W2969912247,On Defining Artificial Intelligence,"{'Abstract': [0], 'This': [1], 'article': [2], 'systematically': [3], 'analyzes': [4], 'the': [5, 20, 23, 60, 64, 96, 108, 120], 'problem': [6], 'of': [7, 22, 29, 34, 86, 110], 'defining': [8], '“artificial': [9], 'intelligence.”': [10], 'It': [11, 99], 'starts': [12], 'by': [13], 'pointing': [14], 'out': [15], 'that': [16, 102], 'a': [17, 30, 35, 44, 116], 'definition': [18, 33, 70, 88, 104], 'influences': [19], 'path': [21], 'research,': [24, 50], 'then': [25], 'establishes': [26], 'four': [27], 'criteria': [28], 'good': [31], 'working': [32], 'notion:': [36], 'being': [37], 'similar': [38], 'to': [39, 48, 57, 74], 'its': [40], 'common': [41], 'usage,': [42], 'drawing': [43], 'sharp': [45], 'boundary,': [46], 'leading': [47], 'fruitful': [49], 'and': [51, 82, 91, 114], 'as': [52, 54], 'simple': [53], 'possible.': [55], 'According': [56], 'these': [58], 'criteria,': [59], 'representative': [61], 'definitions': [62], 'in': [63], 'field': [65], 'are': [66, 89], 'analyzed.': [67], 'A': [68], 'new': [69], 'is': [71, 93, 100], 'proposed,': [72], 'according': [73], 'it': [75, 92], 'intelligence': [76], 'means': [77], '“adaptation': [78], 'with': [79, 95], 'insufficient': [80], 'knowledge': [81], 'resources.”': [83], 'The': [84], 'implications': [85], 'this': [87, 103], 'discussed,': [90], 'compared': [94], 'other': [97], 'definitions.': [98], 'claimed': [101], 'sheds': [105], 'light': [106], 'on': [107], 'solution': [109], 'many': [111], 'existing': [112], 'problems': [113], 'sets': [115], 'sound': [117], 'foundation': [118], 'for': [119], 'field.': [121]}",2019,"['Adaptation (eye)', 'Field (mathematics)', 'Computer science', 'Simple (philosophy)', 'Foundation (evidence)', 'Path (computing)', 'Management science', 'Artificial intelligence', 'Boundary (topology)', 'Data science', 'Cognitive science', 'Epistemology', 'Mathematics', 'Psychology', 'Engineering', 'Political science', 'Philosophy', 'Law', 'Programming language', 'Pure mathematics', 'Mathematical analysis', 'Neuroscience']","Abstract This article systematically analyzes the problem of defining “artificial intelligence.” It starts by pointing out that a definition influences the path of the research, then establishes four criteria of a good working definition of a notion: being similar to its common usage, drawing a sharp boundary, leading to fruitful research, and as simple as possible. According to these criteria, the representative definitions in the field are analyzed. A new definition is proposed, according to it intelligence means “adaptation with insufficient knowledge and resources.” The implications of this definition are discussed, and it is compared with the other definitions. It is claimed that this definition sheds light on the solution of many existing problems and sets a sound foundation for the field."
https://openalex.org/W2959938226,Concepts of Artificial Intelligence for Computer-Assisted Drug Discovery,"{'Artificial': [0], 'intelligence': [1], '(AI),': [2], 'and,': [3], 'in': [4, 65, 95], 'particular,': [5], 'deep': [6], 'learning': [7, 25, 59, 81], 'as': [8], 'a': [9, 53, 127], 'subcategory': [10], 'of': [11, 20, 31, 37, 56, 62, 77, 87, 120], 'AI,': [12], 'provides': [13, 52], 'opportunities': [14], 'for': [15, 45, 133], 'the': [16, 70, 78, 83, 121], 'discovery': [17, 47, 90, 136], 'and': [18, 48, 61, 97, 106, 112, 118, 137], 'development': [19], 'innovative': [21], 'drugs.': [22], 'Various': [23], 'machine': [24, 58, 80], 'approaches': [26], 'have': [27, 41], 'recently': [28], '(re)emerged,': [29], 'some': [30, 74], 'which': [32, 40], 'may': [33], 'be': [34], 'considered': [35], 'instances': [36], 'domain-specific': [38], 'AI': [39], 'been': [42], 'successfully': [43], 'employed': [44], 'drug': [46, 103, 110, 135], 'design.': [49, 138], 'This': [50], 'review': [51], 'comprehensive': [54], 'portrayal': [55], 'these': [57], 'techniques': [60], 'their': [63], 'applications': [64, 94], 'medicinal': [66], 'chemistry.': [67], 'After': [68], 'introducing': [69], 'basic': [71], 'principles,': [72], 'alongside': [73], 'application': [75], 'notes,': [76], 'various': [79], 'algorithms,': [82], 'current': [84, 122], 'state-of-the': [85], 'art': [86], 'AI-assisted': [88, 134], 'pharmaceutical': [89], 'is': [91], 'discussed,': [92], 'including': [93], 'structure-': [96], 'ligand-based': [98], 'virtual': [99], 'screening,': [100], 'de': [101], 'novo': [102], 'design,': [104], 'physicochemical': [105], 'pharmacokinetic': [107], 'property': [108], 'prediction,': [109], 'repurposing,': [111], 'related': [113], 'aspects.': [114], 'Finally,': [115], 'several': [116], 'challenges': [117], 'limitations': [119], 'methods': [123], 'are': [124], 'summarized,': [125], 'with': [126], 'view': [128], 'to': [129], 'potential': [130], 'future': [131], 'directions': [132]}",2019,"['Drug discovery', 'Artificial intelligence', 'Virtual screening', 'Computer science', 'Repurposing', 'Chemistry', 'Data science', 'Machine learning', 'Engineering', 'Waste management', 'Biochemistry']","Artificial intelligence (AI), and, in particular, deep learning as a subcategory of AI, provides opportunities for the discovery and development of innovative drugs. Various machine learning approaches have recently (re)emerged, some of which may be considered instances of domain-specific AI which have been successfully employed for drug discovery and design. This review provides a comprehensive portrayal of these machine learning techniques and of their applications in medicinal chemistry. After introducing the basic principles, alongside some application notes, of the various machine learning algorithms, the current state-of-the art of AI-assisted pharmaceutical discovery is discussed, including applications in structure- and ligand-based virtual screening, de novo drug design, physicochemical and pharmacokinetic property prediction, drug repurposing, and related aspects. Finally, several challenges and limitations of the current methods are summarized, with a view to potential future directions for AI-assisted drug discovery and design."
https://openalex.org/W2950944546,A comprehensive review on automation in agriculture using artificial intelligence,"{'Agriculture': [0], 'automation': [1, 85, 204], 'is': [2, 15, 141], 'the': [3, 27, 43, 52, 64, 71, 73, 105, 147, 174, 177, 183, 189, 200], 'main': [4], 'concern': [5], 'and': [6, 22, 46, 69, 93, 124, 127, 159, 179, 223, 226], 'emerging': [7], 'subject': [8], 'for': [9, 29, 221], 'every': [10], 'country.': [11], 'The': [12, 207], 'world': [13], 'population': [14, 26], 'increasing': [16, 44], 'at': [17], 'a': [18, 67, 196, 211], 'very': [19], 'fast': [20], 'rate': [21], 'with': [23, 77], 'increase': [24, 173], 'in': [25, 58, 70, 163, 205, 218], 'need': [28, 144], 'food': [30], 'increases': [31], 'briskly.': [32], 'Traditional': [33], 'methods': [34], 'used': [35], 'by': [36, 54, 134], 'farmers': [37], ""aren't"": [38], 'sufficient': [39], 'enough': [40], 'to': [41, 50, 107, 145, 172, 194], 'serve': [42], 'demand': [45], 'so': [47], 'they': [48], 'have': [49], 'hamper': [51], 'soil': [53, 178, 184], 'using': [55, 228], 'harmful': [56, 152], 'pesticides': [57], 'an': [59, 142], 'intensified': [60], 'manner.': [61], 'This': [62, 80, 186], 'affects': [63], 'agricultural': [65, 164], 'practice': [66], 'lot': [68], 'end': [72], 'land': [74], 'remains': [75], 'barren': [76], 'no': [78], 'fertility.': [79, 185], 'paper': [81, 187, 208], 'talks': [82], 'about': [83, 199], 'different': [84, 137], 'practices': [86, 169], 'like': [87, 110, 149], 'IOT,': [88], 'Wireless': [89], 'Communications,': [90], 'Machine': [91, 235], 'learning': [92, 236], 'Artificial': [94], 'Intelligence,': [95], 'Deep': [96], 'learning.': [97], 'There': [98], 'are': [99, 103], 'some': [100], 'areas': [101], 'which': [102, 214], 'causing': [104], 'problems': [106, 130], 'agriculture': [108], 'field': [109], 'crop': [111], 'diseases,': [112], 'lack': [113, 121], 'of': [114, 122, 151, 161, 167, 191, 203], 'storage': [115], 'management,': [116, 120], 'pesticide': [117], 'control,': [118], 'weed': [119], 'irrigation': [123], 'water': [125], 'management': [126], 'all': [128], 'this': [129], 'can': [131, 215], 'be': [132, 216], 'solved': [133], 'above': [135], 'mentioned': [136], 'techniques.': [138], 'Today,': [139], 'there': [140], 'urgent': [143], 'decipher': [146], 'issues': [148], 'use': [150], 'pesticides,': [153], 'controlled': [154], 'irrigation,': [155], 'control': [156], 'on': [157], 'pollution': [158], 'effects': [160], 'environment': [162], 'practice.': [165], 'Automation': [166, 231], 'farming': [168], 'has': [170, 181], 'proved': [171], 'gain': [175], 'from': [176], 'also': [180, 209], 'strengthened': [182], 'surveys': [188], 'work': [190], 'many': [192], 'researchers': [193], 'get': [195], 'brief': [197], 'overview': [198], 'current': [201], 'implementation': [202], 'agriculture.': [206], 'discusses': [210], 'proposed': [212], 'system': [213], 'implemented': [217], 'botanical': [219], 'farm': [220], 'flower': [222], 'leaf': [224], 'identification': [225], 'watering': [227], 'IOT.': [229], 'Keywords:': [230], 'artificial': [232], 'intelligence,': [233], 'Irrigation,': [234]}",2019,"['Agriculture', 'Automation', 'Population', 'Agricultural engineering', 'Precision agriculture', 'Computer science', 'Business', 'Environmental planning', 'Engineering', 'Environmental science', 'Ecology', 'Biology', 'Medicine', 'Environmental health', 'Mechanical engineering']","Agriculture automation is the main concern and emerging subject for every country. The world population is increasing at a very fast rate and with increase in population the need for food increases briskly. Traditional methods used by farmers aren't sufficient enough to serve the increasing demand and so they have to hamper the soil by using harmful pesticides in an intensified manner. This affects the agricultural practice a lot and in the end the land remains barren with no fertility. This paper talks about different automation practices like IOT, Wireless Communications, Machine learning and Artificial Intelligence, Deep learning. There are some areas which are causing the problems to agriculture field like crop diseases, lack of storage management, pesticide control, weed management, lack of irrigation and water management and all this problems can be solved by above mentioned different techniques. Today, there is an urgent need to decipher the issues like use of harmful pesticides, controlled irrigation, control on pollution and effects of environment in agricultural practice. Automation of farming practices has proved to increase the gain from the soil and also has strengthened the soil fertility. This paper surveys the work of many researchers to get a brief overview about the current implementation of automation in agriculture. The paper also discusses a proposed system which can be implemented in botanical farm for flower and leaf identification and watering using IOT. Keywords: Automation artificial intelligence, Irrigation, Machine learning"
https://openalex.org/W2942193471,Artificial intelligence in education : challenges and opportunities for sustainable development,"{'Artificial': [0], 'Intelligence': [1], 'is': [2, 106, 206, 359, 421, 449, 623, 683, 740, 797, 825], 'a': [3, 67, 101, 284, 371, 567, 702, 715, 844], 'booming': [4], 'technological': [5, 582, 659], 'domain': [6], 'capable': [7], 'of': [8, 12, 42, 50, 61, 84, 104, 117, 135, 142, 152, 168, 184, 343, 348, 382, 417, 476, 534, 545, 570, 580, 593, 614, 640, 651, 676, 755, 759, 789, 840, 890, 923], 'altering': [9], 'every': [10], 'aspect': [11], 'our': [13, 763], 'social': [14, 80, 646], 'interactions.': [15], 'In': [16, 90], 'education,': [17, 232, 696, 756], 'AI': [18, 35, 65, 119, 173, 186, 217, 227, 344, 374, 454, 547, 574, 615, 630, 677, 693, 713, 721, 779, 802, 815, 865, 894, 924], 'has': [19, 120, 835], 'begun': [20], 'producing': [21], 'new': [22, 368, 425, 642, 671, 708, 915], 'teaching': [23], 'and': [24, 39, 79, 108, 137, 148, 198, 214, 221, 235, 255, 266, 297, 308, 327, 332, 373, 390, 406, 409, 444, 459, 497, 507, 510, 513, 518, 527, 537, 543, 550, 596, 607, 627, 645, 717, 720, 728, 744, 777, 850, 857, 863, 888, 905, 921], 'learning': [25, 179, 223, 520], 'solutions': [26, 260, 730], 'that': [27, 211, 530, 616, 673, 731, 812, 831], 'are': [28, 82, 330, 395, 485, 559, 637, 732, 750], 'now': [29], 'undergoing': [30], 'testing': [31], 'in': [32, 123, 127, 139, 200, 272, 316, 345, 384, 431, 548, 565, 587, 603, 631, 714, 734, 791, 803, 816, 820, 837, 843, 859, 925], 'different': [33, 322, 355], 'contexts.': [34], 'requires': [36], 'advanced': [37, 479], 'infrastructures': [38], 'an': [40, 317, 469, 554, 612, 688, 783, 910], 'ecosystem': [41, 613], 'thriving': [43], 'innovators,': [44], 'but': [45], 'what': [46, 105, 109], 'about': [47], 'the': [48, 59, 77, 85, 133, 140, 143, 153, 201, 321, 340, 357, 380, 399, 412, 418, 436, 466, 477, 505, 525, 535, 541, 581, 591, 649, 666, 753, 757, 787, 821, 829, 832, 918], 'urgencies': [49], 'developing': [51, 128, 202, 428, 566], 'countries?': [52], 'Will': [53], 'they': [54], 'have': [55, 600], 'to': [56, 69, 75, 156, 177, 194, 218, 231, 239, 287, 314, 336, 402, 423, 489, 585, 601, 610, 624, 664, 678, 684, 694, 711, 741, 769, 773, 785, 798, 872, 876, 913], 'wait': [57], 'for': [58, 282, 339, 370, 388, 427, 468, 553, 575, 629, 669, 687, 848, 927], '“luxury”': [60], 'AI?': [62], 'Or': [63], 'should': [64, 96, 531, 761, 781], 'be': [66, 97, 111, 175, 532, 662, 701, 762, 782, 809], 'priority': [68], 'tackle': [70, 490], 'as': [71, 73, 150, 249, 257, 398, 657], 'soon': [72], 'possible': [74], 'reduce': [76], 'digital': [78, 372, 385, 709], 'divide?These': [81], 'some': [83, 475, 502, 514], 'questions': [86], 'guiding': [87], 'this': [88, 91, 93, 169, 491, 588, 698], 'document.': [89], 'regard,': [92], 'urgent': [94], 'discussion': [95, 416, 900], 'taken': [98], 'up': [99], 'with': [100, 433, 648, 855, 909], 'clear': [102], 'picture': [103], 'happening': [107], 'can': [110, 174, 188, 228, 462, 808], 'done.': [112], 'This': [113], 'document': [114, 170, 907], 'gathers': [115], 'examples': [116, 183, 258, 353, 434], 'how': [118, 172, 185, 226, 725], 'been': [121], 'introduced': [122], 'education': [124, 190, 458, 509, 549, 690, 804, 817, 833, 873, 926], 'worldwide,': [125], 'particularly': [126], 'countries.': [129], 'It': [130, 181, 766], 'also': [131, 360, 500], 'sows': [132], 'seeds': [134], 'debates': [136], 'discussions': [138, 916], 'context': [141], '2019': [144], 'Mobile': [145], 'Learning': [146], 'Week': [147], 'beyond,': [149], 'part': [151, 448, 533], 'multiple': [154, 594], 'ways': [155], 'accomplish': [157], 'Sustainable': [158], 'Development': [159], 'Goal': [160], '4,': [161], 'which': [162, 325], 'targets': [163], 'education.': [164, 632], 'The': [165, 204, 415, 446, 561, 578, 620, 633, 737], 'first': [166, 562], 'section': [167, 205, 311, 358, 523], 'analyses': [171], 'used': [176], 'improve': [178, 195, 679, 774], 'outcomes.': [180], 'presents': [182], 'technology': [187], 'help': [189], 'systems': [191, 238, 291], 'use': [192, 712, 862], 'data': [193, 294, 746, 760, 775, 790, 860, 880, 886, 891], 'educational': [196, 290, 328, 334, 792, 841], 'equity': [197, 628], 'quality': [199, 743, 758], 'world.': [203], 'divided': [207, 361], 'into': [208, 362], 'two': [209, 363], 'topics': [210], 'address': [212], 'pedagogical': [213, 716], 'system-wide': [215], 'solutions:i)': [216], 'promote': [219], 'personalisation': [220], 'better': [222], 'outcomes,': [224], 'exploring': [225], 'favour': [229], 'access': [230, 871], 'collaborative': [233], 'environments': [234], 'intelligent': [236], 'tutoring': [237], 'support': [240], 'teachers.': [241], 'We': [242, 499], 'briefly': [243], 'introduce': [244], 'cases': [245, 300, 480, 503], 'from': [246, 262, 295, 301, 354, 411, 435, 481, 504, 516], 'countries': [247, 483, 636], 'such': [248, 397, 656], 'China,': [250], 'Uruguay,': [251], 'Brazil,': [252], 'South': [253, 495], 'Africa': [254], 'Kenya': [256], 'experimental': [259], 'conceived': [261], 'public': [263, 571, 899], 'policies,': [264], 'philanthropic': [265], 'private': [267], 'organisations.': [268], 'ii)': [269], 'Data': [270], 'analytics': [271], 'Education': [273], 'Management': [274], 'Information': [275], 'Systems': [276], '(EMIS).': [277], 'Here': [278, 472], 'we': [279, 473, 749], 'present': [280, 474, 501], 'opportunities': [281, 515], 'improving': [283], 'state’s': [285], 'capacity': [286], 'manage': [288], 'large-scale': [289], 'by': [292, 324], 'increasing': [293, 341], 'schools': [296, 432], 'learning,': [298], 'presenting': [299], 'United': [302, 439], 'Arab': [303], 'Emirates,': [304], 'Kenya,': [305], 'Bhutan,': [306], 'Kyrgyzstan': [307], 'Chile.The': [309], 'second': [310, 447, 621], '“Preparing': [312], 'learners': [313, 338], 'thrive': [315], 'AI-saturated': [318], 'future”': [319], 'explores': [320], 'means': [323], 'governments': [326], 'institutions': [329], 'rethinking': [331], 'reworking': [333], 'programmes': [335], 'prepare': [337, 465, 685], 'presence': [342], 'all': [346], 'aspects': [347], 'human': [349], 'activity.': [350], 'Based': [351], 'on': [352, 379, 452, 573, 801, 814, 884, 901], 'contexts,': [356], 'main': [364, 654], 'parts:': [365], 'i)': [366], '“A': [367], 'curriculum': [369], 'powered': [375], 'world”': [376], 'elaborates': [377], 'further': [378], 'importance': [381, 788], 'advancing': [383], 'competency': [386], 'frameworks': [387], 'teachers': [389, 686, 705, 726], 'students.': [391], 'Some': [392, 653], 'current': [393], 'initiatives': [394], 'presented': [396], '“Global': [400], 'Framework': [401], 'Measure': [403], 'Digital': [404], 'Literacy”': [405], '“ICT': [407], 'Competencies': [408], 'Standards': [410], 'Pedagogical': [413], 'Dimension”.': [414], 'curricular': [419], 'dimension': [420], 'broadened': [422], 'include': [424], 'experiences': [426], 'computational': [429], 'thinking': [430], 'European': [437], 'Union,': [438], 'Kingdom,': [440], 'Estonia,': [441], 'Argentina,': [442], 'Singapore': [443], 'Malaysia.ii)': [445], 'more': [450], 'focused': [451], 'strengthening': [453], 'capacities': [455], 'through': [456], 'post-basic': [457], 'training.': [460], 'How': [461], 'each': [463], 'country': [464], 'conditions': [467, 583, 668], 'AI-powered': [470, 555, 689], 'world?': [471], 'most': [478], 'developed': [482, 635], 'who': [484], 'generating': [486], 'comprehensive': [487, 568], 'plans': [488], 'question,': [492], 'namely': [493], 'France,': [494], 'Korea': [496], 'China.': [498], 'technical': [506], 'vocational': [508], 'training': [511], 'sector': [512, 834], 'non-formal': [517], 'informal': [519], 'scenarios.The': [521], 'last': [522], 'addresses': [524], 'challenges': [526, 558], 'policy': [528, 572], 'implications': [529], 'global': [536], 'local': [538], 'conversations': [539], 'regarding': [540, 870], 'possibilities': [542, 920], 'risks': [544, 922], 'introducing': [546], 'preparing': [551, 692], 'students': [552], 'context.': [556], 'Six': [557], 'presented:': [560], 'challenge': [563, 622, 682, 739, 796, 853], 'lies': [564], 'view': [569], 'sustainable': [576, 618, 733, 928], 'development.': [577, 619, 929], 'complexity': [579], 'needed': [584], 'advance': [586], 'field': [589], 'require': [590, 898], 'alignment': [592], 'factors': [595], 'institutions.': [597], 'Public': [598], 'policies': [599], 'work': [602, 727], 'partnership': [604], 'at': [605, 638], 'international': [606], 'national': [608], 'levels': [609], 'create': [611, 729, 914], 'serves': [617], 'ensure': [625], 'inclusion': [626], 'least': [634], 'risk': [639], 'suffering': [641], 'technological,': [643], 'economic': [644], 'divides': [647], 'development': [650], 'AI.': [652], 'obstacles': [655], 'basic': [658, 667], 'infrastructure': [660], 'must': [661, 699, 706, 723], 'faced': [663], 'establish': [665], 'implementing': [670], 'strategies': [672], 'take': [674], 'advantage': [675], 'learning.The': [680], 'third': [681], 'while': [691], 'understand': [695], 'though': [697], 'nevertheless': [700, 826], 'two-way': [703], 'road:': [704], 'learn': [707, 724], 'skills': [710], 'meaningful': [718], 'way': [719, 846], 'developers': [722], 'real-life': [735], 'environments.': [736], 'fourth': [738], 'develop': [742, 770], 'inclusive': [745], 'systems.': [747], 'If': [748], 'headed': [751], 'towards': [752], 'datafication': [754], 'chief': [764], 'concern.': [765], '́s': [767], 'essential': [768], 'state': [771], 'capabilities': [772], 'collection': [776], 'systematisation.': [778], 'developments': [780], 'opportunity': [784], 'increase': [786, 819], 'system': [793], 'management.The': [794], 'fifth': [795], 'make': [799], 'research': [800, 813, 842], 'significant.': [805], 'While': [806], 'it': [807, 824], 'reasonably': [810], 'expected': [811], 'will': [818, 896], 'coming': [822], 'years,': [823], 'worth': [827], 'recalling': [828], 'difficulties': [830], 'had': [836], 'taking': [838], 'stock': [839], 'significant': [845], 'both': [847], 'practice': [849], 'policy-making.The': [851], 'sixth': [852], 'deals': [854], 'ethics': [856], 'transparency': [858, 904], 'collection,': [861], 'dissemination.': [864], 'opens': [866], 'many': [867], 'ethical': [868], 'concerns': [869], 'system,': [874], 'recommendations': [875], 'individual': [877], 'students,': [878], 'personal': [879], 'concentration,': [881], 'liability,': [882], 'impact': [883], 'work,': [885], 'privacy': [887], 'ownership': [889], 'feeding': [892], 'algorithms.': [893], 'regulation': [895], 'thus': [897], 'ethics,': [902], 'accountability,': [903], 'security.The': [906], 'ends': [908], 'open': [911], 'invitation': [912], 'around': [917], 'uses,': [919]}",2019,"['Sustainable development', 'Engineering ethics', 'Business', 'Political science', 'Engineering', 'Law']","Artificial Intelligence is a booming technological domain capable of altering every aspect of our social interactions. In education, AI has begun producing new teaching and learning solutions that are now undergoing testing in different contexts. AI requires advanced infrastructures and an ecosystem of thriving innovators, but what about the urgencies of developing countries? Will they have to wait for the “luxury” of AI? Or should AI be a priority to tackle as soon as possible to reduce the digital and social divide?These are some of the questions guiding this document. In this regard, this urgent discussion should be taken up with a clear picture of what is happening and what can be done. This document gathers examples of how AI has been introduced in education worldwide, particularly in developing countries. It also sows the seeds of debates and discussions in the context of the 2019 Mobile Learning Week and beyond, as part of the multiple ways to accomplish Sustainable Development Goal 4, which targets education. The first section of this document analyses how AI can be used to improve learning outcomes. It presents examples of how AI technology can help education systems use data to improve educational equity and quality in the developing world. The section is divided into two topics that address pedagogical and system-wide solutions:i) AI to promote personalisation and better learning outcomes, exploring how AI can favour access to education, collaborative environments and intelligent tutoring systems to support teachers. We briefly introduce cases from countries such as China, Uruguay, Brazil, South Africa and Kenya as examples experimental solutions conceived from public policies, philanthropic and private organisations. ii) Data analytics in Education Management Information Systems (EMIS). Here we present opportunities for improving a state’s capacity to manage large-scale educational systems by increasing data from schools and learning, presenting cases from United Arab Emirates, Kenya, Bhutan, Kyrgyzstan and Chile.The second section “Preparing learners to thrive in an AI-saturated future” explores the different means by which governments and educational institutions are rethinking and reworking educational programmes to prepare learners for the increasing presence of AI in all aspects of human activity. Based on examples from different contexts, the section is also divided into two main parts: i) “A new curriculum for a digital and AI powered world” elaborates further on the importance of advancing in digital competency frameworks for teachers and students. Some current initiatives are presented such as the “Global Framework to Measure Digital Literacy” and “ICT Competencies and Standards from the Pedagogical Dimension”. The discussion of the curricular dimension is broadened to include new experiences for developing computational thinking in schools with examples from the European Union, United Kingdom, Estonia, Argentina, Singapore and Malaysia.ii) The second part is more focused on strengthening AI capacities through post-basic education and training. How can each country prepare the conditions for an AI-powered world? Here we present some of the most advanced cases from developed countries who are generating comprehensive plans to tackle this question, namely France, South Korea and China. We also present some cases from the technical and vocational education and training sector and some opportunities from non-formal and informal learning scenarios.The last section addresses the challenges and policy implications that should be part of the global and local conversations regarding the possibilities and risks of introducing AI in education and preparing students for an AI-powered context. Six challenges are presented: The first challenge lies in developing a comprehensive view of public policy on AI for sustainable development. The complexity of the technological conditions needed to advance in this field require the alignment of multiple factors and institutions. Public policies have to work in partnership at international and national levels to create an ecosystem of AI that serves sustainable development. The second challenge is to ensure inclusion and equity for AI in education. The least developed countries are at risk of suffering new technological, economic and social divides with the development of AI. Some main obstacles such as basic technological infrastructure must be faced to establish the basic conditions for implementing new strategies that take advantage of AI to improve learning.The third challenge is to prepare teachers for an AI-powered education while preparing AI to understand education, though this must nevertheless be a two-way road: teachers must learn new digital skills to use AI in a pedagogical and meaningful way and AI developers must learn how teachers work and create solutions that are sustainable in real-life environments. The fourth challenge is to develop quality and inclusive data systems. If we are headed towards the datafication of education, the quality of data should be our chief concern. It ́s essential to develop state capabilities to improve data collection and systematisation. AI developments should be an opportunity to increase the importance of data in educational system management.The fifth challenge is to make research on AI in education significant. While it can be reasonably expected that research on AI in education will increase in the coming years, it is nevertheless worth recalling the difficulties that the education sector has had in taking stock of educational research in a significant way both for practice and policy-making.The sixth challenge deals with ethics and transparency in data collection, use and dissemination. AI opens many ethical concerns regarding access to education system, recommendations to individual students, personal data concentration, liability, impact on work, data privacy and ownership of data feeding algorithms. AI regulation will thus require public discussion on ethics, accountability, transparency and security.The document ends with an open invitation to create new discussions around the uses, possibilities and risks of AI in education for sustainable development."
https://openalex.org/W3148271110,The role of artificial intelligence in healthcare: a structured literature review,"{'Abstract': [0], 'Background/Introduction': [1], 'Artificial': [2], 'intelligence': [3], '(AI)': [4], 'in': [5, 94, 136, 200], 'the': [6, 51, 78, 82, 92, 119, 123, 141, 201], 'healthcare': [7, 202], 'sector': [8], 'is': [9, 97], 'receiving': [10], 'attention': [11], 'from': [12, 24, 58, 81], 'researchers': [13, 52, 189], 'and': [14, 31, 35, 46, 64, 72, 109, 111, 118, 145, 159, 176, 183, 190, 194], 'health': [15, 36, 102, 157, 191], 'professionals.': [16], 'Few': [17], 'previous': [18], 'studies': [19], 'have': [20], 'investigated': [21], 'this': [22, 95], 'topic': [23], 'a': [25, 138, 160], 'multi-disciplinary': [26], 'perspective,': [27], 'including': [28], 'accounting,': [29], 'business': [30], 'management,': [32, 104], 'decision': [33], 'sciences': [34], 'professions.': [37], 'Methods': [38], 'The': [39, 60, 88, 114, 150], 'structured': [40], 'literature': [41, 93, 151], 'review': [42], 'with': [43], 'its': [44], 'reliable': [45], 'replicable': [47], 'research': [48, 163, 197], 'protocol': [49], 'allowed': [50], 'to': [53, 67], 'extract': [54], '288': [55], 'peer-reviewed': [56], 'papers': [57], 'Scopus.': [59], 'authors': [61], 'used': [62], 'qualitative': [63], 'quantitative': [65], 'variables': [66], 'analyse': [68], 'authors,': [69], 'journals,': [70], 'keywords,': [71], 'collaboration': [73], 'networks': [74], 'among': [75], 'researchers.': [76], 'Additionally,': [77], 'paper': [79], 'benefited': [80], 'Bibliometrix': [83], 'R': [84], 'software': [85], 'package.': [86], 'Results': [87], 'investigation': [89], 'showed': [90], 'that': [91, 131, 164], 'field': [96], 'emerging.': [98], 'It': [99], 'focuses': [100], 'on': [101, 198], 'services': [103, 158], 'predictive': [105], 'medicine,': [106], 'patient': [107], 'data': [108, 177], 'diagnostics,': [110], 'clinical': [112], 'decision-making.': [113], 'United': [115, 120], 'States,': [116], 'China,': [117], 'Kingdom': [121], 'contributed': [122], 'highest': [124], 'number': [125], 'of': [126, 143, 162], 'studies.': [127], 'Keyword': [128], 'analysis': [129, 182], 'revealed': [130], 'AI': [132, 154, 172, 199], 'can': [133, 187], 'support': [134], 'physicians': [135], 'making': [137], 'diagnosis,': [139], 'predicting': [140], 'spread': [142], 'diseases': [144], 'customising': [146], 'treatment': [147], 'paths.': [148], 'Conclusions': [149], 'reveals': [152], 'several': [153], 'applications': [155], 'for': [156, 180], 'stream': [161], 'has': [165], 'not': [166], 'fully': [167], 'been': [168], 'covered.': [169], 'For': [170], 'instance,': [171], 'projects': [173], 'require': [174], 'skills': [175], 'quality': [178], 'awareness': [179], 'data-intensive': [181], 'knowledge-based': [184], 'management.': [185], 'Insights': [186], 'help': [188], 'professionals': [192], 'understand': [193], 'address': [195], 'future': [196], 'field.': [203]}",2021,"['Health informatics', 'Health care', 'Knowledge management', 'Data science', 'Protocol (science)', 'Scopus', 'Field (mathematics)', 'Peer review', 'Systematic review', 'Computer science', 'Medical education', 'MEDLINE', 'Medicine', 'Nursing', 'Alternative medicine', 'Public health', 'Pure mathematics', 'Political science', 'Law', 'Pathology', 'Economics', 'Mathematics', 'Economic growth']","Abstract Background/Introduction Artificial intelligence (AI) in the healthcare sector is receiving attention from researchers and health professionals. Few previous studies have investigated this topic from a multi-disciplinary perspective, including accounting, business and management, decision sciences and health professions. Methods The structured literature review with its reliable and replicable research protocol allowed the researchers to extract 288 peer-reviewed papers from Scopus. The authors used qualitative and quantitative variables to analyse authors, journals, keywords, and collaboration networks among researchers. Additionally, the paper benefited from the Bibliometrix R software package. Results The investigation showed that the literature in this field is emerging. It focuses on health services management, predictive medicine, patient data and diagnostics, and clinical decision-making. The United States, China, and the United Kingdom contributed the highest number of studies. Keyword analysis revealed that AI can support physicians in making a diagnosis, predicting the spread of diseases and customising treatment paths. Conclusions The literature reveals several AI applications for health services and a stream of research that has not fully been covered. For instance, AI projects require skills and data quality awareness for data-intensive analysis and knowledge-based management. Insights can help researchers and health professionals understand and address future research on AI in the healthcare field."
https://openalex.org/W3013294478,Checklist for Artificial Intelligence in Medical Imaging (CLAIM): A Guide for Authors and Reviewers,"{'T': [0], 'he': [1], 'advent': [2], 'of': [3, 20, 28, 37, 69, 80, 94, 103, 113, 128, 153, 191, 227], 'deep': [4], 'neural': [5], 'networks': [6], 'as': [7, 248], 'a': [8, 17, 48, 167, 170, 249], 'new': [9], 'artifi-': [10], 'cial': [11], 'intelligence': [12], '(AI)': [13], 'technique': [14], 'has': [15, 121, 221], 'engendered': [16], 'large': [18], 'number': [19, 79], 'medical': [21, 25, 132, 195, 230], 'applications,': [22], 'particularly': [23], 'in': [24, 33, 56, 106, 140, 169, 194, 204, 229, 255], 'imaging.Such': [26], 'applications': [27, 226], 'AI': [29, 141, 192, 203, 228], 'must': [30, 44, 51], 'remain': [31], 'grounded': [32], 'the': [34, 53, 64, 70, 76, 90, 101, 126, 174, 200, 217, 262], 'fundamental': [35], 'tenets': [36], 'science': [38], 'and': [39, 47, 67, 72, 110, 189, 209, 220, 239], 'scientific': [40, 49], 'publication': [41, 50], '(1).Scientific': [42], 'results': [43], 'be': [45, 246], 'reproducible,': [46], 'describe': [52], ""authors'"": [54], 'work': [55], 'sufficient': [57], 'detail': [58], 'to': [59, 62, 74, 124, 137, 142, 163, 224, 252], 'enable': [60], 'readers': [61], 'determine': [63], 'rigor,': [65], 'quality,': [66], 'generalizability': [68], 'work,': [71], 'potentially': [73], 'reproduce': [75], ""work's"": [77], 'results.A': [78], 'valuable': [81], 'manuscript': [82, 183], 'checklists': [83], 'have': [84, 134, 157, 161], 'come': [85], 'into': [86, 166], 'widespread': [87], 'use,': [88], 'including': [89], 'Standards': [91, 112], 'for': [92, 150, 202], 'Reporting': [93, 102, 114], 'Diagnostic': [95], 'Accuracy': [96], 'Studies': [97], '(STARD)': [98], '(2-5),': [99], 'Strengthening': [100], 'Observational': [104], 'studies': [105, 130], 'Epidemiology': [107], '(STROBE)': [108], '(6),': [109], 'Consolidated': [111], 'Trials': [115], '(CONSORT)': [116], '(7,8).A': [117], 'radiomics': [118, 129], 'quality': [119, 127], 'score': [120], 'been': [122, 158, 222], 'proposed': [123, 159], 'assess': [125], '(9).Peer-reviewed': [131], 'journals': [133], 'an': [135], 'opportunity': [136], 'connect': [138], 'innovations': [139], 'clinical': [143], 'practice': [144], 'through': [145], 'rigorous': [146], 'validation': [147], '(10).Various': [148], 'guidelines': [149, 177], 'reporting': [151], 'evaluation': [152], 'machine': [154], 'learning': [155], 'models': [156], '(11)(12)(13)(14).We': [160], 'sought': [162], 'codify': [164], 'these': [165], 'checklist': [168, 263], 'format': [171], 'concordant': [172], 'with': [173, 264], 'EQUATOR': [175], 'Network': [176], '(15,16)': [178], 'that': [179, 232], 'also': [180], 'incorporates': [181], 'general': [182], 'review': [184], 'criteria': [185], '(17,18).To': [186], 'aid': [187], 'authors': [188, 254], 'reviewers': [190], 'manuscripts': [193], 'imaging,': [196], 'we': [197], 'propose': [198], 'CLAIM,': [199], 'Checklist': [201], 'Medical': [205], 'Imaging': [206], '(see': [207], 'Table': [208], 'downloadable': [210], 'Word': [211], 'document': [212], '[supplement]).CLAIM': [213], 'is': [214], 'modeled': [215], 'after': [216], 'STARD': [218], 'guideline': [219], 'extended': [223], 'address': [225], 'imaging': [231], 'include': [233], 'classification,': [234], 'image': [235], 'reconstruction,': [236], 'text': [237, 259], 'analysis,': [238], 'workflow': [240], 'optimization.The': [241], 'elements': [242], 'described': [243], 'here': [244], 'should': [245], 'viewed': [247], '""best': [250], 'practice""': [251], 'guide': [253], 'presenting': [256], 'their': [257], 'research.The': [258], 'below': [260], 'amplifies': [261], 'greater': [265], 'detail.': [266]}",2020,"['Checklist', 'Generalizability theory', 'Guideline', 'Computer science', 'Observational study', 'Quality (philosophy)', 'Medical physics', 'Medical imaging', 'Artificial intelligence', 'Medical education', 'Medicine', 'Psychology', 'Pathology', 'Epistemology', 'Philosophy', 'Developmental psychology', 'Cognitive psychology']","T he advent of deep neural networks as a new artifi- cial intelligence (AI) technique has engendered a large number of medical applications, particularly in medical imaging.Such applications of AI must remain grounded in the fundamental tenets of science and scientific publication (1).Scientific results must be reproducible, and a scientific publication must describe the authors' work in sufficient detail to enable readers to determine the rigor, quality, and generalizability of the work, and potentially to reproduce the work's results.A number of valuable manuscript checklists have come into widespread use, including the Standards for Reporting of Diagnostic Accuracy Studies (STARD) (2-5), Strengthening the Reporting of Observational studies in Epidemiology (STROBE) (6), and Consolidated Standards of Reporting Trials (CONSORT) (7,8).A radiomics quality score has been proposed to assess the quality of radiomics studies (9).Peer-reviewed medical journals have an opportunity to connect innovations in AI to clinical practice through rigorous validation (10).Various guidelines for reporting evaluation of machine learning models have been proposed (11)(12)(13)(14).We have sought to codify these into a checklist in a format concordant with the EQUATOR Network guidelines (15,16) that also incorporates general manuscript review criteria (17,18).To aid authors and reviewers of AI manuscripts in medical imaging, we propose CLAIM, the Checklist for AI in Medical Imaging (see Table and downloadable Word document [supplement]).CLAIM is modeled after the STARD guideline and has been extended to address applications of AI in medical imaging that include classification, image reconstruction, text analysis, and workflow optimization.The elements described here should be viewed as a ""best practice"" to guide authors in presenting their research.The text below amplifies the checklist with greater detail."
https://openalex.org/W3034344071,Human Compatible: Artificial Intelligence and the Problem of Control,"{'""In': [0], 'the': [1, 61, 68, 79, 96, 113, 130, 181, 235, 246, 249, 261], 'popular': [2], 'imagination,': [3], 'superhuman': [4, 107, 135], 'artificial': [5], 'intelligence': [6, 71], 'is': [7, 28, 255, 260], 'an': [8], 'approaching': [9], 'tidal': [10], 'wave': [11], 'that': [12, 48, 99, 161, 212, 263], 'threatens': [13], 'not': [14, 201, 256], 'just': [15, 257], 'jobs': [16], 'and': [17, 26, 32, 74, 94, 134, 195, 216], 'human': [18, 182, 239], 'relationships,': [19], 'but': [20, 54], 'civilization': [21], 'itself.': [22], 'Conflict': [23], 'between': [24], 'humans': [25, 73, 115], 'machines': [27, 173, 190, 211], 'seen': [29], 'as': [30], 'inevitable': [31], 'its': [33], 'outcome': [34], 'all': [35], 'too': [36], 'predictable.': [37], 'In': [38, 219], 'this': [39, 49], 'groundbreaking': [40], 'book,': [41], 'distinguished': [42], 'AI': [43, 59, 97, 136, 165, 232, 254], 'researcher': [44], 'Stuart': [45], 'Russell': [46, 64, 159, 227], 'argues': [47], 'scenario': [50], 'can': [51, 83, 149, 163], 'be': [52, 177, 192, 234, 245], 'avoided,': [53], 'only': [55], 'if': [56], 'we': [57, 82, 105, 138, 150, 162], 'rethink': [58], 'from': [60, 85, 122], 'ground': [62], 'up.': [63], 'begins': [65], 'by': [66], 'exploring': [67], 'idea': [69], 'of': [70, 251, 267], 'in': [72, 75, 230, 238], 'machines.': [76], 'He': [77, 109], 'describes': [78], 'near-term': [80], 'benefits': [81], 'expect,': [84], 'intelligent': [86], 'personal': [87], 'assistants': [88], 'to': [89, 102, 119, 126, 171, 176, 187, 197, 209], 'vastly': [90], 'accelerated': [91], 'scientific': [92], 'research,': [93], 'outlines': [95], 'breakthroughs': [98, 132], 'still': [100], 'have': [101, 140, 155], 'happen': [103], 'before': [104], 'reach': [106], 'AI.': [108], 'also': [110, 244], 'spells': [111], 'out': [112], 'ways': [114], 'are': [116, 174, 185, 213], 'already': [117], 'finding': [118], 'misuse': [120], 'AI,': [121], 'lethal': [123], 'autonomous': [124], 'weapons': [125], 'viral': [127], 'sabotage.': [128], 'If': [129], 'predicted': [131], 'occur': [133], 'emerges,': [137], 'will': [139], 'created': [141], 'entities': [142], 'far': [143], 'more': [144], 'powerful': [145], 'than': [146], 'ourselves.': [147], 'How': [148], 'ensure': [151], 'they': [152, 184], 'never,': [153], 'ever,': [154], 'power': [156], 'over': [157, 253], 'us?': [158], 'suggests': [160], 'rebuild': [164], 'on': [166], 'a': [167, 220, 265], 'new': [168, 204], 'foundation,': [169], 'according': [170], 'which': [172], 'designed': [175], 'inherently': [178], 'uncertain': [179], 'about': [180], 'preferences': [183], 'required': [186], 'satisfy.': [188], 'Such': [189], 'would': [191, 206, 233], 'humble,': [193], 'altruistic,': [194], 'committed': [196], 'pursue': [198], 'our': [199], 'objectives,': [200], 'theirs.': [202], 'This': [203], 'foundation': [205], 'allow': [207], 'us': [208], 'create': [210], 'provably': [214, 217], 'deferential': [215], 'beneficial.': [218], '2014': [221], 'editorial': [222], 'co-authored': [223], 'with': [224], 'Stephen': [225], 'Hawking,': [226], 'wrote,': [228], '""Success': [229], 'creating': [231], 'biggest': [236], 'event': [237], 'history.': [240], 'Unfortunately,': [241], 'it': [242, 259], 'might': [243], 'last.""': [247], 'Solving': [248], 'problem': [250], 'control': [252], 'possible;': [258], 'key': [262], 'unlocks': [264], 'future': [266], 'unlimited': [268], 'promise""--': [269]}",2019,"['Humanity', 'Dream', 'Control (management)', 'Existentialism', 'Artificial intelligence', 'Event (particle physics)', 'Computer science', 'Operations research', 'Environmental ethics', 'Political science', 'Psychology', 'Law', 'Engineering', 'Philosophy', 'Neuroscience', 'Physics', 'Quantum mechanics']","""In the popular imagination, superhuman artificial intelligence is an approaching tidal wave that threatens not just jobs and human relationships, but civilization itself. Conflict between humans and machines is seen as inevitable and its outcome all too predictable. In this groundbreaking book, distinguished AI researcher Stuart Russell argues that this scenario can be avoided, but only if we rethink AI from the ground up. Russell begins by exploring the idea of intelligence in humans and in machines. He describes the near-term benefits we can expect, from intelligent personal assistants to vastly accelerated scientific research, and outlines the AI breakthroughs that still have to happen before we reach superhuman AI. He also spells out the ways humans are already finding to misuse AI, from lethal autonomous weapons to viral sabotage. If the predicted breakthroughs occur and superhuman AI emerges, we will have created entities far more powerful than ourselves. How can we ensure they never, ever, have power over us? Russell suggests that we can rebuild AI on a new foundation, according to which machines are designed to be inherently uncertain about the human preferences they are required to satisfy. Such machines would be humble, altruistic, and committed to pursue our objectives, not theirs. This new foundation would allow us to create machines that are provably deferential and provably beneficial. In a 2014 editorial co-authored with Stephen Hawking, Russell wrote, ""Success in creating AI would be the biggest event in human history. Unfortunately, it might also be the last."" Solving the problem of control over AI is not just possible; it is the key that unlocks a future of unlimited promise""--"
https://openalex.org/W2894468641,Artificial Intelligence trends in education: a narrative overview,"{'Digital': [0], 'technologies': [1, 51], 'have': [2], 'already': [3], 'become': [4], 'an': [5], 'internal': [6], 'part': [7], 'of': [8, 41, 49, 98], 'our': [9], 'life.': [10], 'They': [11], 'change': [12], 'the': [13, 53, 90, 100], 'way': [14], 'we': [15, 21, 28, 68, 92], 'are': [16], 'looking': [17], 'for': [18], 'information,': [19], 'how': [20, 27, 99], 'communicate': [22], 'with': [23], 'each': [24], 'other,': [25], 'even': [26], 'behave.': [29], 'This': [30], 'transformation': [31], 'applies': [32], 'to': [33, 45, 52, 57], 'many': [34], 'areas,': [35], 'including': [36], 'education.': [37], 'The': [38], 'main': [39], 'objective': [40], 'this': [42], 'article': [43], 'is': [44], 'identify': [46], 'prospective': [47], 'impact': [48], 'artificial': [50], 'study': [54], 'process': [55], 'and': [56, 84], 'predict': [58], 'possible': [59, 96], 'changes': [60], 'in': [61], 'educational': [62, 73], 'landscape.': [63, 107], 'In': [64], 'presented': [65], 'literature': [66], 'review': [67], 'considered': [69], 'four': [70], 'categories:': [71], 'customized': [72], 'content,': [74], 'innovative': [75], 'teaching': [76], 'methods,': [77], 'technology': [78], 'enhanced': [79], 'assessment,': [80], 'communication': [81], 'between': [82], 'student': [83], 'lecturer.': [85], 'Having': [86], 'reviewed': [87], 'publications': [88], 'on': [89], 'subject': [91], 'present': [93], 'here': [94], 'a': [95], 'picture': [97], 'Artificial': [101], 'Intelligence': [102], '(AI)': [103], 'will': [104], 'reshape': [105], 'education': [106]}",2018,"['Computer science', 'Process (computing)', 'Narrative', 'Digital transformation', 'Subject (documents)', 'Information and Communications Technology', 'Data science', 'Artificial intelligence', 'World Wide Web', 'Linguistics', 'Operating system', 'Philosophy']","Digital technologies have already become an internal part of our life. They change the way we are looking for information, how we communicate with each other, even how we behave. This transformation applies to many areas, including education. The main objective of this article is to identify prospective impact of artificial technologies to the study process and to predict possible changes in educational landscape. In presented literature review we considered four categories: customized educational content, innovative teaching methods, technology enhanced assessment, communication between student and lecturer. Having reviewed publications on the subject we present here a possible picture of how the Artificial Intelligence (AI) will reshape education landscape."
https://openalex.org/W3182546273,Explainable artificial intelligence: an analytical review,"{'Abstract': [0], 'This': [1, 85], 'paper': [2, 33], 'provides': [3], 'a': [4, 36, 41], 'brief': [5, 37], 'analytical': [6], 'review': [7], 'of': [8, 17, 23, 50, 59, 63, 96], 'the': [9, 15, 21, 45, 54, 70], 'current': [10], 'state‐of‐the‐art': [11], 'in': [12, 20, 26, 48], 'relation': [13], 'to': [14, 69], 'explainability': [16, 51], 'artificial': [18], 'intelligence': [19], 'context': [22], 'recent': [24], 'advances': [25], 'machine': [27], 'learning': [28], 'and': [29, 40, 43, 76, 98], 'deep': [30], 'learning.': [31], 'The': [32], 'starts': [34], 'with': [35], 'historical': [38], 'introduction': [39], 'taxonomy,': [42], 'formulates': [44], 'main': [46], 'challenges': [47], 'terms': [49], 'building': [52], 'on': [53], 'recently': [55], 'formulated': [56], 'National': [57], 'Institute': [58], 'Standards': [60], 'four': [61], 'principles': [62], 'explainability.': [64], 'Recently': [65], 'published': [66], 'methods': [67], 'related': [68], 'topic': [71], 'are': [72, 83], 'then': [73], 'critically': [74], 'reviewed': [75], 'analyzed.': [77], 'Finally,': [78], 'future': [79], 'directions': [80], 'for': [81], 'research': [82], 'suggested.': [84], 'article': [86], 'is': [87], 'categorized': [88], 'under:': [89], 'Technologies': [90], '&gt;': [91, 100], 'Artificial': [92], 'Intelligence': [93], 'Fundamental': [94], 'Concepts': [95], 'Data': [97], 'Knowledge': [99], 'Explainable': [101], 'AI': [102]}",2021,"['Artificial intelligence', 'Computer science', 'Context (archaeology)', 'Taxonomy (biology)', 'Relation (database)', 'Applications of artificial intelligence', 'Management science', 'Engineering', 'Data mining', 'Botany', 'Paleontology', 'Biology']","Abstract This paper provides a brief analytical review of the current state‐of‐the‐art in relation to the explainability of artificial intelligence in the context of recent advances in machine learning and deep learning. The paper starts with a brief historical introduction and a taxonomy, and formulates the main challenges in terms of explainability building on the recently formulated National Institute of Standards four principles of explainability. Recently published methods related to the topic are then critically reviewed and analyzed. Finally, future directions for research are suggested. This article is categorized under: Technologies &gt; Artificial Intelligence Fundamental Concepts of Data and Knowledge &gt; Explainable AI"
https://openalex.org/W2583955450,Applications of artificial intelligence in intelligent manufacturing: a review,"{'Based': [0], 'on': [1, 79], 'research': [2], 'into': [3], 'the': [4, 12, 20, 27, 41, 47, 54, 80, 95, 106, 117], 'applications': [5], 'of': [6, 23, 30, 46, 56, 66, 82, 97, 119], 'artificial': [7], 'intelligence': [8], '(AI)': [9], 'technology': [10, 76, 84], 'in': [11, 15, 26, 40, 53, 109, 121, 124], 'manufacturing': [13, 48, 70, 75, 99, 111, 123], 'industry': [14], 'recent': [16], 'years,': [17], 'we': [18], 'analyze': [19], 'rapid': [21], 'development': [22, 55, 108], 'core': [24], 'technologies': [25], 'new': [28, 61], 'era': [29], ""'Internet"": [31], 'plus': [32], ""AI',"": [33], 'which': [34], 'is': [35, 112], 'triggering': [36], 'a': [37], 'great': [38], 'change': [39], 'models,': [42, 62], 'means,': [43, 63], 'and': [44, 64, 73, 89, 103], 'ecosystems': [45], 'industry,': [49, 102], 'as': [50, 52], 'well': [51], 'AI.': [57], 'We': [58], 'then': [59], 'propose': [60], 'forms': [65], 'intelligent': [67, 69, 74, 98, 110, 122], 'manufacturing,': [68, 88], 'system': [71], 'architecture,': [72], 'system,': [77], 'based': [78], 'integration': [81], 'AI': [83, 120], 'with': [85], 'information': [86], 'communications,': [87], 'related': [90], 'product': [91], 'technology.': [92], 'Moreover,': [93], 'from': [94], 'perspectives': [96], 'application': [100, 104, 118], 'technology,': [101], 'demonstration,': [105], 'current': [107], 'discussed.': [113], 'Finally,': [114], 'suggestions': [115], 'for': [116], 'China': [125], 'are': [126], 'presented.': [127]}",2017,"['Manufacturing engineering', 'Computer-integrated manufacturing', 'Manufacturing', 'Process development execution system', 'Advanced manufacturing', 'Integrated Computer-Aided Manufacturing', 'Smart manufacturing', 'Computer science', 'Industry 4.0', 'Engineering', 'Systems engineering', 'Business', 'Embedded system', 'Marketing']","Based on research into the applications of artificial intelligence (AI) technology in the manufacturing industry in recent years, we analyze the rapid development of core technologies in the new era of 'Internet plus AI', which is triggering a great change in the models, means, and ecosystems of the manufacturing industry, as well as in the development of AI. We then propose new models, means, and forms of intelligent manufacturing, intelligent manufacturing system architecture, and intelligent manufacturing technology system, based on the integration of AI technology with information communications, manufacturing, and related product technology. Moreover, from the perspectives of intelligent manufacturing application technology, industry, and application demonstration, the current development in intelligent manufacturing is discussed. Finally, suggestions for the application of AI in intelligent manufacturing in China are presented."
https://openalex.org/W3033928040,An Overview of Artificial Intelligence Applications for Power Electronics,"{'This': [0, 90], 'article': [1, 91], 'gives': [2], 'an': [3, 95], 'overview': [4], 'of': [5, 46, 49, 85], 'the': [6, 73, 83, 99], 'artificial': [7], 'intelligence': [8], '(AI)': [9], 'applications': [10, 45], 'for': [11, 87, 102], 'power': [12, 88], 'electronic': [13], 'systems.': [14], 'The': [15, 44], 'three': [16], 'distinctive': [17], 'life-cycle': [18], 'phases,': [19], 'design,': [20], 'control,': [21], 'and': [22, 40, 61, 79], 'maintenance': [23], 'are': [24, 51, 54], 'correlated': [25], 'with': [26], 'one': [27], 'or': [28], 'more': [29], 'tasks': [30], 'to': [31, 71], 'be': [32], 'addressed': [33], 'by': [34, 94], 'AI,': [35], 'including': [36], 'optimization,': [37], 'classification,': [38], 'regression,': [39], 'data': [41], 'structure': [42], 'exploration.': [43], 'four': [47], 'categories': [48], 'AI': [50, 86], 'discussed,': [52], 'which': [53], 'expert': [55], 'system,': [56], 'fuzzy': [57], 'logic,': [58], 'metaheuristic': [59], 'method,': [60], 'machine': [62], 'learning.': [63], 'More': [64], 'than': [65], '500': [66], 'publications': [67, 101], 'have': [68], 'been': [69], 'reviewed': [70], 'identify': [72], 'common': [74], 'understandings,': [75], 'practical': [76], 'implementation': [77], 'challenges,': [78], 'research': [80], 'opportunities': [81], 'in': [82], 'application': [84], 'electronics.': [89], 'is': [92], 'accompanied': [93], 'Excel': [96], 'file': [97], 'listing': [98], 'relevant': [100], 'statistical': [103], 'analytics.': [104]}",2020,"['Computer science', 'Listing (finance)', 'Artificial intelligence', 'Fuzzy logic', 'Expert system', 'Power electronics', 'Electronics', 'Machine learning', 'Analytics', 'Metaheuristic', 'Data science', 'Engineering', 'Electrical engineering', 'Economics', 'Finance', 'Voltage']","This article gives an overview of the artificial intelligence (AI) applications for power electronic systems. The three distinctive life-cycle phases, design, control, and maintenance are correlated with one or more tasks to be addressed by AI, including optimization, classification, regression, and data structure exploration. The applications of four categories of AI are discussed, which are expert system, fuzzy logic, metaheuristic method, and machine learning. More than 500 publications have been reviewed to identify the common understandings, practical implementation challenges, and research opportunities in the application of AI for power electronics. This article is accompanied by an Excel file listing the relevant publications for statistical analytics."
https://openalex.org/W2908162093,Applications of Artificial Intelligence in Transport: An Overview,"{'The': [0, 26, 44, 146, 242], 'rapid': [1, 193], 'pace': [2], 'of': [3, 17, 46, 58, 72, 75, 79, 105, 149, 155, 212, 221, 251], 'developments': [4], 'in': [5, 48, 86, 93, 195, 232, 254], 'Artificial': [6, 118, 128], 'Intelligence': [7], '(AI)': [8], 'is': [9, 52, 177], 'providing': [10], 'unprecedented': [11], 'opportunities': [12], 'to': [13, 113, 182, 186, 190, 203, 227], 'enhance': [14], 'the': [15, 23, 38, 40, 49, 56, 73, 114, 156, 172, 184, 208, 222, 247], 'performance': [16], 'different': [18], 'industries': [19], 'and': [20, 67, 81, 84, 97, 136, 141, 160, 165, 169, 206, 210, 239, 249], 'businesses,': [21], 'including': [22], 'transport': [24, 50, 115, 180], 'sector.': [25], 'innovations': [27], 'introduced': [28], 'by': [29, 245], 'AI': [30, 47, 85, 106, 150, 159, 223, 252], 'include': [31, 117], 'highly': [32], 'advanced': [33], 'computational': [34], 'methods': [35, 107], 'that': [36, 108], 'mimic': [37], 'way': [39, 112, 185], 'human': [41], 'brain': [42], 'works.': [43], 'application': [45, 148], 'field': [51, 116], 'aimed': [53], 'at': [54], 'overcoming': [55], 'challenges': [57, 248], 'an': [59, 219], 'increasing': [60], 'travel': [61, 199], 'demand,': [62], 'CO2': [63], 'emissions,': [64], 'safety': [65], 'concerns,': [66], 'environmental': [68], 'degradation.': [69], 'In': [70], 'light': [71], 'availability': [74], 'a': [76, 94, 152, 192], 'huge': [77], 'amount': [78], 'quantitative': [80], 'qualitative': [82], 'data': [83, 161], 'this': [87], 'digital': [88], 'age,': [89], 'addressing': [90, 246], 'these': [91, 188], 'concerns': [92], 'more': [95, 102, 201], 'efficient': [96], 'effective': [98], 'fashion': [99], 'has': [100], 'become': [101], 'plausible.': [103], 'Examples': [104], 'are': [109], 'finding': [110], 'their': [111, 204, 213], 'Neural': [119], 'Networks': [120], '(ANN),': [121], 'Genetic': [122], 'algorithms': [123], '(GA),': [124], 'Simulated': [125], 'Annealing': [126], '(SA),': [127], 'Immune': [129], 'system': [130, 167], '(AIS),': [131], 'Ant': [132], 'Colony': [133, 138], 'Optimiser': [134], '(ACO)': [135], 'Bee': [137], 'Optimization': [139], '(BCO)': [140], 'Fuzzy': [142], 'Logic': [143], 'Model': [144], '(FLM)': [145], 'successful': [147], 'requires': [151], 'good': [153], 'understanding': [154], 'relationships': [157], 'between': [158], 'on': [162, 171], 'one': [163], 'hand,': [164], 'transportation': [166, 229], 'characteristics': [168], 'variables': [170], 'other': [173], 'hand.': [174], 'Moreover,': [175], 'it': [176], 'promising': [178], 'for': [179], 'authorities': [181], 'determine': [183], 'use': [187], 'technologies': [189], 'create': [191], 'improvement': [194], 'relieving': [196], 'congestion,': [197], 'making': [198], 'time': [200], 'reliable': [202], 'customers': [205], 'improve': [207], 'economics': [209], 'productivity': [211], 'vital': [214], 'assets.': [215], 'This': [216], 'paper': [217], 'provides': [218], 'overview': [220, 243], 'techniques': [224], 'applied': [225], 'worldwide': [226], 'address': [228], 'problems': [230], 'mainly': [231], 'traffic': [233, 235], 'management,': [234], 'safety,': [236], 'public': [237], 'transportation,': [238], 'urban': [240], 'mobility.': [241], 'concludes': [244], 'limitations': [250], 'applications': [253], 'transport.': [255]}",2019,"['Computer science', 'Traffic congestion', 'Public transport', 'Artificial intelligence', 'Applications of artificial intelligence', 'Field (mathematics)', 'Artificial neural network', 'Pace', 'Operations research', 'Risk analysis (engineering)', 'Transport engineering', 'Engineering', 'Business', 'Geodesy', 'Geography', 'Pure mathematics', 'Mathematics']","The rapid pace of developments in Artificial Intelligence (AI) is providing unprecedented opportunities to enhance the performance of different industries and businesses, including the transport sector. The innovations introduced by AI include highly advanced computational methods that mimic the way the human brain works. The application of AI in the transport field is aimed at overcoming the challenges of an increasing travel demand, CO2 emissions, safety concerns, and environmental degradation. In light of the availability of a huge amount of quantitative and qualitative data and AI in this digital age, addressing these concerns in a more efficient and effective fashion has become more plausible. Examples of AI methods that are finding their way to the transport field include Artificial Neural Networks (ANN), Genetic algorithms (GA), Simulated Annealing (SA), Artificial Immune system (AIS), Ant Colony Optimiser (ACO) and Bee Colony Optimization (BCO) and Fuzzy Logic Model (FLM) The successful application of AI requires a good understanding of the relationships between AI and data on one hand, and transportation system characteristics and variables on the other hand. Moreover, it is promising for transport authorities to determine the way to use these technologies to create a rapid improvement in relieving congestion, making travel time more reliable to their customers and improve the economics and productivity of their vital assets. This paper provides an overview of the AI techniques applied worldwide to address transportation problems mainly in traffic management, traffic safety, public transportation, and urban mobility. The overview concludes by addressing the challenges and limitations of AI applications in transport."
https://openalex.org/W2783386352,"Artificial Intelligence, Automation and Work","{'We': [0], 'summarize': [1], 'a': [2, 59, 192], 'framework': [3, 23, 162], 'for': [4, 17, 51, 74, 103], 'the': [5, 8, 15, 25, 49, 64, 72, 88, 101, 123, 137, 153, 158, 165, 172, 175, 178, 185, 195, 202, 215], 'study': [6], 'of': [7, 10, 90, 93, 97, 125, 139, 160, 174, 198, 217], 'implications': [9], 'automation': [11, 29, 91, 113, 135, 182, 205], 'and': [12, 20, 33, 53, 87, 121, 149, 167, 177, 183, 201], 'AI': [13, 34], 'on': [14], 'demand': [16, 50, 73, 102], 'labor,': [18], 'wages,': [19], 'employment.Our': [21], 'task-based': [22], 'emphasizes': [24], 'displacement': [26, 44], 'effect': [27, 45, 80], 'that': [28, 39, 169, 204], 'creates': [30], 'as': [31], 'machines': [32], 'replace': [35], 'labor': [36, 52, 75, 126, 145, 154, 179], 'in': [37, 76, 127, 146], 'tasks': [38], 'it': [40, 55], 'used': [41], 'to': [42, 47, 151, 156, 181], 'perform.This': [43], 'tends': [46, 150], 'reduce': [48, 122], 'wages.But': [54], 'is': [56, 81, 136, 206], 'counteracted': [57], 'by': [58, 68, 83], 'productivity': [60, 79, 187], 'effect,': [61], 'resulting': [62, 186], 'from': [63, 189], 'cost': [65], 'savings': [66], 'generated': [67], 'automation,': [69], 'which': [70, 98, 143], 'increase': [71, 100, 152], 'non-automated': [77], 'tasks.The': [78], 'complemented': [82], 'additional': [84], 'capital': [85], 'accumulation': [86], 'deepening': [89], '(improvements': [92], 'existing': [94], 'machinery),': [95], 'both': [96], 'further': [99], 'labor.These': [104], 'countervailing': [105, 132], 'effects': [106], 'are': [107, 111], 'incomplete.Even': [108], 'when': [109], 'they': [110], 'strong,': [112], 'in-creases': [114], 'output': [115], 'per': [116], 'worker': [117], 'more': [118, 130], 'than': [119], 'wages': [120], 'share': [124, 155], 'national': [128], 'income.The': [129], 'powerful': [131], 'force': [133], 'against': [134], 'creation': [138], 'new': [140, 147, 199], 'labor-intensive': [141], 'tasks,': [142], 'reinstates': [144], 'activities': [148], 'counterbalance': [157], 'impact': [159], 'automation.Our': [161], 'also': [163], 'highlights': [164], 'constraints': [166], 'imperfections': [168], 'slow': [170], 'down': [171], 'adjustment': [173], 'economy': [176], 'market': [180], 'weaken': [184], 'gains': [188], 'this': [190], 'transformation:': [191], 'mismatch': [193], 'between': [194], 'skill': [196], 'requirements': [197], 'technologies,': [200], 'possibility': [203], 'being': [207], 'introduced': [208], 'at': [209, 214], 'an': [210], 'excessive': [211], 'rate,': [212], 'possibly': [213], 'expense': [216], 'other': [218], 'productivity-enhancing': [219], 'technologies.': [220]}",2018,"['Automation', 'Work (physics)', 'Computer science', 'Artificial intelligence', 'Engineering', 'Mechanical engineering']","We summarize a framework for the study of the implications of automation and AI on the demand for labor, wages, and employment.Our task-based framework emphasizes the displacement effect that automation creates as machines and AI replace labor in tasks that it used to perform.This displacement effect tends to reduce the demand for labor and wages.But it is counteracted by a productivity effect, resulting from the cost savings generated by automation, which increase the demand for labor in non-automated tasks.The productivity effect is complemented by additional capital accumulation and the deepening of automation (improvements of existing machinery), both of which further increase the demand for labor.These countervailing effects are incomplete.Even when they are strong, automation in-creases output per worker more than wages and reduce the share of labor in national income.The more powerful countervailing force against automation is the creation of new labor-intensive tasks, which reinstates labor in new activities and tends to increase the labor share to counterbalance the impact of automation.Our framework also highlights the constraints and imperfections that slow down the adjustment of the economy and the labor market to automation and weaken the resulting productivity gains from this transformation: a mismatch between the skill requirements of new technologies, and the possibility that automation is being introduced at an excessive rate, possibly at the expense of other productivity-enhancing technologies."
https://openalex.org/W3004493409,Bias in data‐driven artificial intelligence systems—An introductory survey,"{'Abstract': [0], 'Artificial': [1], 'Intelligence': [2], '(AI)‐based': [3], 'systems': [4], 'are': [5], 'widely': [6], 'employed': [7], 'nowadays': [8, 133], 'to': [9, 39, 61, 82, 105, 152, 156], 'make': [10], 'decisions': [11, 21, 168], 'that': [12, 163], 'have': [13], 'far‐reaching': [14], 'impact': [15], 'on': [16, 97, 122, 169], 'individuals': [17], 'and': [18, 26, 49, 52, 59, 100, 137, 179, 189, 199, 207], 'society.': [19], 'Their': [20], 'might': [22, 164], 'affect': [23], 'everyone,': [24], 'everywhere,': [25], 'anytime,': [27], 'entailing': [28], 'concerns': [29], 'about': [30], 'potential': [31, 71], 'human': [32], 'rights': [33], 'issues.': [34], 'Therefore,': [35], 'it': [36], 'is': [37, 81, 131, 184], 'necessary': [38], 'move': [40], 'beyond': [41], 'traditional': [42], 'AI': [43, 74, 94, 130], 'algorithms': [44], 'optimized': [45], 'for': [46], 'predictive': [47], 'performance': [48], 'embed': [50], 'ethical': [51], 'legal': [53, 115], 'principles': [54], 'in': [55, 93, 113, 166, 194], 'their': [56], 'design,': [57], 'training,': [58], 'deployment': [60], 'ensure': [62], 'social': [63], 'good': [64], 'while': [65], 'still': [66], 'benefiting': [67], 'from': [68], 'the': [69, 73, 89, 148, 157, 170], 'huge': [70], 'of': [72, 78, 88, 91, 129, 161, 172], 'technology.': [75], 'The': [76], 'goal': [77], 'this': [79, 118], 'survey': [80], 'provide': [83], 'a': [84, 114, 126], 'broad': [85], 'multidisciplinary': [86], 'overview': [87], 'area': [90], 'bias': [92, 151], 'systems,': [95], 'focusing': [96], 'technical': [98], 'challenges': [99], 'solutions': [101], 'as': [102, 104, 125, 176], 'well': [103], 'suggest': [106], 'new': [107], 'research': [108], 'directions': [109], 'towards': [110], 'approaches': [111], 'well‐grounded': [112], 'frame.': [116], 'In': [117], 'survey,': [119], 'we': [120, 146], 'focus': [121], 'data‐driven': [123], 'AI,': [124], 'large': [127], 'part': [128], 'powered': [132], 'by': [134], '(big)': [135], 'data': [136, 162], 'powerful': [138], 'machine': [139], 'learning': [140], 'algorithms.': [141], 'If': [142], 'otherwise': [143], 'not': [144], 'specified,': [145], 'use': [147], 'general': [149], 'term': [150], 'describe': [153], 'problems': [154], 'related': [155], 'gathering': [158], 'or': [159], 'processing': [160], 'result': [165], 'prejudiced': [167], 'bases': [171], 'demographic': [173], 'features': [174], 'such': [175], 'race,': [177], 'sex,': [178], 'so': [180], 'forth.': [181], 'This': [182], 'article': [183], 'categorized': [185], 'under:': [186], 'Commercial,': [187, 197, 205], 'Legal,': [188, 198, 206], 'Ethical': [190, 200, 203, 208], 'Issues': [191, 201, 209, 212], '&gt;': [192, 202, 210], 'Fairness': [193], 'Data': [195], 'Mining': [196], 'Considerations': [204], 'Legal': [211]}",2020,"['Computer science', 'Big data', 'Artificial intelligence', 'Software deployment', 'Ethical issues', 'Multidisciplinary approach', 'Data science', 'Engineering ethics', 'Political science', 'Law', 'Data mining', 'Engineering', 'Operating system']","Abstract Artificial Intelligence (AI)‐based systems are widely employed nowadays to make decisions that have far‐reaching impact on individuals and society. Their decisions might affect everyone, everywhere, and anytime, entailing concerns about potential human rights issues. Therefore, it is necessary to move beyond traditional AI algorithms optimized for predictive performance and embed ethical and legal principles in their design, training, and deployment to ensure social good while still benefiting from the huge potential of the AI technology. The goal of this survey is to provide a broad multidisciplinary overview of the area of bias in AI systems, focusing on technical challenges and solutions as well as to suggest new research directions towards approaches well‐grounded in a legal frame. In this survey, we focus on data‐driven AI, as a large part of AI is powered nowadays by (big) data and powerful machine learning algorithms. If otherwise not specified, we use the general term bias to describe problems related to the gathering or processing of data that might result in prejudiced decisions on the bases of demographic features such as race, sex, and so forth. This article is categorized under: Commercial, Legal, and Ethical Issues &gt; Fairness in Data Mining Commercial, Legal, and Ethical Issues &gt; Ethical Considerations Commercial, Legal, and Ethical Issues &gt; Legal Issues"
https://openalex.org/W3156614709,A Review of Artificial Intelligence (AI) in Education from 2010 to 2020,"{'This': [0], 'study': [1], 'provided': [2], 'a': [3, 194], 'content': [4, 69], 'analysis': [5, 70], 'of': [6, 30, 36, 58, 111, 124, 151, 156, 174, 188], 'studies': [7], 'aiming': [8], 'to': [9, 18, 66, 148, 183, 202], 'disclose': [10], 'how': [11], 'artificial': [12], 'intelligence': [13], '(AI)': [14], 'has': [15], 'been': [16], 'applied': [17], 'the': [19, 24, 52, 73, 137, 175, 185], 'education': [20, 53, 140, 179, 191], 'sector': [21], 'and': [22, 28, 45, 54, 85, 92, 95, 103, 117, 158, 164, 192, 199], 'explore': [23], 'potential': [25], 'research': [26, 56, 74, 107], 'trends': [27], 'challenges': [29, 138], 'AI': [31, 125, 145, 152, 176, 189, 200], 'in': [32, 126, 139, 190], 'education.': [33], 'A': [34], 'total': [35], '100': [37], 'papers': [38, 42, 48], 'including': [39, 109], '63': [40], 'empirical': [41], '(74': [43], 'studies)': [44], '37': [46], 'analytic': [47], 'were': [49, 128], 'selected': [50], 'from': [51, 64], 'educational': [55], 'category': [57], 'Social': [59], 'Sciences': [60], 'Citation': [61], 'Index': [62], 'database': [63], '2010': [65], '2020.': [67], 'The': [68, 167], 'showed': [71], 'that': [72], 'questions': [75], 'could': [76], 'be': [77, 142], 'classified': [78], 'into': [79, 171], 'development': [80], 'layer': [81, 89, 97], '(classification,': [82], 'matching,': [83], 'recommendation,': [84], 'deep': [86, 115], 'learning),': [87, 94], 'application': [88], '(feedback,': [90], 'reasoning,': [91], 'adaptive': [93], 'integration': [96], '(affection': [98], 'computing,': [99], 'role‐playing,': [100], 'immersive': [101], 'learning,': [102, 116], 'gamification).': [104], 'Moreover,': [105], 'four': [106], 'trends,': [108], 'Internet': [110], 'Things,': [112], 'swarm': [113], 'intelligence,': [114], 'neuroscience,': [118], 'as': [119, 121, 160, 162], 'well': [120, 161], 'an': [122, 172], 'assessment': [123], 'education,': [127], 'suggested': [129], 'for': [130, 178, 197], 'further': [131, 205], 'investigation.': [132], 'However,': [133], 'we': [134], 'also': [135], 'proposed': [136], 'may': [141], 'caused': [143], 'by': [144], 'with': [146], 'regard': [147], 'inappropriate': [149], 'use': [150], 'techniques,': [153], 'changing': [154], 'roles': [155], 'teachers': [157], 'students,': [159], 'social': [163], 'ethical': [165], 'issues.': [166], 'results': [168], 'provide': [169], 'insights': [170], 'overview': [173], 'used': [177], 'domain,': [180], 'which': [181], 'helps': [182], 'strengthen': [184], 'theoretical': [186], 'foundation': [187], 'provides': [193], 'promising': [195], 'channel': [196], 'educators': [198], 'engineers': [201], 'carry': [203], 'out': [204], 'collaborative': [206], 'research.': [207]}",2021,"['Artificial intelligence', 'Computer science', 'Applications of artificial intelligence', 'Machine learning']","This study provided a content analysis of studies aiming to disclose how artificial intelligence (AI) has been applied to the education sector and explore the potential research trends and challenges of AI in education. A total of 100 papers including 63 empirical papers (74 studies) and 37 analytic papers were selected from the education and educational research category of Social Sciences Citation Index database from 2010 to 2020. The content analysis showed that the research questions could be classified into development layer (classification, matching, recommendation, and deep learning), application layer (feedback, reasoning, and adaptive learning), and integration layer (affection computing, role‐playing, immersive learning, and gamification). Moreover, four research trends, including Internet of Things, swarm intelligence, deep learning, and neuroscience, as well as an assessment of AI in education, were suggested for further investigation. However, we also proposed the challenges in education may be caused by AI with regard to inappropriate use of AI techniques, changing roles of teachers and students, as well as social and ethical issues. The results provide insights into an overview of the AI used for education domain, which helps to strengthen the theoretical foundation of AI in education and provides a promising channel for educators and AI engineers to carry out further collaborative research."
https://openalex.org/W2753415590,"Explainable Artificial Intelligence: Understanding, Visualizing and Interpreting Deep Learning Models","{'With': [0], 'the': [1, 13, 23, 107, 158, 161, 168, 176, 181], 'availability': [2], 'of': [3, 15, 30, 35, 57, 96, 109, 150, 160, 180], 'large': [4], 'databases': [5], 'and': [6, 67, 114, 132, 170], 'recent': [7, 127], 'improvements': [8], 'in': [9, 41, 74, 104, 129, 139, 167, 178], 'deep': [10, 116, 151], 'learning': [11, 66, 117, 152], 'methodology,': [12], 'performance': [14], 'AI': [16], 'systems': [17], 'is': [18, 82], 'reaching': [19], 'or': [20, 51], 'even': [21], 'exceeding': [22], 'human': [24], 'level': [25], 'on': [26, 188], 'an': [27], 'increasing': [28, 122], 'number': [29], 'complex': [31], 'tasks.': [32, 191], 'Impressive': [33], 'examples': [34], 'this': [36, 94, 130], 'development': [37, 108], 'can': [38, 98], 'be': [39, 99], 'found': [40], 'domains': [42], 'such': [43], 'as': [44], 'image': [45], 'classification,': [46], 'sentiment': [47], 'analysis,': [48], 'speech': [49], 'understanding': [50], 'strategic': [52], 'game': [53], 'playing.': [54], 'However,': [55], 'because': [56], 'their': [58, 91], 'nested': [59], 'non-linear': [60], 'structure,': [61], 'these': [62], 'highly': [63], 'successful': [64], 'machine': [65], 'artificial': [68, 140], 'intelligence': [69], 'models': [70, 118], 'are': [71, 186], 'usually': [72], 'applied': [73], 'a': [75, 100, 134], 'black': [76], 'box': [77], 'manner,': [78], 'i.e.,': [79], 'no': [80], 'information': [81], 'provided': [83], 'about': [84], 'what': [85], 'exactly': [86], 'makes': [87, 133], 'them': [88], 'arrive': [89], 'at': [90], 'predictions.': [92], 'Since': [93], 'lack': [95], 'transparency': [97], 'major': [101], 'drawback,': [102], 'e.g.,': [103], 'medical': [105], 'applications,': [106], 'methods': [110, 185], 'for': [111, 136], 'visualizing,': [112], 'explaining': [113, 148], 'interpreting': [115], 'has': [119], 'recently': [120], 'attracted': [121], 'attention.': [123], 'This': [124], 'paper': [125], 'summarizes': [126], 'developments': [128], 'field': [131], 'plea': [135], 'more': [137], 'interpretability': [138], 'intelligence.': [141], 'Furthermore,': [142], 'it': [143], 'presents': [144], 'two': [145], 'approaches': [146], 'to': [147, 165], 'predictions': [149], 'models,': [153], 'one': [154, 171], 'method': [155], 'which': [156, 173], 'computes': [157], 'sensitivity': [159], 'prediction': [162], 'with': [163], 'respect': [164], 'changes': [166], 'input': [169, 182], 'approach': [172], 'meaningfully': [174], 'decomposes': [175], 'decision': [177], 'terms': [179], 'variables.': [183], 'These': [184], 'evaluated': [187], 'three': [189], 'classification': [190]}",2017,"['Interpretability', 'Artificial intelligence', 'Computer science', 'Deep learning', 'Machine learning', 'Field (mathematics)', 'Transparency (behavior)', 'Black box', 'Computer security', 'Pure mathematics', 'Mathematics']","With the availability of large databases and recent improvements in deep learning methodology, the performance of AI systems is reaching or even exceeding the human level on an increasing number of complex tasks. Impressive examples of this development can be found in domains such as image classification, sentiment analysis, speech understanding or strategic game playing. However, because of their nested non-linear structure, these highly successful machine learning and artificial intelligence models are usually applied in a black box manner, i.e., no information is provided about what exactly makes them arrive at their predictions. Since this lack of transparency can be a major drawback, e.g., in medical applications, the development of methods for visualizing, explaining and interpreting deep learning models has recently attracted increasing attention. This paper summarizes recent developments in this field and makes a plea for more interpretability in artificial intelligence. Furthermore, it presents two approaches to explaining predictions of deep learning models, one method which computes the sensitivity of the prediction with respect to changes in the input and one approach which meaningfully decomposes the decision in terms of the input variables. These methods are evaluated on three classification tasks."
https://openalex.org/W4360980141,Examining Science Education in ChatGPT: An Exploratory Study of Generative Artificial Intelligence,"{'Abstract': [0], 'The': [1, 16, 215], 'advent': [2], 'of': [3, 14, 98, 142, 154, 217, 233], 'generative': [4, 234], 'artificial': [5], 'intelligence': [6], '(AI)': [7], 'offers': [8], 'transformative': [9], 'potential': [10, 131], 'in': [11, 41, 52, 86, 116, 236], 'the': [12, 76, 87, 96, 102, 140, 211, 218, 231], 'field': [13], 'education.': [15, 238], 'study': [17], 'explores': [18], 'three': [19], 'main': [20], 'areas:': [21], '(1)': [22], 'How': [23, 47], 'did': [24], 'ChatGPT': [25, 40, 49, 94, 164, 195], 'answer': [26], 'questions': [27], 'related': [28, 135], 'to': [29, 74, 136, 150, 167, 190, 207, 221], 'science': [30, 43, 175, 237], 'education?': [31], '(2)': [32], 'What': [33], 'are': [34, 57], 'some': [35], 'ways': [36], 'educators': [37, 149, 173], 'could': [38], 'utilise': [39], 'their': [42, 191], 'pedagogy?': [44], 'and': [45, 55, 139, 159, 178, 187, 206], '(3)': [46], 'has': [48], 'been': [50], 'utilised': [51], 'this': [53], 'study,': [54], 'what': [56], 'my': [58], 'reflections': [59], 'about': [60, 162, 230], 'its': [61, 130], 'use': [62, 153, 232], 'as': [63, 90, 101, 198, 223], 'a': [64, 71, 107, 113, 169, 199, 224, 227], 'research': [65, 69, 200, 212], 'tool?': [66], 'This': [67], 'exploratory': [68], 'applies': [70], 'self-study': [72], 'methodology': [73], 'investigate': [75], 'technology.': [77], 'Impressively,': [78], 'ChatGPT’s': [79], 'output': [80], 'often': [81], 'aligned': [82], 'with': [83, 120, 127, 204, 209], 'key': [84], 'themes': [85], 'research.': [88], 'However,': [89], 'it': [91, 189], 'currently': [92], 'stands,': [93], 'runs': [95], 'risk': [97, 141], 'positioning': [99], 'itself': [100], 'ultimate': [103], 'epistemic': [104], 'authority,': [105], 'where': [106], 'single': [108], 'truth': [109], 'is': [110, 146, 165, 220], 'assumed': [111], 'without': [112], 'proper': [114], 'grounding': [115], 'evidence': [117], 'or': [118], 'presented': [119], 'sufficient': [121], 'qualifications.': [122], 'Key': [123], 'ethical': [124], 'concerns': [125], 'associated': [126], 'AI': [128, 235], 'include': [129], 'environmental': [132], 'impact,': [133], 'issues': [134], 'content': [137], 'moderation,': [138], 'copyright': [143], 'infringement.': [144], 'It': [145], 'important': [147], 'for': [148, 172, 202, 226], 'model': [151], 'responsible': [152], 'ChatGPT,': [155], 'prioritise': [156], 'critical': [157], 'thinking,': [158], 'be': [160, 168], 'clear': [161], 'expectations.': [163], 'likely': [166], 'useful': [170], 'tool': [171, 201], 'designing': [174], 'units,': [176], 'rubrics,': [177], 'quizzes.': [179], 'Educators': [180], 'should': [181], 'critically': [182], 'evaluate': [183], 'any': [184], 'AI-generated': [185], 'resource': [186], 'adapt': [188], 'specific': [192], 'teaching': [193], 'contexts.': [194], 'was': [196], 'used': [197], 'assistance': [203], 'editing': [205], 'experiment': [208], 'making': [210], 'narrative': [213], 'clearer.': [214], 'intention': [216], 'paper': [219], 'act': [222], 'catalyst': [225], 'broader': [228], 'conversation': [229]}",2023,"['Transformative learning', 'Science education', 'Rubric', 'Engineering ethics', 'Narrative', 'Generative grammar', 'Computer science', 'Sociology', 'Psychology', 'Pedagogy', 'Artificial intelligence', 'Engineering', 'Philosophy', 'Linguistics']","Abstract The advent of generative artificial intelligence (AI) offers transformative potential in the field of education. The study explores three main areas: (1) How did ChatGPT answer questions related to science education? (2) What are some ways educators could utilise ChatGPT in their science pedagogy? and (3) How has ChatGPT been utilised in this study, and what are my reflections about its use as a research tool? This exploratory research applies a self-study methodology to investigate the technology. Impressively, ChatGPT’s output often aligned with key themes in the research. However, as it currently stands, ChatGPT runs the risk of positioning itself as the ultimate epistemic authority, where a single truth is assumed without a proper grounding in evidence or presented with sufficient qualifications. Key ethical concerns associated with AI include its potential environmental impact, issues related to content moderation, and the risk of copyright infringement. It is important for educators to model responsible use of ChatGPT, prioritise critical thinking, and be clear about expectations. ChatGPT is likely to be a useful tool for educators designing science units, rubrics, and quizzes. Educators should critically evaluate any AI-generated resource and adapt it to their specific teaching contexts. ChatGPT was used as a research tool for assistance with editing and to experiment with making the research narrative clearer. The intention of the paper is to act as a catalyst for a broader conversation about the use of generative AI in science education."
https://openalex.org/W4322008312,Can artificial intelligence help for scientific writing?,"{'Abstract': [0], 'This': [1], 'paper': [2], 'discusses': [3], 'the': [4, 24, 72, 89, 105, 133, 154, 167], 'use': [5, 168], 'of': [6, 17, 74, 135, 169], 'Artificial': [7], 'Intelligence': [8], 'Chatbot': [9], 'in': [10, 43, 50, 57, 65, 71, 88, 116, 145, 171], 'scientific': [11, 51, 172], 'writing.': [12], 'ChatGPT': [13, 42, 92], 'is': [14, 68], 'a': [15, 86, 99, 142, 161], 'type': [16], 'chatbot,': [18], 'developed': [19], 'by': [20, 111], 'OpenAI,': [21], 'that': [22], 'uses': [23], 'Generative': [25], 'Pre-trained': [26], 'Transformer': [27], '(GPT)': [28], 'language': [29, 37], 'model': [30], 'to': [31, 35, 46, 165], 'understand': [32], 'and': [33, 41, 55, 104, 137, 150], 'respond': [34], 'natural': [36], 'inputs.': [38], 'AI': [39], 'chatbot': [40], 'particular': [44], 'appear': [45], 'be': [47, 85, 96, 109, 176], 'useful': [48], 'tools': [49], 'writing,': [52], 'assisting': [53], 'researchers': [54], 'scientists': [56], 'organizing': [58], 'material,': [59], 'generating': [60], 'an': [61], 'initial': [62], 'draft': [63], 'and/or': [64], 'proofreading.': [66], 'There': [67], 'no': [69], 'publication': [70], 'field': [73], 'critical': [75, 118], 'care': [76], 'medicine': [77], 'prepared': [78], 'using': [79, 128], 'this': [80, 83, 159], 'approach;': [81], 'however,': [82], 'will': [84, 174], 'possibility': [87], 'next': [90], 'future.': [91], 'work': [93], 'should': [94, 107], 'not': [95], 'used': [97, 115], 'as': [98, 132, 139, 141], 'replacement': [100], 'for': [101], 'human': [102], 'judgment': [103], 'output': [106], 'always': [108], 'reviewed': [110], 'experts': [112], 'before': [113], 'being': [114], 'any': [117], 'decision-making': [119], 'or': [120], 'application.': [121], 'Moreover,': [122], 'several': [123], 'ethical': [124], 'issues': [125], 'arise': [126], 'about': [127], 'these': [129], 'tools,': [130], 'such': [131], 'risk': [134], 'plagiarism': [136], 'inaccuracies,': [138], 'well': [140], 'potential': [143], 'imbalance': [144], 'its': [146], 'accessibility': [147], 'between': [148], 'high-': [149], 'low-income': [151], 'countries,': [152], 'if': [153], 'software': [155], 'becomes': [156], 'paying.': [157], 'For': [158], 'reason,': [160], 'consensus': [162], 'on': [163], 'how': [164], 'regulate': [166], 'chatbots': [170], 'writing': [173], 'soon': [175], 'required.': [177]}",2023,"['Chatbot', 'Generative grammar', 'Engineering ethics', 'Computer science', 'Scientific writing', 'Transformer', 'Data science', 'Artificial intelligence', 'Engineering', 'Linguistics', 'Electrical engineering', 'Philosophy', 'Voltage']","Abstract This paper discusses the use of Artificial Intelligence Chatbot in scientific writing. ChatGPT is a type of chatbot, developed by OpenAI, that uses the Generative Pre-trained Transformer (GPT) language model to understand and respond to natural language inputs. AI chatbot and ChatGPT in particular appear to be useful tools in scientific writing, assisting researchers and scientists in organizing material, generating an initial draft and/or in proofreading. There is no publication in the field of critical care medicine prepared using this approach; however, this will be a possibility in the next future. ChatGPT work should not be used as a replacement for human judgment and the output should always be reviewed by experts before being used in any critical decision-making or application. Moreover, several ethical issues arise about using these tools, such as the risk of plagiarism and inaccuracies, as well as a potential imbalance in its accessibility between high- and low-income countries, if the software becomes paying. For this reason, a consensus on how to regulate the use of chatbots in scientific writing will soon be required."
https://openalex.org/W3195625625,Artificial Intelligence and Business Value: a Literature Review,"{'Abstract': [0], 'Artificial': [1], 'Intelligence': [2], '(AI)': [3], 'are': [4, 28, 53], 'a': [5, 40, 45, 67, 87, 93, 167], 'wide-ranging': [6], 'set': [7], 'of': [8, 42, 66, 70, 80, 129, 137, 151, 159], 'technologies': [9, 73, 106], 'that': [10, 97, 170, 173], 'promise': [11], 'several': [12], 'advantages': [13], 'for': [14], 'organizations': [15, 27, 52, 102], 'in': [16, 33, 48, 61, 107, 140, 162], 'terms': [17], 'off': [18], 'added': [19], 'business': [20, 37, 75, 81], 'value.': [21], 'Over': [22], 'the': [23, 112, 118, 124, 135, 141, 146, 160, 163], 'past': [24], 'few': [25], 'years,': [26], 'increasingly': [29], 'turning': [30], 'to': [31, 35, 56, 99, 175], 'AI': [32, 60, 72, 105, 130, 138], 'order': [34], 'gain': [36], 'value': [38, 82], 'following': [39], 'deluge': [41], 'data': [43], 'and': [44, 58, 77, 110, 121, 127, 132, 144, 148, 165], 'strong': [46], 'increase': [47], 'computational': [49], 'capacity.': [50], 'Nevertheless,': [51], 'still': [54], 'struggling': [55], 'adopt': [57], 'leverage': [59, 104], 'their': [62, 108], 'operations.': [63], 'The': [64, 153], 'lack': [65], 'coherent': [68], 'understanding': [69], 'how': [71, 101], 'create': [74], 'value,': [76], 'what': [78], 'type': [79], 'is': [83], 'expected,': [84], 'therefore': [85], 'necessitates': [86], 'holistic': [88], 'understanding.': [89], 'This': [90], 'study': [91], 'provides': [92], 'systematic': [94], 'literature': [95, 120, 164], 'review': [96], 'attempts': [98], 'explain': [100], 'can': [103], 'operations': [109], 'elucidate': [111], 'value-generating': [113], 'mechanisms.': [114], 'Our': [115], 'analysis': [116], 'synthesizes': [117], 'current': [119], 'highlights:': [122], '(1)': [123], 'key': [125], 'enablers': [126], 'inhibitors': [128], 'adoption': [131], 'use;': [133], '(2)': [134], 'typologies': [136], 'use': [139], 'organizational': [142], 'setting;': [143], '(3)': [145], 'first-': [147], 'second-order': [149], 'effects': [150], 'AI.': [152], 'paper': [154], 'concludes': [155], 'with': [156], 'an': [157], 'identification': [158], 'gaps': [161], 'develops': [166], 'research': [168], 'agenda': [169], 'identifies': [171], 'areas': [172], 'need': [174], 'be': [176], 'addressed': [177], 'by': [178], 'future': [179], 'studies.': [180]}",2021,"['Leverage (statistics)', 'Knowledge management', 'Business value', 'Business intelligence', 'Value (mathematics)', 'Computer science', 'Ambidexterity', 'Order (exchange)', 'Value creation', 'Data science', 'Management science', 'Business', 'Artificial intelligence', 'Engineering', 'Economics', 'Machine learning', 'Human capital', 'Finance', 'Economic growth']","Abstract Artificial Intelligence (AI) are a wide-ranging set of technologies that promise several advantages for organizations in terms off added business value. Over the past few years, organizations are increasingly turning to AI in order to gain business value following a deluge of data and a strong increase in computational capacity. Nevertheless, organizations are still struggling to adopt and leverage AI in their operations. The lack of a coherent understanding of how AI technologies create business value, and what type of business value is expected, therefore necessitates a holistic understanding. This study provides a systematic literature review that attempts to explain how organizations can leverage AI technologies in their operations and elucidate the value-generating mechanisms. Our analysis synthesizes the current literature and highlights: (1) the key enablers and inhibitors of AI adoption and use; (2) the typologies of AI use in the organizational setting; and (3) the first- and second-order effects of AI. The paper concludes with an identification of the gaps in the literature and develops a research agenda that identifies areas that need to be addressed by future studies."
https://openalex.org/W4379470483,A Review of the Role of Artificial Intelligence in Healthcare,"{'Artificial': [0], 'intelligence': [1], '(AI)': [2], 'applications': [3, 165], 'have': [4], 'transformed': [5], 'healthcare.': [6, 160], 'This': [7], 'study': [8], 'is': [9, 61, 166, 188], 'based': [10], 'on': [11, 25], 'a': [12, 189, 220], 'general': [13], 'literature': [14], 'review': [15], 'uncovering': [16], 'the': [17, 26, 74, 101, 105, 143, 201, 210, 214], 'role': [18], 'of': [19, 59, 76, 108, 163, 205, 216], 'AI': [20, 60, 158, 164, 217], 'in': [21, 63, 67, 178, 222], 'healthcare': [22, 109, 236], 'and': [23, 33, 42, 48, 52, 70, 98, 115, 124, 126, 137, 147, 151, 154, 171, 173, 181, 196, 203, 224], 'focuses': [24], 'following': [27], 'key': [28], 'aspects:': [29], '(i)': [30], 'medical': [31, 40, 68, 118], 'imaging': [32, 69], 'diagnostics,': [34], '(ii)': [35], 'virtual': [36, 85], 'patient': [37, 46, 86, 96, 169], 'care,': [38], '(iii)': [39], 'research': [41], 'drug': [43], 'discovery,': [44], '(iv)': [45], 'engagement': [47, 97], 'compliance,': [49], '(v)': [50], 'rehabilitation,': [51], '(vi)': [53], 'other': [54], 'administrative': [55, 106], 'applications.': [56], 'The': [57, 161], 'impact': [58], 'observed': [62], 'detecting': [64], 'clinical': [65], 'conditions': [66], 'diagnostic': [71], 'services,': [72], 'controlling': [73], 'outbreak': [75], 'coronavirus': [77], 'disease': [78], '2019': [79], '(COVID-19)': [80], 'with': [81, 100], 'early': [82], 'diagnosis,': [83], 'providing': [84], 'care': [87], 'using': [88], 'AI-powered': [89], 'tools,': [90], 'managing': [91], 'electronic': [92], 'health': [93, 184, 212], 'records,': [94], 'augmenting': [95], 'compliance': [99], 'treatment': [102], 'plan,': [103], 'reducing': [104], 'workload': [107], 'professionals': [110], '(HCPs),': [111], 'discovering': [112], 'new': [113], 'drugs': [114], 'vaccines,': [116], 'spotting': [117], 'prescription': [119], 'errors,': [120], 'extensive': [121], 'data': [122], 'storage': [123], 'analysis,': [125], 'technology-assisted': [127], 'rehabilitation.': [128], 'Nevertheless,': [129], 'this': [130], 'science': [131], 'pitch': [132], 'meets': [133], 'several': [134], 'technical,': [135], 'ethical,': [136, 195], 'social': [138], 'challenges,': [139], 'including': [140], 'privacy,': [141], 'safety,': [142], 'right': [144], 'to': [145, 191, 233], 'decide': [146], 'try,': [148], 'costs,': [149], 'information': [150], 'consent,': [152], 'access,': [153], 'efficacy,': [155], 'while': [156, 199], 'integrating': [157], 'into': [159], 'governance': [162, 187], 'crucial': [167], 'for': [168, 174], 'safety': [170], 'accountability': [172], 'raising': [175], 'HCPs’': [176], 'belief': [177], 'enhancing': [179], 'acceptance': [180, 202], 'boosting': [182], 'significant': [183], 'consequences.': [185], 'Effective': [186], 'prerequisite': [190], 'precisely': [192], 'address': [193], 'regulatory,': [194], 'trust': [197], 'issues': [198], 'advancing': [200], 'implementation': [204], 'AI.': [206], 'Since': [207], 'COVID-19': [208], 'hit': [209], 'global': [211], 'system,': [213], 'concept': [215], 'has': [218], 'created': [219], 'revolution': [221], 'healthcare,': [223], 'such': [225], 'an': [226], 'uprising': [227], 'could': [228], 'be': [229], 'another': [230], 'step': [231], 'forward': [232], 'meet': [234], 'future': [235], 'needs.': [237]}",2023,"['Health care', 'Corporate governance', 'Medicine', 'Accountability', 'Knowledge management', 'Business', 'Computer science', 'Political science', 'Finance', 'Law']","Artificial intelligence (AI) applications have transformed healthcare. This study is based on a general literature review uncovering the role of AI in healthcare and focuses on the following key aspects: (i) medical imaging and diagnostics, (ii) virtual patient care, (iii) medical research and drug discovery, (iv) patient engagement and compliance, (v) rehabilitation, and (vi) other administrative applications. The impact of AI is observed in detecting clinical conditions in medical imaging and diagnostic services, controlling the outbreak of coronavirus disease 2019 (COVID-19) with early diagnosis, providing virtual patient care using AI-powered tools, managing electronic health records, augmenting patient engagement and compliance with the treatment plan, reducing the administrative workload of healthcare professionals (HCPs), discovering new drugs and vaccines, spotting medical prescription errors, extensive data storage and analysis, and technology-assisted rehabilitation. Nevertheless, this science pitch meets several technical, ethical, and social challenges, including privacy, safety, the right to decide and try, costs, information and consent, access, and efficacy, while integrating AI into healthcare. The governance of AI applications is crucial for patient safety and accountability and for raising HCPs’ belief in enhancing acceptance and boosting significant health consequences. Effective governance is a prerequisite to precisely address regulatory, ethical, and trust issues while advancing the acceptance and implementation of AI. Since COVID-19 hit the global health system, the concept of AI has created a revolution in healthcare, and such an uprising could be another step forward to meet future healthcare needs."
https://openalex.org/W3011186445,Innovation and Design in the Age of Artificial Intelligence,"{'At': [0], 'the': [1, 11, 62, 65, 70, 124, 129, 135, 179, 206, 224, 248, 251, 268, 293, 308, 347, 359, 367, 409, 432], 'heart': [2], 'of': [3, 23, 64, 72, 75, 80, 131, 160, 193, 208, 215, 226, 242, 250, 295, 310, 326, 362, 369, 388, 434], 'any': [4], 'innovation': [5, 24, 36, 66, 127, 140, 229, 440], 'process': [6], 'lies': [7], 'a': [8, 120, 400, 405, 414], 'fundamental': [9], 'practice:': [10], 'way': [12, 403], 'people': [13], 'create': [14, 107], 'ideas': [15], 'and': [16, 28, 59, 82, 126, 139, 182, 200, 210, 217, 228, 259, 265, 271, 302, 338, 390, 439, 443], 'solve': [17], 'problems.': [18], 'This': [19, 117, 173, 429], '“decision': [20], 'making”': [21], 'side': [22], 'is': [25, 149], 'what': [26, 99], 'scholars': [27, 442], 'practitioners': [29], 'refer': [30], 'to': [31, 61, 92, 186, 220, 237, 263, 282, 322], 'as': [32, 146], '“design.”': [33], 'Decisions': [34], 'in': [35, 109, 128, 175, 230, 395, 399], 'processes': [37], 'have': [38], 'so': [39], 'far': [40], 'been': [41], 'taken': [42], 'by': [43, 52, 152, 246, 376], 'humans.': [44], 'What': [45, 68], 'happens': [46], 'when': [47], 'they': [48], 'can': [49], 'be': [50, 171], 'substituted': [51], 'machines?': [53], 'Artificial': [54], 'Intelligence': [55], '(AI)': [56], 'brings': [57, 183], 'data': [58], 'algorithms': [60, 393], 'core': [63], 'processes.': [67], 'are': [69, 197, 313, 334, 340, 378, 426], 'implications': [71, 136, 433], 'this': [73], 'diffusion': [74], 'AI': [76, 85, 233, 279, 290, 306, 355], 'for': [77, 122, 137, 178, 223, 329, 437], 'our': [78], 'understanding': [79, 123, 165], 'design': [81, 110, 125, 138, 155, 184, 227, 244, 287, 438], 'innovation?': [83], 'Is': [84], 'just': [86], 'another': [87], 'digital': [88], 'technology': [89], 'that,': [90, 145], 'akin': [91], 'many': [93, 239], 'others,': [94], 'will': [95, 105], 'not': [96, 357], 'significantly': [97, 150], 'question': [98], 'we': [100, 143], 'know': [101], 'about': [102], 'design?': [103], 'Or': [104], 'it': [106, 364], 'transformations': [108], 'that': [111, 163, 312, 333, 339, 384], 'current': [112], 'theoretical': [113], 'frameworks': [114], 'cannot': [115], 'capture?': [116], 'paper': [118, 430], 'proposes': [119], 'framework': [121], 'age': [130], 'AI.': [132], 'We': [133], 'discuss': [134], 'theory.': [141], 'Specifically,': [142], 'observe': [144], 'creative': [147], 'problem‐solving': [148], 'conducted': [151], 'algorithms,': [153], 'human': [154], 'increasingly': [156], 'becomes': [157], 'an': [158, 191, 235, 323], 'activity': [159, 192], 'sensemaking': [161], ',': [162], 'is,': [164, 189], 'which': [166, 188, 425], 'problems': [167, 411], 'should': [168], 'or': [169], 'could': [170], 'addressed.': [172], 'shift': [174], 'focus': [176], 'calls': [177], 'new': [180], 'theories': [181], 'closer': [185], 'leadership,': [187], 'inherently,': [190], 'sensemaking.': [194], 'Our': [195], 'insights': [196, 436], 'derived': [198], 'from': [199], 'illustrated': [201], 'with': [202, 213, 413], 'two': [203, 221], 'cases': [204], 'at': [205], 'frontier': [207], 'AI—Netflix': [209], 'Airbnb': [211], '(complemented': [212], 'analyses': [214], 'Microsoft': [216], 'Tesla)—which': [218], 'point': [219], 'directions': [222], 'evolution': [225], 'firms.': [231], 'First,': [232], 'enables': [234, 307], 'organization': [236], 'overcome': [238], 'past': [240], 'limitations': [241, 387], 'human‐intensive': [243], 'processes,': [245], 'improving': [247], 'scalability': [249], 'process,': [252], 'broadening': [253], 'its': [254, 261], 'scope': [255], 'across': [256, 346], 'traditional': [257], 'boundaries,': [258], 'enhancing': [260], 'ability': [262], 'learn': [264], 'adapt': [266], 'on': [267], 'fly.': [269], 'Second,': [270], 'maybe': [272], 'more': [273, 314, 336], 'surprising,': [274], 'while': [275, 354], 'removing': [276], 'these': [277, 396, 435], 'limitations,': [278], 'also': [280], 'appears': [281], 'deeply': [283], 'enact': [284], 'several': [285], 'popular': [286], 'principles': [288, 294, 361], '.': [289], 'thus': [291], 'reinforces': [292], 'Design': [296], 'Thinking,': [297], 'namely:': [298], 'being': [299], 'people‐centered,': [300], 'abductive,': [301], 'iterative.': [303], 'In': [304, 352], 'fact,': [305], 'creation': [309], 'solutions': [311], 'highly': [315], 'user': [316], 'centered': [317], 'than': [318, 404], 'human‐based': [319], 'approaches': [320], '(i.e.,': [321], 'extreme': [324], 'level': [325], 'granularity,': [327], 'designed': [328], 'every': [330], 'single': [331], 'person);': [332], 'potentially': [335], 'creative;': [337], 'continuously': [341], 'updated': [342], 'through': [343, 421], 'learning': [344, 382], 'iterations': [345], 'entire': [348], 'product': [349], 'life': [350], 'cycle.': [351], 'sum,': [353], 'does': [356], 'undermine': [358], 'basic': [360], 'design,': [363], 'profoundly': [365], 'changes': [366], 'practice': [368], 'design.': [370], 'Problem‐solving': [371], 'tasks,': [372, 424], 'traditionally': [373], 'carried': [374], 'out': [375], 'designers,': [377], 'now': [379], 'automated': [380], 'into': [381], 'loops': [383, 397], 'operate': [385], 'without': [386], 'volume': [389], 'speed.': [391], 'The': [392], 'embedded': [394], 'think': [398], 'radically': [401], 'different': [402], 'designer': [406], 'who': [407], 'handles': [408], 'complex': [410], 'holistically': [412], 'systemic': [415], 'perspective.': [416], 'Algorithms': [417], 'instead': [418], 'handle': [419], 'complexity': [420], 'very': [422], 'simple': [423], 'iterated': [427], 'continuously.': [428], 'discusses': [431], 'management': [441], 'practitioners.': [444]}",2020,"['Sensemaking', 'Computer science', 'Knowledge management', 'Process (computing)', 'Data science', 'Management science', 'Artificial intelligence', 'Engineering', 'Operating system']","At the heart of any innovation process lies a fundamental practice: the way people create ideas and solve problems. This “decision making” side of innovation is what scholars and practitioners refer to as “design.” Decisions in innovation processes have so far been taken by humans. What happens when they can be substituted by machines? Artificial Intelligence (AI) brings data and algorithms to the core of the innovation processes. What are the implications of this diffusion of AI for our understanding of design and innovation? Is AI just another digital technology that, akin to many others, will not significantly question what we know about design? Or will it create transformations in design that current theoretical frameworks cannot capture? This paper proposes a framework for understanding the design and innovation in the age of AI. We discuss the implications for design and innovation theory. Specifically, we observe that, as creative problem‐solving is significantly conducted by algorithms, human design increasingly becomes an activity of sensemaking , that is, understanding which problems should or could be addressed. This shift in focus calls for the new theories and brings design closer to leadership, which is, inherently, an activity of sensemaking. Our insights are derived from and illustrated with two cases at the frontier of AI—Netflix and Airbnb (complemented with analyses of Microsoft and Tesla)—which point to two directions for the evolution of design and innovation in firms. First, AI enables an organization to overcome many past limitations of human‐intensive design processes, by improving the scalability of the process, broadening its scope across traditional boundaries, and enhancing its ability to learn and adapt on the fly. Second, and maybe more surprising, while removing these limitations, AI also appears to deeply enact several popular design principles . AI thus reinforces the principles of Design Thinking, namely: being people‐centered, abductive, and iterative. In fact, AI enables the creation of solutions that are more highly user centered than human‐based approaches (i.e., to an extreme level of granularity, designed for every single person); that are potentially more creative; and that are continuously updated through learning iterations across the entire product life cycle. In sum, while AI does not undermine the basic principles of design, it profoundly changes the practice of design. Problem‐solving tasks, traditionally carried out by designers, are now automated into learning loops that operate without limitations of volume and speed. The algorithms embedded in these loops think in a radically different way than a designer who handles the complex problems holistically with a systemic perspective. Algorithms instead handle complexity through very simple tasks, which are iterated continuously. This paper discusses the implications of these insights for design and innovation management scholars and practitioners."
https://openalex.org/W3005335661,Artificial Intelligence in Medicine: Today and Tomorrow,"{'Artificial': [0], 'intelligence-powered': [1], 'medical': [2, 73, 136, 187], 'technologies': [3], 'are': [4], 'rapidly': [5], 'evolving': [6], 'into': [7], 'applicable': [8], 'solutions': [9], 'for': [10, 87, 108], 'clinical': [11, 43, 113, 128, 181], 'practice.': [12, 114], 'Deep': [13], 'learning': [14], 'algorithms': [15], 'can': [16], 'deal': [17], 'with': [18, 100, 126], 'increasing': [19], 'amounts': [20], 'of': [21, 35, 49, 56, 66, 77, 112, 134, 140, 148, 155, 175], 'data': [22], 'provided': [23], 'by': [24, 82], 'wearables,': [25], 'smartphones,': [26], 'and': [27, 61, 91, 164, 173, 189], 'other': [28], 'mobile': [29], 'monitoring': [30], 'sensors': [31], 'in': [32, 42, 138, 180], 'different': [33], 'areas': [34], 'medicine.': [36], 'Currently,': [37], 'only': [38], 'very': [39], 'specific': [40], 'settings': [41], 'practice': [44, 182], 'benefit': [45], 'from': [46, 102], 'the': [47, 54, 64, 119, 131, 135, 149, 169], 'application': [48], 'artificial': [50, 177], 'intelligence,': [51], 'such': [52, 109], 'as': [53, 143, 145], 'detection': [55], 'atrial': [57], 'fibrillation,': [58], 'epilepsy': [59], 'seizures,': [60], 'hypoglycemia,': [62], 'or': [63, 72], 'diagnosis': [65], 'disease': [67], 'based': [68], 'on': [69, 168, 183], 'histopathological': [70], 'examination': [71], 'imaging.': [74], 'The': [75, 153], 'implementation': [76], 'augmented': [78], 'medicine': [79, 142], 'is': [80, 98, 158], 'long-awaited': [81], 'patients': [83], 'because': [84], 'it': [85, 97], 'allows': [86], 'a': [88, 92, 166], 'greater': [89], 'autonomy': [90], 'more': [93], 'personalized': [94], 'treatment,': [95], 'however,': [96], 'met': [99], 'resistance': [101], 'physicians': [103], 'which': [104], 'were': [105], 'not': [106], 'prepared': [107], 'an': [110], 'evolution': [111], 'This': [115], 'phenomenon': [116], 'also': [117], 'creates': [118], 'need': [120], 'to': [121, 159], 'validate': [122], 'these': [123], 'modern': [124], 'tools': [125], 'traditional': [127], 'trials,': [129], 'debate': [130], 'educational': [132], 'upgrade': [133], 'curriculum': [137], 'light': [139], 'digital': [141], 'well': [144], 'ethical': [146], 'consideration': [147], 'ongoing': [150], 'connected': [151], 'monitoring.': [152], 'aim': [154], 'this': [156], 'paper': [157], 'discuss': [160], 'recent': [161], 'scientific': [162], 'literature': [163], 'provide': [165], 'perspective': [167], 'benefits,': [170], 'future': [171], 'opportunities': [172], 'risks': [174], 'established': [176], 'intelligence': [178], 'applications': [179], 'physicians,': [184], 'healthcare': [185], 'institutions,': [186], 'education,': [188], 'bioethics.': [190]}",2020,"['Clinical Practice', 'Curriculum', 'Autonomy', 'Bioethics', 'Health care', 'Medicine', 'Engineering ethics', 'Medical education', 'Artificial intelligence', 'Computer science', 'Psychology', 'Engineering', 'Nursing', 'Political science', 'Law', 'Pedagogy']","Artificial intelligence-powered medical technologies are rapidly evolving into applicable solutions for clinical practice. Deep learning algorithms can deal with increasing amounts of data provided by wearables, smartphones, and other mobile monitoring sensors in different areas of medicine. Currently, only very specific settings in clinical practice benefit from the application of artificial intelligence, such as the detection of atrial fibrillation, epilepsy seizures, and hypoglycemia, or the diagnosis of disease based on histopathological examination or medical imaging. The implementation of augmented medicine is long-awaited by patients because it allows for a greater autonomy and a more personalized treatment, however, it is met with resistance from physicians which were not prepared for such an evolution of clinical practice. This phenomenon also creates the need to validate these modern tools with traditional clinical trials, debate the educational upgrade of the medical curriculum in light of digital medicine as well as ethical consideration of the ongoing connected monitoring. The aim of this paper is to discuss recent scientific literature and provide a perspective on the benefits, future opportunities and risks of established artificial intelligence applications in clinical practice on physicians, healthcare institutions, medical education, and bioethics."
https://openalex.org/W4225597912,On evaluation metrics for medical applications of artificial intelligence,"{'Abstract': [0], 'Clinicians': [1], 'and': [2, 64, 104, 144], 'software': [3], 'developers': [4], 'need': [5], 'to': [6, 37, 68, 128], 'understand': [7], 'how': [8, 110], 'proposed': [9], 'machine': [10], 'learning': [11], '(ML)': [12], 'models': [13, 55, 70], 'could': [14], 'improve': [15], 'patient': [16], 'care.': [17], 'No': [18], 'single': [19], 'metric': [20], 'captures': [21], 'all': [22], 'the': [23, 72, 95, 101, 132], 'desirable': [24], 'properties': [25], 'of': [26, 54, 89, 97, 109], 'a': [27, 39, 106], 'model,': [28], 'which': [29], 'is': [30, 62], 'why': [31], 'several': [32], 'metrics': [33, 92, 112, 135], 'are': [34, 45], 'typically': [35], 'reported': [36], 'summarize': [38], 'model’s': [40], 'performance.': [41], 'Unfortunately,': [42], 'these': [43], 'measures': [44], 'not': [46], 'easily': [47, 147], 'understandable': [48], 'by': [49], 'many': [50], 'clinicians.': [51], 'Moreover,': [52], 'comparison': [53], 'across': [56], 'studies': [57, 82], 'in': [58, 84, 94, 100, 130, 137], 'an': [59, 87, 119], 'objective': [60], 'manner': [61], 'challenging,': [63], 'no': [65], 'tool': [66, 123], 'exists': [67], 'compare': [69], 'using': [71], 'same': [73], 'performance': [74], 'metrics.': [75], 'This': [76], 'paper': [77, 139], 'looks': [78], 'at': [79], 'previous': [80], 'ML': [81], 'done': [83], 'gastroenterology,': [85], 'provides': [86], 'explanation': [88, 108], 'what': [90], 'different': [91, 111], 'mean': [93], 'context': [96], 'binary': [98], 'classification': [99], 'presented': [102, 136], 'studies,': [103], 'gives': [105], 'thorough': [107], 'should': [113], 'be': [114, 126], 'interpreted.': [115], 'We': [116], 'also': [117], 'release': [118], 'open': [120], 'source': [121], 'web-based': [122], 'that': [124, 141], 'may': [125, 146], 'used': [127], 'aid': [129], 'calculating': [131], 'most': [133], 'relevant': [134], 'this': [138], 'so': [140], 'other': [142], 'researchers': [143], 'clinicians': [145], 'incorporate': [148], 'them': [149], 'into': [150], 'their': [151], 'research.': [152]}",2022,"['Computer science', 'Metric (unit)', 'Context (archaeology)', 'Machine learning', 'Data science', 'Software', 'Data mining', 'Binary classification', 'Open source', 'Artificial intelligence', 'Information retrieval', 'Support vector machine', 'Paleontology', 'Operations management', 'Biology', 'Programming language', 'Economics']","Abstract Clinicians and software developers need to understand how proposed machine learning (ML) models could improve patient care. No single metric captures all the desirable properties of a model, which is why several metrics are typically reported to summarize a model’s performance. Unfortunately, these measures are not easily understandable by many clinicians. Moreover, comparison of models across studies in an objective manner is challenging, and no tool exists to compare models using the same performance metrics. This paper looks at previous ML studies done in gastroenterology, provides an explanation of what different metrics mean in the context of binary classification in the presented studies, and gives a thorough explanation of how different metrics should be interpreted. We also release an open source web-based tool that may be used to aid in calculating the most relevant metrics presented in this paper so that other researchers and clinicians may easily incorporate them into their research."
https://openalex.org/W4226065182,Explainable Artificial Intelligence (XAI),"{'Complex': [0], 'machine': [1, 73], 'learning': [2, 74], 'models': [3, 10], 'perform': [4], 'better.': [5], 'However,': [6], 'we': [7, 161], 'consider': [8, 134], 'these': [9], 'as': [11, 32, 34], 'black': [12], 'boxes.': [13], 'That’s': [14], 'where': [15], 'Explainable': [16], 'AI': [17, 52], '(XAI)': [18], 'comes': [19], 'into': [20], 'play.': [21], 'Understanding': [22], 'why': [23], 'a': [24, 27, 104, 141, 146, 149, 167], 'model': [25], 'makes': [26], 'specific': [28, 163], 'prediction': [29, 106, 147], 'can': [30, 107], 'be': [31], 'crucial': [33], 'its': [35], 'accuracy': [36], 'for': [37, 116, 172], 'many': [38, 44, 101], 'applications,': [39, 46], 'researchers,': [40], 'and': [41, 49, 59, 67, 93, 103, 156], 'decision-makers.': [42], 'In': [43], 'real-world': [45], 'the': [47, 96, 120, 127, 154], 'explainability': [48, 66], 'transparency': [50], 'of': [51, 110, 136, 158], 'systems': [53], 'are': [54, 61, 85], 'indispensable.': [55], 'The': [56], 'research': [57], 'community': [58], 'industry': [60], 'giving': [62], 'growing': [63], 'attention': [64], 'to': [65, 71, 118, 126, 133, 144], 'explainable': [68], 'AI.': [69], 'Compared': [70], 'traditional': [72], 'methods,': [75], 'deep': [76], 'neural': [77, 150, 159], 'networks': [78], '(DNNs)': [79], 'have': [80, 132], 'been': [81], 'very': [82], 'successful.': [83], 'DNNs': [84], 'comparably': [86], 'weak': [87], 'in': [88, 140], 'explaining': [89], 'their': [90], 'inference': [91], 'processes': [92], 'results': [94], 'because': [95], 'data': [97, 124], 'input': [98, 125], 'passes': [99], 'through': [100], 'layers,': [102], 'single': [105], 'involve': [108], 'millions': [109, 135], 'mathematical': [111], 'operations.': [112], 'It': [113], 'is': [114, 170], 'difficult': [115], 'humans': [117], 'follow': [119], 'exact': [121], 'mapping': [122], 'from': [123], 'predicted': [128], 'result.': [129], 'We': [130], 'would': [131], 'weights': [137], 'that': [138], 'interact': [139], 'complex': [142], 'way': [143], 'understand': [145], 'by': [148], 'network.': [151], 'To': [152], 'interpret': [153], 'behavior': [155], 'predictions': [157], 'networks,': [160], 'need': [162], 'interpretation': [164], 'methods.': [165], 'Thus,': [166], 'new': [168], 'frontier': [169], 'opening': [171], 'researchers.': [173]}",2021,"['Artificial intelligence', 'Computer science', 'Geography']","Complex machine learning models perform better. However, we consider these models as black boxes. That’s where Explainable AI (XAI) comes into play. Understanding why a model makes a specific prediction can be as crucial as its accuracy for many applications, researchers, and decision-makers. In many real-world applications, the explainability and transparency of AI systems are indispensable. The research community and industry are giving growing attention to explainability and explainable AI. Compared to traditional machine learning methods, deep neural networks (DNNs) have been very successful. DNNs are comparably weak in explaining their inference processes and results because the data input passes through many layers, and a single prediction can involve millions of mathematical operations. It is difficult for humans to follow the exact mapping from data input to the predicted result. We would have to consider millions of weights that interact in a complex way to understand a prediction by a neural network. To interpret the behavior and predictions of neural networks, we need specific interpretation methods. Thus, a new frontier is opening for researchers."
https://openalex.org/W4388962306,"Artificial intelligence, firm growth, and product innovation","{'We': [0, 10], 'study': [1], 'the': [2], 'use': [3], 'and': [4, 41, 75, 94], 'economic': [5], 'impact': [6], 'of': [7, 15, 66], 'AI': [8, 17, 29, 58, 67, 89], 'technologies.': [9], 'propose': [11], 'a': [12, 25], 'new': [13, 86], 'measure': [14, 23], 'firm-level': [16], 'investments': [18, 30, 59], 'using': [19, 60], 'employee': [20], 'resumes.': [21], 'Our': [22, 52, 82], 'reveals': [24], 'stark': [26], 'increase': [27], 'in': [28, 38], 'across': [31], 'sectors.': [32], 'AI-investing': [33], 'firms': [34, 74, 96], 'experience': [35], 'higher': [36, 79], 'growth': [37, 45, 70, 93], 'sales,': [39], 'employment,': [40], 'market': [42], 'valuations.': [43], 'This': [44], 'comes': [46], 'primarily': [47], 'through': [48, 97], 'increased': [49], 'product': [50, 98], 'innovation.': [51, 99], 'results': [53, 83], 'are': [54], 'robust': [55], 'to': [56, 63, 92], 'instrumenting': [57], ""firms'"": [61], 'exposure': [62], ""universities'"": [64], 'supply': [65], 'graduates.': [68], 'AI-powered': [69], 'concentrates': [71], 'among': [72], 'larger': [73], 'is': [76], 'associated': [77], 'with': [78], 'industry': [80], 'concentration.': [81], 'highlight': [84], 'that': [85], 'technologies': [87], 'like': [88], 'can': [90], 'contribute': [91], 'superstar': [95]}",2023,"['Superstar', 'Product (mathematics)', 'Industrial organization', 'Product market', 'New product development', 'Business', 'Product innovation', 'Economics', 'Marketing', 'Microeconomics', 'Incentive', 'Geometry', 'Mathematics', 'Advertising']","We study the use and economic impact of AI technologies. We propose a new measure of firm-level AI investments using employee resumes. Our measure reveals a stark increase in AI investments across sectors. AI-investing firms experience higher growth in sales, employment, and market valuations. This growth comes primarily through increased product innovation. Our results are robust to instrumenting AI investments using firms' exposure to universities' supply of AI graduates. AI-powered growth concentrates among larger firms and is associated with higher industry concentration. Our results highlight that new technologies like AI can contribute to growth and superstar firms through product innovation."
https://openalex.org/W2977373448,The impact of artificial intelligence in medicine on the future role of the physician,"{'The': [0, 42], 'practice': [1], 'of': [2, 9, 15, 35, 45, 67, 83, 117], 'medicine': [3], 'is': [4, 106], 'changing': [5], 'with': [6, 19], 'the': [7, 31, 65, 81, 91, 115, 145], 'development': [8], 'new': [10], 'Artificial': [11], 'Intelligence': [12], '(AI)': [13], 'methods': [14], 'machine': [16], 'learning.': [17], 'Coupled': [18], 'rapid': [20], 'improvements': [21], 'in': [22, 47, 75, 120, 124], 'computer': [23], 'processing,': [24], 'these': [25], 'AI-based': [26, 69, 118, 135], 'systems': [27, 70, 119, 136], 'are': [28, 141], 'already': [29], 'improving': [30], 'accuracy': [32], 'and': [33, 37, 103, 130, 140], 'efficiency': [34], 'diagnosis': [36], 'treatment': [38], 'across': [39], 'various': [40], 'specializations.': [41], 'increasing': [43], 'focus': [44], 'AI': [46, 57], 'radiology': [48], 'has': [49], 'led': [50], 'to': [51, 98, 143], 'some': [52, 76], 'experts': [53], 'suggesting': [54], 'that': [55, 110, 134], 'someday': [56], 'may': [58], 'even': [59], 'replace': [60, 73, 144], 'radiologists.': [61], 'These': [62], 'suggestions': [63], 'raise': [64], 'question': [66], 'whether': [68], 'will': [71, 79, 137], 'eventually': [72], 'physicians': [74, 84, 94, 139], 'specializations': [77, 125], 'or': [78], 'augment': [80, 138], 'role': [82, 116], 'without': [85], 'actually': [86], 'replacing': [87], 'them.': [88], 'To': [89, 109], 'assess': [90], 'impact': [92], 'on': [93], 'this': [95, 101, 112], 'research': [96], 'seeks': [97], 'better': [99], 'understand': [100], 'technology': [102], 'how': [104], 'it': [105], 'transforming': [107], 'medicine.': [108], 'end': [111], 'paper': [113], 'researches': [114], 'performing': [121], 'medical': [122], 'work': [123], 'including': [126], 'radiology,': [127], 'pathology,': [128], 'ophthalmology,': [129], 'cardiology.': [131], 'It': [132], 'concludes': [133], 'unlikely': [142], 'traditional': [146], 'physician–patient': [147], 'relationship.': [148]}",2019,"['Artificial intelligence', 'Applications of artificial intelligence', 'Medicine', 'Work (physics)', 'Computer science', 'Engineering', 'Mechanical engineering']","The practice of medicine is changing with the development of new Artificial Intelligence (AI) methods of machine learning. Coupled with rapid improvements in computer processing, these AI-based systems are already improving the accuracy and efficiency of diagnosis and treatment across various specializations. The increasing focus of AI in radiology has led to some experts suggesting that someday AI may even replace radiologists. These suggestions raise the question of whether AI-based systems will eventually replace physicians in some specializations or will augment the role of physicians without actually replacing them. To assess the impact on physicians this research seeks to better understand this technology and how it is transforming medicine. To that end this paper researches the role of AI-based systems in performing medical work in specializations including radiology, pathology, ophthalmology, and cardiology. It concludes that AI-based systems will augment physicians and are unlikely to replace the traditional physician–patient relationship."
https://openalex.org/W4280651558,Explainable Artificial Intelligence in education,"{'There': [0], 'are': [1], 'emerging': [2, 27], 'concerns': [3], 'about': [4], 'the': [5, 17, 26, 43, 59, 74, 116, 132, 152, 174], 'Fairness,': [6], 'Accountability,': [7], 'Transparency,': [8], 'and': [9, 51, 106, 135, 169], 'Ethics': [10], '(FATE)': [11], 'of': [12, 19, 25, 45, 77, 126, 131, 138, 154, 177], 'educational': [13, 108, 159], 'interventions': [14], 'supported': [15], 'by': [16, 165], 'use': [18, 37, 44, 76], 'Artificial': [20], 'Intelligence': [21], '(AI)': [22], 'algorithms.': [23], 'One': [24], 'methods': [28, 46], 'for': [29, 53, 103, 120, 173], 'increasing': [30], 'trust': [31], 'in': [32, 69, 99, 156, 179], 'AI': [33, 39, 55, 78, 109, 127, 133, 160], 'systems': [34, 56], 'is': [35], 'to': [36, 91, 101], 'eXplainable': [38], '(XAI),': [40], 'which': [41], 'promotes': [42], 'that': [47, 67, 94, 150], 'produce': [48], 'transparent': [49], 'explanations': [50, 140], 'reasons': [52], 'decisions': [54], 'make.': [57], 'Considering': [58], 'existing': [60], 'literature': [61], 'on': [62, 115], 'XAI,': [63], 'this': [64], 'paper': [65, 163], 'argues': [66], 'XAI': [68, 178], 'education': [70], 'has': [71, 81], 'commonalities': [72], 'with': [73], 'broader': [75], 'but': [79], 'also': [80], 'distinctive': [82], 'needs.': [83], 'Accordingly,': [84], 'we': [85], 'first': [86], 'present': [87, 145], 'a': [88], 'framework,': [89], 'referred': [90], 'as': [92], 'XAI-ED,': [93], 'considers': [95], 'six': [96], 'key': [97, 112], 'aspects': [98, 113], 'relation': [100], 'explainability': [102], 'studying,': [104], 'designing': [105], 'developing': [107], 'tools.': [110, 161], 'These': [111], 'focus': [114], 'stakeholders,': [117], 'benefits,': [118], 'approaches': [119], 'presenting': [121], 'explanations,': [122], 'widely': [123], 'used': [124], 'classes': [125], 'models,': [128], 'human-centred': [129], 'designs': [130], 'interfaces': [134], 'potential': [136], 'pitfalls': [137], 'providing': [139], 'within': [141], 'education.': [142, 180], 'We': [143], 'then': [144], 'four': [146, 157], 'comprehensive': [147], 'case': [148], 'studies': [149], 'illustrate': [151], 'application': [153], 'XAI-ED': [155], 'different': [158], 'The': [162], 'concludes': [164], 'discussing': [166], 'opportunities,': [167], 'challenges': [168], 'future': [170], 'research': [171], 'needs': [172], 'effective': [175], 'incorporation': [176]}",2022,"['Transparency (behavior)', 'Accountability', 'Relation (database)', 'Computer science', 'Key (lock)', 'Knowledge management', 'Engineering ethics', 'Management science', 'Artificial intelligence', 'Political science', 'Engineering', 'Data mining', 'Law', 'Computer security']","There are emerging concerns about the Fairness, Accountability, Transparency, and Ethics (FATE) of educational interventions supported by the use of Artificial Intelligence (AI) algorithms. One of the emerging methods for increasing trust in AI systems is to use eXplainable AI (XAI), which promotes the use of methods that produce transparent explanations and reasons for decisions AI systems make. Considering the existing literature on XAI, this paper argues that XAI in education has commonalities with the broader use of AI but also has distinctive needs. Accordingly, we first present a framework, referred to as XAI-ED, that considers six key aspects in relation to explainability for studying, designing and developing educational AI tools. These key aspects focus on the stakeholders, benefits, approaches for presenting explanations, widely used classes of AI models, human-centred designs of the AI interfaces and potential pitfalls of providing explanations within education. We then present four comprehensive case studies that illustrate the application of XAI-ED in four different educational AI tools. The paper concludes by discussing opportunities, challenges and future research needs for the effective incorporation of XAI in education."
https://openalex.org/W2972320421,Artificial Intelligence in Anesthesiology,"{'Abstract': [0], 'Artificial': [1, 140], 'intelligence': [2, 18, 31, 70, 88, 114, 134, 141], 'has': [3, 142], 'been': [4], 'advancing': [5], 'in': [6, 32, 63, 86, 107, 130, 137, 151], 'fields': [7, 106], 'including': [8], 'anesthesiology.': [9], 'This': [10], 'scoping': [11], 'review': [12], 'of': [13, 16, 27, 29, 36, 41, 112, 128, 149], 'the': [14, 64, 116, 126, 143, 147], 'intersection': [15], 'artificial': [17, 30, 69, 87, 108, 113, 133], 'and': [19, 23, 45, 54, 73, 81, 97, 102, 125], 'anesthesia': [20, 37], 'research': [21], 'identified': [22, 62], 'summarized': [24], 'six': [25], 'themes': [26], 'applications': [28], 'anesthesiology:': [33], '(1)': [34, 75], 'depth': [35], 'monitoring,': [38], '(2)': [39, 84], 'control': [40], 'anesthesia,': [42], '(3)': [43, 103], 'event': [44], 'risk': [46], 'prediction,': [47], '(4)': [48], 'ultrasound': [49], 'guidance,': [50], '(5)': [51], 'pain': [52, 163], 'management,': [53], '(6)': [55], 'operating': [56], 'room': [57], 'logistics.': [58], 'Based': [59], 'on': [60], 'papers': [61], 'review,': [65], 'several': [66], 'topics': [67], 'within': [68], 'were': [71], 'described': [72], 'summarized:': [74], 'machine': [76, 93], 'learning': [77], '(including': [78], 'supervised,': [79], 'unsupervised,': [80], 'reinforcement': [82], 'learning),': [83], 'techniques': [85], '(': [89], 'e.g.': [90], ',': [91], 'classical': [92], 'learning,': [94, 99], 'neural': [95], 'networks': [96], 'deep': [98], 'Bayesian': [100], 'methods),': [101], 'major': [104], 'applied': [105], 'intelligence.': [109], 'The': [110], 'implications': [111], 'for': [115, 135], 'practicing': [117], 'anesthesiologist': [118], 'are': [119, 122], 'discussed': [120], 'as': [121], 'its': [123], 'limitations': [124], 'role': [127], 'clinicians': [129], 'further': [131], 'developing': [132], 'use': [136], 'clinical': [138], 'care.': [139], 'potential': [144], 'to': [145, 157, 161], 'impact': [146], 'practice': [148], 'anesthesiology': [150], 'aspects': [152], 'ranging': [153], 'from': [154], 'perioperative': [155], 'support': [156], 'critical': [158], 'care': [159], 'delivery': [160], 'outpatient': [162], 'management.': [164]}",2019,"['Anesthesiology', 'Medicine', 'Artificial intelligence', 'Artificial neural network', 'Machine learning', 'Computer science', 'Anesthesia']","Abstract Artificial intelligence has been advancing in fields including anesthesiology. This scoping review of the intersection of artificial intelligence and anesthesia research identified and summarized six themes of applications of artificial intelligence in anesthesiology: (1) depth of anesthesia monitoring, (2) control of anesthesia, (3) event and risk prediction, (4) ultrasound guidance, (5) pain management, and (6) operating room logistics. Based on papers identified in the review, several topics within artificial intelligence were described and summarized: (1) machine learning (including supervised, unsupervised, and reinforcement learning), (2) techniques in artificial intelligence ( e.g. , classical machine learning, neural networks and deep learning, Bayesian methods), and (3) major applied fields in artificial intelligence. The implications of artificial intelligence for the practicing anesthesiologist are discussed as are its limitations and the role of clinicians in further developing artificial intelligence for use in clinical care. Artificial intelligence has the potential to impact the practice of anesthesiology in aspects ranging from perioperative support to critical care delivery to outpatient pain management."
https://openalex.org/W4389437528,Education in the Era of Generative Artificial Intelligence (AI): Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning,"{'Since': [0], 'its': [1], 'maiden': [2], 'release': [3], 'into': [4], 'the': [5, 28, 52, 136], 'public': [6], 'domain': [7], 'on': [8, 159, 183], 'November': [9], '30,': [10], '2022,': [11], 'ChatGPT': [12, 46, 91, 99, 137, 161], 'garnered': [13], 'more': [14], 'than': [15], 'one': [16], 'million': [17], 'subscribers': [18], 'within': [19, 51], 'a': [20], 'week.': [21], 'The': [22, 42, 128, 155], 'generative': [23, 187], 'AI': [24, 66, 188], 'tool': [25], '⎼ChatGPT': [26], 'took': [27], 'world': [29], 'by': [30], 'surprise': [31], 'with': [32], 'it': [33], 'sophisticated': [34], 'capacity': [35], 'to': [36, 47, 68, 83, 105, 122, 165, 196], 'carry': [37], 'out': [38], 'remarkably': [39], 'complex': [40, 49], 'tasks.': [41], 'extraordinary': [43], 'abilities': [44], 'of': [45, 54, 90, 98, 107], 'perform': [48], 'tasks': [50], 'field': [53], 'education': [55, 198], 'has': [56], 'caused': [57], 'mixed': [58], 'feelings': [59], 'among': [60], 'educators,': [61], 'as': [62, 139], 'this': [63], 'advancement': [64], 'in': [65, 92, 135, 144], 'seems': [67], 'revolutionize': [69], 'existing': [70, 150], 'educational': [71], 'praxis.': [72], 'This': [73], 'is': [74], 'an': [75], 'exploratory': [76], 'study': [77, 156], 'that': [78, 118], 'synthesizes': [79], 'recent': [80], 'extant': [81], 'literature': [82], 'offer': [84], 'some': [85, 132], 'potential': [86], 'benefits': [87], 'and': [88, 95, 109, 125, 168, 174, 180, 194, 199], 'drawbacks': [89], 'promoting': [93], 'teaching': [94, 124, 167], 'learning.': [96, 169, 202], 'Benefits': [97], 'include': [100], 'but': [101], 'are': [102], 'not': [103], 'limited': [104], 'promotion': [106], 'personalized': [108], 'interactive': [110], 'learning,': [111], 'generating': [112, 140], 'prompts': [113], 'for': [114], 'formative': [115], 'assessment': [116], 'activities': [117], 'provide': [119], 'ongoing': [120], 'feedback': [121], 'inform': [123], 'learning': [126], 'etc.': [127, 154], 'paper': [129], 'also': [130], 'highlights': [131], 'inherent': [133], 'limitations': [134], 'such': [138], 'wrong': [141], 'information,': [142], 'biases': [143], 'data': [145], 'training,': [146], 'which': [147], 'may': [148], 'augment': [149], 'biases,': [151], 'privacy': [152], 'issues': [153], 'offers': [157], 'recommendations': [158], 'how': [160, 184], 'could': [162, 177, 190], 'be': [163, 191], 'leveraged': [164], 'maximize': [166], 'Policy': [170], 'makers,': [171], 'researchers,': [172], 'educators': [173], 'technology': [175], 'experts': [176], 'work': [178], 'together': [179], 'start': [181], 'conversations': [182], 'these': [185], 'evolving': [186], 'tools': [189], 'used': [192], 'safely': [193], 'constructively': [195], 'improve': [197], 'support': [200], 'students’': [201]}",2023,"['Surprise', 'Formative assessment', 'Generative grammar', 'Promotion (chess)', 'Computer science', 'Praxis', 'Field (mathematics)', 'Extant taxon', 'Artificial intelligence', 'Knowledge management', 'Psychology', 'Mathematics education', 'Political science', 'Social psychology', 'Pure mathematics', 'Law', 'Politics', 'Biology', 'Mathematics', 'Evolutionary biology']","Since its maiden release into the public domain on November 30, 2022, ChatGPT garnered more than one million subscribers within a week. The generative AI tool ⎼ChatGPT took the world by surprise with it sophisticated capacity to carry out remarkably complex tasks. The extraordinary abilities of ChatGPT to perform complex tasks within the field of education has caused mixed feelings among educators, as this advancement in AI seems to revolutionize existing educational praxis. This is an exploratory study that synthesizes recent extant literature to offer some potential benefits and drawbacks of ChatGPT in promoting teaching and learning. Benefits of ChatGPT include but are not limited to promotion of personalized and interactive learning, generating prompts for formative assessment activities that provide ongoing feedback to inform teaching and learning etc. The paper also highlights some inherent limitations in the ChatGPT such as generating wrong information, biases in data training, which may augment existing biases, privacy issues etc. The study offers recommendations on how ChatGPT could be leveraged to maximize teaching and learning. Policy makers, researchers, educators and technology experts could work together and start conversations on how these evolving generative AI tools could be used safely and constructively to improve education and support students’ learning."
https://openalex.org/W4383912288,Artificial Intelligence in Pharmaceutical Technology and Drug Delivery Design,"{'Artificial': [0], 'intelligence': [1], '(AI)': [2], 'has': [3], 'emerged': [4], 'as': [5], 'a': [6, 29, 71], 'powerful': [7], 'tool': [8], 'that': [9, 47, 147], 'harnesses': [10], 'anthropomorphic': [11], 'knowledge': [12], 'and': [13, 25, 37, 54, 61, 74, 99, 109, 114, 124, 134, 158, 182, 202, 209, 225], 'provides': [14, 188], 'expedited': [15], 'solutions': [16], 'to': [17, 77, 92, 153], 'complex': [18], 'challenges.': [19], 'Remarkable': [20], 'advancements': [21], 'in': [22, 32, 106, 171, 196, 208, 213], 'AI': [23, 45, 89, 145, 170, 212], 'technology': [24], 'machine': [26], 'learning': [27, 103], 'present': [28], 'transformative': [30], 'opportunity': [31], 'the': [33, 82, 112, 122, 130, 166, 205, 214], 'drug': [34, 67, 78, 86, 117, 172, 174, 222], 'discovery,': [35, 79, 173], 'formulation,': [36], 'testing': [38], 'of': [39, 84, 116, 126, 169, 191, 211], 'pharmaceutical': [40, 197, 215], 'dosage': [41, 176], 'forms.': [42], 'By': [43], 'utilizing': [44], 'algorithms': [46, 104, 146], 'analyze': [48, 148], 'extensive': [49, 133], 'biological': [50], 'data,': [51, 151], 'including': [52], 'genomics': [53], 'proteomics,': [55], 'researchers': [56], 'can': [57, 90, 110, 141], 'identify': [58], 'disease-associated': [59], 'targets': [60], 'predict': [62, 111], 'their': [63, 200], 'interactions': [64], 'with': [65], 'potential': [66], 'candidates.': [68, 118], 'This': [69, 119, 162, 186], 'enables': [70, 121], 'more': [72, 154], 'efficient': [73], 'targeted': [75], 'approach': [76], 'thereby': [80], 'increasing': [81], 'likelihood': [83], 'successful': [85], 'approvals.': [87], 'Furthermore,': [88], 'contribute': [91], 'reducing': [93, 129], 'development': [94, 100, 223], 'costs': [95], 'by': [96], 'optimizing': [97], 'research': [98], 'processes.': [101], 'Machine': [102], 'assist': [105], 'experimental': [107], 'design': [108], 'pharmacokinetics': [113], 'toxicity': [115], 'capability': [120], 'prioritization': [123], 'optimization': [125], 'lead': [127], 'compounds,': [128], 'need': [131], 'for': [132, 220], 'costly': [135], 'animal': [136], 'testing.': [137], 'Personalized': [138], 'medicine': [139], 'approaches': [140, 194], 'be': [142], 'facilitated': [143], 'through': [144], 'real-world': [149], 'patient': [150, 160, 226], 'leading': [152], 'effective': [155], 'treatment': [156], 'outcomes': [157], 'improved': [159], 'adherence.': [161], 'comprehensive': [163], 'review': [164, 187], 'explores': [165], 'wide-ranging': [167], 'applications': [168], 'delivery': [175], 'form': [177], 'designs,': [178], 'process': [179], 'optimization,': [180], 'testing,': [181], 'pharmacokinetics/pharmacodynamics': [183], '(PK/PD)': [184], 'studies.': [185], 'an': [189], 'overview': [190], 'various': [192], 'AI-based': [193], 'utilized': [195], 'technology,': [198], 'highlighting': [199], 'benefits': [201], 'drawbacks.': [203], 'Nevertheless,': [204], 'continued': [206], 'investment': [207], 'exploration': [210], 'industry': [216], 'offer': [217], 'exciting': [218], 'prospects': [219], 'enhancing': [221], 'processes': [224], 'care.': [227]}",2023,"['Computer science', 'Drug discovery', 'Drug development', 'Pharmaceutical industry', 'Risk analysis (engineering)', 'Artificial intelligence', 'Drug', 'Data science', 'Medicine', 'Pharmacology', 'Bioinformatics', 'Biology']","Artificial intelligence (AI) has emerged as a powerful tool that harnesses anthropomorphic knowledge and provides expedited solutions to complex challenges. Remarkable advancements in AI technology and machine learning present a transformative opportunity in the drug discovery, formulation, and testing of pharmaceutical dosage forms. By utilizing AI algorithms that analyze extensive biological data, including genomics and proteomics, researchers can identify disease-associated targets and predict their interactions with potential drug candidates. This enables a more efficient and targeted approach to drug discovery, thereby increasing the likelihood of successful drug approvals. Furthermore, AI can contribute to reducing development costs by optimizing research and development processes. Machine learning algorithms assist in experimental design and can predict the pharmacokinetics and toxicity of drug candidates. This capability enables the prioritization and optimization of lead compounds, reducing the need for extensive and costly animal testing. Personalized medicine approaches can be facilitated through AI algorithms that analyze real-world patient data, leading to more effective treatment outcomes and improved patient adherence. This comprehensive review explores the wide-ranging applications of AI in drug discovery, drug delivery dosage form designs, process optimization, testing, and pharmacokinetics/pharmacodynamics (PK/PD) studies. This review provides an overview of various AI-based approaches utilized in pharmaceutical technology, highlighting their benefits and drawbacks. Nevertheless, the continued investment in and exploration of AI in the pharmaceutical industry offer exciting prospects for enhancing drug development processes and patient care."
https://openalex.org/W3146345129,Artificial Intelligence in Cancer Research and Precision Medicine,"{'Abstract': [0], 'Artificial': [1], 'intelligence': [2], '(AI)': [3], 'is': [4], 'rapidly': [5], 'reshaping': [6], 'cancer': [7, 85, 143], 'research': [8], 'and': [9, 49, 58, 64, 110, 131, 133], 'personalized': [10], 'clinical': [11], 'care.': [12], 'Availability': [13], 'of': [14, 35, 41, 51, 56, 103, 125, 139], 'high-dimensionality': [15], 'datasets': [16], 'coupled': [17], 'with': [18], 'advances': [19, 74], 'in': [20, 38, 84, 122, 141], 'high-performance': [21], 'computing,': [22], 'as': [23, 25], 'well': [24], 'innovative': [26], 'deep': [27], 'learning': [28], 'architectures,': [29], 'has': [30, 94], 'led': [31], 'to': [32, 53, 61, 66, 97, 107, 127], 'an': [33], 'explosion': [34], 'AI': [36, 93, 126, 140], 'use': [37], 'various': [39], 'aspects': [40, 102], 'oncology': [42], 'research.': [43], 'These': [44], 'applications': [45], 'range': [46], 'from': [47], 'detection': [48], 'classification': [50], 'cancer,': [52], 'molecular': [54], 'characterization': [55], 'tumors': [57], 'their': [59], 'microenvironment,': [60], 'drug': [62], 'discovery': [63], 'repurposing,': [65], 'predicting': [67], 'treatment': [68, 109], 'outcomes': [69], 'for': [70, 137], 'patients.': [71], 'As': [72], 'these': [73], 'start': [75], 'penetrating': [76], 'the': [77, 95, 118, 123, 142], 'clinic,': [78], 'we': [79, 116], 'foresee': [80], 'a': [81, 135], 'shifting': [82], 'paradigm': [83], 'care': [86], 'becoming': [87], 'strongly': [88], 'driven': [89], 'by': [90], 'AI.': [91], 'Significance:': [92], 'potential': [96], 'dramatically': [98], 'affect': [99], 'nearly': [100], 'all': [101], 'oncology—from': [104], 'enhancing': [105], 'diagnosis': [106], 'personalizing': [108], 'discovering': [111], 'novel': [112], 'anticancer': [113], 'drugs.': [114], 'Here,': [115], 'review': [117], 'recent': [119], 'enormous': [120], 'progress': [121], 'application': [124], 'oncology,': [128], 'highlight': [129], 'limitations': [130], 'pitfalls,': [132], 'chart': [134], 'path': [136], 'adoption': [138], 'clinic.': [144]}",2021,"['Repurposing', 'Precision medicine', 'Artificial intelligence', 'Cancer', 'Drug repositioning', 'Personalized medicine', 'Computer science', 'Drug discovery', 'Deep learning', 'Cancer Medicine', 'Medicine', 'Data science', 'Bioinformatics', 'Drug', 'Internal medicine', 'Pathology', 'Pharmacology', 'Biology', 'Ecology']","Abstract Artificial intelligence (AI) is rapidly reshaping cancer research and personalized clinical care. Availability of high-dimensionality datasets coupled with advances in high-performance computing, as well as innovative deep learning architectures, has led to an explosion of AI use in various aspects of oncology research. These applications range from detection and classification of cancer, to molecular characterization of tumors and their microenvironment, to drug discovery and repurposing, to predicting treatment outcomes for patients. As these advances start penetrating the clinic, we foresee a shifting paradigm in cancer care becoming strongly driven by AI. Significance: AI has the potential to dramatically affect nearly all aspects of oncology—from enhancing diagnosis to personalizing treatment and discovering novel anticancer drugs. Here, we review the recent enormous progress in the application of AI to oncology, highlight limitations and pitfalls, and chart a path for adoption of AI in the cancer clinic."
https://openalex.org/W3113541070,Application of Artificial Intelligence-Based Technologies in the Healthcare Industry: Opportunities and Challenges,"{'This': [0], 'study': [1, 29], 'examines': [2], 'the': [3, 16, 26, 77, 99, 105, 113, 126, 156, 175, 183], 'current': [4], 'state': [5], 'of': [6, 25, 34, 65, 79, 84, 115, 125, 128, 139, 158, 165, 185], 'artificial': [7], 'intelligence': [8], '(AI)-based': [9], 'technology': [10], 'applications': [11, 36, 96, 130, 164], 'and': [12, 58, 81, 104, 118, 141, 154, 171, 179], 'their': [13, 152, 159], 'impact': [14, 74], 'on': [15, 75], 'healthcare': [17, 93], 'industry.': [18], 'In': [19, 67], 'addition': [20], 'to': [21, 51, 109, 120, 173, 181], 'a': [22, 62, 122], 'thorough': [23], 'review': [24], 'literature,': [27], 'this': [28], 'analyzed': [30], 'several': [31], 'real-world': [32], 'examples': [33], 'AI': [35, 69, 87, 129, 140, 166], 'in': [37, 55, 131], 'healthcare.': [38, 132], 'The': [39], 'results': [40], 'indicate': [41], 'that': [42, 136], 'major': [43], 'hospitals': [44], 'are,': [45], 'at': [46], 'present,': [47], 'using': [48], 'AI-enabled': [49], 'systems': [50, 70], 'augment': [52], 'medical': [53], 'staff': [54], 'patient': [56], 'diagnosis': [57], 'treatment': [59], 'activities': [60, 83], 'for': [61, 151], 'wide': [63], 'range': [64], 'diseases.': [66], 'addition,': [68], 'are': [71], 'making': [72], 'an': [73], 'improving': [76], 'efficiency': [78, 157], 'nursing': [80], 'managerial': [82], 'hospitals.': [85], 'While': [86], 'is': [88, 134], 'being': [89], 'embraced': [90], 'positively': [91], 'by': [92], 'providers,': [94], 'its': [95], 'provide': [97, 121], 'both': [98], 'utopian': [100], 'perspective': [101], '(new': [102], 'opportunities)': [103], 'dystopian': [106], 'view': [107, 124], '(challenges': [108], 'overcome).': [110], 'We': [111], 'discuss': [112], 'details': [114], 'those': [116], 'opportunities': [117], 'challenges': [119], 'balanced': [123], 'value': [127, 150], 'It': [133], 'clear': [135], 'rapid': [137], 'advances': [138], 'related': [142], 'technologies': [143, 187], 'will': [144, 167], 'help': [145], 'care': [146, 177], 'providers': [147], 'create': [148], 'new': [149], 'patients': [153], 'improve': [155], 'operational': [160], 'processes.': [161], 'Nevertheless,': [162], 'effective': [163, 169], 'require': [168], 'planning': [170], 'strategies': [172], 'transform': [174], 'entire': [176], 'service': [178], 'operations': [180], 'reap': [182], 'benefits': [184], 'what': [186], 'offer.': [188]}",2021,"['Health care', 'Healthcare industry', 'Computer science', 'Applications of artificial intelligence', 'Knowledge management', 'Emerging technologies', 'Risk analysis (engineering)', 'Business', 'Engineering management', 'Artificial intelligence', 'Engineering', 'Political science', 'Law']","This study examines the current state of artificial intelligence (AI)-based technology applications and their impact on the healthcare industry. In addition to a thorough review of the literature, this study analyzed several real-world examples of AI applications in healthcare. The results indicate that major hospitals are, at present, using AI-enabled systems to augment medical staff in patient diagnosis and treatment activities for a wide range of diseases. In addition, AI systems are making an impact on improving the efficiency of nursing and managerial activities of hospitals. While AI is being embraced positively by healthcare providers, its applications provide both the utopian perspective (new opportunities) and the dystopian view (challenges to overcome). We discuss the details of those opportunities and challenges to provide a balanced view of the value of AI applications in healthcare. It is clear that rapid advances of AI and related technologies will help care providers create new value for their patients and improve the efficiency of their operational processes. Nevertheless, effective applications of AI will require effective planning and strategies to transform the entire care service and operations to reap the benefits of what technologies offer."
https://openalex.org/W2962411443,Artificial Intelligence for Clinical Trial Design,"{'Clinical': [0], 'trials': [1], 'consume': [2], 'the': [3, 7, 32, 35, 40, 45, 67, 78, 96], 'latter': [4], 'half': [5], 'of': [6, 77, 88, 114], '10': [8, 89], 'to': [9, 23, 54, 69, 110], '15': [10], 'year,': [11], '1.5-2.0': [12], 'billion': [13, 56], 'USD,': [14], 'development': [15, 42], 'cycle': [16], 'for': [17, 81], 'bringing': [18], 'a': [19, 26, 92], 'single': [20], 'new': [21], 'drug': [22], 'market.': [24, 97], 'Hence,': [25], 'failed': [27, 48], 'trial': [28, 36, 50, 83, 94, 116, 120], 'sinks': [29], 'not': [30], 'only': [31, 86], 'investment': [33], 'into': [34], 'itself': [37], 'but': [38], 'also': [39], 'preclinical': [41], 'costs,': [43], 'rendering': [44], 'loss': [46], 'per': [47], 'clinical': [49, 93, 115], 'at': [51], '800': [52], 'million': [53], '1.4': [55], 'USD.': [57], 'Suboptimal': [58], 'patient': [59], 'cohort': [60], 'selection': [61], 'and': [62], 'recruiting': [63], 'techniques,': [64], 'paired': [65], 'with': [66], 'inability': [68], 'monitor': [70], 'patients': [71], 'effectively': [72], 'during': [73], 'trials,': [74], 'are': [75], 'two': [76], 'main': [79], 'causes': [80], 'high': [82], 'failure': [84], 'rates:': [85], 'one': [87], 'compounds': [90], 'entering': [91], 'reaches': [95], 'We': [98], 'explain': [99], 'how': [100], 'recent': [101], 'advances': [102], 'in': [103], 'artificial': [104], 'intelligence': [105], '(AI)': [106], 'can': [107], 'be': [108], 'used': [109], 'reshape': [111], 'key': [112], 'steps': [113], 'design': [117], 'towards': [118], 'increasing': [119], 'success': [121], 'rates.': [122]}",2019,"['Psychology', 'Clinical trial', 'Psychotherapist', 'Medicine', 'Pathology']","Clinical trials consume the latter half of the 10 to 15 year, 1.5-2.0 billion USD, development cycle for bringing a single new drug to market. Hence, a failed trial sinks not only the investment into the trial itself but also the preclinical development costs, rendering the loss per failed clinical trial at 800 million to 1.4 billion USD. Suboptimal patient cohort selection and recruiting techniques, paired with the inability to monitor patients effectively during trials, are two of the main causes for high trial failure rates: only one of 10 compounds entering a clinical trial reaches the market. We explain how recent advances in artificial intelligence (AI) can be used to reshape key steps of clinical trial design towards increasing trial success rates."
https://openalex.org/W3093821457,"Artificial intelligence and innovation management: A review, framework, and research agenda✰","{'Artificial': [0], 'Intelligence': [1], '(AI)': [2], 'reshapes': [3], 'companies': [4], 'and': [5, 16, 38, 52, 69, 87], 'how': [6], 'innovation': [7, 32, 44, 64], 'management': [8, 26, 65], 'is': [9, 90], 'organized.': [10], 'Consistent': [11], 'with': [12], 'rapid': [13], 'technological': [14], 'development': [15], 'the': [17, 40, 49, 53, 57, 61, 79, 96, 99], 'replacement': [18], 'of': [19, 56, 66, 102], 'human': [20], 'organization,': [21], 'AI': [22, 67, 72, 83], 'may': [23], 'indeed': [24], 'compel': [25], 'to': [27, 81, 92, 98], 'rethink': [28], 'a': [29, 76], ""company's"": [30], 'entire': [31], 'process.': [33], 'In': [34], 'response,': [35], 'we': [36, 59], 'review': [37, 60], 'explore': [39], 'implications': [41, 62], 'for': [42, 63, 111], 'future': [43, 112], 'management.': [45], 'Using': [46], 'ideas': [47], 'from': [48], 'Carnegie': [50], 'School': [51], 'behavioral': [54], 'theory': [55], 'firm,': [58], 'technologies': [68], 'machine': [70], 'learning-based': [71], 'systems.': [73], 'We': [74, 104], 'outline': [75], 'framework': [77], 'showing': [78], 'extent': [80], 'which': [82], 'can': [84], 'replace': [85], 'humans': [86], 'explain': [88], 'what': [89], 'important': [91], 'consider': [93], 'in': [94], 'making': [95], 'transformation': [97], 'digital': [100], 'organization': [101], 'innovation.': [103], 'conclude': [105], 'our': [106], 'study': [107], 'by': [108], 'exploring': [109], 'directions': [110], 'research.': [113]}",2020,"['Knowledge management', 'Innovation management', 'Process (computing)', 'Innovation process', 'Digital transformation', 'Technology management', 'Computer science', 'Business', 'Marketing', 'Work in process', 'Operating system', 'World Wide Web']","Artificial Intelligence (AI) reshapes companies and how innovation management is organized. Consistent with rapid technological development and the replacement of human organization, AI may indeed compel management to rethink a company's entire innovation process. In response, we review and explore the implications for future innovation management. Using ideas from the Carnegie School and the behavioral theory of the firm, we review the implications for innovation management of AI technologies and machine learning-based AI systems. We outline a framework showing the extent to which AI can replace humans and explain what is important to consider in making the transformation to the digital organization of innovation. We conclude our study by exploring directions for future research."
https://openalex.org/W2792315573,Machine learning &amp; artificial intelligence in the quantum domain: a review of recent progress,"{'Quantum': [0, 90], 'information': [1, 39], 'technologies,': [2], 'on': [3, 11, 26], 'the': [4, 12, 30, 73, 76, 93, 113, 116, 192, 201, 206, 226, 244, 260, 282, 300], 'one': [5, 106], 'hand,': [6], 'and': [7, 44, 52, 85, 98, 103, 157, 212, 238, 252, 265, 287, 297], 'intelligent': [8], 'learning': [9, 42, 189, 196, 251, 264], 'systems,': [10], 'other,': [13], 'are': [14, 19], 'both': [15, 125], 'emergent': [16], 'technologies': [17, 156], 'that': [18, 270], 'likely': [20], 'to': [21, 78, 111], 'have': [22, 55, 70, 120, 182, 220, 241], 'a': [23, 63, 135, 268, 290], 'transformative': [24], 'impact': [25], 'our': [27, 146], 'society': [28], 'in': [29, 62, 124, 138, 145, 161, 169, 177, 267, 289, 299], 'future.': [31], 'The': [32], 'respective': [33], 'underlying': [34], 'fields': [35, 81], 'of': [36, 66, 75, 115, 127, 194, 203, 209, 216, 228, 247, 250, 259, 263, 293], 'basic': [37], 'research-quantum': [38], 'versus': [40], 'machine': [41], '(ML)': [43], 'artificial': [45], 'intelligence': [46, 266], '(AI)-have': [47], 'their': [48, 222], 'own': [49], 'specific': [50], 'questions': [51, 258], 'challenges,': [53], 'which': [54, 79], 'hitherto': [56], 'been': [57, 71, 184], 'investigated': [58], 'largely': [59], 'independently.': [60], 'However,': [61], 'growing': [64], 'body': [65], 'recent': [67, 285], 'work,': [68], 'researchers': [69], 'probing': [72], 'question': [74], 'extent': [77], 'these': [80], 'can': [82, 108, 233], 'indeed': [83], 'learn': [84], 'benefit': [86], 'from': [87, 105, 166], 'each': [88], 'other.': [89, 117], 'ML': [91, 142, 151, 174, 296], 'explores': [92], 'interaction': [94], 'between': [95], 'quantum': [96, 131, 163, 167, 178, 180, 210, 236, 248, 275, 301], 'computing': [97, 132], 'ML,': [99], 'investigating': [100, 295], 'how': [101], 'results': [102], 'techniques': [104], 'field': [107], 'be': [109], 'used': [110, 176], 'solve': [112], 'problems': [114], 'Recently': [118], 'we': [119, 280], 'witnessed': [121], 'significant': [122], 'breakthroughs': [123], 'directions': [126], 'influence.': [128], 'For': [129], 'instance,': [130], 'is': [133, 271], 'finding': [134], 'vital': [136], 'application': [137], 'providing': [139], 'speed-ups': [140], 'for': [141, 187, 205, 213, 235], 'problems,': [143], 'critical': [144], ""'big"": [147], ""data'"": [148], 'world.': [149], 'Conversely,': [150], 'already': [152], 'permeates': [153], 'many': [154], 'cutting-edge': [155], 'may': [158], 'become': [159], 'instrumental': [160], 'advanced': [162], 'technologies.': [164], 'Aside': [165], 'speed-up': [168], 'data': [170], 'analysis,': [171], 'or': [172], 'classical': [173], 'optimization': [175], 'experiments,': [179], 'enhancements': [181], 'also': [183, 242], '(theoretically)': [185], 'demonstrated': [186], 'interactive': [188], 'tasks,': [190], 'highlighting': [191], 'potential': [193], 'quantum-enhanced': [195], 'agents.': [197], 'Finally,': [198], 'works': [199], 'exploring': [200], 'use': [202], 'AI': [204, 253, 298], 'very': [207, 261], 'design': [208], 'experiments': [211], 'performing': [214], 'parts': [215], 'genuine': [217], 'research': [218, 294], 'autonomously,': [219], 'reported': [221], 'first': [223], 'successes.': [224], 'Beyond': [225], 'topics': [227], 'mutual': [229], 'enhancement-exploring': [230], 'what': [231], 'ML/AI': [232], 'do': [234], 'physics': [237], 'vice': [239], 'versa-researchers': [240], 'broached': [243], 'fundamental': [245], 'issue': [246], 'generalizations': [249], 'concepts.': [254], 'This': [255], 'deals': [256], 'with': [257], 'meaning': [262], 'world': [269], 'fully': [272], 'described': [273], 'by': [274], 'mechanics.': [276], 'In': [277], 'this': [278], 'review,': [279], 'describe': [281], 'main': [283], 'ideas,': [284], 'developments': [286], 'progress': [288], 'broad': [291], 'spectrum': [292], 'domain.': [302]}",2018,"['Transformative learning', 'Quantum', 'Quantum machine learning', 'Quantum computer', 'Physics', 'Quantum information science', 'Field (mathematics)', 'Quantum information', 'Quantum technology', 'Artificial intelligence', 'Computer science', 'Data science', 'Open quantum system', 'Quantum mechanics', 'Psychology', 'Mathematics', 'Pure mathematics', 'Pedagogy', 'Quantum entanglement']","Quantum information technologies, on the one hand, and intelligent learning systems, on the other, are both emergent technologies that are likely to have a transformative impact on our society in the future. The respective underlying fields of basic research-quantum information versus machine learning (ML) and artificial intelligence (AI)-have their own specific questions and challenges, which have hitherto been investigated largely independently. However, in a growing body of recent work, researchers have been probing the question of the extent to which these fields can indeed learn and benefit from each other. Quantum ML explores the interaction between quantum computing and ML, investigating how results and techniques from one field can be used to solve the problems of the other. Recently we have witnessed significant breakthroughs in both directions of influence. For instance, quantum computing is finding a vital application in providing speed-ups for ML problems, critical in our 'big data' world. Conversely, ML already permeates many cutting-edge technologies and may become instrumental in advanced quantum technologies. Aside from quantum speed-up in data analysis, or classical ML optimization used in quantum experiments, quantum enhancements have also been (theoretically) demonstrated for interactive learning tasks, highlighting the potential of quantum-enhanced learning agents. Finally, works exploring the use of AI for the very design of quantum experiments and for performing parts of genuine research autonomously, have reported their first successes. Beyond the topics of mutual enhancement-exploring what ML/AI can do for quantum physics and vice versa-researchers have also broached the fundamental issue of quantum generalizations of learning and AI concepts. This deals with questions of the very meaning of learning and intelligence in a world that is fully described by quantum mechanics. In this review, we describe the main ideas, recent developments and progress in a broad spectrum of research investigating ML and AI in the quantum domain."
https://openalex.org/W2240086230,Research Priorities for Robust and Beneficial Artificial Intelligence,"{'Success': [0], 'in': [1], 'the': [2, 8], 'quest': [3], 'for': [4], 'artificial': [5], 'intelligence': [6], 'has': [7], 'potential': [9, 30], 'to': [10, 14, 21, 24], 'bring': [11], 'unprecedented': [12], 'benefits': [13, 27], 'humanity,': [15], 'and': [16, 59], 'it': [17], 'is': [18], 'therefore': [19], 'worthwhile': [20, 50], 'investigate': [22], 'how': [23], 'maximize': [25], 'these': [26], 'while': [28], 'avoiding': [29], 'pitfalls.': [31], 'This': [32], 'article': [33], 'gives': [34], 'numerous': [35], 'examples': [36], '(which': [37], 'should': [38], 'by': [39], 'no': [40], 'means': [41], 'be': [42], 'construed': [43], 'as': [44], 'an': [45], 'exhaustive': [46], 'list)': [47], 'of': [48], 'such': [49], 'research': [51], 'aimed': [52], 'at': [53], 'ensuring': [54], 'that': [55], 'AI': [56], 'remains': [57], 'robust': [58], 'beneficial.': [60]}",2015,"['Artificial intelligence', 'Computer science', 'Risk analysis (engineering)', 'Humanity', 'Management science', 'Engineering', 'Business', 'Political science', 'Law']","Success in the quest for artificial intelligence has the potential to bring unprecedented benefits to humanity, and it is therefore worthwhile to investigate how to maximize these benefits while avoiding potential pitfalls. This article gives numerous examples (which should by no means be construed as an exhaustive list) of such worthwhile research aimed at ensuring that AI remains robust and beneficial."
https://openalex.org/W3036458852,Artificial Intelligence and Human Trust in Healthcare: Focus on Clinicians,"{'Artificial': [0], 'intelligence': [1], '(AI)': [2], 'can': [3], 'transform': [4], 'health': [5, 138], 'care': [6, 139], 'practices': [7], 'with': [8, 54], 'its': [9], 'increasing': [10], 'ability': [11], 'to': [12, 52, 78, 119, 154], 'translate': [13], 'the': [14, 27, 36, 55, 68, 83, 105, 131, 161], 'uncertainty': [15, 56], 'and': [16, 32, 43, 61, 74, 85, 140, 147], 'complexity': [17], 'in': [18, 111, 115, 137], 'data': [19], 'into': [20], 'actionable—though': [21], 'imperfect—clinical': [22], 'decisions': [23], 'or': [24], 'suggestions.': [25], 'In': [26, 123], 'evolving': [28], 'relationship': [29], 'between': [30, 57, 145], 'humans': [31], 'AI,': [33], 'trust': [34, 89, 99, 110, 114, 144, 155], 'is': [35, 48, 59], 'one': [37], 'mechanism': [38, 51], 'that': [39, 107, 156], 'shapes': [40], 'clinicians’': [41], 'use': [42], 'adoption': [44], 'of': [45, 87, 134, 163], 'AI.': [46, 148], 'Trust': [47], 'a': [49, 97], 'psychological': [50], 'deal': [53], 'what': [58], 'known': [60], 'unknown.': [62], 'Several': [63], 'research': [64], 'studies': [65], 'have': [66], 'highlighted': [67], 'need': [69], 'for': [70, 167], 'improving': [71], 'AI-based': [72, 101], 'systems': [73, 136], 'enhancing': [75], 'their': [76], 'capabilities': [77], 'help': [79], 'clinicians.': [80], 'However,': [81], 'assessing': [82], 'magnitude': [84], 'impact': [86], 'human': [88, 109], 'on': [90, 128], 'AI': [91, 116, 135, 165], 'technology': [92], 'demands': [93], 'substantial': [94], 'attention.': [95], 'Will': [96], 'clinician': [98], 'an': [100], 'system?': [102], 'What': [103], 'are': [104], 'factors': [106, 142], 'influence': [108], 'AI?': [112], 'Can': [113], 'be': [117, 158], 'optimized': [118], 'improve': [120], 'decision-making': [121], 'processes?': [122], 'this': [124], 'paper,': [125], 'we': [126], 'focus': [127], 'clinicians': [129, 146], 'as': [130], 'primary': [132], 'users': [133], 'present': [141], 'shaping': [143], 'We': [149], 'highlight': [150], 'critical': [151], 'challenges': [152], 'related': [153], 'should': [157], 'considered': [159], 'during': [160], 'development': [162], 'any': [164], 'system': [166], 'clinical': [168], 'use.': [169]}",2020,"['Health care', 'Applications of artificial intelligence', 'Computer science', 'Knowledge management', 'Mechanism (biology)', 'Focus (optics)', 'Artificial intelligence', 'Psychology', 'Data science', 'Optics', 'Epistemology', 'Economics', 'Philosophy', 'Economic growth', 'Physics']","Artificial intelligence (AI) can transform health care practices with its increasing ability to translate the uncertainty and complexity in data into actionable—though imperfect—clinical decisions or suggestions. In the evolving relationship between humans and AI, trust is the one mechanism that shapes clinicians’ use and adoption of AI. Trust is a psychological mechanism to deal with the uncertainty between what is known and unknown. Several research studies have highlighted the need for improving AI-based systems and enhancing their capabilities to help clinicians. However, assessing the magnitude and impact of human trust on AI technology demands substantial attention. Will a clinician trust an AI-based system? What are the factors that influence human trust in AI? Can trust in AI be optimized to improve decision-making processes? In this paper, we focus on clinicians as the primary users of AI systems in health care and present factors shaping trust between clinicians and AI. We highlight critical challenges related to trust that should be considered during the development of any AI system for clinical use."
https://openalex.org/W3014725478,"Review of Artificial Intelligence Techniques in Imaging Data Acquisition, Segmentation, and Diagnosis for COVID-19","{'The': [0], 'pandemic': [1], 'of': [2, 44, 61, 108, 144, 166, 173, 189], 'coronavirus': [3], 'disease': [4, 129], '2019': [5], '(COVID-19)': [6], 'is': [7], 'spreading': [8], 'all': [9], 'over': [10], 'the': [11, 27, 33, 42, 45, 55, 59, 78, 84, 92, 96, 119, 141, 164, 179, 186], 'world.': [12], 'Medical': [13], 'imaging': [14, 46, 63, 97, 146, 191], 'such': [15], 'as': [16], 'X-ray': [17, 111, 169], 'and': [18, 48, 81, 112, 132, 147, 158, 170, 192], 'computed': [19], 'tomography': [20], '(CT)': [21], 'plays': [22], 'an': [23], 'essential': [24], 'role': [25], 'in': [26, 58, 110, 178, 182], 'global': [28], 'fight': [29], 'against': [30, 195], 'COVID-19,': [31, 152], 'whereas': [32], 'recently': [34], 'emerging': [35], 'artificial': [36], 'intelligence': [37], '(AI)': [38], 'technologies': [39], 'further': [40], 'strengthen': [41], 'power': [43], 'tools': [47], 'help': [49, 76, 122], 'medical': [50, 62, 145, 190], 'specialists.': [51], 'We': [52, 160], 'hereby': [53], 'review': [54, 136], 'rapid': [56], 'responses': [57], 'community': [60], '(empowered': [64], 'by': [65, 105], 'AI)': [66], 'toward': [67], 'COVID-19.': [68, 196], 'For': [69], 'example,': [70], 'AI-empowered': [71], 'image': [72, 154], 'acquisition': [73], 'can': [74, 101], 'significantly': [75], 'automate': [77], 'scanning': [79], 'procedure': [80], 'also': [82], 'reshape': [83], 'workflow': [85], 'with': [86, 151, 168], 'minimal': [87], 'contact': [88], 'to': [89, 95, 184], 'patients,': [90], 'providing': [91], 'best': [93], 'protection': [94], 'technicians.': [98], 'Also,': [99], 'AI': [100, 167], 'improve': [102], 'work': [103], 'efficiency': [104], 'accurate': [106], 'delineation': [107], 'infections': [109], 'CT': [113], 'images,': [114], 'facilitating': [115], 'subsequent': [116], 'quantification.': [117], 'Moreover,': [118], 'computer-aided': [120], 'platforms': [121], 'radiologists': [123], 'make': [124], 'clinical': [125], 'decisions,': [126], 'i.e.,': [127], 'for': [128], 'diagnosis,': [130, 157], 'tracking,': [131], 'prognosis.': [133], 'In': [134], 'this': [135], 'paper,': [137], 'we': [138], 'thus': [139], 'cover': [140], 'entire': [142], 'pipeline': [143], 'analysis': [148], 'techniques': [149], 'involved': [150], 'including': [153], 'acquisition,': [155], 'segmentation,': [156], 'follow-up.': [159], 'particularly': [161], 'focus': [162], 'on': [163], 'integration': [165], 'CT,': [171], 'both': [172], 'which': [174], 'are': [175], 'widely': [176], 'used': [177], 'frontline': [180], 'hospitals,': [181], 'order': [183], 'depict': [185], 'latest': [187], 'progress': [188], 'radiology': [193], 'fighting': [194]}",2020,[],"The pandemic of coronavirus disease 2019 (COVID-19) is spreading all over the world. Medical imaging such as X-ray and computed tomography (CT) plays an essential role in the global fight against COVID-19, whereas the recently emerging artificial intelligence (AI) technologies further strengthen the power of the imaging tools and help medical specialists. We hereby review the rapid responses in the community of medical imaging (empowered by AI) toward COVID-19. For example, AI-empowered image acquisition can significantly help automate the scanning procedure and also reshape the workflow with minimal contact to patients, providing the best protection to the imaging technicians. Also, AI can improve work efficiency by accurate delineation of infections in X-ray and CT images, facilitating subsequent quantification. Moreover, the computer-aided platforms help radiologists make clinical decisions, i.e., for disease diagnosis, tracking, and prognosis. In this review paper, we thus cover the entire pipeline of medical imaging and analysis techniques involved with COVID-19, including image acquisition, segmentation, diagnosis, and follow-up. We particularly focus on the integration of AI with X-ray and CT, both of which are widely used in the frontline hospitals, in order to depict the latest progress of medical imaging and radiology fighting against COVID-19."
https://openalex.org/W2902461656,Artificial intelligence-enabled healthcare delivery,"{'Summary': [0], 'In': [1, 161], 'recent': [2], 'years,': [3], 'there': [4, 62], 'has': [5, 63], 'been': [6, 65], 'massive': [7], 'progress': [8], 'in': [9, 34, 57], 'artificial': [10], 'intelligence': [11], '(AI)': [12], 'with': [13, 36, 73], 'the': [14, 39, 58, 69, 94, 108, 128], 'development': [15], 'of': [16, 38, 71, 93, 98, 107, 177], 'deep': [17], 'neural': [18], 'networks,': [19], 'natural': [20], 'language': [21], 'processing,': [22], 'computer': [23], 'vision': [24], 'and': [25, 48, 88, 96, 140, 181], 'robotics.': [26], 'These': [27, 84], 'techniques': [28], 'are': [29, 86], 'now': [30], 'actively': [31], 'being': [32, 44], 'applied': [33], 'healthcare': [35, 141], 'many': [37], 'health': [40, 109, 144, 159], 'service': [41], 'activities': [42], 'currently': [43], 'delivered': [45], 'by': [46, 55], 'clinicians': [47, 82], 'administrators': [49], 'predicted': [50, 182], 'to': [51, 115], 'be': [52, 113, 153, 170], 'taken': [53], 'over': [54], 'AI': [56, 72, 78, 99, 111, 125, 147, 179], 'coming': [59], 'years.': [60], 'However,': [61], 'also': [64], 'exceptional': [66], 'hype': [67], 'about': [68], 'abilities': [70], 'a': [74, 90, 117, 149, 174], 'mistaken': [75], 'notion': [76], 'that': [77], 'will': [79], 'replace': [80], 'human': [81], 'altogether.': [83], 'perspectives': [85], 'inaccurate,': [87], 'if': [89], 'balanced': [91], 'perspective': [92], 'limitations': [95], 'promise': [97], 'is': [100], 'taken,': [101], 'one': [102], 'can': [103, 112, 169], 'gauge': [104], 'which': [105], 'parts': [106], 'system': [110, 145, 168], 'integrated': [114], 'make': [116], 'meaningful': [118], 'impact.': [119], 'The': [120], 'four': [121], 'main': [122], 'areas': [123], 'where': [124, 146], 'would': [126, 131], 'have': [127], 'most': [129], 'influence': [130], 'be:': [132], 'patient': [133, 138], 'administration,': [134], 'clinical': [135], 'decision': [136], 'support,': [137], 'monitoring': [139], 'interventions.': [142], 'This': [143], 'plays': [148], 'central': [150], 'role': [151], 'could': [152], 'termed': [154], 'an': [155], 'AI-enabled': [156], 'or': [157], 'AI-augmented': [158], 'system.': [160], 'this': [162, 167], 'article,': [163], 'we': [164], 'discuss': [165], 'how': [166], 'developed': [171], 'based': [172], 'on': [173], 'realistic': [175], 'assessment': [176], 'current': [178], 'technologies': [180], 'developments.': [183]}",2018,"['Artificial intelligence', 'Computer science', 'Health care', 'Applications of artificial intelligence', 'Robotics', 'Clinical decision support system', 'Data science', 'Decision support system', 'Medicine', 'Robot', 'Economic growth', 'Economics']","Summary In recent years, there has been massive progress in artificial intelligence (AI) with the development of deep neural networks, natural language processing, computer vision and robotics. These techniques are now actively being applied in healthcare with many of the health service activities currently being delivered by clinicians and administrators predicted to be taken over by AI in the coming years. However, there has also been exceptional hype about the abilities of AI with a mistaken notion that AI will replace human clinicians altogether. These perspectives are inaccurate, and if a balanced perspective of the limitations and promise of AI is taken, one can gauge which parts of the health system AI can be integrated to make a meaningful impact. The four main areas where AI would have the most influence would be: patient administration, clinical decision support, patient monitoring and healthcare interventions. This health system where AI plays a central role could be termed an AI-enabled or AI-augmented health system. In this article, we discuss how this system can be developed based on a realistic assessment of current AI technologies and predicted developments."
https://openalex.org/W2897620540,"Artificial intelligence, machine learning and health systems","{'AI': [0], 'is': [1, 22, 32], 'a': [2, 33], 'broad': [3, 34], 'discipline': [4], 'that': [5, 12, 36], 'aims': [6], 'to': [7, 25, 27], 'understand': [8], 'and': [9], 'design': [10], 'systems': [11], 'display': [13], 'properties': [14], 'of': [15, 20], 'intelligence': [16], '(Box': [17], '1)': [18], '-emblematic': [19], 'which': [21], 'the': [23], 'ability': [24], 'learn:': [26], 'derive': [28], 'knowledge': [29], 'from': [30], 'data.This': [31], 'definition': [35], 'arguably': [37], 'has': [38], 'some': [39], 'cross': [40], 'over': [41], 'with': [42], 'existing': [43], 'statistical': [44], 'techniques': [45], '[6].The': [46], 'recent': [47], 'explosion': [48], 'in': [49]}",2018,"['Data science', 'Computer science', 'Artificial intelligence', 'Machine learning']",AI is a broad discipline that aims to understand and design systems that display properties of intelligence (Box 1) -emblematic of which is the ability to learn: to derive knowledge from data.This is a broad definition that arguably has some cross over with existing statistical techniques [6].The recent explosion in
https://openalex.org/W2022638422,Uncertainty in artificial intelligence,"{'The': [0], 'first': [1], 'conference': [2], 'on': [3, 22], 'Uncertainty': [4], 'in': [5, 10], 'Artificial': [6], 'Intelligence': [7], 'was': [8, 75], 'held': [9, 46], '1985': [11], 'by': [12], 'a': [13, 31, 67, 88], 'group': [14], 'of': [15, 25, 37, 54, 84], 'people': [16], 'who': [17, 70], 'felt': [18], 'that': [19, 47, 72], 'their': [20], 'views': [21], 'the': [23, 35, 38, 42, 52, 80], 'use': [24], 'probability': [26, 73], 'theory': [27, 74], 'were': [28], 'not': [29, 79], 'receiving': [30], 'fair': [32], 'hearing': [33], 'from': [34], 'rest': [36], 'Al': [39], 'community.': [40], 'At': [41], 'time,': [43], 'mainstream': [44], 'opinion': [45], 'computational': [48], 'complexity': [49], 'of,': [50], 'and': [51], 'amount': [53], 'data': [55], 'required': [56], 'by,': [57], 'probabilistic': [58], 'methods': [59], 'made': [60], 'them': [61], 'inappropriate': [62], 'for': [63], 'realistic': [64], 'applications.': [65], 'As': [66], 'result,': [68], 'those': [69], 'claimed': [71], 'an': [76], 'adequate,': [77, 82], 'if': [78], 'only': [81], 'method': [83], 'handling': [85], 'uncertainty': [86], 'received': [87], 'somewhat': [89], 'frosty': [90], 'reception.': [91]}",1994,"['Rest (music)', 'Probabilistic logic', 'Mainstream', 'Computer science', 'Artificial intelligence', 'Probability theory', 'Statistics', 'Mathematics', 'Cardiology', 'Medicine', 'Theology', 'Philosophy']","The first conference on Uncertainty in Artificial Intelligence was held in 1985 by a group of people who felt that their views on the use of probability theory were not receiving a fair hearing from the rest of the Al community. At the time, mainstream opinion held that computational complexity of, and the amount of data required by, probabilistic methods made them inappropriate for realistic applications. As a result, those who claimed that probability theory was an adequate, if not the only adequate, method of handling uncertainty received a somewhat frosty reception."
https://openalex.org/W2924260403,Toward understanding the impact of artificial intelligence on labor,"{'Rapid': [0], 'advances': [1], 'in': [2, 52, 163, 196, 206, 223], 'artificial': [3], 'intelligence': [4], '(AI)': [5], 'and': [6, 19, 36, 65, 95, 133, 136, 148, 154, 166, 189], 'automation': [7, 20, 49, 96], 'technologies': [8, 142], 'have': [9], 'the': [10, 23, 31, 74, 84, 91, 98, 105, 111, 116, 164, 191, 203], 'potential': [11], 'to': [12, 45, 72, 175, 186, 220, 225], 'significantly': [13], 'disrupt': [14], 'labor': [15], 'markets.': [16], 'While': [17], 'AI': [18, 94], 'can': [21, 29], 'augment': [22], 'productivity': [24], 'of': [25, 55, 61, 76, 93, 100, 107, 113, 119, 122, 126, 139, 169, 194], 'some': [26, 46], 'workers,': [27], 'they': [28], 'replace': [30], 'work': [32, 114, 195], 'done': [33], 'by': [34], 'others': [35], 'will': [37, 182], 'likely': [38], 'transform': [39], 'almost': [40], 'all': [41], 'occupations': [42], 'at': [43], 'least': [44], 'degree.': [47], 'Rising': [48], 'is': [50], 'happening': [51], 'a': [53, 66, 213], 'period': [54], 'growing': [56], 'economic': [57, 146], 'inequality,': [58], 'raising': [59], 'fears': [60], 'mass': [62], 'technological': [63, 77, 199, 208], 'unemployment': [64], 'renewed': [67], 'call': [68], 'for': [69], 'policy': [70], 'efforts': [71], 'address': [73], 'consequences': [75], 'change.': [78], 'In': [79], 'this': [80], 'paper': [81], 'we': [82, 210], 'discuss': [83], 'barriers': [85, 103, 160], 'that': [86, 216], 'inhibit': [87], 'scientists': [88], 'from': [89], 'measuring': [90], 'effects': [92], 'on': [97, 177, 218], 'future': [99], 'work.': [101], 'These': [102, 180], 'include': [104], 'lack': [106, 121], 'high-quality': [108], 'data': [109, 176], 'about': [110], 'nature': [112], '(e.g.,': [115, 130, 151], 'dynamic': [117], 'requirements': [118], 'occupations),': [120], 'empirically': [123], 'informed': [124], 'models': [125], 'key': [127], 'microlevel': [128], 'processes': [129], 'skill': [131], 'substitution': [132], 'human–machine': [134], 'complementarity),': [135], 'insufficient': [137], 'understanding': [138], 'how': [140], 'cognitive': [141], 'interact': [143], 'with': [144, 198], 'broader': [145], 'dynamics': [147], 'institutional': [149], 'mechanisms': [150], 'urban': [152], 'migration': [153], 'international': [155], 'trade': [156], 'policy).': [157], 'Overcoming': [158], 'these': [159], 'requires': [161], 'improvements': [162, 181], 'longitudinal': [165], 'spatial': [167], 'resolution': [168], 'data,': [170], 'as': [171, 173], 'well': [172], 'refinements': [174], 'workplace': [178], 'skills.': [179], 'enable': [183], 'multidisciplinary': [184], 'research': [185], 'quantitatively': [187], 'monitor': [188], 'predict': [190], 'complex': [192], 'evolution': [193], 'tandem': [197], 'progress.': [200], 'Finally,': [201], 'given': [202], 'fundamental': [204], 'uncertainty': [205], 'predicting': [207], 'change,': [209], 'recommend': [211], 'developing': [212], 'decision': [214], 'framework': [215], 'focuses': [217], 'resilience': [219], 'unexpected': [221], 'scenarios': [222], 'addition': [224], 'general': [226], 'equilibrium': [227], 'behavior.': [228]}",2019,"['Technological change', 'Automation', 'Productivity', 'Unemployment', 'Emerging technologies', 'Complementarity (molecular biology)', 'Work (physics)', 'Multidisciplinary approach', 'Computer science', 'Economics', 'Risk analysis (engineering)', 'Business', 'Artificial intelligence', 'Engineering', 'Sociology', 'Economic growth', 'Mechanical engineering', 'Social science', 'Biology', 'Genetics']","Rapid advances in artificial intelligence (AI) and automation technologies have the potential to significantly disrupt labor markets. While AI and automation can augment the productivity of some workers, they can replace the work done by others and will likely transform almost all occupations at least to some degree. Rising automation is happening in a period of growing economic inequality, raising fears of mass technological unemployment and a renewed call for policy efforts to address the consequences of technological change. In this paper we discuss the barriers that inhibit scientists from measuring the effects of AI and automation on the future of work. These barriers include the lack of high-quality data about the nature of work (e.g., the dynamic requirements of occupations), lack of empirically informed models of key microlevel processes (e.g., skill substitution and human–machine complementarity), and insufficient understanding of how cognitive technologies interact with broader economic dynamics and institutional mechanisms (e.g., urban migration and international trade policy). Overcoming these barriers requires improvements in the longitudinal and spatial resolution of data, as well as refinements to data on workplace skills. These improvements will enable multidisciplinary research to quantitatively monitor and predict the complex evolution of work in tandem with technological progress. Finally, given the fundamental uncertainty in predicting technological change, we recommend developing a decision framework that focuses on resilience to unexpected scenarios in addition to general equilibrium behavior."
https://openalex.org/W2887311010,Computer vision and artificial intelligence in precision agriculture for grain crops: A systematic review,"{'Made': [0], 'available': [1], 'in': [2], 'DSpace': [3], 'on': [4], '2018-11-10T00:20:55Z': [5], '(GMT).': [6], 'No.': [7], 'of': [8], 'bitstreams:': [9], '1\\nID444052008CompElectroAgricv153p69.pdf:': [10], '264227': [11], 'bytes,': [12], 'checksum:': [13], '4a8890b403aaa5368c9d63dfd8e85538': [14], '(MD5)\\n': [15], 'Previous': [16], 'issue': [17], 'date:': [18], '2018-11-09': [19]}",2018,"['Context (archaeology)', 'Artificial intelligence', 'Agriculture', 'Precision agriculture', 'Computer science', 'Machine vision', 'Production (economics)', 'Food processing', 'Data science', 'Image processing', 'Agricultural engineering', 'Machine learning', 'Engineering', 'Image (mathematics)', 'Geography', 'Macroeconomics', 'Food science', 'Economics', 'Archaeology', 'Chemistry']","Made available in DSpace on 2018-11-10T00:20:55Z (GMT). No. of bitstreams: 1\nID444052008CompElectroAgricv153p69.pdf: 264227 bytes, checksum: 4a8890b403aaa5368c9d63dfd8e85538 (MD5)\n Previous issue date: 2018-11-09"
https://openalex.org/W2574978968,DeepStack: Expert-level artificial intelligence in heads-up no-limit poker,"{'Computer': [0], 'code': [1], 'based': [2], 'on': [3], 'continual': [4], 'problem': [5], 're-solving': [6], 'beats': [7], 'human': [8], 'professional': [9], 'poker': [10], 'players': [11], 'at': [12], 'a': [13], 'two-player': [14], 'variant': [15], 'of': [16], 'poker.': [17]}",2017,"['Perfect information', 'Exploit', 'Computer science', 'Imperfect', 'Artificial intelligence', 'Intuition', 'Computation', 'Limit (mathematics)', 'Machine learning', 'Cognitive science', 'Mathematical economics', 'Algorithm', 'Mathematics', 'Psychology', 'Computer security', 'Mathematical analysis', 'Linguistics', 'Philosophy']",Computer code based on continual problem re-solving beats human professional poker players at a two-player variant of poker.
https://openalex.org/W3130894836,"Artificial intelligence, robotics, advanced technologies and human resource management: a systematic review","{'Although': [0], 'academic': [1, 48], 'production': [2], 'in': [3, 28, 78, 177], 'intelligent': [4, 51, 111], 'automation': [5, 52, 112], '(e.g.': [6], 'artificial': [7, 98], 'intelligence,': [8, 99], 'robotics)': [9], 'has': [10, 146], 'grown': [11], 'rapidly,': [12], 'we': [13, 93], 'still': [14], 'lack': [15], 'a': [16, 69, 115, 136], 'comprehensive': [17], 'understanding': [18], 'of': [19, 22, 25, 72, 143], 'the': [20, 23, 47, 79, 181], 'impacts': [21], 'utilization': [24], 'these': [26, 144, 175], 'technologies': [27, 104, 113, 145], 'human': [29], 'resource': [30], 'management': [31, 86, 90], '(HRM)': [32], 'at': [33, 135], 'an': [34], 'organizational': [35], '(firms)': [36], 'and': [37, 55, 64, 88, 101, 121, 138, 160, 163, 169, 186, 188], 'individual': [38], '(employees)': [39], 'level.': [40, 140], 'This': [41, 172], 'study': [42, 173], 'therefore': [43], 'aims': [44], 'to': [45, 56, 63, 118, 149, 184], 'systematize': [46], 'inputs': [49], 'on': [50, 151], 'so': [53], 'far': [54], 'clarify': [57], 'what': [58], 'are': [59], 'its': [60], 'main': [61, 182], 'contributions': [62, 183], 'challenges': [65, 134], 'for': [66, 129, 190], 'HRM.': [67], 'In': [68], 'systematic': [70], 'search': [71], '13,136': [73], 'potentially': [74], 'relevant': [75], 'studies': [76], 'published': [77], 'top': [80], 'HRM,': [81], 'international': [82], 'business': [83], '(IB),': [84], 'general': [85], '(GM)': [87], 'information': [89], '(IM)': [91], 'journals,': [92], 'found': [94], '45': [95], 'articles': [96], 'studying': [97], 'robotics': [100], 'other': [102], 'advanced': [103], 'within': [105], 'HRM': [106, 130, 152, 164], 'settings.': [107], 'Results': [108], 'show': [109], 'that': [110], 'constitute': [114], 'new': [116], 'approach': [117], 'managing': [119], 'employees': [120], 'enhancing': [122], 'firm': [123], 'performance,': [124], 'thus': [125], 'offering': [126], 'several': [127], 'opportunities': [128], 'but': [131], 'also': [132], 'considerable': [133], 'technological': [137], 'ethical': [139], 'The': [141], 'impact': [142], 'been': [147], 'identified': [148], 'concentrate': [150], 'strategies,': [153], 'namely,': [154, 166], 'job': [155, 170], 'replacement,': [156], 'human-robot/AI': [157], 'collaboration,': [158], 'decision-making': [159], 'learning': [161], 'opportunities,': [162], 'activities,': [165], 'recruiting,': [167], 'training': [168], 'performance.': [171], 'discusses': [174], 'shifts': [176], 'detail,': [178], 'along': [179], 'with': [180], 'theory': [185], 'practice': [187], 'directions': [189], 'future': [191], 'research.': [192]}",2021,"['Automation', 'Knowledge management', 'Human resource management', 'Artificial intelligence', 'Robotics', 'Human resources', 'Robot', 'Applications of artificial intelligence', 'Computer science', 'Engineering management', 'Business', 'Engineering', 'Management', 'Economics', 'Mechanical engineering']","Although academic production in intelligent automation (e.g. artificial intelligence, robotics) has grown rapidly, we still lack a comprehensive understanding of the impacts of the utilization of these technologies in human resource management (HRM) at an organizational (firms) and individual (employees) level. This study therefore aims to systematize the academic inputs on intelligent automation so far and to clarify what are its main contributions to and challenges for HRM. In a systematic search of 13,136 potentially relevant studies published in the top HRM, international business (IB), general management (GM) and information management (IM) journals, we found 45 articles studying artificial intelligence, robotics and other advanced technologies within HRM settings. Results show that intelligent automation technologies constitute a new approach to managing employees and enhancing firm performance, thus offering several opportunities for HRM but also considerable challenges at a technological and ethical level. The impact of these technologies has been identified to concentrate on HRM strategies, namely, job replacement, human-robot/AI collaboration, decision-making and learning opportunities, and HRM activities, namely, recruiting, training and job performance. This study discusses these shifts in detail, along with the main contributions to theory and practice and directions for future research."
https://openalex.org/W4307486628,Understanding the potential applications of Artificial Intelligence in Agriculture Sector,"{'Artificial': [0], 'Intelligence': [1], '(AI)': [2], 'has': [3, 234], 'been': [4], 'extensively': [5], 'applied': [6], 'in': [7, 99, 210, 283, 295, 301, 322], 'farming': [8], 'recently.': [9], 'To': [10], 'cultivate': [11], 'healthier': [12], 'crops,': [13], 'manage': [14], 'pests,': [15], 'monitor': [16], 'soil': [17, 101, 251], 'and': [18, 25, 89, 140, 164, 176, 181, 197, 207, 212, 222, 230, 250, 256, 292, 303, 315], 'growing': [19], 'conditions,': [20], 'analyse': [21], 'data': [22, 72, 196, 276], 'for': [23, 47, 64, 187, 286], 'farmers,': [24], 'enhance': [26, 173], 'other': [27], 'management': [28], 'activities': [29], 'of': [30, 117, 161, 280, 299, 320], 'the': [31, 35, 51, 61, 95, 108, 115, 118, 125, 136, 141, 159, 165, 217, 231, 237, 261, 278, 281, 317], 'food': [32, 213], 'supply': [33], 'chain,': [34], 'agriculture': [36, 238], 'sector': [37], 'is': [38], 'turning': [39], 'to': [40, 49, 54, 93, 113, 128, 169, 172, 245], 'AI': [41, 57, 97, 103, 120, 186, 221, 232, 291, 300, 309, 321], 'technology.': [42], 'It': [43, 69], 'makes': [44], 'it': [45], 'challenging': [46], 'farmers': [48, 59, 80, 105, 123, 155, 191], 'choose': [50, 60, 124], 'ideal': [52], 'time': [53, 92, 127], 'plant': [55, 129], 'seeds.': [56, 131], 'helps': [58, 104], 'optimum': [62], 'seed': [63], 'a': [65, 150], 'particular': [66], 'weather': [67, 74], 'scenario.': [68], 'also': [70], 'offers': [71], 'on': [73, 158, 185, 277], 'forecasts.': [75], 'AI-powered': [76, 146, 272], 'solutions': [77], 'will': [78, 201], 'help': [79, 122, 267], 'produce': [81], 'more': [82], 'with': [83, 156], 'fewer': [84], 'resources,': [85], 'increase': [86, 114], 'crop': [87, 249, 269], 'quality,': [88], 'hasten': [90], 'product': [91], 'reach': [94], 'market.': [96], 'aids': [98], 'understanding': [100], 'qualities.': [102], 'by': [106, 308], 'suggesting': [107], 'nutrients': [109, 166], 'they': [110], 'should': [111], 'apply': [112], 'quality': [116, 175], 'soil.': [119], 'can': [121, 134, 192, 266], 'optimal': [126], 'their': [130, 162], 'Intelligent': [132], 'equipment': [133], 'calculate': [135], 'spacing': [137], 'between': [138], 'seeds': [139], 'maximum': [142], 'planting': [143], 'depth.': [144], 'An': [145], 'system': [147, 153], 'known': [148], 'as': [149], 'health': [151, 160, 252, 279], 'monitoring': [152, 247], 'provides': [154], 'information': [157], 'crops': [163, 282], 'that': [167, 200, 265], 'need': [168, 294], 'be': [170], 'given': [171], 'yield': [174], 'quantity.': [177], 'This': [178, 288], 'study': [179], 'identifies': [180], 'analyses': [182], 'relevant': [183], 'articles': [184], 'Agriculture.': [188, 296], 'Using': [189], 'AI,': [190], 'now': [193, 235], 'access': [194], 'advanced': [195], 'analytics': [198], 'tools': [199], 'foster': [202], 'better': [203], 'farming,': [204], 'improve': [205], 'efficiencies,': [206], 'reduce': [208], 'waste': [209], 'biofuel': [211], 'production': [214], 'while': [215], 'minimising': [216], 'negative': [218], 'environmental': [219], 'impacts.': [220], 'Machine': [223], 'Learning': [224], '(ML)': [225], 'have': [226], 'transformed': [227], 'various': [228], 'industries,': [229], 'wave': [233], 'reached': [236], 'sector.': [239], 'Companies': [240], 'are': [241, 260, 310], 'developing': [242], 'several': [243], 'technologies': [244, 264, 273], 'make': [246], ""farmers'"": [248], 'easier.': [253], 'Hyperspectral': [254], 'imaging': [255], '3D': [257], 'laser': [258], 'scanning': [259], 'leading': [262], 'AI-based': [263], 'ensure': [268], 'health.': [270], 'These': [271], 'collect': [274], 'precise': [275], 'greater': [284], 'volume': [285], 'analysis.': [287], 'paper': [289], 'studied': [290], 'its': [293], 'The': [297], 'process': [298], 'Agriculture': [302, 305], 'some': [304], 'parameters': [306], 'monitored': [307], 'briefed.': [311], 'Finally,': [312], 'we': [313], 'identified': [314], 'discussed': [316], 'significant': [318], 'applications': [319], 'agriculture.': [323]}",2022,"['Agriculture', 'Agricultural engineering', 'Business', 'Quality (philosophy)', 'Product (mathematics)', 'Production (economics)', 'Computer science', 'Agricultural science', 'Environmental science', 'Engineering', 'Mathematics', 'Economics', 'Macroeconomics', 'Biology', 'Ecology', 'Geometry', 'Philosophy', 'Epistemology']","Artificial Intelligence (AI) has been extensively applied in farming recently. To cultivate healthier crops, manage pests, monitor soil and growing conditions, analyse data for farmers, and enhance other management activities of the food supply chain, the agriculture sector is turning to AI technology. It makes it challenging for farmers to choose the ideal time to plant seeds. AI helps farmers choose the optimum seed for a particular weather scenario. It also offers data on weather forecasts. AI-powered solutions will help farmers produce more with fewer resources, increase crop quality, and hasten product time to reach the market. AI aids in understanding soil qualities. AI helps farmers by suggesting the nutrients they should apply to increase the quality of the soil. AI can help farmers choose the optimal time to plant their seeds. Intelligent equipment can calculate the spacing between seeds and the maximum planting depth. An AI-powered system known as a health monitoring system provides farmers with information on the health of their crops and the nutrients that need to be given to enhance yield quality and quantity. This study identifies and analyses relevant articles on AI for Agriculture. Using AI, farmers can now access advanced data and analytics tools that will foster better farming, improve efficiencies, and reduce waste in biofuel and food production while minimising the negative environmental impacts. AI and Machine Learning (ML) have transformed various industries, and the AI wave has now reached the agriculture sector. Companies are developing several technologies to make monitoring farmers' crop and soil health easier. Hyperspectral imaging and 3D laser scanning are the leading AI-based technologies that can help ensure crop health. These AI-powered technologies collect precise data on the health of the crops in greater volume for analysis. This paper studied AI and its need in Agriculture. The process of AI in Agriculture and some Agriculture parameters monitored by AI are briefed. Finally, we identified and discussed the significant applications of AI in agriculture."
https://openalex.org/W3177617320,The Clinician and Dataset Shift in Artificial Intelligence,"{'Dataset': [0], 'Shift': [1], 'in': [2, 19], 'Clinical': [3], 'Trials': [4], 'This': [5, 22], 'letter': [6], 'outlines': [7], 'how': [8], 'to': [9], 'identify,': [10], 'and': [11], 'potentially': [12], 'mitigate,': [13], 'common': [14], 'sources': [15], 'of': [16], '“dataset': [17], 'shift”': [18], 'machine-learning': [20], 'systems.': [21], 'occurs': [23], 'when': [24], 'the': [25], 'model': [26], '“training': [27], '...': [28]}",2021,"['Paradigm shift', 'Artificial intelligence', 'Computer science', 'Machine learning', 'Epistemology', 'Philosophy']","Dataset Shift in Clinical Trials This letter outlines how to identify, and potentially mitigate, common sources of “dataset shift” in machine-learning systems. This occurs when the model “training ..."
https://openalex.org/W4220863497,Quo vadis artificial intelligence?,"{'Abstract': [0], 'The': [1, 20], 'study': [2], 'of': [3, 12, 75, 91, 97, 108, 170, 172, 188, 205], 'artificial': [4], 'intelligence': [5], '(AI)': [6], 'has': [7, 44, 123], 'been': [8], 'a': [9, 160], 'continuous': [10], 'endeavor': [11], 'scientists': [13], 'and': [14, 58, 147, 177, 196, 207], 'engineers': [15], 'for': [16, 102], 'over': [17], '65': [18], 'years.': [19], 'simple': [21], 'contention': [22], 'is': [23, 70, 140], 'that': [24, 62], 'human-created': [25], 'machines': [26], 'can': [27, 35], 'do': [28], 'more': [29, 60], 'than': [30], 'just': [31], 'labor-intensive': [32], 'work;': [33], 'they': [34], 'develop': [36], 'human-like': [37], 'intelligence.': [38], 'Being': [39], 'aware': [40], 'or': [41], 'not,': [42], 'AI': [43, 69, 86, 109, 122, 175, 179, 189, 206], 'penetrated': [45], 'into': [46], 'our': [47], 'daily': [48], 'lives,': [49], 'playing': [50], 'novel': [51], 'roles': [52], 'in': [53, 94, 182, 190, 209], 'industry,': [54], 'healthcare,': [55], 'transportation,': [56], 'education,': [57], 'many': [59, 95], 'areas': [61], 'are': [63, 198], 'close': [64], 'to': [65, 72, 79, 88, 135, 142, 184, 193], 'the': [66, 76, 89, 106, 119, 144, 168, 174, 178, 185, 191, 202, 210], 'general': [67], 'public.': [68], 'believed': [71], 'be': [73], 'one': [74], 'major': [77], 'drives': [78], 'change': [80], 'socio-economical': [81], 'lives.': [82], 'In': [83, 153], 'another': [84], 'aspect,': [85], 'contributes': [87], 'advancement': [90], 'state-of-the-art': [92], 'technologies': [93], 'fields': [96], 'study,': [98], 'as': [99, 110], 'helpful': [100], 'tools': [101, 176], 'groundbreaking': [103], 'research.': [104], 'However,': [105], 'prosperity': [107], 'we': [111, 156], 'witness': [112], 'today': [113], 'was': [114], 'not': [115], 'established': [116], 'smoothly.': [117], 'During': [118], 'past': [120], 'decades,': [121], 'struggled': [124], 'through': [125], 'historical': [126, 161], 'stages': [127], 'with': [128], 'several': [129], 'winters.': [130], 'Therefore,': [131], 'at': [132], 'this': [133, 154], 'juncture,': [134], 'enlighten': [136], 'future': [137], 'development,': [138], 'it': [139], 'time': [141], 'discuss': [143, 158], 'past,': [145], 'present,': [146], 'have': [148], 'an': [149], 'outlook': [150], 'on': [151, 167], 'AI.': [152], 'article,': [155], 'will': [157], 'from': [159], 'perspective': [162], 'how': [163], 'challenges': [164], 'were': [165], 'faced': [166], 'path': [169], 'revolution': [171], 'both': [173], 'systems.': [180], 'Especially,': [181], 'addition': [183], 'technical': [186], 'development': [187], 'short': [192], 'mid-term,': [194], 'thoughts': [195], 'insights': [197], 'also': [199], 'presented': [200], 'regarding': [201], 'symbiotic': [203], 'relationship': [204], 'humans': [208], 'long': [211], 'run.': [212]}",2022,"['Prosperity', 'Witness', 'Artificial intelligence', 'Applications of artificial intelligence', 'Computer science', 'Engineering ethics', 'Political science', 'Engineering', 'Law']","Abstract The study of artificial intelligence (AI) has been a continuous endeavor of scientists and engineers for over 65 years. The simple contention is that human-created machines can do more than just labor-intensive work; they can develop human-like intelligence. Being aware or not, AI has penetrated into our daily lives, playing novel roles in industry, healthcare, transportation, education, and many more areas that are close to the general public. AI is believed to be one of the major drives to change socio-economical lives. In another aspect, AI contributes to the advancement of state-of-the-art technologies in many fields of study, as helpful tools for groundbreaking research. However, the prosperity of AI as we witness today was not established smoothly. During the past decades, AI has struggled through historical stages with several winters. Therefore, at this juncture, to enlighten future development, it is time to discuss the past, present, and have an outlook on AI. In this article, we will discuss from a historical perspective how challenges were faced on the path of revolution of both the AI tools and the AI systems. Especially, in addition to the technical development of AI in the short to mid-term, thoughts and insights are also presented regarding the symbiotic relationship of AI and humans in the long run."
https://openalex.org/W2174287231,Generality in artificial intelligence,"{'My': [0], '1971': [1, 156], 'Turing': [2], 'Award': [3], 'Lecture': [4], 'was': [5, 24, 59, 153], 'entitled': [6], '""Generality': [7], 'in': [8, 19, 33, 91, 109, 155, 159, 209, 308, 313, 330, 343, 364, 374], 'Artificial': [9], 'Intelligence.""': [10], 'The': [11, 179], 'topic': [12], 'turned': [13], 'out': [14], 'to': [15, 26, 46, 69, 74, 140, 148, 188, 224, 236, 269, 284, 305, 323, 336], 'have': [16, 43, 47, 104], 'been': [17, 44, 207], 'overambitious': [18], 'that': [20, 39, 64, 161, 184, 244, 251, 331], 'I': [21, 23, 66, 389], 'discovered': [22], 'unable': [25], 'put': [27], 'my': [28, 49, 61, 141, 352, 391], 'thoughts': [29], 'on': [30, 115, 300], 'the': [31, 72, 87, 189, 201, 217, 253, 272, 290, 302, 320, 332, 369], 'subject': [32], 'a': [34, 123, 137, 166, 185, 192, 196, 238, 260, 265, 279, 309, 347, 355, 365], 'satisfactory': [35], 'written': [36], 'form': [37], 'at': [38, 63, 136], 'time.': [40, 65], 'It': [41, 152, 170], 'would': [42, 262, 267], 'better': [45], 'reviewed': [48], 'previous': [50], 'work': [51], 'rather': [52, 145], 'than': [53, 146], 'attempt': [54], 'something': [55], 'new,': [56], 'but': [57, 118, 213], 'such': [58, 116, 259], 'not': [60, 107, 298], 'custom': [62], 'am': [67], 'grateful': [68], 'ACM': [70], 'for': [71, 78, 84, 129, 346, 357, 362, 380], 'opportunity': [73], 'try': [75], 'again.': [76], 'Unfortunately': [77], 'our': [79], 'science,': [80], 'although': [81, 101], 'perhaps': [82], 'fortunately': [83], 'this': [85], 'project,': [86], 'problem': [88, 371], 'of': [89, 127, 168, 191, 216, 241, 274, 326, 372, 393], 'generality': [90, 327, 373, 382], 'artificial': [92], 'intelligence': [93], '(AI)': [94], 'is': [95, 120, 171, 183, 231, 304, 368], 'almost': [96], 'as': [97, 99], 'unsolved': [98], 'ever,': [100], 'we': [102, 318, 334], 'now': [103], 'many': [105, 176], 'ideas': [106, 379], 'available': [108], '1971.': [110, 388], 'This': [111, 296], 'paper': [112], 'relies': [113], 'heavily': [114], 'ideas,': [117], 'it': [119], 'far': [121], 'from': [122, 165], 'full': [124], '1987': [125], 'survey': [126], 'approaches': [128], 'achieving': [130, 381], 'generality.': [131, 169], 'Ideas': [132], 'are': [133, 175, 220, 340, 377], 'therefore': [134], 'discussed': [135], 'length': [138], 'proportional': [139], 'familiarity': [142], 'with': [143, 200, 256], 'them': [144], 'according': [147], 'some': [149, 314, 378], 'objective': [150], 'criterion.': [151], 'obvious': [154], 'and': [157, 289, 294, 386], 'even': [158, 221], '1958': [160], 'AI': [162], 'programs': [163], 'suffered': [164], 'lack': [167, 325], 'still': [172], 'obvious;': [173], 'there': [174], 'more': [177], 'details.': [178], 'first': [180], 'gross': [181], 'symptom': [182, 230], 'small': [186, 214], 'addition': [187], 'idea': [190], 'program': [193, 250], 'often': [194], 'involves': [195], 'complete': [197], 'rewrite': [198], 'beginning': [199], 'data': [202, 211], 'structures.': [203], 'Some': [204], 'progress': [205], 'has': [206], 'made': [208], 'modularizing': [210], 'structures,': [212], 'modifications': [215], 'search': [218], 'strategies': [219], 'less': [222], 'likely': [223], 'be': [225, 246, 282, 306], 'accomplished': [226], 'without': [227], 'rewriting.': [228], 'Another': [229], 'no': [232], 'one': [233], 'knows': [234], 'how': [235], 'make': [237], 'general': [239, 348, 359, 366], 'database': [240, 261, 367], 'commonsense': [242, 338, 349, 360], 'knowledge': [243, 303, 339, 361], 'could': [245], 'used': [247], 'by': [248], 'any': [249], 'needed': [252], 'knowledge.': [254], 'Along': [255], 'other': [257, 315], 'information,': [258], 'contain': [263], 'what': [264, 278], 'robot': [266], 'need': [268], 'know': [270, 285], 'about': [271, 286, 292], 'effects': [273], 'moving': [275], 'objects': [276], 'around,': [277], 'person': [280], 'can': [281], 'expected': [283], 'his': [287], 'family,': [288], 'facts': [291], 'buying': [293], 'selling.': [295], 'does': [297], 'depend': [299], 'whether': [301], 'expressed': [307], 'logical': [310], 'language': [311, 356], 'or': [312], 'formalism.': [316], 'When': [317], 'take': [319], 'logic': [321], 'approach': [322], 'AI,': [324], 'shows': [328], 'up': [329], 'axioms': [333], 'devise': [335], 'express': [337], 'too': [341], 'restricted': [342], 'their': [344], 'applicability': [345], 'database.': [350], 'In': [351], 'opinion,': [353], 'getting': [354], 'expressing': [358], 'inclusion': [363], 'key': [370], 'AI.': [375], 'Here': [376], 'proposed': [383], 'both': [384], 'before': [385], 'after': [387], 'repeat': [390], 'disclaimer': [392], 'comprehensiveness.': [394]}",1987,"['Generality', 'Computer science', 'Turing', 'Artificial intelligence', 'Artificial general intelligence', 'Rewriting', 'Cognitive science', 'Programming language', 'Psychology', 'Psychotherapist']","My 1971 Turing Award Lecture was entitled ""Generality in Artificial Intelligence."" The topic turned out to have been overambitious in that I discovered I was unable to put my thoughts on the subject in a satisfactory written form at that time. It would have been better to have reviewed my previous work rather than attempt something new, but such was not my custom at that time. I am grateful to ACM for the opportunity to try again. Unfortunately for our science, although perhaps fortunately for this project, the problem of generality in artificial intelligence (AI) is almost as unsolved as ever, although we now have many ideas not available in 1971. This paper relies heavily on such ideas, but it is far from a full 1987 survey of approaches for achieving generality. Ideas are therefore discussed at a length proportional to my familiarity with them rather than according to some objective criterion. It was obvious in 1971 and even in 1958 that AI programs suffered from a lack of generality. It is still obvious; there are many more details. The first gross symptom is that a small addition to the idea of a program often involves a complete rewrite beginning with the data structures. Some progress has been made in modularizing data structures, but small modifications of the search strategies are even less likely to be accomplished without rewriting. Another symptom is no one knows how to make a general database of commonsense knowledge that could be used by any program that needed the knowledge. Along with other information, such a database would contain what a robot would need to know about the effects of moving objects around, what a person can be expected to know about his family, and the facts about buying and selling. This does not depend on whether the knowledge is to be expressed in a logical language or in some other formalism. When we take the logic approach to AI, lack of generality shows up in that the axioms we devise to express commonsense knowledge are too restricted in their applicability for a general commonsense database. In my opinion, getting a language for expressing general commonsense knowledge for inclusion in a general database is the key problem of generality in AI. Here are some ideas for achieving generality proposed both before and after 1971. I repeat my disclaimer of comprehensiveness."
https://openalex.org/W3200759624,Privacy and artificial intelligence: challenges for protecting health information in a new era,"{'Abstract': [0], 'Background': [1], 'Advances': [2], 'in': [3, 54, 87, 99, 123, 186, 212, 216], 'healthcare': [4], 'artificial': [5], 'intelligence': [6], '(AI)': [7], 'are': [8, 210], 'occurring': [9], 'rapidly': [10], 'and': [11, 27, 44, 57, 69, 82, 128, 141, 150, 219, 233, 235, 244], 'there': [12, 106], 'is': [13], 'a': [14, 49, 213], 'growing': [15], 'discussion': [16], 'about': [17], 'managing': [18], 'its': [19], 'development.': [20], 'Many': [21], 'AI': [22, 38, 96], 'technologies': [23, 225], 'end': [24], 'up': [25], 'owned': [26], 'controlled': [28], 'by': [29, 138], 'private': [30, 88, 206], 'entities.': [31], 'The': [32, 74, 171], 'nature': [33], 'of': [34, 37, 77, 84, 102, 114, 133, 158, 165, 188, 241], 'the': [35, 162, 200, 224], 'implementation': [36, 68], 'could': [39, 198], 'mean': [40], 'such': [41, 195], 'corporations,': [42], 'clinics': [43], 'public': [45], 'bodies': [46], 'will': [47], 'have': [48, 97, 107, 192], 'greater': [50, 111], 'than': [51], 'typical': [52], 'role': [53], 'obtaining,': [55], 'utilizing': [56], 'protecting': [58], 'patient': [59, 85, 129, 177, 203, 231], 'health': [60, 117, 178], 'information.': [61], 'This': [62, 197], 'raises': [63], 'privacy': [64, 127, 166], 'issues': [65], 'relating': [66], 'to': [67, 125, 146, 151, 161, 173, 202], 'data': [70, 86, 116, 134, 148, 179, 204, 242], 'security.': [71], 'Main': [72], 'body': [73], 'first': [75], 'set': [76, 157], 'concerns': [78, 159], 'includes': [79], 'access,': [80], 'use': [81, 154], 'control': [83], 'hands.': [89], 'Some': [90], 'recent': [91], 'public–private': [92], 'partnerships': [93], 'for': [94, 110], 'implementing': [95], 'resulted': [98], 'poor': [100], 'protection': [101, 149], 'privacy.': [103], 'As': [104], 'such,': [105], 'been': [108], 'calls': [109], 'systemic': [112], 'oversight': [113, 220], 'big': [115], 'research.': [118], 'Appropriate': [119], 'safeguards': [120], 'must': [121], 'be': [122, 136, 143, 181], 'place': [124], 'maintain': [126], 'agency.': [130], 'Private': [131], 'custodians': [132], 'can': [135], 'impacted': [137], 'competing': [139], 'goals': [140], 'should': [142, 229, 236], 'structurally': [144], 'encouraged': [145], 'ensure': [147], 'deter': [152], 'alternative': [153], 'thereof.': [155], 'Another': [156], 'relates': [160], 'external': [163], 'risk': [164, 201, 221], 'breaches': [167], 'through': [168], 'AI-driven': [169], 'methods.': [170], 'ability': [172], 'deidentify': [174], 'or': [175, 183], 'anonymize': [176], 'may': [180], 'compromised': [182], 'even': [184], 'nullified': [185], 'light': [187], 'new': [189], 'algorithms': [190], 'that': [191], 'successfully': [193], 'reidentified': [194], 'data.': [196], 'increase': [199], 'under': [205], 'custodianship.': [207], 'Conclusions': [208], 'We': [209], 'currently': [211], 'familiar': [214], 'situation': [215], 'which': [217], 'regulation': [218], 'falling': [222], 'behind': [223], 'they': [226], 'govern.': [227], 'Regulation': [228], 'emphasize': [230], 'agency': [232], 'consent,': [234], 'encourage': [237], 'increasingly': [238], 'sophisticated': [239], 'methods': [240], 'anonymization': [243], 'protection.': [245]}",2021,"['Custodians', 'Agency (philosophy)', 'Data Protection Act 1998', 'Internet privacy', 'Information privacy', 'Big data', 'Health care', 'Business', 'United States National Security Agency', 'Privacy by Design', 'Computer security', 'Public relations', 'Computer science', 'Political science', 'National security', 'Law', 'Data mining', 'Philosophy', 'Archaeology', 'Epistemology', 'History']","Abstract Background Advances in healthcare artificial intelligence (AI) are occurring rapidly and there is a growing discussion about managing its development. Many AI technologies end up owned and controlled by private entities. The nature of the implementation of AI could mean such corporations, clinics and public bodies will have a greater than typical role in obtaining, utilizing and protecting patient health information. This raises privacy issues relating to implementation and data security. Main body The first set of concerns includes access, use and control of patient data in private hands. Some recent public–private partnerships for implementing AI have resulted in poor protection of privacy. As such, there have been calls for greater systemic oversight of big data health research. Appropriate safeguards must be in place to maintain privacy and patient agency. Private custodians of data can be impacted by competing goals and should be structurally encouraged to ensure data protection and to deter alternative use thereof. Another set of concerns relates to the external risk of privacy breaches through AI-driven methods. The ability to deidentify or anonymize patient health data may be compromised or even nullified in light of new algorithms that have successfully reidentified such data. This could increase the risk to patient data under private custodianship. Conclusions We are currently in a familiar situation in which regulation and oversight risk falling behind the technologies they govern. Regulation should emphasize patient agency and consent, and should encourage increasingly sophisticated methods of data anonymization and protection."
https://openalex.org/W4221106857,Legal and Ethical Consideration in Artificial Intelligence in Healthcare: Who Takes Responsibility?,"{'The': [0], 'legal': [1, 112], 'and': [2, 15, 20, 42, 113, 144, 151], 'ethical': [3, 114], 'issues': [4, 115, 136], 'that': [5, 116], 'confront': [6], 'society': [7], 'due': [8, 119], 'to': [9, 98, 109, 120, 132], 'Artificial': [10], 'Intelligence': [11], '(AI)': [12], 'include': [13], 'privacy': [14], 'surveillance,': [16], 'bias': [17], 'or': [18, 57], 'discrimination,': [19], 'potentially': [21], 'the': [22, 26, 55, 60, 69, 73, 76, 111, 121, 138, 148], 'philosophical': [23], 'challenge': [24], 'is': [25, 72, 96], 'role': [27], 'of': [28, 40, 50, 62, 75, 123, 146, 153], 'human': [29], 'judgment.': [30], 'Concerns': [31], 'about': [32], 'newer': [33], 'digital': [34], 'technologies': [35], 'becoming': [36], 'a': [37, 48], 'new': [38], 'source': [39], 'inaccuracy': [41], 'data': [43], 'breaches': [44], 'have': [45, 65], 'arisen': [46], 'as': [47], 'result': [49], 'its': [51], 'use.': [52], 'Mistakes': [53], 'in': [54, 59, 87, 107, 126], 'procedure': [56], 'protocol': [58], 'field': [61], 'healthcare': [63, 127], 'can': [64], 'devastating': [66], 'consequences': [67], 'for': [68, 140], 'patient': [70], 'who': [71], 'victim': [74], 'error.': [77], 'Because': [78], 'patients': [79], 'come': [80], 'into': [81], 'contact': [82], 'with': [83], 'physicians': [84], 'at': [85], 'moments': [86], 'their': [88], 'lives': [89], 'when': [90], 'they': [91], 'are': [92, 103], 'most': [93], 'vulnerable,': [94], 'it': [95], 'crucial': [97], 'remember': [99], 'this.': [100], 'Currently,': [101], 'there': [102], 'no': [104], 'well-defined': [105], 'regulations': [106], 'place': [108], 'address': [110, 133], 'may': [117], 'arise': [118], 'use': [122], 'artificial': [124], 'intelligence': [125], 'settings.': [128], 'This': [129], 'review': [130], 'attempts': [131], 'these': [134], 'pertinent': [135], 'highlighting': [137], 'need': [139], 'algorithmic': [141], 'transparency,': [142], 'privacy,': [143], 'protection': [145], 'all': [147], 'beneficiaries': [149], 'involved': [150], 'cybersecurity': [152], 'associated': [154], 'vulnerabilities.': [155]}",2022,"['Transparency (behavior)', 'Health care', 'Ethical issues', 'Internet privacy', 'Engineering ethics', 'Field (mathematics)', 'Medicine', 'Public relations', 'Computer security', 'Computer science', 'Political science', 'Law', 'Engineering', 'Mathematics', 'Pure mathematics']","The legal and ethical issues that confront society due to Artificial Intelligence (AI) include privacy and surveillance, bias or discrimination, and potentially the philosophical challenge is the role of human judgment. Concerns about newer digital technologies becoming a new source of inaccuracy and data breaches have arisen as a result of its use. Mistakes in the procedure or protocol in the field of healthcare can have devastating consequences for the patient who is the victim of the error. Because patients come into contact with physicians at moments in their lives when they are most vulnerable, it is crucial to remember this. Currently, there are no well-defined regulations in place to address the legal and ethical issues that may arise due to the use of artificial intelligence in healthcare settings. This review attempts to address these pertinent issues highlighting the need for algorithmic transparency, privacy, and protection of all the beneficiaries involved and cybersecurity of associated vulnerabilities."
https://openalex.org/W2921123283,"Artificial Intelligence, Algorithmic Pricing, and Collusion","{'Increasingly,': [0], 'algorithms': [1, 22, 41], 'are': [2, 56], 'supplanting': [3], 'human': [4], 'decision-makers': [5], 'in': [6, 28, 80, 85], 'pricing': [7], 'goods': [8], 'and': [9, 90], 'services.': [10], 'To': [11], 'analyze': [12], 'the': [13, 19, 40, 86], 'possible': [14], 'consequences,': [15], 'we': [16], 'study': [17], 'experimentally': [18], 'behavior': [20], 'of': [21, 33, 65, 88, 93], 'powered': [23], 'by': [24, 58, 68], 'Artificial': [25], 'Intelligence': [26], '(Q-learning)': [27], 'a': [29, 62, 69], 'workhorse': [30], 'oligopoly': [31], 'model': [32], 'repeated': [34], 'price': [35], 'competition.': [36], 'We': [37], 'find': [38], 'that': [39], 'consistently': [42], 'learn': [43], 'to': [44, 72, 78], 'charge': [45], 'supracompetitive': [46], 'prices,': [47], 'without': [48], 'communicating': [49], 'with': [50, 61], 'one': [51], 'another.': [52], 'The': [53], 'high': [54], 'prices': [55], 'sustained': [57], 'collusive': [59], 'strategies': [60], 'finite': [63], 'phase': [64], 'punishment': [66], 'followed': [67], 'gradual': [70], 'return': [71], 'cooperation.': [73], 'This': [74], 'finding': [75], 'is': [76], 'robust': [77], 'asymmetries': [79], 'cost': [81], 'or': [82], 'demand,': [83], 'changes': [84], 'number': [87], 'players,': [89], 'various': [91], 'forms': [92], 'uncertainty.': [94], '(JEL': [95], 'D21,': [96], 'D43,': [97], 'D83,': [98], 'L12,': [99], 'L13)': [100]}",2020,"['Collusion', 'Economics', 'Competition (biology)', 'Microeconomics', 'Oligopoly', 'Punishment (psychology)', 'Computer science', 'Cournot competition', 'Psychology', 'Biology', 'Ecology', 'Social psychology']","Increasingly, algorithms are supplanting human decision-makers in pricing goods and services. To analyze the possible consequences, we study experimentally the behavior of algorithms powered by Artificial Intelligence (Q-learning) in a workhorse oligopoly model of repeated price competition. We find that the algorithms consistently learn to charge supracompetitive prices, without communicating with one another. The high prices are sustained by collusive strategies with a finite phase of punishment followed by a gradual return to cooperation. This finding is robust to asymmetries in cost or demand, changes in the number of players, and various forms of uncertainty. (JEL D21, D43, D83, L12, L13)"
https://openalex.org/W2767568774,Artificial Intelligence and the Modern Productivity Paradox: A Clash of Expectations and Statistics,"{'We': [0], 'live': [1], 'in': [2, 16, 24, 160], 'an': [3], 'age': [4], 'of': [5, 55, 64, 98, 125, 146, 150, 153, 164, 177], 'paradox.Systems': [6], 'using': [7], 'artificial': [8], 'intelligence': [9], 'match': [10], 'or': [11], 'surpass': [12], 'human': [13], 'level': [14], 'performance': [15], 'more': [17, 19], 'and': [18, 27, 43, 66, 72, 130, 137, 181], 'domains,': [20], 'leveraging': [21], 'rapid': [22], 'advances': [23], 'other': [25, 113], 'technologies': [26, 180], 'driving': [28], 'soaring': [29], 'stock': [30], 'prices.Yet': [31], 'measured': [32], 'productivity': [33], 'growth': [34], 'has': [35, 46], 'declined': [36], 'by': [37], 'half': [38], 'over': [39], 'the': [40, 49, 89, 93, 151, 161, 174, 178, 186], 'past': [41], 'decade,': [42], 'real': [44], 'income': [45], 'stagnated': [47], 'since': [48], 'late': [50], '1990s': [51], 'for': [52, 61, 80], 'a': [53, 75, 144], 'majority': [54], 'Americans.We': [56], 'describe': [57], 'four': [58], 'potential': [59], 'explanations': [60], 'this': [62, 154], 'clash': [63], 'expectations': [65], 'statistics:': [67], 'false': [68], 'hopes,': [69], 'mismeasurement,': [70], 'redistribution,': [71], 'implementation': [73], 'lags.While': [74], 'case': [76], 'can': [77, 140], 'be': [78, 121, 141], 'made': [79], 'each,': [81], 'we': [82], 'argue': [83], 'that': [84], 'lags': [85], 'have': [86, 106, 185], 'likely': [87], 'been': [88], 'biggest': [90], 'contributor': [91], 'to': [92, 172], 'paradox.The': [94], 'most': [95], 'impressive': [96], 'capabilities': [97], 'AI,': [99], 'particularly': [100], 'those': [101], 'based': [102], 'on': [103], 'machine': [104], 'learning,': [105], 'not': [107], 'yet': [108], 'diffused': [109], 'widely.More': [110], 'importantly,': [111], 'like': [112], 'general': [114], 'purpose': [115], 'technologies,': [116], 'their': [117], 'full': [118, 175], 'effects': [119], ""won't"": [120], 'realized': [122], 'until': [123], 'waves': [124], 'complementary': [126], 'innovations': [127], 'are': [128], 'developed': [129], 'implemented.The': [131], 'required': [132], 'adjustment': [133], 'costs,': [134], 'organizational': [135], 'changes,': [136], 'new': [138, 179], 'skills': [139], 'modeled': [142], 'as': [143], 'kind': [145], 'intangible': [147, 155], 'capital.A': [148], 'portion': [149], 'value': [152, 163], 'capital': [156], 'is': [157], 'already': [158], 'reflected': [159], 'market': [162], 'firms.However,': [165], 'going': [166], 'forward,': [167], 'national': [168], 'statistics': [169], 'could': [170], 'fail': [171], 'measure': [173], 'benefits': [176], 'some': [182], 'may': [183], 'even': [184], 'wrong': [187], 'sign.': [188]}",2017,"['Productivity', 'Statistics', 'Data science', 'Econometrics', 'Artificial intelligence', 'Computer science', 'Economics', 'Mathematics', 'Macroeconomics']","We live in an age of paradox.Systems using artificial intelligence match or surpass human level performance in more and more domains, leveraging rapid advances in other technologies and driving soaring stock prices.Yet measured productivity growth has declined by half over the past decade, and real income has stagnated since the late 1990s for a majority of Americans.We describe four potential explanations for this clash of expectations and statistics: false hopes, mismeasurement, redistribution, and implementation lags.While a case can be made for each, we argue that lags have likely been the biggest contributor to the paradox.The most impressive capabilities of AI, particularly those based on machine learning, have not yet diffused widely.More importantly, like other general purpose technologies, their full effects won't be realized until waves of complementary innovations are developed and implemented.The required adjustment costs, organizational changes, and new skills can be modeled as a kind of intangible capital.A portion of the value of this intangible capital is already reflected in the market value of firms.However, going forward, national statistics could fail to measure the full benefits of the new technologies and some may even have the wrong sign."
https://openalex.org/W2995887567,Artificial Intelligence and Surgical Decision-making,"{'Integration': [0], 'of': [1, 25], 'artificial': [2], 'intelligence': [3], 'with': [4], 'surgical': [5], 'decision-making': [6], 'has': [7], 'the': [8, 15], 'potential': [9], 'to': [10, 17], 'transform': [11], 'care': [12], 'by': [13], 'augmenting': [14], 'decision': [16], 'operate,': [18], 'informed': [19], 'consent': [20], 'process,': [21], 'identification': [22], 'and': [23, 33], 'mitigation': [24], 'modifiable': [26], 'risk': [27], 'factors,': [28], 'decisions': [29, 35], 'regarding': [30, 36], 'postoperative': [31], 'management,': [32], 'shared': [34], 'resource': [37], 'use.': [38]}",2019,"['Interpretability', 'Medicine', 'Decision support system', 'Heuristics', 'Clinical decision support system', 'Decision analysis', 'Evidential reasoning approach', 'Standardization', 'Artificial intelligence', 'Risk analysis (engineering)', 'Computer science', 'Business decision mapping', 'Mathematics', 'Statistics', 'Operating system']","Integration of artificial intelligence with surgical decision-making has the potential to transform care by augmenting the decision to operate, informed consent process, identification and mitigation of modifiable risk factors, decisions regarding postoperative management, and shared decisions regarding resource use."
https://openalex.org/W2973537858,Frontiers: Machines vs. Humans: The Impact of Artificial Intelligence Chatbot Disclosure on Customer Purchases,"{'Chatbot': [0], 'identity': [1], 'disclosure': [2], 'negatively': [3], 'affects': [4], 'customer': [5], 'purchases': [6], 'because': [7], 'customers': [8], 'perceive': [9], 'the': [10], 'disclosed': [11], 'bot': [12], 'as': [13], 'less': [14, 17], 'knowledgeable': [15], 'and': [16], 'empathetic.': [18]}",2019,"['Chatbot', 'Business', 'Marketing', 'Computer science', 'Artificial intelligence', 'Advertising', 'Industrial organization', 'Internet privacy']",Chatbot identity disclosure negatively affects customer purchases because customers perceive the disclosed bot as less knowledgeable and less empathetic.
https://openalex.org/W3147517805,Human- versus Artificial Intelligence,"{'AI': [0, 122, 128, 175, 198, 221, 245], 'is': [1, 148, 178, 294], 'one': [2, 102], 'of': [3, 8, 21, 51, 93, 103, 107, 116, 120, 190, 209, 220, 261, 266], 'the': [4, 17, 49, 55, 80, 90, 112, 125, 187, 206, 218, 248, 262], 'most': [5, 145], 'debated': [6], 'subjects': [7], 'today': [9], 'and': [10, 19, 24, 36, 43, 67, 82, 86, 110, 136, 165, 176, 192, 203], 'there': [11], 'seems': [12], 'little': [13], 'common': [14], 'understanding': [15], 'concerning': [16], 'differences': [18, 83], 'similarities': [20, 81], 'human': [22, 94, 99, 179, 210, 224, 234], 'intelligence': [23, 53, 100, 226], 'artificial': [25, 87, 193], 'intelligence.': [26], 'Discussions': [27], 'on': [28, 79, 186], 'many': [29, 104], 'relevant': [30], 'topics,': [31], 'such': [32], 'as': [33, 54, 101, 158, 160], 'trustworthiness,': [34], 'explainability,': [35], 'ethics': [37], 'are': [38, 170], 'characterized': [39], 'by': [40], 'implicit': [41], 'anthropocentric': [42], 'anthropomorphistic': [44], 'conceptions': [45], 'and,': [46], 'for': [47, 58, 205, 291], 'instance,': [48], 'pursuit': [50], 'human-like': [52], 'golden': [56], 'standard': [57], 'Artificial': [59], 'Intelligence.': [60], 'In': [61, 236], 'order': [62, 237, 270], 'to': [63, 68, 172, 174, 196, 201, 238, 255, 271], 'provide': [64], 'more': [65, 231, 283], 'agreement': [66], 'substantiate': [69], 'possible': [70, 105], 'future': [71], 'research': [72], 'objectives,': [73], 'this': [74, 142, 286], 'paper': [75], 'presents': [76], 'three': [77], 'notions': [78], 'between': [84], 'human-': [85, 191], 'intelligence:': [88], '1)': [89], 'fundamental': [91], 'constraints': [92, 208], '(and': [95, 153, 212], 'artificial)': [96], 'intelligence,': [97, 109], '2)': [98], 'forms': [106, 119], 'general': [108], '3)': [111], 'high': [113], 'potential': [114], 'impact': [115], 'multiple': [117], '(integrated)': [118], 'narrow-hybrid': [121], 'applications.': [123], 'For': [124, 141, 162, 285], 'time': [126], 'being,': [127], 'systems': [129, 157, 199, 246], 'will': [130], 'have': [131, 254], 'fundamentally': [132], 'different': [133], 'cognitive': [134], 'qualities': [135], 'abilities': [137], 'than': [138], 'biological': [139], 'systems.': [140], 'reason,': [143], 'a': [144, 288], 'prominent': [146], 'issue': [147], 'how': [149], 'we': [150, 184, 216, 229], 'can': [151, 183], 'use': [152], '“collaborate”': [154], 'with)': [155], 'these': [156, 240], 'effectively': [159, 200], 'possible?': [161], 'what': [163, 167], 'tasks': [164], 'under': [166], 'conditions,': [168], 'decisions': [169], 'safe': [171], 'leave': [173], 'when': [177], 'judgment': [180], 'required?': [181], 'How': [182, 195], 'capitalize': [185], 'specific': [188], 'strengths': [189], 'intelligence?': [194], 'deploy': [197], 'complement': [202], 'compensate': [204], 'inherent': [207], 'cognition': [211], 'vice': [213], 'versa)?': [214], 'Should': [215], 'pursue': [217], 'development': [219], '“partners”': [222], 'with': [223, 244], '(-level)': [225], 'or': [227, 250], 'should': [228, 280], 'focus': [230], 'at': [232], 'supplementing': [233], 'limitations?': [235], 'answer': [239], 'questions,': [241], 'humans': [242, 279], 'working': [243], 'in': [247, 251, 269, 278], 'workplace': [249], 'policy': [252], 'making': [253], 'develop': [256], 'an': [257], 'adequate': [258], 'mental': [259], 'model': [260], 'underlying': [263], '‘psychological’': [264], 'mechanisms': [265], 'AI.': [267], 'So,': [268], 'obtain': [272], 'well-functioning': [273], 'human-AI': [274], 'systems,': [275], 'Intelligence': [276], 'Awareness': [277], 'be': [281], 'addressed': [282], 'vigorously.': [284], 'purpose': [287], 'first': [289], 'framework': [290], 'educational': [292], 'content': [293], 'proposed.': [295]}",2021,"['Human intelligence', 'Artificial general intelligence', 'Artificial intelligence', 'Cognition', 'Computer science', 'Applications of artificial intelligence', 'Order (exchange)', 'Cognitive science', 'Psychology', 'Finance', 'Economics', 'Neuroscience']","AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and “collaborate” with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI “partners” with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying ‘psychological’ mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed."
https://openalex.org/W4385878593,New Era of Artificial Intelligence in Education: Towards a Sustainable Multifaceted Revolution,"{'The': [0], 'recent': [1], 'high': [2], 'performance': [3], 'of': [4, 15, 26, 46, 60, 75, 83, 101], 'ChatGPT': [5], 'on': [6, 49, 77, 98, 119], 'several': [7], 'standardized': [8], 'academic': [9], 'tests': [10], 'has': [11], 'thrust': [12], 'the': [13, 20, 24, 35, 50, 72, 84, 99, 120, 139, 146], 'topic': [14], 'artificial': [16, 102], 'intelligence': [17, 103], '(AI)': [18], 'into': [19], 'mainstream': [21], 'conversation': [22], 'about': [23], 'future': [25, 128], 'education.': [27, 134], 'As': [28], 'deep': [29], 'learning': [30], 'is': [31, 39, 143], 'poised': [32], 'to': [33, 41, 54, 70, 144, 152], 'shift': [34], 'teaching': [36], 'paradigm,': [37], 'it': [38], 'essential': [40], 'have': [42], 'a': [43], 'clear': [44], 'understanding': [45], 'its': [47, 154], 'effects': [48], 'current': [51], 'education': [52, 78], 'system': [53], 'ensure': [55], 'sustainable': [56], 'development': [57], 'and': [58, 65, 81, 93, 113, 126], 'deployment': [59], 'AI-driven': [61], 'technologies': [62], 'at': [63], 'schools': [64], 'universities.': [66], 'This': [67], 'research': [68], 'aims': [69], 'investigate': [71], 'potential': [73, 121], 'impact': [74], 'AI': [76, 131], 'through': [79], 'review': [80, 96], 'analysis': [82], 'existing': [85], 'literature': [86], 'across': [87], 'three': [88], 'major': [89], 'axes:': [90], 'applications,': [91], 'advantages,': [92], 'challenges.': [94], 'Our': [95], 'focuses': [97], 'use': [100], 'in': [104, 133], 'collaborative': [105], 'teacher–student': [106], 'learning,': [107], 'intelligent': [108], 'tutoring': [109], 'systems,': [110], 'automated': [111], 'assessment,': [112], 'personalized': [114], 'learning.': [115], 'We': [116], 'also': [117], 'report': [118], 'negative': [122], 'aspects,': [123], 'ethical': [124], 'issues,': [125], 'possible': [127], 'routes': [129], 'for': [130], 'implementation': [132], 'Ultimately,': [135], 'we': [136], 'find': [137], 'that': [138], 'only': [140], 'way': [141], 'forward': [142], 'embrace': [145], 'new': [147], 'technology,': [148], 'while': [149], 'implementing': [150], 'guardrails': [151], 'prevent': [153], 'abuse.': [155]}",2023,"['Mainstream', 'Software deployment', 'Applications of artificial intelligence', 'Computer science', 'Conversation', 'Artificial intelligence', 'Engineering ethics', 'Engineering management', 'Engineering', 'Knowledge management', 'Psychology', 'Political science', 'Software engineering', 'Law', 'Communication']","The recent high performance of ChatGPT on several standardized academic tests has thrust the topic of artificial intelligence (AI) into the mainstream conversation about the future of education. As deep learning is poised to shift the teaching paradigm, it is essential to have a clear understanding of its effects on the current education system to ensure sustainable development and deployment of AI-driven technologies at schools and universities. This research aims to investigate the potential impact of AI on education through review and analysis of the existing literature across three major axes: applications, advantages, and challenges. Our review focuses on the use of artificial intelligence in collaborative teacher–student learning, intelligent tutoring systems, automated assessment, and personalized learning. We also report on the potential negative aspects, ethical issues, and possible future routes for AI implementation in education. Ultimately, we find that the only way forward is to embrace the new technology, while implementing guardrails to prevent its abuse."
https://openalex.org/W2981296841,Introducing Artificial Intelligence Training in Medical Education,"{'Health': [0], 'care': [1, 59], 'is': [2], 'evolving': [3], 'and': [4, 86, 91, 97, 124], 'with': [5], 'it': [6], 'the': [7, 14, 19, 25, 37, 44, 109, 117, 133], 'need': [8, 38, 71], 'to': [9, 29, 56, 61, 66, 72, 82, 88, 101, 131, 137], 'reform': [10], 'medical': [11, 47, 120, 134], 'education.': [12], 'As': [13, 43], 'practice': [15, 67], 'of': [16, 21, 27, 46, 108, 119], 'medicine': [17], 'enters': [18], 'age': [20], 'artificial': [22], 'intelligence': [23], '(AI),': [24], 'use': [26, 63], 'data': [28], 'improve': [30, 83], 'clinical': [31], 'decision': [32], 'making': [33], 'will': [34], 'grow,': [35], 'pushing': [36], 'for': [39], 'skillful': [40], 'medicine-machine': [41], 'interaction.': [42], 'rate': [45], 'knowledge': [48, 65], 'grows,': [49], 'technologies': [50], 'such': [51, 94], 'as': [52, 95], 'AI': [53, 99], 'are': [54], 'needed': [55], 'enable': [57], 'health': [58, 89], 'professionals': [60, 70], 'effectively': [62], 'this': [64, 77, 112], 'medicine.': [68], 'Medical': [69], 'be': [73, 102], 'adequately': [74], 'trained': [75], 'in': [76], 'new': [78], 'technology,': [79], 'its': [80, 92], 'advantages': [81], 'cost,': [84], 'quality,': [85], 'access': [87], 'care,': [90], 'shortfalls': [93], 'transparency': [96], 'liability.': [98], 'needs': [100], 'seamlessly': [103], 'integrated': [104], 'across': [105], 'different': [106], 'aspects': [107], 'curriculum.': [110], 'In': [111], 'paper,': [113], 'we': [114], 'have': [115, 125], 'addressed': [116], 'state': [118], 'education': [121, 135], 'at': [122], 'present': [123], 'recommended': [126], 'a': [127], 'framework': [128], 'on': [129], 'how': [130], 'evolve': [132], 'curriculum': [136], 'include': [138], 'AI.': [139]}",2019,"['Curriculum', 'Transparency (behavior)', 'Health care', 'Medical education', 'Liability', 'Medical knowledge', 'Quality (philosophy)', 'Knowledge management', 'Training (meteorology)', 'Computer science', 'Artificial intelligence', 'Medicine', 'Psychology', 'Business', 'Political science', 'Pedagogy', 'Computer security', 'Philosophy', 'Law', 'Meteorology', 'Finance', 'Epistemology', 'Physics']","Health care is evolving and with it the need to reform medical education. As the practice of medicine enters the age of artificial intelligence (AI), the use of data to improve clinical decision making will grow, pushing the need for skillful medicine-machine interaction. As the rate of medical knowledge grows, technologies such as AI are needed to enable health care professionals to effectively use this knowledge to practice medicine. Medical professionals need to be adequately trained in this new technology, its advantages to improve cost, quality, and access to health care, and its shortfalls such as transparency and liability. AI needs to be seamlessly integrated across different aspects of the curriculum. In this paper, we have addressed the state of medical education at present and have recommended a framework on how to evolve the medical education curriculum to include AI."
https://openalex.org/W3094019951,Artificial-Intelligence-Enabled Intelligent 6G Networks,"{'With': [0], 'the': [1, 53, 69, 104, 128, 140, 148], 'rapid': [2], 'development': [3, 181], 'of': [4, 72, 79, 130], 'smart': [5, 94, 121, 160], 'terminals': [6], 'and': [7, 15, 28, 47, 99, 115, 120, 136, 145, 159, 169, 182], 'infrastructures,': [8], 'as': [9, 64], 'well': [10], 'as\\ndiversified': [11], 'applications': [12, 129], '(e.g.,': [13], 'virtual': [14], 'augmented': [16], 'reality,': [17], 'remote': [18], 'surgery\\nand': [19], 'holographic': [20], 'projection)': [21], 'with': [22, 75], 'colorful': [23], 'requirements,': [24], 'current': [25], 'networks': [26, 74, 90, 135], '(e.g.,\\n4G': [27], 'upcoming': [29], '5G': [30], 'networks)': [31], 'may': [32], 'not': [33], 'be': [34], 'able': [35], 'to': [36, 52, 143], 'completely': [37], 'meet': [38], 'quickly': [39], 'rising\\ntraffic': [40], 'demands.': [41], 'Accordingly,': [42], 'efforts': [43], 'from': [44], 'both': [45], 'industry': [46], 'academia': [48], 'have\\nalready': [49], 'been': [50, 62], 'put': [51], 'research': [54, 167], 'on': [55], '6G': [56, 73, 89, 134, 174], 'networks.': [57], 'Recently,': [58], 'artificial\\nintelligence': [59], '(AI)': [60], 'has': [61], 'utilized': [63], 'a': [65, 76], 'new': [66], 'paradigm': [67], 'for': [68, 88, 133, 172], 'design': [70], 'and\\noptimization': [71], 'high': [77], 'level': [78], 'intelligence.': [80], 'Therefore,': [81], 'this\\narticle': [82], 'proposes': [83], 'an': [84], 'AI-enabled': [85], 'intelligent': [86, 100, 110, 117, 155], 'architecture': [87, 105], 'to\\nrealize': [91], 'knowledge': [92], 'discovery,': [93], 'resource': [95], 'management,': [96, 158], 'automatic': [97], 'network\\nadjustment': [98], 'service': [101], 'provisioning,': [102], 'where': [103], 'is\\ndivided': [106], 'into': [107], 'four': [108], 'layers:': [109], 'sensing': [111], 'layer,': [112], 'data': [113], 'mining': [114], 'analytics\\nlayer,': [116], 'control': [118], 'layer': [119], 'application': [122], 'layer.': [123], 'We': [124], 'then': [125], 'review\\nand': [126], 'discuss': [127], 'AI': [131, 141], 'techniques': [132, 142], 'elaborate': [137], 'how\\nto': [138], 'employ': [139], 'efficiently': [144], 'effectively': [146], 'optimize': [147], 'network\\nperformance,': [149], 'including': [150, 176], 'AI-empowered': [151], 'mobile': [152], 'edge': [153], 'computing,': [154], 'mobility\\nand': [156], 'handover': [157], 'spectrum': [161], 'management.': [162], 'Moreover,': [163], 'we': [164], 'highlight\\nimportant': [165], 'future': [166], 'directions': [168], 'potential': [170], 'solutions': [171], 'AI-enabled\\nintelligent': [173], 'networks,': [175], 'computation': [177], 'efficiency,': [178], 'algorithms\\nrobustness,': [179], 'hardware': [180], 'energy': [183], 'management.\\n': [184]}",2020,"['Computer science', 'Intelligent Network', 'Network architecture', 'Service layer', 'Provisioning', 'Computer network', 'Handover', 'Intelligent decision support system', 'Distributed computing', 'Artificial intelligence', 'Quality of service']","With the rapid development of smart terminals and infrastructures, as well as\ndiversified applications (e.g., virtual and augmented reality, remote surgery\nand holographic projection) with colorful requirements, current networks (e.g.,\n4G and upcoming 5G networks) may not be able to completely meet quickly rising\ntraffic demands. Accordingly, efforts from both industry and academia have\nalready been put to the research on 6G networks. Recently, artificial\nintelligence (AI) has been utilized as a new paradigm for the design and\noptimization of 6G networks with a high level of intelligence. Therefore, this\narticle proposes an AI-enabled intelligent architecture for 6G networks to\nrealize knowledge discovery, smart resource management, automatic network\nadjustment and intelligent service provisioning, where the architecture is\ndivided into four layers: intelligent sensing layer, data mining and analytics\nlayer, intelligent control layer and smart application layer. We then review\nand discuss the applications of AI techniques for 6G networks and elaborate how\nto employ the AI techniques to efficiently and effectively optimize the network\nperformance, including AI-empowered mobile edge computing, intelligent mobility\nand handover management, and smart spectrum management. Moreover, we highlight\nimportant future research directions and potential solutions for AI-enabled\nintelligent 6G networks, including computation efficiency, algorithms\nrobustness, hardware development and energy management.\n"
https://openalex.org/W3015977534,Transparency in artificial intelligence,"{'This': [0], 'conceptual': [1, 24, 115], 'paper': [2], 'addresses': [3], 'the': [4, 23, 36, 75, 92, 106, 109, 158, 170], 'issues': [5], 'of': [6, 64, 86, 94, 108, 117, 141, 160, 172], 'transparency': [7, 27, 56, 112, 145], 'as': [8, 41, 57, 90, 174], 'linked': [9, 121], 'to': [10, 50, 122, 132, 144, 167, 169], 'artificial': [11], 'intelligence': [12], '(AI)': [13], 'from': [14], 'socio-legal': [15], 'and': [16, 30, 33, 63, 104, 155, 178], 'computer': [17], 'scientific': [18], 'perspectives.': [19], 'Firstly,': [20], 'we': [21, 53, 102, 136, 150], 'discuss': [22, 103], 'distinction': [25], 'between': [26], 'in': [28, 48, 68, 83, 91, 146, 165, 179], 'AI': [29, 87, 153, 173], 'algorithmic': [31], 'transparency,': [32, 154], 'argue': [34, 156], 'for': [35, 157], 'wider': [37], 'concept': [38, 60], '‘in': [39], 'AI’,': [40], 'a': [42, 58, 81, 114, 138, 162], 'partly': [43], 'contested': [44], 'albeit': [45], 'useful': [46], 'notion': [47], 'relation': [49], 'transparency.': [51], 'Secondly,': [52], 'show': [54, 105], 'that': [55, 111, 127], 'general': [59, 119], 'is': [61], 'multifaceted,': [62], 'widespread': [65], 'theoretical': [66], 'use': [67], 'multiple': [69], 'disciplines': [70], 'over': [71], 'time,': [72], 'particularly': [73], 'since': [74], '1990s.': [76], 'Still,': [77], 'it': [78], 'has': [79], 'had': [80], 'resurgence': [82], 'contemporary': [84], 'notions': [85], 'governance,': [88], 'such': [89], 'multitude': [93], 'recently': [95], 'published': [96], 'ethics': [97], 'guidelines': [98], 'on': [99, 176], 'AI.': [100], 'Thirdly,': [101], 'relevance': [107], 'fact': [110], 'expresses': [113], 'metaphor': [116], 'more': [118], 'significance,': [120], 'knowing,': [123], 'bringing': [124], 'positive': [125], 'connotations': [126], 'may': [128], 'have': [129], 'normative': [130], 'effects': [131], 'regulatory': [133], 'debates.': [134], 'Finally,': [135], 'draw': [137], 'possible': [139], 'categorisation': [140], 'aspects': [142], 'related': [143], 'AI,': [147], 'or': [148], 'what': [149], 'interchangeably': [151], 'call': [152], 'need': [159], 'developing': [161], 'multidisciplinary': [163], 'understanding,': [164], 'order': [166], 'contribute': [168], 'governance': [171], 'applied': [175], 'markets': [177], 'society.': [180]}",2020,"['Transparency (behavior)', 'Artificial intelligence', 'Computer science', 'Engineering ethics', 'Political science', 'Engineering', 'Computer security']","This conceptual paper addresses the issues of transparency as linked to artificial intelligence (AI) from socio-legal and computer scientific perspectives. Firstly, we discuss the conceptual distinction between transparency in AI and algorithmic transparency, and argue for the wider concept ‘in AI’, as a partly contested albeit useful notion in relation to transparency. Secondly, we show that transparency as a general concept is multifaceted, and of widespread theoretical use in multiple disciplines over time, particularly since the 1990s. Still, it has had a resurgence in contemporary notions of AI governance, such as in the multitude of recently published ethics guidelines on AI. Thirdly, we discuss and show the relevance of the fact that transparency expresses a conceptual metaphor of more general significance, linked to knowing, bringing positive connotations that may have normative effects to regulatory debates. Finally, we draw a possible categorisation of aspects related to transparency in AI, or what we interchangeably call AI transparency, and argue for the need of developing a multidisciplinary understanding, in order to contribute to the governance of AI as applied on markets and in society."
https://openalex.org/W3009785512,Artificial intelligence in oncology,"{'Abstract': [0], 'Artificial': [1], 'intelligence': [2], '(AI)': [3], 'has': [4, 72], 'contributed': [5], 'substantially': [6], 'to': [7, 80, 120], 'the': [8, 19, 60, 108, 132], 'resolution': [9], 'of': [10, 13, 26, 44, 59, 62, 110, 117, 123], 'a': [11, 24], 'variety': [12], 'biomedical': [14], 'problems,': [15], 'including': [16, 66], 'cancer,': [17], 'over': [18], 'past': [20], 'decade.': [21, 134], 'Deep': [22], 'learning,': [23], 'subfield': [25], 'AI': [27, 63, 111, 124], 'that': [28, 76, 87, 104], 'is': [29, 37], 'highly': [30], 'flexible': [31], 'and': [32, 47, 83, 102, 121], 'supports': [33], 'automatic': [34], 'feature': [35], 'extraction,': [36], 'increasingly': [38], 'being': [39], 'applied': [40], 'in': [41, 64, 68, 129, 131], 'various': [42], 'areas': [43], 'both': [45], 'basic': [46], 'clinical': [48], 'cancer': [49, 113], 'research.': [50, 114], 'In': [51], 'this': [52], 'review,': [53], 'we': [54, 84], 'describe': [55], 'numerous': [56], 'recent': [57], 'examples': [58], 'application': [61, 93], 'oncology,': [65], 'cases': [67], 'which': [69], 'deep': [70], 'learning': [71], 'efficiently': [73], 'solved': [74], 'problems': [75], 'were': [77], 'previously': [78], 'thought': [79], 'be': [81, 89], 'unsolvable,': [82], 'address': [85], 'obstacles': [86], 'must': [88], 'overcome': [90], 'before': [91], 'such': [92], 'can': [94, 105], 'become': [95], 'more': [96], 'widespread.': [97], 'We': [98], 'also': [99], 'highlight': [100], 'resources': [101], 'datasets': [103], 'help': [106], 'harness': [107], 'power': [109], 'for': [112], 'The': [115], 'development': [116], 'innovative': [118], 'approaches': [119], 'applications': [122], 'will': [125], 'yield': [126], 'important': [127], 'insights': [128], 'oncology': [130], 'coming': [133]}",2020,"['Medicine', 'Medical physics', 'Oncology', 'Internal medicine']","Abstract Artificial intelligence (AI) has contributed substantially to the resolution of a variety of biomedical problems, including cancer, over the past decade. Deep learning, a subfield of AI that is highly flexible and supports automatic feature extraction, is increasingly being applied in various areas of both basic and clinical cancer research. In this review, we describe numerous recent examples of the application of AI in oncology, including cases in which deep learning has efficiently solved problems that were previously thought to be unsolvable, and we address obstacles that must be overcome before such application can become more widespread. We also highlight resources and datasets that can help harness the power of AI for cancer research. The development of innovative approaches to and applications of AI will yield important insights in oncology in the coming decade."
https://openalex.org/W3166943242,Governance of artificial intelligence,"{'ABSTRACT': [0], 'The': [1, 64, 209], 'rapid': [2], 'developments': [3], 'in': [4, 11, 16, 215], 'Artificial': [5], 'Intelligence': [6], '(AI)': [7], 'and': [8, 26, 39, 75, 84, 87, 117, 123, 126, 129, 140, 167, 194, 199, 201, 204, 224, 230, 235], 'the': [9, 12, 37, 100, 106, 115, 120, 143, 154, 163, 176, 213, 216, 228], 'intensification': [10], 'adoption': [13], 'of': [14, 41, 54, 57, 67, 77, 91, 119, 145, 156, 179, 181, 197, 218, 232], 'AI': [15, 58, 68, 103, 139, 146, 198, 233], 'domains': [17], 'such': [18], 'as': [19, 33], 'autonomous': [20], 'vehicles,': [21], 'lethal': [22], 'weapon': [23], 'systems,': [24], 'robotics': [25], 'alike': [27], 'pose': [28, 88], 'serious': [29], 'challenges': [30, 157, 178, 196, 229], 'to': [31, 95, 112, 131, 187, 221, 226], 'governments': [32, 109], 'they': [34, 80], 'must': [35], 'manage': [36], 'scale': [38], 'speed': [40], 'socio-technical': [42], 'transitions': [43], 'occurring.': [44], 'While': [45], 'there': [46], 'is': [47, 59], 'considerable': [48], 'literature': [49], 'emerging': [50, 184], 'on': [51], 'various': [52], 'aspects': [53], 'AI,': [55, 182, 188, 219], 'governance': [56, 127, 180, 185, 217, 234], 'a': [60], 'significantly': [61], 'underdeveloped': [62], 'area.': [63], 'new': [65, 89], 'applications': [66], 'offer': [69], 'opportunities': [70], 'for': [71, 239], 'increasing': [72], 'economic': [73], 'efficiency': [74], 'quality': [76], 'life,': [78], 'but': [79], 'also': [81], 'generate': [82], 'unexpected': [83], 'unintended': [85], 'consequences': [86], 'forms': [90], 'risks': [92, 121], 'that': [93, 206], 'need': [94, 111, 207], 'be': [96, 148], 'addressed.': [97], 'To': [98], 'enhance': [99], 'benefits': [101], 'from': [102], 'while': [104], 'minimising': [105], 'adverse': [107], 'risks,': [108], 'worldwide': [110], 'understand': [113], 'better': [114], 'scope': [116], 'depth': [118], 'posed': [122], 'develop': [124], 'regulatory': [125, 195], 'processes': [128], 'structures': [130], 'address': [132], 'these': [133], 'challenges.': [134], 'This': [135, 172], 'introductory': [136], 'article': [137], 'unpacks': [138], 'describes': [141], 'why': [142], 'Governance': [144], 'should': [147], 'gaining': [149], 'far': [150], 'more': [151], 'attention': [152], 'given': [153], 'myriad': [155], 'it': [158], 'presents.': [159], 'It': [160], 'then': [161], 'summarises': [162], 'special': [164, 173, 210], 'issue': [165, 174, 211], 'articles': [166], 'highlights': [168], 'their': [169], 'key': [170], 'contributions.': [171], 'introduces': [175], 'multifaceted': [177], 'including': [183], 'approaches': [186], 'policy': [189], 'capacity': [190], 'building,': [191], 'exploring': [192], 'legal': [193], 'Robotics,': [200], 'outstanding': [202], 'issues': [203], 'gaps': [205], 'attention.': [208], 'showcases': [212], 'state-of-the-art': [214], 'aiming': [220], 'enable': [222], 'researchers': [223], 'practitioners': [225], 'appreciate': [227], 'complexities': [231], 'highlight': [236], 'future': [237], 'avenues': [238], 'exploration.': [240]}",2021,"['Corporate governance', 'Scope (computer science)', 'Artificial intelligence', 'Unintended consequences', 'Quality (philosophy)', 'Robotics', 'Political science', 'Engineering ethics', 'Computer science', 'Business', 'Engineering', 'Robot', 'Law', 'Epistemology', 'Philosophy', 'Finance', 'Programming language']","ABSTRACT The rapid developments in Artificial Intelligence (AI) and the intensification in the adoption of AI in domains such as autonomous vehicles, lethal weapon systems, robotics and alike pose serious challenges to governments as they must manage the scale and speed of socio-technical transitions occurring. While there is considerable literature emerging on various aspects of AI, governance of AI is a significantly underdeveloped area. The new applications of AI offer opportunities for increasing economic efficiency and quality of life, but they also generate unexpected and unintended consequences and pose new forms of risks that need to be addressed. To enhance the benefits from AI while minimising the adverse risks, governments worldwide need to understand better the scope and depth of the risks posed and develop regulatory and governance processes and structures to address these challenges. This introductory article unpacks AI and describes why the Governance of AI should be gaining far more attention given the myriad of challenges it presents. It then summarises the special issue articles and highlights their key contributions. This special issue introduces the multifaceted challenges of governance of AI, including emerging governance approaches to AI, policy capacity building, exploring legal and regulatory challenges of AI and Robotics, and outstanding issues and gaps that need attention. The special issue showcases the state-of-the-art in the governance of AI, aiming to enable researchers and practitioners to appreciate the challenges and complexities of AI governance and highlight future avenues for exploration."
https://openalex.org/W4311487064,What factors contribute to the acceptance of artificial intelligence? A systematic review,"{'Artificial': [0], 'Intelligence': [1], '(AI)': [2], 'agents': [3], 'are': [4], 'predicted': [5, 204], 'to': [6, 106, 124, 185, 269], 'infiltrate': [7], 'most': [8, 181, 248], 'industries': [9], 'within': [10], 'the': [11, 22, 47, 70, 78, 119, 141, 149, 180, 224, 238, 250, 255, 271, 277], 'next': [12], 'decade,': [13], 'creating': [14], 'a': [15, 26, 31, 74, 129], 'personal,': [16], 'industrial,': [17], 'and': [18, 35, 52, 85, 99, 112, 163, 198, 202, 208], 'social': [19], 'shift': [20], 'towards': [21, 37], 'new': [23], 'technology.': [24, 114], 'As': [25], 'result,': [27], 'there': [28], 'has': [29], 'been': [30], 'surge': [32], 'of': [33, 40, 59, 62, 101, 135, 189, 211, 244, 249, 279], 'interest': [34], 'research': [36, 49, 263], 'user': [38, 60, 110, 187], 'acceptance': [39, 61, 111, 188], 'AI': [41, 63, 113, 159, 169, 190, 212, 280], 'technology': [42], 'in': [43, 69, 140, 148, 160, 217, 254], 'recent': [44], 'years.': [45], 'However,': [46, 216], 'existing': [48], 'appears': [50, 222], 'dispersed': [51], 'lacks': [53], 'systematic': [54, 75], 'synthesis,': [55], 'limiting': [56], 'our': [57], 'understanding': [58], 'technologies.': [64, 191, 281], 'To': [65], 'address': [66], 'this': [67], 'gap': [68], 'literature,': [71], 'we': [72], 'conducted': [73], 'review': [76], 'following': [77], 'Preferred': [79], 'Reporting': [80], 'Items': [81], 'for': [82, 170, 226], 'Systematic': [83], 'Reviews': [84], 'meta-Analysis': [86], 'guidelines': [87], 'using': [88, 264], 'five': [89], 'databases:': [90], 'EBSCO': [91], 'host,': [92], 'Embase,': [93], 'Inspec': [94], '(Engineering': [95], 'Village': [96], 'host),': [97], 'Scopus,': [98], 'Web': [100], 'Science.': [102], 'Papers': [103], 'were': [104, 138, 146], 'required': [105], 'focus': [107], 'on': [108, 259], 'both': [109], 'Acceptance': [115, 176], 'was': [116, 179], 'defined': [117], 'as': [118], 'behavioural': [120, 205], 'intention': [121], 'or': [122, 127, 131, 232, 241], 'willingness': [123], 'use,': [125], 'buy,': [126], 'try': [128], 'good': [130], 'service.': [132], 'A': [133], 'total': [134], '7912': [136], 'articles': [137, 145], 'identified': [139], 'database': [142], 'search.': [143], 'Sixty': [144], 'included': [147], 'review.': [150], 'Most': [151], 'studies': [152, 165], '(n': [153], '=': [154], '31)': [155], 'did': [156, 166], 'not': [157, 167], 'define': [158, 168], 'their': [161, 171], 'papers,': [162], '38': [164], 'participants.': [172], 'The': [173], 'extended': [174], 'Technology': [175], 'Model': [177], '(TAM)': [178], 'frequently': [182], 'used': [183], 'theory': [184], 'assess': [186], 'Perceived': [192], 'usefulness,': [193], 'performance': [194], 'expectancy,': [195], 'attitudes,': [196], 'trust,': [197], 'effort': [199], 'expectancy': [200], 'significantly': [201], 'positively': [203], 'intention,': [206], 'willingness,': [207], 'use': [209], 'behaviour': [210], 'across': [213], 'multiple': [214], 'industries.': [215], 'some': [218], 'cultural': [219], 'scenarios,': [220], 'it': [221], 'that': [223, 247, 274], 'need': [225], 'human': [227], 'contact': [228], 'cannot': [229], 'be': [230], 'replicated': [231], 'replaced': [233], 'by': [234], 'AI,': [235], 'no': [236], 'matter': [237], 'perceived': [239, 242], 'usefulness': [240], 'ease': [243], 'use.': [245], 'Given': [246], 'methodological': [251], 'approaches': [252], 'present': [253], 'literature': [256], 'have': [257], 'relied': [258], 'self-reported': [260], 'data,': [261], 'further': [262], 'naturalistic': [265], 'methods': [266], 'is': [267], 'needed': [268], 'validate': [270], 'theoretical': [272], 'model/s': [273], 'best': [275], 'predict': [276], 'adoption': [278]}",2022,"['Expectancy theory', 'Scopus', 'Systematic review', 'Technology acceptance model', 'Computer science', 'Psychology', 'Usability', 'Knowledge management', 'Social psychology', 'MEDLINE', 'Political science', 'Human–computer interaction', 'Law']","Artificial Intelligence (AI) agents are predicted to infiltrate most industries within the next decade, creating a personal, industrial, and social shift towards the new technology. As a result, there has been a surge of interest and research towards user acceptance of AI technology in recent years. However, the existing research appears dispersed and lacks systematic synthesis, limiting our understanding of user acceptance of AI technologies. To address this gap in the literature, we conducted a systematic review following the Preferred Reporting Items for Systematic Reviews and meta-Analysis guidelines using five databases: EBSCO host, Embase, Inspec (Engineering Village host), Scopus, and Web of Science. Papers were required to focus on both user acceptance and AI technology. Acceptance was defined as the behavioural intention or willingness to use, buy, or try a good or service. A total of 7912 articles were identified in the database search. Sixty articles were included in the review. Most studies (n = 31) did not define AI in their papers, and 38 studies did not define AI for their participants. The extended Technology Acceptance Model (TAM) was the most frequently used theory to assess user acceptance of AI technologies. Perceived usefulness, performance expectancy, attitudes, trust, and effort expectancy significantly and positively predicted behavioural intention, willingness, and use behaviour of AI across multiple industries. However, in some cultural scenarios, it appears that the need for human contact cannot be replicated or replaced by AI, no matter the perceived usefulness or perceived ease of use. Given that most of the methodological approaches present in the literature have relied on self-reported data, further research using naturalistic methods is needed to validate the theoretical model/s that best predict the adoption of AI technologies."
https://openalex.org/W2772124661,Artificial Intelligence and Statistics,"{'Artificial': [0], 'intelligence': [1], '(AI)': [2], 'is': [3], 'intrinsically': [4], 'data-driven.': [5], 'It': [6], 'calls': [7], 'for': [8, 63], 'the': [9, 39, 89, 105, 111, 122], 'application': [10], 'of': [11, 19, 22, 26, 42, 45, 48, 53, 81, 91, 98, 107, 113], 'statistical': [12, 40, 65], 'concepts': [13, 41], 'through': [14, 38], 'human-machine': [15, 33], 'collaboration': [16, 34], 'during': [17], 'generation': [18], 'data,': [20, 50], 'development': [21], 'algorithms,': [23], 'and': [24, 51, 73, 83, 96, 100, 119], 'evaluation': [25], 'results.': [27, 102], 'This': [28], 'paper': [29], 'discusses': [30], 'how': [31], 'such': [32], 'can': [35], 'be': [36], 'approached': [37], 'population,': [43], 'question': [44], 'interest,': [46], 'representativeness': [47], 'training': [49], 'scrutiny': [52], 'results': [54], '(PQRS).': [55], 'The': [56], 'PQRS': [57], 'workflow': [58], 'provides': [59], 'a': [60], 'conceptual': [61], 'framework': [62], 'integrating': [64], 'ideas': [66, 76], 'with': [67], 'human': [68], 'input': [69], 'into': [70], 'AI': [71], 'products': [72], 'research.': [74, 125], 'These': [75], 'include': [77], 'experimental': [78], 'design': [79], 'principles': [80, 109], 'randomization': [82], 'local': [84], 'control': [85], 'as': [86, 88], 'well': [87], 'principle': [90], 'stability': [92], 'to': [93], 'gain': [94], 'reproducibility': [95], 'interpretability': [97], 'algorithms': [99], 'data': [101], 'We': [103], 'discuss': [104], 'use': [106], 'these': [108], 'in': [110], 'contexts': [112], 'self-driving': [114], 'cars,': [115], 'automated': [116], 'medical': [117], 'diagnoses,': [118], 'examples': [120], 'from': [121], ""authors'"": [123], 'collaborative': [124]}",2017,"['Representativeness heuristic', 'Interpretability', 'Computer science', 'Workflow', 'Artificial intelligence', 'Data science', 'Machine learning', 'Scrutiny', 'Population', 'Data mining', 'Management science', 'Statistics', 'Mathematics', 'Engineering', 'Political science', 'Sociology', 'Law', 'Demography', 'Database']","Artificial intelligence (AI) is intrinsically data-driven. It calls for the application of statistical concepts through human-machine collaboration during generation of data, development of algorithms, and evaluation of results. This paper discusses how such human-machine collaboration can be approached through the statistical concepts of population, question of interest, representativeness of training data, and scrutiny of results (PQRS). The PQRS workflow provides a conceptual framework for integrating statistical ideas with human input into AI products and research. These ideas include experimental design principles of randomization and local control as well as the principle of stability to gain reproducibility and interpretability of algorithms and data results. We discuss the use of these principles in the contexts of self-driving cars, automated medical diagnoses, and examples from the authors' collaborative research."
https://openalex.org/W3203241482,"Artificial intelligence in the construction industry: A review of present status, opportunities and future challenges","{'©': [0], '2021': [1], 'The': [2, 4, 76], 'Authors.': [3], 'growth': [5], 'of': [6, 78, 110, 153, 180, 216], 'the': [7, 14, 38, 43, 54, 108, 123, 147, 160, 176, 209, 213, 219], 'construction': [8, 34, 124, 148, 161, 184, 220], 'industry': [9, 35, 162], 'is': [10, 36, 66], 'severely': [11], 'limited': [12], 'by': [13], 'myriad': [15], 'complex': [16], 'challenges': [17, 114, 142, 179], 'it': [18, 48, 51, 56, 201], 'faces': [19], 'such': [20, 70, 80, 163], 'as': [21, 71, 81, 164, 200, 206, 208], 'cost': [22], 'and': [23, 27, 30, 74, 89, 104, 138, 141, 170, 178, 187], 'time': [24], 'overruns,': [25], 'health': [26], 'safety,': [28], 'productivity': [29], 'labour': [31], 'shortages.': [32], 'Also,': [33], 'one': [37], 'least': [39], 'digitized': [40], 'industries': [41, 69, 97], 'in': [42, 95, 122, 146, 159, 183, 189, 218], 'world,': [44], 'which': [45, 115], 'has': [46], 'made': [47], 'difficult': [49], 'for': [50, 143], 'to': [52, 98, 118, 129, 203, 211], 'tackle': [53], 'problems': [55], 'currently': [57, 67], 'faces.': [58], 'An': [59], 'advanced': [60], 'digital': [61], 'technology,': [62], 'Artificial': [63], 'Intelligence': [64], '(AI),': [65], 'revolutionising': [68], 'manufacturing,': [72], 'retail,': [73], 'telecommunications.': [75], 'subfields': [77], 'AI': [79, 111, 119, 131, 134, 144, 157, 181, 198, 217], 'machine': [82], 'learning,': [83], 'knowledge-based': [84], 'systems,': [85], 'computer': [86], 'vision,': [87], 'robotics': [88], 'optimisation': [90, 172], 'have': [91], 'successfully': [92], 'been': [93], 'applied': [94], 'other': [96], 'achieve': [99], 'increased': [100], 'profitability,': [101], 'efficiency,': [102], 'safety': [103], 'security.': [105], 'While': [106], 'acknowledging': [107], 'benefits': [109, 215], 'applications,': [112, 132], 'numerous': [113], 'are': [116], 'relevant': [117], 'still': [120], 'exist': [121], 'industry.': [125, 149, 221], 'This': [126, 192], 'study': [127, 193], 'aims': [128], 'unravel': [130], 'examine': [133], 'techniques': [135], 'being': [136], 'used': [137], 'identify': [139], 'opportunites': [140], 'applications': [145, 158, 182, 199], 'A': [150], 'critical': [151], 'review': [152], 'available': [154], 'literature': [155], 'on': [156], 'activity': [165], 'monitoring,': [166], 'risk': [167], 'management,': [168], 'resource': [169], 'waste': [171], 'was': [173], 'conducted.': [174], 'Furthermore,': [175], 'opportunities': [177], 'were': [185], 'identified': [186], 'presented': [188], 'this': [190], 'study.': [191], 'provides': [194], 'insights': [195], 'into': [196], 'key': [197], 'applies': [202], 'construction-specific': [204], 'challenges,': [205], 'well': [207], 'pathway': [210], 'realise': [212], 'acrueable': [214]}",2021,"['Productivity', 'Profitability index', 'Engineering', 'Applications of artificial intelligence', 'Resource efficiency', 'Industry 4.0', 'Engineering management', 'Robotics', 'Risk analysis (engineering)', 'Construction industry', 'Artificial intelligence', 'Economic shortage', 'Computer science', 'Manufacturing engineering', 'Construction engineering', 'Business', 'Robot', 'Linguistics', 'Ecology', 'Economics', 'Finance', 'Biology', 'Macroeconomics', 'Embedded system', 'Government (linguistics)', 'Philosophy']","© 2021 The Authors. The growth of the construction industry is severely limited by the myriad complex challenges it faces such as cost and time overruns, health and safety, productivity and labour shortages. Also, construction industry is one the least digitized industries in the world, which has made it difficult for it to tackle the problems it currently faces. An advanced digital technology, Artificial Intelligence (AI), is currently revolutionising industries such as manufacturing, retail, and telecommunications. The subfields of AI such as machine learning, knowledge-based systems, computer vision, robotics and optimisation have successfully been applied in other industries to achieve increased profitability, efficiency, safety and security. While acknowledging the benefits of AI applications, numerous challenges which are relevant to AI still exist in the construction industry. This study aims to unravel AI applications, examine AI techniques being used and identify opportunites and challenges for AI applications in the construction industry. A critical review of available literature on AI applications in the construction industry such as activity monitoring, risk management, resource and waste optimisation was conducted. Furthermore, the opportunities and challenges of AI applications in construction were identified and presented in this study. This study provides insights into key AI applications as it applies to construction-specific challenges, as well as the pathway to realise the acrueable benefits of AI in the construction industry."
https://openalex.org/W3113317199,Artificial intelligence and machine learning in design of mechanical materials,"{'This': [0], 'review': [1], 'revisits': [2], 'the': [3, 6, 12], 'state': [4], 'of': [5, 8, 14], 'art': [7], 'research': [9], 'efforts': [10], 'on': [11], 'design': [13], 'mechanical': [15], 'materials': [16], 'using': [17], 'machine': [18], 'learning.': [19]}",2020,"['Mechanical design', 'Materials science', 'Machine design', 'Artificial intelligence', 'Nanotechnology', 'Mechanical engineering', 'Computer science', 'Engineering']",This review revisits the state of the art of research efforts on the design of mechanical materials using machine learning.
https://openalex.org/W3128384299,Artificial intelligence in marketing: Systematic review and future research direction,"{'Disruptive': [0], 'technologies': [1], 'such': [2], 'as': [3], 'the': [4, 17, 23, 30, 47, 63, 118, 136, 144], 'internet': [5], 'of': [6, 65, 85, 96, 107], 'things,': [7], 'big': [8], 'data': [9], 'analytics,': [10], 'blockchain,': [11], 'and': [12, 34, 71, 92, 102, 112, 126, 132, 138, 151], 'artificial': [13, 26, 66], 'intelligence': [14, 27, 67], 'have': [15], 'changed': [16], 'ways': [18], 'businesses': [19], 'operate.': [20], 'Of': [21], 'all': [22], 'disruptive': [24], 'technologies,': [25], '(AI)': [28, 68], 'is': [29], 'latest': [31], 'technological': [32], 'disruptor': [33], 'holds': [35], 'immense': [36], 'marketing': [37, 54, 70, 88], 'transformation': [38], 'potential.': [39], 'Practitioners': [40], 'worldwide': [41], 'are': [42], 'trying': [43], 'to': [44, 80, 116, 155], 'figure': [45], 'out': [46], 'best': [48], 'fit': [49], 'AI': [50, 86, 157], 'solutions': [51], 'for': [52], 'their': [53], 'functions.': [55], 'However,': [56], 'a': [57, 82], 'systematic': [58], 'literature': [59, 98], 'review': [60, 84, 106], 'can': [61], 'highlight': [62], 'importance': [64], 'in': [69, 87, 158], 'chart': [72], 'future': [73, 152], 'research': [74, 149, 153], 'directions.': [75], 'The': [76], 'present': [77], 'study': [78], 'aims': [79], 'offer': [81], 'comprehensive': [83, 105], 'using': [89, 143], 'bibliometric,': [90], 'conceptual': [91, 137], 'intellectual': [93, 139], 'network': [94], 'analysis': [95, 134], 'extant': [97], 'published': [99], 'between': [100], '1982': [101], '2020.': [103], 'A': [104], 'one': [108], 'thousand': [109], 'five': [110], 'hundred': [111], 'eighty': [113], 'papers': [114], 'helped': [115, 147], 'identify': [117, 148], 'scientific': [119], ""actors'"": [120], 'performance': [121], 'like': [122], 'most': [123, 127], 'relevant': [124, 128], 'authors': [125], 'sources.': [129], 'Furthermore,': [130], 'co-citation': [131], 'co-occurrence': [133], 'offered': [135], 'network.': [140], 'Data': [141], 'clustering': [142], 'Louvain': [145], 'algorithm': [146], 'sub-themes': [150], 'directions': [154], 'expand': [156], 'marketing.': [159]}",2021,"['Data science', 'Extant taxon', 'Big data', 'Marketing research', 'Computer science', 'The Internet', 'Management science', 'Marketing', 'Knowledge management', 'Business', 'Engineering', 'World Wide Web', 'Data mining', 'Biology', 'Evolutionary biology']","Disruptive technologies such as the internet of things, big data analytics, blockchain, and artificial intelligence have changed the ways businesses operate. Of all the disruptive technologies, artificial intelligence (AI) is the latest technological disruptor and holds immense marketing transformation potential. Practitioners worldwide are trying to figure out the best fit AI solutions for their marketing functions. However, a systematic literature review can highlight the importance of artificial intelligence (AI) in marketing and chart future research directions. The present study aims to offer a comprehensive review of AI in marketing using bibliometric, conceptual and intellectual network analysis of extant literature published between 1982 and 2020. A comprehensive review of one thousand five hundred and eighty papers helped to identify the scientific actors' performance like most relevant authors and most relevant sources. Furthermore, co-citation and co-occurrence analysis offered the conceptual and intellectual network. Data clustering using the Louvain algorithm helped identify research sub-themes and future research directions to expand AI in marketing."
https://openalex.org/W2893740026,Supply chain risk management and artificial intelligence: state of the art and future research directions,"{'Supply': [0], 'chain': [1, 78, 109], 'risk': [2, 110], 'management': [3], '(SCRM)': [4], 'encompasses': [5], 'a': [6, 33, 56, 73, 118, 156], 'wide': [7], 'variety': [8], 'of': [9, 32, 67, 76, 107, 159, 180], 'strategies': [10, 37], 'aiming': [11], 'to': [12, 71, 84, 123, 128, 137, 164], 'identify,': [13], 'assess,': [14], 'mitigate': [15], 'and': [16, 42, 105, 111, 140, 144, 168, 171, 182], 'monitor': [17], 'unexpected': [18], 'events': [19], 'or': [20, 153], 'conditions': [21], 'which': [22], 'might': [23], 'have': [24], 'an': [25, 97], 'impact,': [26], 'mostly': [27], 'adverse,': [28], 'on': [29, 40, 46, 101], 'any': [30], 'part': [31], 'supply': [34, 77, 108], 'chain.': [35], 'SCRM': [36, 55, 85, 147, 181], 'often': [38], 'depend': [39], 'rapid': [41], 'adaptive': [43], 'decision-making': [44], 'based': [45], 'potentially': [47], 'large,': [48], 'multidimensional': [49], 'data': [50], 'sources.': [51], 'These': [52], 'characteristics': [53], 'make': [54], 'suitable': [57], 'application': [58], 'area': [59], 'for': [60, 174], 'artificial': [61], 'intelligence': [62], '(AI)': [63], 'techniques.': [64], 'The': [65], 'aim': [66], 'this': [68], 'paper': [69], 'is': [70, 99, 121, 162], 'provide': [72], 'comprehensive': [74, 157], 'review': [75], 'literature': [79, 126], 'that': [80, 88, 95], 'addresses': [81], 'problems': [82], 'relevant': [83], 'using': [86], 'approaches': [87], 'fall': [89], 'within': [90], 'the': [91, 102, 129, 145, 178], 'AI': [92, 130], 'spectrum.': [93], 'To': [94], 'end,': [96], 'investigation': [98], 'conducted': [100], 'various': [103], 'definitions': [104], 'classifications': [106], 'related': [112], 'notions': [113], 'such': [114], 'as': [115], 'uncertainty.': [116], 'Then,': [117], 'mapping': [119], 'study': [120], 'performed': [122], 'categorise': [124], 'existing': [125], 'according': [127], 'methodology': [131], 'used,': [132], 'ranging': [133], 'from': [134], 'mathematical': [135], 'programming': [136], 'Machine': [138], 'Learning': [139], 'Big': [141], 'Data': [142], 'Analytics,': [143], 'specific': [146], 'task': [148], 'they': [149], 'address': [150], '(identification,': [151], 'assessment': [152], 'response).': [154], 'Finally,': [155], 'analysis': [158], 'each': [160], 'category': [161], 'provided': [163], 'identify': [165], 'missing': [166], 'aspects': [167], 'unexplored': [169], 'areas': [170], 'propose': [172], 'directions': [173], 'future': [175], 'research': [176], 'at': [177], 'confluence': [179], 'AI.': [183]}",2018,"['Supply chain', 'Computer science', 'Variety (cybernetics)', 'Task (project management)', 'Risk analysis (engineering)', 'Analytics', 'Big data', 'Supply chain management', 'Risk management', 'Identification (biology)', 'Supply chain risk management', 'Artificial intelligence', 'Data science', 'Systems engineering', 'Service management', 'Engineering', 'Data mining', 'Business', 'Marketing', 'Biology', 'Botany', 'Finance']","Supply chain risk management (SCRM) encompasses a wide variety of strategies aiming to identify, assess, mitigate and monitor unexpected events or conditions which might have an impact, mostly adverse, on any part of a supply chain. SCRM strategies often depend on rapid and adaptive decision-making based on potentially large, multidimensional data sources. These characteristics make SCRM a suitable application area for artificial intelligence (AI) techniques. The aim of this paper is to provide a comprehensive review of supply chain literature that addresses problems relevant to SCRM using approaches that fall within the AI spectrum. To that end, an investigation is conducted on the various definitions and classifications of supply chain risk and related notions such as uncertainty. Then, a mapping study is performed to categorise existing literature according to the AI methodology used, ranging from mathematical programming to Machine Learning and Big Data Analytics, and the specific SCRM task they address (identification, assessment or response). Finally, a comprehensive analysis of each category is provided to identify missing aspects and unexplored areas and propose directions for future research at the confluence of SCRM and AI."
https://openalex.org/W4229056760,The Promises and Challenges of Artificial Intelligence for Teachers: a Systematic Review of Research,"{'Abstract': [0], 'This': [1], 'study': [2], 'provides': [3], 'an': [4], 'overview': [5], 'of': [6, 11, 62, 76, 98], 'research': [7], 'on': [8], 'teachers’': [9, 22], 'use': [10], 'artificial': [12], 'intelligence': [13], '(AI)': [14], 'applications': [15], 'and': [16, 41, 52, 55, 89], 'machine': [17], 'learning': [18], 'methods': [19], 'to': [20], 'analyze': [21], 'data.': [23], 'Our': [24, 103], 'analysis': [25], 'showed': [26], 'that': [27, 68], 'AI': [28, 77, 87, 92, 99, 110], 'offers': [29], 'teachers': [30, 43, 69], 'several': [31, 107], 'opportunities': [32], 'for': [33, 85, 118], 'improved': [34], 'planning': [35], '(e.g.,': [36, 48, 57], 'by': [37, 94], 'defining': [38], 'students’': [39], 'needs': [40], 'familiarizing': [42], 'with': [44], 'such': [45], 'needs),': [46], 'implementation': [47, 111], 'through': [49, 58], 'immediate': [50], 'feedback': [51], 'teacher': [53], 'intervention),': [54], 'assessment': [56, 101], 'automated': [59, 100], 'essay': [60], 'scoring)': [61], 'their': [63], 'teaching.': [64], 'We': [65], 'also': [66], 'found': [67], 'have': [70], 'various': [71], 'roles': [72, 80], 'in': [73, 91, 109, 112], 'the': [74, 96, 120], 'development': [75, 93], 'technology.': [78], 'These': [79], 'include': [81], 'acting': [82], 'as': [83], 'models': [84], 'training': [86], 'algorithms': [88], 'participating': [90], 'checking': [95], 'accuracy': [97], 'systems.': [102], 'findings': [104], 'further': [105], 'underlined': [106], 'challenges': [108], 'teaching': [113], 'practice,': [114], 'which': [115], 'provide': [116], 'guidelines': [117], 'developing': [119], 'field.': [121]}",2022,"['Field (mathematics)', 'Computer science', 'Artificial intelligence', 'Applications of artificial intelligence', 'Intervention (counseling)', 'Educational technology', 'Mathematics education', 'Psychology', 'Pure mathematics', 'Psychiatry', 'Mathematics']","Abstract This study provides an overview of research on teachers’ use of artificial intelligence (AI) applications and machine learning methods to analyze teachers’ data. Our analysis showed that AI offers teachers several opportunities for improved planning (e.g., by defining students’ needs and familiarizing teachers with such needs), implementation (e.g., through immediate feedback and teacher intervention), and assessment (e.g., through automated essay scoring) of their teaching. We also found that teachers have various roles in the development of AI technology. These roles include acting as models for training AI algorithms and participating in AI development by checking the accuracy of AI automated assessment systems. Our findings further underlined several challenges in AI implementation in teaching practice, which provide guidelines for developing the field."
https://openalex.org/W3212941463,"Edge Artificial Intelligence for 6G: Vision, Enabling Technologies, and Applications","{'The': [0], 'thriving': [1], 'of': [2, 12, 29, 66, 109, 130, 142, 182], 'artificial': [3], 'intelligence': [4], '(AI)': [5], 'applications': [6], 'is': [7], 'driving': [8], 'the': [9, 27, 67, 80, 103, 178], 'further': [10], 'evolution': [11, 28], 'wireless': [13, 30, 131, 143], 'networks.': [14, 111], 'It': [15], 'has': [16], 'been': [17], 'envisioned': [18], 'that': [19], '6G': [20, 92, 110], 'will': [21, 25, 162], 'be': [22, 163], 'transformative': [23], 'and': [24, 41, 51, 61, 69, 76, 99, 107, 122, 134, 167, 170, 180], 'revolutionize': [26], 'from': [31], ""'connected"": [32, 35], ""things'"": [33], 'to': [34, 93, 158, 176], ""intelligence'."": [36], 'However,': [37], 'state-of-the-art': [38], 'deep': [39], 'learning': [40, 137], 'big': [42], 'data': [43], 'analytics': [44], 'based': [45], 'AI': [46, 84, 125, 161, 184], 'systems': [47, 126], 'require': [48], 'tremendous': [49], 'computation': [50], 'communication': [52, 132], 'resources,': [53], 'causing': [54], 'significant': [55], 'latency,': [56], 'energy': [57], 'consumption,': [58], 'network': [59, 81], 'congestion,': [60], 'privacy': [62], 'leakage': [63], 'in': [64], 'both': [65], 'training': [68, 75], 'inference': [70, 77], 'processes.': [71], 'By': [72], 'embedding': [73], 'model': [74], 'capabilities': [78], 'into': [79], 'edge,': [82], 'edge': [83, 124, 160, 183], 'stands': [85], 'out': [86], 'as': [87, 150, 152], 'a': [88, 153], 'disruptive': [89], 'technology': [90], 'for': [91, 120], 'seamlessly': [94], 'integrate': [95], 'sensing,': [96], 'communication,': [97], 'computation,': [98], 'intelligence,': [100], 'thereby': [101], 'improving': [102], 'efficiency,': [104], 'effectiveness,': [105], 'privacy,': [106], 'security': [108], 'In': [112], 'this': [113], 'paper,': [114], 'we': [115], 'shall': [116], 'provide': [117], 'our': [118], 'vision': [119], 'scalable': [121], 'trustworthy': [123], 'with': [127], 'integrated': [128], 'design': [129, 140], 'strategies': [133], 'decentralized': [135], 'machine': [136], 'models.': [138], 'New': [139], 'principles': [141], 'networks,': [144], 'service-driven': [145], 'resource': [146], 'allocation': [147], 'optimization': [148], 'methods,': [149], 'well': [151], 'holistic': [154], 'end-to-end': [155], 'system': [156], 'architecture': [157], 'support': [159], 'described.': [164], 'Standardization,': [165], 'software': [166], 'hardware': [168], 'platforms,': [169], 'application': [171], 'scenarios': [172], 'are': [173], 'also': [174], 'discussed': [175], 'facilitate': [177], 'industrialization': [179], 'commercialization': [181], 'systems.': [185], '©': [186], '1983-2012': [187], 'IEEE.': [188]}",2021,"['Computer science', 'Artificial intelligence', 'Enhanced Data Rates for GSM Evolution', 'Edge computing', 'Human–computer interaction', 'Computer vision', 'Computer architecture', 'Multimedia', 'Telecommunications']","The thriving of artificial intelligence (AI) applications is driving the further evolution of wireless networks. It has been envisioned that 6G will be transformative and will revolutionize the evolution of wireless from 'connected things' to 'connected intelligence'. However, state-of-the-art deep learning and big data analytics based AI systems require tremendous computation and communication resources, causing significant latency, energy consumption, network congestion, and privacy leakage in both of the training and inference processes. By embedding model training and inference capabilities into the network edge, edge AI stands out as a disruptive technology for 6G to seamlessly integrate sensing, communication, computation, and intelligence, thereby improving the efficiency, effectiveness, privacy, and security of 6G networks. In this paper, we shall provide our vision for scalable and trustworthy edge AI systems with integrated design of wireless communication strategies and decentralized machine learning models. New design principles of wireless networks, service-driven resource allocation optimization methods, as well as a holistic end-to-end system architecture to support edge AI will be described. Standardization, software and hardware platforms, and application scenarios are also discussed to facilitate the industrialization and commercialization of edge AI systems. © 1983-2012 IEEE."
https://openalex.org/W1550696814,Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence (1995),"{'This': [0], 'is': [1], 'the': [2, 5], 'Proceedings': [3], 'of': [4], 'Eleventh': [6], 'Conference': [7], 'on': [8], 'Uncertainty': [9], 'in': [10, 16], 'Artificial': [11], 'Intelligence,': [12], 'which': [13], 'was': [14], 'held': [15], 'Montreal,': [17], 'QU,': [18], 'August': [19], '18-20,': [20], '1995': [21]}",2013,"['Eleventh', 'Computer science', 'Artificial intelligence', 'Operations research', 'Political science', 'Engineering', 'Physics', 'Acoustics']","This is the Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence, which was held in Montreal, QU, August 18-20, 1995"
https://openalex.org/W2792145227,Artificial intelligence powers digital medicine,"{'Abstract': [0], 'Artificial': [1], 'intelligence': [2, 65], '(AI)': [3], 'has': [4], 'recently': [5], 'surpassed': [6], 'human': [7, 92], 'performance': [8], 'in': [9, 18, 76], 'several': [10, 70], 'domains,': [11], 'and': [12, 28, 40, 60, 66], 'there': [13], 'is': [14, 88], 'great': [15], 'hope': [16], 'that': [17, 35, 46, 78], 'healthcare,': [19], 'AI': [20, 36, 47, 74], 'may': [21], 'allow': [22], 'for': [23, 57], 'better': [24], 'prevention,': [25], 'detection,': [26], 'diagnosis,': [27], 'treatment': [29], 'of': [30, 63, 73, 82], 'disease.': [31], 'While': [32], 'many': [33, 50], 'fear': [34], 'will': [37], 'disrupt': [38], 'jobs': [39], 'the': [41, 55, 61], 'physician–patient': [42], 'relationship,': [43], 'we': [44], 'believe': [45], 'can': [48], 'eliminate': [49], 'repetitive': [51], 'tasks': [52], 'to': [53], 'clear': [54], 'way': [56], 'human-to-human': [58], 'bonding': [59], 'application': [62], 'emotional': [64], 'judgment.': [67], 'We': [68], 'review': [69], 'recent': [71], 'studies': [72], 'applications': [75], 'healthcare': [77, 86], 'provide': [79], 'a': [80, 83, 89], 'view': [81], 'future': [84], 'where': [85], 'delivery': [87], 'more': [90], 'unified,': [91], 'experience.': [93]}",2018,"['Applications of artificial intelligence', 'Health care', 'Computer science', 'Artificial intelligence', 'Human disease', 'Human intelligence', 'Healthcare delivery', 'Emotional intelligence', 'Psychology', 'Disease', 'Medicine', 'Social psychology', 'Political science', 'Pathology', 'Law']","Abstract Artificial intelligence (AI) has recently surpassed human performance in several domains, and there is great hope that in healthcare, AI may allow for better prevention, detection, diagnosis, and treatment of disease. While many fear that AI will disrupt jobs and the physician–patient relationship, we believe that AI can eliminate many repetitive tasks to clear the way for human-to-human bonding and the application of emotional intelligence and judgment. We review several recent studies of AI applications in healthcare that provide a view of a future where healthcare delivery is a more unified, human experience."
https://openalex.org/W3124957586,"Artificial intelligence capability: Conceptualization, measurement calibration, and empirical study on its impact on organizational creativity and firm performance","{'Artificial': [0], 'intelligence': [1], '(AI)': [2], 'has': [3], 'been': [4], 'heralded': [5], 'by': [6], 'many': [7], 'as': [8], 'the': [9, 17, 21, 30, 37, 56, 60, 65, 79], 'next': [10], 'source': [11], 'of': [12, 20, 59], 'business': [13], 'value.': [14], 'Grounded': [15], 'on': [16, 24, 27], 'resource-based': [18], 'theory': [19], 'firm': [22], 'and': [23, 46, 62, 71, 74, 83, 86, 98], 'recent': [25], 'work': [26], 'AI': [28, 44, 57, 69, 91], 'at': [29], 'organizational': [31, 72, 96], 'context,': [32], 'this': [33], 'study': [34], '(1)': [35], 'identifies': [36], 'AI-specific': [38], 'resources': [39], 'that': [40, 89], 'jointly': [41], 'create': [42], 'an': [43, 52, 68, 90], 'capability': [45, 58, 70, 92], 'provides': [47], 'a': [48], 'definition,': [49], '(2)': [50], 'develops': [51], 'instrument': [53, 85], 'to': [54], 'capture': [55], 'firms,': [61], '(3)': [63], 'examines': [64], 'relationship': [66], 'between': [67], 'creativity': [73, 97], 'performance.': [75, 99], 'Findings': [76], 'empirically': [77], 'support': [78], 'suggested': [80], 'theoretical': [81], 'framework': [82], 'corresponding': [84], 'provide': [87], 'evidence': [88], 'results': [93], 'in': [94], 'increased': [95]}",2021,"['Creativity', 'Conceptualization', 'Knowledge management', 'Context (archaeology)', 'Organizational performance', 'Computer science', 'Empirical research', 'Artificial intelligence', 'Psychology', 'Social psychology', 'Biology', 'Epistemology', 'Paleontology', 'Philosophy']","Artificial intelligence (AI) has been heralded by many as the next source of business value. Grounded on the resource-based theory of the firm and on recent work on AI at the organizational context, this study (1) identifies the AI-specific resources that jointly create an AI capability and provides a definition, (2) develops an instrument to capture the AI capability of the firms, and (3) examines the relationship between an AI capability and organizational creativity and performance. Findings empirically support the suggested theoretical framework and corresponding instrument and provide evidence that an AI capability results in increased organizational creativity and performance."
https://openalex.org/W3011742849,Artificial intelligence with multi-functional machine learning platform development for better healthcare and precision medicine,"{'Abstract': [0], 'Precision': [1], 'medicine': [2, 47, 122, 258], 'is': [3, 137, 233], 'one': [4], 'of': [5, 24, 77, 89, 107, 143, 156, 173, 194, 228, 251, 296], 'the': [6, 16, 20, 40, 49, 87, 92, 108, 141, 190, 239, 244, 249, 289], 'recent': [7], 'and': [8, 32, 35, 45, 62, 66, 131, 152, 164, 171, 176, 185, 192, 211, 224, 256, 269, 275, 280], 'powerful': [9], 'developments': [10], 'in': [11, 84, 103, 231, 241, 287, 298], 'medical': [12], 'care,': [13], 'which': [14, 70], 'has': [15, 238], 'potential': [17, 240], 'to': [18, 43, 51, 60, 73, 99, 126, 139, 168, 189, 220, 243, 283], 'improve': [19], 'traditional': [21], 'symptom-driven': [22], 'practice': [23], 'medicine,': [25], 'allowing': [26], 'earlier': [27], 'interventions': [28], 'using': [29], 'advanced': [30], 'diagnostics': [31], 'tailoring': [33], 'better': [34, 75, 254], 'economically': [36], 'personalized': [37, 44, 255], 'treatments.': [38], 'Identifying': [39], 'best': [41], 'pathway': [42], 'population': [46, 257], 'involves': [48], 'ability': [50, 125], 'analyze': [52], 'comprehensive': [53], 'patient': [54, 129], 'information': [55, 102], 'together': [56], 'with': [57, 123, 197], 'broader': [58], 'aspects': [59], 'monitor': [61], 'distinguish': [63], 'between': [64], 'sick': [65], 'relatively': [67], 'healthy': [68], 'people,': [69], 'will': [71], 'lead': [72], 'a': [74, 234, 292], 'understanding': [76], 'biological': [78], 'indicators': [79], 'that': [80, 237], 'can': [81, 213], 'signal': [82], 'shifts': [83], 'health.': [85], 'While': [86], 'complexities': [88], 'disease': [90, 157], 'at': [91, 259], 'individual': [93], 'level': [94], 'have': [95, 111], 'made': [96], 'it': [97, 136], 'difficult': [98], 'utilize': [100], 'healthcare': [101, 195, 232], 'clinical': [104, 206], 'decision-making,': [105], 'some': [106], 'existing': [109], 'constraints': [110], 'been': [112], 'greatly': [113], 'minimized': [114], 'by': [115, 147, 216], 'technological': [116], 'advancements.': [117], 'To': [118], 'implement': [119], 'effective': [120, 198], 'precision': [121], 'enhanced': [124], 'positively': [127], 'impact': [128], 'outcomes': [130], 'provide': [132], 'real-time': [133], 'decision': [134], 'support,': [135], 'important': [138], 'harness': [140], 'power': [142], 'electronic': [144], 'health': [145, 178], 'records': [146], 'integrating': [148], 'disparate': [149], 'data': [150, 196, 207], 'sources': [151], 'discovering': [153], 'patient-specific': [154], 'patterns': [155], 'progression.': [158], 'Useful': [159], 'analytic': [160], 'tools,': [161], 'technologies,': [162], 'databases,': [163], 'approaches': [165, 279], 'are': [166], 'required': [167], 'augment': [169], 'networking': [170], 'interoperability': [172], 'clinical,': [174], 'laboratory': [175], 'public': [177], 'systems,': [179], 'as': [180, 182], 'well': [181], 'addressing': [183], 'ethical': [184], 'social': [186], 'issues': [187], 'related': [188], 'privacy': [191], 'protection': [193], 'balance.': [199], 'Developing': [200], 'multifunctional': [201], 'machine': [202, 276], 'learning': [203, 277], 'platforms': [204], 'for': [205, 247, 291], 'extraction,': [208], 'aggregation,': [209], 'management': [210], 'analysis': [212], 'support': [214], 'clinicians': [215], 'efficiently': [217], 'stratifying': [218], 'subjects': [219], 'understand': [221], 'specific': [222], 'scenarios': [223], 'optimize': [225], 'decision-making.': [226], 'Implementation': [227], 'artificial': [229, 273], 'intelligence': [230, 274], 'compelling': [235], 'vision': [236], 'leading': [242], 'significant': [245], 'improvements': [246], 'achieving': [248], 'goals': [250], 'providing': [252], 'real-time,': [253], 'lower': [260], 'costs.': [261], 'In': [262], 'this': [263], 'study,': [264], 'we': [265], 'focused': [266], 'on': [267], 'analyzing': [268], 'discussing': [270], 'various': [271], 'published': [272], 'solutions,': [278], 'perspectives,': [281], 'aiming': [282], 'advance': [284], 'academic': [285], 'solutions': [286], 'paving': [288], 'way': [290], 'new': [293], 'data-centric': [294], 'era': [295], 'discovery': [297], 'healthcare.': [299]}",2020,"['Interoperability', 'Precision medicine', 'Health care', 'Clinical decision support system', 'Computer science', 'Personalized medicine', 'Artificial intelligence', 'Data science', 'Decision support system', 'Knowledge management', 'Machine learning', 'Medicine', 'Bioinformatics', 'Operating system', 'Biology', 'Economic growth', 'Economics', 'Pathology']","Abstract Precision medicine is one of the recent and powerful developments in medical care, which has the potential to improve the traditional symptom-driven practice of medicine, allowing earlier interventions using advanced diagnostics and tailoring better and economically personalized treatments. Identifying the best pathway to personalized and population medicine involves the ability to analyze comprehensive patient information together with broader aspects to monitor and distinguish between sick and relatively healthy people, which will lead to a better understanding of biological indicators that can signal shifts in health. While the complexities of disease at the individual level have made it difficult to utilize healthcare information in clinical decision-making, some of the existing constraints have been greatly minimized by technological advancements. To implement effective precision medicine with enhanced ability to positively impact patient outcomes and provide real-time decision support, it is important to harness the power of electronic health records by integrating disparate data sources and discovering patient-specific patterns of disease progression. Useful analytic tools, technologies, databases, and approaches are required to augment networking and interoperability of clinical, laboratory and public health systems, as well as addressing ethical and social issues related to the privacy and protection of healthcare data with effective balance. Developing multifunctional machine learning platforms for clinical data extraction, aggregation, management and analysis can support clinicians by efficiently stratifying subjects to understand specific scenarios and optimize decision-making. Implementation of artificial intelligence in healthcare is a compelling vision that has the potential in leading to the significant improvements for achieving the goals of providing real-time, better personalized and population medicine at lower costs. In this study, we focused on analyzing and discussing various published artificial intelligence and machine learning solutions, approaches and perspectives, aiming to advance academic solutions in paving the way for a new data-centric era of discovery in healthcare."
https://openalex.org/W4205941964,"Artificial intelligence in disease diagnosis: a systematic literature review, synthesizing framework and future research agenda","{'Artificial': [0, 15], 'intelligence': [1, 16, 50, 66, 92], 'can': [2], 'assist': [3], 'providers': [4], 'in': [5, 27], 'a': [6], 'variety': [7], 'of': [8, 158, 173, 176, 186], 'patient': [9, 35], 'care': [10], 'and': [11, 34, 72, 108, 112, 126, 130, 141, 167, 214], 'intelligent': [12], 'health': [13], 'systems.': [14], 'techniques': [17, 93], 'ranging': [18], 'from': [19], 'machine': [20], 'learning': [21, 24], 'to': [22, 44, 77, 94, 146, 152], 'deep': [23], 'are': [25, 42, 144, 194], 'prevalent': [26], 'healthcare': [28], 'for': [29, 133, 138, 170], 'disease': [30, 190], 'diagnosis,': [31, 191], 'drug': [32], 'discovery,': [33], 'risk': [36], 'identification.': [37], 'Numerous': [38], 'medical': [39, 123], 'data': [40], 'sources': [41], 'required': [43], 'perfectly': [45], 'diagnose': [46, 95], 'diseases': [47, 97, 177], 'using': [48, 178, 197], 'artificial': [49, 65, 91, 179], 'techniques,': [51], 'such': [52, 98, 201], 'as': [53, 99, 202], 'ultrasound,': [54], 'magnetic': [55], 'resonance': [56], 'imaging,': [57], 'mammography,': [58], 'genomics,': [59], 'computed': [60], 'tomography': [61], 'scan,': [62], 'etc.': [63], 'Furthermore,': [64], 'primarily': [67], 'enhanced': [68], 'the': [69, 86, 121, 148, 156, 184, 192, 208], 'infirmary': [70], 'experience': [71], 'sped': [73], 'up': [74, 151], 'preparing': [75], 'patients': [76], 'continue': [78], 'their': [79, 127], 'rehabilitation': [80], 'at': [81], 'home.': [82], 'This': [83], 'article': [84], 'covers': [85], 'comprehensive': [87], 'survey': [88, 119], 'based': [89], 'on': [90, 155, 183, 189], 'numerous': [96], 'Alzheimer,': [100], 'cancer,': [101], 'diabetes,': [102], 'chronic': [103], 'heart': [104], 'disease,': [105], 'tuberculosis,': [106], 'stroke': [107], 'cerebrovascular,': [109], 'hypertension,': [110], 'skin,': [111], 'liver': [113], 'disease.': [114], 'We': [115], 'conducted': [116], 'an': [117], 'extensive': [118], 'including': [120], 'used': [122, 145], 'imaging': [124], 'dataset': [125], 'feature': [128], 'extraction': [129], 'classification': [131], 'process': [132], 'predictions.': [134], 'Preferred': [135], 'reporting': [136], 'items': [137], 'systematic': [139], 'reviews': [140], 'Meta-Analysis': [142], 'guidelines': [143], 'select': [147], 'articles': [149, 188], 'published': [150], 'October': [153], '2020': [154], 'Web': [157], 'Science,': [159], 'Scopus,': [160], 'Google': [161], 'Scholar,': [162], 'PubMed,': [163], 'Excerpta': [164], 'Medical': [165], 'Database,': [166], 'Psychology': [168], 'Information': [169], 'early': [171], 'prediction': [172, 203], 'distinct': [174], 'kinds': [175], 'intelligence-based': [180], 'techniques.': [181], 'Based': [182], 'study': [185], 'different': [187], 'results': [193], 'also': [195], 'compared': [196], 'various': [198], 'quality': [199], 'parameters': [200], 'rate,': [204], 'accuracy,': [205], 'sensitivity,': [206], 'specificity,': [207], 'area': [209], 'under': [210], 'curve': [211], 'precision,': [212], 'recall,': [213], 'F1-score.': [215]}",2022,"['Artificial intelligence', 'Computer science', 'Machine learning', 'Computational intelligence', 'Health care', 'Disease', 'Medicine', 'Pathology', 'Economic growth', 'Economics']","Artificial intelligence can assist providers in a variety of patient care and intelligent health systems. Artificial intelligence techniques ranging from machine learning to deep learning are prevalent in healthcare for disease diagnosis, drug discovery, and patient risk identification. Numerous medical data sources are required to perfectly diagnose diseases using artificial intelligence techniques, such as ultrasound, magnetic resonance imaging, mammography, genomics, computed tomography scan, etc. Furthermore, artificial intelligence primarily enhanced the infirmary experience and sped up preparing patients to continue their rehabilitation at home. This article covers the comprehensive survey based on artificial intelligence techniques to diagnose numerous diseases such as Alzheimer, cancer, diabetes, chronic heart disease, tuberculosis, stroke and cerebrovascular, hypertension, skin, and liver disease. We conducted an extensive survey including the used medical imaging dataset and their feature extraction and classification process for predictions. Preferred reporting items for systematic reviews and Meta-Analysis guidelines are used to select the articles published up to October 2020 on the Web of Science, Scopus, Google Scholar, PubMed, Excerpta Medical Database, and Psychology Information for early prediction of distinct kinds of diseases using artificial intelligence-based techniques. Based on the study of different articles on disease diagnosis, the results are also compared using various quality parameters such as prediction rate, accuracy, sensitivity, specificity, the area under curve precision, recall, and F1-score."
https://openalex.org/W3013681994,"Artificial intelligence versus clinicians: systematic review of design, reporting standards, and claims of deep learning studies","{'Abstract': [0], 'Objective': [1], 'To': [2], 'systematically': [3], 'examine': [4], 'the': [5, 17, 46, 69, 135, 195, 246, 332], 'design,': [6], 'reporting': [7, 207, 217, 225, 299, 374, 454, 485], 'standards,': [8], 'risk': [9, 166, 248, 259, 287, 361, 447, 476], 'of': [10, 14, 19, 29, 42, 71, 83, 104, 137, 167, 216, 226, 240, 249, 260, 280, 288, 293, 329, 356, 362, 368, 382, 387, 396, 408, 412, 448, 477], 'bias,': [11, 289, 449, 478], 'and': [12, 45, 65, 194, 222, 255, 295, 301, 315, 346, 354, 371, 431, 450, 457, 465, 486, 488], 'claims': [13], 'studies': [15, 61, 67, 157, 221, 254, 370, 389, 414, 420, 430, 473], 'comparing': [16, 68], 'performance': [18, 70, 395], 'diagnostic': [20, 173], 'deep': [21, 73, 97, 110, 274, 428], 'learning': [22, 74, 98, 111, 197, 275, 429], 'algorithms': [23], 'for': [24, 59, 127, 133, 143, 163, 219, 231, 236, 252, 264, 273, 291, 380], 'medical': [25, 77, 161, 436], 'imaging': [26, 78, 90, 162], 'with': [27, 79, 118, 185], 'that': [28, 113, 140, 394, 407, 417], 'expert': [30, 87], 'clinicians.': [31, 88, 409], 'Design': [32], 'Systematic': [33], 'review.': [34], 'Data': [35, 456], 'sources': [36], 'Medline,': [37], 'Embase,': [38], 'Cochrane': [39, 247], 'Central': [40], 'Register': [41], 'Controlled': [43], 'Trials,': [44], 'World': [47], 'Health': [48], 'Organization': [49], 'trial': [50, 63], 'registry': [51], 'from': [52, 452], '2010': [53], 'to': [54, 153, 159, 206, 298, 343, 373, 403], 'June': [55], '2019.': [56], 'Eligibility': [57], 'criteria': [58], 'selecting': [60], 'Randomised': [62], 'registrations': [64], 'non-randomised': [66, 237, 265, 307, 439], 'a': [72, 80, 93, 186, 227, 321], 'algorithm': [75, 131], 'in': [76, 96, 109, 320, 331, 352, 366, 391, 435, 462], 'contemporary': [81], 'group': [82, 334], 'one': [84], 'or': [85, 170, 177, 191, 234, 421], 'more': [86], 'Medical': [89], 'has': [91], 'seen': [92], 'growing': [94], 'interest': [95], 'research.': [99], 'The': [100, 130, 155, 326, 359], 'main': [101], 'distinguishing': [102], 'feature': [103], 'convolutional': [105], 'neural': [106], 'networks': [107], '(CNNs)': [108], 'is': [112], 'when': [114], 'CNNs': [115], 'are': [116, 141, 303, 441, 444, 460, 469], 'fed': [117], 'raw': [119, 181], 'data,': [120], 'they': [121], 'develop': [122], 'their': [123, 392], 'own': [124], 'representations': [125], 'needed': [126], 'pattern': [128], 'recognition.': [129], 'learns': [132], 'itself': [134], 'features': [136, 152], 'an': [138], 'image': [139], 'important': [142], 'classification': [144, 171], 'rather': [145], 'than': [146], 'being': [147], 'told': [148], 'by': [149, 211, 244], 'humans': [150], 'which': [151, 198, 281], 'use.': [154], 'selected': [156], 'aimed': [158], 'use': [160], 'predicting': [164], 'absolute': [165], 'existing': [168, 453], 'disease': [169, 176], 'into': [172], 'groups': [174, 468], '(eg,': [175], 'non-disease).': [178], 'For': [179], 'example,': [180], 'chest': [182], 'radiographs': [183], 'tagged': [184], 'label': [187], 'such': [188], 'as': [189], 'pneumothorax': [190, 193], 'no': [192], 'CNN': [196], 'pixel': [199], 'patterns': [200], 'suggest': [201], 'pneumothorax.': [202], 'Review': [203], 'methods': [204], 'Adherence': [205], 'standards': [208, 215, 375], 'was': [209, 242, 335, 348, 364, 376, 399], 'assessed': [210, 243], 'using': [212, 245], 'CONSORT': [213], '(consolidated': [214], 'trials)': [218], 'randomised': [220, 253, 276, 432], 'TRIPOD': [223, 384], '(transparent': [224], 'multivariable': [228], 'prediction': [229], 'model': [230, 258], 'individual': [232], 'prognosis': [233], 'diagnosis)': [235], 'studies.': [238, 266], 'Risk': [239], 'bias': [241, 250, 261, 363], 'tool': [251], 'PROBAST': [256], '(prediction': [257], 'assessment': [262], 'tool)': [263], 'Results': [267], 'Only': [268, 410], '10': [269], 'records': [270], 'were': [271, 313, 318, 423], 'found': [272], 'clinical': [277, 308, 324, 482], 'trials,': [278], 'two': [279], 'have': [282], 'been': [283], 'published': [284], '(with': [285], 'low': [286], 'except': [290], 'lack': [292], 'blinding,': [294], 'high': [296, 365, 446], 'adherence': [297, 372, 379], 'standards)': [300], 'eight': [302], 'ongoing.': [304], 'Of': [305], '81': [306, 369, 388, 413], 'trials': [309, 422, 433, 440], 'identified,': [310], 'only': [311, 336], 'nine': [312], 'prospective': [314, 419, 427], 'just': [316], 'six': [317], 'tested': [319], 'real': [322, 480], 'world': [323, 481], 'setting.': [325], 'median': [327], 'number': [328], 'experts': [330], 'comparator': [333, 467], 'four': [337], '(interquartile': [338], 'range': [339], '2-9).': [340], 'Full': [341], 'access': [342], 'all': [344], 'datasets': [345], 'code': [347, 458], 'severely': [349], 'limited': [350], '(unavailable': [351], '95%': [353], '93%': [355], 'studies,': [357, 464], 'respectively).': [358], 'overall': [360], '58': [367], 'suboptimal': [377], '(&lt;50%': [378], '12': [381], '29': [383], 'items).': [385], '61': [386], 'stated': [390, 416], 'abstract': [393], 'artificial': [397], 'intelligence': [398], 'at': [400, 445], 'least': [401], 'comparable': [402], '(or': [404], 'better': [405], 'than)': [406], '31': [411], '(38%)': [415], 'further': [418], 'required.': [424], 'Conclusions': [425], 'Few': [426], 'exist': [434], 'imaging.': [437], 'Most': [438], 'not': [442], 'prospective,': [443], 'deviate': [451], 'standards.': [455], 'availability': [459], 'lacking': [461], 'most': [463], 'human': [466], 'often': [470], 'small.': [471], 'Future': [472], 'should': [474], 'diminish': [475], 'enhance': [479], 'relevance,': [483], 'improve': [484], 'transparency,': [487], 'appropriately': [489], 'temper': [490], 'conclusions.': [491], 'Study': [492], 'registration': [493], 'PROSPERO': [494], 'CRD42019123605.': [495]}",2020,"['Artificial intelligence', 'Medicine', 'MEDLINE', 'Deep learning', 'Machine learning', 'Systematic review', 'Convolutional neural network', 'Medical physics', 'Computer science', 'Political science', 'Law']","Abstract Objective To systematically examine the design, reporting standards, risk of bias, and claims of studies comparing the performance of diagnostic deep learning algorithms for medical imaging with that of expert clinicians. Design Systematic review. Data sources Medline, Embase, Cochrane Central Register of Controlled Trials, and the World Health Organization trial registry from 2010 to June 2019. Eligibility criteria for selecting studies Randomised trial registrations and non-randomised studies comparing the performance of a deep learning algorithm in medical imaging with a contemporary group of one or more expert clinicians. Medical imaging has seen a growing interest in deep learning research. The main distinguishing feature of convolutional neural networks (CNNs) in deep learning is that when CNNs are fed with raw data, they develop their own representations needed for pattern recognition. The algorithm learns for itself the features of an image that are important for classification rather than being told by humans which features to use. The selected studies aimed to use medical imaging for predicting absolute risk of existing disease or classification into diagnostic groups (eg, disease or non-disease). For example, raw chest radiographs tagged with a label such as pneumothorax or no pneumothorax and the CNN learning which pixel patterns suggest pneumothorax. Review methods Adherence to reporting standards was assessed by using CONSORT (consolidated standards of reporting trials) for randomised studies and TRIPOD (transparent reporting of a multivariable prediction model for individual prognosis or diagnosis) for non-randomised studies. Risk of bias was assessed by using the Cochrane risk of bias tool for randomised studies and PROBAST (prediction model risk of bias assessment tool) for non-randomised studies. Results Only 10 records were found for deep learning randomised clinical trials, two of which have been published (with low risk of bias, except for lack of blinding, and high adherence to reporting standards) and eight are ongoing. Of 81 non-randomised clinical trials identified, only nine were prospective and just six were tested in a real world clinical setting. The median number of experts in the comparator group was only four (interquartile range 2-9). Full access to all datasets and code was severely limited (unavailable in 95% and 93% of studies, respectively). The overall risk of bias was high in 58 of 81 studies and adherence to reporting standards was suboptimal (&lt;50% adherence for 12 of 29 TRIPOD items). 61 of 81 studies stated in their abstract that performance of artificial intelligence was at least comparable to (or better than) that of clinicians. Only 31 of 81 studies (38%) stated that further prospective studies or trials were required. Conclusions Few prospective deep learning studies and randomised trials exist in medical imaging. Most non-randomised trials are not prospective, are at high risk of bias, and deviate from existing reporting standards. Data and code availability are lacking in most studies, and human comparator groups are often small. Future studies should diminish risk of bias, enhance real world clinical relevance, improve reporting and transparency, and appropriately temper conclusions. Study registration PROSPERO CRD42019123605."
https://openalex.org/W2767479331,The Impact of Artificial Intelligence on Innovation,"{'Artificial': [0], 'intelligence': [1], 'may': [2, 12, 170], 'greatly': [3], 'increase': [4], 'the': [5, 8, 30, 33, 37, 49, 72, 103, 114, 117], 'efficiency': [6], 'of': [7, 25, 32, 39, 63, 68, 74, 102, 125, 134, 161], 'existing': [9], 'economy.But': [10], 'it': [11], 'have': [13], 'an': [14], 'even': [15], 'larger': [16], 'impact': [17], 'by': [18, 137], 'serving': [19], 'as': [20, 46, 59], 'a': [21, 60, 69, 88, 132], 'new': [22], 'general-purpose': [23, 61], '""method': [24], 'invention""': [26], 'that': [27, 81, 99, 154], 'can': [28], 'reshape': [29], 'nature': [31], 'innovation': [34], 'process': [35], 'and': [36, 48, 110, 145, 150, 159, 167, 178], 'organization': [38], 'R&D.We': [40], 'distinguish': [41], 'between': [42, 105], 'automation-oriented': [43], 'applications': [44], 'such': [45], 'robotics': [47], 'potential': [50, 118], 'for': [51, 140, 174], 'recent': [52], 'developments': [53], 'in': [54, 71, 131], '""deep': [55], 'learning""': [56], 'to': [57, 85, 87, 129, 143], 'serve': [58], 'method': [62], 'invention,': [64], 'finding': [65], 'strong': [66], 'evidence': [67], '""shift""': [70], 'importance': [73], 'application-oriented': [75], 'learning': [76], 'research': [77, 96, 98, 126, 176], 'since': [78], '2009.We': [79], 'suggest': [80, 153], 'this': [82, 123], 'is': [83], 'likely': [84, 128], 'lead': [86], 'significant': [89], 'substitution': [90], 'away': [91], 'from': [92, 121], 'more': [93], 'routinized': [94], 'labor-intensive': [95], 'towards': [97], 'takes': [100], 'advantage': [101], 'interplay': [104], 'passively': [106], 'generated': [107], 'large': [108, 148], 'datasets': [109, 149, 163], 'enhanced': [111], 'prediction': [112], 'algorithms.At': [113], 'same': [115], 'time,': [116], 'commercial': [119], 'rewards': [120], 'mastering': [122], 'mode': [124], 'are': [127], 'usher': [130], 'period': [133], 'racing,': [135], 'driven': [136], 'powerful': [138], 'incentives': [139], 'individual': [141], 'companies': [142], 'acquire': [144], 'control': [146], 'critical': [147, 172], 'application-specific': [151], 'algorithms.We': [152], 'policies': [155], 'which': [156], 'encourage': [157], 'transparency': [158], 'sharing': [160], 'core': [162], 'across': [164], 'both': [165], 'public': [166], 'private': [168], 'actors': [169], 'be': [171], 'tools': [173], 'stimulating': [175], 'productivity': [177], 'innovation-oriented': [179], 'competition': [180], 'going': [181], 'forward.': [182]}",2018,"['Artificial intelligence', 'Productivity', 'Transparency (behavior)', 'Incentive', 'Computer science', 'Competition (biology)', 'Automation', 'Industrial organization', 'Process (computing)', 'Knowledge management', 'Data science', 'Machine learning', 'Business', 'Engineering', 'Economics', 'Microeconomics', 'Computer security', 'Macroeconomics', 'Operating system', 'Ecology', 'Mechanical engineering', 'Biology']","Artificial intelligence may greatly increase the efficiency of the existing economy.But it may have an even larger impact by serving as a new general-purpose ""method of invention"" that can reshape the nature of the innovation process and the organization of R&D.We distinguish between automation-oriented applications such as robotics and the potential for recent developments in ""deep learning"" to serve as a general-purpose method of invention, finding strong evidence of a ""shift"" in the importance of application-oriented learning research since 2009.We suggest that this is likely to lead to a significant substitution away from more routinized labor-intensive research towards research that takes advantage of the interplay between passively generated large datasets and enhanced prediction algorithms.At the same time, the potential commercial rewards from mastering this mode of research are likely to usher in a period of racing, driven by powerful incentives for individual companies to acquire and control critical large datasets and application-specific algorithms.We suggest that policies which encourage transparency and sharing of core datasets across both public and private actors may be critical tools for stimulating research productivity and innovation-oriented competition going forward."
https://openalex.org/W3097904695,Artificial intelligence in recommender systems,"{'Abstract': [0], 'Recommender': [1], 'systems': [2, 43, 69, 113, 125, 174], 'provide': [3], 'personalized': [4], 'service': [5], 'support': [6, 157], 'to': [7, 44, 111, 123, 161], 'users': [8], 'by': [9], 'learning': [10, 30], 'their': [11, 16], 'previous': [12], 'behaviors': [13], 'and': [14, 28, 32, 48, 52, 64, 70, 79, 91, 100, 117, 144, 147, 159, 166], 'predicting': [15], 'current': [17, 97, 164], 'preferences': [18], 'for': [19], 'particular': [20], 'products.': [21], 'Artificial': [22], 'intelligence': [23, 27], '(AI),': [24], 'particularly': [25], 'computational': [26], 'machine': [29], 'methods': [31], 'algorithms,': [33, 139, 141], 'has': [34], 'been': [35], 'naturally': [36], 'applied': [37], 'in': [38, 67, 152, 169], 'the': [39, 61, 76, 120, 127, 170], 'development': [40, 78], 'of': [41, 81, 129, 172], 'recommender': [42, 68, 82, 112, 173], 'improve': [45, 75], 'prediction': [46], 'accuracy': [47], 'solve': [49], 'data': [50], 'sparsity': [51], 'cold': [53], 'start': [54], 'problems.': [55], 'This': [56], 'position': [57], 'paper': [58, 85, 154], 'systematically': [59], 'discusses': [60], 'basic': [62], 'methodologies': [63], 'prevailing': [65], 'techniques': [66], 'how': [71], 'AI': [72, 131], 'can': [73], 'effectively': [74], 'technological': [77], 'application': [80], 'systems.': [83], 'The': [84, 150], 'not': [86], 'only': [87], 'reviews': [88, 119], 'cutting-edge': [89], 'theoretical': [90], 'practical': [92], 'contributions,': [93], 'but': [94], 'also': [95, 118], 'identifies': [96], 'research': [98, 103], 'issues': [99, 109], 'indicates': [101], 'new': [102, 167], 'directions.': [104], 'It': [105], 'carefully': [106], 'surveys': [107], 'various': [108], 'related': [110], 'that': [114], 'use': [115, 128], 'AI,': [116], 'improvements': [121], 'made': [122], 'these': [124], 'through': [126], 'such': [130], 'approaches': [132], 'as': [133], 'fuzzy': [134], 'techniques,': [135], 'transfer': [136], 'learning,': [137, 146], 'genetic': [138], 'evolutionary': [140], 'neural': [142], 'networks': [143], 'deep': [145], 'active': [148], 'learning.': [149], 'observations': [151], 'this': [153], 'will': [155], 'directly': [156], 'researchers': [158], 'professionals': [160], 'better': [162], 'understand': [163], 'developments': [165], 'directions': [168], 'field': [171], 'using': [175], 'AI.': [176]}",2020,"['Recommender system', 'Computational intelligence', 'Computer science', 'Artificial intelligence', 'Field (mathematics)', 'Machine learning', 'Artificial neural network', 'Fuzzy logic', 'Applications of artificial intelligence', 'Pure mathematics', 'Mathematics']","Abstract Recommender systems provide personalized service support to users by learning their previous behaviors and predicting their current preferences for particular products. Artificial intelligence (AI), particularly computational intelligence and machine learning methods and algorithms, has been naturally applied in the development of recommender systems to improve prediction accuracy and solve data sparsity and cold start problems. This position paper systematically discusses the basic methodologies and prevailing techniques in recommender systems and how AI can effectively improve the technological development and application of recommender systems. The paper not only reviews cutting-edge theoretical and practical contributions, but also identifies current research issues and indicates new research directions. It carefully surveys various issues related to recommender systems that use AI, and also reviews the improvements made to these systems through the use of such AI approaches as fuzzy techniques, transfer learning, genetic algorithms, evolutionary algorithms, neural networks and deep learning, and active learning. The observations in this paper will directly support researchers and professionals to better understand current developments and new directions in the field of recommender systems using AI."
https://openalex.org/W2787887017,"The malicious use of artificial intelligence: Forecasting, prevention, and mitigation","{'This': [0], 'report': [1], 'surveys': [2], 'the': [3, 27, 34, 38, 67, 88], 'landscape': [4, 36], 'of': [5, 12, 69, 91], 'potential': [6], 'security': [7], 'threats': [8], 'from': [9], 'malicious': [10], 'uses': [11], 'AI,': [13], 'and': [14, 21, 41, 52, 93], 'proposes': [15], 'ways': [16, 28], 'to': [17, 78], 'better': [18], 'forecast,': [19], 'prevent,': [20], 'mitigate': [22], 'these': [23], 'threats.': [24], 'After': [25], 'analyzing': [26], 'in': [29, 37], 'which': [30], 'AI': [31, 50], 'may': [32], 'influence': [33], 'threat': [35], 'digital,': [39], 'physical,': [40], 'political': [42], 'domains,': [43], 'we': [44, 81], 'make': [45, 72], 'four': [46], 'high-level': [47], 'recommendations': [48], 'for': [49, 61], 'researchers': [51], 'other': [53], 'stakeholders.': [54], 'We': [55], 'also': [56], 'suggest': [57], 'several': [58], 'promising': [59], 'areas': [60], 'further': [62], 'research': [63], 'that': [64], 'could': [65], 'expand': [66], 'portfolio': [68], 'defenses,': [70], 'or': [71, 76], 'attacks': [73], 'less': [74], 'effective': [75], 'harder': [77], 'execute.': [79], 'Finally,': [80], 'discuss,': [82], 'but': [83], 'do': [84], 'not': [85], 'conclusively': [86], 'resolve,': [87], 'long-term': [89], 'equilibrium': [90], 'attackers': [92], 'defenders.': [94]}",2018,"['Computer science', 'Computer security', 'Term (time)', 'Focus (optics)', 'Artificial intelligence', 'Risk analysis (engineering)', 'Business', 'Optics', 'Quantum mechanics', 'Physics']","This report surveys the landscape of potential security threats from malicious uses of AI, and proposes ways to better forecast, prevent, and mitigate these threats. After analyzing the ways in which AI may influence the threat landscape in the digital, physical, and political domains, we make four high-level recommendations for AI researchers and other stakeholders. We also suggest several promising areas for further research that could expand the portfolio of defenses, or make attacks less effective or harder to execute. Finally, we discuss, but do not conclusively resolve, the long-term equilibrium of attackers and defenders."
https://openalex.org/W2990290777,Artificial intelligence in clinical and genomic diagnostics,"{'Abstract': [0], 'Artificial': [1], 'intelligence': [2], '(AI)': [3], 'is': [4, 98], 'the': [5, 32, 113, 128, 167, 185, 196], 'development': [6], 'of': [7, 91, 116, 170, 199], 'computer': [8, 58], 'systems': [9, 120], 'that': [10, 16, 37, 118, 132, 190], 'are': [11, 61, 121], 'able': [12], 'to': [13, 43, 63, 73, 100, 124], 'perform': [14], 'tasks': [15, 131, 145], 'normally': [17], 'require': [18], 'human': [19, 207], 'intelligence.': [20], 'Advances': [21], 'in': [22, 50, 77, 146, 172, 180, 201], 'AI': [23, 52, 69, 92, 119, 171, 200], 'software': [24], 'and': [25, 31, 46, 103, 126, 154, 157, 184, 188, 209], 'hardware,': [26], 'especially': [27, 176], 'deep': [28, 96], 'learning': [29, 97], 'algorithms': [30], 'graphics': [33], 'processing': [34], 'units': [35], '(GPUs)': [36], 'power': [38], 'their': [39], 'training,': [40], 'have': [41, 71], 'led': [42], 'a': [44, 88, 164], 'recent': [45], 'rapidly': [47], 'increasing': [48], 'interest': [49], 'medical': [51, 202], 'applications.': [53], 'In': [54, 81, 107], 'clinical': [55, 86, 129, 147], 'diagnostics,': [56, 66], 'AI-based': [57], 'vision': [59], 'approaches': [60], 'poised': [62], 'revolutionize': [64], 'image-based': [65], 'while': [67], 'other': [68], 'subtypes': [70], 'begun': [72], 'show': [74], 'similar': [75], 'promise': [76], 'various': [78], 'diagnostic': [79, 130], 'modalities.': [80], 'some': [82], 'areas,': [83], 'such': [84], 'as': [85, 95], 'genomics,': [87, 148], 'specific': [89, 144], 'type': [90], 'algorithm': [93], 'known': [94], 'used': [99], 'process': [101], 'large': [102], 'complex': [104, 182], 'genomic': [105], 'datasets.': [106], 'this': [108], 'review,': [109], 'we': [110, 138, 161], 'first': [111], 'summarize': [112], 'main': [114], 'classes': [115], 'problems': [117], 'well': [122], 'suited': [123], 'solve': [125], 'describe': [127], 'benefit': [133], 'from': [134], 'these': [135], 'solutions.': [136], 'Next,': [137], 'focus': [139], 'on': [140, 166], 'emerging': [141], 'methods': [142], 'for': [143, 177, 195], 'including': [149], 'variant': [150, 155], 'calling,': [151], 'genome': [152], 'annotation': [153], 'classification,': [156], 'phenotype-to-genotype': [158], 'correspondence.': [159], 'Finally,': [160], 'end': [162], 'with': [163], 'discussion': [165], 'future': [168], 'potential': [169], 'individualized': [173], 'medicine': [174], 'applications,': [175, 203], 'risk': [178], 'prediction': [179], 'common': [181], 'diseases,': [183], 'challenges,': [186], 'limitations,': [187], 'biases': [189], 'must': [191], 'be': [192], 'carefully': [193], 'addressed': [194], 'successful': [197], 'deployment': [198], 'particularly': [204], 'those': [205], 'utilizing': [206], 'genetics': [208], 'genomics': [210], 'data.': [211]}",2019,"['Artificial intelligence', 'Computer science', 'Deep learning', 'Precision medicine', 'Genomics', 'Modalities', 'Data science', 'Software deployment', 'Applications of artificial intelligence', 'Process (computing)', 'Annotation', 'Machine learning', 'Genome', 'Medicine', 'Biology', 'Pathology', 'Software engineering', 'Operating system', 'Biochemistry', 'Sociology', 'Gene', 'Social science']","Abstract Artificial intelligence (AI) is the development of computer systems that are able to perform tasks that normally require human intelligence. Advances in AI software and hardware, especially deep learning algorithms and the graphics processing units (GPUs) that power their training, have led to a recent and rapidly increasing interest in medical AI applications. In clinical diagnostics, AI-based computer vision approaches are poised to revolutionize image-based diagnostics, while other AI subtypes have begun to show similar promise in various diagnostic modalities. In some areas, such as clinical genomics, a specific type of AI algorithm known as deep learning is used to process large and complex genomic datasets. In this review, we first summarize the main classes of problems that AI systems are well suited to solve and describe the clinical diagnostic tasks that benefit from these solutions. Next, we focus on emerging methods for specific tasks in clinical genomics, including variant calling, genome annotation and variant classification, and phenotype-to-genotype correspondence. Finally, we end with a discussion on the future potential of AI in individualized medicine applications, especially for risk prediction in common complex diseases, and the challenges, limitations, and biases that must be carefully addressed for the successful deployment of AI in medical applications, particularly those utilizing human genetics and genomics data."
https://openalex.org/W2896245505,"Governing artificial intelligence: ethical, legal and technical opportunities and challenges","{'This': [0, 103, 179], 'paper': [1], 'is': [2, 81, 104, 163, 181], 'the': [3, 6, 31, 44, 65, 72, 79, 107, 123, 152, 174, 184], 'introduction': [4], 'to': [5, 43, 71, 83, 88, 172], 'special': [7, 113], 'issue': [8, 186], 'entitled:': [9], '‘Governing': [10, 187], 'artificial': [11, 188], 'intelligence:': [12, 189], 'ethical,': [13, 124, 190], 'legal': [14], 'and': [15, 18, 40, 54, 64, 85, 92, 99, 126, 160, 192, 195], 'technical': [16, 127, 161, 193], 'opportunities': [17, 194], ""challenges'."": [19], 'Artificial': [20], 'intelligence': [21], '(AI)': [22], 'increasingly': [23], 'permeates': [24], 'every': [25], 'aspect': [26], 'of': [27, 67, 74, 106, 122, 143, 151, 183], 'our': [28], 'society,': [29], 'from': [30], 'critical,': [32], 'like': [33, 46, 56], 'urban': [34], 'infrastructure,': [35], 'law': [36], 'enforcement,': [37], 'banking,': [38], 'healthcare': [39], 'humanitarian': [41], 'aid,': [42], 'mundane': [45], 'dating.': [47], 'AI,': [48], 'including': [49], 'embodied': [50], 'AI': [51, 75, 87, 135, 147, 156, 177], 'in': [52, 76, 111, 115, 146], 'robotics': [53], 'techniques': [55], 'machine': [57], 'learning,': [58], 'can': [59, 95], 'improve': [60], 'economic,': [61], 'social': [62], 'welfare': [63], 'exercise': [66], 'human': [68], 'rights.': [69], 'Owing': [70], 'proliferation': [73], 'high-risk': [77], 'areas,': [78], 'pressure': [80], 'mounting': [82], 'design': [84], 'govern': [86], 'be': [89, 97], 'accountable,': [90], 'fair': [91], 'transparent.': [93], 'How': [94], 'this': [96, 112], 'achieved': [98], 'through': [100], 'which': [101, 116], 'frameworks?': [102], 'one': [105], 'central': [108], 'questions': [109], 'addressed': [110], 'issue,': [114], 'eight': [117], 'authors': [118], 'present': [119], 'in-depth': [120], 'analyses': [121], 'legal-regulatory': [125], 'challenges': [128], 'posed': [129], 'by': [130], 'developing': [131], 'governance': [132], 'regimes': [133], 'for': [134, 154], 'systems.': [136], 'It': [137], 'also': [138], 'gives': [139], 'a': [140], 'brief': [141], 'overview': [142], 'recent': [144], 'developments': [145], 'governance,': [148], 'how': [149], 'much': [150], 'agenda': [153], 'defining': [155], 'regulation,': [157], 'ethical': [158], 'frameworks': [159], 'approaches': [162], 'set,': [164], 'as': [165, 167], 'well': [166], 'providing': [168], 'some': [169], 'concrete': [170], 'suggestions': [171], 'further': [173], 'debate': [175], 'on': [176], 'governance.': [178], 'article': [180], 'part': [182], 'theme': [185], 'legal,': [191], 'challenges’.': [196]}",2018,"['Corporate governance', 'Artificial intelligence', 'Engineering ethics', 'Political science', 'Enforcement', 'Sociology', 'Engineering', 'Law', 'Computer science', 'Economics', 'Management']","This paper is the introduction to the special issue entitled: ‘Governing artificial intelligence: ethical, legal and technical opportunities and challenges'. Artificial intelligence (AI) increasingly permeates every aspect of our society, from the critical, like urban infrastructure, law enforcement, banking, healthcare and humanitarian aid, to the mundane like dating. AI, including embodied AI in robotics and techniques like machine learning, can improve economic, social welfare and the exercise of human rights. Owing to the proliferation of AI in high-risk areas, the pressure is mounting to design and govern AI to be accountable, fair and transparent. How can this be achieved and through which frameworks? This is one of the central questions addressed in this special issue, in which eight authors present in-depth analyses of the ethical, legal-regulatory and technical challenges posed by developing governance regimes for AI systems. It also gives a brief overview of recent developments in AI governance, how much of the agenda for defining AI regulation, ethical frameworks and technical approaches is set, as well as providing some concrete suggestions to further the debate on AI governance. This article is part of the theme issue ‘Governing artificial intelligence: ethical, legal, and technical opportunities and challenges’."
https://openalex.org/W3041968715,Decolonial AI: Decolonial Theory as Sociotechnical Foresight in Artificial Intelligence,"{'Abstract': [0], 'This': [1], 'paper': [2], 'explores': [3], 'the': [4, 22, 35, 47, 57, 136, 186, 219, 226, 243], 'important': [5], 'role': [6], 'of': [7, 13, 51, 59, 89, 138, 141, 153, 169, 177, 188, 201, 228, 245], 'critical': [8, 104, 174], 'science,': [9], 'and': [10, 15, 20, 43, 49, 74, 97, 115, 122, 143, 155, 182, 185, 190, 205, 225, 247], 'in': [11, 18, 25, 198], 'particular': [12], 'post-colonial': [14], 'decolonial': [16, 103, 158, 167], 'theories,': [17], 'understanding': [19], 'shaping': [21], 'ongoing': [23], 'advances': [24, 37], 'artificial': [26, 170], 'intelligence.': [27], 'Artificial': [28], 'intelligence': [29], '(AI)': [30], 'is': [31], 'viewed': [32], 'as': [33], 'amongst': [34], 'technological': [36], 'that': [38, 53, 91, 117, 150, 163, 238], 'will': [39, 196], 'reshape': [40], 'modern': [41], 'societies': [42], 'their': [44], 'relations.': [45], 'While': [46], 'design': [48], 'deployment': [50], 'systems': [52], 'continually': [54], 'adapt': [55], 'holds': [56], 'promise': [58], 'far-reaching': [60], 'positive': [61], 'change,': [62], 'they': [63], 'simultaneously': [64], 'pose': [65], 'significant': [66], 'risks,': [67], 'especially': [68], 'to': [69, 78, 86, 134, 217, 232], 'already': [70], 'vulnerable': [71, 130], 'peoples.': [72], 'Values': [73], 'power': [75, 90], 'are': [76, 151], 'central': [77], 'this': [79], 'discussion.': [80], 'Decolonial': [81], 'theories': [82], 'use': [83], 'historical': [84], 'hindsight': [85], 'explain': [87], 'patterns': [88], 'shape': [92], 'our': [93], 'intellectual,': [94], 'political,': [95], 'economic,': [96], 'social': [98, 220], 'world.': [99], 'By': [100], 'embedding': [101], 'a': [102, 157, 166, 173, 199], 'approach': [105], 'within': [106], 'its': [107], 'technical': [108, 175], 'practice,': [109], 'AI': [110, 209, 215], 'communities': [111, 216], 'can': [112, 118, 164], 'develop': [113], 'foresight': [114, 224], 'tactics': [116, 162], 'better': [119], 'align': [120], 'research': [121], 'technology': [123], 'development': [124], 'with': [125, 242], 'established': [126], 'ethical': [127, 223], 'principles,': [128], 'centring': [129], 'peoples': [131], 'who': [132], 'continue': [133], 'bear': [135], 'brunt': [137], 'negative': [139], 'impacts': [140], 'innovation': [142], 'scientific': [144, 203], 'progress.': [145], 'We': [146], 'highlight': [147], 'problematic': [148], 'applications': [149], 'instances': [152], 'coloniality,': [154], 'using': [156], 'lens,': [159], 'submit': [160], 'three': [161], 'form': [165], 'field': [168], 'intelligence:': [171], 'creating': [172], 'practice': [176], 'AI,': [178], 'seeking': [179], 'reverse': [180, 183], 'tutelage': [181], 'pedagogies,': [184], 'renewal': [187], 'affective': [189], 'political': [191], 'communities.': [192], 'The': [193], 'years': [194], 'ahead': [195], 'usher': [197], 'wave': [200], 'new': [202], 'breakthroughs': [204], 'technologies': [206, 237], 'driven': [207], 'by': [208], 'research,': [210], 'making': [211], 'it': [212], 'incumbent': [213], 'upon': [214], 'strengthen': [218], 'contract': [221], 'through': [222], 'multiplicity': [227], 'intellectual': [229], 'perspectives': [230], 'available': [231], 'us,': [233], 'ultimately': [234], 'supporting': [235], 'future': [236], 'enable': [239], 'greater': [240], 'well-being,': [241], 'goal': [244], 'beneficence': [246], 'justice': [248], 'for': [249], 'all.': [250]}",2020,"['Futures studies', 'Philosophy of technology', 'Sociotechnical system', 'Sociology', 'Politics', 'Engineering ethics', 'Technoscience', 'Environmental ethics', 'Epistemology', 'Philosophy of science', 'Political science', 'Social science', 'Artificial intelligence', 'Engineering', 'Computer science', 'Law', 'Philosophy']","Abstract This paper explores the important role of critical science, and in particular of post-colonial and decolonial theories, in understanding and shaping the ongoing advances in artificial intelligence. Artificial intelligence (AI) is viewed as amongst the technological advances that will reshape modern societies and their relations. While the design and deployment of systems that continually adapt holds the promise of far-reaching positive change, they simultaneously pose significant risks, especially to already vulnerable peoples. Values and power are central to this discussion. Decolonial theories use historical hindsight to explain patterns of power that shape our intellectual, political, economic, and social world. By embedding a decolonial critical approach within its technical practice, AI communities can develop foresight and tactics that can better align research and technology development with established ethical principles, centring vulnerable peoples who continue to bear the brunt of negative impacts of innovation and scientific progress. We highlight problematic applications that are instances of coloniality, and using a decolonial lens, submit three tactics that can form a decolonial field of artificial intelligence: creating a critical technical practice of AI, seeking reverse tutelage and reverse pedagogies, and the renewal of affective and political communities. The years ahead will usher in a wave of new scientific breakthroughs and technologies driven by AI research, making it incumbent upon AI communities to strengthen the social contract through ethical foresight and the multiplicity of intellectual perspectives available to us, ultimately supporting future technologies that enable greater well-being, with the goal of beneficence and justice for all."
https://openalex.org/W2917855746,"Art, Creativity, and the Potential of Artificial Intelligence","{'Our': [0, 69], 'essay': [1], 'discusses': [2], 'an': [3], 'AI': [4, 14, 73], 'process': [5], 'developed': [6], 'for': [7, 17, 40, 75, 117], 'making': [8], 'art': [9, 19, 35, 54, 76, 86, 124, 144], '(AICAN),': [10], 'and': [11, 20, 34, 56, 66, 80, 96, 101, 110, 123, 137, 140, 153], 'the': [12, 23, 41, 52, 94, 113], 'issues': [13], 'creativity': [15, 122, 155], 'raises': [16], 'understanding': [18], 'artists': [21, 136], 'in': [22, 30, 71, 85, 132, 160], '21st': [24], 'century.': [25], 'Backed': [26], 'by': [27], 'our': [28], 'training': [29], 'computer': [31], 'science': [32], '(Elgammal)': [33], 'history': [36, 87, 95], '(Mazzone),': [37], 'we': [38, 62, 147], 'argue': [39], 'consideration': [42], 'of': [43, 60, 98, 143], 'AICAN’s': [44], 'works': [45, 50], 'as': [46, 127], 'art,': [47], 'relate': [48], 'AICAN': [49], 'to': [51, 91, 102, 112, 129, 165], 'contemporary': [53], 'context,': [55], 'urge': [57, 148], 'a': [58, 118, 149, 163], 'reconsideration': [59], 'how': [61, 104], 'might': [63], 'define': [64], 'human': [65, 99, 135, 152], 'machine': [67, 121, 154], 'creativity.': [68], 'work': [70], 'developing': [72], 'processes': [74], 'making,': [77], 'style': [78, 83], 'analysis,': [79], 'detecting': [81], 'large-scale': [82], 'patterns': [84, 106], 'has': [88], 'led': [89], 'us': [90], 'carefully': [92], 'consider': [93], 'dynamics': [97], 'art-making': [100], 'examine': [103], 'those': [105], 'can': [107], 'be': [108], 'modeled': [109], 'taught': [111], 'machine.': [114], 'We': [115], 'advocate': [116], 'connection': [119], 'between': [120, 151], 'broadly': [125], 'defined': [126], 'parallel': [128], 'but': [130], 'not': [131], 'conflict': [133], 'with': [134], 'their': [138], 'emotional': [139], 'social': [141], 'intentions': [142], 'making.': [145], 'Rather,': [146], 'partnership': [150], 'when': [156], 'called': [157], 'for,': [158], 'seeing': [159], 'this': [161], 'collaboration': [162], 'means': [164], 'maximize': [166], 'both': [167], 'partners’': [168], 'creative': [169], 'strengths.': [170]}",2019,"['Creativity', 'Computational creativity', 'Style (visual arts)', 'Context (archaeology)', 'Art methodology', 'General partnership', 'Creativity technique', 'Scale (ratio)', 'Computer science', 'Contemporary art', 'Psychology', 'Visual arts', 'Art', 'Social psychology', 'Political science', 'History', 'Art history', 'Performance art', 'Law', 'Quantum mechanics', 'Archaeology', 'Physics']","Our essay discusses an AI process developed for making art (AICAN), and the issues AI creativity raises for understanding art and artists in the 21st century. Backed by our training in computer science (Elgammal) and art history (Mazzone), we argue for the consideration of AICAN’s works as art, relate AICAN works to the contemporary art context, and urge a reconsideration of how we might define human and machine creativity. Our work in developing AI processes for art making, style analysis, and detecting large-scale style patterns in art history has led us to carefully consider the history and dynamics of human art-making and to examine how those patterns can be modeled and taught to the machine. We advocate for a connection between machine creativity and art broadly defined as parallel to but not in conflict with human artists and their emotional and social intentions of art making. Rather, we urge a partnership between human and machine creativity when called for, seeing in this collaboration a means to maximize both partners’ creative strengths."
https://openalex.org/W3037880470,Artificial Intelligence and Marketing: Pitfalls and Opportunities,"{'This': [0], 'article': [1], 'discusses': [2], 'the': [3, 12, 23, 69, 88, 144], 'pitfalls': [4, 71], 'and': [5, 17, 36, 54, 58, 63, 72, 104, 121, 153], 'opportunities': [6], 'of': [7, 14, 25, 80, 90, 132, 146], 'AI': [8, 30, 83, 108, 128, 151], 'in': [9, 42, 84, 135], 'marketing': [10, 74, 137, 154], 'through': [11], 'lenses': [13], 'knowledge': [15, 18, 148], 'creation': [16], 'transfer.': [19], 'First,': [20], 'we': [21, 46, 67, 125, 140], 'discuss': [22, 68], 'notion': [24], '“higher-order': [26], 'learning”': [27], 'that': [28, 117, 127], 'distinguishes': [29], 'applications': [31], 'from': [32], 'traditional': [33], 'modeling': [34], 'approaches,': [35], 'while': [37], 'focusing': [38], 'on': [39, 114], 'recent': [40], 'advances': [41], 'deep': [43, 112], 'neural': [44, 56], 'networks,': [45], 'cover': [47], 'its': [48, 133], 'underlying': [49], 'methodologies': [50], '(multilayer': [51], 'perceptron,': [52], 'convolutional,': [53], 'recurrent': [55], 'networks)': [57], 'learning': [59, 98], 'paradigms': [60], '(supervised,': [61], 'unsupervised,': [62], 'reinforcement': [64], 'learning).': [65], 'Second,': [66], 'technological': [70], 'dangers': [73], 'managers': [75], 'need': [76], 'to': [77], 'be': [78, 119], 'aware': [79], 'when': [81], 'implementing': [82], 'their': [85], 'organizations,': [86], 'including': [87], 'concepts': [89], 'badly': [91], 'defined': [92], 'objective': [93], 'functions,': [94], 'unsafe': [95], 'or': [96], 'unrealistic': [97], 'environments,': [99], 'biased': [100], 'AI,': [101, 103], 'explainable': [102], 'controllable': [105], 'AI.': [106], 'Third,': [107], 'will': [109, 129], 'have': [110], 'a': [111], 'impact': [113], 'predictive': [115], 'tasks': [116], 'can': [118], 'automated': [120], 'require': [122], 'little': [123], 'explainability,': [124], 'predict': [126], 'fall': [130], 'short': [131], 'promises': [134], 'many': [136], 'domains': [138], 'if': [139], 'do': [141], 'not': [142], 'solve': [143], 'challenges': [145], 'tacit': [147], 'transfer': [149], 'between': [150], 'models': [152], 'organizations.': [155]}",2020,"['Computer science', 'Artificial intelligence', 'Deep learning', 'Convolutional neural network', 'Transfer of learning', 'Artificial neural network', 'Machine learning', 'Data science', 'Knowledge management']","This article discusses the pitfalls and opportunities of AI in marketing through the lenses of knowledge creation and knowledge transfer. First, we discuss the notion of “higher-order learning” that distinguishes AI applications from traditional modeling approaches, and while focusing on recent advances in deep neural networks, we cover its underlying methodologies (multilayer perceptron, convolutional, and recurrent neural networks) and learning paradigms (supervised, unsupervised, and reinforcement learning). Second, we discuss the technological pitfalls and dangers marketing managers need to be aware of when implementing AI in their organizations, including the concepts of badly defined objective functions, unsafe or unrealistic learning environments, biased AI, explainable AI, and controllable AI. Third, AI will have a deep impact on predictive tasks that can be automated and require little explainability, we predict that AI will fall short of its promises in many marketing domains if we do not solve the challenges of tacit knowledge transfer between AI models and marketing organizations."
https://openalex.org/W3136552952,Reporting guidelines for clinical trial reports for interventions involving artificial intelligence: the CONSORT-AI extension,"{'Abstract': [0], 'The': [1, 53, 150], 'CONSORT': [2, 176], '2010': [3, 177], 'statement': [4, 84], 'provides': [5], 'minimum': [6], 'guidelines': [7, 99], 'for': [8, 67, 85, 94, 162, 195, 238], 'reporting': [9, 65, 235], 'randomized': [10], 'trials.': [11], 'Its': [12], 'widespread': [13], 'use': [14], 'has': [15, 30], 'been': [16, 31], 'instrumental': [17], 'in': [18, 21, 79, 126, 135, 171, 199, 234, 270], 'ensuring': [19], 'transparency': [20, 231], 'the': [22, 174, 187, 197, 201, 206, 213, 216, 251, 260, 271], 'evaluation': [23, 46], 'of': [24, 57, 186, 208, 212, 221, 224, 262, 268], 'new': [25, 64, 155], 'interventions.': [26, 240], 'More': [27], 'recently,': [28], 'there': [29], 'a': [32, 63, 103, 127, 136, 145], 'growing': [33], 'recognition': [34], 'that': [35, 157, 165, 181], 'interventions': [36, 71, 164], 'involving': [37, 107], 'artificial': [38], 'intelligence': [39], '(AI)': [40], 'need': [41], 'to': [42, 47, 113, 173, 254], 'undergo': [43], 'rigorous,': [44], 'prospective': [45], 'demonstrate': [48], 'impact': [49], 'on': [50], 'health': [51], 'outcomes.': [52, 273], 'CONSORT-AI': [54, 151, 179, 227], '(Consolidated': [55], 'Standards': [56], 'Reporting': [58], 'Trials–Artificial': [59, 96], 'Intelligence)': [60], 'extension': [61, 152], 'is': [62, 204], 'guideline': [66], 'clinical': [68, 86, 236, 263], 'trials': [69, 237], 'evaluating': [70], 'with': [72, 81], 'an': [73, 122, 222], 'AI': [74, 163, 188, 202, 214, 239], 'component.': [75], 'It': [76, 241], 'was': [77], 'developed': [78, 101], 'parallel': [80], 'its': [82], 'companion': [83], 'trial': [87, 264], 'protocols:': [88], 'SPIRIT-AI': [89], '(Standard': [90], 'Protocol': [91], 'Items:': [92], 'Recommendations': [93], 'Interventional': [95], 'Intelligence).': [97], 'Both': [98], 'were': [100, 119, 158], 'through': [102, 144], 'staged': [104], 'consensus': [105, 138], 'process': [106], 'literature': [108], 'review': [109], 'and': [110, 142, 192, 210, 219, 232, 245, 257, 266], 'expert': [111], 'consultation': [112], 'generate': [114], '29': [115], 'candidate': [116], 'items,': [117], 'which': [118, 200], 'assessed': [120], 'by': [121], 'international': [123], 'multi-stakeholder': [124], 'group': [125], 'two-stage': [128], 'Delphi': [129], 'survey': [130], '(103': [131], 'stakeholders),': [132], 'agreed': [133], 'upon': [134], 'two-day': [137], 'meeting': [139], '(31': [140], 'stakeholders)': [141], 'refined': [143], 'checklist': [146], 'pilot': [147], '(34': [148], 'participants).': [149], 'includes': [153], '14': [154], 'items': [156], 'considered': [159], 'sufficiently': [160], 'important': [161], 'they': [166], 'should': [167], 'be': [168], 'routinely': [169], 'reported': [170, 272], 'addition': [172], 'core': [175], 'items.': [178], 'recommends': [180], 'investigators': [182], 'provide': [183], 'clear': [184], 'descriptions': [185], 'intervention,': [189, 215], 'including': [190], 'instructions': [191], 'skills': [193], 'required': [194], 'use,': [196], 'setting': [198], 'intervention': [203], 'integrated,': [205], 'handling': [207], 'inputs': [209], 'outputs': [211], 'human–AI': [217], 'interaction': [218], 'provision': [220], 'analysis': [223], 'error': [225], 'cases.': [226], 'will': [228, 242], 'help': [229], 'promote': [230], 'completeness': [233], 'assist': [243], 'editors': [244], 'peer': [246], 'reviewers,': [247], 'as': [248, 250], 'well': [249], 'general': [252], 'readership,': [253], 'understand,': [255], 'interpret': [256], 'critically': [258], 'appraise': [259], 'quality': [261], 'design': [265], 'risk': [267], 'bias': [269]}",2020,"['Consolidated Standards of Reporting Trials', 'Psychological intervention', 'Checklist', 'Clinical trial', 'Delphi method', 'Medicine', 'Protocol (science)', 'Guideline', 'Artificial intelligence', 'Computer science', 'Alternative medicine', 'Psychology', 'Nursing', 'Pathology', 'Cognitive psychology']","Abstract The CONSORT 2010 statement provides minimum guidelines for reporting randomized trials. Its widespread use has been instrumental in ensuring transparency in the evaluation of new interventions. More recently, there has been a growing recognition that interventions involving artificial intelligence (AI) need to undergo rigorous, prospective evaluation to demonstrate impact on health outcomes. The CONSORT-AI (Consolidated Standards of Reporting Trials–Artificial Intelligence) extension is a new reporting guideline for clinical trials evaluating interventions with an AI component. It was developed in parallel with its companion statement for clinical trial protocols: SPIRIT-AI (Standard Protocol Items: Recommendations for Interventional Trials–Artificial Intelligence). Both guidelines were developed through a staged consensus process involving literature review and expert consultation to generate 29 candidate items, which were assessed by an international multi-stakeholder group in a two-stage Delphi survey (103 stakeholders), agreed upon in a two-day consensus meeting (31 stakeholders) and refined through a checklist pilot (34 participants). The CONSORT-AI extension includes 14 new items that were considered sufficiently important for AI interventions that they should be routinely reported in addition to the core CONSORT 2010 items. CONSORT-AI recommends that investigators provide clear descriptions of the AI intervention, including instructions and skills required for use, the setting in which the AI intervention is integrated, the handling of inputs and outputs of the AI intervention, the human–AI interaction and provision of an analysis of error cases. CONSORT-AI will help promote transparency and completeness in reporting clinical trials for AI interventions. It will assist editors and peer reviewers, as well as the general readership, to understand, interpret and critically appraise the quality of clinical trial design and risk of bias in the reported outcomes."
https://openalex.org/W4281791809,"Definition, roles, and potential research issues of the metaverse in education: An artificial intelligence perspective","{'The': [0], 'metaverse': [1, 20, 69, 83, 117], 'has': [2], 'been': [3], 'recognized': [4], 'as': [5, 84, 86], 'one': [6], 'of': [7, 18, 32, 35, 44, 59, 67, 79, 102, 114], 'the': [8, 11, 16, 19, 33, 36, 41, 60, 68, 77, 82, 100, 116, 144], 'technologies': [9], 'with': [10], 'greatest': [12], 'potential': [13, 42], 'today.': [14], 'However,': [15], 'use': [17], 'for': [21, 125], 'educational': [22, 71, 107, 126], 'purposes': [23], 'is': [24, 92, 118, 131], 'seldom': [25], 'discussed.': [26, 90], 'Most': [27], 'educators': [28], 'might': [29], 'be': [30, 123, 141], 'unaware': [31], 'features': [34], 'metaverse,': [37], 'not': [38], 'to': [39, 54, 137], 'mention': [40], 'applications': [43, 63], 'this': [45, 49, 96], 'emerging': [46], 'technology.': [47], 'In': [48], 'position': [50], 'paper,': [51, 97], 'we': [52], 'aim': [53], 'provide': [55], 'a': [56, 111], 'clear': [57, 112], 'definition': [58], 'metaverse.': [61], 'Potential': [62], 'and': [64, 106, 119], 'research': [65], 'issues': [66], 'in': [70, 81, 143], 'settings': [72], 'are': [73, 89], 'also': [74], 'presented.': [75], 'Moreover,': [76], 'roles': [78], 'AI': [80], 'well': [85], 'metaverse-based': [87, 138], 'education': [88, 139], 'It': [91], 'expected': [93, 132], 'that,': [94], 'via': [95], 'researchers': [98], 'from': [99], 'fields': [101], 'both': [103], 'computer': [104], 'science': [105], 'technology': [108], 'would': [109], 'have': [110], 'picture': [113], 'what': [115], 'how': [120], 'it': [121, 130], 'can': [122, 140], 'used': [124], 'purposes.': [127], 'More': [128], 'importantly,': [129], 'that': [133], 'more': [134], 'studies': [135], 'related': [136], 'reported': [142], 'near': [145], 'future.': [146]}",2022,"['Metaverse', 'Perspective (graphical)', 'Possible world', 'Computer science', 'Epistemology', 'Data science', 'Human–computer interaction', 'Artificial intelligence', 'Philosophy', 'Virtual reality']","The metaverse has been recognized as one of the technologies with the greatest potential today. However, the use of the metaverse for educational purposes is seldom discussed. Most educators might be unaware of the features of the metaverse, not to mention the potential applications of this emerging technology. In this position paper, we aim to provide a clear definition of the metaverse. Potential applications and research issues of the metaverse in educational settings are also presented. Moreover, the roles of AI in the metaverse as well as metaverse-based education are discussed. It is expected that, via this paper, researchers from the fields of both computer science and educational technology would have a clear picture of what the metaverse is and how it can be used for educational purposes. More importantly, it is expected that more studies related to metaverse-based education can be reported in the near future."
https://openalex.org/W2997569720,Artificial Intelligence in Healthcare: Review and Prediction Case Studies,"{'Artificial': [0, 156], 'intelligence': [1], '(AI)': [2], 'has': [3], 'been': [4], 'developing': [5], 'rapidly': [6], 'in': [7, 10, 19, 37, 76, 82, 100, 104, 130], 'recent': [8], 'years': [9], 'terms': [11], 'of': [12, 23, 33, 35, 52, 59, 67, 74, 98, 122, 143, 150], 'software': [13], 'algorithms,': [14], 'hardware': [15], 'implementation,': [16], 'and': [17, 47, 78, 110, 118, 125, 147], 'applications': [18, 34], 'a': [20, 151], 'vast': [21], 'number': [22], 'areas.': [24], 'In': [25], 'this': [26, 53], 'review,': [27], 'we': [28], 'summarize': [29], 'the': [30, 65, 71, 96, 116, 120, 131, 141, 148], 'latest': [31], 'developments': [32, 127], 'AI': [36, 75, 94, 99, 123], 'biomedicine,': [38, 77], 'including': [39], 'disease': [40], 'diagnostics,': [41], 'living': [42], 'assistance,': [43], 'biomedical': [44, 48], 'information': [45], 'processing,': [46], 'research.': [49], 'The': [50], 'aim': [51], 'review': [54], 'is': [55, 102], 'to': [56, 63, 69, 79, 114, 139], 'keep': [57], 'track': [58], 'new': [60], 'scientific': [61], 'accomplishments,': [62], 'understand': [64], 'availability': [66], 'technologies,': [68], 'appreciate': [70], 'tremendous': [72], 'potential': [73], 'provide': [80], 'researchers': [81], 'related': [83], 'fields': [84], 'with': [85], 'inspiration.': [86], 'It': [87], 'can': [88], 'be': [89], 'asserted': [90], 'that,': [91], 'just': [92], 'like': [93], 'itself,': [95], 'application': [97], 'biomedicine': [101], 'still': [103], 'its': [105], 'early': [106], 'stage.': [107], 'New': [108], 'progress': [109], 'breakthroughs': [111], 'will': [112], 'continue': [113], 'push': [115], 'frontier': [117], 'widen': [119], 'scope': [121], 'application,': [124], 'fast': [126], 'are': [128, 137], 'envisioned': [129], 'near': [132], 'future.': [133], 'Two': [134], 'case': [135], 'studies': [136], 'provided': [138], 'illustrate': [140], 'prediction': [142], 'epileptic': [144], 'seizure': [145], 'occurrences': [146], 'filling': [149, 172], 'dysfunctional': [152], 'urinary': [153], 'bladder.': [154], 'Keywords:': [155], 'intelligence,': [157], 'Machine': [158], 'learning,': [159, 161], 'Deep': [160], 'Neural': [162], 'network,': [163], 'Biomedical': [164], 'research,': [165], 'Healthcare': [166], 'applications,': [167], 'Epileptic': [168], 'seizure,': [169], 'Urinary': [170], 'bladder': [171]}",2020,"['Biomedicine', 'Scope (computer science)', 'Data science', 'Computer science', 'Artificial intelligence', 'Applications of artificial intelligence', 'Bioinformatics', 'Biology', 'Programming language']","Artificial intelligence (AI) has been developing rapidly in recent years in terms of software algorithms, hardware implementation, and applications in a vast number of areas. In this review, we summarize the latest developments of applications of AI in biomedicine, including disease diagnostics, living assistance, biomedical information processing, and biomedical research. The aim of this review is to keep track of new scientific accomplishments, to understand the availability of technologies, to appreciate the tremendous potential of AI in biomedicine, and to provide researchers in related fields with inspiration. It can be asserted that, just like AI itself, the application of AI in biomedicine is still in its early stage. New progress and breakthroughs will continue to push the frontier and widen the scope of AI application, and fast developments are envisioned in the near future. Two case studies are provided to illustrate the prediction of epileptic seizure occurrences and the filling of a dysfunctional urinary bladder. Keywords: Artificial intelligence, Machine learning, Deep learning, Neural network, Biomedical research, Healthcare applications, Epileptic seizure, Urinary bladder filling"
https://openalex.org/W2895420596,Artificial Intelligence in Drug Design,"{'Artificial': [0, 58], 'Intelligence': [1], '(AI)': [2], 'plays': [3], 'a': [4], 'pivotal': [5], 'role': [6], 'in': [7, 28, 48, 60, 84, 108], 'drug': [8, 102], 'discovery.': [9], 'In': [10], 'particular': [11], 'artificial': [12, 82], 'neural': [13, 18], 'networks': [14, 19, 22], 'such': [15], 'as': [16], 'deep': [17], 'or': [20, 30, 53], 'recurrent': [21], 'drive': [23], 'this': [24, 46, 85], 'area.': [25], 'Numerous': [26], 'applications': [27], 'property': [29], 'activity': [31], 'predictions': [32], 'like': [33], 'physicochemical': [34], 'and': [35, 41, 91, 97, 99], 'ADMET': [36], 'properties': [37], 'have': [38], 'recently': [39], 'appeared': [40], 'underpin': [42], 'the': [43, 65, 79, 109], 'strength': [44, 80], 'of': [45, 67, 81, 93], 'technology': [47], 'quantitative': [49, 54], 'structure-property': [50], 'relationships': [51, 56], '(QSPR)': [52], 'structure-activity': [55], '(QSAR).': [57], 'intelligence': [59, 83], 'de': [61], 'novo': [62], 'design': [63], 'drives': [64], 'generation': [66], 'meaningful': [68], 'new': [69], 'biologically': [70], 'active': [71], 'molecules': [72], 'towards': [73], 'desired': [74], 'properties.': [75], 'Several': [76], 'examples': [77], 'establish': [78], 'field.': [86], 'Combination': [87], 'with': [88], 'synthesis': [89, 94], 'planning': [90], 'ease': [92], 'is': [95, 106], 'feasible': [96], 'more': [98, 100], 'automated': [101], 'discovery': [103], 'by': [104], 'computers': [105], 'expected': [107], 'near': [110], 'future.': [111]}",2018,"['Quantitative structure–activity relationship', 'Artificial intelligence', 'Artificial neural network', 'Drug discovery', 'Computer science', 'Machine learning', 'Field (mathematics)', 'Property (philosophy)', 'Mathematics', 'Bioinformatics', 'Biology', 'Pure mathematics', 'Epistemology', 'Philosophy']",Artificial Intelligence (AI) plays a pivotal role in drug discovery. In particular artificial neural networks such as deep neural networks or recurrent networks drive this area. Numerous applications in property or activity predictions like physicochemical and ADMET properties have recently appeared and underpin the strength of this technology in quantitative structure-property relationships (QSPR) or quantitative structure-activity relationships (QSAR). Artificial intelligence in de novo design drives the generation of meaningful new biologically active molecules towards desired properties. Several examples establish the strength of artificial intelligence in this field. Combination with synthesis planning and ease of synthesis is feasible and more and more automated drug discovery by computers is expected in the near future.
https://openalex.org/W2947151330,Artificial Intelligence and the Implementation Challenge,"{'If': [0], 'the': [1, 8, 20, 31], 'implementation': [2], 'science': [3], 'community': [4], 'is': [5], 'to': [6, 16], 'facilitate': [7], 'adoption': [9], 'of': [10], 'ML': [11], 'in': [12, 23, 30], 'ways': [13], 'that': [14], 'stand': [15], 'generate': [17], 'widespread': [18], 'benefits,': [19], 'issues': [21], 'raised': [22], 'this': [24], 'paper': [25], 'will': [26], 'require': [27], 'substantial': [28], 'attention': [29], 'coming': [32], 'years.': [33]}",2019,"['Health care', 'Clinical decision support system', 'Computer science', 'Decision support system', 'Knowledge management', 'Data science', 'Management science', 'Artificial intelligence', 'Political science', 'Engineering', 'Law']","If the implementation science community is to facilitate the adoption of ML in ways that stand to generate widespread benefits, the issues raised in this paper will require substantial attention in the coming years."
https://openalex.org/W3040455124,"Developments, application, and performance of artificial intelligence in dentistry – A systematic review","{'These': [0], 'studies': [1, 25], 'indicate': [2], 'that': [3, 29], 'the': [4, 16], 'performance': [5, 42], 'of': [6, 20, 41], 'an': [7], 'AI': [8], 'based': [9], 'automated': [10], 'system': [11], 'is': [12], 'excellent.': [13], 'They': [14], 'mimic': [15], 'precision': [17], 'and': [18, 43], 'accuracy': [19], 'trained': [21], 'specialists,': [22], 'in': [23, 39], 'some': [24], 'it': [26], 'was': [27], 'found': [28], 'these': [30], 'systems': [31], 'were': [32], 'even': [33], 'able': [34], 'to': [35], 'outmatch': [36], 'dental': [37], 'specialists': [38], 'terms': [40], 'accuracy.': [44]}",2020,"['Dentistry', 'MEDLINE', 'Medicine', 'Cochrane Library', 'Dental alveolus', 'Convolutional neural network', 'Web of science', 'Medical physics', 'Computer science', 'Artificial intelligence', 'Orthodontics', 'Meta-analysis', 'Pathology', 'Political science', 'Law']","These studies indicate that the performance of an AI based automated system is excellent. They mimic the precision and accuracy of trained specialists, in some studies it was found that these systems were even able to outmatch dental specialists in terms of performance and accuracy."
https://openalex.org/W2163605009,ImageNet classification with deep convolutional neural networks,"{'We': [0, 124], 'trained': [1], 'a': [2, 79, 92, 111, 127, 138], 'large,': [3], 'deep': [4], 'convolutional': [5, 63], 'neural': [6, 50], 'network': [7], 'to': [8, 120, 147], 'classify': [9], 'the': [10, 16, 21, 26, 46, 98, 105, 133, 151], '1.2': [11], 'million': [12, 55], 'high-resolution': [13], 'images': [14], 'in': [15, 104, 132], 'ImageNet': [17], 'LSVRC-2010': [18], 'contest': [19], 'into': [20], '1000': [22], 'different': [23], 'classes.': [24], 'On': [25], 'test': [27, 141], 'data,': [28], 'we': [29, 87, 109], 'achieved': [30, 137, 149], 'top-1': [31], 'and': [32, 38, 57, 73, 91, 136], 'top-5': [33, 140], 'error': [34, 142], 'rates': [35], 'of': [36, 61, 66, 97, 129, 144], '37.5%': [37], '17.0%,': [39], 'respectively,': [40], 'which': [41, 52, 67], 'is': [42], 'considerably': [43], 'better': [44], 'than': [45], 'previous': [47], 'state-of-the-art.': [48], 'The': [49], 'network,': [51], 'has': [53], '60': [54], 'parameters': [56], '650,000': [58], 'neurons,': [59], 'consists': [60], 'five': [62], 'layers,': [64, 72], 'some': [65], 'are': [68], 'followed': [69], 'by': [70, 150], 'max-pooling': [71], 'three': [74], 'fully': [75, 106], 'connected': [76, 107], 'layers': [77, 108], 'with': [78], 'final': [80], '1000-way': [81], 'softmax.': [82], 'To': [83, 101], 'make': [84], 'training': [85], 'faster,': [86], 'used': [88], 'non-saturating': [89], 'neurons': [90], 'very': [93, 122], 'efficient': [94], 'GPU': [95], 'implementation': [96], 'convolution': [99], 'operation.': [100], 'reduce': [102], 'overfitting': [103], 'employed': [110], 'recently': [112], 'developed': [113], 'regularization': [114], 'method': [115], 'called': [116], '""dropout""': [117], 'that': [118], 'proved': [119], 'be': [121], 'effective.': [123], 'also': [125], 'entered': [126], 'variant': [128], 'this': [130], 'model': [131], 'ILSVRC-2012': [134], 'competition': [135], 'winning': [139], 'rate': [143], '15.3%,': [145], 'compared': [146], '26.2%': [148], 'second-best': [152], 'entry.': [153]}",2017,"['Softmax function', 'Convolutional neural network', 'Computer science', 'Pooling', 'Dropout (neural networks)', 'Artificial intelligence', 'Convolution (computer science)', 'Regularization (linguistics)', 'Pattern recognition (psychology)', 'Deep neural networks', 'Word error rate', 'Normalization (sociology)', 'Artificial neural network', 'Machine learning', 'Sociology', 'Anthropology']","We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called ""dropout"" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry."
https://openalex.org/W2124776405,Neural Networks: A Comprehensive Foundation,"{'From': [0], 'the': [1, 5, 27, 35, 72], 'Publisher:\r\nThis': [2], 'book': [3, 77], 'represents': [4], 'most': [6], 'comprehensive': [7], 'treatment': [8], 'available': [9], 'of': [10, 30, 54], 'neural': [11, 55], 'networks': [12], 'from': [13], 'an': [14], 'engineering': [15, 67], 'perspective.': [16], 'Thorough,': [17], 'well-organized,': [18], 'and': [19, 49, 51, 61, 83, 98], 'completely': [20], 'up': [21], 'to': [22, 70], 'date,': [23], 'it': [24], 'examines': [25], 'all': [26], 'important': [28], 'aspects': [29], 'this': [31, 76, 87], 'emerging': [32], 'technology,': [33], 'including': [34], 'learning': [36], 'process,': [37], 'back-propagation': [38], 'learning,': [39], 'radial-basis': [40], 'function': [41], 'networks,': [42, 46], 'self-organizing': [43], 'systems,': [44], 'modular': [45], 'temporal': [47], 'processing': [48], 'neurodynamics,': [50], 'VLSI': [52], 'implementation': [53], 'networks.': [56], 'Written': [57], 'in': [58], 'a': [59, 65, 95], 'concise': [60], 'fluid': [62], 'manner,': [63], 'by': [64], 'foremost': [66], 'textbook': [68], 'author,': [69], 'make': [71], 'material': [73], 'more': [74], 'accessible,': [75], 'is': [78], 'ideal': [79], 'for': [80], 'professional': [81], 'engineers': [82], 'graduate': [84], 'students': [85], 'entering': [86], 'exciting': [88], 'field.': [89], 'Computer': [90], 'experiments,': [91], 'problems,': [92], 'worked': [93], 'examples,': [94], 'bibliography,': [96], 'photographs,': [97], 'illustrations': [99], 'reinforce': [100], 'key': [101], 'concepts.': [102]}",1998,"['Modular design', 'Computer science', 'Field (mathematics)', 'Artificial neural network', 'Process (computing)', 'Function (biology)', 'Ideal (ethics)', 'Key (lock)', 'Perspective (graphical)', 'Artificial intelligence', 'Foundation (evidence)', 'Engineering', 'Geography', 'Epistemology', 'Mathematics', 'Pure mathematics', 'Computer security', 'Biology', 'Philosophy', 'Operating system', 'Archaeology', 'Evolutionary biology']","From the Publisher:
This book represents the most comprehensive treatment available of neural networks from an engineering perspective. Thorough, well-organized, and completely up to date, it examines all the important aspects of this emerging technology, including the learning process, back-propagation learning, radial-basis function networks, self-organizing systems, modular networks, temporal processing and neurodynamics, and VLSI implementation of neural networks. Written in a concise and fluid manner, by a foremost engineering textbook author, to make the material more accessible, this book is ideal for professional engineers and graduate students entering this exciting field. Computer experiments, problems, worked examples, a bibliography, photographs, and illustrations reinforce key concepts."
https://openalex.org/W1821462560,Distilling the Knowledge in a Neural Network,"{'A': [0], 'very': [1], 'simple': [2], 'way': [3], 'to': [4, 15, 26, 47, 50, 75, 90, 161], 'improve': [5, 117], 'the': [6, 21, 58, 77, 118, 129, 166], 'performance': [7], 'of': [8, 37, 54, 121, 134, 146, 149, 173], 'almost': [9], 'any': [10], 'machine': [11], 'learning': [12], 'algorithm': [13], 'is': [14, 39, 73, 87], 'train': [16], 'many': [17, 156], 'different': [18, 100], 'models': [19, 38, 60, 135, 154, 158, 168, 177], 'on': [20, 108], 'same': [22], 'data': [23], 'and': [24, 41, 66, 92, 110, 155, 182], 'then': [25], 'average': [27], 'their': [28], 'predictions.': [29], 'Unfortunately,': [30], 'making': [31], 'predictions': [32], 'using': [33, 98], 'a': [34, 51, 83, 99, 122, 137, 143, 171], 'whole': [35], 'ensemble': [36, 81, 133, 147], 'cumbersome': [40], 'may': [42], 'be': [43, 179], 'too': [44], 'computationally': [45], 'expensive': [46], 'allow': [48], 'deployment': [49], 'large': [52, 62], 'number': [53], 'users,': [55], 'especially': [56], 'if': [57], 'individual': [59], 'are': [61], 'neural': [63], 'nets.': [64], 'Caruana': [65], 'his': [67], 'collaborators': [68], 'have': [69], 'shown': [70], 'that': [71, 113, 165], 'it': [72], 'possible': [74], 'compress': [76], 'knowledge': [78, 130], 'in': [79, 131, 183], 'an': [80, 132], 'into': [82, 136], 'single': [84, 138], 'model': [85, 120], 'which': [86, 159], 'much': [88], 'easier': [89], 'deploy': [91], 'we': [93, 111, 114], 'develop': [94], 'this': [95], 'approach': [96], 'further': [97], 'compression': [101], 'technique.': [102], 'We': [103, 140], 'achieve': [104], 'some': [105], 'surprising': [106], 'results': [107], 'MNIST': [109], 'show': [112], 'can': [115, 178], 'significantly': [116], 'acoustic': [119], 'heavily': [123], 'used': [124], 'commercial': [125], 'system': [126], 'by': [127], 'distilling': [128], 'model.': [139], 'also': [141], 'introduce': [142], 'new': [144], 'type': [145], 'composed': [148], 'one': [150], 'or': [151], 'more': [152], 'full': [153, 167], 'specialist': [157, 176], 'learn': [160], 'distinguish': [162], 'fine-grained': [163], 'classes': [164], 'confuse.': [169], 'Unlike': [170], 'mixture': [172], 'experts,': [174], 'these': [175], 'trained': [180], 'rapidly': [181], 'parallel.': [184]}",2015,"['Artificial neural network', 'Computer science', 'Artificial intelligence']","A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel."
https://openalex.org/W2130942839,Sequence to Sequence Learning with Neural Networks,"{'Deep': [0], 'Neural': [1], 'Networks': [2], '(DNNs)': [3], 'are': [4, 25, 202, 208], 'powerful': [5], 'models': [6], 'that': [7, 48, 94, 201, 221], 'have': [8, 138], 'achieved': [9], 'excellent': [10], 'performance': [11, 239], 'on': [12, 52, 95, 118, 130, 140, 155, 189], 'difficult': [13], 'learning': [14, 47], 'tasks.': [15], 'Although': [16], 'DNNs': [17], 'work': [18], 'well': [19], 'whenever': [20], 'large': [21], 'labeled': [22], 'training': [23], 'sets': [24], 'available,': [26], 'they': [27], 'cannot': [28], 'be': [29], 'used': [30, 161], 'to': [31, 34, 45, 65, 70, 82, 98, 164, 179, 184, 204, 211], 'map': [32, 66], 'sequences': [33], 'sequences.': [35], 'In': [36], 'this': [37, 190], 'paper,': [38], 'we': [39, 160, 219], 'present': [40], 'a': [41, 59, 71, 74, 113, 145, 150], 'general': [42], 'end-to-end': [43], 'approach': [44], 'sequence': [46, 54, 69, 86], 'makes': [49], 'minimal': [50], 'assumptions': [51], 'the': [53, 67, 84, 88, 103, 106, 110, 119, 124, 134, 156, 162, 166, 171, 185, 212, 215, 223, 226, 237, 250, 253, 258], 'structure.': [55], 'Our': [56, 90], 'method': [57], 'uses': [58], 'multilayered': [60], 'Long': [61], 'Short-Term': [62], 'Memory': [63], '(LSTM)': [64], 'input': [68], 'vector': [72], 'of': [73, 116, 153, 225], 'fixed': [75], 'dimensionality,': [76], 'and': [77, 198, 207, 214, 252], 'then': [78], 'another': [79], 'deep': [80], 'LSTM': [81, 111, 135, 163, 193], 'decode': [83], 'target': [85, 234, 254], 'from': [87, 102], 'vector.': [89], 'main': [91], 'result': [92, 188], 'is': [93, 182], 'an': [96], 'English': [97], 'French': [99], 'translation': [100], 'task': [101], ""WMT'14"": [104], 'dataset,': [105], 'translations': [107], 'produced': [108, 169], 'by': [109, 170], 'achieve': [112], 'BLEU': [114, 126, 151, 176], 'score': [115, 127, 152, 177], '34.8': [117], 'entire': [120], 'test': [121], 'set,': [122], 'where': [123], ""LSTM's"": [125, 238], 'was': [128], 'penalized': [129], 'out-of-vocabulary': [131], 'words.': [132], 'Additionally,': [133], 'did': [136], 'not': [137, 233], 'difficulty': [139], 'long': [141], 'sentences.': [142], 'For': [143], 'comparison,': [144], 'phrase-based': [146], 'SMT': [147, 173], 'system': [148], 'achieves': [149], '33.3': [154], 'same': [157], 'dataset.': [158], 'When': [159], 'rerank': [165], '1000': [167], 'hypotheses': [168], 'aforementioned': [172], 'system,': [174], 'its': [175], 'increases': [178], '36.5,': [180], 'which': [181, 256], 'close': [183], 'previous': [186], 'best': [187], 'task.': [191], 'The': [192], 'also': [194], 'learned': [195], 'sensible': [196], 'phrase': [197], 'sentence': [199, 255], 'representations': [200], 'sensitive': [203], 'word': [205], 'order': [206, 224], 'relatively': [209], 'invariant': [210], 'active': [213], 'passive': [216], 'voice.': [217], 'Finally,': [218], 'found': [220], 'reversing': [222], 'words': [227], 'in': [228], 'all': [229], 'source': [230, 251], 'sentences': [231], '(but': [232], 'sentences)': [235], 'improved': [236], 'markedly,': [240], 'because': [241], 'doing': [242], 'so': [243], 'introduced': [244], 'many': [245], 'short': [246], 'term': [247], 'dependencies': [248], 'between': [249], 'made': [257], 'optimization': [259], 'problem': [260], 'easier.': [261]}",2014,"['Computer science', 'Artificial intelligence', 'Sentence', 'Phrase', 'Sequence (biology)', 'Natural language processing', 'Word (group theory)', 'Task (project management)', 'Speech recognition', 'Recurrent neural network', 'Artificial neural network', 'Machine translation', 'Vocabulary', 'Deep learning', 'Mathematics', 'Genetics', 'Geometry', 'Management', 'Economics', 'Philosophy', 'Biology', 'Linguistics']","Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT'14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous best result on this task. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier."
https://openalex.org/W1832693441,Convolutional Neural Networks for Sentence Classification,"{'We': [0], 'report': [1], 'on': [2, 13, 38, 80], 'a': [3, 25, 52], 'series': [4], 'of': [5, 15, 63, 77, 83], 'experiments': [6], 'with': [7, 28], 'convolutional': [8], 'neural': [9], 'networks': [10], '(CNN)': [11], 'trained': [12], 'top': [14], 'pre-trained': [16], 'word': [17], 'vectors': [18, 34, 42], 'for': [19, 60], 'sentence-level': [20], 'classification': [21], 'tasks.We': [22], 'show': [23], 'that': [24], 'simple': [26, 53], 'CNN': [27, 69], 'little': [29], 'hyperparameter': [30], 'tuning': [31], 'and': [32, 66, 90], 'static': [33, 67], 'achieves': [35], 'excellent': [36], 'results': [37], 'multiple': [39], 'benchmarks.Learning': [40], 'task-specific': [41, 65], 'through': [43], 'fine-tuning': [44], 'offers': [45], 'further': [46], 'gains': [47], 'in': [48], 'performance.We': [49], 'additionally': [50], 'propose': [51], 'modification': [54], 'to': [55, 58], 'the': [56, 61, 75, 78], 'architecture': [57], 'allow': [59], 'use': [62], 'both': [64], 'vectors.The': [68], 'models': [70], 'discussed': [71], 'herein': [72], 'improve': [73], 'upon': [74], 'state': [76], 'art': [79], '4': [81], 'out': [82], '7': [84], 'tasks,': [85], 'which': [86], 'include': [87], 'sentiment': [88], 'analysis': [89], 'question': [91], 'classification.': [92]}",2014,"['Convolutional neural network', 'Computer science', 'Sentence', 'Artificial intelligence', 'Natural language processing', 'Speech recognition']","We report on a series of experiments with convolutional neural networks (CNN) trained on top of pre-trained word vectors for sentence-level classification tasks.We show that a simple CNN with little hyperparameter tuning and static vectors achieves excellent results on multiple benchmarks.Learning task-specific vectors through fine-tuning offers further gains in performance.We additionally propose a simple modification to the architecture to allow for the use of both task-specific and static vectors.The CNN models discussed herein improve upon the state of the art on 4 out of 7 tasks, which include sentiment analysis and question classification."
https://openalex.org/W1924770834,Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling,"{'In': [0], 'this': [1], 'paper': [2], 'we': [3, 16, 80], 'compare': [4], 'different': [5], 'types': [6], 'of': [7, 51], 'recurrent': [8, 11, 40, 46, 65, 73], 'units': [9, 21, 47, 66, 74], 'in': [10], 'neural': [12], 'networks': [13], '(RNNs).': [14], 'Especially,': [15], 'focus': [17], 'on': [18, 48], 'more': [19, 71], 'sophisticated': [20], 'that': [22, 62], 'implement': [23], 'a': [24, 29, 36], 'gating': [25], 'mechanism,': [26], 'such': [27, 75], 'as': [28, 76], 'long': [30], 'short-term': [31], 'memory': [32], '(LSTM)': [33], 'unit': [34, 41], 'and': [35, 55], 'recently': [37], 'proposed': [38], 'gated': [39], '(GRU).': [42], 'We': [43], 'evaluate': [44], 'these': [45, 63], 'the': [49], 'tasks': [50], 'polyphonic': [52], 'music': [53], 'modeling': [54], 'speech': [56], 'signal': [57], 'modeling.': [58], 'Our': [59], 'experiments': [60], 'revealed': [61], 'advanced': [64], 'are': [67], 'indeed': [68], 'better': [69], 'than': [70], 'traditional': [72], 'tanh': [77], 'units.': [78], 'Also,': [79], 'found': [81], 'GRU': [82], 'to': [83, 86], 'be': [84], 'comparable': [85], 'LSTM.': [87]}",2014,"['Recurrent neural network', 'Computer science', 'Focus (optics)', 'Speech recognition', 'Long short term memory', 'Sequence (biology)', 'Artificial intelligence', 'Polyphony', 'Artificial neural network', 'Psychology', 'Biology', 'Pedagogy', 'Optics', 'Physics', 'Genetics']","In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM."
https://openalex.org/W2907492528,A Comprehensive Survey on Graph Neural Networks,"{'Deep': [0], 'learning': [1, 6, 77, 85, 110], 'has': [2, 69], 'revolutionized': [3], 'many': [4, 80], 'machine': [5, 76, 109], 'tasks': [7, 29], 'in': [8, 27, 33, 105, 164], 'recent': [9], 'years,': [10], 'ranging': [11], 'from': [12, 49], 'image': [13], 'classification': [14], 'and': [15, 21, 52, 60, 108, 132, 145, 153], 'video': [16], 'processing': [17], 'to': [18, 117], 'speech': [19], 'recognition': [20], 'natural': [22], 'language': [23], 'understanding.': [24], 'The': [25, 64], 'data': [26, 46, 68, 89, 106, 151], 'these': [28], 'are': [30, 47, 53], 'typically': [31], 'represented': [32, 54], 'the': [34, 74, 119, 138, 147], 'Euclidean': [35], 'space.': [36], 'However,': [37], 'there': [38], 'is': [39], 'an': [40], 'increasing': [41], 'number': [42], 'of': [43, 66, 100, 140, 156], 'applications,': [44], 'where': [45], 'generated': [48], 'non-Euclidean': [50], 'domains': [51, 144], 'as': [55], 'graphs': [56], 'with': [57], 'complex': [58], 'relationships': [59], 'interdependency': [61], 'between': [62], 'objects.': [63], 'complexity': [65], 'graph': [67, 88, 101, 130], 'imposed': [70], 'significant': [71], 'challenges': [72], 'on': [73, 82], 'existing': [75], 'algorithms.': [78], 'Recently,': [79], 'studies': [81], 'extending': [83], 'deep': [84], 'approaches': [86], 'for': [87], 'have': [90], 'emerged.': [91], 'In': [92], 'this': [93, 165], 'article,': [94], 'we': [95, 159], 'provide': [96], 'a': [97, 114], 'comprehensive': [98], 'overview': [99], 'neural': [102], 'networks': [103], '(GNNs)': [104], 'mining': [107], 'fields.': [111], 'We': [112, 135], 'propose': [113, 160], 'new': [115], 'taxonomy': [116], 'divide': [118], 'state-of-the-art': [120], 'GNNs': [121, 141], 'into': [122], 'four': [123], 'categories,': [124], 'namely,': [125], 'recurrent': [126], 'GNNs,': [127, 129], 'convolutional': [128], 'autoencoders,': [131], 'spatial-temporal': [133], 'GNNs.': [134, 157], 'further': [136], 'discuss': [137], 'applications': [139], 'across': [142], 'various': [143], 'summarize': [146], 'open-source': [148], 'codes,': [149], 'benchmark': [150], 'sets,': [152], 'model': [154], 'evaluation': [155], 'Finally,': [158], 'potential': [161], 'research': [162], 'directions': [163], 'rapidly': [166], 'growing': [167], 'field.': [168]}",2020,[],"Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications, where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on the existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this article, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art GNNs into four categories, namely, recurrent GNNs, convolutional GNNs, graph autoencoders, and spatial-temporal GNNs. We further discuss the applications of GNNs across various domains and summarize the open-source codes, benchmark data sets, and model evaluation of GNNs. Finally, we propose potential research directions in this rapidly growing field."
https://openalex.org/W2612445135,MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications,"{'We': [0, 34, 70, 91], 'present': [1, 71], 'a': [2, 19, 99], 'class': [3], 'of': [4, 67, 96, 102], 'efficient': [5], 'models': [6, 87], 'called': [7], 'MobileNets': [8, 15, 97], 'for': [9, 60], 'mobile': [10], 'and': [11, 46, 76, 79, 104, 114], 'embedded': [12], 'vision': [13], 'applications.': [14], 'are': [16], 'based': [17, 63], 'on': [18, 64, 74, 88], 'streamlined': [20], 'architecture': [21], 'that': [22, 40], 'uses': [23], 'depth-wise': [24], 'separable': [25], 'convolutions': [26], 'to': [27, 54, 84], 'build': [28], 'light': [29], 'weight': [30], 'deep': [31], 'neural': [32], 'networks.': [33], 'introduce': [35], 'two': [36], 'simple': [37], 'global': [38], 'hyper-parameters': [39, 49], 'efficiently': [41], 'trade': [42], 'off': [43], 'between': [44], 'latency': [45], 'accuracy.': [47], 'These': [48], 'allow': [50], 'the': [51, 56, 65, 68, 94], 'model': [52, 59], 'builder': [53], 'choose': [55], 'right': [57], 'sized': [58], 'their': [61], 'application': [62], 'constraints': [66], 'problem.': [69], 'extensive': [72], 'experiments': [73], 'resource': [75], 'accuracy': [77], 'tradeoffs': [78], 'show': [80], 'strong': [81], 'performance': [82], 'compared': [83], 'other': [85], 'popular': [86], 'ImageNet': [89], 'classification.': [90], 'then': [92], 'demonstrate': [93], 'effectiveness': [95], 'across': [98], 'wide': [100], 'range': [101], 'applications': [103], 'use': [105], 'cases': [106], 'including': [107], 'object': [108], 'detection,': [109], 'finegrain': [110], 'classification,': [111], 'face': [112], 'attributes': [113], 'large': [115], 'scale': [116], 'geo-localization.': [117]}",2017,"['Computer science', 'Convolutional neural network', 'Latency (audio)', 'Artificial intelligence', 'Deep neural networks', 'Face (sociological concept)', 'Architecture', 'Deep learning', 'Mobile device', 'Object detection', 'Class (philosophy)', 'Simple (philosophy)', 'Range (aeronautics)', 'Artificial neural network', 'Scale (ratio)', 'Machine learning', 'Pattern recognition (psychology)', 'Engineering', 'Telecommunications', 'Visual arts', 'Physics', 'Aerospace engineering', 'Social science', 'Sociology', 'Epistemology', 'Philosophy', 'Operating system', 'Art', 'Quantum mechanics']","We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization."
https://openalex.org/W1673923490,Intriguing properties of neural networks,"{'Deep': [0], 'neural': [1, 102, 109], 'networks': [2, 110], 'are': [3, 115], 'highly': [4], 'expressive': [5], 'models': [6], 'that': [7, 38, 54, 81, 91, 107, 114, 169], 'have': [8, 40], 'recently': [9], 'achieved': [10], 'state': [11], 'of': [12, 68, 76, 93, 101, 151, 159, 176], 'the': [13, 26, 84, 88, 94, 98, 125, 142, 148, 161, 177, 181], 'art': [14], 'performance': [15], 'on': [16, 172], 'speech': [17], 'and': [18, 64], 'visual': [19], 'recognition': [20], 'tasks.': [21], 'While': [22], 'their': [23], 'expressiveness': [24], 'is': [25, 56, 83, 138, 154], 'reason': [27], 'they': [28], 'succeed,': [29], 'it': [30, 82], 'also': [31], 'causes': [32], 'them': [33], 'to': [34, 73, 118, 127, 179], 'learn': [35, 111], 'uninterpretable': [36], 'solutions': [37], 'could': [39], 'counter-intuitive': [41], 'properties.': [42, 50], 'In': [43, 146], 'this': [44], 'paper': [45], 'we': [46, 52, 105], 'report': [47], 'two': [48], 'such': [49], 'First,': [51], 'find': [53, 106], 'there': [55], 'no': [57], 'distinction': [58], 'between': [59], 'individual': [60, 89], 'high': [61, 69, 99], 'level': [62, 70], 'units': [63], 'random': [65, 157], 'linear': [66], 'combinations': [67], 'units,': [71, 90], 'according': [72], 'various': [74], 'methods': [75], 'unit': [77], 'analysis.': [78], 'It': [79], 'suggests': [80], 'space,': [85], 'rather': [86], 'than': [87], 'contains': [92], 'semantic': [95], 'information': [96], 'in': [97], 'layers': [100], 'networks.': [103], 'Second,': [104], 'deep': [108], 'input-output': [112], 'mappings': [113], 'fairly': [116], 'discontinuous': [117], 'a': [119, 133, 156, 166, 173], 'significant': [120], 'extend.': [121], 'We': [122], 'can': [123, 164], 'cause': [124, 165], 'network': [126], 'misclassify': [128, 180], 'an': [129], 'image': [130], 'by': [131, 140], 'applying': [132], 'certain': [134], 'imperceptible': [135], 'perturbation,': [136], 'which': [137], 'found': [139], 'maximizing': [141], ""network's"": [143], 'prediction': [144], 'error.': [145], 'addition,': [147], 'specific': [149], 'nature': [150], 'these': [152], 'perturbations': [153], 'not': [155], 'artifact': [158], 'learning:': [160], 'same': [162, 182], 'perturbation': [163], 'different': [167, 174], 'network,': [168], 'was': [170], 'trained': [171], 'subset': [175], 'dataset,': [178], 'input.': [183]}",2013,"['Computer science', 'Artificial neural network', 'Artifact (error)', 'Perturbation (astronomy)', 'Artificial intelligence', 'Deep neural networks', 'Machine learning', 'Physics', 'Quantum mechanics']","Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties. First, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains of the semantic information in the high layers of neural networks. Second, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extend. We can cause the network to misclassify an image by applying a certain imperceptible perturbation, which is found by maximizing the network's prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input."
https://openalex.org/W2560647685,Overcoming catastrophic forgetting in neural networks,"{'Significance': [0], 'Deep': [1], 'neural': [2], 'networks': [3], 'are': [4, 35], 'currently': [5], 'the': [6, 57, 74], 'most': [7], 'successful': [8], 'machine-learning': [9], 'technique': [10], 'for': [11, 60], 'solving': [12], 'a': [13, 47], 'variety': [14], 'of': [15, 27, 73], 'tasks,': [16], 'including': [17], 'language': [18], 'translation,': [19], 'image': [20, 23], 'classification,': [21], 'and': [22], 'generation.': [24], 'One': [25], 'weakness': [26], 'such': [28, 52], 'models': [29, 53], 'is': [30], 'that,': [31], 'unlike': [32], 'humans,': [33], 'they': [34], 'unable': [36], 'to': [37, 50], 'learn': [38], 'multiple': [39, 78], 'tasks': [40], 'sequentially.': [41, 83], 'In': [42], 'this': [43], 'work': [44], 'we': [45], 'propose': [46], 'practical': [48], 'solution': [49], 'train': [51], 'sequentially': [54], 'by': [55, 66], 'protecting': [56], 'weights': [58], 'important': [59], 'previous': [61], 'tasks.': [62], 'This': [63], 'approach,': [64], 'inspired': [65], 'synaptic': [67], 'consolidation': [68], 'in': [69], 'neuroscience,': [70], 'enables': [71], 'state': [72], 'art': [75], 'results': [76], 'on': [77], 'reinforcement': [79], 'learning': [80], 'problems': [81], 'experienced': [82]}",2017,"['Forgetting', 'Artificial neural network', 'Computer science', 'Psychology', 'Artificial intelligence', 'Cognitive psychology']","Significance Deep neural networks are currently the most successful machine-learning technique for solving a variety of tasks, including language translation, image classification, and image generation. One weakness of such models is that, unlike humans, they are unable to learn multiple tasks sequentially. In this work we propose a practical solution to train such models sequentially by protecting the weights important for previous tasks. This approach, inspired by synaptic consolidation in neuroscience, enables state of the art results on multiple reinforcement learning problems experienced sequentially."
https://openalex.org/W1904365287,Improving neural networks by preventing co-adaptation of feature detectors,"{'When': [0], 'a': [1, 9, 44, 65], 'large': [2, 79], 'feedforward': [3], 'neural': [4], 'network': [5], 'is': [6, 23, 47, 68], 'trained': [7], 'on': [8, 17, 34, 94], 'small': [10], 'training': [11, 36], 'set,': [12], 'it': [13, 86], 'typically': [14], 'performs': [15], 'poorly': [16], 'held-out': [18], 'test': [19], 'data.': [20], 'This': [21, 38], '""overfitting""': [22], 'greatly': [24], 'reduced': [25], 'by': [26], 'randomly': [27], 'omitting': [28], 'half': [29], 'of': [30, 53, 81], 'the': [31, 51, 73, 77], 'feature': [32, 45, 57, 66], 'detectors': [33], 'each': [35, 60], 'case.': [37], 'prevents': [39], 'complex': [40], 'co-adaptations': [41], 'in': [42, 50, 84], 'which': [43, 85], 'detector': [46], 'only': [48], 'helpful': [49, 70], 'context': [52], 'several': [54], 'other': [55], 'specific': [56], 'detectors.': [58], 'Instead,': [59], 'neuron': [61], 'learns': [62], 'to': [63], 'detect': [64], 'that': [67], 'generally': [69], 'for': [71, 102], 'producing': [72], 'correct': [74], 'answer': [75], 'given': [76], 'combinatorially': [78], 'variety': [80], 'internal': [82], 'contexts': [83], 'must': [87], 'operate.': [88], 'Random': [89], '""dropout""': [90], 'gives': [91], 'big': [92], 'improvements': [93], 'many': [95], 'benchmark': [96], 'tasks': [97], 'and': [98, 104], 'sets': [99], 'new': [100], 'records': [101], 'speech': [103], 'object': [105], 'recognition.': [106]}",2012,"['Overfitting', 'Feature (linguistics)', 'Dropout (neural networks)', 'Computer science', 'Benchmark (surveying)', 'Adaptation (eye)', 'Context (archaeology)', 'Detector', 'Set (abstract data type)', 'Artificial intelligence', 'Artificial neural network', 'Pattern recognition (psychology)', 'Variety (cybernetics)', 'Feed forward', 'Feedforward neural network', 'Machine learning', 'Engineering', 'Psychology', 'Geodesy', 'Programming language', 'Linguistics', 'Telecommunications', 'Paleontology', 'Neuroscience', 'Geography', 'Control engineering', 'Philosophy', 'Biology']","When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This ""overfitting"" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random ""dropout"" gives big improvements on many benchmark tasks and sets new records for speech and object recognition."
https://openalex.org/W2946948417,EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,"{'Convolutional': [0], 'Neural': [1], 'Networks': [2], '(ConvNets)': [3], 'are': [4, 22], 'commonly': [5], 'developed': [6], 'at': [7, 177], 'a': [8, 53, 65, 96, 106], 'fixed': [9], 'resource': [10], 'budget,': [11], 'and': [12, 32, 40, 83, 100, 117, 137, 152, 161], 'then': [13], 'scaled': [14], 'up': [15, 81, 103], 'for': [16], 'better': [17, 45, 115], 'accuracy': [18, 116, 130, 155], 'if': [19], 'more': [20], 'resources': [21], 'available.': [23], 'In': [24, 122], 'this': [25, 49, 77], 'paper,': [26], 'we': [27, 51, 89], 'systematically': [28], 'study': [29], 'model': [30], 'scaling': [31, 55, 80], 'identify': [33], 'that': [34, 57], 'carefully': [35], 'balancing': [36], 'network': [37, 99], 'depth,': [38], 'width,': [39], 'resolution': [41], 'can': [42], 'lead': [43], 'to': [44, 94, 104], 'performance.': [46], 'Based': [47], 'on': [48, 79, 131, 140, 156], 'observation,': [50], 'propose': [52], 'new': [54, 97], 'method': [56, 78], 'uniformly': [58], 'scales': [59], 'all': [60], 'dimensions': [61], 'of': [62, 76, 108, 170], 'depth/width/resolution': [63], 'using': [64], 'simple': [66], 'yet': [67], 'highly': [68], 'effective': [69], 'compound': [70], 'coefficient.': [71], 'We': [72], 'demonstrate': [73], 'the': [74, 143], 'effectiveness': [75], 'MobileNets': [82], 'ResNet.': [84], 'To': [85], 'go': [86], 'even': [87], 'further,': [88], 'use': [90], 'neural': [91], 'architecture': [92], 'search': [93], 'design': [95], 'baseline': [98], 'scale': [101], 'it': [102], 'obtain': [105], 'family': [107], 'models,': [109], 'called': [110], 'EfficientNets,': [111], 'which': [112], 'achieve': [113, 153], 'much': [114], 'efficiency': [118], 'than': [119, 142], 'previous': [120], 'ConvNets.': [121], 'particular,': [123], 'our': [124], 'EfficientNet-B7': [125], 'achieves': [126], 'state-of-the-art': [127, 154], '84.3%': [128], 'top-1': [129], 'ImageNet,': [132], 'while': [133], 'being': [134], '8.4x': [135], 'smaller': [136], '6.1x': [138], 'faster': [139], 'inference': [141], 'best': [144], 'existing': [145], 'ConvNet.': [146], 'Our': [147], 'EfficientNets': [148], 'also': [149], 'transfer': [150, 164], 'well': [151], 'CIFAR-100': [157], '(91.7%),': [158], 'Flowers': [159], '(98.8%),': [160], '3': [162], 'other': [163], 'learning': [165], 'datasets,': [166], 'with': [167], 'an': [168], 'order': [169], 'magnitude': [171], 'fewer': [172], 'parameters.': [173], 'Source': [174], 'code': [175], 'is': [176], 'https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet.': [178]}",2019,"['Scaling', 'Computer science', 'Inference', 'Convolutional neural network', 'Code (set theory)', 'Transfer of learning', 'Scale (ratio)', 'Algorithm', 'Artificial neural network', 'Resolution (logic)', 'Artificial intelligence', 'Machine learning', 'Pattern recognition (psychology)', 'Mathematics', 'Physics', 'Set (abstract data type)', 'Geometry', 'Quantum mechanics', 'Programming language']","Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.3% top-1 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet. Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7%), Flowers (98.8%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters. Source code is at https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet."
https://openalex.org/W1815076433,On the difficulty of training Recurrent Neural Networks,"{'There': [0], 'are': [1], 'two': [2], 'widely': [3], 'known': [4], 'issues': [5, 37], 'with': [6, 72], 'properly': [7], 'training': [8], 'Recurrent': [9], 'Neural': [10], 'Networks,': [11], 'the': [12, 15, 32, 35, 80, 93], 'vanishing': [13, 81], 'and': [14, 47, 75, 89], 'exploding': [16, 73], 'gradient': [17, 66], 'problems': [18, 41], 'detailed': [19], 'in': [20, 92], 'Bengio': [21], 'et': [22], 'al.': [23], '(1994).': [24], 'In': [25], 'this': [26], 'paper': [27], 'we': [28], 'attempt': [29], 'to': [30, 56, 70], 'improve': [31], 'understanding': [33], 'of': [34], 'underlying': [36], 'by': [38], 'exploring': [39], 'these': [40], 'from': [42], 'an': [43], 'analytical,': [44], 'a': [45, 48, 58, 65, 76], 'geometric': [46], 'dynamical': [49], 'systems': [50], 'perspective.': [51], 'Our': [52], 'analysis': [53], 'is': [54], 'used': [55], 'justify': [57], 'simple': [59], 'yet': [60], 'effective': [61], 'solution.': [62], 'We': [63, 84], 'propose': [64], 'norm': [67], 'clipping': [68], 'strategy': [69], 'deal': [71], 'gradients': [74, 82], 'soft': [77], 'constraint': [78], 'for': [79], 'problem.': [83], 'validate': [85], 'empirically': [86], 'our': [87], 'hypothesis': [88], 'proposed': [90], 'solutions': [91], 'experimental': [94], 'section.': [95]}",2012,"['Constraint (computer-aided design)', 'Perspective (graphical)', 'Computer science', 'Artificial neural network', 'Simple (philosophy)', 'Norm (philosophy)', 'Artificial intelligence', 'Gradient descent', 'Algorithm', 'Mathematical optimization', 'Mathematics', 'Geometry', 'Epistemology', 'Philosophy']","There are two widely known issues with properly training Recurrent Neural Networks, the vanishing and the exploding gradient problems detailed in Bengio et al. (1994). In this paper we attempt to improve the understanding of the underlying issues by exploring these problems from an analytical, a geometric and a dynamical systems perspective. Our analysis is used to justify a simple yet effective solution. We propose a gradient norm clipping strategy to deal with exploding gradients and a soft constraint for the vanishing gradients problem. We validate empirically our hypothesis and proposed solutions in the experimental section."
https://openalex.org/W2243397390,DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks,"{'State-of-the-art': [0], 'deep': [1, 50, 76], 'neural': [2], 'networks': [3], 'have': [4, 17, 40], 'achieved': [5], 'impressive': [6], 'results': [7, 89], 'on': [8, 55], 'many': [9], 'image': [10], 'classification': [11], 'tasks.': [12], 'However,': [13], 'these': [14, 85], 'same': [15], 'architectures': [16], 'been': [18, 41], 'shown': [19], 'to': [20, 23, 43, 52, 70], 'be': [21], 'unstable': [22], 'small,': [24], 'well': [25], 'sought,': [26], 'perturbations': [27, 54, 73, 103], 'of': [28, 34, 48, 84, 100], 'the': [29, 32, 46, 67, 82, 98], 'images.': [30], 'Despite': [31], 'importance': [33], 'this': [35, 59, 63], 'phenomenon,': [36], 'no': [37], 'effective': [38], 'methods': [39, 96], 'proposed': [42], 'accurately': [44], 'compute': [45, 72], 'robustness': [47, 83], 'state-of-the-art': [49], 'classifiers': [51, 106], 'such': [53], 'large-scale': [56], 'datasets.': [57], 'In': [58], 'paper,': [60], 'we': [61], 'fill': [62], 'gap': [64], 'and': [65, 78, 104], 'propose': [66], 'DeepFool': [68], 'algorithm': [69], 'efficiently': [71], 'that': [74, 91], 'fool': [75], 'networks,': [77], 'thus': [79], 'reliably': [80], 'quantify': [81], 'classifiers.': [86], 'Extensive': [87], 'experimental': [88], 'show': [90], 'our': [92], 'approach': [93], 'outperforms': [94], 'recent': [95], 'in': [97], 'task': [99], 'computing': [101], 'adversarial': [102], 'making': [105], 'more': [107], 'robust.': [108]}",2016,"['Simple (philosophy)', 'Computer science', 'Artificial neural network', 'Deep neural networks', 'Artificial intelligence', 'Philosophy', 'Epistemology']","State-of-the-art deep neural networks have achieved impressive results on many image classification tasks. However, these same architectures have been shown to be unstable to small, well sought, perturbations of the images. Despite the importance of this phenomenon, no effective methods have been proposed to accurately compute the robustness of state-of-the-art deep classifiers to such perturbations on large-scale datasets. In this paper, we fill this gap and propose the DeepFool algorithm to efficiently compute perturbations that fool deep networks, and thus reliably quantify the robustness of these classifiers. Extensive experimental results show that our approach outperforms recent methods in the task of computing adversarial perturbations and making classifiers more robust."
https://openalex.org/W2949888546,Sequence to Sequence Learning with Neural Networks,"{'Deep': [0], 'Neural': [1], 'Networks': [2], '(DNNs)': [3], 'are': [4, 25, 200, 206], 'powerful': [5], 'models': [6], 'that': [7, 48, 93, 199, 219], 'have': [8, 137], 'achieved': [9], 'excel-lent': [10], 'performance': [11, 237], 'on': [12, 52, 94, 117, 129, 139, 154], 'difficult': [13], 'learning': [14, 47], 'tasks.': [15], 'Although': [16], 'DNNs': [17], 'work': [18], 'well': [19], 'whenever': [20], 'large': [21], 'labeled': [22], 'training': [23], 'sets': [24], 'available,': [26], 'they': [27], 'cannot': [28], 'be': [29], 'used': [30, 160], 'to': [31, 34, 45, 64, 69, 81, 97, 163, 178, 183, 202, 209], 'map': [32, 65], 'sequences': [33], 'sequences.': [35], 'In': [36], 'this': [37], 'paper,': [38], 'we': [39, 159, 217], 'present': [40], 'a': [41, 59, 70, 73, 112, 144, 149], 'general': [42], 'end-to-end': [43], 'approach': [44], 'sequence': [46, 54, 68, 85], 'makes': [49], 'minimal': [50], 'assumptions': [51], 'the': [53, 66, 83, 87, 102, 105, 109, 118, 123, 133, 155, 161, 165, 170, 184, 188, 210, 213, 221, 224, 235, 248, 251, 256], 'structure.': [55], 'Our': [56, 89], 'method': [57], 'uses': [58], 'multilayered': [60], 'Long': [61], 'Short-TermMemory': [62], '(LSTM)': [63], 'input': [67], 'vector': [71], 'of': [72, 115, 152, 187, 223], 'fixed': [74], 'dimensionality,': [75], 'and': [76, 196, 205, 212, 250], 'then': [77], 'another': [78], 'deep': [79], 'LSTM': [80, 110, 134, 162, 191], 'decode': [82], 'target': [84, 232, 252], 'from': [86, 101], 'vector.': [88], 'main': [90], 'result': [91], 'is': [92, 181], 'an': [95], 'English': [96], 'French': [98], 'translation': [99], 'task': [100], 'WMT-14': [103], 'dataset,': [104], 'translations': [106], 'produced': [107, 168], 'by': [108, 169], 'achieve': [111], 'BLEU': [113, 125, 150, 175], 'score': [114, 126, 151, 176], '34.8': [116], 'entire': [119], 'test': [120], 'set,': [121], 'where': [122], 'LSTM’s': [124, 236], 'was': [127], 'penalized': [128], 'out-of-vocabulary': [130], 'words.': [131], 'Additionally,': [132], 'did': [135], 'not': [136, 231], 'difficulty': [138], 'long': [140], 'sentences.': [141], 'For': [142], 'comparison,': [143], 'phrase-based': [145], 'SMT': [146, 172], 'system': [147], 'achieves': [148], '33.3': [153], 'same': [156], 'dataset.': [157], 'When': [158], 'rerank': [164], '1000': [166], 'hypotheses': [167], 'aforementioned': [171], 'system,': [173], 'its': [174], 'increases': [177], '36.5,': [179], 'which': [180, 254], 'close': [182], 'previous': [185], 'state': [186], 'art.': [189], 'The': [190], 'also': [192], 'learned': [193], 'sensible': [194], 'phrase': [195], 'sentence': [197, 253], 'representations': [198], 'sensitive': [201], 'word': [203], 'order': [204, 222], 'relatively': [207], 'invariant': [208], 'active': [211], 'passive': [214], 'voice.': [215], 'Fi-nally,': [216], 'found': [218], 'reversing': [220], 'words': [225], 'in': [226], 'all': [227], 'source': [228, 249], 'sentences': [229], '(but': [230], 'sentences)': [233], 'improved': [234], 'markedly,': [238], 'because': [239], 'doing': [240], 'so': [241], 'introduced': [242], 'many': [243], 'short': [244], 'term': [245], 'dependencies': [246], 'between': [247], 'made': [255], 'optimization': [257], 'problem': [258], 'easier.': [259], '1': [260]}",2014,"['Computer science', 'Artificial intelligence', 'Sentence', 'Phrase', 'Sequence (biology)', 'Natural language processing', 'Word (group theory)', 'Task (project management)', 'Speech recognition', 'Recurrent neural network', 'Artificial neural network', 'Machine translation', 'Sequence learning', 'Mathematics', 'Biology', 'Genetics', 'Economics', 'Management', 'Geometry']","Deep Neural Networks (DNNs) are powerful models that have achieved excel-lent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-TermMemory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT-14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM’s BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous state of the art. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Fi-nally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM’s performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier. 1"
https://openalex.org/W2120615054,A Convolutional Neural Network for Modelling Sentences,"{'The': [0, 32, 45, 71, 111], 'ability': [1], 'to': [2, 8, 84, 134], 'accurately': [3], 'represent': [4], 'sentences': [5, 49], 'is': [6, 62, 81], 'central': [7], 'language': [9], 'understanding.': [10], 'We': [11, 87], 'describe': [12], 'a': [13, 38, 55, 77, 122], 'convolutional': [14], 'architecture': [15], 'dubbed': [16], 'the': [17, 27, 59, 89, 117, 129, 135], 'Dynamic': [18, 35], 'Convolutional': [19], 'Neural': [20], 'Network': [21], '(DCNN)': [22], 'that': [23, 61], 'we': [24], 'adopt': [25], 'for': [26], 'semantic': [28], 'modelling': [29], 'of': [30, 50, 64], 'sentences.': [31], 'network': [33, 46, 72, 112], 'uses': [34], 'k-Max': [36], 'Pooling,': [37], 'global': [39], 'pooling': [40], 'operation': [41], 'over': [42, 58], 'linear': [43], 'sequences.': [44], 'handles': [47], 'input': [48], 'varying': [51], 'length': [52], 'and': [53, 68, 80, 97, 104, 121], 'induces': [54], 'feature': [56], 'graph': [57], 'sentence': [60], 'capable': [63], 'explicitly': [65], 'capturing': [66], 'short': [67], 'long-range': [69], 'relations.': [70], 'does': [73], 'not': [74], 'rely': [75], 'on': [76], 'parse': [78], 'tree': [79], 'easily': [82], 'applicable': [83], 'any': [85], 'language.': [86], 'test': [88], 'DCNN': [90], 'in': [91, 116, 128], 'four': [92], 'experiments:': [93], 'small': [94], 'scale': [95], 'binary': [96], 'multi-class': [98], 'sentiment': [99, 106], 'prediction,': [100], 'six-way': [101], 'question': [102], 'classification': [103], 'Twitter': [105], 'prediction': [107], 'by': [108], 'distant': [109], 'supervision.': [110], 'achieves': [113], 'excellent': [114], 'performance': [115], 'first': [118], 'three': [119], 'tasks': [120], 'greater': [123], 'than': [124], '25%': [125], 'error': [126], 'reduction': [127], 'last': [130], 'task': [131], 'with': [132], 'respect': [133], 'strongest': [136], 'baseline.': [137]}",2014,"['Computer science', 'Convolutional neural network', 'Artificial intelligence', 'Natural language processing', 'Speech recognition']","The ability to accurately represent sentences is central to language understanding. We describe a convolutional architecture dubbed the Dynamic Convolutional Neural Network (DCNN) that we adopt for the semantic modelling of sentences. The network uses Dynamic k-Max Pooling, a global pooling operation over linear sequences. The network handles input sentences of varying length and induces a feature graph over the sentence that is capable of explicitly capturing short and long-range relations. The network does not rely on a parse tree and is easily applicable to any language. We test the DCNN in four experiments: small scale binary and multi-class sentiment prediction, six-way question classification and Twitter sentiment prediction by distant supervision. The network achieves excellent performance in the first three tasks and a greater than 25% error reduction in the last task with respect to the strongest baseline."
https://openalex.org/W3168997536,"A Survey of Convolutional Neural Networks: Analysis, Applications, and Prospects","{'A': [0], 'convolutional': [1], 'neural': [2], 'network': [3], '(CNN)': [4], 'is': [5], 'one': [6], 'of': [7, 112, 119, 152, 162], 'the': [8, 13, 46, 110, 160], 'most': [9], 'significant': [10], 'networks': [11], 'in': [12, 22, 45, 58, 89], 'deep': [14], 'learning': [15], 'field.': [16, 92], 'Since': [17], 'CNN': [18, 63, 127, 178], 'made': [19], 'impressive': [20], 'achievements': [21], 'many': [23], 'areas,': [24], 'including': [25], 'but': [26, 98], 'not': [27, 75, 94], 'limited': [28], 'to': [29, 82], 'computer': [30], 'vision': [31], 'and': [32, 43, 68, 87, 101, 125, 148, 156, 165, 174], 'natural': [33], 'language': [34], 'processing,': [35], 'it': [36], 'attracted': [37], 'much': [38], 'attention': [39], 'from': [40, 64], 'both': [41], 'industry': [42], 'academia': [44], 'past': [47], 'few': [48], 'years.': [49], 'The': [50], 'existing': [51], 'reviews': [52], 'mainly': [53], 'focus': [54], 'on': [55], ""CNN's"": [56], 'applications': [57, 161], 'different': [59], 'scenarios': [60], 'without': [61], 'considering': [62], 'a': [65], 'general': [66], 'perspective,': [67], 'some': [69, 84, 123, 146, 171], 'novel': [70, 85], 'ideas': [71, 86], 'proposed': [72], 'recently': [73], 'are': [74, 104, 129, 168, 179], 'covered.': [76, 169], 'In': [77], 'this': [78, 90, 107], 'review,': [79], 'we': [80, 115, 144], 'aim': [81], 'provide': [83, 116, 149], 'prospects': [88], 'fast-growing': [91], 'Besides,': [93], 'only': [95], '2-D': [96], 'convolution': [97, 167], 'also': [99], '1-D': [100], 'multidimensional': [102, 166], 'ones': [103], 'involved.': [105], 'First,': [106], 'review': [108], 'introduces': [109], 'history': [111], 'CNN.': [113], 'Second,': [114], 'an': [117], 'overview': [118], 'various': [120], 'convolutions.': [121], 'Third,': [122], 'classic': [124], 'advanced': [126], 'models': [128], 'introduced;': [130], 'especially': [131], 'those': [132], 'key': [133], 'points': [134], 'making': [135], 'them': [136], 'reach': [137], 'state-of-the-art': [138], 'results.': [139], 'Fourth,': [140], 'through': [141], 'experimental': [142], 'analysis,': [143], 'draw': [145], 'conclusions': [147], 'several': [150], 'rules': [151], 'thumb': [153], 'for': [154, 177, 183], 'functions': [155], 'hyperparameter': [157], 'selection.': [158], 'Fifth,': [159], '1-D,': [163], '2-D,': [164], 'Finally,': [170], 'open': [172], 'issues': [173], 'promising': [175], 'directions': [176], 'discussed': [180], 'as': [181], 'guidelines': [182], 'future': [184], 'work.': [185]}",2021,"['Convolutional neural network', 'Computer science', 'Data science', 'Artificial intelligence']","A convolutional neural network (CNN) is one of the most significant networks in the deep learning field. Since CNN made impressive achievements in many areas, including but not limited to computer vision and natural language processing, it attracted much attention from both industry and academia in the past few years. The existing reviews mainly focus on CNN's applications in different scenarios without considering CNN from a general perspective, and some novel ideas proposed recently are not covered. In this review, we aim to provide some novel ideas and prospects in this fast-growing field. Besides, not only 2-D convolution but also 1-D and multidimensional ones are involved. First, this review introduces the history of CNN. Second, we provide an overview of various convolutions. Third, some classic and advanced CNN models are introduced; especially those key points making them reach state-of-the-art results. Fourth, through experimental analysis, we draw some conclusions and provide several rules of thumb for functions and hyperparameter selection. Fifth, the applications of 1-D, 2-D, and multidimensional convolution are covered. Finally, some open issues and promising directions for CNN are discussed as guidelines for future work."
https://openalex.org/W2512971201,Deep Neural Networks for YouTube Recommendations,"{'YouTube': [0], 'represents': [1], 'one': [2], 'of': [3], 'the': [4, 20, 29, 43], 'largest': [5], 'scale': [6], 'and': [7, 26, 57, 70, 76], 'most': [8], 'sophisticated': [9], 'industrial': [10], 'recommendation': [11, 80], 'systems': [12], 'in': [13], 'existence.': [14], 'In': [15], 'this': [16], 'paper,': [17], 'we': [18, 50], 'describe': [19, 59], 'system': [21, 81], 'at': [22], 'a': [23, 52, 60, 78], 'high': [24], 'level': [25], 'focus': [27], 'on': [28], 'dramatic': [30], 'performance': [31], 'improvements': [32], 'brought': [33], 'by': [34], 'deep': [35, 53, 62], 'learning.': [36], 'The': [37], 'paper': [38], 'is': [39], 'split': [40], 'according': [41], 'to': [42], 'classic': [44], 'two-stage': [45], 'information': [46], 'retrieval': [47], 'dichotomy:': [48], 'first,': [49], 'detail': [51], 'candidate': [54], 'generation': [55], 'model': [56], 'then': [58], 'separate': [61], 'ranking': [63], 'model.': [64], 'We': [65], 'also': [66], 'provide': [67], 'practical': [68], 'lessons': [69], 'insights': [71], 'derived': [72], 'from': [73], 'designing,': [74], 'iterating': [75], 'maintaining': [77], 'massive': [79], 'with': [82], 'enormous': [83], 'user-facing': [84], 'impact.': [85]}",2016,"['Deep learning', 'Computer science', 'Ranking (information retrieval)', 'Focus (optics)', 'Deep neural networks', 'Artificial intelligence', 'Recommender system', 'Artificial neural network', 'Scale (ratio)', 'Data science', 'Information retrieval', 'Machine learning', 'Geography', 'Cartography', 'Optics', 'Physics']","YouTube represents one of the largest scale and most sophisticated industrial recommendation systems in existence. In this paper, we describe the system at a high level and focus on the dramatic performance improvements brought by deep learning. The paper is split according to the classic two-stage information retrieval dichotomy: first, we detail a deep candidate generation model and then describe a separate deep ranking model. We also provide practical lessons and insights derived from designing, iterating and maintaining a massive recommendation system with enormous user-facing impact."
https://openalex.org/W3186179742,Accurate prediction of protein structures and interactions using a three-track neural network,"{'Deep': [0, 43], 'learning': [1, 44], 'takes': [2], 'on': [3, 65], 'protein': [4], 'folding': [5], 'In': [6], '1972,': [7], 'Anfinsen': [8], 'won': [9], 'a': [10, 15, 18, 71], 'Nobel': [11], 'prize': [12], 'for': [13], 'demonstrating': [14], 'connection': [16], 'between': [17], 'protein’s': [19], 'amino': [20], 'acid': [21], 'sequence': [22], 'and': [23, 78, 82, 98, 103], 'its': [24], 'three-dimensional': [25], 'structure.': [26], 'Since': [27], '1994,': [28], 'scientists': [29], 'have': [30], 'competed': [31], 'in': [32], 'the': [33, 66], 'biannual': [34], 'Critical': [35], 'Assessment': [36], 'of': [37, 87, 107], 'Structure': [38], 'Prediction': [39], '(CASP)': [40], 'protein-folding': [41], 'challenge.': [42], 'methods': [45], 'took': [46], 'center': [47], 'stage': [48], 'at': [49], 'CASP14,': [50], 'with': [51], 'DeepMind’s': [52], 'Alphafold2': [53], 'achieving': [54], 'remarkable': [55], 'accuracy.': [56], 'Baek': [57], 'et': [58], 'al': [59], '.': [60], 'explored': [61], 'network': [62, 73], 'architectures': [63], 'based': [64], 'DeepMind': [67], 'framework.': [68], 'They': [69], 'used': [70], 'three-track': [72], 'to': [74], 'process': [75], 'sequence,': [76], 'distance,': [77], 'coordinate': [79], 'information': [80], 'simultaneously': [81], 'achieved': [83], 'accuracies': [84], 'approaching': [85], 'those': [86], 'DeepMind.': [88], 'The': [89], 'method,': [90], 'RoseTTA': [91], 'fold,': [92], 'can': [93], 'solve': [94], 'challenging': [95], 'x-ray': [96], 'crystallography': [97], 'cryo–electron': [99], 'microscopy': [100], 'modeling': [101], 'problems': [102], 'generate': [104], 'accurate': [105], 'models': [106], 'protein-protein': [108], 'complexes.': [109], '—VV': [110]}",2021,"['CASP', 'Protein structure prediction', 'Artificial neural network', 'Computer science', 'Folding (DSP implementation)', 'Artificial intelligence', 'Sequence (biology)', 'Protein folding', 'Deep learning', 'Protein structure', 'Computational biology', 'Machine learning', 'Chemistry', 'Biology', 'Engineering', 'Biochemistry', 'Electrical engineering']","Deep learning takes on protein folding In 1972, Anfinsen won a Nobel prize for demonstrating a connection between a protein’s amino acid sequence and its three-dimensional structure. Since 1994, scientists have competed in the biannual Critical Assessment of Structure Prediction (CASP) protein-folding challenge. Deep learning methods took center stage at CASP14, with DeepMind’s Alphafold2 achieving remarkable accuracy. Baek et al . explored network architectures based on the DeepMind framework. They used a three-track network to process sequence, distance, and coordinate information simultaneously and achieved accuracies approaching those of DeepMind. The method, RoseTTA fold, can solve challenging x-ray crystallography and cryo–electron microscopy modeling problems and generate accurate models of protein-protein complexes. —VV"
https://openalex.org/W2149933564,How transferable are features in deep neural networks?,"{'Many': [0], 'deep': [1, 94], 'neural': [2, 96], 'networks': [3, 142], 'trained': [4, 154], 'on': [5, 14, 128, 155, 168], 'natural': [6], 'images': [7], 'exhibit': [8], 'a': [9, 37, 93, 100, 224, 237], 'curious': [10], 'phenomenon': [11], 'in': [12, 44, 89], 'common:': [13], 'the': [15, 63, 67, 83, 113, 124, 129, 174, 180, 186, 192, 195, 247], 'first': [16], 'layer': [17, 65, 91, 117], 'they': [18, 46], 'learn': [19], 'features': [20, 30, 170, 189, 205, 228], 'similar': [21], 'to': [22, 33, 36, 49, 60, 119, 140, 239, 246], 'Gabor': [23], 'filters': [24], 'and': [25, 52, 98, 135, 198], 'color': [26], 'blobs.': [27], 'Such': [28], 'first-layer': [29], 'appear': [31], 'not': [32, 73, 148], 'be': [34, 211], 'specific': [35, 61], 'particular': [38], 'dataset': [39], 'or': [40, 177], 'task,': [41, 131], 'but': [42, 69, 202], 'general': [43, 59], 'that': [45, 159, 185, 203, 222, 241], 'are': [47, 171], 'applicable': [48], 'many': [50], 'datasets': [51], 'tasks.': [53], 'Features': [54], 'must': [55], 'eventually': [56], 'transition': [57, 71], 'from': [58, 173, 207, 229], 'by': [62, 108], 'last': [64], 'of': [66, 87, 92, 115, 126, 161, 179, 188, 233], 'network,': [68], 'this': [70, 78], 'has': [72], 'been': [74], 'studied': [75], 'extensively.': [76], 'In': [77, 150], 'paper': [79], 'we': [80, 157], 'experimentally': [81], 'quantify': [82], 'generality': [84], 'versus': [85], 'specificity': [86], 'neurons': [88, 118], 'each': [90], 'convolutional': [95], 'network': [97, 153, 225], 'report': [99], 'few': [101], 'surprising': [102, 219], 'results.': [103], 'Transferability': [104], 'is': [105, 221], 'negatively': [106], 'affected': [107], 'two': [109, 163], 'distinct': [110], 'issues:': [111], '(1)': [112], 'specialization': [114], 'higher': [116], 'their': [120], 'original': [121], 'task': [122, 197, 200], 'at': [123], 'expense': [125], 'performance': [127], 'target': [130, 199, 248], 'which': [132, 146], 'was': [133, 147], 'expected,': [134], '(2)': [136], 'optimization': [137], 'difficulties': [138], 'related': [139], 'splitting': [141], 'between': [143, 194], 'co-adapted': [144], 'neurons,': [145], 'expected.': [149], 'an': [151], 'example': [152], 'ImageNet,': [156], 'demonstrate': [158], 'either': [160], 'these': [162], 'issues': [164], 'may': [165], 'dominate,': [166], 'depending': [167], 'whether': [169], 'transferred': [172, 227], 'bottom,': [175], 'middle,': [176], 'top': [178], 'network.': [181], 'We': [182], 'also': [183], 'document': [184], 'transferability': [187], 'decreases': [190], 'as': [191], 'distance': [193], 'base': [196], 'increases,': [201], 'transferring': [204], 'even': [206, 243], 'distant': [208], 'tasks': [209], 'can': [210, 235], 'better': [212], 'than': [213], 'using': [214], 'random': [215], 'features.': [216], 'A': [217], 'final': [218], 'result': [220], 'initializing': [223], 'with': [226], 'almost': [230], 'any': [231], 'number': [232], 'layers': [234], 'produce': [236], 'boost': [238], 'generalization': [240], 'lingers': [242], 'after': [244], 'fine-tuning': [245], 'dataset.': [249]}",2014,"['Computer science', 'Initialization', 'Generality', 'Artificial intelligence', 'Task (project management)', 'Artificial neural network', 'Generalization', 'Layer (electronics)', 'Transferability', 'Convolutional neural network', 'Deep learning', 'Pattern recognition (psychology)', 'Machine learning', 'Mathematics', 'Economics', 'Mathematical analysis', 'Psychology', 'Management', 'Organic chemistry', 'Logit', 'Psychotherapist', 'Programming language', 'Chemistry']","Many deep neural networks trained on natural images exhibit a curious phenomenon in common: on the first layer they learn features similar to Gabor filters and color blobs. Such first-layer features appear not to be specific to a particular dataset or task, but general in that they are applicable to many datasets and tasks. Features must eventually transition from general to specific by the last layer of the network, but this transition has not been studied extensively. In this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results. Transferability is negatively affected by two distinct issues: (1) the specialization of higher layer neurons to their original task at the expense of performance on the target task, which was expected, and (2) optimization difficulties related to splitting networks between co-adapted neurons, which was not expected. In an example network trained on ImageNet, we demonstrate that either of these two issues may dominate, depending on whether features are transferred from the bottom, middle, or top of the network. We also document that the transferability of features decreases as the distance between the base task and target task increases, but that transferring features even from distant tasks can be better than using random features. A final surprising result is that initializing a network with transferred features from almost any number of layers can produce a boost to generalization that lingers even after fine-tuning to the target dataset."
https://openalex.org/W2253429366,"Deep Convolutional Neural Networks for Computer-Aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning","{'Remarkable': [0], 'progress': [1], 'has': [2], 'been': [3], 'made': [4], 'in': [5, 44, 144], 'image': [6, 30, 64, 97, 101, 158], 'recognition,': [7], 'primarily': [8], 'due': [9], 'to': [10, 62, 99, 120, 138, 237], 'the': [11, 45, 67, 151, 200, 204, 210, 238], 'availability': [12], 'of': [13, 114, 146, 153, 240], 'large-scale': [14], 'annotated': [15, 41], 'datasets': [16, 38], 'and': [17, 76, 127, 142, 156, 166, 192, 208, 231], 'deep': [18, 116], 'convolutional': [19, 117], 'neural': [20, 118], 'networks': [21, 119], '(CNNs).': [22], 'CNNs': [23, 61], 'enable': [24], 'learning': [25, 169], 'data-driven,': [26], 'highly': [27], 'representative,': [28], 'hierarchical': [29], 'features': [31], 'from': [32, 69, 95, 170], 'sufficient': [33], 'training': [34, 66], 'data.': [35], 'However,': [36], 'obtaining': [37], 'as': [39, 42], 'comprehensively': [40], 'ImageNet': [43, 172], 'medical': [46, 63, 100, 247], 'imaging': [47, 248], 'domain': [48], 'remains': [49], 'a': [50], 'challenge.': [51], 'There': [52], 'are': [53], 'currently': [54], 'three': [55, 108], 'major': [56], 'techniques': [57], 'that': [58], 'successfully': [59], 'employ': [60], 'classification:': [65], 'CNN': [68, 74, 79, 92, 130, 228], 'scratch,': [70], 'using': [71], 'off-the-shelf': [72], 'pre-trained': [73, 94, 171], 'features,': [75], 'conducting': [77], 'unsupervised': [78], 'pre-training': [80], 'with': [81, 221], 'supervised': [82], 'fine-tuning.': [83], 'Another': [84], 'effective': [85], 'method': [86], 'is': [87], 'transfer': [88, 168], 'learning,': [89], 'i.e.,': [90], 'fine-tuning': [91], 'models': [93, 134], 'natural': [96], 'dataset': [98, 154], 'tasks.': [102, 249], 'In': [103], 'this': [104], 'paper,': [105], 'we': [106, 163], 'exploit': [107], 'important,': [109], 'but': [110], 'previously': [111], 'understudied': [112], 'factors': [113], 'employing': [115], 'computer-aided': [121, 182], 'detection': [122, 183, 191], 'problems.': [123], 'We': [124, 148, 178, 198], 'first': [125, 211], 'explore': [126], 'evaluate': [128, 150], 'different': [129], 'architectures.': [131], 'The': [132], 'studied': [133], 'contain': [135], '5': [136], 'thousand': [137], '160': [139], 'million': [140], 'parameters,': [141], 'vary': [143], 'numbers': [145], 'layers.': [147], 'then': [149], 'influence': [152], 'scale': [155], 'spatial': [157], 'context': [159], 'on': [160, 203, 216], 'performance.': [161], 'Finally,': [162], 'examine': [164], 'when': [165], 'why': [167], '(via': [173], 'fine-tuning)': [174], 'can': [175, 234], 'be': [176, 235], 'useful.': [177], 'study': [179], 'two': [180], 'specific': [181], '(CADe)': [184], 'problems,': [185], 'namely': [186], 'thoraco-abdominal': [187], 'lymph': [188], 'node': [189], '(LN)': [190], 'interstitial': [193], 'lung': [194], 'disease': [195], '(ILD)': [196], 'classification.': [197], 'achieve': [199], 'state-of-the-art': [201], 'performance': [202, 242], 'mediastinal': [205], 'LN': [206], 'detection,': [207], 'report': [209], 'five-fold': [212], 'cross-validation': [213], 'classification': [214], 'results': [215], 'predicting': [217], 'axial': [218], 'CT': [219], 'slices': [220], 'ILD': [222], 'categories.': [223], 'Our': [224], 'extensive': [225], 'empirical': [226], 'evaluation,': [227], 'model': [229], 'analysis': [230], 'valuable': [232], 'insights': [233], 'extended': [236], 'design': [239], 'high': [241], 'CAD': [243], 'systems': [244], 'for': [245], 'other': [246]}",2016,"['Convolutional neural network', 'Computer science', 'Transfer of learning', 'Artificial intelligence', 'Deep learning', 'Contextual image classification', 'Pattern recognition (psychology)', 'Context (archaeology)', 'Medical imaging', 'Machine learning', 'Object detection', 'Feature extraction', 'Image (mathematics)', 'Paleontology', 'Biology']","Remarkable progress has been made in image recognition, primarily due to the availability of large-scale annotated datasets and deep convolutional neural networks (CNNs). CNNs enable learning data-driven, highly representative, hierarchical image features from sufficient training data. However, obtaining datasets as comprehensively annotated as ImageNet in the medical imaging domain remains a challenge. There are currently three major techniques that successfully employ CNNs to medical image classification: training the CNN from scratch, using off-the-shelf pre-trained CNN features, and conducting unsupervised CNN pre-training with supervised fine-tuning. Another effective method is transfer learning, i.e., fine-tuning CNN models pre-trained from natural image dataset to medical image tasks. In this paper, we exploit three important, but previously understudied factors of employing deep convolutional neural networks to computer-aided detection problems. We first explore and evaluate different CNN architectures. The studied models contain 5 thousand to 160 million parameters, and vary in numbers of layers. We then evaluate the influence of dataset scale and spatial image context on performance. Finally, we examine when and why transfer learning from pre-trained ImageNet (via fine-tuning) can be useful. We study two specific computer-aided detection (CADe) problems, namely thoraco-abdominal lymph node (LN) detection and interstitial lung disease (ILD) classification. We achieve the state-of-the-art performance on the mediastinal LN detection, and report the first five-fold cross-validation classification results on predicting axial CT slices with ILD categories. Our extensive empirical evaluation, CNN model analysis and valuable insights can be extended to the design of high performance CAD systems for other medical imaging tasks."
https://openalex.org/W2963285578,Convergence Results for Neural Networks via Electrodynamics,"{'We': [0], 'study': [1], 'whether': [2, 28, 70], 'a': [3, 18, 85, 159], 'depth': [4, 11], 'two': [5, 12], 'neural': [6], 'network': [7, 13, 155], 'can': [8, 148], 'learn': [9, 152], 'another': [10], 'using': [14], 'gradient': [15, 29, 128, 146], 'descent.': [16], 'Assuming': [17], 'linear': [19], 'output': [20], 'node,': [21], 'we': [22, 118, 143], 'show': [23, 144], 'that': [24, 127, 145], 'the': [25, 33, 39, 57, 61, 67, 74, 81, 88, 95, 102, 107, 111, 120, 135, 139, 153], 'question': [26, 41], 'of': [27, 122, 134], 'descent': [30, 129, 147], 'converges': [31], 'to': [32, 38, 56, 84, 151], 'target': [34, 140], 'function': [35, 109, 125], 'is': [36, 104], 'equivalent': [37], 'following': [40], 'in': [42, 48, 138], 'electrodynamics:': [43], 'Given': [44], 'k': [45, 51], 'fixed': [46], 'protons': [47, 62], 'R^d,': [49], 'and': [50, 63, 110], 'electrons,': [52, 69], 'each': [53], 'moving': [54], 'due': [55], 'attractive': [58], 'force': [59, 65, 103], 'from': [60, 66, 94], 'repulsive': [64], 'remaining': [68], 'at': [71, 131, 158], 'equilibrium': [72], 'all': [73], 'electrons': [75], 'will': [76], 'be': [77, 149], 'matched': [78], 'up': [79, 83], 'with': [80], 'protons,': [82], 'permutation.': [86], 'Under': [87], 'standard': [89], 'electrical': [90], 'force,': [91], 'this': [92, 116], 'follows': [93], 'classic': [96], ""Earnshaw's"": [97], 'theorem.': [98], 'In': [99], 'our': [100], 'setting,': [101], 'determined': [105], 'by': [106], 'activation': [108, 124], 'input': [112], 'distribution.': [113], 'Building': [114], 'on': [115], 'equivalence,': [117], 'prove': [119], 'existence': [121], 'an': [123], 'such': [126], 'learns': [130], 'least': [132], 'one': [133, 156], 'hidden': [136], 'nodes': [137], 'network.': [141], 'Iterating,': [142], 'used': [150], 'entire': [154], 'node': [157], 'time.': [160]}",2018,"['Computer science', 'Exponential function', 'Artificial intelligence', 'Mathematics', 'Mathematical analysis']","We study whether a depth two neural network can learn another depth two network using gradient descent. Assuming a linear output node, we show that the question of whether gradient descent converges to the target function is equivalent to the following question in electrodynamics: Given k fixed protons in R^d, and k electrons, each moving due to the attractive force from the protons and repulsive force from the remaining electrons, whether at equilibrium all the electrons will be matched up with the protons, up to a permutation. Under the standard electrical force, this follows from the classic Earnshaw's theorem. In our setting, the force is determined by the activation function and the input distribution. Building on this equivalence, we prove the existence of an activation function such that gradient descent learns at least one of the hidden nodes in the target network. Iterating, we show that gradient descent can be used to learn the entire network one node at a time."
https://openalex.org/W1591801644,Recurrent Neural Network Regularization,"{'We': [0], 'present': [1], 'a': [2, 54], 'simple': [3], 'regularization': [4], 'technique': [5, 21], 'for': [6, 22], 'Recurrent': [7], 'Neural': [8], 'Networks': [9], '(RNNs)': [10], 'with': [11, 30], 'Long': [12], 'Short-Term': [13], 'Memory': [14], '(LSTM)': [15], 'units.': [16], 'Dropout,': [17], 'the': [18], 'most': [19], 'successful': [20], 'regularizing': [23], 'neural': [24], 'networks,': [25], 'does': [26], 'not': [27], 'work': [28], 'well': [29], 'RNNs': [31], 'and': [32, 46, 68], 'LSTMs.': [33], 'In': [34], 'this': [35], 'paper,': [36], 'we': [37], 'show': [38, 47], 'how': [39], 'to': [40, 44], 'correctly': [41], 'apply': [42], 'dropout': [43], 'LSTMs,': [45], 'that': [48], 'it': [49], 'substantially': [50], 'reduces': [51], 'overfitting': [52], 'on': [53], 'variety': [55], 'of': [56], 'tasks.': [57], 'These': [58], 'tasks': [59], 'include': [60], 'language': [61], 'modeling,': [62], 'speech': [63], 'recognition,': [64], 'image': [65], 'caption': [66], 'generation,': [67], 'machine': [69], 'translation.': [70]}",2014,"['Regularization (linguistics)', 'Artificial neural network', 'Computer science', 'Artificial intelligence']","We present a simple regularization technique for Recurrent Neural Networks (RNNs) with Long Short-Term Memory (LSTM) units. Dropout, the most successful technique for regularizing neural networks, does not work well with RNNs and LSTMs. In this paper, we show how to correctly apply dropout to LSTMs, and show that it substantially reduces overfitting on a variety of tasks. These tasks include language modeling, speech recognition, image caption generation, and machine translation."
https://openalex.org/W2746314669,Improved Regularization of Convolutional Neural Networks with Cutout,"{'Convolutional': [0], 'neural': [1, 81], 'networks': [2], 'are': [3, 11, 30], 'capable': [4], 'of': [5, 55, 61, 79, 106, 139], 'learning': [6, 16], 'powerful': [7], 'representational': [8], 'spaces,': [9], 'which': [10, 65], 'necessary': [12], 'for': [13], 'tackling': [14], 'complex': [15], 'tasks.': [17], 'However,': [18], 'due': [19], 'to': [20, 25, 33, 42, 72, 90, 112, 124], 'the': [21, 51, 74, 129], 'model': [22, 115], 'capacity': [23], 'required': [24], 'capture': [26], 'such': [27], 'representations,': [28], 'they': [29], 'often': [31], 'susceptible': [32], 'overfitting': [34], 'and': [35, 76, 109, 132, 142], 'therefore': [36], 'require': [37], 'proper': [38], 'regularization': [39, 53], 'in': [40, 101], 'order': [41], 'generalize': [43], 'well.': [44], 'In': [45], 'this': [46, 86, 119], 'paper,': [47], 'we': [48, 66, 93], 'show': [49], 'that': [50, 96], 'simple': [52], 'technique': [54], 'randomly': [56], 'masking': [57], 'out': [58], 'square': [59], 'regions': [60], 'input': [62], 'during': [63], 'training,': [64], 'call': [67], 'cutout,': [68], 'can': [69, 98], 'be': [70, 99], 'used': [71, 100], 'improve': [73, 114], 'robustness': [75], 'overall': [77], 'performance': [78], 'convolutional': [80], 'networks.': [82], 'Not': [83], 'only': [84], 'is': [85, 148], 'method': [87, 120], 'extremely': [88], 'easy': [89], 'implement,': [91], 'but': [92], 'also': [94], 'demonstrate': [95], 'it': [97, 123], 'conjunction': [102], 'with': [103], 'existing': [104], 'forms': [105], 'data': [107], 'augmentation': [108], 'other': [110], 'regularizers': [111], 'further': [113], 'performance.': [116], 'We': [117], 'evaluate': [118], 'by': [121], 'applying': [122], 'current': [125], 'state-of-the-art': [126, 137], 'architectures': [127], 'on': [128], 'CIFAR-10,': [130], 'CIFAR-100,': [131], 'SVHN': [133], 'datasets,': [134], 'yielding': [135], 'new': [136], 'results': [138], '2.56%,': [140], '15.20%,': [141], '1.30%': [143], 'test': [144], 'error': [145], 'respectively.': [146], 'Code': [147], 'available': [149], 'at': [150], 'https://github.com/uoguelph-mlrg/Cutout': [151]}",2017,"['Convolutional neural network', 'Regularization (linguistics)', 'Computer science', 'Artificial intelligence']","Convolutional neural networks are capable of learning powerful representational spaces, which are necessary for tackling complex learning tasks. However, due to the model capacity required to capture such representations, they are often susceptible to overfitting and therefore require proper regularization in order to generalize well. In this paper, we show that the simple regularization technique of randomly masking out square regions of input during training, which we call cutout, can be used to improve the robustness and overall performance of convolutional neural networks. Not only is this method extremely easy to implement, but we also demonstrate that it can be used in conjunction with existing forms of data augmentation and other regularizers to further improve model performance. We evaluate this method by applying it to current state-of-the-art architectures on the CIFAR-10, CIFAR-100, and SVHN datasets, yielding new state-of-the-art results of 2.56%, 15.20%, and 1.30% test error respectively. Code is available at https://github.com/uoguelph-mlrg/Cutout"
https://openalex.org/W2319920447,Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1,"{'We': [0], 'introduce': [1], 'a': [2, 98], 'method': [3], 'to': [4, 56, 109], 'train': [5], 'Binarized': [6], 'Neural': [7], 'Networks': [8], '(BNNs)': [9], '-': [10], 'neural': [11], 'networks': [12], 'with': [13, 50, 104, 118], 'binary': [14, 23, 99], 'weights': [15, 24], 'and': [16, 25, 43, 45, 75, 89, 134], 'activations': [17, 26], 'at': [18], 'run-time.': [19], 'At': [20], 'training-time': [21], 'the': [22, 31, 35, 62, 73, 86], 'are': [27], 'used': [28], 'for': [29, 132], 'computing': [30], 'parameters': [32], 'gradients.': [33], 'During': [34], 'forward': [36], 'pass,': [37], 'BNNs': [38, 65, 80, 137], 'drastically': [39], 'reduce': [40], 'memory': [41], 'size': [42], 'accesses,': [44], 'replace': [46], 'most': [47], 'arithmetic': [48], 'operations': [49], 'bit-wise': [51], 'operations,': [52], 'which': [53, 105], 'is': [54, 107, 138], 'expected': [55], 'substantially': [57], 'improve': [58], 'power-efficiency.': [59], 'To': [60], 'validate': [61], 'effectiveness': [63], 'of': [64, 70], 'we': [66, 96], 'conduct': [67], 'two': [68], 'sets': [69], 'experiments': [71], 'on': [72], 'Torch7': [74], 'Theano': [76], 'frameworks.': [77], 'On': [78], 'both,': [79], 'achieved': [81], 'nearly': [82], 'state-of-the-art': [83], 'results': [84], 'over': [85], 'MNIST,': [87], 'CIFAR-10': [88], 'SVHN': [90], 'datasets.': [91], 'Last': [92], 'but': [93], 'not': [94], 'least,': [95], 'wrote': [97], 'matrix': [100], 'multiplication': [101], 'GPU': [102, 121], 'kernel': [103], 'it': [106], 'possible': [108], 'run': [110], 'our': [111, 136], 'MNIST': [112], 'BNN': [113], '7': [114], 'times': [115], 'faster': [116], 'than': [117], 'an': [119], 'unoptimized': [120], 'kernel,': [122], 'without': [123], 'suffering': [124], 'any': [125], 'loss': [126], 'in': [127], 'classification': [128], 'accuracy.': [129], 'The': [130], 'code': [131], 'training': [133], 'running': [135], 'available': [139], 'on-line.': [140]}",2016,"['MNIST database', 'Computer science', 'Artificial neural network', 'Multiplication (music)', 'Binary number', 'Kernel (algebra)', 'Code (set theory)', 'Deep neural networks', 'Artificial intelligence', 'Machine learning', 'Deep learning', 'Matrix multiplication', 'Pattern recognition (psychology)', 'Arithmetic', 'Mathematics', 'Physics', 'Quantum mechanics', 'Quantum', 'Programming language', 'Set (abstract data type)', 'Combinatorics']","We introduce a method to train Binarized Neural Networks (BNNs) - neural networks with binary weights and activations at run-time. At training-time the binary weights and activations are used for computing the parameters gradients. During the forward pass, BNNs drastically reduce memory size and accesses, and replace most arithmetic operations with bit-wise operations, which is expected to substantially improve power-efficiency. To validate the effectiveness of BNNs we conduct two sets of experiments on the Torch7 and Theano frameworks. On both, BNNs achieved nearly state-of-the-art results over the MNIST, CIFAR-10 and SVHN datasets. Last but not least, we wrote a binary matrix multiplication GPU kernel with which it is possible to run our MNIST BNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy. The code for training and running our BNNs is available on-line."
https://openalex.org/W2113325037,DeepPose: Human Pose Estimation via Deep Neural Networks,"{'We': [0, 27, 71], 'propose': [1], 'a': [2, 20, 29, 52, 57, 73], 'method': [3], 'for': [4], 'human': [5], 'pose': [6, 15, 40, 50], 'estimation': [7, 16], 'based': [8], 'on': [9, 65, 82], 'Deep': [10, 69], 'Neural': [11], 'Networks': [12], '(DNNs).': [13], 'The': [14, 42], 'is': [17], 'formulated': [18], 'as': [19], 'DNN-based': [21], 'regression': [22], 'problem': [23], 'towards': [24], 'body': [25], 'joints.': [26], 'present': [28, 72], 'cascade': [30], 'of': [31, 47, 86], 'such': [32], 'DNN': [33], 'regressors': [34], 'which': [35, 63], 'results': [36], 'in': [37, 51, 68], 'high': [38], 'precision': [39], 'estimates.': [41], 'approach': [43], 'has': [44, 56], 'the': [45], 'advantage': [46], 'reasoning': [48], 'about': [49], 'holistic': [53], 'fashion': [54], 'and': [55], 'simple': [58], 'but': [59], 'yet': [60], 'powerful': [61], 'formulation': [62], 'capitalizes': [64], 'recent': [66], 'advances': [67], 'Learning.': [70], 'detailed': [74], 'empirical': [75], 'analysis': [76], 'with': [77], 'state-of-art': [78], 'or': [79], 'better': [80], 'performance': [81], 'four': [83], 'academic': [84], 'benchmarks': [85], 'diverse': [87], 'real-world': [88], 'images.': [89]}",2014,"['Computer science', 'Artificial intelligence', 'Pose', 'Artificial neural network', 'Estimation', 'Deep neural networks', 'Computer vision', 'Pattern recognition (psychology)', 'Machine learning', 'Engineering', 'Systems engineering']",We propose a method for human pose estimation based on Deep Neural Networks (DNNs). The pose estimation is formulated as a DNN-based regression problem towards body joints. We present a cascade of such DNN regressors which results in high precision pose estimates. The approach has the advantage of reasoning about pose in a holistic fashion and has a simple but yet powerful formulation which capitalizes on recent advances in Deep Learning. We present a detailed empirical analysis with state-of-art or better performance on four academic benchmarks of diverse real-world images.
https://openalex.org/W2901312569,State-of-the-art in artificial neural network applications: A survey,"{'This': [0], 'is': [1], 'a': [2, 14, 152], 'survey': [3], 'of': [4, 16, 27, 38, 60, 150], 'neural': [5, 18, 105], 'network': [6], 'applications': [7, 34, 59], 'in': [8, 32, 63, 110], 'the': [9, 23, 43], 'real-world': [10], 'scenario.': [11], 'It': [12], 'provides': [13], 'taxonomy': [15], 'artificial': [17, 104], 'networks': [19, 106], '(ANNs)': [20], 'and': [21, 29, 36, 52, 79, 89, 101, 120, 143], 'furnish': [22], 'reader': [24], 'with': [25], 'knowledge': [26], 'current': [28], 'emerging': [30], 'trends': [31], 'ANN': [33, 46, 61, 85, 123, 161], 'research': [35, 126, 156], 'area': [37], 'focus': [39, 127, 158], 'for': [40, 125], 'researchers.': [41], 'Additionally,': [42], 'study': [44, 56, 83, 93], 'presents': [45], 'application': [47, 112], 'challenges,': [48], 'contributions,': [49, 86], 'compare': [50, 87], 'performances': [51, 88], 'critiques': [53, 90], 'methods.': [54, 91], 'The': [55, 82, 92], 'covers': [57], 'many': [58], 'techniques': [62], 'various': [64], 'disciplines': [65], 'which': [66], 'include': [67], 'computing,': [68], 'science,': [69], 'engineering,': [70], 'medicine,': [71], 'environmental,': [72], 'agriculture,': [73], 'mining,': [74], 'technology,': [75], 'climate,': [76], 'business,': [77], 'arts,': [78], 'nanotechnology,': [80], 'etc.': [81], 'assesses': [84], 'found': [94], 'that': [95, 148], 'neural-network': [96], 'models': [97, 124, 162], 'such': [98], 'as': [99], 'feedforward': [100, 119], 'feedback': [102, 121], 'propagation': [103, 122], 'are': [107], 'performing': [108], 'better': [109], 'its': [111], 'to': [113], 'human': [114], 'problems.': [115], 'Therefore,': [116], 'we': [117, 146], 'proposed': [118], 'based': [128], 'on': [129, 159], 'data': [130], 'analysis': [131], 'factors': [132], 'like': [133], 'accuracy,': [134], 'processing': [135], 'speed,': [136], 'latency,': [137], 'fault': [138], 'tolerance,': [139], 'volume,': [140], 'scalability,': [141], 'convergence,': [142], 'performance.': [144], 'Moreover,': [145], 'recommend': [147], 'instead': [149], 'applying': [151], 'single': [153], 'method,': [154], 'future': [155], 'can': [157], 'combining': [160], 'into': [163], 'one': [164], 'network-wide': [165], 'application.': [166]}",2018,"['Artificial neural network', 'State (computer science)', 'Artificial intelligence', 'Computer science', 'Data science', 'Engineering', 'Algorithm']","This is a survey of neural network applications in the real-world scenario. It provides a taxonomy of artificial neural networks (ANNs) and furnish the reader with knowledge of current and emerging trends in ANN applications research and area of focus for researchers. Additionally, the study presents ANN application challenges, contributions, compare performances and critiques methods. The study covers many applications of ANN techniques in various disciplines which include computing, science, engineering, medicine, environmental, agriculture, mining, technology, climate, business, arts, and nanotechnology, etc. The study assesses ANN contributions, compare performances and critiques methods. The study found that neural-network models such as feedforward and feedback propagation artificial neural networks are performing better in its application to human problems. Therefore, we proposed feedforward and feedback propagation ANN models for research focus based on data analysis factors like accuracy, processing speed, latency, fault tolerance, volume, scalability, convergence, and performance. Moreover, we recommend that instead of applying a single method, future research can focus on combining ANN models into one network-wide application."
https://openalex.org/W2950993016,Performance of neural network basecalling tools for Oxford Nanopore sequencing,"{'Basecalling': [0], 'accuracy': [1, 23, 29], 'has': [2], 'seen': [3], 'significant': [4], 'improvements': [5], 'over': [6], 'the': [7, 48], 'last': [8], '2': [9], 'years.': [10], 'The': [11], 'current': [12], 'version': [13], 'of': [14], ""ONT's"": [15], 'Guppy': [16], 'basecaller': [17], 'performs': [18], 'well': [19], 'overall,': [20], 'with': [21], 'good': [22], 'and': [24], 'fast': [25], 'performance.': [26], 'If': [27], 'higher': [28], 'is': [30], 'required,': [31], 'users': [32], 'should': [33], 'consider': [34], 'producing': [35], 'a': [36, 40], 'custom': [37], 'model': [38], 'using': [39], 'larger': [41], 'neural': [42], 'network': [43], 'and/or': [44], 'training': [45], 'data': [46], 'from': [47], 'same': [49], 'species.': [50]}",2019,"['Biology', 'Nanopore sequencing', 'Genome Biology', 'Human genetics', 'Computational biology', 'Artificial neural network', 'DNA sequencing', 'Nanopore', 'Evolutionary biology', 'Genomics', 'Artificial intelligence', 'Genetics', 'Computer science', 'Genome', 'Nanotechnology', 'Gene', 'Materials science']","Basecalling accuracy has seen significant improvements over the last 2 years. The current version of ONT's Guppy basecaller performs well overall, with good accuracy and fast performance. If higher accuracy is required, users should consider producing a custom model using a larger neural network and/or training data from the same species."
https://openalex.org/W2741907166,Deep learning with convolutional neural networks for EEG decoding and visualization,"{'Abstract': [0], 'Deep': [1], 'learning': [2, 18, 94], 'with': [3, 69, 104, 241], 'convolutional': [4], 'neural': [5], 'networks': [6], '(deep': [7], 'ConvNets)': [8], 'has': [9], 'revolutionized': [10], 'computer': [11], 'vision': [12], 'through': [13], 'end‐to‐end': [14, 32, 47], 'learning,': [15], 'that': [16, 88, 168], 'is,': [17], 'from': [19, 82, 91, 226], 'the': [20, 54, 58, 92, 110, 122, 149, 164, 178, 191, 196, 199, 209, 227, 235], 'raw': [21, 83, 228], 'data.': [22], 'There': [23], 'is': [24, 61, 142], 'increasing': [25], 'interest': [26], 'in': [27, 177, 204], 'using': [28], 'deep': [29, 67, 111, 138, 238], 'ConvNets': [30, 45, 59, 68, 112, 153, 169, 221, 239], 'for': [31, 46, 76, 162, 188, 245], 'EEG': [33, 48, 56, 229], 'analysis,': [34], 'but': [35], 'a': [36, 70, 105, 157], 'better': [37], 'understanding': [38], 'of': [39, 72, 198, 202, 237], 'how': [40, 51, 216], 'to': [41, 52, 144, 172, 208, 217, 222], 'design': [42, 218], 'and': [43, 50, 99, 181, 185, 219, 233], 'train': [44, 220], 'decoding': [49, 77, 113, 133, 210], 'visualize': [53], 'informative': [55], 'features': [57, 150, 166, 193, 203, 232], 'learn': [60], 'still': [62], 'needed.': [63], 'Here,': [64], 'we': [65], 'studied': [66], 'range': [71], 'different': [73, 205], 'architectures,': [74], 'designed': [75, 143], 'imagined': [78], 'or': [79], 'executed': [80], 'tasks': [81], 'EEG.': [84], 'Our': [85, 159, 212], 'results': [86], 'show': [87], 'recent': [89], 'advances': [90], 'machine': [93], 'field,': [95], 'including': [96], 'batch': [97], 'normalization': [98], 'exponential': [100], 'linear': [101], 'units,': [102], 'together': [103], 'cropped': [106], 'training': [107], 'strategy,': [108], 'boosted': [109], 'performance,': [114], 'reaching': [115], 'at': [116], 'least': [117], 'as': [118, 121], 'good': [119], 'performance': [120], 'widely': [123], 'used': [124, 151], 'filter': [125], 'bank': [126], 'common': [127], 'spatial': [128], 'patterns': [129], '(FBCSP)': [130], 'algorithm': [131], '(mean': [132], 'accuracies': [134], '82.1%': [135], 'FBCSP,': [136], '84.0%': [137], 'ConvNets).': [139], 'While': [140], 'FBCSP': [141], 'use': [145, 173], 'spectral': [146, 174], 'power': [147, 175], 'modulations,': [148], 'by': [152, 194], 'are': [154], 'not': [155], 'fixed': [156], 'priori.': [158], 'novel': [160], 'methods': [161], 'visualizing': [163], 'learned': [165, 171, 192], 'demonstrated': [167], 'indeed': [170], 'modulations': [176], 'alpha,': [179], 'beta,': [180], 'high': [182], 'gamma': [183], 'frequencies,': [184], 'proved': [186], 'useful': [187], 'spatially': [189], 'mapping': [190], 'revealing': [195], 'topography': [197], 'causal': [200], 'contributions': [201], 'frequency': [206], 'bands': [207], 'decision.': [211], 'study': [213], 'thus': [214], 'shows': [215], 'decode': [223], 'task‐related': [224], 'information': [225], 'without': [230], 'handcrafted': [231], 'highlights': [234], 'potential': [236], 'combined': [240], 'advanced': [242], 'visualization': [243], 'techniques': [244], 'EEG‐based': [246], 'brain': [247], 'mapping.': [248], 'Hum': [249], 'Brain': [250], 'Mapp': [251], '38:5391–5420,': [252], '2017': [253, 256], '.': [254], '©': [255], 'Wiley': [257], 'Periodicals,': [258], 'Inc.': [259]}",2017,"['Artificial intelligence', 'Deep learning', 'Computer science', 'Decoding methods', 'Convolutional neural network', 'Pattern recognition (psychology)', 'Visualization', 'Electroencephalography', 'Normalization (sociology)', 'Machine learning', 'Algorithm', 'Anthropology', 'Psychology', 'Psychiatry', 'Sociology']","Abstract Deep learning with convolutional neural networks (deep ConvNets) has revolutionized computer vision through end‐to‐end learning, that is, learning from the raw data. There is increasing interest in using deep ConvNets for end‐to‐end EEG analysis, but a better understanding of how to design and train ConvNets for end‐to‐end EEG decoding and how to visualize the informative EEG features the ConvNets learn is still needed. Here, we studied deep ConvNets with a range of different architectures, designed for decoding imagined or executed tasks from raw EEG. Our results show that recent advances from the machine learning field, including batch normalization and exponential linear units, together with a cropped training strategy, boosted the deep ConvNets decoding performance, reaching at least as good performance as the widely used filter bank common spatial patterns (FBCSP) algorithm (mean decoding accuracies 82.1% FBCSP, 84.0% deep ConvNets). While FBCSP is designed to use spectral power modulations, the features used by ConvNets are not fixed a priori. Our novel methods for visualizing the learned features demonstrated that ConvNets indeed learned to use spectral power modulations in the alpha, beta, and high gamma frequencies, and proved useful for spatially mapping the learned features by revealing the topography of the causal contributions of features in different frequency bands to the decoding decision. Our study thus shows how to design and train ConvNets to decode task‐related information from the raw EEG without handcrafted features and highlights the potential of deep ConvNets combined with advanced visualization techniques for EEG‐based brain mapping. Hum Brain Mapp 38:5391–5420, 2017 . © 2017 Wiley Periodicals, Inc."
https://openalex.org/W2124592697,Conditional Random Fields as Recurrent Neural Networks,"{'Pixel-level': [0], 'labelling': [1, 32], 'tasks,': [2], 'such': [3], 'as': [4, 99, 111], 'semantic': [5, 171], 'segmentation,': [6, 173], 'play': [7], 'a': [8, 58, 112, 115, 119], 'central': [9, 35], 'role': [10], 'in': [11, 37, 110], 'image': [12, 27, 172], 'understanding.': [13], 'Recent': [14], 'approaches': [15], 'have': [16], 'attempted': [17], 'to': [18, 29, 48, 117, 143, 167], 'harness': [19], 'the': [20, 41, 67, 91, 145, 151, 164, 168, 178], 'capabilities': [21], 'of': [22, 44, 61, 69, 114, 126, 170], 'deep': [23, 45, 120, 147], 'learning': [24, 46], 'techniques': [25, 47], 'for': [26, 90, 159], 'recognition': [28], 'tackle': [30], 'pixel-level': [31], 'tasks.': [33], 'One': [34], 'issue': [36], 'this': [38, 54, 83], 'methodology': [39], 'is': [40, 107], 'limited': [42], 'capacity': [43], 'delineate': [49], 'visual': [50], 'objects.': [51], 'To': [52, 82], 'solve': [53], 'problem,': [55], 'we': [56, 85], 'introduce': [57], 'new': [59], 'form': [60], 'convolutional': [62], 'neural': [63], 'network': [64, 121, 148], 'that': [65, 122], 'combines': [66], 'strengths': [68], 'Convolutional': [70], 'Neural': [71, 101], 'Networks': [72], '(CNNs)': [73], 'and': [74, 129], 'Conditional': [75, 92], 'Random': [76, 93], 'Fields': [77, 94], '(CRFs)-based': [78], 'probabilistic': [79], 'graphical': [80], 'modelling.': [81], 'end,': [84], 'formulate': [86], 'mean-field': [87], 'approximate': [88], 'inference': [89], 'with': [95, 138, 150], 'Gaussian': [96], 'pairwise': [97], 'potentials': [98], 'Recurrent': [100], 'Networks.': [102], 'This': [103], 'network,': [104], 'called': [105], 'CRF-RNN,': [106], 'then': [108], 'plugged': [109], 'part': [113], 'CNN': [116], 'obtain': [118], 'has': [123], 'desirable': [124], 'properties': [125], 'both': [127], 'CNNs': [128], 'CRFs.': [130], 'Importantly,': [131], 'our': [132], 'system': [133], 'fully': [134], 'integrates': [135], 'CRF': [136], 'modelling': [137], 'CNNs,': [139], 'making': [140], 'it': [141], 'possible': [142], 'train': [144], 'whole': [146], 'end-to-end': [149], 'usual': [152], 'back-propagation': [153], 'algorithm,': [154], 'avoiding': [155], 'offline': [156], 'post-processing': [157], 'methods': [158], 'object': [160], 'delineation.': [161], 'We': [162], 'apply': [163], 'proposed': [165], 'method': [166], 'problem': [169], 'obtaining': [174], 'top': [175], 'results': [176], 'on': [177], 'challenging': [179], 'Pascal': [180], 'VOC': [181], '2012': [182], 'segmentation': [183], 'benchmark.': [184]}",2015,"['Conditional random field', 'Computer science', 'Artificial neural network', 'Recurrent neural network', 'Artificial intelligence']","Pixel-level labelling tasks, such as semantic segmentation, play a central role in image understanding. Recent approaches have attempted to harness the capabilities of deep learning techniques for image recognition to tackle pixel-level labelling tasks. One central issue in this methodology is the limited capacity of deep learning techniques to delineate visual objects. To solve this problem, we introduce a new form of convolutional neural network that combines the strengths of Convolutional Neural Networks (CNNs) and Conditional Random Fields (CRFs)-based probabilistic graphical modelling. To this end, we formulate mean-field approximate inference for the Conditional Random Fields with Gaussian pairwise potentials as Recurrent Neural Networks. This network, called CRF-RNN, is then plugged in as a part of a CNN to obtain a deep network that has desirable properties of both CNNs and CRFs. Importantly, our system fully integrates CRF modelling with CNNs, making it possible to train the whole deep network end-to-end with the usual back-propagation algorithm, avoiding offline post-processing methods for object delineation. We apply the proposed method to the problem of semantic image segmentation, obtaining top results on the challenging Pascal VOC 2012 segmentation benchmark."
https://openalex.org/W2559463885,EEGNet: a compact convolutional neural network for EEG-based brain–computer interfaces,"{'Our': [0, 22], 'results': [1], 'suggest': [2], 'that': [3], 'EEGNet': [4], 'is': [5], 'robust': [6], 'enough': [7], 'to': [8], 'learn': [9], 'a': [10, 17], 'wide': [11], 'variety': [12], 'of': [13, 19], 'interpretable': [14], 'features': [15], 'over': [16], 'range': [18], 'BCI': [20], 'tasks.': [21], 'models': [23], 'can': [24], 'be': [25], 'found': [26], 'at:': [27], 'https://github.com/vlawhern/arl-eegmodels.': [28]}",2018,[],Our results suggest that EEGNet is robust enough to learn a wide variety of interpretable features over a range of BCI tasks. Our models can be found at: https://github.com/vlawhern/arl-eegmodels.
https://openalex.org/W2265846598,Recurrent Convolutional Neural Networks for Text Classification,"{'Text': [0], 'classification': [1, 42, 94], 'is': [2], 'a': [3, 35, 51, 81], 'foundational': [4], 'task': [5], 'in': [6, 92, 100], 'many': [7, 16], 'NLP': [8], 'applications.': [9], 'Traditional': [10], 'text': [11, 41, 93], 'classifiers': [12], 'often': [13], 'rely': [14], 'on': [15, 105, 122, 126], 'human-designed': [17, 44], 'features,': [18], 'such': [19], 'as': [20, 58, 60], 'dictionaries,': [21], 'knowledge': [22], 'bases': [23], 'and': [24], 'special': [25], 'tree': [26], 'kernels.': [27], 'In': [28, 46], 'contrast': [29], 'to': [30, 54, 73, 95], 'traditional': [31, 74], 'methods,': [32], 'we': [33, 49], 'introduce': [34, 68], 'recurrent': [36, 52], 'convolutional': [37], 'neural': [38, 76], 'network': [39], 'for': [40], 'without': [43], 'features.': [45], 'our': [47], 'model,': [48], 'apply': [50], 'structure': [53], 'capture': [55, 96], 'contextual': [56], 'information': [57], 'far': [59], 'possible': [61], 'when': [62], 'learning': [63], 'word': [64], 'representations,': [65], 'which': [66, 87], 'may': [67], 'considerably': [69], 'less': [70], 'noise': [71], 'compared': [72], 'window-based': [75], 'networks.': [77], 'We': [78, 102], 'also': [79], 'employ': [80], 'max-pooling': [82], 'layer': [83], 'that': [84, 114], 'automatically': [85], 'judges': [86], 'words': [88], 'play': [89], 'key': [90, 98], 'roles': [91], 'the': [97, 115, 119], 'components': [99], 'texts.': [101], 'conduct': [103], 'experiments': [104], 'four': [106], 'commonly': [107], 'used': [108], 'datasets.': [109, 128], 'The': [110], 'experimental': [111], 'results': [112], 'show': [113], 'proposed': [116], 'method': [117], 'outperforms': [118], 'state-of-the-art': [120], 'methods': [121], 'several': [123], 'datasets,': [124], 'particularly': [125], 'document-level': [127]}",2015,"['Computer science', 'Artificial intelligence', 'Pooling', 'Convolutional neural network', 'Key (lock)', 'Task (project management)', 'Natural language processing', 'Word (group theory)', 'Recurrent neural network', 'Contrast (vision)', 'Machine learning', 'Tree (set theory)', 'Artificial neural network', 'Pattern recognition (psychology)', 'Mathematics', 'Management', 'Linguistics', 'Philosophy', 'Mathematical analysis', 'Economics', 'Computer security']","Text classification is a foundational task in many NLP applications. Traditional text classifiers often rely on many human-designed features, such as dictionaries, knowledge bases and special tree kernels. In contrast to traditional methods, we introduce a recurrent convolutional neural network for text classification without human-designed features. In our model, we apply a recurrent structure to capture contextual information as far as possible when learning word representations, which may introduce considerably less noise compared to traditional window-based neural networks. We also employ a max-pooling layer that automatically judges which words play key roles in text classification to capture the key components in texts. We conduct experiments on four commonly used datasets. The experimental results show that the proposed method outperforms the state-of-the-art methods on several datasets, particularly on document-level datasets."
https://openalex.org/W2119144962,"Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding","{'Neural': [0], 'networks': [1, 49, 193], 'are': [2, 203], 'both': [3], 'computationally': [4], 'intensive': [5], 'and': [6, 36, 99, 200, 209, 220], 'memory': [7], 'intensive,': [8], 'making': [9], 'them': [10], 'difficult': [11], 'to': [12, 42, 52, 75, 93, 111, 126, 144, 161, 216, 222], 'deploy': [13], 'on': [14, 206], 'embedded': [15], 'systems': [16], 'with': [17, 164], 'limited': [18], 'hardware': [19], 'resources.': [20], 'To': [21], 'address': [22], 'this': [23], 'limitation,': [24], 'we': [25, 71, 80, 89], 'introduce': [26], '""deep': [27], 'compression"",': [28], 'a': [29], 'three': [30], 'stage': [31], 'pipeline:': [32], 'pruning,': [33], 'trained': [34], 'quantization': [35], 'Huffman': [37, 82], 'coding,': [38], 'that': [39, 120], 'work': [40], 'together': [41], 'reduce': [43], 'the': [44, 62, 67, 73, 85, 91, 96, 100, 105, 116, 129, 135, 153, 172, 188], 'storage': [45, 136], 'requirement': [46], 'of': [47, 107, 118, 148, 155, 167, 190], 'neural': [48, 192], 'by': [50, 64, 109, 138, 140, 157], '35x': [51], '49x': [53, 158], 'without': [54, 146], 'affecting': [55], 'their': [56], 'accuracy.': [57, 149, 168], 'Our': [58, 150, 183], 'method': [59, 133, 151, 185], 'first': [60, 86], 'prunes': [61], 'network': [63, 92, 213], 'learning': [65], 'only': [66], 'important': [68], 'connections.': [69], 'Next,': [70], 'quantize': [72], 'weights': [74], 'enforce': [76], 'weight': [77], 'sharing,': [78], 'finally,': [79], 'apply': [81], 'coding.': [83], 'After': [84], 'two': [87], 'steps': [88], 'retrain': [90], 'fine': [94], 'tune': [95], 'remaining': [97], 'connections': [98, 108], 'quantized': [101], 'centroids.': [102], 'Pruning,': [103], 'reduces': [104, 115], 'number': [106, 117], '9x': [110], '13x;': [112], 'Quantization': [113], 'then': [114], 'bits': [119], 'represent': [121], 'each': [122], 'connection': [123], 'from': [124, 142, 159], '32': [125], '5.': [127], 'On': [128], 'ImageNet': [130], 'dataset,': [131], 'our': [132], 'reduced': [134, 152], 'required': [137], 'AlexNet': [139], '35x,': [141], '240MB': [143], '6.9MB,': [145], 'loss': [147, 166], 'size': [154, 199], 'VGG-16': [156], '552MB': [160], '11.3MB,': [162], 'again': [163], 'no': [165], 'This': [169], 'allows': [170], 'fitting': [171], 'model': [173], 'into': [174], 'on-chip': [175], 'SRAM': [176], 'cache': [177], 'rather': [178], 'than': [179], 'off-chip': [180], 'DRAM': [181], 'memory.': [182], 'compression': [184], 'also': [186], 'facilitates': [187], 'use': [189], 'complex': [191], 'in': [194], 'mobile': [195, 210], 'applications': [196], 'where': [197], 'application': [198], 'download': [201], 'bandwidth': [202], 'constrained.': [204], 'Benchmarked': [205], 'CPU,': [207], 'GPU': [208], 'GPU,': [211], 'compressed': [212], 'has': [214], '3x': [215, 221], '4x': [217], 'layerwise': [218], 'speedup': [219], '7x': [223], 'better': [224], 'energy': [225], 'efficiency.': [226]}",2015,"['Huffman coding', 'Computer science', 'Quantization (signal processing)', 'Artificial neural network', 'Speedup', 'Parallel computing', 'Coding (social sciences)', 'Cache', 'SIMD', 'CPU cache', 'Computer engineering', 'Artificial intelligence', 'Data compression', 'Algorithm', 'Mathematics', 'Statistics']","Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems with limited hardware resources. To address this limitation, we introduce ""deep compression"", a three stage pipeline: pruning, trained quantization and Huffman coding, that work together to reduce the storage requirement of neural networks by 35x to 49x without affecting their accuracy. Our method first prunes the network by learning only the important connections. Next, we quantize the weights to enforce weight sharing, finally, we apply Huffman coding. After the first two steps we retrain the network to fine tune the remaining connections and the quantized centroids. Pruning, reduces the number of connections by 9x to 13x; Quantization then reduces the number of bits that represent each connection from 32 to 5. On the ImageNet dataset, our method reduced the storage required by AlexNet by 35x, from 240MB to 6.9MB, without loss of accuracy. Our method reduced the size of VGG-16 by 49x from 552MB to 11.3MB, again with no loss of accuracy. This allows fitting the model into on-chip SRAM cache rather than off-chip DRAM memory. Our compression method also facilitates the use of complex neural networks in mobile applications where application size and download bandwidth are constrained. Benchmarked on CPU, GPU and mobile GPU, compressed network has 3x to 4x layerwise speedup and 3x to 7x better energy efficiency."
https://openalex.org/W2624871570,An Overview of Multi-Task Learning in Deep Neural Networks,"{'Multi-task': [0], 'learning': [1], '(MTL)': [2], 'has': [3], 'led': [4], 'to': [5, 20, 29, 67], 'successes': [6], 'in': [7, 37, 50], 'many': [8], 'applications': [9], 'of': [10, 34, 56], 'machine': [11], 'learning,': [12], 'from': [13], 'natural': [14], 'language': [15], 'processing': [16], 'and': [17, 23, 59, 80], 'speech': [18], 'recognition': [19], 'computer': [21], 'vision': [22], 'drug': [24], 'discovery.': [25], 'This': [26], 'article': [27], 'aims': [28], 'give': [30], 'a': [31], 'general': [32], 'overview': [33, 55], 'MTL,': [35], 'particularly': [36], 'deep': [38], 'neural': [39], 'networks.': [40], 'It': [41], 'introduces': [42], 'the': [43, 57], 'two': [44], 'most': [45], 'common': [46], 'methods': [47], 'for': [48, 83], 'MTL': [49, 72, 78], 'Deep': [51], 'Learning,': [52], 'gives': [53], 'an': [54], 'literature,': [58], 'discusses': [60], 'recent': [61], 'advances.': [62], 'In': [63], 'particular,': [64], 'it': [65], 'seeks': [66], 'help': [68], 'ML': [69], 'practitioners': [70], 'apply': [71], 'by': [73], 'shedding': [74], 'light': [75], 'on': [76], 'how': [77], 'works': [79], 'providing': [81], 'guidelines': [82], 'choosing': [84], 'appropriate': [85], 'auxiliary': [86], 'tasks.': [87]}",2017,"['Computer science', 'Deep learning', 'Task (project management)', 'Artificial intelligence', 'Deep neural networks', 'Artificial neural network', 'Machine learning', 'Cognitive science', 'Psychology', 'Engineering', 'Systems engineering']","Multi-task learning (MTL) has led to successes in many applications of machine learning, from natural language processing and speech recognition to computer vision and drug discovery. This article aims to give a general overview of MTL, particularly in deep neural networks. It introduces the two most common methods for MTL in Deep Learning, gives an overview of the literature, and discusses recent advances. In particular, it seeks to help ML practitioners apply MTL by shedding light on how MTL works and providing guidelines for choosing appropriate auxiliary tasks."
https://openalex.org/W2574952845,Deep Convolutional Neural Network for Inverse Problems in Imaging,"{'In': [0], 'this': [1, 73, 118], 'paper,': [2], 'we': [3, 120], 'propose': [4, 121], 'a': [5, 86, 114, 127, 222, 226], 'novel': [6], 'deep': [7], 'convolutional': [8], 'neural': [9], 'network': [10, 181, 207], '(CNN)-based': [11], 'algorithm': [12], 'for': [13, 213], 'solving': [14], 'ill-posed': [15, 28], 'inverse': [16, 29, 132], 'problems.': [17, 133], 'Regularized': [18], 'iterative': [19, 80, 211], 'algorithms': [20], 'have': [21, 82], 'emerged': [22], 'as': [23, 198, 200], 'the': [24, 32, 53, 58, 64, 76, 83, 94, 101, 104, 110, 138, 142, 149, 154, 176, 179, 214, 232], 'standard': [25], 'approach': [26], 'to': [27, 45, 50, 129, 146, 164, 166, 186, 224], 'problems': [30], 'in': [31, 47, 162, 182, 195, 201], 'past': [33], 'few': [34], 'decades.': [35], 'These': [36], 'methods': [37, 81], 'produce': [38], 'excellent': [39], 'results,': [40], 'but': [41, 144], 'can': [42], 'be': [43], 'challenging': [44], 'deploy': [46], 'practice': [48], 'due': [49], 'factors': [51], 'including': [52], 'high': [54], 'computational': [55], 'cost': [56], 'of': [57, 66, 72, 85, 103, 109, 141, 178], 'forward': [59, 105, 111], 'and': [60, 63, 159, 218], 'adjoint': [61, 102], 'operators': [62], 'difficulty': [65], 'hyperparameter': [67], 'selection.': [68], 'The': [69, 134, 205], 'starting': [70], 'point': [71], 'paper': [74], 'is': [75, 100, 113, 151], 'observation': [77], 'that': [78], 'unrolled': [79], 'form': [84], 'CNN': [87, 128, 155], '(filtering': [88], 'followed': [89, 125], 'by': [90, 126], 'pointwise': [91], 'nonlinearity)': [92], 'when': [93, 148], 'normal': [95], 'operator': [96], '(H*H,': [97], 'where': [98], 'H*': [99], 'imaging': [106], 'operator,': [107], 'H)': [108], 'model': [112, 140], 'convolution.': [115], 'Based': [116], 'on': [117, 189, 231], 'observation,': [119], 'using': [122], 'direct': [123, 135], 'inversion': [124, 136], 'solve': [130], 'normal-convolutional': [131], 'encapsulates': [137], 'physical': [139], 'system,': [143], 'leads': [145], 'artifacts': [147, 169], 'problem': [150], 'ill': [152], 'posed;': [153], 'combines': [156], 'multiresolution': [157], 'decomposition': [158], 'residual': [160], 'learning': [161], 'order': [163], 'learn': [165], 'remove': [167], 'these': [168], 'while': [170], 'preserving': [171], 'image': [172, 230], 'structure.': [173], 'We': [174], 'demonstrate': [175], 'performance': [177], 'proposed': [180, 206], 'sparse-view': [183], 'reconstruction': [184, 212], '(down': [185], '50': [187], 'views)': [188], 'parallel': [190], 'beam': [191], 'X-ray': [192], 'computed': [193], 'tomography': [194], 'synthetic': [196], 'phantoms': [197, 217], 'well': [199], 'real': [202], 'experimental': [203], 'sinograms.': [204], 'outperforms': [208], 'total': [209], 'variation-regularized': [210], 'more': [215], 'realistic': [216], 'requires': [219], 'less': [220], 'than': [221], 'second': [223], 'reconstruct': [225], '512': [227, 229], '×': [228], 'GPU.': [233]}",2017,"['Convolutional neural network', 'Computer science', 'Artificial intelligence', 'Inverse problem', 'Pattern recognition (psychology)', 'Artificial neural network', 'Medical imaging', 'Image processing', 'Image (mathematics)', 'Mathematics', 'Mathematical analysis']","In this paper, we propose a novel deep convolutional neural network (CNN)-based algorithm for solving ill-posed inverse problems. Regularized iterative algorithms have emerged as the standard approach to ill-posed inverse problems in the past few decades. These methods produce excellent results, but can be challenging to deploy in practice due to factors including the high computational cost of the forward and adjoint operators and the difficulty of hyperparameter selection. The starting point of this paper is the observation that unrolled iterative methods have the form of a CNN (filtering followed by pointwise nonlinearity) when the normal operator (H*H, where H* is the adjoint of the forward imaging operator, H) of the forward model is a convolution. Based on this observation, we propose using direct inversion followed by a CNN to solve normal-convolutional inverse problems. The direct inversion encapsulates the physical model of the system, but leads to artifacts when the problem is ill posed; the CNN combines multiresolution decomposition and residual learning in order to learn to remove these artifacts while preserving image structure. We demonstrate the performance of the proposed network in sparse-view reconstruction (down to 50 views) on parallel beam X-ray computed tomography in synthetic phantoms as well as in real experimental sinograms. The proposed network outperforms total variation-regularized iterative reconstruction for the more realistic phantoms and requires less than a second to reconstruct a 512 × 512 image on the GPU."
https://openalex.org/W2626967530,On Calibration of Modern Neural Networks,"{'Confidence': [0], 'calibration': [1, 64], '--': [2, 15, 103, 110], 'the': [3, 11, 59], 'problem': [4], 'of': [5, 10, 61, 107], 'predicting': [6], 'probability': [7], 'estimates': [8], 'representative': [9], 'true': [12], 'correctness': [13], 'likelihood': [14], 'is': [16, 111], 'important': [17, 53], 'for': [18, 95], 'classification': [19, 73], 'models': [20], 'in': [21], 'many': [22], 'applications.': [23], 'We': [24, 57], 'discover': [25], 'that': [26, 44], 'modern': [27], 'neural': [28, 84], 'networks,': [29], 'unlike': [30], 'those': [31], 'from': [32], 'a': [33, 90, 104], 'decade': [34], 'ago,': [35], 'are': [36, 52], 'poorly': [37], 'calibrated.': [38], 'Through': [39], 'extensive': [40], 'experiments,': [41], 'we': [42], 'observe': [43], 'depth,': [45], 'width,': [46], 'weight': [47], 'decay,': [48], 'and': [49, 71, 77, 92], 'Batch': [50], 'Normalization': [51], 'factors': [54], 'influencing': [55], 'calibration.': [56], 'evaluate': [58], 'performance': [60], 'various': [62], 'post-processing': [63], 'methods': [65], 'on': [66, 98], 'state-of-the-art': [67], 'architectures': [68], 'with': [69], 'image': [70], 'document': [72], 'datasets.': [74], 'Our': [75], 'analysis': [76], 'experiments': [78], 'not': [79], 'only': [80], 'offer': [81], 'insights': [82], 'into': [83], 'network': [85], 'learning,': [86], 'but': [87], 'also': [88], 'provide': [89], 'simple': [91], 'straightforward': [93], 'recipe': [94], 'practical': [96], 'settings:': [97], 'most': [99], 'datasets,': [100], 'temperature': [101], 'scaling': [102], 'single-parameter': [105], 'variant': [106], 'Platt': [108], 'Scaling': [109], 'surprisingly': [112], 'effective': [113], 'at': [114], 'calibrating': [115], 'predictions.': [116]}",2017,"['Normalization (sociology)', 'Artificial neural network', 'Correctness', 'Scaling', 'Computer science', 'Calibration', 'Deep neural networks', 'Artificial intelligence', 'Machine learning', 'Simple (philosophy)', 'Pattern recognition (psychology)', 'Data mining', 'Algorithm', 'Mathematics', 'Statistics', 'Epistemology', 'Philosophy', 'Anthropology', 'Geometry', 'Sociology']","Confidence calibration -- the problem of predicting probability estimates representative of the true correctness likelihood -- is important for classification models in many applications. We discover that modern neural networks, unlike those from a decade ago, are poorly calibrated. Through extensive experiments, we observe that depth, width, weight decay, and Batch Normalization are important factors influencing calibration. We evaluate the performance of various post-processing calibration methods on state-of-the-art architectures with image and document classification datasets. Our analysis and experiments not only offer insights into neural network learning, but also provide a simple and straightforward recipe for practical settings: on most datasets, temperature scaling -- a single-parameter variant of Platt Scaling -- is surprisingly effective at calibrating predictions."
https://openalex.org/W2807021761,Graph Convolutional Neural Networks for Web-Scale Recommender Systems,"{'Recent': [0], 'advancements': [1], 'in': [2], 'deep': [3, 43, 174, 187], 'neural': [4], 'networks': [5], 'for': [6], 'graph-structured': [7], 'data': [8], 'have\\nled': [9], 'to': [10, 23, 68, 86, 114, 162, 190], 'state-of-the-art': [11], 'performance': [12], 'on': [13, 95, 143, 147, 204], 'recommender': [14, 201], 'system': [15], 'benchmarks.': [16], 'However,\\nmaking': [17], 'these': [18], 'methods': [19], 'practical': [20], 'and': [21, 30, 66, 103, 117, 155, 157, 166, 176, 192], 'scalable': [22], 'web-scale': [24, 200], 'recommendation': [25, 44], 'tasks\\nwith': [26], 'billions': [27], 'of': [28, 32, 34, 71, 186, 199], 'items': [29], 'hundreds': [31], 'millions': [33], 'users': [35], 'remains': [36], 'a': [37, 41, 54, 91, 105, 133, 148, 196], 'challenge.\\nHere': [38], 'we': [39, 47, 89], 'describe': [40], 'large-scale': [42], 'engine': [45], 'that': [46, 75, 109], 'developed': [48], 'and\\ndeployed': [49], 'at': [50, 139], 'Pinterest.': [51], 'We': [52, 121, 136], 'develop': [53, 90, 123], 'data-efficient': [55], 'Graph': [56], 'Convolutional': [57], 'Network\\n(GCN)': [58], 'algorithm': [59, 129], 'PinSage,': [60], 'which': [61], 'combines': [62], 'efficient': [63, 97, 125], 'random': [64, 98], 'walks': [65, 99], 'graph\\nconvolutions': [67], 'generate': [69], 'embeddings': [70, 131, 189], 'nodes': [72, 153], '(i.e.,': [73], 'items)': [74], 'incorporate\\nboth': [76], 'graph': [77, 149, 188], 'structure': [78], 'as': [79, 81], 'well': [80], 'node': [82], 'feature': [83], 'information.': [84], 'Compared': [85], 'prior': [87], 'GCN\\napproaches,': [88], 'novel': [92, 106], 'method': [93], 'based': [94, 203], 'highly': [96], 'to\\nstructure': [100], 'the': [101, 183, 194], 'convolutions': [102], 'design': [104], 'training': [107, 112], 'strategy': [108], 'relies': [110], 'on\\nharder-and-harder': [111], 'examples': [113, 146], 'improve': [115], 'robustness': [116], 'convergence': [118], 'of\\nthe': [119], 'model.': [120, 135], 'also': [122], 'an': [124], 'MapReduce': [126], 'model': [127], 'inference': [128], 'to\\ngenerate': [130], 'using': [132], 'trained': [134], 'deploy': [137], 'PinSage': [138, 169], 'Pinterest': [140], 'and\\ntrain': [141], 'it': [142], '7.5': [144], 'billion': [145, 152, 159], 'with': [150], '3': [151], 'representing\\npins': [154], 'boards,': [156], '18': [158], 'edges.': [160], 'According': [161], 'offline': [163], 'metrics,': [164], 'user\\nstudies': [165], 'A/B': [167], 'tests,': [168], 'generates': [170], 'higher-quality': [171], 'recommendations': [172], 'than\\ncomparable': [173], 'learning': [175], 'graph-based': [177], 'alternatives.': [178], 'To': [179], 'our': [180], 'knowledge,': [181], 'this\\nis': [182], 'largest': [184], 'application': [185], 'date': [191], 'paves': [193], 'way\\nfor': [195], 'new': [197], 'generation': [198], 'systems': [202], 'graph\\nconvolutional': [205], 'architectures.\\n': [206]}",2018,[],"Recent advancements in deep neural networks for graph-structured data have\nled to state-of-the-art performance on recommender system benchmarks. However,\nmaking these methods practical and scalable to web-scale recommendation tasks\nwith billions of items and hundreds of millions of users remains a challenge.\nHere we describe a large-scale deep recommendation engine that we developed and\ndeployed at Pinterest. We develop a data-efficient Graph Convolutional Network\n(GCN) algorithm PinSage, which combines efficient random walks and graph\nconvolutions to generate embeddings of nodes (i.e., items) that incorporate\nboth graph structure as well as node feature information. Compared to prior GCN\napproaches, we develop a novel method based on highly efficient random walks to\nstructure the convolutions and design a novel training strategy that relies on\nharder-and-harder training examples to improve robustness and convergence of\nthe model. We also develop an efficient MapReduce model inference algorithm to\ngenerate embeddings using a trained model. We deploy PinSage at Pinterest and\ntrain it on 7.5 billion examples on a graph with 3 billion nodes representing\npins and boards, and 18 billion edges. According to offline metrics, user\nstudies and A/B tests, PinSage generates higher-quality recommendations than\ncomparable deep learning and graph-based alternatives. To our knowledge, this\nis the largest application of deep graph embeddings to date and paves the way\nfor a new generation of web-scale recommender systems based on graph\nconvolutional architectures.\n"
https://openalex.org/W2892880750,Hypergraph Neural Networks,"{'In': [0, 60, 77], 'this': [1, 61, 78], 'paper,': [2], 'we': [3, 37], 'present': [4], 'a': [5, 22, 45, 63, 108], 'hypergraph': [6, 23, 81], 'neural': [7], 'networks': [8, 135], '(HGNN)': [9], 'framework': [10, 110], 'for': [11, 31], 'data': [12, 19, 33, 42, 52, 72, 104, 114, 169], 'representation': [13, 30, 75, 100], 'learning,': [14], 'which': [15, 47, 106], 'can': [16, 84, 153], 'encode': [17], 'high-order': [18, 103], 'correlation': [20, 73], 'in': [21, 34, 44], 'structure.': [24], 'Confronting': [25], 'the': [26, 71, 97, 102, 112, 144, 157, 160], 'challenges': [27], 'of': [28], 'learning': [29, 82], 'complex': [32, 58, 113], 'real': [35], 'practice,': [36], 'propose': [38], 'to': [39, 69, 95], 'incorporate': [40], 'such': [41], 'structure': [43], 'hypergraph,': [46], 'is': [48, 67, 93, 107, 163], 'more': [49], 'flexible': [50], 'on': [51, 120], 'modeling,': [53], 'especially': [54], 'when': [55, 165], 'dealing': [56, 166], 'with': [57, 132, 167, 171], 'data.': [59], 'method,': [62], 'hyperedge': [64, 88], 'convolution': [65, 89], 'operation': [66], 'designed': [68], 'handle': [70], 'during': [74], 'learning.': [76], 'way,': [79], 'traditional': [80, 138], 'procedure': [83], 'be': [85], 'conducted': [86, 118], 'using': [87], 'operations': [90], 'efficiently.': [91], 'HGNN': [92, 131, 146, 162], 'able': [94], 'learn': [96], 'hidden': [98], 'layer': [99], 'considering': [101, 111], 'structure,': [105], 'general': [109], 'correlations.': [115], 'We': [116, 152], 'have': [117], 'experiments': [119], 'citation': [121], 'network': [122], 'classification': [123], 'and': [124, 129, 136], 'visual': [125], 'object': [126], 'recognition': [127], 'tasks': [128], 'compared': [130, 170], 'graph': [133], 'convolutional': [134], 'other': [137], 'methods.': [139, 151, 173], 'Experimental': [140], 'results': [141, 158], 'demonstrate': [142], 'that': [143, 159], 'proposed': [145, 161], 'method': [147], 'outperforms': [148], 'recent': [149], 'state-of-theart': [150], 'also': [154], 'reveal': [155], 'from': [156], 'superior': [164], 'multi-modal': [168], 'existing': [172]}",2019,"['Hypergraph', 'Computer science', 'Representation (politics)', 'Artificial intelligence', 'Theoretical computer science', 'Graph', 'Convolutional neural network', 'External Data Representation', 'ENCODE', 'Pattern recognition (psychology)', 'Data mining', 'Machine learning', 'Mathematics', 'Political science', 'Chemistry', 'Politics', 'Gene', 'Biochemistry', 'Law', 'Discrete mathematics']","In this paper, we present a hypergraph neural networks (HGNN) framework for data representation learning, which can encode high-order data correlation in a hypergraph structure. Confronting the challenges of learning representation for complex data in real practice, we propose to incorporate such data structure in a hypergraph, which is more flexible on data modeling, especially when dealing with complex data. In this method, a hyperedge convolution operation is designed to handle the data correlation during representation learning. In this way, traditional hypergraph learning procedure can be conducted using hyperedge convolution operations efficiently. HGNN is able to learn the hidden layer representation considering the high-order data structure, which is a general framework considering the complex data correlations. We have conducted experiments on citation network classification and visual object recognition tasks and compared HGNN with graph convolutional networks and other traditional methods. Experimental results demonstrate that the proposed HGNN method outperforms recent state-of-theart methods. We can also reveal from the results that the proposed HGNN is superior when dealing with multi-modal data compared with existing methods."
https://openalex.org/W2346062110,Convolutional Neural Networks for Medical Image Analysis: Full Training or Fine Tuning?,"{'Training': [0], 'a': [1, 14, 22, 37, 46, 101, 152, 164, 180, 214, 225], 'deep': [2, 91, 102, 140, 207], 'convolutional': [3], 'neural': [4], 'network': [5], '(CNN)': [6], 'from': [7, 104, 129, 143, 183, 200], 'scratch': [8, 144], 'is': [9, 34], 'difficult': [10], 'because': [11], 'it': [12], 'requires': [13], 'large': [15, 47], 'amount': [16, 241], 'of': [17, 25, 49, 82, 89, 139, 163, 194, 242], 'labeled': [18, 50], 'training': [19, 100, 195], 'data': [20], 'and': [21, 59, 122, 127, 134, 217], 'great': [23], 'deal': [24], 'expertise': [26], 'to': [27, 35, 73, 191, 228], 'ensure': [28], 'proper': [29], 'convergence.': [30], 'A': [31], 'promising': [32], 'alternative': [33], 'fine-tune': [36], 'CNN': [38, 103, 166, 181], 'that': [39, 159], 'has': [40], 'been': [41], 'pre-trained': [42, 90, 148, 165], 'using,': [43], 'for': [44, 99, 213, 233], 'instance,': [45], 'set': [48], 'natural': [51, 58], 'images.': [52], 'However,': [53], 'the': [54, 75, 80, 87, 97, 137, 147, 161, 173, 192, 210, 230, 234, 240], 'substantial': [55], 'differences': [56], 'between': [57], 'medical': [60, 83, 114], 'images': [61], 'may': [62], 'advise': [63], 'against': [64], 'such': [65], 'knowledge': [66], 'transfer.': [67], 'In': [68], 'this': [69, 108], 'paper,': [70], 'we': [71, 110], 'seek': [72], 'answer': [74], 'following': [76], 'central': [77], 'question': [78], 'in': [79, 117, 151, 172], 'context': [81], 'image': [84], 'analysis:': [85], 'Can': [86], 'use': [88, 162], 'CNNs': [92, 141, 149, 187, 198], 'with': [93, 146, 167], 'sufficient': [94], 'fine-tuning': [95, 169, 221], 'eliminate': [96], 'need': [98], 'scratch?': [105], 'To': [106], 'address': [107], 'question,': [109], 'considered': [111], 'four': [112], 'distinct': [113], 'imaging': [115, 132], 'applications': [116], 'three': [118, 130], 'specialties': [119], '(radiology,': [120], 'cardiology,': [121], 'gastroenterology)': [123], 'involving': [124], 'classification,': [125], 'detection,': [126], 'segmentation': [128], 'different': [131], 'modalities,': [133], 'investigated': [135], 'how': [136], 'performance': [138, 232], 'trained': [142, 182, 199], 'compared': [145], 'fine-tuned': [150, 186], 'layer-wise': [153, 220], 'manner.': [154], 'Our': [155], 'experiments': [156], 'consistently': [157], 'demonstrated': [158], '1)': [160], 'adequate': [168], 'outperformed': [170], 'or,': [171], 'worst': [174], 'case,': [175], 'performed': [176], 'as': [177, 179], 'well': [178], 'scratch;': [184, 201], '2)': [185], 'were': [188], 'more': [189], 'robust': [190], 'size': [193], 'sets': [196], 'than': [197], '3)': [202], 'neither': [203], 'shallow': [204], 'tuning': [205, 208], 'nor': [206], 'was': [209], 'optimal': [211], 'choice': [212], 'particular': [215], 'application;': [216], '4)': [218], 'our': [219], 'scheme': [222], 'could': [223], 'offer': [224], 'practical': [226], 'way': [227], 'reach': [229], 'best': [231], 'application': [235], 'at': [236], 'hand': [237], 'based': [238], 'on': [239], 'available': [243], 'data.': [244]}",2016,"['Convolutional neural network', 'Computer science', 'Artificial intelligence', 'Deep learning', 'Scratch', 'Fine-tuning', 'Medical imaging', 'Context (archaeology)', 'Contextual image classification', 'Segmentation', 'Pattern recognition (psychology)', 'Transfer of learning', 'Image (mathematics)', 'Image segmentation', 'Machine learning', 'Biology', 'Physics', 'Operating system', 'Paleontology', 'Quantum mechanics']","Training a deep convolutional neural network (CNN) from scratch is difficult because it requires a large amount of labeled training data and a great deal of expertise to ensure proper convergence. A promising alternative is to fine-tune a CNN that has been pre-trained using, for instance, a large set of labeled natural images. However, the substantial differences between natural and medical images may advise against such knowledge transfer. In this paper, we seek to answer the following central question in the context of medical image analysis: Can the use of pre-trained deep CNNs with sufficient fine-tuning eliminate the need for training a deep CNN from scratch? To address this question, we considered four distinct medical imaging applications in three specialties (radiology, cardiology, and gastroenterology) involving classification, detection, and segmentation from three different imaging modalities, and investigated how the performance of deep CNNs trained from scratch compared with the pre-trained CNNs fine-tuned in a layer-wise manner. Our experiments consistently demonstrated that 1) the use of a pre-trained CNN with adequate fine-tuning outperformed or, in the worst case, performed as well as a CNN trained from scratch; 2) fine-tuned CNNs were more robust to the size of training sets than CNNs trained from scratch; 3) neither shallow tuning nor deep tuning was the optimal choice for a particular application; and 4) our layer-wise fine-tuning scheme could offer a practical way to reach the best performance for the application at hand based on the amount of available data."
https://openalex.org/W2598457882,Deep Learning‐Based Crack Damage Detection Using Convolutional Neural Networks,"{'Abstract': [0], 'A': [1], 'number': [2], 'of': [3, 61, 77, 95, 107, 121, 160, 169, 209], 'image': [4, 97, 147], 'processing': [5], 'techniques': [6], '(IPTs)': [7], 'have': [8], 'been': [9], 'implemented': [10], 'for': [11, 82, 109, 184], 'detecting': [12, 83], 'civil': [13], 'infrastructure': [14], 'defects': [15], 'to': [16, 27, 30, 55, 57, 144, 205], 'partially': [17], 'replace': [18], 'human‐conducted': [19], 'onsite': [20], 'inspections.': [21], 'These': [22], 'IPTs': [23, 108], 'are': [24, 93, 164, 203], 'primarily': [25], 'used': [26, 183], 'manipulate': [28], 'images': [29, 120, 168], 'extract': [31], 'defect': [32, 89], 'features,': [33], 'such': [34], 'as': [35], 'cracks': [36, 85, 237], 'in': [37, 238], 'concrete': [38, 84, 236], 'and': [39, 50, 158, 186, 197, 216, 232], 'steel': [40], 'surfaces.': [41], 'However,': [42], 'the': [43, 58, 88, 100, 105, 161, 207, 210, 225], 'extensively': [44], 'varying': [45], 'real‐world': [46], 'situations': [47], '(e.g.,': [48, 192], 'lighting': [49], 'shadow': [51], 'changes)': [52], 'can': [53, 233], 'lead': [54], 'challenges': [56], 'wide': [59], 'adoption': [60], 'IPTs.': [62], 'To': [63], 'overcome': [64], 'these': [65], 'challenges,': [66], 'this': [67], 'article': [68], 'proposes': [69], 'a': [70, 74, 140, 177], 'vision‐based': [71], 'method': [72, 102, 227], 'using': [73, 213], 'deep': [75], 'architecture': [76], 'convolutional': [78], 'neural': [79], 'networks': [80], '(CNNs)': [81], 'without': [86, 104], 'calculating': [87], 'features.': [90, 111], 'As': [91], 'CNNs': [92], 'capable': [94], 'learning': [96], 'features': [98], 'automatically,': [99], 'proposed': [101, 162, 211, 226], 'works': [103], 'conjugation': [106], 'extracting': [110], 'The': [112, 134, 156, 221], 'designed': [113], 'CNN': [114, 136, 212], 'is': [115, 137, 181], 'trained': [116, 135], 'on': [117, 166], '40': [118], 'K': [119], '256': [122, 124, 151, 153], '×': [123, 152, 171], 'pixel': [125, 154, 173], 'resolutions': [126, 174], 'and,': [127], 'consequently,': [128], 'records': [129], 'with': [130, 139], 'about': [131], '98%': [132], 'accuracy.': [133], 'combined': [138], 'sliding': [141], 'window': [142], 'technique': [143], 'scan': [145], 'any': [146], 'size': [148], 'larger': [149], 'than': [150], 'resolutions.': [155], 'robustness': [157], 'adaptability': [159], 'approach': [163], 'tested': [165], '55': [167], '5,888': [170], '3,584': [172], 'taken': [175], 'from': [176], 'different': [178], 'structure': [179], 'which': [180], 'not': [182], 'training': [185], 'validation': [187], 'processes': [188], 'under': [189], 'various': [190], 'conditions': [191], 'strong': [193], 'light': [194], 'spot,': [195], 'shadows,': [196], 'very': [198], 'thin': [199], 'cracks).': [200], 'Comparative': [201], 'studies': [202], 'conducted': [204], 'examine': [206], 'performance': [208], 'traditional': [214], 'Canny': [215], 'Sobel': [217], 'edge': [218], 'detection': [219], 'methods.': [220], 'results': [222], 'show': [223], 'that': [224], 'shows': [228], 'quite': [229], 'better': [230], 'performances': [231], 'indeed': [234], 'find': [235], 'realistic': [239], 'situations.': [240]}",2017,"['Convolutional neural network', 'Sobel operator', 'Computer science', 'Artificial intelligence', 'Robustness (evolution)', 'Pixel', 'Computer vision', 'Canny edge detector', 'Shadow (psychology)', 'Deep learning', 'Pattern recognition (psychology)', 'Adaptability', 'Image (mathematics)', 'Edge detection', 'Image processing', 'Psychology', 'Chemistry', 'Biochemistry', 'Ecology', 'Psychotherapist', 'Biology', 'Gene']","Abstract A number of image processing techniques (IPTs) have been implemented for detecting civil infrastructure defects to partially replace human‐conducted onsite inspections. These IPTs are primarily used to manipulate images to extract defect features, such as cracks in concrete and steel surfaces. However, the extensively varying real‐world situations (e.g., lighting and shadow changes) can lead to challenges to the wide adoption of IPTs. To overcome these challenges, this article proposes a vision‐based method using a deep architecture of convolutional neural networks (CNNs) for detecting concrete cracks without calculating the defect features. As CNNs are capable of learning image features automatically, the proposed method works without the conjugation of IPTs for extracting features. The designed CNN is trained on 40 K images of 256 × 256 pixel resolutions and, consequently, records with about 98% accuracy. The trained CNN is combined with a sliding window technique to scan any image size larger than 256 × 256 pixel resolutions. The robustness and adaptability of the proposed approach are tested on 55 images of 5,888 × 3,584 pixel resolutions taken from a different structure which is not used for training and validation processes under various conditions (e.g., strong light spot, shadows, and very thin cracks). Comparative studies are conducted to examine the performance of the proposed CNN using traditional Canny and Sobel edge detection methods. The results show that the proposed method shows quite better performances and can indeed find concrete cracks in realistic situations."
https://openalex.org/W2914721378,Graph Neural Networks for Social Recommendation,"{'In': [0, 128], 'recent': [1], 'years,': [2], 'Graph': [3], 'Neural': [4], 'Networks': [5], '(GNNs),': [6], 'which': [7, 150], 'can': [8, 44], 'naturally': [9], 'integrate': [10], 'node': [11], 'information': [12], 'and': [13, 51, 54, 60, 83, 102, 139, 145, 155], 'topological': [14], 'structure,': [15], 'have': [16, 89], 'been': [17], 'demonstrated': [18], 'to': [19, 34, 135], 'be': [20, 45], 'powerful': [21], 'in': [22, 40, 94, 113, 141], 'learning': [23, 55], 'on': [24, 71, 160], 'graph': [25, 50, 79, 101, 120, 144], 'data.': [26], 'These': [27], 'advantages': [28], 'of': [29, 58, 167], 'GNNs': [30, 72], 'provide': [31, 131], 'great': [32], 'potential': [33], 'advance': [35], 'social': [36, 41, 49, 67, 87, 100, 126], 'recommendation': [37], 'since': [38], 'data': [39], 'recommender': [42, 68], 'systems': [43, 69], 'represented': [46], 'as': [47], 'user-user': [48, 99], 'user-item': [52, 78, 104, 143], 'graph;': [53], 'latent': [56], 'factors': [57], 'users': [59, 92], 'items': [61], 'is': [62], 'the': [63, 77, 98, 103, 108, 142, 147, 165, 168], 'key.': [64], 'However,': [65], 'building': [66], 'based': [70], 'faces': [73], 'challenges.': [74], 'For': [75], 'example,': [76], 'encodes': [80], 'both': [81], 'interactions': [82, 138], 'their': [84], 'associated': [85], 'opinions;': [86], 'relations': [88], 'heterogeneous': [90, 156], 'strengths;': [91], 'involve': [93], 'two': [95, 153, 161], 'graphs': [96, 154], '(e.g.,': [97], 'graph).': [105], 'To': [106], 'address': [107], 'three': [109], 'aforementioned': [110], 'challenges': [111], 'simultaneously,': [112], 'this': [114], 'paper,': [115], 'we': [116, 130], 'present': [117], 'a': [118, 132], 'novel': [119], 'neural': [121], 'network': [122], 'framework': [123, 148, 170], '(GraphRec)': [124], 'for': [125], 'recommendations.': [127], 'particular,': [129], 'principled': [133], 'approach': [134], 'jointly': [136], 'capture': [137], 'opinions': [140], 'propose': [146], 'GraphRec,': [149], 'coherently': [151], 'models': [152], 'strengths.': [157], 'Extensive': [158], 'experiments': [159], 'real-world': [162], 'datasets': [163], 'demonstrate': [164], 'effectiveness': [166], 'proposed': [169], 'GraphRec.': [171]}",2019,"['Computer science', 'Recommender system', 'Social graph', 'Graph', 'Graph database', 'Theoretical computer science', 'Artificial intelligence', 'Machine learning', 'Information retrieval', 'Data science', 'World Wide Web', 'Social media']","In recent years, Graph Neural Networks (GNNs), which can naturally integrate node information and topological structure, have been demonstrated to be powerful in learning on graph data. These advantages of GNNs provide great potential to advance social recommendation since data in social recommender systems can be represented as user-user social graph and user-item graph; and learning latent factors of users and items is the key. However, building social recommender systems based on GNNs faces challenges. For example, the user-item graph encodes both interactions and their associated opinions; social relations have heterogeneous strengths; users involve in two graphs (e.g., the user-user social graph and the user-item graph). To address the three aforementioned challenges simultaneously, in this paper, we present a novel graph neural network framework (GraphRec) for social recommendations. In particular, we provide a principled approach to jointly capture interactions and opinions in the user-item graph and propose the framework GraphRec, which coherently models two graphs and heterogeneous strengths. Extensive experiments on two real-world datasets demonstrate the effectiveness of the proposed framework GraphRec."
https://openalex.org/W2524428287,Quantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations,"{'We': [0, 68], 'introduce': [1], 'a': [2, 58, 153], 'method': [3], 'to': [4, 64, 86, 113, 164], 'train': [5], 'Quantized': [6, 125], 'Neural': [7], 'Networks': [8], '(QNNs)': [9], '---': [10], 'neural': [11, 127], 'networks': [12, 128], 'with': [13, 54, 97, 159, 173], 'extremely': [14], 'low': [15], 'precision': [16], '(e.g.,': [17], '1-bit)': [18], 'weights': [19, 28, 99], 'and': [20, 29, 47, 49, 76, 100, 136], 'activations,': [21], 'at': [22], 'run-time.': [23], 'At': [24], 'train-time': [25], 'the': [26, 35, 39, 72, 110, 132], 'quantized': [27, 93], 'activations': [30, 102], 'are': [31], 'used': [32], 'for': [33], 'computing': [34], 'parameter': [36, 111], 'gradients.': [37], 'During': [38], 'forward': [40], 'pass,': [41], 'QNNs': [42, 70, 81], 'drastically': [43, 66], 'reduce': [44], 'memory': [45], 'size': [46], 'accesses,': [48], 'replace': [50], 'most': [51], 'arithmetic': [52], 'operations': [53], 'bit-wise': [55, 123], 'operations.': [56], 'As': [57], 'result,': [59], 'power': [60], 'consumption': [61], 'is': [62, 162, 188], 'expected': [63], 'be': [65], 'reduced.': [67], 'trained': [69], 'over': [71, 131], 'MNIST,': [73], 'CIFAR-10,': [74], 'SVHN': [75], 'ImageNet': [77], 'datasets.': [78], 'The': [79, 185], 'resulting': [80], 'achieve': [82], 'prediction': [83], 'accuracy': [84, 139], 'comparable': [85, 138], 'their': [87, 141], '32-bit': [88, 142], 'counterparts.': [89], 'For': [90], 'example,': [91], 'our': [92, 166], 'version': [94], 'of': [95], 'AlexNet': [96], '1-bit': [98], '2-bit': [101], 'achieves': [103], '$51\\%$': [104], 'top-1': [105], 'accuracy.': [106, 184], 'Moreover,': [107], 'we': [108, 151], 'quantize': [109], 'gradients': [112, 119], '6-bits': [114], 'as': [115, 140], 'well': [116], 'which': [117, 160], 'enables': [118], 'computation': [120], 'using': [121, 144], 'only': [122, 145], 'operation.': [124], 'recurrent': [126], 'were': [129], 'tested': [130], 'Penn': [133], 'Treebank': [134], 'dataset,': [135], 'achieved': [137], 'counterparts': [143], '4-bits.': [146], 'Last': [147], 'but': [148], 'not': [149], 'least,': [150], 'programmed': [152], 'binary': [154], 'matrix': [155], 'multiplication': [156], 'GPU': [157, 176], 'kernel': [158], 'it': [161], 'possible': [163], 'run': [165], 'MNIST': [167], 'QNN': [168, 186], '7': [169], 'times': [170], 'faster': [171], 'than': [172], 'an': [174], 'unoptimized': [175], 'kernel,': [177], 'without': [178], 'suffering': [179], 'any': [180], 'loss': [181], 'in': [182], 'classification': [183], 'code': [187], 'available': [189], 'online.': [190]}",2016,"['Artificial neural network', 'Computer science', 'Artificial intelligence', 'Training (meteorology)', 'Deep neural networks', 'Machine learning', 'Pattern recognition (psychology)', 'Physics', 'Meteorology']","We introduce a method to train Quantized Neural Networks (QNNs) --- neural networks with extremely low precision (e.g., 1-bit) weights and activations, at run-time. At train-time the quantized weights and activations are used for computing the parameter gradients. During the forward pass, QNNs drastically reduce memory size and accesses, and replace most arithmetic operations with bit-wise operations. As a result, power consumption is expected to be drastically reduced. We trained QNNs over the MNIST, CIFAR-10, SVHN and ImageNet datasets. The resulting QNNs achieve prediction accuracy comparable to their 32-bit counterparts. For example, our quantized version of AlexNet with 1-bit weights and 2-bit activations achieves $51\%$ top-1 accuracy. Moreover, we quantize the parameter gradients to 6-bits as well which enables gradients computation using only bit-wise operation. Quantized recurrent neural networks were tested over the Penn Treebank dataset, and achieved comparable accuracy as their 32-bit counterparts using only 4-bits. Last but not least, we programmed a binary matrix multiplication GPU kernel with which it is possible to run our MNIST QNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy. The QNN code is available online."
https://openalex.org/W1598796236,A Critical Review of Recurrent Neural Networks for Sequence Learning,"{'Countless': [0], 'learning': [1, 136, 192], 'tasks': [2, 158], 'require': [3, 16], 'dealing': [4], 'with': [5, 137, 217], 'sequential': [6], 'data.': [7], 'Image': [8], 'captioning,': [9, 163], 'speech': [10], 'synthesis,': [11], 'and': [12, 35, 58, 116, 129, 149, 166, 174, 186, 200, 221], 'music': [13], 'generation': [14], 'all': [15], 'that': [17, 22, 45, 73, 96, 178], 'a': [18, 39, 60, 94, 207, 218], 'model': [19, 40], 'produce': [20], 'outputs': [21], 'are': [23, 46, 70], 'sequences.': [24, 47], 'In': [25, 139, 169], 'other': [26], 'domains,': [27], 'such': [28, 50], 'as': [29, 51, 159, 161], 'time': [30], 'series': [31], 'prediction,': [32], 'video': [33], 'analysis,': [34], 'musical': [36], 'information': [37, 99], 'retrieval,': [38], 'must': [41], 'learn': [42], 'from': [43, 100], 'inputs': [44], 'Interactive': [48], 'tasks,': [49], 'translating': [52], 'natural': [53], 'language,': [54], 'engaging': [55], 'in': [56, 81, 124], 'dialogue,': [57], 'controlling': [59], 'robot,': [61], 'often': [62, 117], 'demand': [63], 'both': [64], 'capabilities.': [65], 'Recurrent': [66], 'neural': [67, 89, 108], 'networks': [68, 92, 109], '(RNNs)': [69], 'connectionist': [71], 'models': [72], 'capture': [74], 'the': [75, 82, 176, 180, 211, 214], 'dynamics': [76], 'of': [77, 84, 120, 210, 213], 'sequences': [78], 'via': [79], 'cycles': [80], 'network': [83, 125], 'nodes.': [85], 'Unlike': [86], 'standard': [87], 'feedforward': [88], 'networks,': [90], 'recurrent': [91, 107], 'retain': [93], 'state': [95, 212], 'can': [97], 'represent': [98], 'an': [101], 'arbitrarily': [102], 'long': [103, 145], 'context': [104], 'window.': [105], 'Although': [106], 'have': [110, 132, 153], 'traditionally': [111], 'been': [112], 'difficult': [113], 'to': [114, 205, 223], 'train,': [115], 'contain': [118], 'millions': [119], 'parameters,': [121], 'recent': [122, 140], 'advances': [123], 'architectures,': [126], 'optimization': [127], 'techniques,': [128], 'parallel': [130], 'computation': [131], 'enabled': [133], 'successful': [134], 'large-scale': [135], 'them.': [138], 'years,': [141], 'systems': [142], 'based': [143], 'on': [144, 157], 'short-term': [146], 'memory': [147], '(LSTM)': [148], 'bidirectional': [150], '(BRNN)': [151], 'architectures': [152], 'demonstrated': [154], 'ground-breaking': [155], 'performance': [156], 'varied': [160], 'image': [162], 'language': [164], 'translation,': [165], 'handwriting': [167], 'recognition.': [168], 'this': [170], 'survey,': [171], 'we': [172, 196], 'review': [173], 'synthesize': [175], 'research': [177], 'over': [179], 'past': [181], 'three': [182], 'decades': [183], 'first': [184], 'yielded': [185], 'then': [187], 'made': [188], 'practical': [189], 'these': [190], 'powerful': [191], 'models.': [193], 'When': [194], 'appropriate,': [195], 'reconcile': [197], 'conflicting': [198], 'notation': [199], 'nomenclature.': [201], 'Our': [202], 'goal': [203], 'is': [204], 'provide': [206], 'self-contained': [208], 'explication': [209], 'art': [215], 'together': [216], 'historical': [219], 'perspective': [220], 'references': [222], 'primary': [224], 'research.': [225]}",2015,"['Computer science', 'Recurrent neural network', 'Closed captioning', 'Artificial intelligence', 'Connectionism', 'Context (archaeology)', 'Language model', 'Deep learning', 'Artificial neural network', 'Natural language', 'Machine learning', 'Biology', 'Image (mathematics)', 'Paleontology']","Countless learning tasks require dealing with sequential data. Image captioning, speech synthesis, and music generation all require that a model produce outputs that are sequences. In other domains, such as time series prediction, video analysis, and musical information retrieval, a model must learn from inputs that are sequences. Interactive tasks, such as translating natural language, engaging in dialogue, and controlling a robot, often demand both capabilities. Recurrent neural networks (RNNs) are connectionist models that capture the dynamics of sequences via cycles in the network of nodes. Unlike standard feedforward neural networks, recurrent networks retain a state that can represent information from an arbitrarily long context window. Although recurrent neural networks have traditionally been difficult to train, and often contain millions of parameters, recent advances in network architectures, optimization techniques, and parallel computation have enabled successful large-scale learning with them. In recent years, systems based on long short-term memory (LSTM) and bidirectional (BRNN) architectures have demonstrated ground-breaking performance on tasks as varied as image captioning, language translation, and handwriting recognition. In this survey, we review and synthesize the research that over the past three decades first yielded and then made practical these powerful learning models. When appropriate, we reconcile conflicting notation and nomenclature. Our goal is to provide a self-contained explication of the state of the art together with a historical perspective and references to primary research."
https://openalex.org/W2604662567,DeepFM: A Factorization-Machine based Neural Network for CTR Prediction,"{'Learning': [0], 'sophisticated': [1], 'feature': [2, 34, 57, 75, 108], 'interactions': [3], 'behind': [4], 'user': [5], 'behaviors': [6], 'is': [7, 43], 'critical': [8], 'in': [9, 77], 'maximizing': [10], 'CTR': [11, 130], 'for': [12, 69, 74, 129], 'recommender': [13], 'systems.': [14], 'Despite': [15], 'great': [16], 'progress,': [17], 'existing': [18, 127], 'methods': [19], 'seem': [20], 'to': [21, 45, 84, 98, 117], 'have': [22], 'a': [23, 78, 95], 'strong': [24], 'bias': [25], 'towards': [26], 'low-': [27, 54], 'or': [28, 31], 'high-order': [29, 56], 'interactions,': [30], 'require': [32], 'expertise': [33], 'engineering.': [35], 'In': [36], 'this': [37], 'paper,': [38], 'we': [39], 'show': [40], 'that': [41, 51], 'it': [42], 'possible': [44], 'derive': [46], 'an': [47], 'end-to-end': [48], 'learning': [49, 73, 76], 'model': [50, 90], 'emphasizes': [52], 'both': [53, 133], 'and': [55, 71, 101, 121, 136], 'interactions.': [58], 'The': [59], 'proposed': [60], 'model,': [61], 'DeepFM,': [62], 'combines': [63], 'the': [64, 85, 119, 126], 'power': [65], 'of': [66, 107, 123], 'factorization': [67], 'machines': [68], 'recommendation': [70], 'deep': [72], 'new': [79], 'neural': [80], 'network': [81], 'architecture.': [82], 'Compared': [83], 'latest': [86], 'Wide': [87], '&amp;': [88], 'Deep': [89], 'from': [91], 'Google,': [92], 'DeepFM': [93, 124], 'has': [94], 'shared': [96], 'input': [97], 'its': [99], '""wide""': [100], '""deep""': [102], 'parts,': [103], 'with': [104], 'no': [105], 'need': [106], 'engineering': [109], 'besides': [110], 'raw': [111], 'features.': [112], 'Comprehensive': [113], 'experiments': [114], 'are': [115], 'conducted': [116], 'demonstrate': [118], 'effectiveness': [120], 'efficiency': [122], 'over': [125], 'models': [128], 'prediction,': [131], 'on': [132], 'benchmark': [134], 'data': [135], 'commercial': [137], 'data.': [138]}",2017,"['Feature engineering', 'Computer science', 'Benchmark (surveying)', 'Feature (linguistics)', 'Artificial intelligence', 'Deep learning', 'Machine learning', 'Recommender system', 'Artificial neural network', 'Deep neural networks', 'Factorization', 'Feature learning', 'Raw data', 'Algorithm', 'Linguistics', 'Geodesy', 'Programming language', 'Geography', 'Philosophy']","Learning sophisticated feature interactions behind user behaviors is critical in maximizing CTR for recommender systems. Despite great progress, existing methods seem to have a strong bias towards low- or high-order interactions, or require expertise feature engineering. In this paper, we show that it is possible to derive an end-to-end learning model that emphasizes both low- and high-order feature interactions. The proposed model, DeepFM, combines the power of factorization machines for recommendation and deep learning for feature learning in a new neural network architecture. Compared to the latest Wide &amp; Deep model from Google, DeepFM has a shared input to its ""wide"" and ""deep"" parts, with no need of feature engineering besides raw features. Comprehensive experiments are conducted to demonstrate the effectiveness and efficiency of DeepFM over the existing models for CTR prediction, on both benchmark data and commercial data."
https://openalex.org/W2965857891,Heterogeneous Graph Neural Network,"{'Representation': [0], 'learning': [1], 'in': [2, 247, 263], 'heterogeneous': [3, 43, 63, 105, 112, 126, 153, 192], 'graphs': [4], 'aims': [5], 'to': [6, 17, 41, 58, 84, 131, 145, 175, 224, 243], 'pursue': [7], 'a': [8, 76, 125, 139, 147, 168, 233, 238], 'meaningful': [9], 'vector': [10], 'representation': [11], 'for': [12, 61, 155, 198], 'each': [13, 73, 116, 156, 199], 'node': [14, 27, 117, 157, 163, 228, 272, 278], 'so': [15], 'as': [16, 22, 93, 95, 109, 111], 'facilitate': [18], 'downstream': [19], 'applications': [20], 'such': [21], 'link': [23, 269], 'prediction,': [24, 270], 'personalized': [25], 'recommendation,': [26, 271], 'classification,': [28], 'etc.': [29], 'This': [30], 'task,': [31], 'however,': [32], 'is': [33], 'challenging': [34], 'not': [35], 'only': [36], 'because': [37], 'of': [38, 48, 51, 79, 100, 115, 150, 179, 191, 208, 221], 'the': [39, 59, 219, 226, 245], 'demand': [40], 'incorporate': [42], 'structural': [44, 106], '(graph)': [45, 107], 'information': [46, 108, 114, 178], 'consisting': [47], 'multiple': [49], 'types': [50], 'nodes': [52], 'and': [53, 158, 194, 213, 237, 276], 'edges,': [54], 'but': [55], 'also': [56], 'due': [57], 'need': [60], 'considering': [62, 218], 'attributes': [64], 'or': [65, 69], 'contents': [66, 113, 193], '(e.g.,': [67], 'text': [68], 'image)': [70], 'associated': [71], 'with': [72, 142, 172], 'node.': [74, 200], 'Despite': [75], 'substantial': [77], 'amount': [78], 'effort': [80], 'has': [81], 'been': [82], 'made': [83], 'homogeneous': [85], '(or': [86], 'heterogeneous)': [87], 'graph': [88, 91, 96, 127, 234, 265], 'embedding,': [89], 'attributed': [90], 'embedding': [92, 197], 'well': [94, 110], 'neural': [97, 128, 169], 'networks,': [98], 'few': [99], 'them': [101, 160, 216], 'can': [102, 259], 'jointly': [103], 'consider': [104], 'effectively.': [118], 'In': [119], 'this': [120, 133], 'paper,': [121], 'we': [122, 136, 166, 231], 'propose': [123], 'HetGNN,': [124], 'network': [129, 170], 'model,': [130], 'resolve': [132], 'issue.': [134], 'Specifically,': [135], 'first': [137, 185], 'introduce': [138], 'random': [140], 'walk': [141], 'restart': [143], 'strategy': [144], 'sample': [146], 'fixed': [148], 'size': [149], 'strongly': [151], 'correlated': [152], 'neighbors': [154], 'group': [159], 'based': [161], 'upon': [162], 'types.': [164], 'Next,': [165], 'design': [167], 'architecture': [171], 'two': [173], 'modules': [174], 'aggregate': [176], 'feature': [177, 189], 'those': [180], 'sampled': [181], 'neighboring': [182, 210], 'nodes.': [183], 'The': [184, 201], 'module': [186, 203], 'encodes': [187], '""deep""': [188], 'interactions': [190], 'generates': [195], 'content': [196, 205], 'second': [202], 'aggregates': [204], '(attribute)': [206], 'embeddings': [207], 'different': [209, 222], 'groups': [211, 223], '(types)': [212], 'further': [214], 'combines': [215], 'by': [217], 'impacts': [220], 'obtain': [225], 'ultimate': [227], 'embedding.': [229], 'Finally,': [230], 'leverage': [232], 'context': [235], 'loss': [236], 'mini-batch': [239], 'gradient': [240], 'descent': [241], 'procedure': [242], 'train': [244], 'model': [246], 'an': [248], 'end-to-end': [249], 'manner.': [250], 'Extensive': [251], 'experiments': [252], 'on': [253], 'several': [254], 'datasets': [255], 'demonstrate': [256], 'that': [257], 'HetGNN': [258], 'outperform': [260], 'state-of-the-art': [261], 'baselines': [262], 'various': [264], 'mining': [266], 'tasks,': [267], 'i.e.,': [268], 'classification': [273, 279], '&': [274, 280], 'clustering': [275], 'inductive': [277], 'clustering.': [281]}",2019,"['Computer science', 'Theoretical computer science', 'Stochastic gradient descent', 'Graph embedding', 'Embedding', 'Graph', 'Feature learning', 'Heterogeneous network', 'Leverage (statistics)', 'Node (physics)', 'Artificial neural network', 'Artificial intelligence', 'Telecommunications', 'Structural engineering', 'Engineering', 'Wireless network', 'Wireless']","Representation learning in heterogeneous graphs aims to pursue a meaningful vector representation for each node so as to facilitate downstream applications such as link prediction, personalized recommendation, node classification, etc. This task, however, is challenging not only because of the demand to incorporate heterogeneous structural (graph) information consisting of multiple types of nodes and edges, but also due to the need for considering heterogeneous attributes or contents (e.g., text or image) associated with each node. Despite a substantial amount of effort has been made to homogeneous (or heterogeneous) graph embedding, attributed graph embedding as well as graph neural networks, few of them can jointly consider heterogeneous structural (graph) information as well as heterogeneous contents information of each node effectively. In this paper, we propose HetGNN, a heterogeneous graph neural network model, to resolve this issue. Specifically, we first introduce a random walk with restart strategy to sample a fixed size of strongly correlated heterogeneous neighbors for each node and group them based upon node types. Next, we design a neural network architecture with two modules to aggregate feature information of those sampled neighboring nodes. The first module encodes ""deep"" feature interactions of heterogeneous contents and generates content embedding for each node. The second module aggregates content (attribute) embeddings of different neighboring groups (types) and further combines them by considering the impacts of different groups to obtain the ultimate node embedding. Finally, we leverage a graph context loss and a mini-batch gradient descent procedure to train the model in an end-to-end manner. Extensive experiments on several datasets demonstrate that HetGNN can outperform state-of-the-art baselines in various graph mining tasks, i.e., link prediction, recommendation, node classification & clustering and inductive node classification & clustering."
https://openalex.org/W2419175238,Solving the quantum many-body problem with artificial neural networks,"{'Machine': [0], 'learning': [1, 47], 'and': [2, 40], 'quantum': [3, 9, 55, 93], 'physics': [4], 'Elucidating': [5], 'the': [6, 18, 32, 43, 54, 59, 92], 'behavior': [7], 'of': [8, 12, 17, 31, 45], 'interacting': [10], 'systems': [11], 'many': [13], 'particles': [14], 'remains': [15], 'one': [16], 'biggest': [19], 'challenges': [20], 'in': [21, 91], 'physics.': [22], 'Traditional': [23], 'numerical': [24], 'methods': [25], 'often': [26], 'work': [27], 'well,': [28], 'but': [29], 'some': [30], 'most': [33], 'interesting': [34], 'problems': [35], 'leave': [36], 'them': [37], 'stumped.': [38], 'Carleo': [39], 'Troyer': [41], 'harnessed': [42], 'power': [44], 'machine': [46], 'to': [48, 53], 'develop': [49], 'a': [50, 74, 77, 88], 'variational': [51], 'approach': [52], 'many-body': [56], 'problem': [57], '(see': [58], 'Perspective': [60], 'by': [61], 'Hush).': [62], 'The': [63], 'method': [64], 'performed': [65], 'at': [66], 'least': [67], 'as': [68, 70], 'well': [69, 86], 'state-of-the-art': [71], 'approaches,': [72], 'setting': [73], 'benchmark': [75], 'for': [76], 'prototypical': [78], 'two-dimensional': [79], 'problem.': [80], 'With': [81], 'further': [82], 'development,': [83], 'it': [84], 'may': [85], 'prove': [87], 'valuable': [89], 'piece': [90], 'toolbox.': [94], 'Science': [95], ',': [96], 'this': [97], 'issue': [98], 'p.': [99, 104], '602': [100], ';': [101], 'see': [102], 'also': [103], '580': [105]}",2017,"['Unitary state', 'Quantum', 'Quantum machine learning', 'Computer science', 'Artificial neural network', 'Reinforcement learning', 'Wave function', 'Spins', 'Representation (politics)', 'Function (biology)', 'Hidden variable theory', 'Quantum state', 'Statistical physics', 'Theoretical computer science', 'Quantum computer', 'Artificial intelligence', 'Physics', 'Quantum mechanics', 'Politics', 'Biology', 'Evolutionary biology', 'Condensed matter physics', 'Political science', 'Law']","Machine learning and quantum physics Elucidating the behavior of quantum interacting systems of many particles remains one of the biggest challenges in physics. Traditional numerical methods often work well, but some of the most interesting problems leave them stumped. Carleo and Troyer harnessed the power of machine learning to develop a variational approach to the quantum many-body problem (see the Perspective by Hush). The method performed at least as well as state-of-the-art approaches, setting a benchmark for a prototypical two-dimensional problem. With further development, it may well prove a valuable piece in the quantum toolbox. Science , this issue p. 602 ; see also p. 580"
https://openalex.org/W2250861254,A Fast and Accurate Dependency Parser using Neural Networks,"{'Almost': [0], 'all': [1], 'current': [2], 'dependency': [3, 48], 'parsers': [4], 'classify': [5], 'based': [6], 'on': [7, 79, 102], 'millions': [8], 'of': [9, 22, 36, 59], 'sparse': [10], 'indicator': [11], 'features.Not': [12], 'only': [13], 'do': [14], 'these': [15], 'features': [16], 'generalize': [17], 'poorly,': [18], 'but': [19], 'the': [20, 103], 'cost': [21], 'feature': [23], 'computation': [24], 'restricts': [25], 'parsing': [26], 'speed': [27], 'significantly.In': [28], 'this': [29, 50], 'work,': [30], 'we': [31], 'propose': [32], 'a': [33, 38, 45, 56], 'novel': [34], 'way': [35], 'learning': [37], 'neural': [39], 'network': [40], 'classifier': [41, 51], 'for': [42], 'use': [43], 'in': [44, 73], 'greedy,': [46], 'transition-based': [47], 'parser.Because': [49], 'learns': [52], 'and': [53, 75, 82], 'uses': [54], 'just': [55], 'small': [57], 'number': [58], 'dense': [60], 'features,': [61], 'it': [62], 'can': [63], 'work': [64], 'very': [65], 'fast,': [66], 'while': [67], 'achieving': [68], 'an': [69], 'about': [70], '2%': [71], 'improvement': [72], 'unlabeled': [74, 99], 'labeled': [76], 'attachment': [77, 100], 'scores': [78], 'both': [80], 'English': [81, 104], 'Chinese': [83], 'datasets.Concretely,': [84], 'our': [85], 'parser': [86], 'is': [87], 'able': [88], 'to': [89], 'parse': [90], 'more': [91], 'than': [92], '1000': [93], 'sentences': [94], 'per': [95], 'second': [96], 'at': [97], '92.2%': [98], 'score': [101], 'Penn': [105], 'Treebank.': [106]}",2014,"['Computer science', 'Parsing', 'Dependency (UML)', 'Dependency grammar', 'Artificial intelligence', 'Natural language processing', 'Artificial neural network', 'Speech recognition']","Almost all current dependency parsers classify based on millions of sparse indicator features.Not only do these features generalize poorly, but the cost of feature computation restricts parsing speed significantly.In this work, we propose a novel way of learning a neural network classifier for use in a greedy, transition-based dependency parser.Because this classifier learns and uses just a small number of dense features, it can work very fast, while achieving an about 2% improvement in unlabeled and labeled attachment scores on both English and Chinese datasets.Concretely, our parser is able to parse more than 1000 sentences per second at 92.2% unlabeled attachment score on the English Penn Treebank."
https://openalex.org/W2270470215,Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition,"{'Human': [0], 'activity': [1, 75, 133], 'recognition': [2, 76, 134], '(HAR)': [3], 'tasks': [4], 'have': [5], 'traditionally': [6], 'been': [7, 128], 'solved': [8], 'using': [9], 'engineered': [10], 'features': [11], 'obtained': [12], 'by': [13, 151, 162], 'heuristic': [14], 'processes.': [15], 'Current': [16], 'research': [17], 'suggests': [18], 'that': [19, 139, 169], 'deep': [20, 72, 144], 'convolutional': [21, 79], 'neural': [22, 62], 'networks': [23, 63, 146], 'are': [24, 37], 'suited': [25], 'to': [26, 164, 175, 185, 196], 'automate': [27], 'feature': [28, 115], 'extraction': [29], 'from': [30], 'raw': [31], 'sensor': [32, 95, 177], 'inputs.': [33], 'However,': [34], 'human': [35], 'activities': [36], 'made': [38], 'of': [39, 42, 60, 114, 125, 157], 'complex': [40], 'sequences': [41], 'motor': [43], 'movements,': [44], 'and': [45, 80, 107], 'capturing': [46], 'this': [47], 'temporal': [48, 112], 'dynamics': [49, 113], 'is': [50, 86], 'fundamental': [51], 'for': [52, 64, 74, 88], 'successful': [53], 'HAR.': [54], 'Based': [55], 'on': [56, 78, 121, 147, 153, 194], 'the': [57, 111, 148, 158, 170], 'recent': [58], 'success': [59], 'recurrent': [61, 82], 'time': [65], 'series': [66], 'domains,': [67], 'we': [68], 'propose': [69], 'a': [70, 131], 'generic': [71], 'framework': [73, 120, 141, 171], 'based': [77], 'LSTM': [81], 'units,': [83], 'which:': [84], '(i)': [85], 'suitable': [87], 'multimodal': [89, 183], 'wearable': [90], 'sensors;': [91], '(ii)': [92], 'can': [93, 172, 180], 'perform': [94], 'fusion': [96], 'naturally;': [97], '(iii)': [98], 'does': [99], 'not': [100], 'require': [101], 'expert': [102], 'knowledge': [103], 'in': [104, 130], 'designing': [105], 'features;': [106], '(iv)': [108], 'explicitly': [109], 'models': [110], 'activations.': [116], 'We': [117, 188], 'evaluate': [118], 'our': [119, 140], 'two': [122], 'datasets,': [123], 'one': [124], 'which': [126], 'has': [127], 'used': [129], 'public': [132], 'challenge.': [135], 'Our': [136, 166], 'results': [137, 161, 167], 'show': [138, 168], 'outperforms': [142], 'competing': [143], 'non-recurrent': [145], 'challenge': [149], 'dataset': [150], '4%': [152], 'average;': [154], 'outperforming': [155], 'some': [156], 'previous': [159], 'reported': [160], 'up': [163], '9%.': [165], 'be': [173], 'applied': [174], 'homogeneous': [176], 'modalities,': [178], 'but': [179], 'also': [181], 'fuse': [182], 'sensors': [184], 'improve': [186], 'performance.': [187], 'characterise': [189], 'key': [190], 'architectural': [191], 'hyperparameters’': [192], 'influence': [193], 'performance': [195], 'provide': [197], 'insights': [198], 'about': [199], 'their': [200], 'optimisation.': [201]}",2016,"['Convolutional neural network', 'Computer science', 'Wearable computer', 'Deep learning', 'Recurrent neural network', 'Artificial intelligence', 'Activity recognition', 'Speech recognition', 'Pattern recognition (psychology)', 'Artificial neural network', 'Embedded system']","Human activity recognition (HAR) tasks have traditionally been solved using engineered features obtained by heuristic processes. Current research suggests that deep convolutional neural networks are suited to automate feature extraction from raw sensor inputs. However, human activities are made of complex sequences of motor movements, and capturing this temporal dynamics is fundamental for successful HAR. Based on the recent success of recurrent neural networks for time series domains, we propose a generic deep framework for activity recognition based on convolutional and LSTM recurrent units, which: (i) is suitable for multimodal wearable sensors; (ii) can perform sensor fusion naturally; (iii) does not require expert knowledge in designing features; and (iv) explicitly models the temporal dynamics of feature activations. We evaluate our framework on two datasets, one of which has been used in a public activity recognition challenge. Our results show that our framework outperforms competing deep non-recurrent networks on the challenge dataset by 4% on average; outperforming some of the previous reported results by up to 9%. Our results show that the framework can be applied to homogeneous sensor modalities, but can also fuse multimodal sensors to improve performance. We characterise key architectural hyperparameters’ influence on performance to provide insights about their optimisation."
https://openalex.org/W2953318193,Pixel Recurrent Neural Networks,"{'Modeling': [0], 'the': [1, 36, 42, 49, 53, 59, 65, 97, 101, 110, 117], 'distribution': [2], 'of': [3, 52, 62, 78, 100], 'natural': [4, 90], 'images': [5, 91], 'is': [6, 20], 'a': [7, 29], 'landmark': [8], 'problem': [9], 'in': [10, 38, 64, 81], 'unsupervised': [11], 'learning.': [12], 'This': [13], 'task': [14], 'requires': [15], 'an': [16, 39, 75], 'image': [17, 40], 'model': [18, 118], 'that': [19, 33, 92], 'at': [21], 'once': [22], 'expressive,': [23], 'tractable': [24], 'and': [25, 57, 74, 122], 'scalable.': [26], 'We': [27, 85], 'present': [28], 'deep': [30, 82], 'neural': [31], 'network': [32], 'sequentially': [34], 'predicts': [35], 'pixels': [37], 'along': [41], 'two': [43], 'spatial': [44], 'dimensions.': [45], 'Our': [46, 103], 'method': [47], 'models': [48], 'discrete': [50], 'probability': [51], 'raw': [54], 'pixel': [55], 'values': [56], 'encodes': [58], 'complete': [60], 'set': [61], 'dependencies': [63], 'image.': [66], 'Architectural': [67], 'novelties': [68], 'include': [69], 'fast': [70], 'two-dimensional': [71], 'recurrent': [72, 83], 'layers': [73], 'effective': [76], 'use': [77], 'residual': [79], 'connections': [80], 'networks.': [84], 'achieve': [86], 'log-likelihood': [87], 'scores': [88], 'on': [89, 109], 'are': [93], 'considerably': [94], 'better': [95], 'than': [96], 'previous': [98], 'state': [99], 'art.': [102], 'main': [104], 'results': [105], 'also': [106], 'provide': [107], 'benchmarks': [108], 'diverse': [111], 'ImageNet': [112], 'dataset.': [113], 'Samples': [114], 'generated': [115], 'from': [116], 'appear': [119], 'crisp,': [120], 'varied': [121], 'globally': [123], 'coherent.': [124]}",2016,"['Pixel', 'Computer science', 'Landmark', 'Artificial intelligence', 'Image (mathematics)', 'Scalability', 'Residual', 'Set (abstract data type)', 'Pattern recognition (psychology)', 'Artificial neural network', 'Deep learning', 'Task (project management)', 'Deep neural networks', 'Machine learning', 'Algorithm', 'Management', 'Economics', 'Database', 'Programming language']","Modeling the distribution of natural images is a landmark problem in unsupervised learning. This task requires an image model that is at once expressive, tractable and scalable. We present a deep neural network that sequentially predicts the pixels in an image along the two spatial dimensions. Our method models the discrete probability of the raw pixel values and encodes the complete set of dependencies in the image. Architectural novelties include fast two-dimensional recurrent layers and an effective use of residual connections in deep recurrent networks. We achieve log-likelihood scores on natural images that are considerably better than the previous state of the art. Our main results also provide benchmarks on the diverse ImageNet dataset. Samples generated from the model appear crisp, varied and globally coherent."
https://openalex.org/W2158985775,Artificial neural networks for solving ordinary and partial differential equations,"{'We': [0], 'present': [1, 124], 'a': [2, 25, 58, 118], 'method': [3, 115, 134, 152], 'to': [4, 50, 80, 97, 104, 157], 'solve': [5], 'initial': [6], 'and': [7, 37, 75, 102, 123, 147], 'boundary': [8], 'value': [9], 'problems': [10, 122], 'using': [11, 129], 'artificial': [12], 'neural': [13, 60], 'networks.': [14], 'A': [15], 'trial': [16], 'solution': [17], 'of': [18, 27, 87, 99, 120, 138, 145], 'the': [19, 34, 52, 70, 76, 82, 114, 130, 143, 151, 158, 163], 'differential': [20, 83, 94, 106, 140], 'equation': [21], 'is': [22, 45, 78], 'written': [23], 'as': [24, 48], 'sum': [26], 'two': [28], 'parts.': [29], 'The': [30, 42, 85], 'first': [31], 'part': [32, 44, 56], 'satisfies': [33], 'initial/boundary': [35, 53, 71], 'conditions': [36, 72], 'contains': [38], 'no': [39], 'adjustable': [40, 63], 'parameters.': [41], 'second': [43], 'constructed': [46], 'so': [47], 'not': [49], 'affect': [51], 'conditions.': [54], 'This': [55], 'involves': [57], 'feedforward': [59], 'network': [61, 77], 'containing': [62], 'parameters': [64], '(the': [65], 'weights).': [66], 'Hence': [67], 'by': [68, 116], 'construction': [69], 'are': [73], 'satisfied': [74], 'trained': [79], 'satisfy': [81], 'equation.': [84], 'applicability': [86], 'this': [88, 110], 'approach': [89], 'ranges': [90], 'from': [91], 'single': [92], 'ordinary': [93], 'equations': [95, 107], ""(ODE's),"": [96], 'systems': [98], 'coupled': [100], ""ODE's"": [101], 'also': [103], 'partial': [105, 139], ""(PDE's)."": [108], 'In': [109], 'article,': [111], 'we': [112], 'illustrate': [113], 'solving': [117], 'variety': [119], 'model': [121], 'comparisons': [125], 'with': [126], 'solutions': [127], 'obtained': [128], 'Galekrkin': [131], 'finite': [132], 'element': [133], 'for': [135], 'several': [136], 'cases': [137], 'equations.': [141], 'With': [142], 'advent': [144], 'neuroprocessors': [146], 'digital': [148], 'signal': [149], 'processors': [150], 'becomes': [153], 'particularly': [154], 'interesting': [155], 'due': [156], 'expected': [159], 'essential': [160], 'gains': [161], 'in': [162], 'execution': [164], 'speed.': [165]}",1998,[],"We present a method to solve initial and boundary value problems using artificial neural networks. A trial solution of the differential equation is written as a sum of two parts. The first part satisfies the initial/boundary conditions and contains no adjustable parameters. The second part is constructed so as not to affect the initial/boundary conditions. This part involves a feedforward neural network containing adjustable parameters (the weights). Hence by construction the initial/boundary conditions are satisfied and the network is trained to satisfy the differential equation. The applicability of this approach ranges from single ordinary differential equations (ODE's), to systems of coupled ODE's and also to partial differential equations (PDE's). In this article, we illustrate the method by solving a variety of model problems and present comparisons with solutions obtained using the Galekrkin finite element method for several cases of partial differential equations. With the advent of neuroprocessors and digital signal processors the method becomes particularly interesting due to the expected essential gains in the execution speed."
https://openalex.org/W1521436688,Deep Convolutional Neural Networks for Hyperspectral Image Classification,"{'Recently,': [0], 'convolutional': [1, 23, 55], 'neural': [2, 24], 'networks': [3, 25], 'have': [4], 'demonstrated': [5], 'excellent': [6], 'performance': [7, 100], 'on': [8, 74, 85], 'various': [9], 'visual': [10], 'tasks,': [11], 'including': [12], 'the': [13, 38, 41, 51, 54, 57, 61, 66, 93, 111], 'classification': [14, 99], 'of': [15, 40], 'common': [16], 'two-dimensional': [17], 'images.': [18], 'In': [19], 'this': [20], 'paper,': [21], 'deep': [22, 113], 'are': [26, 50, 72], 'employed': [27], 'to': [28, 78], 'classify': [29], 'hyperspectral': [30, 87], 'images': [31], 'directly': [32], 'in': [33], 'spectral': [34, 76], 'domain.': [35], 'More': [36], 'specifically,': [37], 'architecture': [39], 'proposed': [42, 94], 'classifier': [43], 'contains': [44], 'five': [45, 70], 'layers': [46, 71], 'with': [47], 'weights': [48], 'which': [49], 'input': [52], 'layer,': [53, 56, 60, 64], 'max': [58], 'pooling': [59], 'full': [62], 'connection': [63], 'and': [65, 110], 'output': [67], 'layer.': [68], 'These': [69], 'implemented': [73], 'each': [75], 'signature': [77], 'discriminate': [79], 'against': [80], 'others.': [81], 'Experimental': [82], 'results': [83], 'based': [84], 'several': [86], 'image': [88], 'data': [89], 'sets': [90], 'demonstrate': [91], 'that': [92], 'method': [95], 'can': [96], 'achieve': [97], 'better': [98], 'than': [101], 'some': [102], 'traditional': [103], 'methods,': [104], 'such': [105], 'as': [106], 'support': [107], 'vector': [108], 'machines': [109], 'conventional': [112], 'learning-based': [114], 'methods.': [115]}",2015,"['Hyperspectral imaging', 'Convolutional neural network', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Computer science', 'Classifier (UML)', 'Pooling', 'Deep learning', 'Layer (electronics)', 'Contextual image classification', 'Support vector machine', 'Image (mathematics)', 'Materials science', 'Composite material']","Recently, convolutional neural networks have demonstrated excellent performance on various visual tasks, including the classification of common two-dimensional images. In this paper, deep convolutional neural networks are employed to classify hyperspectral images directly in spectral domain. More specifically, the architecture of the proposed classifier contains five layers with weights which are the input layer, the convolutional layer, the max pooling layer, the full connection layer, and the output layer. These five layers are implemented on each spectral signature to discriminate against others. Experimental results based on several hyperspectral image data sets demonstrate that the proposed method can achieve better classification performance than some traditional methods, such as support vector machines and the conventional deep learning-based methods."
https://openalex.org/W4319988532,Progressive Neural Networks,"{'Learning': [0], 'to': [1, 17, 35, 45], 'solve': [2], 'complex': [3], 'sequences': [4], 'of': [5, 58, 97], 'tasks--while': [6], 'both': [7, 90], 'leveraging': [8], 'transfer': [9, 87], 'and': [10, 37, 63, 67, 77, 93], 'avoiding': [11], 'catastrophic': [12], 'forgetting--remains': [13], 'a': [14, 26, 55, 80], 'key': [15], 'obstacle': [16], 'achieving': [18], 'human-level': [19], 'intelligence.': [20], 'The': [21], 'progressive': [22], 'networks': [23], 'approach': [24], 'represents': [25], 'step': [27], 'forward': [28], 'in': [29], 'this': [30, 51], 'direction:': [31], 'they': [32], 'are': [33], 'immune': [34], 'forgetting': [36], 'can': [38], 'leverage': [39], 'prior': [40], 'knowledge': [41], 'via': [42], 'lateral': [43], 'connections': [44], 'previously': [46], 'learned': [47, 99], 'features.': [48], 'We': [49], 'evaluate': [50], 'architecture': [52], 'extensively': [53], 'on': [54, 75], 'wide': [56], 'variety': [57], 'reinforcement': [59], 'learning': [60], 'tasks': [61], '(Atari': [62], '3D': [64], 'maze': [65], 'games),': [66], 'show': [68], 'that': [69, 86], 'it': [70], 'outperforms': [71], 'common': [72], 'baselines': [73], 'based': [74], 'pretraining': [76], 'finetuning.': [78], 'Using': [79], 'novel': [81], 'sensitivity': [82], 'measure,': [83], 'we': [84], 'demonstrate': [85], 'occurs': [88], 'at': [89], 'low-level': [91], 'sensory': [92], 'high-level': [94], 'control': [95], 'layers': [96], 'the': [98], 'policy.': [100]}",2016,"['Forgetting', 'Leverage (statistics)', 'Computer science', 'Reinforcement learning', 'Artificial intelligence', 'Transfer of learning', 'Machine learning', 'Artificial neural network', 'Key (lock)', 'Cognitive psychology', 'Psychology', 'Computer security']","Learning to solve complex sequences of tasks--while both leveraging transfer and avoiding catastrophic forgetting--remains a key obstacle to achieving human-level intelligence. The progressive networks approach represents a step forward in this direction: they are immune to forgetting and can leverage prior knowledge via lateral connections to previously learned features. We evaluate this architecture extensively on a wide variety of reinforcement learning tasks (Atari and 3D maze games), and show that it outperforms common baselines based on pretraining and finetuning. Using a novel sensitivity measure, we demonstrate that transfer occurs at both low-level sensory and high-level control layers of the learned policy."
https://openalex.org/W2951266961,Weight Uncertainty in Neural Networks,"{'We': [0, 49, 65], 'introduce': [1], 'a': [2, 11, 18, 31], 'new,': [3], 'efficient,': [4], 'principled': [5, 53], 'and': [6, 85], 'backpropagation-compatible': [7], 'algorithm': [8], 'for': [9], 'learning': [10], 'probability': [12], 'distribution': [13], 'on': [14, 45, 62], 'the': [15, 27, 36, 41, 46, 69, 73, 95], 'weights': [16, 28, 74], 'of': [17, 55], 'neural': [19], 'network,': [20], 'called': [21], 'Bayes': [22], 'by': [23, 29], 'Backprop.': [24], 'It': [25], 'regularises': [26], 'minimising': [30], 'compression': [32], 'cost,': [33], 'known': [34], 'as': [35], 'variational': [37], 'free': [38], 'energy': [39], 'or': [40], 'expected': [42], 'lower': [43], 'bound': [44], 'marginal': [47], 'likelihood.': [48], 'show': [50], 'that': [51], 'this': [52, 87], 'kind': [54], 'regularisation': [56], 'yields': [57], 'comparable': [58], 'performance': [59], 'to': [60, 78, 93], 'dropout': [61], 'MNIST': [63], 'classification.': [64], 'then': [66], 'demonstrate': [67], 'how': [68, 86], 'learnt': [70], 'uncertainty': [71, 89], 'in': [72, 81, 98], 'can': [75, 90], 'be': [76, 91], 'used': [77, 92], 'improve': [79], 'generalisation': [80], 'non-linear': [82], 'regression': [83], 'problems,': [84], 'weight': [88], 'drive': [94], 'exploration-exploitation': [96], 'trade-off': [97], 'reinforcement': [99], 'learning.': [100]}",2015,"['MNIST database', 'Dropout (neural networks)', 'Backpropagation', 'Artificial neural network', 'Computer science', 'Artificial intelligence', 'Reinforcement learning', 'Upper and lower bounds', ""Bayes' theorem"", 'Energy (signal processing)', 'Machine learning', 'Mathematical optimization', 'Bayesian probability', 'Mathematics', 'Statistics', 'Mathematical analysis']","We introduce a new, efficient, principled and backpropagation-compatible algorithm for learning a probability distribution on the weights of a neural network, called Bayes by Backprop. It regularises the weights by minimising a compression cost, known as the variational free energy or the expected lower bound on the marginal likelihood. We show that this principled kind of regularisation yields comparable performance to dropout on MNIST classification. We then demonstrate how the learnt uncertainty in the weights can be used to improve generalisation in non-linear regression problems, and how this weight uncertainty can be used to drive the exploration-exploitation trade-off in reinforcement learning."
https://openalex.org/W2798701005,All-optical machine learning using diffractive deep neural networks,"{'All-optical': [0], 'deep': [1], 'learning': [2, 4, 42], 'Deep': [3], 'uses': [5, 44], 'multilayered': [6, 27], 'artificial': [7, 69], 'neural': [8, 28, 70], 'networks': [9, 29], 'to': [10, 67, 76], 'learn': [11], 'digitally': [12], 'from': [13], 'large': [14], 'datasets.': [15], 'It': [16], 'then': [17], 'performs': [18], 'advanced': [19], 'identification': [20], 'and': [21, 52], 'classification': [22], 'tasks.': [23], 'To': [24], 'date,': [25], 'these': [26], 'have': [30], 'been': [31], 'implemented': [32], 'on': [33], 'a': [34], 'computer.': [35], 'Lin': [36], 'et': [37], 'al.': [38], 'demonstrate': [39], 'all-optical': [40], 'machine': [41], 'that': [43, 48, 72], 'passive': [45], 'optical': [46, 64], 'components': [47], 'can': [49, 73], 'be': [50, 74], 'patterned': [51], 'fabricated': [53], 'with': [54], '3D-printing.': [55], 'Their': [56], 'hardware': [57], 'approach': [58], 'comprises': [59], 'stacked': [60], 'layers': [61], 'of': [62, 83], 'diffractive': [63], 'elements': [65], 'analogous': [66], 'an': [68], 'network': [71], 'trained': [75], 'execute': [77], 'complex': [78], 'functions': [79], 'at': [80], 'the': [81], 'speed': [82], 'light.': [84], 'Science': [85], ',': [86], 'this': [87], 'issue': [88], 'p.': [89], '1004': [90]}",2018,"['Computer science', 'Deep learning', 'Artificial intelligence', 'Artificial neural network', 'Feature (linguistics)', 'Lithography', 'Deep neural networks', 'Pattern recognition (psychology)', 'Computer architecture', 'Computer vision', 'Materials science', 'Optoelectronics', 'Linguistics', 'Philosophy']","All-optical deep learning Deep learning uses multilayered artificial neural networks to learn digitally from large datasets. It then performs advanced identification and classification tasks. To date, these multilayered neural networks have been implemented on a computer. Lin et al. demonstrate all-optical machine learning that uses passive optical components that can be patterned and fabricated with 3D-printing. Their hardware approach comprises stacked layers of diffractive optical elements analogous to an artificial neural network that can be trained to execute complex functions at the speed of light. Science , this issue p. 1004"
https://openalex.org/W2766856748,Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties,"{'The': [0], 'use': [1], 'of': [2, 10, 22, 65, 76, 86, 96, 132], 'machine': [3], 'learning': [4], 'methods': [5], 'for': [6, 92, 146], 'accelerating': [7], 'the': [8, 27, 33, 63, 68, 120], 'design': [9], 'crystalline': [11, 77], 'materials': [12, 147], 'usually': [13], 'requires': [14], 'manually': [15], 'constructed': [16], 'feature': [17], 'vectors': [18], 'or': [19, 39], 'complex': [20], 'transformation': [21], 'atom': [23], 'coordinates': [24], 'to': [25, 35, 43, 57, 126, 142], 'input': [26], 'crystal': [28, 37, 51], 'structure,': [29], 'which': [30], 'either': [31], 'constrains': [32], 'model': [34], 'certain': [36], 'types': [38, 101], 'makes': [40], 'it': [41], 'difficult': [42], 'provide': [44], 'chemical': [45, 124], 'insights.': [46], 'Here,': [47], 'we': [48, 134], 'develop': [49], 'a': [50, 71, 82], 'graph': [52], 'convolutional': [53], 'neural': [54], 'networks': [55], 'framework': [56, 113], 'directly': [58], 'learn': [59], 'material': [60], 'properties': [61, 91, 95], 'from': [62, 122], 'connection': [64], 'atoms': [66], 'in': [67], 'crystal,': [69], 'providing': [70], 'universal': [72], 'and': [73, 102], 'interpretable': [74, 115], 'representation': [75], 'materials.': [78], 'Our': [79], 'method': [80], 'provides': [81], 'highly': [83], 'accurate': [84], 'prediction': [85], 'density': [87], 'functional': [88], 'theory': [89], 'calculated': [90], 'eight': [93], 'different': [94], 'crystals': [97], 'with': [98, 107], 'various': [99], 'structure': [100], 'compositions': [103], 'after': [104], 'being': [105], 'trained': [106], '10^{4}': [108], 'data': [109], 'points.': [110], 'Further,': [111], 'our': [112], 'is': [114], 'because': [116], 'one': [117], 'can': [118, 139], 'extract': [119], 'contributions': [121], 'local': [123], 'environments': [125], 'global': [127], 'properties.': [128], 'Using': [129], 'an': [130], 'example': [131], 'perovskites,': [133], 'show': [135], 'how': [136], 'this': [137], 'information': [138], 'be': [140], 'utilized': [141], 'discover': [143], 'empirical': [144], 'rules': [145], 'design.': [148]}",2018,"['Computer science', 'Convolutional neural network', 'Crystal (programming language)', 'Representation (politics)', 'Graph', 'Crystal structure', 'Graph rewriting', 'Artificial neural network', 'Crystal structure prediction', 'Atom (system on chip)', 'Transformation (genetics)', 'Artificial intelligence', 'Theoretical computer science', 'Algorithm', 'Chemistry', 'Crystallography', 'Gene', 'Biochemistry', 'Politics', 'Embedded system', 'Programming language', 'Political science', 'Law']","The use of machine learning methods for accelerating the design of crystalline materials usually requires manually constructed feature vectors or complex transformation of atom coordinates to input the crystal structure, which either constrains the model to certain crystal types or makes it difficult to provide chemical insights. Here, we develop a crystal graph convolutional neural networks framework to directly learn material properties from the connection of atoms in the crystal, providing a universal and interpretable representation of crystalline materials. Our method provides a highly accurate prediction of density functional theory calculated properties for eight different properties of crystals with various structure types and compositions after being trained with 10^{4} data points. Further, our framework is interpretable because one can extract the contributions from local chemical environments to global properties. Using an example of perovskites, we show how this information can be utilized to discover empirical rules for materials design."
https://openalex.org/W2809090039,Neural Tangent Kernel: Convergence and Generalization in Neural Networks,"{'At': [0], 'initialization,': [1], 'artificial': [2], 'neural': [3], 'networks': [4], '(ANNs)': [5], 'are': [6], 'equivalent': [7], 'to': [8, 18, 55, 71, 88, 112, 127, 148, 219, 245], 'Gaussian': [9], 'processes': [10], 'in': [11, 69, 106, 133, 188], 'the': [12, 24, 42, 47, 59, 63, 72, 79, 90, 96, 107, 129, 142, 149, 152, 157, 160, 164, 169, 172, 180, 189, 192, 208, 214, 220, 233, 246], 'infinite-width': [13, 108, 190, 247], 'limit,': [14, 191], 'thus': [15], 'connecting': [16], 'them': [17], 'kernel': [19, 60, 85, 116, 210], 'methods.': [20], 'We': [21, 155, 176], 'prove': [22, 156], 'that': [23, 187], 'evolution': [25], 'of': [26, 44, 62, 93, 131, 137, 141, 151, 159, 182, 213], 'an': [27, 45, 113], 'ANN': [28], 'during': [29, 38, 104, 121, 201], 'training': [30, 130, 143], 'can': [31, 144], 'also': [32], 'be': [33, 146], 'described': [34], 'by': [35], 'a': [36, 76, 197, 224], 'kernel:': [37, 78], 'gradient': [39, 61], 'descent': [40], 'on': [41, 168, 179], 'parameters': [43], 'ANN,': [46], 'network': [48, 193], 'function': [49, 134, 194], '$f_θ$': [50, 195], '(which': [51, 66], 'maps': [52], 'input': [53, 215], 'vectors': [54], 'output': [56], 'vectors)': [57], 'follows': [58, 196], 'functional': [64], 'cost': [65], 'is': [67, 86, 98, 166, 174, 205], 'convex,': [68], 'contrast': [70], 'parameter': [73, 138], 'cost)': [74], 'w.r.t.': [75], 'new': [77], 'Neural': [80], 'Tangent': [81], 'Kernel': [82], '(NTK).': [83], 'This': [84, 123], 'central': [87], 'describe': [89], 'generalization': [91], 'features': [92], 'ANNs.': [94], 'While': [95], 'NTK': [97, 162, 234], 'random': [99], 'at': [100], 'initialization': [101], 'and': [102, 117, 171, 185, 242], 'varies': [103], 'training,': [105], 'limit': [109], 'it': [110, 118, 125, 244], 'converges': [111], 'explicit': [114], 'limiting': [115, 153, 161], 'stays': [119], 'constant': [120], 'training.': [122, 202], 'makes': [124], 'possible': [126], 'study': [128, 232], 'ANNs': [132], 'space': [135], 'instead': [136], 'space.': [139], 'Convergence': [140], 'then': [145, 177], 'related': [147], 'positive-definiteness': [150, 158], 'NTK.': [154], 'when': [163], 'data': [165, 216], 'supported': [167], 'sphere': [170], 'non-linearity': [173], 'non-polynomial.': [175], 'focus': [178], 'setting': [181], 'least-squares': [183], 'regression': [184], 'show': [186], 'linear': [198], 'differential': [199], 'equation': [200], 'The': [203], 'convergence': [204], 'fastest': [206], 'along': [207], 'largest': [209], 'principal': [211], 'components': [212], 'with': [217], 'respect': [218], 'NTK,': [221], 'hence': [222], 'suggesting': [223], 'theoretical': [225], 'motivation': [226], 'for': [227, 239], 'early': [228], 'stopping.': [229], 'Finally': [230], 'we': [231], 'numerically,': [235], 'observe': [236], 'its': [237], 'behavior': [238], 'wide': [240], 'networks,': [241], 'compare': [243], 'limit.': [248]}",2018,"['Mathematics', 'Kernel (algebra)', 'Artificial neural network', 'Gradient descent', 'Initialization', 'Applied mathematics', 'Variable kernel density estimation', 'Kernel method', 'Limit (mathematics)', 'Overfitting', 'Mathematical analysis', 'Computer science', 'Artificial intelligence', 'Combinatorics', 'Support vector machine', 'Programming language']","At initialization, artificial neural networks (ANNs) are equivalent to Gaussian processes in the infinite-width limit, thus connecting them to kernel methods. We prove that the evolution of an ANN during training can also be described by a kernel: during gradient descent on the parameters of an ANN, the network function $f_θ$ (which maps input vectors to output vectors) follows the kernel gradient of the functional cost (which is convex, in contrast to the parameter cost) w.r.t. a new kernel: the Neural Tangent Kernel (NTK). This kernel is central to describe the generalization features of ANNs. While the NTK is random at initialization and varies during training, in the infinite-width limit it converges to an explicit limiting kernel and it stays constant during training. This makes it possible to study the training of ANNs in function space instead of parameter space. Convergence of the training can then be related to the positive-definiteness of the limiting NTK. We prove the positive-definiteness of the limiting NTK when the data is supported on the sphere and the non-linearity is non-polynomial. We then focus on the setting of least-squares regression and show that in the infinite-width limit, the network function $f_θ$ follows a linear differential equation during training. The convergence is fastest along the largest kernel principal components of the input data with respect to the NTK, hence suggesting a theoretical motivation for early stopping. Finally we study the NTK numerically, observe its behavior for wide networks, and compare it to the infinite-width limit."
https://openalex.org/W2016415759,"Fuzzy logic, neural networks, and soft computing","{'article': [0], 'Free': [1], 'Access': [2], 'Share': [3], 'on': [4, 81], 'Fuzzy': [5], 'logic,': [6], 'neural': [7], 'networks,': [8], 'and': [9, 58], 'soft': [10], 'computing': [11], 'Author:': [12], 'Lotfi': [13], 'A.': [14], 'Zadeh': [15], 'Univ.': [16, 20], 'of': [17, 21, 30], 'California,': [18, 22], 'Berkeley': [19], 'BerkeleyView': [23], 'Profile': [24], 'Authors': [25], 'Info': [26], '&': [27], 'Claims': [28], 'Communications': [29], 'the': [31, 82], 'ACMVolume': [32], '37Issue': [33], '3March': [34], '1994pp': [35], '77–84https://doi.org/10.1145/175247.175255Published:01': [36], 'March': [37], '1994Publication': [38], 'History': [39], '1,090citation7,848DownloadsMetricsTotal': [40], 'Citations1,090Total': [41], 'Downloads7,848Last': [42], '12': [43], 'Months265Last': [44], '6': [45], 'weeks18': [46], 'Get': [47], 'Citation': [48, 50, 87], 'AlertsNew': [49, 86], 'Alert': [51], 'added!This': [52], 'alert': [53, 78], 'has': [54, 73], 'been': [55, 74], 'successfully': [56], 'added': [57], 'will': [59, 63], 'be': [60, 64], 'sent': [61], 'to:You': [62], 'notified': [65], 'whenever': [66], 'a': [67, 99], 'record': [68], 'that': [69], 'you': [70], 'have': [71], 'chosen': [72], 'cited.To': [75], 'manage': [76], 'your': [77, 92], 'preferences,': [79], 'click': [80], 'button': [83], 'below.Manage': [84], 'my': [85], 'Alert!Please': [88], 'log': [89], 'in': [90], 'to': [91, 95, 97], 'account': [93], 'Save': [94], 'BinderSave': [96], 'BinderCreate': [98], 'New': [100], 'BinderNameCancelCreateExport': [101], 'CitationPublisher': [102], 'SiteeReaderPDF': [103]}",1994,"['Soft computing', 'Citation', 'Computer science', 'Fuzzy logic', 'Artificial neural network', 'Artificial intelligence', 'World Wide Web']","article Free Access Share on Fuzzy logic, neural networks, and soft computing Author: Lotfi A. Zadeh Univ. of California, Berkeley Univ. of California, BerkeleyView Profile Authors Info & Claims Communications of the ACMVolume 37Issue 3March 1994pp 77–84https://doi.org/10.1145/175247.175255Published:01 March 1994Publication History 1,090citation7,848DownloadsMetricsTotal Citations1,090Total Downloads7,848Last 12 Months265Last 6 weeks18 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF"
https://openalex.org/W1825675169,Understanding Neural Networks Through Deep Visualization,"{'Recent': [0], 'years': [1], 'have': [2, 101], 'produced': [3, 80, 147], 'great': [4], 'advances': [5], 'in': [6, 16, 46, 110, 138], 'training': [7, 17], 'large,': [8], 'deep': [9], 'neural': [10, 19, 63], 'networks': [11, 20], '(DNNs),': [12], 'including': [13], 'notable': [14], 'successes': [15], 'convolutional': [18], '(convnets)': [21], 'to': [22, 112, 160], 'recognize': [23], 'natural': [24], 'images.': [25], 'However,': [26], 'our': [27], 'understanding': [28], 'of': [29, 56, 84, 132, 144], 'how': [30, 120], 'these': [31], 'models': [32], 'work,': [33], 'especially': [34], 'what': [35], 'computations': [36], 'they': [37], 'perform': [38], 'at': [39, 105, 129], 'intermediate': [40], 'layers,': [41], 'has': [42], 'lagged': [43], 'behind.': [44], 'Progress': [45], 'the': [47, 54, 78], 'field': [48], 'will': [49], 'be': [50], 'further': [51], 'accelerated': [52], 'by': [53], 'development': [55], 'better': [57], 'tools': [58, 69, 168], 'for': [59], 'visualizing': [60, 127], 'and': [61, 172], 'interpreting': [62], 'nets.': [64], 'We': [65, 100], 'introduce': [66, 153], 'two': [67], 'such': [68], 'here.': [70], 'The': [71, 123], 'first': [72], 'is': [73], 'a': [74, 85, 96, 133, 175], 'tool': [75, 125], 'that': [76, 103, 108, 158], 'visualizes': [77], 'activations': [79, 107], 'on': [81, 174], 'each': [82, 130], 'layer': [83, 131], 'trained': [86], 'convnet': [87, 177], 'as': [88], 'it': [89], 'processes': [90], 'an': [91], 'image': [92, 139], 'or': [93], 'video': [94], '(e.g.': [95], 'live': [97, 106], 'webcam': [98], 'stream).': [99], 'found': [102], 'looking': [104], 'change': [109], 'response': [111], 'user': [113], 'input': [114], 'helps': [115], 'build': [116], 'valuable': [117], 'intuitions': [118], 'about': [119], 'convnets': [121], 'work.': [122], 'second': [124], 'enables': [126], 'features': [128], 'DNN': [134], 'via': [135], 'regularized': [136], 'optimization': [137], 'space.': [140], 'Because': [141], 'previous': [142], 'versions': [143], 'this': [145], 'idea': [146], 'less': [148], 'recognizable': [149], 'images,': [150], 'here': [151], 'we': [152], 'several': [154], 'new': [155], 'regularization': [156], 'methods': [157], 'combine': [159], 'produce': [161], 'qualitatively': [162], 'clearer,': [163], 'more': [164], 'interpretable': [165], 'visualizations.': [166], 'Both': [167], 'are': [169], 'open': [170], 'source': [171], 'work': [173], 'pre-trained': [176], 'with': [178], 'minimal': [179], 'setup.': [180]}",2015,"['Visualization', 'Artificial neural network', 'Computer science', 'Deep neural networks', 'Artificial intelligence', 'Data science']","Recent years have produced great advances in training large, deep neural networks (DNNs), including notable successes in training convolutional neural networks (convnets) to recognize natural images. However, our understanding of how these models work, especially what computations they perform at intermediate layers, has lagged behind. Progress in the field will be further accelerated by the development of better tools for visualizing and interpreting neural nets. We introduce two such tools here. The first is a tool that visualizes the activations produced on each layer of a trained convnet as it processes an image or video (e.g. a live webcam stream). We have found that looking at live activations that change in response to user input helps build valuable intuitions about how convnets work. The second tool enables visualizing features at each layer of a DNN via regularized optimization in image space. Because previous versions of this idea produced less recognizable images, here we introduce several new regularization methods that combine to produce qualitatively clearer, more interpretable visualizations. Both tools are open source and work on a pre-trained convnet with minimal setup."
https://openalex.org/W1828163288,Sequence Transduction with Recurrent Neural Networks,"{'Many': [0], 'machine': [1, 18], 'learning': [2, 40, 72, 79], 'tasks': [3], 'can': [4], 'be': [5], 'expressed': [6], 'as': [7, 59], 'the': [8, 33, 44, 90, 105, 108, 120, 123, 166], 'transformation---or': [9], '\\emph{transduction}---of': [10], 'input': [11, 45, 91, 150], 'sequences': [12, 48, 94], 'into': [13, 152], 'output': [14, 47, 93, 124, 156], 'sequences:': [15], 'speech': [16, 168], 'recognition,': [17], 'translation,': [19], 'protein': [20], 'secondary': [21], 'structure': [22], 'prediction': [23], 'and': [24, 46, 62, 92], 'text-to-speech': [25], 'to': [26, 41, 55, 95, 147], 'name': [27], 'but': [28], 'a': [29, 50, 69, 86, 100], 'few.': [30], 'One': [31], 'of': [32, 78, 112, 122], 'key': [34], 'challenges': [35], 'in': [36, 49, 144], 'sequence': [37, 71, 114, 125, 135, 151], 'transduction': [38, 115, 136], 'is': [39, 53, 99, 107, 126, 143], 'represent': [42], 'both': [43], 'way': [51], 'that': [52, 74, 142], 'invariant': [54], 'sequential': [56], 'distortions': [57], 'such': [58, 80], 'shrinking,': [60], 'stretching': [61], 'translating.': [63], 'Recurrent': [64], 'neural': [65], 'networks': [66], '(RNNs)': [67], 'are': [68, 163], 'powerful': [70], 'architecture': [73], 'has': [75], 'proven': [76], 'capable': [77], 'representations.': [81], 'However': [82], 'RNNs': [83], 'traditionally': [84], 'require': [85], 'pre-defined': [87], 'alignment': [88, 106], 'between': [89], 'perform': [96], 'transduction.': [97], 'This': [98, 129], 'severe': [101], 'limitation': [102], 'since': [103], '\\emph{finding}': [104], 'most': [109], 'difficult': [110], 'aspect': [111], 'many': [113], 'problems.': [116], 'Indeed,': [117], 'even': [118], 'determining': [119], 'length': [121], 'often': [127], 'challenging.': [128], 'paper': [130], 'introduces': [131], 'an': [132], 'end-to-end,': [133], 'probabilistic': [134], 'system,': [137], 'based': [138], 'entirely': [139], 'on': [140, 165], 'RNNs,': [141], 'principle': [145], 'able': [146], 'transform': [148], 'any': [149, 153], 'finite,': [154], 'discrete': [155], 'sequence.': [157], 'Experimental': [158], 'results': [159], 'for': [160], 'phoneme': [161], 'recognition': [162], 'provided': [164], 'TIMIT': [167], 'corpus.': [169]}",2012,"['Transduction (biophysics)', 'TIMIT', 'Sequence (biology)', 'Recurrent neural network', 'Sequence learning', 'Computer science', 'Artificial intelligence', 'Speech recognition', 'Artificial neural network', 'Hidden Markov model', 'Biology', 'Genetics', 'Biochemistry']","Many machine learning tasks can be expressed as the transformation---or \emph{transduction}---of input sequences into output sequences: speech recognition, machine translation, protein secondary structure prediction and text-to-speech to name but a few. One of the key challenges in sequence transduction is learning to represent both the input and output sequences in a way that is invariant to sequential distortions such as shrinking, stretching and translating. Recurrent neural networks (RNNs) are a powerful sequence learning architecture that has proven capable of learning such representations. However RNNs traditionally require a pre-defined alignment between the input and output sequences to perform transduction. This is a severe limitation since \emph{finding} the alignment is the most difficult aspect of many sequence transduction problems. Indeed, even determining the length of the output sequence is often challenging. This paper introduces an end-to-end, probabilistic sequence transduction system, based entirely on RNNs, that is in principle able to transform any input sequence into any finite, discrete output sequence. Experimental results for phoneme recognition are provided on the TIMIT speech corpus."
https://openalex.org/W2905224888,Graph Neural Networks: A Review of Methods and Applications,"{'Lots': [0], 'of': [1, 57, 63, 87, 95, 101, 142], 'learning': [2, 19, 41, 124], 'tasks': [3], 'require': [4], 'dealing': [5], 'with': [6], 'graph': [7, 34, 73, 105, 109, 113], 'data': [8, 44], 'which': [9, 70], 'contains': [10], 'rich': [11], 'relation': [12], 'information': [13], 'among': [14], 'elements.': [15], 'Modeling': [16], 'physics': [17], 'systems,': [18], 'molecular': [20], 'fingerprints,': [21], 'predicting': [22], 'protein': [23], 'interface,': [24], 'and': [25, 47, 59, 138, 149], 'classifying': [26], 'diseases': [27], 'demand': [28], 'a': [29, 131], 'model': [30], 'to': [31], 'learn': [32], 'from': [33, 42], 'inputs.': [35], 'In': [36, 97, 126], 'other': [37], 'domains': [38], 'such': [39, 103], 'as': [40, 104], 'non-structural': [43], 'like': [45], 'texts': [46], 'images,': [48], 'reasoning': [49, 74], 'on': [50, 121], 'extracted': [51], 'structures': [52], '(like': [53], 'the': [54, 60, 85, 93, 140, 147], 'dependency': [55], 'trees': [56], 'sentences': [58], 'scene': [61], 'graphs': [62, 88], 'images)': [64], 'is': [65], 'an': [66], 'important': [67], 'research': [68], 'topic': [69], 'also': [71], 'needs': [72], 'models.': [75], 'Graph': [76], 'neural': [77, 81], 'networks': [78], '(GNNs)': [79], 'are': [80], 'models': [82, 137], 'that': [83], 'capture': [84], 'dependence': [86], 'via': [89], 'message': [90], 'passing': [91], 'between': [92], 'nodes': [94], 'graphs.': [96], 'recent': [98], 'years,': [99], 'variants': [100, 141], 'GNNs': [102], 'convolutional': [106], 'network': [107, 111, 115], '(GCN),': [108], 'attention': [110], '(GAT),': [112], 'recurrent': [114], '(GRN)': [116], 'have': [117], 'demonstrated': [118], 'ground-breaking': [119], 'performances': [120], 'many': [122], 'deep': [123], 'tasks.': [125], 'this': [127], 'survey,': [128], 'we': [129], 'propose': [130, 150], 'general': [132], 'design': [133], 'pipeline': [134], 'for': [135, 154], 'GNN': [136], 'discuss': [139], 'each': [143], 'component,': [144], 'systematically': [145], 'categorize': [146], 'applications,': [148], 'four': [151], 'open': [152], 'problems': [153], 'future': [155], 'research.': [156]}",2018,"['Computer science', 'Graph', 'Categorization', 'Artificial intelligence', 'Deep learning', 'Graph database', 'Theoretical computer science', 'Convolutional neural network', 'Machine learning']","Lots of learning tasks require dealing with graph data which contains rich relation information among elements. Modeling physics systems, learning molecular fingerprints, predicting protein interface, and classifying diseases demand a model to learn from graph inputs. In other domains such as learning from non-structural data like texts and images, reasoning on extracted structures (like the dependency trees of sentences and the scene graphs of images) is an important research topic which also needs graph reasoning models. Graph neural networks (GNNs) are neural models that capture the dependence of graphs via message passing between the nodes of graphs. In recent years, variants of GNNs such as graph convolutional network (GCN), graph attention network (GAT), graph recurrent network (GRN) have demonstrated ground-breaking performances on many deep learning tasks. In this survey, we propose a general design pipeline for GNN models and discuss the variants of each component, systematically categorize the applications, and propose four open problems for future research."
https://openalex.org/W2167224731,"ALVINN, an autonomous land vehicle in a neural network","{'Computer': [0], 'Science': [1], 'Department': [2]}",1990,"['Computer science', 'Task (project management)', 'Artificial neural network', 'Artificial intelligence', 'Computer vision', 'Real-time computing', 'Representation (politics)', 'Field (mathematics)', 'Simulation', 'Engineering', 'Pure mathematics', 'Political science', 'Mathematics', 'Systems engineering', 'Politics', 'Law']",Computer Science Department
https://openalex.org/W2607219512,Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks,"{'Although': [0], 'deep': [1], 'neural': [2], 'networks': [3], '(DNNs)': [4], 'have': [5, 43], 'achieved': [6], 'great': [7], 'success': [8, 47], 'in': [9, 87, 148], 'many\\ntasks,': [10], 'they': [11], 'can': [12, 58, 145], 'often': [13], 'be': [14, 59, 146], 'fooled': [15], 'by': [16, 21, 65], '\\\\emph{adversarial': [17], 'examples}': [18], 'that': [19, 80, 104], 'are\\ngenerated': [20], 'adding': [22], 'small': [23], 'but': [24, 42], 'purposeful': [25], 'distortions': [26], 'to': [27, 31, 61, 75, 82, 141, 152], 'natural': [28], 'examples.\\nPrevious': [29], 'studies': [30], 'defend': [32], 'against': [33, 157], 'adversarial': [34, 67], 'examples': [35, 111], 'mostly': [36], 'focused': [37], 'on\\nrefining': [38], 'the': [39, 71, 126], 'DNN': [40, 63, 97], 'models,': [41], 'either': [44], 'shown': [45], 'limited': [46], 'or': [48], 'required\\nexpensive': [49], 'computation.': [50], 'We': [51], 'propose': [52], 'a': [53, 91, 96, 149], 'new': [54], 'strategy,': [55], '\\\\emph{feature': [56], 'squeezing},\\nthat': [57], 'used': [60], 'harden': [62], 'models': [64], 'detecting': [66], 'examples.\\nFeature': [68], 'squeezing': [69, 109, 123], 'reduces': [70], 'search': [72], 'space': [73, 89], 'available': [74], 'an': [76], 'adversary': [77], 'by\\ncoalescing': [78], 'samples': [79], 'correspond': [81], 'many': [83], 'different': [84], 'feature': [85, 108, 122], 'vectors': [86], 'the\\noriginal': [88], 'into': [90], 'single': [92], 'sample.': [93], 'By': [94], 'comparing': [95], ""model's"": [98], 'prediction': [99], 'on\\nthe': [100], 'original': [101], 'input': [102], 'with': [103, 112], 'on': [105], 'squeezed': [106], 'inputs,': [107], 'detects\\nadversarial': [110], 'high': [113, 154], 'accuracy': [114], 'and': [115, 132, 144], 'few': [116], 'false': [117], 'positives.': [118], 'This': [119], 'paper\\nexplores': [120], 'two': [121], 'methods:': [124], 'reducing': [125], 'color': [127], 'bit': [128], 'depth': [129], 'of': [130], 'each\\npixel': [131], 'spatial': [133], 'smoothing.': [134], 'These': [135], 'simple': [136], 'strategies': [137], 'are': [138], 'inexpensive': [139], 'and\\ncomplementary': [140], 'other': [142], 'defenses,': [143], 'combined': [147], 'joint': [150], 'detection\\nframework': [151], 'achieve': [153], 'detection': [155], 'rates': [156], 'state-of-the-art': [158], 'attacks.\\n': [159]}",2018,"['Adversarial system', 'Feature (linguistics)', 'Computer science', 'Artificial intelligence', 'Smoothing', 'Feature vector', 'Artificial neural network', 'Deep neural networks', 'False positive paradox', 'Computation', 'Pattern recognition (psychology)', 'Pixel', 'Deep learning', 'Machine learning', 'Algorithm', 'Computer vision', 'Linguistics', 'Philosophy']","Although deep neural networks (DNNs) have achieved great success in many\ntasks, they can often be fooled by \\emph{adversarial examples} that are\ngenerated by adding small but purposeful distortions to natural examples.\nPrevious studies to defend against adversarial examples mostly focused on\nrefining the DNN models, but have either shown limited success or required\nexpensive computation. We propose a new strategy, \\emph{feature squeezing},\nthat can be used to harden DNN models by detecting adversarial examples.\nFeature squeezing reduces the search space available to an adversary by\ncoalescing samples that correspond to many different feature vectors in the\noriginal space into a single sample. By comparing a DNN model's prediction on\nthe original input with that on squeezed inputs, feature squeezing detects\nadversarial examples with high accuracy and few false positives. This paper\nexplores two feature squeezing methods: reducing the color bit depth of each\npixel and spatial smoothing. These simple strategies are inexpensive and\ncomplementary to other defenses, and can be combined in a joint detection\nframework to achieve high detection rates against state-of-the-art attacks.\n"
https://openalex.org/W3035035250,ACTIVATION FUNCTIONS IN NEURAL NETWORKS,"{'Artificial': [0, 95], 'Neural': [1, 96], 'Networks': [2], 'are': [3, 38, 58, 100], 'inspired': [4], 'from': [5, 24, 50], 'the': [6, 10, 16, 51, 55, 62, 68, 73, 77, 117], 'human': [7], 'brain': [8], 'and': [9, 21, 44, 65, 108, 113, 119], 'network': [11, 57], 'of': [12, 41, 54, 111], 'neurons': [13], 'present': [14], 'in': [15, 33, 106], 'brain.The': [17], 'information': [18], 'is': [19, 80], 'processed': [20], 'passed': [22, 59], 'on': [23, 60], 'one': [25], 'neuron': [26], 'to': [27, 46, 61, 67, 76, 83], 'another': [28], 'through': [29], 'neuro': [30], 'synaptic': [31], 'junctions.Similarly,': [32], 'artificial': [34], 'neural': [35, 56], 'networks': [36], 'there': [37], 'different': [39], 'layers': [40, 53, 64], 'cells': [42], 'arranged': [43], 'connected': [45], 'each': [47], 'other.The': [48], 'output/information': [49], 'inner': [52, 84], 'next': [63], 'finally': [66], 'outermost': [69], 'layer': [70, 79], 'which': [71], 'gives': [72], 'output.The': [74], 'input': [75], 'outer': [78], 'provided': [81], 'nonlinearity': [82], ""layers'"": [85], 'output': [86], 'so': [87], 'that': [88], 'it': [89], 'can': [90], 'be': [91], 'further': [92], 'processed.In': [93], 'an': [94], 'Network,': [97], 'activation': [98], 'functions': [99], 'very': [101], 'important': [102], 'as': [103], 'they': [104], 'help': [105], 'learning': [107], 'making': [109], 'sense': [110], 'non-linear': [112], 'complicated': [114], 'mappings': [115], 'between': [116], 'inputs': [118], 'corresponding': [120], 'outputs.': [121]}",2020,"['Artificial neural network', 'Physical neural network', 'Computer science', 'Types of artificial neural networks', 'Layer (electronics)', 'Nonlinear system', 'Artificial intelligence', 'Nervous system network models', 'Time delay neural network', 'Stochastic neural network', 'Topology (electrical circuits)', 'Mathematics', 'Physics', 'Materials science', 'Nanotechnology', 'Combinatorics', 'Quantum mechanics']","Artificial Neural Networks are inspired from the human brain and the network of neurons present in the brain.The information is processed and passed on from one neuron to another through neuro synaptic junctions.Similarly, in artificial neural networks there are different layers of cells arranged and connected to each other.The output/information from the inner layers of the neural network are passed on to the next layers and finally to the outermost layer which gives the output.The input to the outer layer is provided nonlinearity to inner layers' output so that it can be further processed.In an Artificial Neural Network, activation functions are very important as they help in learning and making sense of non-linear and complicated mappings between the inputs and corresponding outputs."
https://openalex.org/W2765424254,One Pixel Attack for Fooling Deep Neural Networks,"{'Recent': [0], 'research': [1], 'has': [2], 'revealed': [3], 'that': [4, 45, 86, 156, 190], 'the': [5, 22, 78, 89, 100, 130, 134, 139, 182], 'output': [6], 'of': [7, 74, 81, 88, 99, 174, 184], 'Deep': [8], 'Neural': [9], 'Networks': [10], '(DNN)': [11], 'can': [12, 41, 70, 106, 191], 'be': [13, 42, 107], 'easily': [14], 'altered': [15], 'by': [16, 115], 'adding': [17], 'relatively': [18], 'small': [19], 'perturbations': [20, 55], 'to': [21, 77, 109, 162], 'input': [23], 'vector.': [24], 'In': [25], 'this': [26], 'paper,': [27], 'we': [28, 46, 168], 'analyze': [29], 'an': [30, 33, 151, 171], 'attack': [31, 141], 'in': [32, 92, 150, 181], 'extremely': [34], 'limited': [35, 153], 'scenario': [36], 'where': [37], 'only': [38], 'one': [39, 112, 118], 'pixel': [40, 119], 'modified.': [43], 'For': [44], 'propose': [47], 'a': [48, 143], 'novel': [49], 'method': [50], 'for': [51, 200], 'generating': [52], 'one-pixel': [53], 'adversarial': [54, 64, 147, 185, 195], 'based': [56], 'on': [57, 125, 133, 146], 'differential': [58], 'evolution': [59], '(DE).': [60], 'It': [61], 'requires': [62], 'less': [63], 'information': [65], '(a': [66], 'black-box': [67], 'attack)': [68], 'and': [69, 97, 122], 'fool': [71], 'more': [72], 'types': [73], 'networks': [75, 199], 'due': [76], 'inherent': [79], 'features': [80], 'DE.': [82], 'The': [83], 'results': [84], 'show': [85, 129], '67.97%': [87], 'natural': [90], 'images': [91, 105], 'Kaggle': [93], 'CIFAR-10': [94, 136], 'test': [95, 104], 'dataset': [96], '16.04%': [98], 'ImageNet': [101], '(ILSVRC': [102], '2012)': [103], 'perturbed': [108], 'at': [110], 'least': [111], 'target': [113], 'class': [114], 'modifying': [116], 'just': [117], 'with': [120], '74.03%': [121], '22.91%': [123], 'confidence': [124], 'average.': [126], 'We': [127], 'also': [128, 160, 169], 'same': [131], 'vulnerability': [132], 'original': [135], 'dataset.': [137], 'Thus,': [138], 'proposed': [140], 'explores': [142], 'different': [144], 'take': [145], 'machine': [148, 186], 'learning': [149], 'extreme': [152], 'scenario,': [154], 'showing': [155], 'current': [157], 'DNNs': [158], 'are': [159], 'vulnerable': [161], 'such': [163], 'low': [164], 'dimension': [165], 'attacks.': [166], 'Besides,': [167], 'illustrate': [170], 'important': [172], 'application': [173], 'DE': [175], '(or': [176], 'broadly': [177], 'speaking,': [178], 'evolutionary': [179], 'computation)': [180], 'domain': [183], 'learning:': [187], 'creating': [188], 'tools': [189], 'effectively': [192], 'generate': [193], 'low-cost': [194], 'attacks': [196], 'against': [197], 'neural': [198], 'evaluating': [201], 'robustness.': [202]}",2019,[],"Recent research has revealed that the output of Deep Neural Networks (DNN) can be easily altered by adding relatively small perturbations to the input vector. In this paper, we analyze an attack in an extremely limited scenario where only one pixel can be modified. For that we propose a novel method for generating one-pixel adversarial perturbations based on differential evolution (DE). It requires less adversarial information (a black-box attack) and can fool more types of networks due to the inherent features of DE. The results show that 67.97% of the natural images in Kaggle CIFAR-10 test dataset and 16.04% of the ImageNet (ILSVRC 2012) test images can be perturbed to at least one target class by modifying just one pixel with 74.03% and 22.91% confidence on average. We also show the same vulnerability on the original CIFAR-10 dataset. Thus, the proposed attack explores a different take on adversarial machine learning in an extreme limited scenario, showing that current DNNs are also vulnerable to such low dimension attacks. Besides, we also illustrate an important application of DE (or broadly speaking, evolutionary computation) in the domain of adversarial machine learning: creating tools that can effectively generate low-cost adversarial attacks against neural networks for evaluating robustness."
https://openalex.org/W2753783305,Trojaning Attack on Neural Networks,"{'With': [0], 'the': [1, 33, 42, 64, 76, 88, 99, 111, 134, 141, 144, 162, 173, 178, 231], 'fast': [2], 'spread': [3], 'of': [4, 164, 222], 'machine': [5, 12], 'learning': [6, 13], 'techniques,': [7], 'sharing': [8], 'and': [9, 73, 167, 188, 208], 'adopting': [10], 'public': [11, 214], 'models': [14, 34, 47], 'become': [15], 'very': [16], 'popular.This': [17], 'gives': [18], 'attackers': [19], 'many': [20], 'new': [21], 'opportunities.In': [22], 'this': [23], 'paper,': [24], 'we': [25, 104, 130, 233], 'propose': [26], 'a': [27, 69, 169, 219, 226], 'trojaning': [28], 'attack': [29, 43, 184, 225], 'on': [30, 172, 213], 'neural': [31, 65], 'networks.As': [32], 'are': [35, 92, 137, 146], 'not': [36, 106, 132, 148], 'intuitive': [37], 'for': [38, 205], 'human': [39, 55], 'to': [40, 67, 83, 87, 108, 119, 124, 126, 139, 151, 160, 224], 'understand,': [41], 'features': [44], 'stealthiness.Deploying': [45], 'trojaned': [46, 190], 'can': [48, 192], 'cause': [49], 'various': [50], 'severe': [51], 'consequences': [52], 'including': [53], 'endangering': [54], 'lives': [56], '(in': [57], 'applications': [58, 159], 'like': [59], 'autonomous': [60], 'driving).We': [61], 'first': [62], 'inverse': [63], 'network': [66, 229], 'generate': [68], 'general': [70], 'trojan': [71, 100], 'trigger,': [72], 'then': [74], 'retrain': [75], 'model': [77], 'with': [78, 98, 110, 210], 'reversed': [79], 'engineered': [80], 'training': [81, 113], 'data': [82], 'inject': [84], 'malicious': [85, 90], 'behaviors': [86, 91, 191], 'model.The': [89], 'only': [93, 217], 'activated': [94], 'by': [95], 'inputs': [96], 'stamped': [97], 'trigger.In': [101], 'our': [102, 128, 165, 183], 'attack,': [103, 166], 'do': [105, 131], 'need': [107], 'tamper': [109], 'original': [112], 'process,': [114], 'which': [115], 'usually': [116, 147], 'takes': [117, 122, 218], 'weeks': [118], 'months.Instead,': [120], 'it': [121, 216], 'minutes': [123], 'hours': [125], 'apply': [127], 'attack.Also,': [129], 'require': [133], 'datasets': [135, 145], 'that': [136, 176, 182], 'used': [138], 'train': [140], 'model.In': [142, 230], 'practice,': [143], 'shared': [149], 'due': [150], 'privacy': [152], 'or': [153], 'copyright': [154], 'concerns.We': [155], 'use': [156], 'five': [157], 'different': [158], 'demonstrate': [161], 'power': [163], 'perform': [168], 'deep': [170], 'analysis': [171], 'possible': [174, 236], 'factors': [175], 'affect': [177], 'attack.The': [179], 'results': [180], 'show': [181], 'is': [185], 'highly': [186], 'effective': [187], 'efficient.The': [189], 'be': [193], 'successfully': [194], 'triggered': [195], '(with': [196], 'nearly': [197], '100%': [198], 'possibility)': [199], 'without': [200], 'affecting': [201], 'its': [202], 'test': [203], 'accuracy': [204, 212], 'normal': [206], 'input': [207], 'even': [209], 'better': [211], 'dataset.Also,': [215], 'small': [220], 'amount': [221], 'time': [223], 'complex': [227], 'neuron': [228], 'end,': [232], 'also': [234], 'discuss': [235], 'defense': [237], 'against': [238], 'such': [239], 'attacks.': [240]}",2018,"['Computer science', 'Trojan', 'Artificial neural network', 'Process (computing)', 'Computer security', 'Artificial intelligence', 'Machine learning', 'Deep learning', 'Operating system']","With the fast spread of machine learning techniques, sharing and adopting public machine learning models become very popular.This gives attackers many new opportunities.In this paper, we propose a trojaning attack on neural networks.As the models are not intuitive for human to understand, the attack features stealthiness.Deploying trojaned models can cause various severe consequences including endangering human lives (in applications like autonomous driving).We first inverse the neural network to generate a general trojan trigger, and then retrain the model with reversed engineered training data to inject malicious behaviors to the model.The malicious behaviors are only activated by inputs stamped with the trojan trigger.In our attack, we do not need to tamper with the original training process, which usually takes weeks to months.Instead, it takes minutes to hours to apply our attack.Also, we do not require the datasets that are used to train the model.In practice, the datasets are usually not shared due to privacy or copyright concerns.We use five different applications to demonstrate the power of our attack, and perform a deep analysis on the possible factors that affect the attack.The results show that our attack is highly effective and efficient.The trojaned behaviors can be successfully triggered (with nearly 100% possibility) without affecting its test accuracy for normal input and even with better accuracy on public dataset.Also, it only takes a small amount of time to attack a complex neuron network model.In the end, we also discuss possible defense against such attacks."
https://openalex.org/W2468907370,Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering,"{'In': [0], 'this': [1, 103], 'work,': [2], 'we': [3], 'are': [4, 21], 'interested': [5], 'in': [6, 45], 'generalizing': [7], 'convolutional': [8, 66], 'neural': [9], 'networks': [10], '(CNNs)': [11], 'from': [12], 'low-dimensional': [13], 'regular': [14], 'grids,': [15], 'where': [16], 'image,': [17], 'video': [18], 'and': [19, 58, 80, 97, 112], 'speech': [20], 'represented,': [22], 'to': [23, 62, 90, 108], 'high-dimensional': [24], 'irregular': [25], 'domains,': [26], 'such': [27], 'as': [28, 84], 'social': [29], 'networks,': [30], 'brain': [31], 'connectomes': [32], 'or': [33], ""words'"": [34], 'embedding,': [35], 'represented': [36], 'by': [37], 'graphs.': [38, 69, 116], 'We': [39], 'present': [40], 'a': [41], 'formulation': [42], 'of': [43, 48, 102], 'CNNs': [44], 'the': [46, 54, 71, 75, 100], 'context': [47], 'spectral': [49], 'graph': [50, 92], 'theory,': [51], 'which': [52], 'provides': [53], 'necessary': [55], 'mathematical': [56], 'background': [57], 'efficient': [59], 'numerical': [60], 'schemes': [61], 'design': [63], 'fast': [64], 'localized': [65], 'filters': [67], 'on': [68, 95, 115], 'Importantly,': [70], 'proposed': [72], 'technique': [73], 'offers': [74], 'same': [76], 'linear': [77], 'computational': [78], 'complexity': [79, 83], 'constant': [81], 'learning': [82, 106], 'classical': [85], 'CNNs,': [86], 'while': [87], 'being': [88], 'universal': [89], 'any': [91], 'structure.': [93], 'Experiments': [94], 'MNIST': [96], '20NEWS': [98], 'demonstrate': [99], 'ability': [101], 'novel': [104], 'deep': [105], 'system': [107], 'learn': [109], 'local,': [110], 'stationary,': [111], 'compositional': [113], 'features': [114]}",2016,"['MNIST database', 'Convolutional neural network', 'Computer science', 'Embedding', 'Theoretical computer science', 'Graph', 'Spectral graph theory', 'Context (archaeology)', 'Artificial intelligence', 'Deep learning', 'Algorithm', 'Line graph', 'Graph power', 'Paleontology', 'Biology']","In this work, we are interested in generalizing convolutional neural networks (CNNs) from low-dimensional regular grids, where image, video and speech are represented, to high-dimensional irregular domains, such as social networks, brain connectomes or words' embedding, represented by graphs. We present a formulation of CNNs in the context of spectral graph theory, which provides the necessary mathematical background and efficient numerical schemes to design fast localized convolutional filters on graphs. Importantly, the proposed technique offers the same linear computational complexity and constant learning complexity as classical CNNs, while being universal to any graph structure. Experiments on MNIST and 20NEWS demonstrate the ability of this novel deep learning system to learn local, stationary, and compositional features on graphs."
https://openalex.org/W1902934009,BinaryConnect: Training Deep Neural Networks with binary weights during propagations,"{'Deep': [0, 80], 'Neural': [1], 'Networks': [2], '(DNN)': [3], 'have': [4], 'achieved': [5], 'state-of-the-art': [6, 178], 'results': [7, 17, 179], 'in': [8, 72, 138, 158], 'a': [9, 66, 134, 140], 'wide': [10], 'range': [11], 'of': [12, 34, 76, 124, 128, 154], 'tasks,': [13], 'with': [14, 19, 142, 180], 'the': [15, 27, 40, 118, 125, 146, 155, 183], 'best': [16], 'obtained': [18], 'large': [20, 24], 'training': [21, 46, 139], 'sets': [22], 'and': [23, 47, 58, 74, 121, 148, 174, 187], 'models.': [25], 'In': [26, 39], 'past,': [28], 'GPUs': [29], 'enabled': [30], 'these': [31], 'breakthroughs': [32], 'because': [33], 'their': [35], 'greater': [36], 'computational': [37], 'speed.': [38], 'future,': [41], 'faster': [42], 'computation': [43], 'at': [44], 'both': [45], 'test': [48], 'time': [49], 'is': [50, 69], 'likely': [51], 'to': [52, 90, 103], 'be': [53], 'crucial': [54], 'for': [55, 59, 79], 'further': [56], 'progress': [57], 'consumer': [60], 'applications': [61], 'on': [62, 182], 'low-power': [63], 'devices.': [64], 'As': [65], 'result,': [67], 'there': [68], 'much': [70], 'interest': [71], 'research': [73], 'development': [75], 'dedicated': [77], 'hardware': [78, 106], 'Learning': [81], '(DL).': [82], 'Binary': [83], 'weights,': [84], 'i.e.,': [85], 'weights': [86, 144, 157], 'which': [87, 136, 159], 'are': [88, 117, 161], 'constrained': [89], 'only': [91], 'two': [92], 'possible': [93], 'values': [94], '(e.g.': [95], '-1': [96], 'or': [97], '1),': [98], 'would': [99], 'bring': [100], 'great': [101], 'benefits': [102], 'specialized': [104], 'DL': [105], 'by': [107, 112], 'replacing': [108], 'many': [109], 'multiply-accumulate': [110], 'operations': [111], 'simple': [113], 'accumulations,': [114], 'as': [115, 172], 'multipliers': [116], 'most': [119], 'space': [120], 'power-hungry': [122], 'components': [123], 'digital': [126], 'implementation': [127], 'neural': [129], 'networks.': [130], 'We': [131], 'introduce': [132], 'BinaryConnect,': [133], 'method': [135], 'consists': [137], 'DNN': [141], 'binary': [143], 'during': [145], 'forward': [147], 'backward': [149], 'propagations,': [150], 'while': [151], 'retaining': [152], 'precision': [153], 'stored': [156], 'gradients': [160], 'accumulated.': [162], 'Like': [163], 'other': [164], 'dropout': [165], 'schemes,': [166], 'we': [167, 175], 'show': [168], 'that': [169], 'BinaryConnect': [170, 181], 'acts': [171], 'regularizer': [173], 'obtain': [176], 'near': [177], 'permutation-invariant': [184], 'MNIST,': [185], 'CIFAR-10': [186], 'SVHN.': [188]}",2015,"['MNIST database', 'Computer science', 'Dropout (neural networks)', 'Artificial neural network', 'Deep neural networks', 'Binary number', 'Invariant (physics)', 'Computation', 'Range (aeronautics)', 'Artificial intelligence', 'Permutation (music)', 'Computer engineering', 'Simple (philosophy)', 'Deep learning', 'Algorithm', 'Machine learning', 'Arithmetic', 'Mathematics', 'Mathematical physics', 'Acoustics', 'Epistemology', 'Physics', 'Philosophy', 'Materials science', 'Composite material']","Deep Neural Networks (DNN) have achieved state-of-the-art results in a wide range of tasks, with the best results obtained with large training sets and large models. In the past, GPUs enabled these breakthroughs because of their greater computational speed. In the future, faster computation at both training and test time is likely to be crucial for further progress and for consumer applications on low-power devices. As a result, there is much interest in research and development of dedicated hardware for Deep Learning (DL). Binary weights, i.e., weights which are constrained to only two possible values (e.g. -1 or 1), would bring great benefits to specialized DL hardware by replacing many multiply-accumulate operations by simple accumulations, as multipliers are the most space and power-hungry components of the digital implementation of neural networks. We introduce BinaryConnect, a method which consists in training a DNN with binary weights during the forward and backward propagations, while retaining precision of the stored weights in which gradients are accumulated. Like other dropout schemes, we show that BinaryConnect acts as regularizer and we obtain near state-of-the-art results with BinaryConnect on the permutation-invariant MNIST, CIFAR-10 and SVHN."
https://openalex.org/W2899457523,Session-Based Recommendation with Graph Neural Networks,"{'The': [0], 'problem': [1], 'of': [2, 50, 61, 101, 122, 130], 'session-based': [3, 151], 'recommendation': [4, 152], 'aims': [5], 'to': [6, 29, 39, 106], 'predict': [7], 'user': [8, 24, 42], 'actions': [9], 'based': [10], 'on': [11, 92, 140], 'anonymous': [12], 'sessions.': [13], 'Previous': [14], 'methods': [15, 153], 'model': [16], 'a': [17, 20, 67], 'session': [18, 84, 94, 115, 132], 'as': [19, 88, 119], 'sequence': [21], 'and': [22, 46, 57, 126], 'estimate': [23], 'representations': [25, 28], 'besides': [26], 'item': [27, 55], 'make': [30], 'recommendations.': [31], 'Though': [32], 'achieved': [33], 'promising': [34], 'results,': [35], 'they': [36], 'are': [37, 86, 104], 'insufficient': [38], 'obtain': [40, 53], 'accurate': [41, 54], 'vectors': [43], 'in': [44], 'sessions': [45], 'neglect': [47], 'complex': [48, 59, 99], 'transitions': [49, 60, 100], 'items.': [51], 'To': [52], 'embedding': [56], 'take': [58], 'items': [62], 'into': [63], 'account,': [64], 'we': [65], 'propose': [66], 'novel': [68], 'method,': [69, 83], 'i.e.': [70], 'Session-based': [71], 'Recommendation': [72], 'with': [73], 'Graph': [74], 'Neural': [75], 'Networks,': [76], 'SR-GNN': [77, 146], 'for': [78], 'brevity.': [79], 'In': [80], 'the': [81, 93, 120, 123, 127, 149], 'proposed': [82], 'sequences': [85], 'modeled': [87], 'graphstructured': [89], 'data.': [90], 'Based': [91], 'graph,': [95], 'GNN': [96], 'can': [97], 'capture': [98], 'items,': [102], 'which': [103], 'difficult': [105], 'be': [107], 'revealed': [108], 'by': [109], 'previous': [110], 'conventional': [111], 'sequential': [112], 'methods.': [113], 'Each': [114], 'is': [116], 'then': [117], 'represented': [118], 'composition': [121], 'global': [124], 'preference': [125], 'current': [128], 'interest': [129], 'that': [131, 145], 'using': [133], 'an': [134], 'attention': [135], 'network.': [136], 'Extensive': [137], 'experiments': [138], 'conducted': [139], 'two': [141], 'real': [142], 'datasets': [143], 'show': [144], 'evidently': [147], 'outperforms': [148], 'state-of-the-art': [150], 'consistently.': [154]}",2019,[],"The problem of session-based recommendation aims to predict user actions based on anonymous sessions. Previous methods model a session as a sequence and estimate user representations besides item representations to make recommendations. Though achieved promising results, they are insufficient to obtain accurate user vectors in sessions and neglect complex transitions of items. To obtain accurate item embedding and take complex transitions of items into account, we propose a novel method, i.e. Session-based Recommendation with Graph Neural Networks, SR-GNN for brevity. In the proposed method, session sequences are modeled as graphstructured data. Based on the session graph, GNN can capture complex transitions of items, which are difficult to be revealed by previous conventional sequential methods. Each session is then represented as the composition of the global preference and the current interest of that session using an attention network. Extensive experiments conducted on two real datasets show that SR-GNN evidently outperforms the state-of-the-art session-based recommendation methods consistently."
https://openalex.org/W2963188159,PoseCNN: A Convolutional Neural Network for 6D Object Pose Estimation in Cluttered Scenes,"{'Estimating': [0], 'the': [1, 14, 22, 29, 57, 68, 75, 80, 117, 129, 147, 180, 188], '6D': [2, 52, 112, 123], 'pose': [3, 54, 114, 166], 'of': [4, 24, 31, 60, 79, 125], 'known': [5], 'objects': [6, 25, 127], 'is': [7, 18, 82, 154], 'important': [8], 'for': [9, 51, 111], 'robots': [10], 'to': [11, 21, 86, 99, 150, 157, 177], 'interact': [12], 'with': [13, 136], 'real': [15], 'world.The': [16], 'problem': [17], 'challenging': [19, 189], 'due': [20], 'variety': [23], 'as': [26, 28, 172], 'well': [27], 'complexity': [30], 'a': [32, 46, 87, 92, 106], 'scene': [33], 'caused': [34], 'by': [35, 63, 84], 'clutter': [36], 'and': [37, 70, 146, 163], 'occlusions': [38], 'between': [39], 'objects.In': [40, 102], 'this': [41], 'work,': [42], 'we': [43, 104], 'introduce': [44, 91], 'PoseCNN,': [45], 'new': [47], 'Convolutional': [48], 'Neural': [49], 'Network': [50], 'object': [53, 62, 81, 113], 'estimation.PoseCNN': [55], 'estimates': [56], '3D': [58, 77], 'translation': [59], 'an': [61], 'localizing': [64], 'its': [65, 72], 'center': [66], 'in': [67, 133], 'image': [69], 'predicting': [71], 'distance': [73], 'from': [74, 128], 'camera.The': [76], 'rotation': [78], 'estimated': [83], 'regressing': [85], 'quaternion': [88], 'representation.We': [89], 'also': [90], 'novel': [93], 'loss': [94], 'function': [95], 'that': [96, 152], 'enables': [97], 'PoseCNN': [98, 153], 'handle': [100, 160], 'symmetric': [101, 161], 'addition,': [103], 'contribute': [105], 'large': [107], 'scale': [108], 'video': [109], 'dataset': [110, 120, 131, 145, 149], 'estimation': [115, 167], 'named': [116], 'YCB-Video': [118, 144], 'dataset.Our': [119], 'provides': [121], 'accurate': [122, 165], 'poses': [124], '21': [126], 'YCB': [130], 'observed': [132], '92': [134], 'videos': [135], '133,827': [137], 'frames.We': [138], 'conduct': [139], 'extensive': [140], 'experiments': [141], 'on': [142, 187], 'our': [143, 182], 'OccludedLINEMOD': [148, 190], 'show': [151], 'highly': [155], 'robust': [156], 'occlusions,': [158], 'can': [159], 'objects,': [162], 'provide': [164], 'using': [168, 174], 'only': [169], 'color': [170], 'images': [171], 'input.When': [173], 'depth': [175], 'data': [176], 'further': [178], 'refine': [179], 'poses,': [181], 'approach': [183], 'achieves': [184], 'state-of-the-art': [185], 'results': [186], 'dataset.': [191]}",2018,"['Artificial intelligence', 'Computer science', 'Pose', 'Computer vision', 'Convolutional neural network', 'Clutter', 'Object (grammar)', 'Quaternion', 'Representation (politics)', 'Translation (biology)', 'Object detection', 'Rotation (mathematics)', 'Pattern recognition (psychology)', '3D pose estimation', 'Mathematics', 'Gene', 'Geometry', 'Messenger RNA', 'Biochemistry', 'Law', 'Telecommunications', 'Radar', 'Politics', 'Chemistry', 'Political science']","Estimating the 6D pose of known objects is important for robots to interact with the real world.The problem is challenging due to the variety of objects as well as the complexity of a scene caused by clutter and occlusions between objects.In this work, we introduce PoseCNN, a new Convolutional Neural Network for 6D object pose estimation.PoseCNN estimates the 3D translation of an object by localizing its center in the image and predicting its distance from the camera.The 3D rotation of the object is estimated by regressing to a quaternion representation.We also introduce a novel loss function that enables PoseCNN to handle symmetric objects.In addition, we contribute a large scale video dataset for 6D object pose estimation named the YCB-Video dataset.Our dataset provides accurate 6D poses of 21 objects from the YCB dataset observed in 92 videos with 133,827 frames.We conduct extensive experiments on our YCB-Video dataset and the OccludedLINEMOD dataset to show that PoseCNN is highly robust to occlusions, can handle symmetric objects, and provide accurate pose estimation using only color images as input.When using depth data to further refine the poses, our approach achieves state-of-the-art results on the challenging OccludedLINEMOD dataset."
https://openalex.org/W2762776925,A Deep Learning Approach for Intrusion Detection Using Recurrent Neural Networks,"{'Intrusion': [0], 'detection': [1, 33, 48, 160], 'plays': [2], 'an': [3, 31], 'important': [4], 'role': [5], 'in': [6, 20, 62, 145], 'ensuring': [7], 'information': [8], 'security,': [9], 'and': [10, 39, 65, 68, 73, 100, 131, 148, 161], 'the': [11, 21, 57, 60, 69, 79, 82, 110, 155, 158], 'key': [12], 'technology': [13], 'is': [14, 120, 135], 'to': [15, 29, 137], 'accurately': [16], 'identify': [17], 'various': [18], 'attacks': [19], 'network.': [22], 'In': [23], 'this': [24], 'paper,': [25], 'we': [26, 40, 55], 'explore': [27], 'how': [28], 'model': [30, 61, 127, 153], 'intrusion': [32, 47, 159, 168], 'system': [34], 'based': [35], 'on': [36, 78, 109], 'deep': [37, 43], 'learning,': [38], 'propose': [41], 'a': [42, 125, 163], 'learning': [44, 75, 103, 142], 'approach': [45], 'for': [46, 123, 167], 'using': [49], 'recurrent': [50], 'neural': [51, 93], 'networks': [52], '(RNN-IDS).': [53], 'Moreover,': [54], 'study': [56], 'performance': [58, 80, 134], 'of': [59, 71, 81, 90, 139, 157], 'binary': [63, 147], 'classification': [64, 126, 143], 'multiclass': [66, 149], 'classification,': [67], 'number': [70], 'neurons': [72], 'different': [74], 'rate': [76], 'impacts': [77], 'proposed': [83, 105], 'model.': [84], 'We': [85], 'compare': [86], 'it': [87], 'with': [88, 128], 'those': [89], 'J48,': [91], 'artificial': [92], 'network,': [94], 'random': [95], 'forest,': [96], 'support': [97], 'vector': [98], 'machine,': [99], 'other': [101], 'machine': [102, 141], 'methods': [104, 144], 'by': [106], 'previous': [107], 'researchers': [108], 'benchmark': [111], 'data': [112], 'set.': [113], 'The': [114, 151], 'experimental': [115], 'results': [116], 'show': [117], 'that': [118, 132, 138], 'RNN-IDS': [119, 152], 'very': [121], 'suitable': [122], 'modeling': [124], 'high': [129], 'accuracy': [130, 156], 'its': [133], 'superior': [136], 'traditional': [140], 'both': [146], 'classification.': [150], 'improves': [154], 'provides': [162], 'new': [164], 'research': [165], 'method': [166], 'detection.': [169]}",2017,"['Computer science', 'Artificial intelligence', 'Intrusion detection system', 'Machine learning', 'Recurrent neural network', 'Deep learning', 'Multiclass classification', 'Benchmark (surveying)', 'Support vector machine', 'Random forest', 'C4.5 algorithm', 'Artificial neural network', 'Binary classification', 'Data mining', 'Naive Bayes classifier', 'Geodesy', 'Geography']","Intrusion detection plays an important role in ensuring information security, and the key technology is to accurately identify various attacks in the network. In this paper, we explore how to model an intrusion detection system based on deep learning, and we propose a deep learning approach for intrusion detection using recurrent neural networks (RNN-IDS). Moreover, we study the performance of the model in binary classification and multiclass classification, and the number of neurons and different learning rate impacts on the performance of the proposed model. We compare it with those of J48, artificial neural network, random forest, support vector machine, and other machine learning methods proposed by previous researchers on the benchmark data set. The experimental results show that RNN-IDS is very suitable for modeling a classification model with high accuracy and that its performance is superior to that of traditional machine learning classification methods in both binary and multiclass classification. The RNN-IDS model improves the accuracy of the intrusion detection and provides a new research method for intrusion detection."
https://openalex.org/W2462592242,Pansharpening by Convolutional Neural Networks,"{'A': [0], 'new': [1], 'pansharpening': [2, 25], 'method': [3, 58], 'is': [4], 'proposed,': [5], 'based': [6], 'on': [7, 51], 'convolutional': [8], 'neural': [9], 'networks.': [10], 'We': [11], 'adapt': [12], 'a': [13, 84], 'simple': [14], 'and': [15, 78, 81], 'effective': [16], 'three-layer': [17], 'architecture': [18], 'recently': [19], 'proposed': [20, 57], 'for': [21], 'super-resolution': [22], 'to': [23, 28, 59], 'the': [24, 36, 56, 67, 71], 'problem.': [26], 'Moreover,': [27], 'improve': [29], 'performance': [30], 'without': [31], 'increasing': [32], 'complexity,': [33], 'we': [34], 'augment': [35], 'input': [37], 'by': [38], 'including': [39], 'several': [40], 'maps': [41], 'of': [42, 47, 70, 75], 'nonlinear': [43], 'radiometric': [44], 'indices': [45], 'typical': [46], 'remote': [48], 'sensing.': [49], 'Experiments': [50], 'three': [52], 'representative': [53], 'datasets': [54], 'show': [55], 'provide': [60], 'very': [61], 'promising': [62], 'results,': [63], 'largely': [64], 'competitive': [65], 'with': [66], 'current': [68], 'state': [69], 'art': [72], 'in': [73], 'terms': [74], 'both': [76], 'full-reference': [77], 'no-reference': [79], 'metrics,': [80], 'also': [82], 'at': [83], 'visual': [85], 'inspection.': [86]}",2016,"['Computer science', 'Convolutional neural network', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Remote sensing', 'Geology']","A new pansharpening method is proposed, based on convolutional neural networks. We adapt a simple and effective three-layer architecture recently proposed for super-resolution to the pansharpening problem. Moreover, to improve performance without increasing complexity, we augment the input by including several maps of nonlinear radiometric indices typical of remote sensing. Experiments on three representative datasets show the proposed method to provide very promising results, largely competitive with the current state of the art in terms of both full-reference and no-reference metrics, and also at a visual inspection."
https://openalex.org/W2267635276,Binarized Neural Networks,"{'We': [0, 28], 'introduce': [1], 'a': [2, 37, 81, 92], 'method': [3], 'to': [4, 80, 103], 'train': [5, 46], 'Binarized': [6], 'Neural': [7], 'Networks': [8], '(BNNs)': [9], '-': [10], 'neural': [11], 'networks': [12], 'with': [13, 74, 98, 112], 'binary': [14, 93], 'weights': [15], 'and': [16, 20, 42, 51, 53, 67, 69, 128], 'activations': [17], 'at': [18, 26], 'run-time': [19], 'when': [21], 'computing': [22], 'the': [23, 59], ""parameters'"": [24], 'gradient': [25], 'train-time.': [27], 'conduct': [29], 'two': [30], 'sets': [31], 'of': [32], 'experiments,': [33], 'each': [34], 'based': [35], 'on': [36, 48], 'different': [38], 'framework,': [39], 'namely': [40], 'Torch7': [41], 'Theano,': [43], 'where': [44], 'we': [45, 90], 'BNNs': [47, 62, 131], 'MNIST,': [49], 'CIFAR-10': [50], 'SVHN,': [52], 'achieve': [54], 'nearly': [55], 'state-of-the-art': [56], 'results.': [57], 'During': [58], 'forward': [60], 'pass,': [61], 'drastically': [63], 'reduce': [64], 'memory': [65], 'size': [66], 'accesses,': [68], 'replace': [70], 'most': [71], 'arithmetic': [72], 'operations': [73], 'bit-wise': [75], 'operations,': [76], 'which': [77, 99], 'might': [78], 'lead': [79], 'great': [82], 'increase': [83], 'in': [84, 121], 'power-efficiency.': [85], 'Last': [86], 'but': [87], 'not': [88], 'least,': [89], 'wrote': [91], 'matrix': [94], 'multiplication': [95], 'GPU': [96, 115], 'kernel': [97], 'it': [100], 'is': [101, 132], 'possible': [102], 'run': [104], 'our': [105, 130], 'MNIST': [106], 'BNN': [107], '7': [108], 'times': [109], 'faster': [110], 'than': [111], 'an': [113], 'unoptimized': [114], 'kernel,': [116], 'without': [117], 'suffering': [118], 'any': [119], 'loss': [120], 'classification': [122], 'accuracy.': [123], 'The': [124], 'code': [125], 'for': [126], 'training': [127], 'running': [129], 'available.': [133]}",2016,"['MNIST database', 'Computer science', 'Kernel (algebra)', 'Artificial neural network', 'Multiplication (music)', 'Binary number', 'Code (set theory)', 'Artificial intelligence', 'Deep neural networks', 'Matrix multiplication', 'Binary code', 'Deep learning', 'Machine learning', 'Pattern recognition (psychology)', 'Arithmetic', 'Mathematics', 'Set (abstract data type)', 'Physics', 'Quantum mechanics', 'Quantum', 'Combinatorics', 'Programming language']","We introduce a method to train Binarized Neural Networks (BNNs) - neural networks with binary weights and activations at run-time and when computing the parameters' gradient at train-time. We conduct two sets of experiments, each based on a different framework, namely Torch7 and Theano, where we train BNNs on MNIST, CIFAR-10 and SVHN, and achieve nearly state-of-the-art results. During the forward pass, BNNs drastically reduce memory size and accesses, and replace most arithmetic operations with bit-wise operations, which might lead to a great increase in power-efficiency. Last but not least, we wrote a binary matrix multiplication GPU kernel with which it is possible to run our MNIST BNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy. The code for training and running our BNNs is available."
https://openalex.org/W2531327146,A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks,"{'We': [0, 15, 46, 71], 'consider': [1], 'the': [2, 64, 74, 81], 'two': [3], 'related': [4], 'problems': [5], 'of': [6, 66], 'detecting': [7], 'if': [8], 'an': [9], 'example': [10], 'is': [11], 'misclassified': [12], 'or': [13], 'out-of-distribution.': [14], 'present': [16], 'a': [17], 'simple': [18], 'baseline': [19, 68, 75], 'that': [20], 'utilizes': [21], 'probabilities': [22, 35], 'from': [23], 'softmax': [24, 34], 'distributions.': [25], 'Correctly': [26], 'classified': [27, 38], 'examples': [28], 'tend': [29], 'to': [30], 'have': [31], 'greater': [32], 'maximum': [33], 'than': [36], 'erroneously': [37], 'and': [39, 59], 'out-of-distribution': [40], 'examples,': [41], 'allowing': [42], 'for': [43, 83], 'their': [44], 'detection.': [45], 'assess': [47], 'performance': [48], 'by': [49], 'defining': [50], 'several': [51], 'tasks': [52], 'in': [53], 'computer': [54], 'vision,': [55], 'natural': [56], 'language': [57], 'processing,': [58], 'automatic': [60], 'speech': [61], 'recognition,': [62], 'showing': [63], 'effectiveness': [65], 'this': [67], 'across': [69], 'all.': [70], 'then': [72], 'show': [73], 'can': [76], 'sometimes': [77], 'be': [78], 'surpassed,': [79], 'demonstrating': [80], 'room': [82], 'future': [84], 'research': [85], 'on': [86], 'these': [87], 'underexplored': [88], 'detection': [89], 'tasks.': [90]}",2016,"['Baseline (sea)', 'Artificial neural network', 'Computer science', 'Distribution (mathematics)', 'Artificial intelligence', 'Mathematics', 'Geology', 'Mathematical analysis', 'Oceanography']","We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks."
https://openalex.org/W2584483805,Low-Dose CT With a Residual Encoder-Decoder Convolutional Neural Network,"{'Given': [0], 'the': [1, 8, 18, 23, 55, 59, 63, 66, 86, 94, 102, 116], 'potential': [2], 'risk': [3], 'of': [4, 57, 88, 142], 'X-ray': [5], 'radiation': [6], 'to': [7, 41, 50, 54, 124], 'patient,': [9], 'low-dose': [10, 26, 110], 'CT': [11, 27, 111], 'has': [12, 136], 'attracted': [13], 'a': [14, 120], 'considerable': [15], 'interest': [16], 'in': [17, 62, 127, 140], 'medical': [19], 'imaging': [20], 'field.': [21], 'Currently,': [22], 'main': [24], 'stream': [25], 'methods': [28, 68, 126], 'include': [29], 'vendor-specific': [30], 'sinogram': [31], 'domain': [32], 'filtration': [33], 'and': [34, 98, 130, 147], 'iterative': [35], 'reconstruction': [36], 'algorithms,': [37], 'but': [38], 'they': [39], 'need': [40], 'access': [42], 'raw': [43], 'data,': [44], 'whose': [45], 'formats': [46], 'are': [47], 'not': [48], 'transparent': [49], 'most': [51], 'users.': [52], 'Due': [53], 'difficulty': [56], 'modeling': [58], 'statistical': [60], 'characteristics': [61], 'image': [64, 76], 'domain,': [65], 'existing': [67], 'for': [69, 109], 'directly': [70], 'processing': [71], 'reconstructed': [72], 'images': [73], 'cannot': [74], 'eliminate': [75], 'noise': [77, 143], 'very': [78], 'well': [79], 'while': [80], 'keeping': [81], 'structural': [82, 145], 'details.': [83], 'Inspired': [84], 'by': [85], 'idea': [87], 'deep': [89], 'learning,': [90], 'here': [91], 'we': [92], 'combine': [93], 'autoencoder,': [95], 'deconvolution': [96], 'network,': [97], 'shortcut': [99], 'connections': [100], 'into': [101], 'residual': [103], 'encoder-decoder': [104], 'convolutional': [105], 'neural': [106], 'network': [107], '(RED-CNN)': [108], 'imaging.': [112], 'After': [113], 'patch-based': [114], 'training,': [115], 'proposed': [117], 'RED-CNN': [118], 'achieves': [119], 'competitive': [121], 'performance': [122], 'relative': [123], 'the-state-of-art': [125], 'both': [128], 'simulated': [129], 'clinical': [131], 'cases.': [132], 'Especially,': [133], 'our': [134], 'method': [135], 'been': [137], 'favorably': [138], 'evaluated': [139], 'terms': [141], 'suppression,': [144], 'preservation,': [146], 'lesion': [148], 'detection.': [149]}",2017,"['Convolutional neural network', 'Residual', 'Encoder', 'Computer science', 'Convolutional code', 'Artificial intelligence', 'Decoding methods', 'Computer vision', 'Pattern recognition (psychology)', 'Algorithm', 'Operating system']","Given the potential risk of X-ray radiation to the patient, low-dose CT has attracted a considerable interest in the medical imaging field. Currently, the main stream low-dose CT methods include vendor-specific sinogram domain filtration and iterative reconstruction algorithms, but they need to access raw data, whose formats are not transparent to most users. Due to the difficulty of modeling the statistical characteristics in the image domain, the existing methods for directly processing reconstructed images cannot eliminate image noise very well while keeping structural details. Inspired by the idea of deep learning, here we combine the autoencoder, deconvolution network, and shortcut connections into the residual encoder-decoder convolutional neural network (RED-CNN) for low-dose CT imaging. After patch-based training, the proposed RED-CNN achieves a competitive performance relative to the-state-of-art methods in both simulated and clinical cases. Especially, our method has been favorably evaluated in terms of noise suppression, structural preservation, and lesion detection."
https://openalex.org/W2949541494,Convolutional Neural Networks for Sentence Classification,"{'We': [0, 23, 52], 'report': [1], 'on': [2, 13, 39, 84], 'a': [3, 26, 55], 'series': [4], 'of': [5, 15, 66, 81, 87], 'experiments': [6], 'with': [7, 29], 'convolutional': [8], 'neural': [9], 'networks': [10], '(CNN)': [11], 'trained': [12], 'top': [14], 'pre-trained': [16], 'word': [17], 'vectors': [18, 35, 44], 'for': [19, 63], 'sentence-level': [20], 'classification': [21], 'tasks.': [22], 'show': [24], 'that': [25], 'simple': [27, 56], 'CNN': [28, 73], 'little': [30], 'hyperparameter': [31], 'tuning': [32], 'and': [33, 69, 94], 'static': [34, 70], 'achieves': [36], 'excellent': [37], 'results': [38], 'multiple': [40], 'benchmarks.': [41], 'Learning': [42], 'task-specific': [43, 68], 'through': [45], 'fine-tuning': [46], 'offers': [47], 'further': [48], 'gains': [49], 'in': [50], 'performance.': [51], 'additionally': [53], 'propose': [54], 'modification': [57], 'to': [58, 61], 'the': [59, 64, 79, 82], 'architecture': [60], 'allow': [62], 'use': [65], 'both': [67], 'vectors.': [71], 'The': [72], 'models': [74], 'discussed': [75], 'herein': [76], 'improve': [77], 'upon': [78], 'state': [80], 'art': [83], '4': [85], 'out': [86], '7': [88], 'tasks,': [89], 'which': [90], 'include': [91], 'sentiment': [92], 'analysis': [93], 'question': [95], 'classification.': [96]}",2014,"['Hyperparameter', 'Computer science', 'Convolutional neural network', 'Sentence', 'Artificial intelligence', 'Task (project management)', 'Word (group theory)', 'Simple (philosophy)', 'Machine learning', 'Natural language processing', 'Pattern recognition (psychology)', 'Mathematics', 'Engineering', 'Geometry', 'Epistemology', 'Philosophy', 'Systems engineering']","We report on a series of experiments with convolutional neural networks (CNN) trained on top of pre-trained word vectors for sentence-level classification tasks. We show that a simple CNN with little hyperparameter tuning and static vectors achieves excellent results on multiple benchmarks. Learning task-specific vectors through fine-tuning offers further gains in performance. We additionally propose a simple modification to the architecture to allow for the use of both task-specific and static vectors. The CNN models discussed herein improve upon the state of the art on 4 out of 7 tasks, which include sentiment analysis and question classification."
https://openalex.org/W2250966211,Document Modeling with Gated Recurrent Neural Network for Sentiment Classification,"{'Document': [0], 'level': [1, 74], 'sentiment': [2, 75, 118], 'classification': [3, 76], 'remains': [4], 'a': [5, 18, 25, 35], 'challenge:': [6], 'encoding': [7], 'the': [8, 14], 'intrinsic': [9], 'relations': [10, 59], 'between': [11], 'sentences': [12, 56], 'in': [13, 34, 63, 114], 'semantic': [15], 'meaning': [16], 'of': [17, 55], 'document.': [19], 'To': [20], 'address': [21], 'this,': [22], 'we': [23], 'introduce': [24], 'neural': [26, 47, 69, 94, 106, 112], 'network': [27, 48, 107, 113], 'model': [28, 40, 95], 'to': [29], 'learn': [30], 'vector-based': [31], 'document': [32, 64, 73, 115], 'representation': [33, 44, 65], 'unified,': [36], 'bottom-up': [37], 'fashion.': [38], 'The': [39], 'first': [41], 'learns': [42], 'sentence': [43], 'with': [45, 66], 'convolutional': [46], 'or': [49], 'long': [50], 'short-term': [51], 'memory.': [52], 'Afterwards,': [53], 'semantics': [54], 'and': [57, 84], 'their': [58], 'are': [60], 'adaptively': [61], 'encoded': [62], 'gated': [67, 104], 'recurrent': [68, 105, 111], 'network.': [70], 'We': [71], 'conduct': [72], 'on': [77], 'four': [78], 'large-scale': [79], 'review': [80], 'datasets': [81], 'from': [82], 'IMDB': [83], 'Yelp': [85], 'Dataset': [86], 'Challenge.': [87], 'Experimental': [88], 'results': [89], 'show': [90], 'that:': [91], '(1)': [92], 'our': [93], 'shows': [96], 'superior': [97], 'performances': [98], 'over': [99], 'several': [100], 'state-of-the-art': [101], 'algorithms;': [102], '(2)': [103], 'dramatically': [108], 'outperforms': [109], 'standard': [110], 'modeling': [116], 'for': [117], 'classification.': [119], '1': [120]}",2015,"['Computer science', 'Artificial intelligence', 'Artificial neural network', 'Natural language processing']","Document level sentiment classification remains a challenge: encoding the intrinsic relations between sentences in the semantic meaning of a document. To address this, we introduce a neural network model to learn vector-based document representation in a unified, bottom-up fashion. The model first learns sentence representation with convolutional neural network or long short-term memory. Afterwards, semantics of sentences and their relations are adaptively encoded in document representation with gated recurrent neural network. We conduct document level sentiment classification on four large-scale review datasets from IMDB and Yelp Dataset Challenge. Experimental results show that: (1) our neural model shows superior performances over several state-of-the-art algorithms; (2) gated recurrent neural network dramatically outperforms standard recurrent neural network in document modeling for sentiment classification. 1"
https://openalex.org/W2963358464,Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic\n Forecasting,"{'Spatiotemporal': [0], 'forecasting': [1, 11, 75], 'has': [2], 'various': [3], 'applications': [4], 'in': [5, 82], 'neuroscience,': [6], 'climate\\nand': [7], 'transportation': [8], 'domain.': [9], 'Traffic': [10], 'is': [12, 21], 'one': [13], 'canonical': [14], 'example': [15], 'of': [16, 42, 123], 'such\\nlearning': [17], 'task.': [18], 'The': [19], 'task': [20], 'challenging': [22], 'due': [23], 'to': [24, 50], '(1)': [25], 'complex': [26], 'spatial': [27, 78, 89], 'dependency': [28, 81, 90, 100], 'on\\nroad': [29], 'networks,': [30], '(2)': [31], 'non-linear': [32], 'temporal': [33, 80, 99], 'dynamics': [34], 'with': [35], 'changing': [36], 'road': [37], 'conditions\\nand': [38], '(3)': [39], 'inherent': [40], 'difficulty': [41], 'long-term': [43], 'forecasting.': [44], 'To': [45], 'address': [46], 'these\\nchallenges,': [47], 'we': [48], 'propose': [49], 'model': [51], 'the': [52, 83, 88, 96, 98, 102, 109], 'traffic': [53, 74, 84, 117], 'flow': [54], 'as': [55], 'a': [56, 69], 'diffusion': [57], 'process': [58], 'on': [59, 95, 111], 'a\\ndirected': [60], 'graph': [61], 'and': [62, 79, 119], 'introduce': [63], 'Diffusion': [64], 'Convolutional': [65], 'Recurrent': [66], 'Neural': [67], 'Network\\n(DCRNN),': [68], 'deep': [70], 'learning': [71], 'framework': [72, 110], 'for': [73], 'that': [76], 'incorporates\\nboth': [77], 'flow.': [85], 'Specifically,': [86], 'DCRNN\\ncaptures': [87], 'using': [91, 101], 'bidirectional': [92], 'random': [93], 'walks': [94], 'graph,\\nand': [97], 'encoder-decoder': [103], 'architecture': [104], 'with\\nscheduled': [105], 'sampling.': [106], 'We': [107], 'evaluate': [108], 'two': [112], 'real-world': [113], 'large': [114], 'scale\\nroad': [115], 'network': [116], 'datasets': [118], 'observe': [120], 'consistent': [121], 'improvement': [122], '12%': [124], '-': [125], '15%\\nover': [126], 'state-of-the-art': [127], 'baselines.\\n': [128]}",2017,"['Convolutional neural network', 'Computer science', 'Diffusion', 'Artificial intelligence', 'Artificial neural network', 'Data mining', 'Physics', 'Thermodynamics']","Spatiotemporal forecasting has various applications in neuroscience, climate\nand transportation domain. Traffic forecasting is one canonical example of such\nlearning task. The task is challenging due to (1) complex spatial dependency on\nroad networks, (2) non-linear temporal dynamics with changing road conditions\nand (3) inherent difficulty of long-term forecasting. To address these\nchallenges, we propose to model the traffic flow as a diffusion process on a\ndirected graph and introduce Diffusion Convolutional Recurrent Neural Network\n(DCRNN), a deep learning framework for traffic forecasting that incorporates\nboth spatial and temporal dependency in the traffic flow. Specifically, DCRNN\ncaptures the spatial dependency using bidirectional random walks on the graph,\nand the temporal dependency using the encoder-decoder architecture with\nscheduled sampling. We evaluate the framework on two real-world large scale\nroad network traffic datasets and observe consistent improvement of 12% - 15%\nover state-of-the-art baselines.\n"
https://openalex.org/W2273396394,An Introduction to Convolutional Neural Networks,"{'The': [0], 'field': [1], 'of': [2, 16, 34, 37, 46, 51, 56, 84, 122], 'machine': [3, 42, 125], 'learning': [4, 43], 'has': [5], 'taken': [6], 'a': [7, 81, 92], 'dramatic': [8], 'twist': [9], 'in': [10, 40, 105], 'recent': [11], 'times,': [12], 'with': [13, 74, 87, 119], 'the': [14, 17, 32, 47, 57, 120], 'rise': [15], 'Artificial': [18], 'Neural': [19, 59], 'Network': [20, 60], '(ANN).': [21], 'These': [22], 'biologically': [23], 'inspired': [24], 'computational': [25], 'models': [26], 'are': [27, 63, 117], 'able': [28], 'to': [29, 66, 95], 'far': [30], 'exceed': [31], 'performance': [33], 'previous': [35], 'forms': [36, 50], 'artificial': [38], 'intelligence': [39], 'common': [41], 'tasks.': [44], 'One': [45], 'most': [48], 'impressive': [49], 'ANN': [52], 'architecture': [53], 'is': [54], 'that': [55], 'Convolutional': [58], '(CNN).': [61], 'CNNs': [62], 'primarily': [64], 'used': [65], 'solve': [67], 'difficult': [68], 'image-driven': [69], 'pattern': [70], 'recognition': [71, 111], 'tasks': [72], 'and': [73, 101, 124], 'their': [75], 'precise': [76], 'yet': [77], 'simple': [78], 'architecture,': [79], 'offers': [80], 'simplified': [82], 'method': [83], 'getting': [85], 'started': [86], 'ANNs.': [88], 'This': [89, 113], 'document': [90], 'provides': [91], 'brief': [93], 'introduction': [94, 114], 'CNNs,': [96], 'discussing': [97], 'recently': [98], 'published': [99], 'papers': [100], 'newly': [102], 'formed': [103], 'techniques': [104], 'developing': [106], 'these': [107], 'brilliantly': [108], 'fantastic': [109], 'image': [110], 'models.': [112], 'assumes': [115], 'you': [116], 'familiar': [118], 'fundamentals': [121], 'ANNs': [123], 'learning.': [126]}",2015,"['Computer science', 'Artificial intelligence', 'Convolutional neural network', 'Artificial neural network', 'Field (mathematics)', 'Simple (philosophy)', 'Architecture', 'Machine learning', 'Deep learning', 'Neocognitron', 'Pattern recognition (psychology)', 'Time delay neural network', 'Visual arts', 'Mathematics', 'Art', 'Philosophy', 'Epistemology', 'Pure mathematics']","The field of machine learning has taken a dramatic twist in recent times, with the rise of the Artificial Neural Network (ANN). These biologically inspired computational models are able to far exceed the performance of previous forms of artificial intelligence in common machine learning tasks. One of the most impressive forms of ANN architecture is that of the Convolutional Neural Network (CNN). CNNs are primarily used to solve difficult image-driven pattern recognition tasks and with their precise yet simple architecture, offers a simplified method of getting started with ANNs. This document provides a brief introduction to CNNs, discussing recently published papers and newly formed techniques in developing these brilliantly fantastic image recognition models. This introduction assumes you are familiar with the fundamentals of ANNs and machine learning."
https://openalex.org/W2470368200,Deep Neural Networks Based Recognition of Plant Diseases by Leaf Image Classification,"{'The': [0, 63, 157], 'latest': [1], 'generation': [2], 'of': [3, 15, 29, 42, 48, 73, 77], 'convolutional': [4, 44], 'neural': [5], 'networks': [6], '(CNNs)': [7], 'has': [8, 100], 'achieved': [9, 164], 'impressive': [10], 'results': [11, 159], 'in': [12, 61, 127], 'the': [13, 27, 40, 51, 81, 104, 121, 153, 161], 'field': [14], 'image': [16, 37], 'classification.': [17], 'This': [18], 'paper': [19], 'is': [20, 66], 'concerned': [21], 'with': [22, 80], 'a': [23, 55, 131, 138], 'new': [24], 'approach': [25], 'to': [26, 68, 83, 91, 129, 151], 'development': [28], 'plant': [30, 74, 85, 97], 'disease': [31, 98, 114], 'recognition': [32, 99, 115], 'model,': [33], 'based': [34], 'on': [35, 160, 174], 'leaf': [36], 'classification,': [38], 'by': [39, 134, 143], 'use': [41], 'deep': [43, 139, 154], 'networks.': [45], 'Novel': [46], 'way': [47], 'training': [49], 'and': [50, 57, 146, 168], 'methodology': [52], 'used': [53, 150], 'facilitate': [54], 'quick': [56], 'easy': [58], 'system': [59], 'implementation': [60], 'practice.': [62], 'developed': [64, 142, 162], 'model': [65, 116, 163], 'able': [67], 'recognize': [69], '13': [70], 'different': [71], 'types': [72], 'diseases': [75], 'out': [76], 'healthy': [78], 'leaves,': [79], 'ability': [82], 'distinguish': [84], 'leaves': [86], 'from': [87, 124], 'their': [88], 'surroundings.': [89], 'According': [90], 'our': [92], 'knowledge,': [93], 'this': [94, 113], 'method': [95], 'for': [96, 103, 111, 170], 'been': [101], 'proposed': [102], 'first': [105], 'time.': [106], 'All': [107], 'essential': [108], 'steps': [109], 'required': [110], 'implementing': [112], 'are': [117], 'fully': [118], 'described': [119], 'throughout': [120], 'paper,': [122], 'starting': [123], 'gathering': [125], 'images': [126], 'order': [128], 'create': [130], 'database,': [132], 'assessed': [133], 'agricultural': [135], 'experts.': [136], 'Caffe,': [137], 'learning': [140], 'framework': [141], 'Berkley': [144], 'Vision': [145], 'Learning': [147], 'Centre,': [148], 'was': [149], 'perform': [152], 'CNN': [155], 'training.': [156], 'experimental': [158], 'precision': [165], 'between': [166], '91%': [167], '98%,': [169], 'separate': [171], 'class': [172], 'tests,': [173], 'average': [175], '96.3%.': [176]}",2016,"['Artificial intelligence', 'Convolutional neural network', 'Computer science', 'Deep learning', 'Plant disease', 'Pattern recognition (psychology)', 'Field (mathematics)', 'Machine learning', 'Artificial neural network', 'Contextual image classification', 'Image processing', 'Image (mathematics)', 'Mathematics', 'Biology', 'Pure mathematics', 'Biotechnology']","The latest generation of convolutional neural networks (CNNs) has achieved impressive results in the field of image classification. This paper is concerned with a new approach to the development of plant disease recognition model, based on leaf image classification, by the use of deep convolutional networks. Novel way of training and the methodology used facilitate a quick and easy system implementation in practice. The developed model is able to recognize 13 different types of plant diseases out of healthy leaves, with the ability to distinguish plant leaves from their surroundings. According to our knowledge, this method for plant disease recognition has been proposed for the first time. All essential steps required for implementing this disease recognition model are fully described throughout the paper, starting from gathering images in order to create a database, assessed by agricultural experts. Caffe, a deep learning framework developed by Berkley Vision and Learning Centre, was used to perform the deep CNN training. The experimental results on the developed model achieved precision between 91% and 98%, for separate class tests, on average 96.3%."
https://openalex.org/W2578240541,Generating Focused Molecule Libraries for Drug Discovery with Recurrent Neural Networks,"{'In': [0, 21, 71], '<i>de': [1, 144], 'novo</i>': [2, 145], 'drug': [3, 146, 157], 'design,': [4], 'computational': [5], 'strategies': [6], 'are': [7, 96], 'used': [8, 66], 'to': [9, 16, 40, 67, 73, 86, 98, 149], 'generate': [10, 150], 'novel': [11, 154], 'molecules': [12, 56, 65, 77, 115, 155], 'with': [13, 60, 76, 90, 134], 'good': [14], 'affinity': [15], 'the': [17, 51, 54, 61, 64, 69, 88, 107, 142], 'desired': [18], 'biological': [19, 82], 'target.': [20, 103], 'this': [22], 'work,': [23], 'we': [24, 84], 'show': [25], 'that': [26, 50, 102, 116], 'recurrent': [27], 'neural': [28], 'networks': [29], 'can': [30, 140], 'be': [31, 99], 'trained': [32], 'as': [33], 'generative': [34], 'models': [35, 43], 'for': [36, 156], 'molecular': [37], 'structures,': [38], 'similar': [39], 'statistical': [41], 'language': [42, 46], 'in': [44], 'natural': [45], 'processing.': [47], 'We': [48], 'demonstrate': [49], 'properties': [52, 62], 'of': [53, 63, 93, 111, 128, 153], 'generated': [55], 'correlate': [57], 'very': [58], 'well': [59], 'train': [68], 'model.': [70], 'order': [72], 'enrich': [74], 'libraries': [75], 'active': [78, 100], 'toward': [79], 'a': [80, 135], 'given': [81], 'target,': [83], 'propose': [85], 'fine-tune': [87], 'model': [89, 108, 139], 'small': [91], 'sets': [92, 152], 'molecules,': [94], 'which': [95], 'known': [97], 'against': [101, 121], 'Against': [104], '<i>Staphylococcus': [105], 'aureus</i>,': [106], 'reproduced': [109, 126], '14%': [110], '6051': [112], 'hold-out': [113], 'test': [114, 130], 'medicinal': [117], 'chemists': [118], 'designed,': [119], 'whereas': [120], '<i>Plasmodium': [122], 'falciparum</i>': [123], '(Malaria),': [124], 'it': [125], '28%': [127], '1240': [129], 'molecules.': [131], 'When': [132], 'coupled': [133], 'scoring': [136], 'function,': [137], 'our': [138], 'perform': [141], 'complete': [143], 'design': [147], 'cycle': [148], 'large': [151], 'discovery.': [158]}",2017,"['Drug discovery', 'Computer science', 'Drug', 'Artificial neural network', 'Computational biology', 'Data science', 'Artificial intelligence', 'Medicine', 'Bioinformatics', 'Biology', 'Pharmacology']","In <i>de novo</i> drug design, computational strategies are used to generate novel molecules with good affinity to the desired biological target. In this work, we show that recurrent neural networks can be trained as generative models for molecular structures, similar to statistical language models in natural language processing. We demonstrate that the properties of the generated molecules correlate very well with the properties of the molecules used to train the model. In order to enrich libraries with molecules active toward a given biological target, we propose to fine-tune the model with small sets of molecules, which are known to be active against that target. Against <i>Staphylococcus aureus</i>, the model reproduced 14% of 6051 hold-out test molecules that medicinal chemists designed, whereas against <i>Plasmodium falciparum</i> (Malaria), it reproduced 28% of 1240 test molecules. When coupled with a scoring function, our model can perform the complete <i>de novo</i> drug design cycle to generate large sets of novel molecules for drug discovery."
https://openalex.org/W1955055330,Learning to compare image patches via convolutional neural networks,"{'In': [0], 'this': [1, 73], 'paper': [2], 'we': [3, 40, 61], 'show': [4, 76], 'how': [5], 'to': [6, 14, 48, 72], 'learn': [7], 'directly': [8], 'from': [9], 'image': [10, 22], 'data': [11], '(i.e.,': [12], 'without\\nresorting': [13], 'manually-designed': [15], 'features)': [16], 'a': [17, 26, 38, 43, 51], 'general': [18], 'similarity': [19], 'function': [20], 'for\\ncomparing': [21], 'patches,': [23], 'which': [24, 68], 'is': [25, 46], 'task': [27], 'of': [28, 54], 'fundamental': [29], 'importance': [30], 'for': [31, 42, 50], 'many\\ncomputer': [32], 'vision': [33], 'problems.': [34], 'To': [35, 58], 'encode': [36], 'such': [37], 'function,': [39], 'opt': [41], 'CNN-based\\nmodel': [44], 'that': [45, 59, 77], 'trained': [47], 'account': [49], 'wide': [52], 'variety': [53], 'changes': [55], 'in': [56], 'image\\nappearance.': [57], 'end,': [60], 'explore': [62], 'and': [63, 87], 'study': [64], 'multiple': [65], 'neural': [66], 'network\\narchitectures,': [67], 'are': [69], 'specifically': [70], 'adapted': [71], 'task.': [74], 'We': [75], 'such\\nan': [78], 'approach': [79], 'can': [80], 'significantly': [81], 'outperform': [82], 'the': [83], 'state-of-the-art': [84], 'on': [85], 'several\\nproblems': [86], 'benchmark': [88], 'datasets.\\n': [89]}",2015,"['Convolutional neural network', 'Computer science', 'Artificial intelligence', 'Image (mathematics)', 'Pattern recognition (psychology)', 'Computer vision']","In this paper we show how to learn directly from image data (i.e., without\nresorting to manually-designed features) a general similarity function for\ncomparing image patches, which is a task of fundamental importance for many\ncomputer vision problems. To encode such a function, we opt for a CNN-based\nmodel that is trained to account for a wide variety of changes in image\nappearance. To that end, we explore and study multiple neural network\narchitectures, which are specifically adapted to this task. We show that such\nan approach can significantly outperform the state-of-the-art on several\nproblems and benchmark datasets.\n"
https://openalex.org/W648786980,Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks,"{'Recurrent': [0], 'Neural': [1], 'Networks': [2], 'can': [3, 74, 78], 'be': [4], 'trained': [5], 'to': [6, 28, 91, 141], 'produce': [7], 'sequences': [8], 'of': [9, 32, 36], 'tokens': [10], 'given': [11, 42], 'some': [12], 'input,': [13], 'as': [14], 'exemplified': [15], 'by': [16, 60, 64], 'recent': [17], 'results': [18], 'in': [19, 39, 137], 'machine': [20], 'translation': [21], 'and': [22, 47, 72], 'image': [23, 144], 'captioning.': [24], 'The': [25], 'current': [26, 44], 'approach': [27, 128], 'training': [29, 71, 95], 'them': [30], 'consists': [31], 'maximizing': [33], 'the': [34, 40, 43, 48, 53, 65, 82, 94, 103, 115, 142], 'likelihood': [35], 'each': [37], 'token': [38, 56, 62, 117], 'sequence': [41, 122], '(recurrent)': [45], 'state': [46], 'previous': [49, 55, 105], 'token.': [50], 'At': [51], 'inference,': [52], 'unknown': [54], 'is': [57], 'then': [58], 'replaced': [59], 'a': [61, 87, 98, 108], 'generated': [63, 83, 116], 'model': [66], 'itself.': [67], 'This': [68], 'discrepancy': [69], 'between': [70], 'inference': [73], 'yield': [75], 'errors': [76], 'that': [77, 126], 'accumulate': [79], 'quickly': [80], 'along': [81], 'sequence.': [84], 'We': [85], 'propose': [86], 'curriculum': [88], 'learning': [89], 'strategy': [90], 'gently': [92], 'change': [93], 'process': [96], 'from': [97], 'fully': [99], 'guided': [100, 110], 'scheme': [101, 111], 'using': [102], 'true': [104], 'token,': [106], 'towards': [107], 'less': [109], 'which': [112], 'mostly': [113], 'uses': [114], 'instead.': [118], 'Experiments': [119], 'on': [120], 'several': [121], 'prediction': [123], 'tasks': [124], 'show': [125], 'this': [127], 'yields': [129], 'significant': [130], 'improvements.': [131], 'Moreover,': [132], 'it': [133], 'was': [134], 'used': [135], 'successfully': [136], 'our': [138], 'winning': [139], 'entry': [140], 'MSCOCO': [143], 'captioning': [145], 'challenge,': [146], '2015.': [147]}",2015,"['Security token', 'Closed captioning', 'Computer science', 'Inference', 'Sequence (biology)', 'Scheme (mathematics)', 'Artificial neural network', 'Artificial intelligence', 'Recurrent neural network', 'Process (computing)', 'Token passing', 'Deep learning', 'Speech recognition', 'Machine learning', 'Image (mathematics)', 'Mathematics', 'Computer network', 'Operating system', 'Genetics', 'Biology', 'Mathematical analysis']","Recurrent Neural Networks can be trained to produce sequences of tokens given some input, as exemplified by recent results in machine translation and image captioning. The current approach to training them consists of maximizing the likelihood of each token in the sequence given the current (recurrent) state and the previous token. At inference, the unknown previous token is then replaced by a token generated by the model itself. This discrepancy between training and inference can yield errors that can accumulate quickly along the generated sequence. We propose a curriculum learning strategy to gently change the training process from a fully guided scheme using the true previous token, towards a less guided scheme which mostly uses the generated token instead. Experiments on several sequence prediction tasks show that this approach yields significant improvements. Moreover, it was used successfully in our winning entry to the MSCOCO image captioning challenge, 2015."
https://openalex.org/W2129095580,"ChloroP, a neural network‐based method for predicting chloroplast transit peptides and their cleavage sites","{'Abstract': [0], 'We': [1], 'present': [2], 'a': [3, 59, 126], 'neural': [4], 'network': [5], 'based': [6], 'method': [7, 105], '(ChloroP)': [8], 'for': [9, 109], 'identifying': [10], 'chloroplast': [11, 50], 'transit': [12, 34, 114], 'peptides': [13, 35, 115], 'and': [14], 'their': [15], 'cleavage': [16, 73, 87], 'sites.': [17], 'Using': [18], 'cross‐validation,': [19], '88%': [20], 'of': [21, 46, 70, 94, 112], 'the': [22, 47, 71, 86, 103, 110], 'sequences': [23, 98], 'in': [24, 75, 90, 116], 'our': [25, 76], 'homology': [26], 'reduced': [27], 'training': [28], 'set': [29], 'were': [30, 79], 'correctly': [31], 'classified': [32], 'as': [33, 125], 'or': [36], 'nontransit': [37], 'peptides.': [38], 'This': [39], 'performance': [40], 'level': [41], 'is': [42, 123], 'well': [43], 'above': [44], 'that': [45, 102], 'publicly': [48], 'available': [49, 124], 'localization': [51], 'predictor': [52, 122], 'PSORT.': [53], 'Cleavage': [54], 'sites': [55, 74, 88], 'are': [56], 'predicted': [57, 80], 'using': [58], 'scoring': [60], 'matrix': [61], 'derived': [62], 'by': [63], 'an': [64], 'automatic': [65], 'motif‐finding': [66], 'algorithm.': [67], 'Approximately': [68], '60%': [69], 'known': [72], 'sequence': [77, 118], 'collection': [78], 'to': [81], 'within': [82], '62': [83], 'residues': [84], 'from': [85, 99], 'given': [89], 'SWISS‐PROT.': [91], 'An': [92], 'analysis': [93], '715': [95], 'Arabidopsis': [96], 'thaliana': [97], 'SWISS‐PROT': [100], 'suggests': [101], 'ChloroP': [104, 121], 'should': [106], 'be': [107], 'useful': [108], 'identification': [111], 'putative': [113], 'genome‐wide': [117], 'data.': [119], 'The': [120], 'web‐server': [127], 'at': [128], 'http://www.cbs.dtu.dk/services/ChloroP/': [129], '.': [130]}",1999,"['Transit Peptide', 'Cleavage (geology)', 'Chloroplast', 'Computational biology', 'Genome', 'Sequence homology', 'Distance matrix', 'Biology', 'Computer science', 'Genetics', 'Peptide sequence', 'Gene', 'Algorithm', 'Fracture (geology)', 'Paleontology', 'Plastid']","Abstract We present a neural network based method (ChloroP) for identifying chloroplast transit peptides and their cleavage sites. Using cross‐validation, 88% of the sequences in our homology reduced training set were correctly classified as transit peptides or nontransit peptides. This performance level is well above that of the publicly available chloroplast localization predictor PSORT. Cleavage sites are predicted using a scoring matrix derived by an automatic motif‐finding algorithm. Approximately 60% of the known cleavage sites in our sequence collection were predicted to within 62 residues from the cleavage sites given in SWISS‐PROT. An analysis of 715 Arabidopsis thaliana sequences from SWISS‐PROT suggests that the ChloroP method should be useful for the identification of putative transit peptides in genome‐wide sequence data. The ChloroP predictor is available as a web‐server at http://www.cbs.dtu.dk/services/ChloroP/ ."
https://openalex.org/W2934843808,Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks,"{'Lack': [0], 'of': [1, 124, 129, 145, 147], 'transparency': [2], 'in': [3, 46], 'deep': [4], 'neural': [5], 'networks': [6], '(DNNs)': [7], 'make': [8], 'them': [9], 'susceptible': [10], 'to': [11, 22, 65], 'backdoor': [12, 32, 92, 130, 149], 'attacks,': [13], 'where': [14], 'hidden': [15, 52], 'associations': [16], 'or': [17, 68, 76], 'triggers': [18], 'override': [19], 'normal': [20], 'classification': [21], 'produce': [23], 'unexpected': [24], 'results.': [25], 'For': [26], 'example,': [27], 'a': [28, 31, 35, 41, 61, 122, 143], 'model': [29], 'with': [30], 'always': [33], 'identifies': [34], 'face': [36], 'as': [37], 'Bill': [38], 'Gates': [39], 'if': [40], 'specific': [42], 'symbol': [43], 'is': [44], 'present': [45, 60, 80], 'the': [47, 81, 148], 'input.': [48], 'Backdoors': [49], 'can': [50], 'stay': [51], 'indefinitely': [53], 'until': [54], 'activated': [55], 'by': [56, 134], 'an': [57], 'input,': [58], 'and': [59, 84, 87, 98, 112], 'serious': [62], 'security': [63, 67], 'risk': [64], 'many': [66], 'safety': [69], 'related': [70], 'applications,': [71], 'e.g.': [72], 'biometric': [73], 'authentication': [74], 'systems': [75], 'self-driving': [77], 'cars.': [78], 'We': [79, 102, 114], 'first': [82], 'robust': [83, 141], 'generalizable': [85], 'detection': [86], 'mitigation': [88, 105], 'system': [89], 'for': [90], 'DNN': [91], 'attacks.': [93], 'Our': [94, 137], 'techniques': [95, 106, 138], 'identify': [96, 103], 'backdoors': [97], 'reconstruct': [99], 'possible': [100], 'triggers.': [101], 'multiple': [104], 'via': [107, 118], 'input': [108], 'filters,': [109], 'neuron': [110], 'pruning': [111], 'unlearning.': [113], 'demonstrate': [115], 'their': [116], 'efficacy': [117], 'extensive': [119], 'experiments': [120], 'on': [121], 'variety': [123], 'DNNs,': [125], 'against': [126, 142], 'two': [127], 'types': [128], 'injection': [131], 'methods': [132], 'identified': [133], 'prior': [135], 'work.': [136], 'also': [139], 'prove': [140], 'number': [144], 'variants': [146], 'attack.': [150]}",2019,"['Backdoor', 'Artificial neural network', 'Computer science', 'Artificial intelligence', 'Computer security']","Lack of transparency in deep neural networks (DNNs) make them susceptible to backdoor attacks, where hidden associations or triggers override normal classification to produce unexpected results. For example, a model with a backdoor always identifies a face as Bill Gates if a specific symbol is present in the input. Backdoors can stay hidden indefinitely until activated by an input, and present a serious security risk to many security or safety related applications, e.g. biometric authentication systems or self-driving cars. We present the first robust and generalizable detection and mitigation system for DNN backdoor attacks. Our techniques identify backdoors and reconstruct possible triggers. We identify multiple mitigation techniques via input filters, neuron pruning and unlearning. We demonstrate their efficacy via extensive experiments on a variety of DNNs, against two types of backdoor injection methods identified by prior work. Our techniques also prove robust against a number of variants of the backdoor attack."
https://openalex.org/W3080253043,Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks,"{'Modeling': [0], 'multivariate': [1, 28, 95, 120], 'time': [2, 29, 96, 121, 171], 'series': [3, 30, 97, 122], 'has': [4, 10], 'long': [5], 'been': [6], 'a': [7, 14, 111, 134, 155], 'subject': [8], 'that': [9, 33, 49, 192], 'attracted': [11], 'researchers': [12], 'from': [13], 'diverse': [15], 'range': [16], 'of': [17, 61, 203], 'fields': [18], 'including': [19], 'economics,': [20], 'finance,': [21], 'and': [22, 154, 166, 178, 207], 'traffic.': [23], 'A': [24, 149], 'basic': [25], 'assumption': [26], 'behind': [27], 'forecasting': [31], 'is': [32, 45], 'its': [34], 'variables': [35, 132], 'depend': [36], 'on': [37, 201, 214], 'one': [38], 'another': [39], 'but,': [40], 'upon': [41], 'looking': [42], 'closely,': [43], 'it': [44], 'fair': [46], 'to': [47, 53, 162], 'say': [48], 'existing': [50], 'methods': [51, 200], 'fail': [52], 'fully': [54], 'exploit': [55], 'latent': [56], 'spatial': [57, 165], 'dependencies': [58, 100, 168], 'between': [59], 'pairs': [60], 'variables.': [62], 'In': [63, 106], 'recent': [64], 'years,': [65], 'meanwhile,': [66], 'graph': [67, 82, 113, 135, 174, 176], 'neural': [68, 114], 'networks': [69], '(GNNs)': [70], 'have': [71], 'shown': [72], 'high': [73], 'capability': [74], 'in': [75, 104, 185], 'handling': [76], 'relational': [77], 'dependencies.': [78], 'GNNs': [79], 'require': [80], 'well-defined': [81], 'structures': [83], 'for': [84, 94, 119], 'information': [85], 'propagation': [86, 152], 'which': [87, 139, 218], 'means': [88], 'they': [89], 'cannot': [90], 'be': [91, 146], 'applied': [92], 'directly': [93], 'where': [98], 'the': [99, 128, 164, 170, 197], 'are': [101, 159, 182], 'not': [102], 'known': [103], 'advance.': [105], 'this': [107], 'paper,': [108], 'we': [109], 'propose': [110], 'general': [112], 'network': [115], 'framework': [116], 'designed': [117], 'specifically': [118], 'data.': [123], 'Our': [124], 'approach': [125], 'automatically': [126], 'extracts': [127], 'uni-directed': [129], 'relations': [130], 'among': [131], 'through': [133], 'learning': [136], 'module,': [137], 'into': [138], 'external': [140], 'knowledge': [141], 'like': [142], 'variable': [143], 'attributes': [144], 'can': [145], 'easily': [147], 'integrated.': [148], 'novel': [150], 'mix-hop': [151], 'layer': [153, 158], 'dilated': [156], 'inception': [157], 'further': [160], 'proposed': [161, 194], 'capture': [163], 'temporal': [167, 179], 'within': [169], 'series.': [172], 'The': [173], 'learning,': [175], 'convolution,': [177], 'convolution': [180], 'modules': [181], 'jointly': [183], 'learned': [184], 'an': [186], 'end-to-end': [187], 'framework.': [188], 'Experimental': [189], 'results': [190], 'show': [191], 'our': [193], 'model': [195], 'outperforms': [196], 'state-of-the-art': [198], 'baseline': [199], '3': [202], '4': [204], 'benchmark': [205], 'datasets': [206, 217], 'achieves': [208], 'on-par': [209], 'performance': [210], 'with': [211], 'other': [212], 'approaches': [213], 'two': [215], 'traffic': [216], 'provide': [219], 'extra': [220], 'structural': [221], 'information.': [222]}",2020,"['Computer science', 'Multivariate statistics', 'Graph', 'Data mining', 'Time series', 'Exploit', 'Artificial intelligence', 'Artificial neural network', 'Machine learning', 'Theoretical computer science', 'Computer security']","Modeling multivariate time series has long been a subject that has attracted researchers from a diverse range of fields including economics, finance, and traffic. A basic assumption behind multivariate time series forecasting is that its variables depend on one another but, upon looking closely, it is fair to say that existing methods fail to fully exploit latent spatial dependencies between pairs of variables. In recent years, meanwhile, graph neural networks (GNNs) have shown high capability in handling relational dependencies. GNNs require well-defined graph structures for information propagation which means they cannot be applied directly for multivariate time series where the dependencies are not known in advance. In this paper, we propose a general graph neural network framework designed specifically for multivariate time series data. Our approach automatically extracts the uni-directed relations among variables through a graph learning module, into which external knowledge like variable attributes can be easily integrated. A novel mix-hop propagation layer and a dilated inception layer are further proposed to capture the spatial and temporal dependencies within the time series. The graph learning, graph convolution, and temporal convolution modules are jointly learned in an end-to-end framework. Experimental results show that our proposed model outperforms the state-of-the-art baseline methods on 3 of 4 benchmark datasets and achieves on-par performance with other approaches on two traffic datasets which provide extra structural information."
https://openalex.org/W2962834855,Sigmoid-weighted linear units for neural network function approximation in reinforcement learning,"{'In': [0], 'recent': [1], 'years,': [2], 'neural': [3, 55], 'networks': [4], 'have': [5], 'enjoyed': [6], 'a': [7, 119, 141, 167], 'renaissance': [8], 'as': [9], 'function': [10, 57, 70, 82], 'approximators': [11], 'in': [12, 25, 36, 59, 134, 160], 'reinforcement': [13, 29, 60], 'learning.': [14], 'Two': [15], 'decades': [16], 'after': [17], ""Tesauro's"": [18], 'TD-Gammon': [19], 'achieved': [20, 33], 'near': [21], 'top-level': [22], 'human': [23], 'performance': [24, 35], 'backgammon,': [26], 'the': [27, 62, 75, 80, 91, 116, 161], 'deep': [28, 168], 'learning': [30, 98, 149], 'algorithm': [31], 'DQN': [32, 159], 'human-level': [34], 'many': [37], 'Atari': [38, 162], '2600': [39, 163], 'games.': [40], 'The': [41, 72], 'purpose': [42], 'of': [43, 74, 95, 103], 'this': [44], 'study': [45], 'is': [46, 77], 'twofold.': [47], 'First,': [48], 'we': [49, 88], 'propose': [50], 'two': [51], 'activation': [52, 73], 'functions': [53], 'for': [54, 118], 'network': [56, 153], 'approximation': [58], 'learning:': [61], 'sigmoid-weighted': [63], 'linear': [64], 'unit': [65], '(SiLU)': [66], 'and': [67, 106, 138, 150, 173], 'its': [68, 85], 'derivative': [69], '(dSiLU).': [71], 'SiLU': [76, 172], 'computed': [78], 'by': [79, 84, 157, 165], 'sigmoid': [81], 'multiplied': [83], 'input.': [86], 'Second,': [87], 'suggest': [89], 'that': [90], 'more': [92], 'traditional': [93], 'approach': [94, 127], 'using': [96, 147, 166], 'on-policy': [97], 'with': [99, 113, 140, 171], 'eligibility': [100], 'traces,': [101], 'instead': [102], 'experience': [104], 'replay,': [105], 'softmax': [107], 'action': [108], 'selection': [109], 'can': [110], 'be': [111], 'competitive': [112], 'DQN,': [114], 'without': [115], 'need': [117], 'separate': [120], 'target': [121], 'network.': [122], 'We': [123], 'validate': [124], 'our': [125], 'proposed': [126], 'by,': [128], 'first,': [129], 'achieving': [130], 'new': [131], 'state-of-the-art': [132], 'results': [133], 'both': [135], 'stochastic': [136], 'SZ-Tetris': [137], 'Tetris': [139], 'small': [142], '10': [143, 145], '×': [144], 'board,': [146], 'TD(λ)': [148], 'shallow': [151], 'dSiLU': [152, 174], 'agents,': [154], 'and,': [155], 'then,': [156], 'outperforming': [158], 'domain': [164], 'Sarsa(λ)': [169], 'agent': [170], 'hidden': [175], 'units.': [176]}",2018,"['Sigmoid function', 'Artificial neural network', 'Reinforcement learning', 'Reinforcement', 'Computer science', 'Artificial intelligence', 'Function approximation', 'Function (biology)', 'Mathematics', 'Psychology', 'Biology', 'Evolutionary biology', 'Social psychology']","In recent years, neural networks have enjoyed a renaissance as function approximators in reinforcement learning. Two decades after Tesauro's TD-Gammon achieved near top-level human performance in backgammon, the deep reinforcement learning algorithm DQN achieved human-level performance in many Atari 2600 games. The purpose of this study is twofold. First, we propose two activation functions for neural network function approximation in reinforcement learning: the sigmoid-weighted linear unit (SiLU) and its derivative function (dSiLU). The activation of the SiLU is computed by the sigmoid function multiplied by its input. Second, we suggest that the more traditional approach of using on-policy learning with eligibility traces, instead of experience replay, and softmax action selection can be competitive with DQN, without the need for a separate target network. We validate our proposed approach by, first, achieving new state-of-the-art results in both stochastic SZ-Tetris and Tetris with a small 10 × 10 board, using TD(λ) learning and shallow dSiLU network agents, and, then, by outperforming DQN in the Atari 2600 domain by using a deep Sarsa(λ) agent with SiLU and dSiLU hidden units."
https://openalex.org/W2469490737,DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients,"{'We': [0], 'propose': [1], 'DoReFa-Net,': [2], 'a': [3, 118], 'method': [4], 'to': [5, 32, 39, 63, 87, 137], 'train': [6], 'convolutional': [7, 40], 'neural': [8, 93], 'networks': [9], 'that': [10, 106, 123], 'have': [11], 'low': [12, 18, 33, 51, 91], 'bitwidth': [13, 19, 34, 52, 92], 'weights': [14, 53], 'and': [15, 54, 67, 81, 102], 'activations': [16], 'using': [17, 134], 'parameter': [20, 27], 'gradients.': [21], 'In': [22], 'particular,': [23], 'during': [24, 44], 'backward': [25], 'pass,': [26], 'gradients': [28, 136], 'are': [29], 'stochastically': [30], 'quantized': [31], 'numbers': [35], 'before': [36], 'being': [37], 'propagated': [38], 'layers.': [41], 'As': [42], 'convolutions': [43, 72], 'forward/backward': [45], 'passes': [46], 'can': [47, 58, 73, 108, 129], 'now': [48], 'operate': [49], 'on': [50, 77, 95, 100, 142], 'activations/gradients': [55], 'respectively,': [56], 'DoReFa-Net': [57, 83, 107, 119, 147], 'use': [59], 'bit': [60, 71], 'convolution': [61], 'kernels': [62], 'accelerate': [64, 88], 'both': [65], 'training': [66, 89], 'inference.': [68], 'Moreover,': [69], 'as': [70, 113], 'be': [74, 130], 'efficiently': [75], 'implemented': [76], 'CPU,': [78], 'FPGA,': [79], 'ASIC': [80], 'GPU,': [82], 'opens': [84], 'the': [85], 'way': [86], 'of': [90], 'network': [94], 'these': [96], 'hardware.': [97], 'Our': [98], 'experiments': [99], 'SVHN': [101], 'ImageNet': [103, 143], 'datasets': [104], 'prove': [105], 'achieve': [109], 'comparable': [110], 'prediction': [111], 'accuracy': [112, 141], '32-bit': [114], 'counterparts.': [115], 'For': [116], 'example,': [117], 'derived': [120], 'from': [121, 132], 'AlexNet': [122, 148], 'has': [124], '1-bit': [125], 'weights,': [126], '2-bit': [127], 'activations,': [128], 'trained': [131], 'scratch': [133], '6-bit': [135], 'get': [138], '46.1\\%': [139], 'top-1': [140], 'validation': [144], 'set.': [145], 'The': [146], 'model': [149], 'is': [150], 'released': [151], 'publicly.': [152]}",2016,"['Computer science', 'Convolutional neural network', 'Net (polyhedron)', 'Convolution (computer science)', 'Inference', 'Set (abstract data type)', 'Algorithm', 'Parallel computing', 'Application-specific integrated circuit', 'Artificial neural network', 'Artificial intelligence', 'Computer hardware', 'Mathematics', 'Programming language', 'Geometry']","We propose DoReFa-Net, a method to train convolutional neural networks that have low bitwidth weights and activations using low bitwidth parameter gradients. In particular, during backward pass, parameter gradients are stochastically quantized to low bitwidth numbers before being propagated to convolutional layers. As convolutions during forward/backward passes can now operate on low bitwidth weights and activations/gradients respectively, DoReFa-Net can use bit convolution kernels to accelerate both training and inference. Moreover, as bit convolutions can be efficiently implemented on CPU, FPGA, ASIC and GPU, DoReFa-Net opens the way to accelerate training of low bitwidth neural network on these hardware. Our experiments on SVHN and ImageNet datasets prove that DoReFa-Net can achieve comparable prediction accuracy as 32-bit counterparts. For example, a DoReFa-Net derived from AlexNet that has 1-bit weights, 2-bit activations, can be trained from scratch using 6-bit gradients to get 46.1\% top-1 accuracy on ImageNet validation set. The DoReFa-Net AlexNet model is released publicly."
https://openalex.org/W4395669330,Fault Detection Method based on Artificial Neural Network for 330kV Nigerian Transmission Line,"{'This': [0], 'research': [1], 'focused': [2], 'on': [3, 10, 92], 'identifying': [4, 85], 'various': [5, 86], 'types': [6, 62], 'of': [7, 17, 58, 63, 80], 'faults': [8, 64], 'occurring': [9], '330kV': [11, 28, 95], 'transmission': [12, 29, 96], 'lines': [13], 'through': [14], 'the': [15, 26, 50, 78, 81, 93], 'use': [16], 'artificial': [18], 'neural': [19], 'networks': [20], '(ANN).': [21], 'A': [22], 'MATLAB': [23, 100], 'model': [24, 83], 'for': [25, 55], 'Gwagwalada-Katampe': [27, 94], 'line': [30], 'in': [31, 84], 'Nigeria': [32], 'was': [33], 'implemented': [34], 'to': [35, 46], 'generate': [36], 'fault': [37, 42, 59, 87], 'datasets.': [38], 'Voltage': [39], 'and': [40, 48, 89], 'current': [41], 'parameters': [43, 91], 'were': [44, 65], 'utilized': [45], 'train': [47], 'simulate': [49], 'ANN': [51], 'network': [52], 'architecture': [53], 'selected': [54], 'each': [56], 'stage': [57], 'detection.': [60], 'Four': [61], 'considered,': [66], 'along': [67], 'with': [68], 'a': [69], 'fifth': [70], 'condition': [71], 'representing': [72], 'no': [73], 'fault.': [74], 'The': [75], 'results': [76], 'illustrated': [77], 'success': [79], 'developed': [82], 'conditions': [88], 'system': [90], 'line,': [97], 'modelled': [98], 'using': [99], 'Simulink.': [101]}",2024,"['Artificial neural network', 'Computer science', 'Transmission line', 'Fault (geology)', 'Fault detection and isolation', 'Artificial intelligence', 'Transmission (telecommunications)', 'Line (geometry)', 'Electric power transmission', 'Pattern recognition (psychology)', 'Engineering', 'Telecommunications', 'Electrical engineering', 'Mathematics', 'Biology', 'Paleontology', 'Actuator', 'Geometry']","This research focused on identifying various types of faults occurring on 330kV transmission lines through the use of artificial neural networks (ANN). A MATLAB model for the Gwagwalada-Katampe 330kV transmission line in Nigeria was implemented to generate fault datasets. Voltage and current fault parameters were utilized to train and simulate the ANN network architecture selected for each stage of fault detection. Four types of faults were considered, along with a fifth condition representing no fault. The results illustrated the success of the developed model in identifying various fault conditions and system parameters on the Gwagwalada-Katampe 330kV transmission line, modelled using MATLAB Simulink."
https://openalex.org/W2707890836,Pruning Convolutional Neural Networks for Resource Efficient Inference,"{'We': [0, 16, 38, 60, 115], 'propose': [1, 39], 'a': [2, 26, 40, 135, 141], 'new': [3, 41], 'formulation': [4], 'for': [5, 94, 149], 'pruning': [6, 20, 57, 95, 119], 'convolutional': [7], 'kernels': [8], 'in': [9, 34, 51, 130, 138, 140], 'neural': [10], 'networks': [11, 68], 'to': [12, 71, 81, 100, 122, 154], 'enable': [13], 'efficient': [14, 28], 'inference.': [15], 'interleave': [17], 'greedy': [18], 'criteria-based': [19], 'with': [21, 134], 'fine-tuning': [22], 'by': [23, 56], 'backpropagation': [24], '-': [25], 'computationally': [27], 'procedure': [29], 'that': [30, 47, 118], 'maintains': [31], 'good': [32], 'generalization': [33], 'the': [35, 49, 52, 85, 110, 150, 156], 'pruned': [36], 'network.': [37], 'criterion': [42, 76], 'based': [43], 'on': [44, 62, 109], 'Taylor': [45], 'expansion': [46], 'approximates': [48], 'change': [50], 'cost': [53], 'function': [54], 'induced': [55], 'network': [58], 'parameters.': [59], 'focus': [61], 'transfer': [63], 'learning,': [64], 'where': [65], 'large': [66, 96], 'pretrained': [67], 'are': [69], 'adapted': [70, 131], 'specialized': [72], 'tasks.': [73], 'The': [74], 'proposed': [75], 'demonstrates': [77], 'superior': [78], 'performance': [79], 'compared': [80], 'other': [82], 'criteria,': [83], 'e.g.': [84], 'norm': [86], 'of': [87, 158], 'kernel': [88], 'weights': [89], 'or': [90], 'feature': [91], 'map': [92], 'activation,': [93], 'CNNs': [97], 'after': [98], 'adaptation': [99], 'fine-grained': [101], 'classification': [102], 'tasks': [103], '(Birds-200': [104], 'and': [105], 'Flowers-102)': [106], 'relaying': [107], 'only': [108], 'first': [111], 'order': [112], 'gradient': [113], 'information.': [114], 'also': [116], 'show': [117, 147], 'can': [120], 'lead': [121], 'more': [123], 'than': [124], '10x': [125], 'theoretical': [126], '(5x': [127], 'practical)': [128], 'reduction': [129], '3D-convolutional': [132], 'filters': [133], 'small': [136], 'drop': [137], 'accuracy': [139], 'recurrent': [142], 'gesture': [143], 'classifier.': [144], 'Finally,': [145], 'we': [146], 'results': [148], 'large-scale': [151], 'ImageNet': [152], 'dataset': [153], 'emphasize': [155], 'flexibility': [157], 'our': [159], 'approach.': [160]}",2016,"['Computer science', 'Convolutional neural network', 'Artificial intelligence', 'Inference', 'Pruning', 'Backpropagation', 'Classifier (UML)', 'Machine learning', 'Pattern recognition (psychology)', 'Artificial neural network', 'Biology', 'Agronomy']","We propose a new formulation for pruning convolutional kernels in neural networks to enable efficient inference. We interleave greedy criteria-based pruning with fine-tuning by backpropagation - a computationally efficient procedure that maintains good generalization in the pruned network. We propose a new criterion based on Taylor expansion that approximates the change in the cost function induced by pruning network parameters. We focus on transfer learning, where large pretrained networks are adapted to specialized tasks. The proposed criterion demonstrates superior performance compared to other criteria, e.g. the norm of kernel weights or feature map activation, for pruning large CNNs after adaptation to fine-grained classification tasks (Birds-200 and Flowers-102) relaying only on the first order gradient information. We also show that pruning can lead to more than 10x theoretical (5x practical) reduction in adapted 3D-convolutional filters with a small drop in accuracy in a recurrent gesture classifier. Finally, we show results for the large-scale ImageNet dataset to emphasize the flexibility of our approach."
https://openalex.org/W2541404351,ANI-1: an extensible neural network potential with DFT accuracy at force field computational cost,"{'We': [0], 'demonstrate': [1], 'how': [2], 'a': [3, 10], 'deep': [4], 'neural': [5], 'network': [6], '(NN)': [7], 'trained': [8], 'on': [9], 'data': [11], 'set': [12], 'of': [13], 'quantum': [14], 'mechanical': [15], '(QM)': [16], 'DFT': [17], 'calculated': [18], 'energies': [19], 'can': [20], 'learn': [21], 'an': [22], 'accurate': [23], 'and': [24, 35], 'transferable': [25], 'atomistic': [26], 'potential': [27], 'for': [28], 'organic': [29], 'molecules': [30], 'containing': [31], 'H,': [32], 'C,': [33], 'N,': [34], 'O': [36], 'atoms.': [37]}",2017,"['Artificial neural network', 'Force field (fiction)', 'Extensibility', 'Set (abstract data type)', 'Molecule', 'Quantum', 'Field (mathematics)', 'Computer science', 'Organic molecules', 'Computational chemistry', 'Deep neural networks', 'Density functional theory', 'Biological system', 'Artificial intelligence', 'Materials science', 'Chemistry', 'Physics', 'Quantum mechanics', 'Mathematics', 'Biology', 'Pure mathematics', 'Programming language', 'Operating system']","We demonstrate how a deep neural network (NN) trained on a data set of quantum mechanical (QM) DFT calculated energies can learn an accurate and transferable atomistic potential for organic molecules containing H, C, N, and O atoms."
https://openalex.org/W2805003733,"The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks","{'Neural': [0], 'network': [1, 101, 192], 'pruning': [2, 37, 56], 'techniques': [3], 'can': [4], 'reduce': [5], 'the': [6, 32, 43, 75, 99, 115, 143, 148, 165, 181, 190], 'parameter': [7], 'counts': [8], 'of': [9, 22, 66, 106, 139, 150, 164, 167], 'trained': [10, 90], 'networks': [11, 82], 'by': [12, 36], 'over': [13], '90%,': [14], 'decreasing': [15], 'storage': [16], 'requirements': [17], 'and': [18, 136, 147, 170, 176, 193], 'improving': [19], 'computational': [20], 'performance': [21], 'inference': [23], 'without': [24], 'compromising': [25], 'accuracy.': [26, 197], 'However,': [27], 'contemporary': [28], 'experience': [29], 'is': [30], 'that': [31, 53, 87, 123, 141, 159, 184], 'sparse': [33], 'architectures': [34, 173], 'produced': [35], 'are': [38, 160], 'difficult': [39], 'to': [40, 98, 132], 'train': [41], 'from': [42], 'start,': [44], 'which': [45], 'would': [46], 'similarly': [47], 'improve': [48], 'training': [49, 67, 125], 'performance.': [50], 'We': [51, 128, 154], 'find': [52, 112, 156, 186], 'a': [54, 103, 137], 'standard': [55], 'technique': [57], 'naturally': [58], 'uncovers': [59], 'subnetworks': [60, 84], 'whose': [61], 'initializations': [62], 'made': [63], 'them': [64], 'capable': [65], 'effectively.': [68], 'Based': [69], 'on': [70], 'these': [71, 151], 'results,': [72], 'we': [73, 111, 185], 'articulate': [74], '""lottery': [76], 'ticket': [77, 145], 'hypothesis:""': [78], 'dense,': [79], 'randomly-initialized,': [80], 'feed-forward': [81, 172], 'contain': [83], '(""winning': [85], 'tickets"")': [86], '-': [88, 93], 'when': [89], 'in': [91, 102], 'isolation': [92], 'reach': [94, 194], 'test': [95, 196], 'accuracy': [96], 'comparable': [97], 'original': [100, 191], 'similar': [104], 'number': [105], 'iterations.': [107], 'The': [108], 'winning': [109, 134, 157, 182], 'tickets': [110, 135, 158, 183], 'have': [113, 120], 'won': [114], 'initialization': [116], 'lottery:': [117], 'their': [118], 'connections': [119], 'initial': [121], 'weights': [122], 'make': [124], 'particularly': [126], 'effective.': [127], 'present': [129], 'an': [130], 'algorithm': [131], 'identify': [133], 'series': [138], 'experiments': [140], 'support': [142], 'lottery': [144], 'hypothesis': [146], 'importance': [149], 'fortuitous': [152], 'initializations.': [153], 'consistently': [155], 'less': [161], 'than': [162, 189], '10-20%': [163], 'size': [166], 'several': [168], 'fully-connected': [169], 'convolutional': [171], 'for': [174], 'MNIST': [175], 'CIFAR10.': [177], 'Above': [178], 'this': [179], 'size,': [180], 'learn': [187], 'faster': [188], 'higher': [195]}",2018,"['Pruning', 'Initialization', 'Lottery', 'Computer science', 'Ticket', 'Inference', 'Machine learning', 'Artificial intelligence', 'Artificial neural network', 'Convolutional neural network', 'MNIST database', 'Test (biology)', 'Mathematics', 'Statistics', 'Computer security', 'Agronomy', 'Programming language', 'Paleontology', 'Biology']","Neural network pruning techniques can reduce the parameter counts of trained networks by over 90%, decreasing storage requirements and improving computational performance of inference without compromising accuracy. However, contemporary experience is that the sparse architectures produced by pruning are difficult to train from the start, which would similarly improve training performance. We find that a standard pruning technique naturally uncovers subnetworks whose initializations made them capable of training effectively. Based on these results, we articulate the ""lottery ticket hypothesis:"" dense, randomly-initialized, feed-forward networks contain subnetworks (""winning tickets"") that - when trained in isolation - reach test accuracy comparable to the original network in a similar number of iterations. The winning tickets we find have won the initialization lottery: their connections have initial weights that make training particularly effective. We present an algorithm to identify winning tickets and a series of experiments that support the lottery ticket hypothesis and the importance of these fortuitous initializations. We consistently find winning tickets that are less than 10-20% of the size of several fully-connected and convolutional feed-forward architectures for MNIST and CIFAR10. Above this size, the winning tickets that we find learn faster than the original network and reach higher test accuracy."
https://openalex.org/W2076750860,Neural Networks: A Review from a Statistical Perspective,"{'This': [0], 'paper': [1, 132], 'informs': [2], 'a': [3, 41, 73], 'statistical': [4, 18, 35, 74, 98], 'readership': [5], 'about': [6], 'Artificial': [7], 'Neural': [8], 'Networks': [9], '(ANNs),': [10], 'points': [11], 'out': [12], 'some': [13, 135], 'of': [14, 34, 43, 48, 140], 'the': [15, 25, 46, 64, 138, 141], 'links': [16], 'with': [17, 120, 128, 134], 'methodology': [19], 'and': [20, 40, 68, 71, 100, 103, 123, 125, 146], 'encourages': [21], 'cross-disciplinary': [22], 'research': [23], 'in': [24, 56, 79], 'directions': [26], 'most': [27], 'likely': [28], 'to': [29, 86, 97, 116], 'bear': [30], 'fruit.': [31], 'The': [32, 76, 131], 'areas': [33], 'interest': [36], 'are': [37, 82, 114], 'briefly': [38], 'outlined,': [39], 'series': [42], 'examples': [44], 'indicates': [45], 'flavor': [47], 'ANN': [49], 'models.': [50], 'We': [51], 'then': [52], 'treat': [53], 'various': [54], 'topics': [55, 77], 'more': [57], 'depth.': [58], 'In': [59], 'each': [60], 'case,': [61], 'we': [62], 'describe': [63], 'neural': [65, 144], 'network': [66], 'architectures': [67], 'training': [69], 'rules': [70], 'provide': [72], 'commentary.': [75], 'treated': [78], 'this': [80], 'way': [81], 'perceptrons': [83], '(from': [84], 'single-unit': [85], 'multilayer': [87], 'versions),': [88], 'Hopfield-type': [89], 'recurrent': [90], 'networks': [91, 106, 127, 145], '(including': [92], 'probabilistic': [93], 'versions': [94], 'strongly': [95], 'related': [96], 'physics': [99], 'Gibbs': [101], 'distributions)': [102], 'associative': [104], 'memory': [105], 'trained': [107], 'by': [108], 'so-called': [109], 'unsuperviszd': [110], 'learning': [111], 'rules.': [112], 'Perceptrons': [113], 'shown': [115], 'have': [117], 'strong': [118], 'associations': [119], 'discriminant': [121], 'analysis': [122], 'regression,': [124], 'unsupervized': [126], 'cluster': [129], 'analysis.': [130], 'concludes': [133], 'thoughts': [136], 'on': [137], 'future': [139], 'interface': [142], 'between': [143], 'statistics.': [147]}",1994,"['Artificial neural network', 'Perceptron', 'Computer science', 'Artificial intelligence', 'Statistical model', 'Machine learning', 'Probabilistic logic', 'Perspective (graphical)', 'Associative property', 'Mathematics', 'Pure mathematics']","This paper informs a statistical readership about Artificial Neural Networks (ANNs), points out some of the links with statistical methodology and encourages cross-disciplinary research in the directions most likely to bear fruit. The areas of statistical interest are briefly outlined, and a series of examples indicates the flavor of ANN models. We then treat various topics in more depth. In each case, we describe the neural network architectures and training rules and provide a statistical commentary. The topics treated in this way are perceptrons (from single-unit to multilayer versions), Hopfield-type recurrent networks (including probabilistic versions strongly related to statistical physics and Gibbs distributions) and associative memory networks trained by so-called unsuperviszd learning rules. Perceptrons are shown to have strong associations with discriminant analysis and regression, and unsupervized networks with cluster analysis. The paper concludes with some thoughts on the future of the interface between neural networks and statistics."
https://openalex.org/W2415243320,Deep Neural Networks for Learning Graph Representations,"{'In': [0], 'this': [1], 'paper,': [2], 'we': [3, 33, 166], 'propose': [4], 'a': [5, 14, 35, 78], 'novel': [6], 'model': [7, 38, 113, 151, 157, 191], 'for': [8, 18, 51, 81, 133], 'learning': [9], 'graph': [10, 24, 41], 'representations,': [11], 'which': [12, 93, 126], 'generates': [13], 'low-dimensional': [15], 'vector': [16], 'representation': [17], 'each': [19], 'vertex': [20, 177], 'by': [21, 56, 87, 118], 'capturing': [22], 'the': [23, 48, 82, 94, 107, 111, 128, 131, 135, 139, 143, 161, 175], 'structural': [25, 42], 'information.': [26], 'Different': [27], 'from': [28, 69, 138], 'other': [29, 193], 'previous': [30], 'research': [31], 'efforts,': [32], 'adopt': [34], 'random': [36], 'surfing': [37], 'to': [39, 106, 152], 'capture': [40], 'information': [43, 97], 'directly,': [44], 'instead': [45], 'of': [46, 63, 110, 130, 163, 185], 'using': [47], 'sampling-based': [49], 'method': [50, 85], 'generating': [52], 'linear': [53], 'sequences': [54], 'proposed': [55, 86, 117], 'Perozzi': [57], 'et': [58, 120], 'al.': [59, 121], '(2014).': [60], 'The': [61], 'advantages': [62], 'our': [64, 150, 164, 190], 'approach': [65, 125], 'will': [66], 'be': [67], 'illustrated': [68], 'both': [70], 'theorical': [71], 'and': [72, 89, 156, 171], 'empirical': [73], 'perspectives.': [74], 'We': [75], 'also': [76], 'give': [77], 'new': [79], 'perspective': [80], 'matrix': [83, 99], 'factorization': [84], 'Levy': [88], 'Goldberg': [90], '(2014),': [91], 'in': [92, 149, 196], 'pointwise': [95], 'mutual': [96], '(PMI)': [98], 'is': [100, 147], 'considered': [101], 'as': [102, 179], 'an': [103], 'analytical': [104], 'solution': [105], 'objective': [108], 'function': [109], 'skip-gram': [112], 'with': [114], 'negative': [115], 'sampling': [116], 'Mikolov': [119], '(2013).': [122], 'Unlike': [123], 'their': [124], 'involves': [127], 'use': [129], 'SVD': [132], 'finding': [134], 'low-dimensitonal': [136], 'projections': [137], 'PMI': [140], 'matrix,': [141], 'however,': [142], 'stacked': [144], 'denoising': [145], 'autoencoder': [146], 'introduced': [148], 'extract': [153], 'complex': [154], 'features': [155], 'non-linearities.': [158], 'To': [159], 'demonstrate': [160], 'effectiveness': [162], 'model,': [165], 'conduct': [167], 'experiments': [168], 'on': [169, 183], 'clustering': [170], 'visualization': [172], 'tasks,': [173], 'employing': [174], 'learned': [176], 'representations': [178], 'features.': [180], 'Empirical': [181], 'results': [182], 'datasets': [184], 'varying': [186], 'sizes': [187], 'show': [188], 'that': [189], 'outperforms': [192], 'stat-of-the-art': [194], 'models': [195], 'such': [197], 'tasks.': [198]}",2016,"['Computer science', 'Laplacian matrix', 'Pointwise', 'Cluster analysis', 'Theoretical computer science', 'Graph', 'Artificial intelligence', 'Matrix decomposition', 'Autoencoder', 'Vertex (graph theory)', 'Algorithm', 'Artificial neural network', 'Pattern recognition (psychology)', 'Mathematics', 'Eigenvalues and eigenvectors', 'Physics', 'Mathematical analysis', 'Quantum mechanics']","In this paper, we propose a novel model for learning graph representations, which generates a low-dimensional vector representation for each vertex by capturing the graph structural information. Different from other previous research efforts, we adopt a random surfing model to capture graph structural information directly, instead of using the sampling-based method for generating linear sequences proposed by Perozzi et al. (2014). The advantages of our approach will be illustrated from both theorical and empirical perspectives. We also give a new perspective for the matrix factorization method proposed by Levy and Goldberg (2014), in which the pointwise mutual information (PMI) matrix is considered as an analytical solution to the objective function of the skip-gram model with negative sampling proposed by Mikolov et al. (2013). Unlike their approach which involves the use of the SVD for finding the low-dimensitonal projections from the PMI matrix, however, the stacked denoising autoencoder is introduced in our model to extract complex features and model non-linearities. To demonstrate the effectiveness of our model, we conduct experiments on clustering and visualization tasks, employing the learned vertex representations as features. Empirical results on datasets of varying sizes show that our model outperforms other stat-of-the-art models in such tasks."
https://openalex.org/W2606202972,Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs,"{'A': [0], 'number': [1], 'of': [2, 34, 55, 63, 79, 91], 'problems': [3], 'can': [4], 'be': [5], 'formulated': [6], 'as': [7], 'prediction': [8], 'on': [9, 48, 95], 'graph-structured\\ndata.': [10], 'In': [11], 'this': [12], 'work,': [13], 'we': [14, 75, 86, 100], 'generalize': [15], 'the': [16, 26, 49, 60, 77, 88, 92], 'convolution': [17], 'operator': [18], 'from': [19], 'regular': [20], 'grids\\nto': [21], 'arbitrary': [22], 'graphs': [23, 33], 'while': [24], 'avoiding': [25], 'spectral': [27], 'domain,': [28], 'which': [29], 'allows': [30], 'us': [31], 'to\\nhandle': [32], 'varying': [35], 'size': [36], 'and': [37, 94], 'connectivity.': [38], 'To': [39], 'move': [40], 'beyond': [41], 'a': [42, 56, 96], 'simple\\ndiffusion,': [43], 'filter': [44], 'weights': [45], 'are': [46], 'conditioned': [47], 'specific': [50], 'edge': [51], 'labels': [52], 'in': [53, 82], 'the\\nneighborhood': [54], 'vertex.': [57], 'Together': [58], 'with': [59], 'proper': [61], 'choice': [62], 'graph': [64, 72], 'coarsening,\\nwe': [65], 'explore': [66], 'constructing': [67], 'deep': [68, 103], 'neural': [69], 'networks': [70], 'for': [71], 'classification.': [73], 'In\\nparticular,': [74], 'demonstrate': [76], 'generality': [78], 'our': [80], 'formulation': [81], 'point': [83], 'cloud\\nclassification,': [84], 'where': [85, 99], 'set': [87], 'new': [89], 'state': [90], 'art,': [93], 'graph\\nclassification': [97], 'dataset,': [98], 'outperform': [101], 'other': [102], 'learning': [104], 'approaches.': [105], 'The\\nsource': [106], 'code': [107], 'is': [108], 'available': [109], 'at': [110], 'https://github.com/mys007/ecc\\n': [111]}",2017,"['Computer science', 'Convolutional neural network', 'Generality', 'Graph', 'Deep learning', 'Vertex (graph theory)', 'Theoretical computer science', 'Artificial intelligence', 'Algorithm', 'Psychotherapist', 'Psychology']","A number of problems can be formulated as prediction on graph-structured\ndata. In this work, we generalize the convolution operator from regular grids\nto arbitrary graphs while avoiding the spectral domain, which allows us to\nhandle graphs of varying size and connectivity. To move beyond a simple\ndiffusion, filter weights are conditioned on the specific edge labels in the\nneighborhood of a vertex. Together with the proper choice of graph coarsening,\nwe explore constructing deep neural networks for graph classification. In\nparticular, we demonstrate the generality of our formulation in point cloud\nclassification, where we set the new state of the art, and on a graph\nclassification dataset, where we outperform other deep learning approaches. The\nsource code is available at https://github.com/mys007/ecc\n"
https://openalex.org/W2137687977,Artificial neural networks in medical diagnosis,"{'An': [0], 'extensive': [1], 'amount': [2], 'of': [3, 14, 20, 25, 30, 81, 103], 'information': [4, 33], 'is': [5], 'currently': [6], 'available': [7], 'to': [8, 17, 40], 'clinical': [9, 15], 'specialists,': [10], 'ranging': [11], 'from': [12], 'details': [13], 'symptoms': [16], 'various': [18], 'types': [19, 80], 'biochemical': [21], 'data': [22, 31, 83], 'and': [23, 38, 56, 66, 84, 96, 101], 'outputs': [24], 'imaging': [26], 'devices.': [27], 'Each': [28], 'type': [29], 'provides': [32], 'that': [34], 'must': [35], 'be': [36, 71], 'evaluated': [37], 'assigned': [39], 'a': [41], 'particular': [42], 'pathology': [43], 'during': [44], 'the': [45, 50, 98], 'diagnostic': [46, 51], 'process.': [47], 'To': [48], 'streamline': [49], 'process': [52], 'in': [53, 107], 'daily': [54], 'routine': [55], 'avoid': [57], 'misdiagnosis,': [58], 'artificial': [59, 67, 104], 'intelligence': [60], 'methods': [61], '(especially': [62], 'computer': [63], 'aided': [64], 'diagnosis': [65, 109], 'neural': [68, 105], 'networks)': [69], 'can': [70, 77], 'employed.': [72], 'These': [73], 'adaptive': [74], 'learning': [75], 'algorithms': [76], 'handle': [78], 'diverse': [79], 'medical': [82, 108], 'integrate': [85], 'them': [86], 'into': [87], 'categorized': [88], 'outputs.': [89], 'In': [90], 'this': [91], 'paper,': [92], 'we': [93], 'briefly': [94], 'review': [95], 'discuss': [97], 'philosophy,': [99], 'capabilities,': [100], 'limitations': [102], 'networks': [106], 'through': [110], 'selected': [111], 'examples.': [112]}",2013,"['Artificial neural network', 'Artificial intelligence', 'Computer science', 'Process (computing)', 'Machine learning', 'Clinical diagnosis', 'Medicine', 'Intensive care medicine', 'Operating system']","An extensive amount of information is currently available to clinical specialists, ranging from details of clinical symptoms to various types of biochemical data and outputs of imaging devices. Each type of data provides information that must be evaluated and assigned to a particular pathology during the diagnostic process. To streamline the diagnostic process in daily routine and avoid misdiagnosis, artificial intelligence methods (especially computer aided diagnosis and artificial neural networks) can be employed. These adaptive learning algorithms can handle diverse types of medical data and integrate them into categorized outputs. In this paper, we briefly review and discuss the philosophy, capabilities, and limitations of artificial neural networks in medical diagnosis through selected examples."
https://openalex.org/W2803187616,Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels,"{'Deep': [0], 'neural': [1], 'networks': [2], '(DNNs)': [3], 'have': [4], 'achieved': [5], 'tremendous': [6], 'success': [7], 'in': [8, 38, 72, 124], 'a': [9, 57, 87, 100, 125], 'variety': [10], 'of': [11, 25, 91, 102, 128], 'applications': [12], 'across': [13], 'many': [14], 'disciplines.': [15], 'Yet,': [16], 'their': [17], 'superior': [18], 'performance': [19, 123], 'comes': [20], 'with': [21, 79, 113, 138], 'the': [22, 61], 'expensive': [23], 'cost': [24], 'requiring': [26], 'correctly': [27], 'annotated': [28], 'large-scale': [29], 'datasets.': [30, 83], 'Moreover,': [31], 'due': [32], 'to': [33, 60], ""DNNs'"": [34], 'rich': [35], 'capacity,': [36], 'errors': [37], 'training': [39], 'labels': [40], 'can': [41, 76, 96, 109], 'hamper': [42], 'performance.': [43], 'To': [44], 'combat': [45], 'this': [46, 73], 'problem,': [47], 'mean': [48], 'absolute': [49], 'error': [50], '(MAE)': [51], 'has': [52], 'recently': [53], 'been': [54], 'proposed': [55], 'as': [56, 69, 99], 'noise-robust': [58, 92], 'alternative': [59], 'commonly-used': [62], 'categorical': [63], 'cross': [64], 'entropy': [65], '(CCE)': [66], 'loss.': [67], 'However,': [68], 'we': [70, 85], 'show': [71], 'paper,': [74], 'MAE': [75, 103], 'perform': [77], 'poorly': [78], 'DNNs': [80], 'and': [81, 104, 118, 141, 144], 'challenging': [82], 'Here,': [84], 'present': [86], 'theoretically': [88], 'grounded': [89], 'set': [90], 'loss': [93, 107], 'functions': [94, 108], 'that': [95], 'be': [97, 110], 'seen': [98], 'generalization': [101], 'CCE.': [105], 'Proposed': [106], 'readily': [111], 'applied': [112], 'any': [114], 'existing': [115], 'DNN': [116], 'architecture': [117], 'algorithm,': [119], 'while': [120], 'yielding': [121], 'good': [122], 'wide': [126], 'range': [127], 'noisy': [129, 147], 'label': [130], 'scenarios.': [131], 'We': [132], 'report': [133], 'results': [134], 'from': [135], 'experiments': [136], 'conducted': [137], 'CIFAR-10,': [139], 'CIFAR-100': [140], 'FASHION-MNIST': [142], 'datasets': [143], 'synthetically': [145], 'generated': [146], 'labels.': [148]}",2018,"['MNIST database', 'Deep neural networks', 'Computer science', 'Cross entropy', 'Artificial intelligence', 'Artificial neural network', 'Generalization', 'Machine learning', 'Training set', 'Categorical variable', 'Entropy (arrow of time)', 'Noise (video)', 'Pattern recognition (psychology)', 'Mathematics', 'Physics', 'Quantum mechanics', 'Mathematical analysis', 'Image (mathematics)']","Deep neural networks (DNNs) have achieved tremendous success in a variety of applications across many disciplines. Yet, their superior performance comes with the expensive cost of requiring correctly annotated large-scale datasets. Moreover, due to DNNs' rich capacity, errors in training labels can hamper performance. To combat this problem, mean absolute error (MAE) has recently been proposed as a noise-robust alternative to the commonly-used categorical cross entropy (CCE) loss. However, as we show in this paper, MAE can perform poorly with DNNs and challenging datasets. Here, we present a theoretically grounded set of noise-robust loss functions that can be seen as a generalization of MAE and CCE. Proposed loss functions can be readily applied with any existing DNN architecture and algorithm, while yielding good performance in a wide range of noisy label scenarios. We report results from experiments conducted with CIFAR-10, CIFAR-100 and FASHION-MNIST datasets and synthetically generated noisy labels."
https://openalex.org/W2534240011,Reynolds averaged turbulence modelling using deep neural networks with embedded invariance,"{'There': [0], 'exists': [1], 'significant': [2, 125], 'demand': [3], 'for': [4, 38, 117], 'improved': [5, 83], 'Reynolds-averaged': [6], 'Navier–Stokes': [7], '(RANS)': [8], 'turbulence': [9, 22], 'models': [10, 137], 'that': [11, 77, 93], 'are': [12, 110], 'informed': [13], 'by': [14], 'and': [15, 133], 'can': [16], 'represent': [17], 'a': [18, 27, 36, 57, 88], 'richer': [19], 'set': [20], 'of': [21, 29, 105], 'physics.': [23], 'This': [24], 'paper': [25], 'presents': [26], 'method': [28], 'using': [30], 'deep': [31], 'neural': [32, 50, 79, 90, 108], 'networks': [33], 'to': [34, 65, 113], 'learn': [35], 'model': [37], 'the': [39, 70, 114], 'Reynolds': [40, 101], 'stress': [41, 102], 'anisotropy': [42, 72, 103], 'tensor': [43, 63], 'from': [44], 'high-fidelity': [45], 'simulation': [46], 'data.': [47], 'A': [48], 'novel': [49], 'network': [51, 80, 91, 109], 'architecture': [52, 81, 92], 'is': [53, 75, 138], 'proposed': [54], 'which': [55], 'uses': [56], 'multiplicative': [58], 'layer': [59], 'with': [60, 87], 'an': [61], 'invariant': [62, 107], 'basis': [64], 'embed': [66, 96], 'Galilean': [67], 'invariance': [68, 98], 'into': [69], 'predicted': [71], 'tensor.': [73], 'It': [74], 'demonstrated': [76], 'this': [78, 97, 106], 'provides': [82], 'prediction': [84], 'accuracy': [85], 'compared': [86], 'generic': [89], 'does': [94], 'not': [95], 'property.': [99], 'The': [100], 'predictions': [104], 'propagated': [111], 'through': [112], 'velocity': [115], 'field': [116], 'two': [118], 'test': [119, 123], 'cases.': [120], 'For': [121], 'both': [122], 'cases,': [124], 'improvement': [126], 'versus': [127], 'baseline': [128], 'RANS': [129], 'linear': [130], 'eddy': [131, 135], 'viscosity': [132, 136], 'nonlinear': [134], 'demonstrated.': [139]}",2016,"['Reynolds-averaged Navier–Stokes equations', 'Turbulence modeling', 'Reynolds stress', 'Turbulence', 'Reynolds stress equation model', 'Artificial neural network', 'Invariant (physics)', 'K-epsilon turbulence model', 'Physics', 'Tensor (intrinsic definition)', 'Nonlinear system', 'Reynolds number', 'Computer science', 'Mechanics', 'Classical mechanics', 'K-omega turbulence model', 'Statistical physics', 'Applied mathematics', 'Mathematics', 'Artificial intelligence', 'Geometry', 'Mathematical physics', 'Quantum mechanics']","There exists significant demand for improved Reynolds-averaged Navier–Stokes (RANS) turbulence models that are informed by and can represent a richer set of turbulence physics. This paper presents a method of using deep neural networks to learn a model for the Reynolds stress anisotropy tensor from high-fidelity simulation data. A novel neural network architecture is proposed which uses a multiplicative layer with an invariant tensor basis to embed Galilean invariance into the predicted anisotropy tensor. It is demonstrated that this neural network architecture provides improved prediction accuracy compared with a generic neural network architecture that does not embed this invariance property. The Reynolds stress anisotropy predictions of this invariant neural network are propagated through to the velocity field for two test cases. For both test cases, significant improvement versus baseline RANS linear eddy viscosity and nonlinear eddy viscosity models is demonstrated."
https://openalex.org/W2502390809,Convolutional Neural Networks for Diabetic Retinopathy,"{'The': [0], 'diagnosis': [1, 92], 'of': [2, 19, 129, 139, 144], 'diabetic': [3], 'retinopathy': [4], '(DR)': [5], 'through': [6], 'colour': [7], 'fundus': [8, 51], 'images': [9, 52, 131], 'requires': [10], 'experienced': [11], 'clinicians': [12], 'to': [13, 46], 'identify': [14, 70], 'the': [15, 71, 76, 86, 110, 126], 'presence': [16], 'and': [17, 34, 53, 65, 83, 88, 94, 115, 141], 'significance': [18], 'many': [20], 'small': [21], 'features': [22, 73], 'which,': [23], 'along': [24], 'with': [25, 62], 'a': [26, 32, 43, 60, 91, 103, 121, 137], 'complex': [27], 'grading': [28], 'system,': [29], 'makes': [30], 'this': [31, 39, 100], 'difficult': [33], 'time': [35], 'consuming': [36], 'task.': [37, 124], 'In': [38], 'paper,': [40], 'we': [41], 'propose': [42], 'CNN': [44, 63, 135], 'approach': [45], 'diagnosing': [47], 'DR': [48], 'from': [49], 'digital': [50], 'accurately': [54], 'classifying': [55], 'its': [56], 'severity.': [57], 'We': [58, 98], 'develop': [59], 'network': [61, 101], 'architecture': [64], 'data': [66, 127], 'augmentation': [67], 'which': [68], 'can': [69], 'intricate': [72], 'involved': [74], 'in': [75], 'classification': [77, 123], 'task': [78], 'such': [79], 'as': [80], 'micro-aneurysms,': [81], 'exudate': [82], 'haemorrhages': [84], 'on': [85, 109, 146], 'retina': [87], 'consequently': [89], 'provide': [90], 'automatically': [93], 'without': [95], 'user': [96], 'input.': [97], 'train': [99], 'using': [102], 'high-end': [104], 'graphics': [105], 'processor': [106], 'unit': [107], '(GPU)': [108], 'publicly': [111], 'available': [112], 'Kaggle': [113], 'dataset': [114], 'demonstrate': [116], 'impressive': [117], 'results,': [118], 'particularly': [119], 'for': [120], 'high-level': [122], 'On': [125], 'set': [128], '80,000': [130], 'used': [132], 'our': [133], 'proposed': [134], 'achieves': [136], 'sensitivity': [138], '95%': [140], 'an': [142], 'accuracy': [143], '75%': [145], '5,000': [147], 'validation': [148], 'images.': [149]}",2016,"['Computer science', 'Convolutional neural network', 'Artificial intelligence', 'Diabetic retinopathy', 'Fundus (uterus)', 'Task (project management)', 'Data set', 'Grading (engineering)', 'Pattern recognition (psychology)', 'Medicine', 'Endocrinology', 'Civil engineering', 'Economics', 'Engineering', 'Diabetes mellitus', 'Ophthalmology', 'Management']","The diagnosis of diabetic retinopathy (DR) through colour fundus images requires experienced clinicians to identify the presence and significance of many small features which, along with a complex grading system, makes this a difficult and time consuming task. In this paper, we propose a CNN approach to diagnosing DR from digital fundus images and accurately classifying its severity. We develop a network with CNN architecture and data augmentation which can identify the intricate features involved in the classification task such as micro-aneurysms, exudate and haemorrhages on the retina and consequently provide a diagnosis automatically and without user input. We train this network using a high-end graphics processor unit (GPU) on the publicly available Kaggle dataset and demonstrate impressive results, particularly for a high-level classification task. On the data set of 80,000 images used our proposed CNN achieves a sensitivity of 95% and an accuracy of 75% on 5,000 validation images."
https://openalex.org/W2594014149,A Deep Cascade of Convolutional Neural Networks for Dynamic MR Image Reconstruction,"{'Inspired': [0], 'by': [1, 108], 'recent': [2], 'advances': [3], 'in': [4, 82, 150, 166], 'deep': [5, 27], 'learning,': [6], 'we': [7, 42, 55, 99], 'propose': [8], 'a': [9, 26], 'framework': [10], 'for': [11, 156], 'reconstructing': [12, 92], 'dynamic': [13, 145], 'sequences': [14, 97], 'of': [15, 29, 84, 95, 128], '2-D': [16, 60, 71, 158], 'cardiac': [17], 'magnetic': [18], 'resonance': [19], '(MR)': [20], 'images': [21], 'from': [22], 'undersampled': [23], 'data': [24, 37, 47, 112], 'using': [25, 50], 'cascade': [28], 'convolutional': [30], 'neural': [31], 'networks': [32], '(CNNs)': [33], 'to': [34, 135], 'accelerate': [35], 'the': [36, 44, 66, 93, 96, 118, 157], 'acquisition': [38], 'process.': [39], 'In': [40], 'particular,': [41], 'address': [43], 'case': [45], 'where': [46], 'are': [48], 'acquired': [49], 'aggressive': [51], 'Cartesian': [52], 'undersampling.': [53, 137], 'First,': [54], 'show': [56, 116], 'that': [57, 101, 117], 'when': [58, 91], 'each': [59, 143, 160], 'image': [61, 80, 161], 'frame': [62, 162], 'is': [63, 126, 140], 'reconstructed': [64, 149, 165], 'independently,': [65], 'proposed': [67, 119], 'method': [68, 120], 'outperforms': [69, 122], 'state-of-the-art': [70, 123], 'compressed': [72], 'sensing': [73], 'approaches,': [74], 'such': [75], 'as': [76], 'dictionary': [77], 'learning-based': [78], 'MR': [79], 'reconstruction,': [81], 'terms': [83], 'reconstruction': [85, 88, 139], 'error': [86], 'and': [87, 111, 125], 'speed.': [89], 'Second,': [90], 'frames': [94], 'jointly,': [98], 'demonstrate': [100], 'CNNs': [102], 'can': [103, 147, 163], 'learn': [104], 'spatio-temporal': [105], 'correlations': [106], 'efficiently': [107], 'combining': [109], 'convolution': [110], 'sharing': [113], 'approaches.': [114], 'We': [115], 'consistently': [121], 'methods': [124], 'capable': [127], 'preserving': [129], 'anatomical': [130], 'structure': [131], 'more': [132], 'faithfully': [133], 'up': [134], '11-fold': [136], 'Moreover,': [138], 'very': [141], 'fast:': [142], 'complete': [144], 'sequence': [146], 'be': [148, 164], 'less': [151], 'than': [152], '10': [153], 's': [154], 'and,': [155], 'case,': [159], '23': [167], 'ms,': [168], 'enabling': [169], 'real-time': [170], 'applications.': [171]}",2017,"['Undersampling', 'Computer science', 'Artificial intelligence', 'Iterative reconstruction', 'Convolutional neural network', 'Deep learning', 'Convolution (computer science)', 'Pattern recognition (psychology)', 'Compressed sensing', 'Frame (networking)', 'Computer vision', 'Autoencoder', 'Artificial neural network', 'Telecommunications']","Inspired by recent advances in deep learning, we propose a framework for reconstructing dynamic sequences of 2-D cardiac magnetic resonance (MR) images from undersampled data using a deep cascade of convolutional neural networks (CNNs) to accelerate the data acquisition process. In particular, we address the case where data are acquired using aggressive Cartesian undersampling. First, we show that when each 2-D image frame is reconstructed independently, the proposed method outperforms state-of-the-art 2-D compressed sensing approaches, such as dictionary learning-based MR image reconstruction, in terms of reconstruction error and reconstruction speed. Second, when reconstructing the frames of the sequences jointly, we demonstrate that CNNs can learn spatio-temporal correlations efficiently by combining convolution and data sharing approaches. We show that the proposed method consistently outperforms state-of-the-art methods and is capable of preserving anatomical structure more faithfully up to 11-fold undersampling. Moreover, reconstruction is very fast: each complete dynamic sequence can be reconstructed in less than 10 s and, for the 2-D case, each image frame can be reconstructed in 23 ms, enabling real-time applications."
https://openalex.org/W1850742715,DRAW: A Recurrent Neural Network For Image Generation,"{'This': [0], 'paper': [1], 'introduces': [2], 'the': [3, 25, 28, 40, 51, 54, 65, 82], 'Deep': [4], 'Recurrent': [5], 'Attentive': [6], 'Writer': [7], '(DRAW)': [8], 'neural': [9], 'network': [10], 'architecture': [11], 'for': [12, 39, 56], 'image': [13], 'generation.': [14], 'DRAW': [15], 'networks': [16], 'combine': [17], 'a': [18, 32], 'novel': [19], 'spatial': [20], 'attention': [21], 'mechanism': [22], 'that': [23, 37, 74], 'mimics': [24], 'foveation': [26], 'of': [27, 43, 53], 'human': [29], 'eye,': [30], 'with': [31, 81], 'sequential': [33], 'variational': [34], 'auto-encoding': [35], 'framework': [36], 'allows': [38], 'iterative': [41], 'construction': [42], 'complex': [44], 'images.': [45], 'The': [46], 'system': [47], 'substantially': [48], 'improves': [49], 'on': [50, 59, 64], 'state': [52], 'art': [55], 'generative': [57], 'models': [58], 'MNIST,': [60], 'and,': [61], 'when': [62], 'trained': [63], 'Street': [66], 'View': [67], 'House': [68], 'Numbers': [69], 'dataset,': [70], 'it': [71], 'generates': [72], 'images': [73], 'cannot': [75], 'be': [76], 'distinguished': [77], 'from': [78], 'real': [79], 'data': [80], 'naked': [83], 'eye.': [84]}",2015,"['Computer science', 'Image (mathematics)', 'Artificial neural network', 'Artificial intelligence']","This paper introduces the Deep Recurrent Attentive Writer (DRAW) neural network architecture for image generation. DRAW networks combine a novel spatial attention mechanism that mimics the foveation of the human eye, with a sequential variational auto-encoding framework that allows for the iterative construction of complex images. The system substantially improves on the state of the art for generative models on MNIST, and, when trained on the Street View House Numbers dataset, it generates images that cannot be distinguished from real data with the naked eye."
https://openalex.org/W2176263492,Sequence Level Training with Recurrent Neural Networks,"{'Many': [0], 'natural': [1], 'language': [2, 6], 'processing': [3], 'applications': [4], 'use': [5], 'models': [7, 12], 'to': [8, 16, 43], 'generate': [9, 44], 'text.': [10], 'These': [11], 'are': [13], 'typically': [14], 'trained': [15], 'predict': [17], 'the': [18, 25, 39, 45, 60, 77], 'next': [19], 'word': [20], 'in': [21], 'a': [22, 68], 'sequence,': [23], 'given': [24], 'previous': [26], 'words': [27], 'and': [28], 'some': [29], 'context': [30], 'such': [31, 83], 'as': [32, 55, 84], 'an': [33], 'image.': [34], 'However,': [35], 'at': [36, 80], 'test': [37, 81], 'time': [38], 'model': [40], 'is': [41, 103], 'expected': [42], 'entire': [46], 'sequence': [47, 70], 'from': [48], 'scratch.': [49], 'This': [50], 'discrepancy': [51], 'makes': [52], 'generation': [53], 'brittle,': [54], 'errors': [56], 'may': [57], 'accumulate': [58], 'along': [59], 'way.': [61], 'We': [62], 'address': [63], 'this': [64], 'issue': [65], 'by': [66], 'proposing': [67], 'novel': [69], 'level': [71], 'training': [72], 'algorithm': [73], 'that': [74], 'directly': [75], 'optimizes': [76], 'metric': [78], 'used': [79], 'time,': [82], 'BLEU': [85], 'or': [86], 'ROUGE.': [87], 'On': [88], 'three': [89], 'different': [90], 'tasks,': [91], 'our': [92], 'approach': [93], 'outperforms': [94], 'several': [95, 114], 'strong': [96], 'baselines': [97, 108], 'for': [98], 'greedy': [99], 'generation.': [100], 'The': [101], 'method': [102], 'also': [104], 'competitive': [105], 'when': [106], 'these': [107], 'employ': [109], 'beam': [110], 'search,': [111], 'while': [112], 'being': [113], 'times': [115], 'faster.': [116]}",2015,"['Computer science', 'Sequence (biology)', 'Scratch', 'Beam search', 'Context (archaeology)', 'Word (group theory)', 'Artificial intelligence', 'Metric (unit)', 'Language model', 'Artificial neural network', 'Natural language processing', 'Speech recognition', 'Algorithm', 'Search algorithm', 'Programming language', 'Paleontology', 'Economics', 'Philosophy', 'Genetics', 'Linguistics', 'Biology', 'Operations management']","Many natural language processing applications use language models to generate text. These models are typically trained to predict the next word in a sequence, given the previous words and some context such as an image. However, at test time the model is expected to generate the entire sequence from scratch. This discrepancy makes generation brittle, as errors may accumulate along the way. We address this issue by proposing a novel sequence level training algorithm that directly optimizes the metric used at test time, such as BLEU or ROUGE. On three different tasks, our approach outperforms several strong baselines for greedy generation. The method is also competitive when these baselines employ beam search, while being several times faster."
https://openalex.org/W4288039037,Scientific Machine Learning Through Physics–Informed Neural Networks: Where we are and What’s Next,"{'Abstract': [0], 'Physics-Informed': [1], 'Neural': [2], 'Networks': [3], '(PINN)': [4], 'are': [5, 27, 192], 'neural': [6, 23, 107, 124, 152], 'networks': [7, 85, 125], '(NNs)': [8], 'that': [9, 136, 199], 'encode': [10], 'model': [11], 'equations,': [12, 34, 36], 'like': [13, 186], 'Partial': [14], 'Differential': [15], 'Equations': [16], '(PDE),': [17], 'as': [18, 45, 115, 117, 122], 'a': [19, 46, 52, 60, 66, 100], 'component': [20], 'of': [21, 69, 78, 103, 163], 'the': [22, 70, 75, 79, 112, 143, 160], 'network': [24, 153], 'itself.': [25], 'PINNs': [26, 167], 'nowadays': [28], 'used': [29], 'to': [30, 82, 96, 175], 'solve': [31], 'PDEs,': [32], 'fractional': [33], 'integral-differential': [35], 'and': [37, 86, 90, 129, 155], 'stochastic': [38], 'PDEs.': [39], 'This': [40, 63], 'novel': [41], 'methodology': [42], 'has': [43, 139], 'arisen': [44], 'multi-task': [47], 'learning': [48], 'framework': [49], 'in': [50, 179], 'which': [51, 109, 166], 'NN': [53], 'must': [54], 'fit': [55], 'observed': [56], 'data': [57], 'while': [58, 74], 'reducing': [59], 'PDE': [61], 'residual.': [62], 'article': [64], 'provides': [65], 'comprehensive': [67], 'review': [68, 93], 'literature': [71], 'on': [72, 99, 141], 'PINNs:': [73], 'primary': [76], 'goal': [77], 'study': [80, 134], 'was': [81], 'characterize': [83], 'these': [84], 'their': [87, 173], 'related': [88], 'advantages': [89], 'disadvantages.': [91], 'The': [92, 133], 'also': [94], 'attempts': [95], 'incorporate': [97], 'publications': [98], 'broader': [101], 'range': [102, 162], 'collocation-based': [104], 'physics': [105], 'informed': [106], 'networks,': [108], 'stars': [110], 'form': [111], 'vanilla': [113], 'PINN,': [114], 'well': [116], 'many': [118], 'other': [119], 'variants,': [120], 'such': [121], 'physics-constrained': [123], '(PCNN),': [126], 'variational': [127], 'hp-VPINN,': [128], 'conservative': [130], 'PINN': [131, 144], '(CPINN).': [132], 'indicates': [135], 'most': [137, 195], 'research': [138], 'focused': [140], 'customizing': [142], 'through': [145], 'different': [146], 'activation': [147], 'functions,': [148], 'gradient': [149], 'optimization': [150], 'techniques,': [151], 'structures,': [154], 'loss': [156], 'function': [157], 'structures.': [158], 'Despite': [159], 'wide': [161], 'applications': [164], 'for': [165], 'have': [168], 'been': [169], 'used,': [170], 'by': [171], 'demonstrating': [172], 'ability': [174], 'be': [176], 'more': [177], 'feasible': [178], 'some': [180], 'contexts': [181], 'than': [182], 'classical': [183], 'numerical': [184], 'techniques': [185], 'Finite': [187], 'Element': [188], 'Method': [189], '(FEM),': [190], 'advancements': [191], 'still': [193], 'possible,': [194], 'notably': [196], 'theoretical': [197], 'issues': [198], 'remain': [200], 'unresolved.': [201]}",2022,"['Artificial neural network', 'Collocation (remote sensing)', 'Partial differential equation', 'Function (biology)', 'Computer science', 'Finite element method', 'Range (aeronautics)', 'Artificial intelligence', 'Applied mathematics', 'Mathematics', 'Mathematical optimization', 'Machine learning', 'Physics', 'Mathematical analysis', 'Engineering', 'Thermodynamics', 'Biology', 'Evolutionary biology', 'Aerospace engineering']","Abstract Physics-Informed Neural Networks (PINN) are neural networks (NNs) that encode model equations, like Partial Differential Equations (PDE), as a component of the neural network itself. PINNs are nowadays used to solve PDEs, fractional equations, integral-differential equations, and stochastic PDEs. This novel methodology has arisen as a multi-task learning framework in which a NN must fit observed data while reducing a PDE residual. This article provides a comprehensive review of the literature on PINNs: while the primary goal of the study was to characterize these networks and their related advantages and disadvantages. The review also attempts to incorporate publications on a broader range of collocation-based physics informed neural networks, which stars form the vanilla PINN, as well as many other variants, such as physics-constrained neural networks (PCNN), variational hp-VPINN, and conservative PINN (CPINN). The study indicates that most research has focused on customizing the PINN through different activation functions, gradient optimization techniques, neural network structures, and loss function structures. Despite the wide range of applications for which PINNs have been used, by demonstrating their ability to be more feasible in some contexts than classical numerical techniques like Finite Element Method (FEM), advancements are still possible, most notably theoretical issues that remain unresolved."
https://openalex.org/W94052953,neuralnet: Training of Neural Networks,"{'Artificial': [0], 'neural': [1, 30], 'networks': [2, 31], 'are': [3, 32, 53], 'applied': [4], 'in': [5, 14, 107], 'many': [6], 'situations.neuralnet': [7], 'is': [8, 40, 105], 'built': [9], 'to': [10, 21, 87], 'train': [11], 'multi-layer': [12], 'perceptrons': [13, 89], 'the': [15, 95, 100, 108], 'context': [16], 'of': [17, 36, 50, 60, 67, 75, 97], 'regression': [18], 'analyses,': [19], 'i.e.': [20], 'approximate': [22], 'functional': [23], 'relationships': [24], 'between': [25], 'covariates': [26, 68], 'and': [27, 47, 55, 62, 69, 90, 93], 'response': [28, 70], 'variables.Thus,': [29], 'used': [33], 'as': [34, 72, 74], 'extensions': [35], 'generalized': [37], 'linear': [38], 'models.neuralnet': [39], 'a': [41, 58, 84], 'very': [42], 'flexible': [43], 'package.The': [44], 'backpropagation': [45, 52, 92], 'algorithm': [46], 'three': [48], 'versions': [49], 'resilient': [51, 91], 'implemented': [54], 'it': [56], 'provides': [57], 'custom-choice': [59], 'activation': [61], 'error': [63], 'function.An': [64], 'arbitrary': [65], 'number': [66], 'variables': [71], 'well': [73], 'hidden': [76], 'layers': [77], 'can': [78], 'theoretically': [79], 'be': [80], 'included.The': [81], 'paper': [82], 'gives': [83], 'brief': [85], 'introduction': [86], 'multilayer': [88], 'demonstrates': [94], 'application': [96], 'neuralnet': [98], 'using': [99], 'data': [101], 'set': [102], 'infert,': [103], 'which': [104], 'contained': [106], 'R': [109], 'distribution.': [110]}",2010,"['Training (meteorology)', 'Artificial neural network', 'Computer science', 'Artificial intelligence', 'Geography', 'Meteorology']","Artificial neural networks are applied in many situations.neuralnet is built to train multi-layer perceptrons in the context of regression analyses, i.e. to approximate functional relationships between covariates and response variables.Thus, neural networks are used as extensions of generalized linear models.neuralnet is a very flexible package.The backpropagation algorithm and three versions of resilient backpropagation are implemented and it provides a custom-choice of activation and error function.An arbitrary number of covariates and response variables as well as of hidden layers can theoretically be included.The paper gives a brief introduction to multilayer perceptrons and resilient backpropagation and demonstrates the application of neuralnet using the data set infert, which is contained in the R distribution."
https://openalex.org/W2803831897,Adversarial Attacks on Neural Networks for Graph Data,"{'Deep': [0], 'learning': [1, 94], 'models': [2, 168], 'for': [3, 9, 45], 'graphs': [4, 46], 'have': [5], 'achieved': [6], 'strong': [7], 'performance': [8], 'the': [10, 37, 55, 79, 88, 100, 104, 108, 128, 160, 181], 'task\\nof': [11], 'node': [12, 146], 'classification.': [13], 'Despite': [14], 'their': [15, 22], 'proliferation,': [16], 'currently': [17], 'there': [18], 'is': [19, 183], 'no\\nstudy': [20], 'of': [21, 68, 83, 91, 145], 'robustness': [23], 'to': [24, 33, 73, 164], 'adversarial': [25, 58], 'attacks.': [26], 'Yet,': [27], 'in': [28, 112], 'domains': [29], 'where': [30], 'they\\nare': [31], 'likely': [32], 'be': [34, 47], 'used,': [35], 'e.g.': [36], 'web,': [38], 'adversaries': [39], 'are': [40, 174], 'common.': [41], 'Can': [42], 'deep': [43], 'learning\\nmodels': [44], 'easily': [48], 'fooled?': [49], 'In': [50, 71], 'this': [51], 'work,': [52], 'we': [53, 115, 132], 'introduce': [54], 'first': [56], 'study\\nof': [57], 'attacks': [59, 74, 158, 162], 'on': [60, 65], 'attributed': [61], 'graphs,': [62], 'specifically': [63], 'focusing': [64], 'models\\nexploiting': [66], 'ideas': [67], 'graph': [69, 105, 182], 'convolutions.': [70], 'addition': [72], 'at': [75], 'test': [76], 'time,': [77], 'we\\ntackle': [78], 'more': [80], 'challenging': [81], 'class': [82], 'poisoning/causative': [84], 'attacks,': [85], 'which': [86], 'focus\\non': [87], 'training': [89], 'phase': [90], 'a': [92], 'machine': [93], 'model.': [95], 'We': [96], 'generate': [97], 'adversarial\\nperturbations': [98], 'targeting': [99], ""node's"": [101], 'features': [102], 'and': [103, 169, 172], 'structure,': [106], 'thus,\\ntaking': [107], 'dependencies': [109], 'between': [110], 'instances': [111], 'account.': [113], 'Moreover,': [114], 'ensure': [116], 'that\\nthe': [117], 'perturbations': [118], 'remain': [119], 'unnoticeable': [120], 'by': [121], 'preserving': [122], 'important': [123], 'data\\ncharacteristics.': [124], 'To': [125], 'cope': [126], 'with': [127], 'underlying': [129], 'discrete': [130], 'domain': [131], 'propose': [133], 'an\\nefficient': [134], 'algorithm': [135], 'Nettack': [136], 'exploiting': [137], 'incremental': [138], 'computations.': [139], 'Our\\nexperimental': [140], 'study': [141], 'shows': [142], 'that': [143], 'accuracy': [144], 'classification': [147], 'significantly\\ndrops': [148], 'even': [149], 'when': [150, 176], 'performing': [151], 'only': [152, 177], 'few': [153], 'perturbations.': [154], 'Even': [155], 'more,': [156], 'our': [157], 'are\\ntransferable:': [159], 'learned': [161], 'generalize': [163], 'other': [165], 'state-of-the-art': [166], 'node\\nclassification': [167], 'unsupervised': [170], 'approaches,': [171], 'likewise': [173], 'successful\\neven': [175], 'limited': [178], 'knowledge': [179], 'about': [180], 'given.\\n': [184]}",2018,"['Computer science', 'Adversarial system', 'Graph', 'Computer security', 'Artificial neural network', 'Artificial intelligence', 'Theoretical computer science']","Deep learning models for graphs have achieved strong performance for the task\nof node classification. Despite their proliferation, currently there is no\nstudy of their robustness to adversarial attacks. Yet, in domains where they\nare likely to be used, e.g. the web, adversaries are common. Can deep learning\nmodels for graphs be easily fooled? In this work, we introduce the first study\nof adversarial attacks on attributed graphs, specifically focusing on models\nexploiting ideas of graph convolutions. In addition to attacks at test time, we\ntackle the more challenging class of poisoning/causative attacks, which focus\non the training phase of a machine learning model. We generate adversarial\nperturbations targeting the node's features and the graph structure, thus,\ntaking the dependencies between instances in account. Moreover, we ensure that\nthe perturbations remain unnoticeable by preserving important data\ncharacteristics. To cope with the underlying discrete domain we propose an\nefficient algorithm Nettack exploiting incremental computations. Our\nexperimental study shows that accuracy of node classification significantly\ndrops even when performing only few perturbations. Even more, our attacks are\ntransferable: the learned attacks generalize to other state-of-the-art node\nclassification models and unsupervised approaches, and likewise are successful\neven when only limited knowledge about the graph is given.\n"
https://openalex.org/W1996901117,Speeding up Convolutional Neural Networks with Low Rank Expansions,"{'The': [0], 'focus': [1], 'of': [2, 10, 21, 42, 77], 'this': [3, 49, 109], 'paper': [4], 'is': [5, 63], 'speeding': [6, 58], 'up': [7, 59], 'the': [8, 40, 43, 83], 'application': [9], 'convolutional': [11, 101], 'neural': [12], 'networks.': [13], 'While': [14], 'delivering': [15], 'impressive': [16], 'results': [17], 'across': [18], 'a': [19, 73, 111, 123], 'range': [20], 'computer': [22], 'vision': [23], 'and': [24, 46, 91, 99, 132], 'machine': [25], 'learning': [26], 'tasks,': [27], 'these': [28, 60], 'networks': [29], 'are': [30, 80, 88], 'computationally': [31], 'demanding,': [32], 'limiting': [33], 'their': [34], 'deployability.': [35], 'Convolutional': [36], 'layers': [37], 'generally': [38], 'consume': [39], 'bulk': [41], 'processing': [44], 'time,': [45], 'so': [47], 'in': [48, 82, 130, 140], 'work': [50], 'we': [51], 'present': [52], 'two': [53], 'simple': [54], 'schemes': [55], 'for': [56, 103, 116], 'drastically': [57], 'layers.': [61], 'This': [62], 'achieved': [64], 'by': [65], 'exploiting': [66], 'cross-channel': [67], 'or': [68], 'filter': [69], 'redundancy': [70], 'to': [71, 96], 'construct': [72], 'low': [74], 'rank': [75], 'basis': [76], 'filters': [78], 'that': [79], 'rank-1': [81], 'spatial': [84], 'domain.': [85], 'Our': [86], 'methods': [87], 'architecture': [89], 'agnostic,': [90], 'can': [92], 'be': [93], 'easily': [94], 'applied': [95], 'existing': [97], 'CPU': [98], 'GPU': [100], 'frameworks': [102], 'tuneable': [104], 'speedup': [105, 126, 134], 'performance.': [106], 'We': [107], 'demonstrate': [108], 'with': [110, 127, 135], 'real': [112], 'world': [113], 'network': [114], 'designed': [115], 'scene': [117], 'text': [118], 'character': [119], 'recognition': [120], '[15],': [121], 'showing': [122], 'possible': [124], '2.5×': [125], 'no': [128], 'loss': [129], 'accuracy,': [131, 141], '4.5×': [133], 'less': [136], 'than': [137], '1%': [138], 'drop': [139], 'still': [142], 'achieving': [143], 'state-of-the-art': [144], 'on': [145], 'standard': [146], 'benchmarks.': [147]}",2014,"['Convolutional neural network', 'Computer science', 'Rank (graph theory)', 'Artificial intelligence', 'Mathematics', 'Combinatorics']","The focus of this paper is speeding up the application of convolutional neural networks. While delivering impressive results across a range of computer vision and machine learning tasks, these networks are computationally demanding, limiting their deployability. Convolutional layers generally consume the bulk of the processing time, and so in this work we present two simple schemes for drastically speeding up these layers. This is achieved by exploiting cross-channel or filter redundancy to construct a low rank basis of filters that are rank-1 in the spatial domain. Our methods are architecture agnostic, and can be easily applied to existing CPU and GPU convolutional frameworks for tuneable speedup performance. We demonstrate this with a real world network designed for scene text character recognition [15], showing a possible 2.5× speedup with no loss in accuracy, and 4.5× speedup with less than 1% drop in accuracy, still achieving state-of-the-art on standard benchmarks."
https://openalex.org/W2406128552,Learning Convolutional Neural Networks for Graphs,"{'Numerous': [0], 'important': [1], 'problems': [2], 'can': [3], 'be': [4, 26], 'framed': [5], 'as': [6], 'learning': [7, 16], 'from': [8, 63], 'graph': [9, 84], 'data.': [10], 'We': [11], 'propose': [12], 'a': [13, 55], 'framework': [14], 'for': [15, 20], 'convolutional': [17, 42], 'neural': [18], 'networks': [19, 43], 'arbitrary': [21], 'graphs.': [22, 64], 'These': [23], 'graphs': [24], 'may': [25], 'undirected,': [27], 'directed,': [28], 'and': [29, 33, 36, 86], 'with': [30, 79], 'both': [31], 'discrete': [32], 'continuous': [34], 'node': [35], 'edge': [37], 'attributes.': [38], 'Analogous': [39], 'to': [40, 58], 'image-based': [41], 'that': [44, 72, 87], 'operate': [45], 'on': [46], 'locally': [47, 60], 'connected': [48, 61], 'regions': [49, 62], 'of': [50, 81], 'the': [51, 73, 82], 'input,': [52], 'we': [53, 70], 'present': [54], 'general': [56], 'approach': [57], 'extracting': [59], 'Using': [65], 'established': [66], 'benchmark': [67], 'data': [68], 'sets,': [69], 'demonstrate': [71], 'learned': [74], 'feature': [75], 'representations': [76], 'are': [77], 'competitive': [78], 'state': [80], 'art': [83], 'kernels': [85], 'their': [88], 'computation': [89], 'is': [90], 'highly': [91], 'efficient.': [92]}",2016,"['Computer science', 'Convolutional neural network', 'Benchmark (surveying)', 'Theoretical computer science', 'Graph', 'Artificial intelligence', 'Node (physics)', 'Enhanced Data Rates for GSM Evolution', 'Computation', 'Algorithm', 'Geography', 'Engineering', 'Geodesy', 'Structural engineering']","Numerous important problems can be framed as learning from graph data. We propose a framework for learning convolutional neural networks for arbitrary graphs. These graphs may be undirected, directed, and with both discrete and continuous node and edge attributes. Analogous to image-based convolutional networks that operate on locally connected regions of the input, we present a general approach to extracting locally connected regions from graphs. Using established benchmark data sets, we demonstrate that the learned feature representations are competitive with state of the art graph kernels and that their computation is highly efficient."
https://openalex.org/W2509065397,Deep Convolutional Neural Networks and Data Augmentation for Environmental Sound Classification,"{'The': [0], 'ability': [1], 'of': [2, 23, 29, 32, 56, 64, 70, 75, 101, 130, 157], 'deep': [3, 44], 'convolutional': [4], 'neural': [5], 'networks': [6], '(CNN)': [7], 'to': [8], 'learn\\ndiscriminative': [9], 'spectro-temporal': [10], 'patterns': [11], 'makes': [12], 'them': [13], 'well': [14], 'suited': [15], 'to\\nenvironmental': [16], 'sound': [17, 50], 'classification.': [18, 51], 'However,': [19], 'the': [20, 27, 54, 62, 68, 76, 95, 114, 134, 143, 155, 158], 'relative': [21], 'scarcity': [22], 'labeled\\ndata': [24], 'has': [25, 36], 'impeded': [26], 'exploitation': [28], 'this': [30], 'family': [31], 'high-capacity': [33, 104], 'models.': [34], 'This\\nstudy': [35], 'two': [37], 'primary': [38], 'contributions:': [39], 'first,': [40], 'we': [41, 127], 'propose': [42], 'a': [43, 102], 'convolutional\\nneural': [45], 'network': [46], 'architecture': [47], 'for': [48, 60, 89, 138, 145], 'environmental': [49, 90], 'Second,': [52], 'we\\npropose': [53], 'use': [55], 'audio': [57], 'data': [58, 82, 166], 'augmentation': [59, 118, 132], 'overcoming': [61], 'problem': [63], 'data\\nscarcity': [65], 'and': [66, 106, 119, 140], 'explore': [67], 'influence': [69], 'different': [71], 'augmentations': [72], 'on': [73, 133], 'the\\nperformance': [74], 'proposed': [77, 84, 115], 'CNN': [78, 116], 'architecture.': [79], 'Combined': [80], 'with': [81, 124], 'augmentation,\\nthe': [83], 'model': [85, 105, 123, 159], 'produces': [86], 'state-of-the-art': [87], 'results': [88], 'sound\\nclassification.': [91], 'We': [92], 'show': [93], 'that': [94, 142, 154], 'improved': [96], 'performance': [97, 156], 'stems': [98], 'from': [99], 'the\\ncombination': [100], 'deep,': [103], 'an': [107], 'augmented': [108], 'training': [109], 'set:': [110], 'this\\ncombination': [111], 'outperforms': [112], 'both': [113], 'without': [117], 'a\\n""shallow""': [120], 'dictionary': [121], 'learning': [122], 'augmentation.': [125], 'Finally,': [126], 'examine': [128], 'the\\ninfluence': [129], 'each': [131, 146, 151], ""model's"": [135], 'classification': [136], 'accuracy': [137, 144], 'each\\nclass,': [139], 'observe': [141], 'class': [147], 'is': [148], 'influenced': [149], 'differently\\nby': [150], 'augmentation,': [152], 'suggesting': [153], 'could': [160], 'be\\nimproved': [161], 'further': [162], 'by': [163], 'applying': [164], 'class-conditional': [165], 'augmentation.\\n': [167]}",2017,[],"The ability of deep convolutional neural networks (CNN) to learn\ndiscriminative spectro-temporal patterns makes them well suited to\nenvironmental sound classification. However, the relative scarcity of labeled\ndata has impeded the exploitation of this family of high-capacity models. This\nstudy has two primary contributions: first, we propose a deep convolutional\nneural network architecture for environmental sound classification. Second, we\npropose the use of audio data augmentation for overcoming the problem of data\nscarcity and explore the influence of different augmentations on the\nperformance of the proposed CNN architecture. Combined with data augmentation,\nthe proposed model produces state-of-the-art results for environmental sound\nclassification. We show that the improved performance stems from the\ncombination of a deep, high-capacity model and an augmented training set: this\ncombination outperforms both the proposed CNN without augmentation and a\n""shallow"" dictionary learning model with augmentation. Finally, we examine the\ninfluence of each augmentation on the model's classification accuracy for each\nclass, and observe that the accuracy for each class is influenced differently\nby each augmentation, suggesting that the performance of the model could be\nimproved further by applying class-conditional data augmentation.\n"
https://openalex.org/W3132191748,Explaining Deep Neural Networks and Beyond: A Review of Methods and Applications,"{'With': [0], 'the': [1, 14, 37, 114], 'broader': [2], 'and': [3, 13, 28, 40, 78, 94, 119, 137], 'highly': [4], 'successful': [5, 122], 'usage': [6, 116, 123], 'of': [7, 36, 42, 66, 117, 124, 130, 141, 146], 'machine': [8], 'learning': [9], '(ML)': [10], 'in': [11, 45, 126], 'industry': [12], 'sciences,': [15], 'there': [16], 'has': [17], 'been': [18], 'a': [19, 33, 63, 72, 88, 92, 127], 'growing': [20], 'demand': [21], 'for': [22, 31], 'explainable': [23], 'artificial': [24], 'intelligence': [25], '(XAI).': [26], 'Interpretability': [27], 'explanation': [29], 'methods': [30, 112], 'gaining': [32], 'better': [34], 'understanding': [35], 'problem-solving': [38], 'abilities': [39], 'strategies': [41], 'nonlinear': [43], 'ML,': [44], 'particular,': [46], 'deep': [47], 'neural': [48], 'networks,': [49], 'are,': [50], 'therefore,': [51], 'receiving': [52], 'increased': [53], 'attention.': [54], 'In': [55], 'this': [56, 67, 142], 'work,': [57], 'we': [58, 134], 'aim': [59], 'to:': [60], '1)': [61], 'provide': [62], 'timely': [64], 'overview': [65], 'active': [68], 'emerging': [69], 'field,': [70], 'with': [71], 'focus': [73], 'on': [74], ""'post"": [75], ""hoc'"": [76], 'explanations,': [77], 'explain': [79], 'its': [80], 'theoretical': [81], 'foundations;': [82], '2)': [83], 'put': [84], 'interpretability': [85], 'algorithms': [86], 'to': [87, 108], 'test': [89], 'both': [90], 'from': [91], 'theory': [93], 'comparative': [95], 'evaluation': [96], 'perspective': [97], 'using': [98], 'extensive': [99], 'simulations;': [100], '3)': [101], 'outline': [102], 'best': [103, 109], 'practice': [104], 'aspects,': [105], 'i.e.,': [106], 'how': [107], 'include': [110], 'interpretation': [111], 'into': [113], 'standard': [115], 'ML;': [118], '4)': [120], 'demonstrate': [121], 'XAI': [125], 'representative': [128], 'selection': [129], 'application': [131], 'scenarios.': [132], 'Finally,': [133], 'discuss': [135], 'challenges': [136], 'possible': [138], 'future': [139], 'directions': [140], 'exciting': [143], 'foundational': [144], 'field': [145], 'ML.': [147]}",2021,"['Interpretability', 'Artificial intelligence', 'Computer science', 'Machine learning', 'Field (mathematics)', 'Perspective (graphical)', 'Artificial neural network', 'Interpretation (philosophy)', 'Deep neural networks', 'Selection (genetic algorithm)', 'Deep learning', 'Management science', 'Data science', 'Engineering', 'Programming language', 'Pure mathematics', 'Mathematics']","With the broader and highly successful usage of machine learning (ML) in industry and the sciences, there has been a growing demand for explainable artificial intelligence (XAI). Interpretability and explanation methods for gaining a better understanding of the problem-solving abilities and strategies of nonlinear ML, in particular, deep neural networks, are, therefore, receiving increased attention. In this work, we aim to: 1) provide a timely overview of this active emerging field, with a focus on 'post hoc' explanations, and explain its theoretical foundations; 2) put interpretability algorithms to a test both from a theory and comparative evaluation perspective using extensive simulations; 3) outline best practice aspects, i.e., how to best include interpretation methods into the standard usage of ML; and 4) demonstrate successful usage of XAI in a representative selection of application scenarios. Finally, we discuss challenges and possible future directions of this exciting foundational field of ML."
https://openalex.org/W2942091739,BadNets: Evaluating Backdooring Attacks on Deep Neural Networks,"{'Deep': [0], 'learning-based': [1], 'techniques': [2, 227], 'have': [3, 237], 'achieved': [4], 'state-of-the-art': [5, 88], 'performance': [6, 89], 'on': [7, 29, 46, 90, 100, 190], 'a': [8, 33, 54, 74, 83, 112, 117, 127, 133, 146, 183], 'wide': [9], 'variety': [10], 'of': [11, 27, 109, 188, 212], 'recognition': [12], 'and': [13, 94, 181, 230, 242], 'classification': [14], 'tasks.': [15], 'However,': [16], 'these': [17], 'networks': [18, 205, 214], 'are': [19, 50, 206], 'typically': [20], 'computationally': [21], 'expensive': [22], 'to': [23, 41, 151, 217], 'train,': [24], 'requiring': [25], 'weeks': [26], 'computation': [28], 'many': [30, 35], 'GPUs;': [31], 'as': [32, 142, 235], 'result,': [34], 'users': [36], 'outsource': [37], 'the': [38, 42, 63, 87, 91, 107, 152, 161, 173, 193, 210], 'training': [39, 65, 93], 'procedure': [40], 'cloud': [43], 'or': [44, 82], 'rely': [45], 'pre-trained': [47], 'models': [48], 'that': [49, 62, 85, 138, 160, 201], 'then': [51, 156], 'fine-tuned': [52], 'for': [53, 178, 223, 228, 240], 'specific': [55, 101], 'task.': [56], 'In': [57], 'this': [58], 'paper,': [59], 'we': [60, 123, 155, 236], 'show': [61, 157], 'outsourced': [64], 'introduces': [66], 'new': [67], 'security': [68], 'risks:': [69], 'an': [70, 186], 'adversary': [71], 'can': [72, 169], 'create': [73], 'maliciously': [75], 'trained': [76], 'network': [77, 174], '(a': [78], 'backdoored': [79, 118], 'neural': [80, 204, 213, 232], 'network,': [81], 'BadNet)': [84], 'has': [86], ""user's"": [92], 'validation': [95], 'samples': [96], 'but': [97], 'behaves': [98], 'badly': [99], 'attacker-chosen': [102], 'inputs.': [103], 'We': [104], 'first': [105], 'explore': [106], 'properties': [108], 'BadNets': [110], 'in': [111, 126, 158, 163, 185, 203], 'toy': [113], 'example,': [114], 'by': [115, 131], 'creating': [116, 132], 'handwritten': [119], 'digit': [120], 'classifier.': [121], 'Next,': [122], 'demonstrate': [124, 200], 'backdoors': [125, 202], 'more': [128], 'realistic': [129], 'scenario': [130], 'U.S.': [134, 165], 'street': [135, 166], 'sign': [136, 167], 'classifier': [137], 'identifies': [139], 'stop': [140, 153], 'signs': [141], 'speed': [143], 'limits': [144], 'when': [145, 192], 'special': [147], 'sticker': [148], 'is': [149, 175, 196, 215], 'added': [150], 'sign;': [154], 'addition': [159], 'backdoor': [162, 194], 'our': [164], 'detector': [168], 'persist': [170], 'even': [171], 'if': [172], 'later': [176], 'retrained': [177], 'another': [179], 'task': [180], 'cause': [182], 'drop': [184], 'accuracy': [187], '25%': [189], 'average': [191], 'trigger': [195], 'present.': [197], 'These': [198], 'results': [199], 'both': [207], 'powerful': [208], 'and-because': [209], 'behavior': [211], 'difficult': [216], 'explicate-stealthy.': [218], 'This': [219], 'paper': [220], 'provides': [221], 'motivation': [222], 'further': [224], 'research': [225], 'into': [226], 'verifying': [229, 241], 'inspecting': [231], 'networks,': [233], 'just': [234], 'developed': [238], 'tools': [239], 'debugging': [243], 'software.': [244]}",2019,"['Backdoor', 'Computer science', 'Traffic sign recognition', 'Adversary', 'Artificial neural network', 'Artificial intelligence', 'Classifier (UML)', 'Deep neural networks', 'Deep learning', 'Machine learning', 'Task (project management)', 'Computer security', 'Sign (mathematics)', 'Traffic sign', 'Management', 'Mathematics', 'Economics', 'Mathematical analysis']","Deep learning-based techniques have achieved state-of-the-art performance on a wide variety of recognition and classification tasks. However, these networks are typically computationally expensive to train, requiring weeks of computation on many GPUs; as a result, many users outsource the training procedure to the cloud or rely on pre-trained models that are then fine-tuned for a specific task. In this paper, we show that the outsourced training introduces new security risks: an adversary can create a maliciously trained network (a backdoored neural network, or a BadNet) that has the state-of-the-art performance on the user's training and validation samples but behaves badly on specific attacker-chosen inputs. We first explore the properties of BadNets in a toy example, by creating a backdoored handwritten digit classifier. Next, we demonstrate backdoors in a more realistic scenario by creating a U.S. street sign classifier that identifies stop signs as speed limits when a special sticker is added to the stop sign; we then show in addition that the backdoor in our U.S. street sign detector can persist even if the network is later retrained for another task and cause a drop in an accuracy of 25% on average when the backdoor trigger is present. These results demonstrate that backdoors in neural networks are both powerful and-because the behavior of neural networks is difficult to explicate-stealthy. This paper provides motivation for further research into techniques for verifying and inspecting neural networks, just as we have developed tools for verifying and debugging software."
https://openalex.org/W2572303978,Spectral–Spatial Classification of Hyperspectral Imagery with 3D Convolutional Neural Network,"{'Recent': [0], 'research': [1], 'has': [2], 'shown': [3], 'that': [4, 150], 'using': [5], 'spectral–spatial': [6, 44], 'information': [7], 'can': [8], 'considerably': [9], 'improve': [10], 'the': [11, 24, 43, 69, 82, 99, 117], 'performance': [12], 'of': [13, 26], 'hyperspectral': [14], 'image': [15], '(HSI)': [16], 'classification.': [17, 64], 'HSI': [18, 63, 70, 126, 141], 'data': [19, 72], 'is': [20, 59, 101], 'typically': [21], 'presented': [22], 'in': [23], 'format': [25], '3D': [27, 30, 53], 'cubes.': [28], 'Thus,': [29, 98], 'spatial': [31], 'filtering': [32], 'naturally': [33], 'offers': [34], 'a': [35, 52, 160], 'simple': [36], 'and': [37, 107, 113, 136, 158], 'effective': [38], 'method': [39, 67, 119, 153], 'for': [40, 61], 'simultaneously': [41], 'extracting': [42, 81], 'features': [45, 85], 'within': [46], 'such': [47], 'images.': [48], 'In': [49, 87], 'this': [50], 'paper,': [51], 'convolutional': [54], 'neural': [55], 'network': [56, 134], '(3D-CNN)': [57], 'framework': [58], 'proposed': [60, 66, 118], 'accurate': [62], 'The': [65], 'views': [68], 'cube': [71], 'altogether': [73], 'without': [74], 'relying': [75], 'on': [76], 'any': [77], 'preprocessing': [78], 'or': [79], 'post-processing,': [80], 'deep': [83, 95, 124, 132], 'spectral–spatial-combined': [84], 'effectively.': [86], 'addition,': [88], 'it': [89], 'requires': [90], 'fewer': [91], 'parameters': [92], 'than': [93], 'other': [94, 123], 'learning-based': [96, 125], 'methods.': [97], 'model': [100], 'lighter,': [102], 'less': [103], 'likely': [104], 'to': [105, 109], 'over-fit,': [106], 'easier': [108], 'train.': [110], 'For': [111], 'comparison': [112], 'validation,': [114], 'we': [115], 'test': [116], 'along': [120], 'with': [121], 'three': [122, 139], 'classification': [127], 'methods—namely,': [128], 'stacked': [129], 'autoencoder': [130], '(SAE),': [131], 'brief': [133], '(DBN),': [135], '2D-CNN-based': [137], 'methods—on': [138], 'real-world': [140], 'datasets': [142], 'captured': [143], 'by': [144], 'different': [145], 'sensors.': [146], 'Experimental': [147], 'results': [148], 'demonstrate': [149], 'our': [151], '3D-CNN-based': [152], 'outperforms': [154], 'these': [155], 'state-of-the-art': [156], 'methods': [157], 'sets': [159], 'new': [161], 'record.': [162]}",2017,"['Hyperspectral imaging', 'Artificial intelligence', 'Computer science', 'Autoencoder', 'Pattern recognition (psychology)', 'Preprocessor', 'Convolutional neural network', 'Deep learning', 'Spatial analysis', 'Data cube', 'Cube (algebra)', 'Artificial neural network', 'Remote sensing', 'Data mining', 'Mathematics', 'Geology', 'Combinatorics']","Recent research has shown that using spectral–spatial information can considerably improve the performance of hyperspectral image (HSI) classification. HSI data is typically presented in the format of 3D cubes. Thus, 3D spatial filtering naturally offers a simple and effective method for simultaneously extracting the spectral–spatial features within such images. In this paper, a 3D convolutional neural network (3D-CNN) framework is proposed for accurate HSI classification. The proposed method views the HSI cube data altogether without relying on any preprocessing or post-processing, extracting the deep spectral–spatial-combined features effectively. In addition, it requires fewer parameters than other deep learning-based methods. Thus, the model is lighter, less likely to over-fit, and easier to train. For comparison and validation, we test the proposed method along with three other deep learning-based HSI classification methods—namely, stacked autoencoder (SAE), deep brief network (DBN), and 2D-CNN-based methods—on three real-world HSI datasets captured by different sensors. Experimental results demonstrate that our 3D-CNN-based method outperforms these state-of-the-art methods and sets a new record."
https://openalex.org/W2912581782,Speech Recognition Using Deep Neural Networks: A Systematic Review,"{'Over': [0], 'the': [1, 13, 27, 79, 124, 138], 'past': [2, 28], 'decades,': [3], 'a': [4, 57, 66, 75, 94], 'tremendous': [5], 'amount': [6], 'of': [7, 15, 44, 59, 70, 78, 97, 140], 'research': [8, 31, 141, 152], 'has': [9, 32, 47], 'been': [10, 84], 'done': [11], 'on': [12, 34, 137], 'use': [14], 'machine': [16, 45, 98], 'learning': [17, 37, 46, 90], 'for': [18, 38, 100], 'speech': [19, 23, 101], 'processing': [20], 'applications,': [21], 'especially': [22], 'recognition.': [24], 'However,': [25], 'in': [26, 56, 109, 132, 142], 'few': [29], 'years,': [30], 'focused': [33], 'utilizing': [35], 'deep': [36, 89], 'speech-related': [39], 'applications.': [40, 102], 'This': [41, 72], 'new': [42, 95, 151], 'area': [43, 69, 96, 144], 'yielded': [48], 'far': [49], 'better': [50], 'results': [51, 130], 'when': [52, 88], 'compared': [53], 'to': [54, 150], 'others': [55], 'variety': [58], 'applications': [60], 'including': [61], 'speech,': [62], 'and': [63, 127], 'thus': [64], 'became': [65], 'very': [67], 'attractive': [68], 'research.': [71], 'paper': [73, 134], 'provides': [74], 'thorough': [76, 104], 'examination': [77], 'different': [80], 'studies': [81], 'that': [82], 'have': [83], 'conducted': [85, 114], 'since': [86], '2006,': [87], 'first': [91], 'arose': [92], 'as': [93, 145, 147], 'learning,': [99], 'A': [103], 'statistical': [105], 'analysis': [106], 'is': [107], 'provided': [108, 131], 'this': [110, 133, 143], 'review': [111], 'which': [112], 'was': [113], 'by': [115], 'extracting': [116], 'specific': [117], 'information': [118], 'from': [119], '174': [120], 'papers': [121], 'published': [122], 'between': [123], 'years': [125], '2006': [126], '2018.': [128], 'The': [129], 'shed': [135], 'light': [136], 'trends': [139], 'well': [146], 'bring': [148], 'focus': [149], 'topics.': [153]}",2019,"['Computer science', 'Speech recognition', 'Artificial neural network', 'Artificial intelligence']","Over the past decades, a tremendous amount of research has been done on the use of machine learning for speech processing applications, especially speech recognition. However, in the past few years, research has focused on utilizing deep learning for speech-related applications. This new area of machine learning has yielded far better results when compared to others in a variety of applications including speech, and thus became a very attractive area of research. This paper provides a thorough examination of the different studies that have been conducted since 2006, when deep learning first arose as a new area of machine learning, for speech applications. A thorough statistical analysis is provided in this review which was conducted by extracting specific information from 174 papers published between the years 2006 and 2018. The results provided in this paper shed light on the trends of research in this area as well as bring focus to new research topics."
https://openalex.org/W1598866093,One weird trick for parallelizing convolutional neural networks,"{'I': [0], 'present': [1], 'a': [2], 'new': [3], 'way': [4], 'to': [5, 26], 'parallelize': [6], 'the': [7], 'training': [8], 'of': [9], 'convolutional': [10, 28], 'neural': [11, 29], 'networks': [12], 'across': [13], 'multiple': [14], 'GPUs.': [15], 'The': [16], 'method': [17], 'scales': [18], 'significantly': [19], 'better': [20], 'than': [21], 'all': [22], 'alternatives': [23], 'when': [24], 'applied': [25], 'modern': [27], 'networks.': [30]}",2014,"['Computer science', 'Convolutional neural network', 'Artificial intelligence', 'Programming language', 'Parallel computing']",I present a new way to parallelize the training of convolutional neural networks across multiple GPUs. The method scales significantly better than all alternatives when applied to modern convolutional neural networks.
https://openalex.org/W2419597278,An Analysis of Deep Neural Network Models for Practical Applications,"{'Since': [0], 'the': [1, 13, 18, 29, 37, 106, 114, 123], 'emergence': [2], 'of': [3, 15, 40, 58, 83, 116, 122, 134], 'Deep': [4], 'Neural': [5], 'Networks': [6], '(DNNs)': [7], 'as': [8], 'a': [9, 24, 55, 95, 119, 131], 'prominent': [10], 'technique': [11], 'in': [12, 27, 61, 94], 'field': [14], 'computer': [16], 'vision,': [17], 'ImageNet': [19], 'classification': [20], 'challenge': [21], 'has': [22, 43], 'played': [23], 'major': [25], 'role': [26], 'advancing': [28], 'state-of-the-art.': [30], 'While': [31], 'accuracy': [32, 89, 109], 'figures': [33], 'have': [34], 'steadily': [35], 'increased,': [36], 'resource': [38], 'utilisation': [39], 'winning': [41], 'models': [42], 'not': [44], 'been': [45], 'properly': [46], 'taken': [47], 'into': [48], 'account.': [49], 'In': [50], 'this': [51], 'work,': [52], 'we': [53], 'present': [54], 'comprehensive': [56], 'analysis': [57, 129], 'important': [59], 'metrics': [60], 'practical': [62], 'applications:': [63], 'accuracy,': [64], 'memory': [65], 'footprint,': [66], 'parameters,': [67], 'operations': [68, 117], 'count,': [69], 'inference': [70, 91, 124], 'time': [71, 92], 'and': [72, 86, 90, 110, 139], 'power': [73, 79], 'consumption.': [74], 'Key': [75], 'findings': [76], 'are:': [77], '(1)': [78], 'consumption': [80], 'is': [81, 101, 118], 'independent': [82], 'batch': [84], 'size': [85], 'architecture;': [87], '(2)': [88], 'are': [93], 'hyperbolic': [96], 'relationship;': [97], '(3)': [98], 'energy': [99], 'constraint': [100], 'an': [102], 'upper': [103], 'bound': [104], 'on': [105], 'maximum': [107], 'achievable': [108], 'model': [111], 'complexity;': [112], '(4)': [113], 'number': [115], 'reliable': [120], 'estimate': [121], 'time.': [125], 'We': [126], 'believe': [127], 'our': [128], 'provides': [130], 'compelling': [132], 'set': [133], 'information': [135], 'that': [136], 'helps': [137], 'design': [138], 'engineer': [140], 'efficient': [141], 'DNNs.': [142]}",2016,"['Artificial neural network', 'Computer science', 'Deep neural networks', 'Artificial intelligence']","Since the emergence of Deep Neural Networks (DNNs) as a prominent technique in the field of computer vision, the ImageNet classification challenge has played a major role in advancing the state-of-the-art. While accuracy figures have steadily increased, the resource utilisation of winning models has not been properly taken into account. In this work, we present a comprehensive analysis of important metrics in practical applications: accuracy, memory footprint, parameters, operations count, inference time and power consumption. Key findings are: (1) power consumption is independent of batch size and architecture; (2) accuracy and inference time are in a hyperbolic relationship; (3) energy constraint is an upper bound on the maximum achievable accuracy and model complexity; (4) the number of operations is a reliable estimate of the inference time. We believe our analysis provides a compelling set of information that helps design and engineer efficient DNNs."
https://openalex.org/W2251135946,Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks,"{'Two': [0], 'problems': [1], 'arise': [2], 'when': [3], 'using': [4], 'distant': [5, 94], 'supervision': [6], 'for': [7], 'relation': [8, 96], 'extraction.First,': [9], 'in': [10, 38, 43, 104], 'this': [11, 68], 'method,': [12], 'an': [13], 'already': [14], 'existing': [15], 'knowledge': [16], 'base': [17], 'is': [18, 98, 111, 141], 'heuristically': [19], 'aligned': [20], 'to': [21, 52, 85, 132], 'texts,': [22], 'and': [23, 123, 143], 'the': [24, 32, 60, 76, 91, 106, 116], 'alignment': [25, 34], 'results': [26], 'are': [27], 'treated': [28, 99], 'as': [29, 100], 'labeled': [30], 'data.However,': [31], 'heuristic': [33], 'can': [35, 64], 'fail,': [36], 'resulting': [37], 'wrong': [39], 'label': [40], 'problem.In': [41], 'addition,': [42], 'previous': [44], 'approaches,': [45], 'statistical': [46], 'models': [47], 'have': [48], 'typically': [49], 'been': [50], 'applied': [51], 'ad': [53], 'hoc': [54], 'features.The': [55], 'noise': [56], 'that': [57, 138], 'originates': [58], 'from': [59], 'feature': [61, 121], 'extraction': [62, 97], 'process': [63], 'cause': [65], 'poor': [66], 'performance.In': [67], 'paper,': [69], 'we': [70, 119], 'propose': [71], 'a': [72, 101], 'novel': [73], 'model': [74], 'dubbed': [75], 'Piecewise': [77], 'Convolutional': [78], 'Neural': [79], 'Networks': [80], '(PCNNs)': [81], 'with': [82, 128], 'multi-instance': [83, 102], 'learning': [84], 'address': [86, 115], 'these': [87], 'two': [88], 'problems.To': [89], 'solve': [90], 'first': [92], 'problem,': [93, 118], 'supervised': [95], 'problem': [103], 'which': [105], 'uncertainty': [107], 'of': [108], 'instance': [109], 'labels': [110], 'taken': [112], 'into': [113], 'account.To': [114], 'latter': [117], 'avoid': [120], 'engineering': [122], 'instead': [124], 'adopt': [125], 'convolutional': [126], 'architecture': [127], 'piecewise': [129], 'max': [130], 'pooling': [131], 'automatically': [133], 'learn': [134], 'relevant': [135], 'features.Experiments': [136], 'show': [137], 'our': [139], 'method': [140], 'effective': [142], 'outperforms': [144], 'several': [145], 'competitive': [146], 'baseline': [147], 'methods.': [148]}",2015,"['Convolutional neural network', 'Computer science', 'Piecewise', 'Relation (database)', 'Relationship extraction', 'Extraction (chemistry)', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Data mining', 'Mathematics', 'Chemistry', 'Chromatography', 'Mathematical analysis']","Two problems arise when using distant supervision for relation extraction.First, in this method, an already existing knowledge base is heuristically aligned to texts, and the alignment results are treated as labeled data.However, the heuristic alignment can fail, resulting in wrong label problem.In addition, in previous approaches, statistical models have typically been applied to ad hoc features.The noise that originates from the feature extraction process can cause poor performance.In this paper, we propose a novel model dubbed the Piecewise Convolutional Neural Networks (PCNNs) with multi-instance learning to address these two problems.To solve the first problem, distant supervised relation extraction is treated as a multi-instance problem in which the uncertainty of instance labels is taken into account.To address the latter problem, we avoid feature engineering and instead adopt convolutional architecture with piecewise max pooling to automatically learn relevant features.Experiments show that our method is effective and outperforms several competitive baseline methods."
https://openalex.org/W2561238782,Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer,"{'Attention': [0], 'plays': [1], 'a': [2, 32, 74, 87, 106], 'critical': [3], 'role': [4, 22], 'in': [5, 23, 66], 'human': [6], 'visual': [7], 'experience.': [8], 'Furthermore,': [9], 'it': [10, 80], 'has': [11], 'recently': [12], 'been': [13], 'demonstrated': [14], 'that': [15, 92], 'attention': [16, 53, 84], 'can': [17, 59], 'also': [18], 'play': [19], 'an': [20], 'important': [21], 'the': [24, 71, 83], 'context': [25], 'of': [26, 34, 64, 73, 86, 99, 108], 'applying': [27], 'artificial': [28], 'neural': [29, 56, 112], 'networks': [30], 'to': [31, 68, 81], 'variety': [33, 107], 'tasks': [35], 'from': [36], 'fields': [37], 'such': [38], 'as': [39], 'computer': [40], 'vision': [41], 'and': [42, 110, 116], 'NLP.': [43], 'In': [44], 'this': [45, 62], 'work': [46], 'we': [47, 58, 94], 'show': [48], 'that,': [49], 'by': [50, 78], 'properly': [51], 'defining': [52], 'for': [54, 118], 'convolutional': [55, 111], 'networks,': [57], 'actually': [60], 'use': [61], 'type': [63], 'information': [65], 'order': [67], 'significantly': [69], 'improve': [70], 'performance': [72], 'student': [75], 'CNN': [76], 'network': [77, 113], 'forcing': [79], 'mimic': [82], 'maps': [85], 'powerful': [88], 'teacher': [89], 'network.': [90], 'To': [91], 'end,': [93], 'propose': [95], 'several': [96], 'novel': [97], 'methods': [98], 'transferring': [100], 'attention,': [101], 'showing': [102], 'consistent': [103], 'improvement': [104], 'across': [105], 'datasets': [109], 'architectures.': [114], 'Code': [115], 'models': [117], 'our': [119], 'experiments': [120], 'are': [121], 'available': [122], 'at': [123], 'https://github.com/szagoruyko/attention-transfer': [124]}",2016,"['Computer science', 'Convolutional neural network', 'Variety (cybernetics)', 'Context (archaeology)', 'Attention network', 'Artificial intelligence', 'Forcing (mathematics)', 'Machine learning', 'Artificial neural network', 'Transfer of learning', 'Code (set theory)', 'Biology', 'Paleontology', 'Set (abstract data type)', 'Climatology', 'Geology', 'Programming language']","Attention plays a critical role in human visual experience. Furthermore, it has recently been demonstrated that attention can also play an important role in the context of applying artificial neural networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that, by properly defining attention for convolutional neural networks, we can actually use this type of information in order to significantly improve the performance of a student CNN network by forcing it to mimic the attention maps of a powerful teacher network. To that end, we propose several novel methods of transferring attention, showing consistent improvement across a variety of datasets and convolutional neural network architectures. Code and models for our experiments are available at https://github.com/szagoruyko/attention-transfer"
https://openalex.org/W2762410434,Convolutional neural network for earthquake detection and location,"{'ConvNetQuake': [0], 'is': [1], 'the': [2], 'first': [3], 'neural': [4], 'network': [5], 'for': [6], 'detection': [7], 'and': [8], 'location': [9], 'of': [10], 'earthquakes': [11], 'from': [12], 'seismograms.': [13]}",2018,"['Seismogram', 'Convolutional neural network', 'Computer science', 'Seismology', 'Artificial neural network', 'Geology', 'Pattern recognition (psychology)', 'Artificial intelligence']",ConvNetQuake is the first neural network for detection and location of earthquakes from seismograms.
https://openalex.org/W3009207988,"Introduction to Machine Learning, Neural Networks, and Deep Learning.","{'The': [0, 25], 'aim': [1], 'of': [2, 15, 35, 40, 46], 'this': [3], 'review': [4], 'article': [5], 'is': [6, 27], 'to': [7, 28], 'provide': [8, 29], 'the': [9, 16, 30, 36, 44], 'nontechnical': [10], 'readers': [11], 'a': [12, 32], ""layman's"": [13], 'explanation': [14], 'machine': [17], 'learning': [18], 'methods': [19], 'being': [20], 'used': [21], 'in': [22], 'medicine': [23], 'today.': [24], 'goal': [26], 'reader': [31], 'better': [33], 'understanding': [34], 'potential': [37], 'and': [38], 'challenges': [39], 'artificial': [41], 'intelligence': [42], 'within': [43], 'field': [45], 'medicine.': [47]}",2020,"['Computer science', 'Artificial intelligence', 'Artificial neural network', 'Deep learning', 'Machine learning']",The aim of this review article is to provide the nontechnical readers a layman's explanation of the machine learning methods being used in medicine today. The goal is to provide the reader a better understanding of the potential and challenges of artificial intelligence within the field of medicine.
https://openalex.org/W2105192472,Neural Networks in Materials Science.,"{'There': [0], 'are': [1, 16, 25], 'difficult': [2], 'problems': [3], 'in': [4, 40, 109], 'materials': [5, 113], 'science': [6], 'where': [7], 'the': [8, 27, 35, 56, 107, 110], 'general': [9], 'concepts': [10], 'might': [11], 'be': [12, 63], 'understood': [13], 'but': [14], 'which': [15, 48, 78], 'not': [17], 'as': [18], 'yet': [19], 'amenable': [20], 'to': [21, 37, 62, 96], 'scientific': [22], 'treatment.': [23], 'We': [24], 'at': [26], 'same': [28], 'time': [29], 'told': [30], 'that': [31], 'good': [32], 'engineering': [33], 'has': [34], 'responsibility': [36], 'reach': [38], 'objectives': [39], 'a': [41, 52, 71, 101], 'cost': [42], 'and': [43, 99], 'time-effective': [44], 'way.': [45], 'Any': [46], 'model': [47], 'deals': [49], 'with': [50, 65, 93], 'only': [51], 'small': [53], 'part': [54], 'of': [55, 73, 103, 106, 112], 'required': [57], 'technology': [58], 'is': [59, 70], 'therefore': [60], 'unlikely': [61], 'treated': [64], 'respect.': [66], 'Neural': [67], 'network': [68], 'analysis': [69], 'form': [72], 'regression': [74], 'or': [75], 'classification': [76], 'modelling': [77], 'can': [79], 'help': [80], 'resolve': [81], 'these': [82], 'difficulties': [83], 'whilst': [84], 'striving': [85], 'for': [86], 'longer': [87], 'term': [88], 'solutions.': [89], 'This': [90], 'paper': [91], 'begins': [92], 'an': [94], 'introduction': [95], 'neural': [97], 'networks': [98], 'contains': [100], 'review': [102], 'some': [104], 'applications': [105], 'technique': [108], 'context': [111], 'science.': [114]}",1999,"['Artificial neural network', 'Context (archaeology)', 'Term (time)', 'Computer science', 'Management science', 'Artificial intelligence', 'Data science', 'Risk analysis (engineering)', 'Engineering', 'Business', 'Quantum mechanics', 'Paleontology', 'Physics', 'Biology']",There are difficult problems in materials science where the general concepts might be understood but which are not as yet amenable to scientific treatment. We are at the same time told that good engineering has the responsibility to reach objectives in a cost and time-effective way. Any model which deals with only a small part of the required technology is therefore unlikely to be treated with respect. Neural network analysis is a form of regression or classification modelling which can help resolve these difficulties whilst striving for longer term solutions. This paper begins with an introduction to neural networks and contains a review of some applications of the technique in the context of materials science.
https://openalex.org/W2513853720,Training Deep Spiking Neural Networks Using Backpropagation,"{'Deep': [0], 'spiking': [1, 51], 'neural': [2, 17, 177, 218], 'networks': [3, 18, 26], '(SNNs)': [4], 'hold': [5], 'the': [6, 10, 31, 47, 76, 106, 110, 118, 126, 135, 147, 151, 163, 184, 190, 193, 221], 'potential': [7, 107], 'for': [8, 71], 'improving': [9], 'latency': [11], 'and': [12, 90, 101, 132, 167, 181, 207], 'energy': [13], 'efficiency': [14], 'of': [15, 34, 50, 112, 157, 192], 'deep': [16, 72, 82, 202], 'through': [19], 'data-driven': [20], 'event-based': [21, 141], 'computation.': [22], 'However,': [23], 'training': [24, 100], 'such': [25], 'is': [27, 226], 'difficult': [28], 'due': [29], 'to': [30, 108, 162, 198], 'non-differentiable': [32], 'nature': [33], 'spike': [35, 59, 88], 'events.': [36], 'In': [37, 220], 'this': [38], 'paper,': [39], 'we': [40], 'introduce': [41], 'a': [42, 155, 170, 174], 'novel': [43], 'technique,': [44], 'which': [45, 146], 'treats': [46], 'membrane': [48, 91], 'potentials': [49], 'neurons': [52], 'as': [53, 63, 79], 'differentiable': [54], 'signals,': [55], 'where': [56], 'discontinuities': [57], 'at': [58], 'times': [60, 231], 'are': [61], 'considered': [62], 'noise.': [64], 'This': [65], 'enables': [66], 'an': [67, 140], 'error': [68, 152], 'backpropagation': [69], 'mechanism': [70], 'SNNs': [73, 203], 'that': [74, 196], 'follows': [75], 'same': [77, 185], 'principles': [78], 'in': [80, 145, 189], 'conventional': [81, 175, 217], 'networks,': [83], 'but': [84], 'works': [85], 'directly': [86], 'on': [87, 98, 121, 134, 183], 'signals': [89], 'potentials.': [92], 'Compared': [93], 'with': [94, 139, 210, 216, 228], 'previous': [95, 165], 'methods': [96], 'relying': [97], 'indirect': [99], 'conversion,': [102], 'our': [103, 211], 'technique': [104], 'has': [105], 'capture': [109], 'statistics': [111], 'spikes': [113], 'more': [114, 158], 'precisely.': [115], 'We': [116, 187], 'evaluate': [117], 'proposed': [119, 148], 'framework': [120], 'artificially': [122], 'generated': [123], 'events': [124], 'from': [125], 'original': [127], 'MNIST': [128, 194], 'handwritten': [129], 'digit': [130], 'benchmark,': [131], 'also': [133, 168], 'N-MNIST': [136, 222], 'benchmark': [137], 'recorded': [138], 'dynamic': [142], 'vision': [143], 'sensor,': [144], 'method': [149, 212], 'reduces': [150], 'rate': [153], 'by': [154], 'factor': [156], 'than': [159, 173], 'three': [160], 'compared': [161], 'best': [164], 'SNN,': [166], 'achieves': [169], 'higher': [171], 'accuracy': [172, 214, 225], 'convolutional': [176], 'network': [178], '(CNN)': [179], 'trained': [180, 209], 'tested': [182], 'data.': [186], 'demonstrate': [188], 'context': [191], 'task': [195], 'thanks': [197], 'their': [199], 'event-driven': [200], 'operation,': [201], '(both': [204], 'fully': [205], 'connected': [206], 'convolutional)': [208], 'achieve': [213], 'equivalent': [215, 224], 'networks.': [219], 'example,': [223], 'achieved': [227], 'about': [229], 'five': [230], 'fewer': [232], 'computational': [233], 'operations.': [234]}",2016,"['MNIST database', 'Computer science', 'Spiking neural network', 'Artificial intelligence', 'Backpropagation', 'Benchmark (surveying)', 'Convolutional neural network', 'Deep learning', 'Artificial neural network', 'Pattern recognition (psychology)', 'Machine learning', 'Geodesy', 'Geography']","Deep spiking neural networks (SNNs) hold the potential for improving the latency and energy efficiency of deep neural networks through data-driven event-based computation. However, training such networks is difficult due to the non-differentiable nature of spike events. In this paper, we introduce a novel technique, which treats the membrane potentials of spiking neurons as differentiable signals, where discontinuities at spike times are considered as noise. This enables an error backpropagation mechanism for deep SNNs that follows the same principles as in conventional deep networks, but works directly on spike signals and membrane potentials. Compared with previous methods relying on indirect training and conversion, our technique has the potential to capture the statistics of spikes more precisely. We evaluate the proposed framework on artificially generated events from the original MNIST handwritten digit benchmark, and also on the N-MNIST benchmark recorded with an event-based dynamic vision sensor, in which the proposed method reduces the error rate by a factor of more than three compared to the best previous SNN, and also achieves a higher accuracy than a conventional convolutional neural network (CNN) trained and tested on the same data. We demonstrate in the context of the MNIST task that thanks to their event-driven operation, deep SNNs (both fully connected and convolutional) trained with our method achieve accuracy equivalent with conventional neural networks. In the N-MNIST example, equivalent accuracy is achieved with about five times fewer computational operations."
https://openalex.org/W2613328025,A Dual-Stage Attention-Based Recurrent Neural Network for Time Series Prediction,"{'The': [0], 'Nonlinear': [1], 'autoregressive': [2], 'exogenous': [3], '(NARX)': [4], 'model,': [5], 'which': [6], 'predicts': [7], 'the': [8, 23, 39, 53, 60, 85, 110, 116, 159, 164, 171], 'current': [9, 24], 'value': [10], 'of': [11, 28, 49], 'a': [12, 72, 121], 'time': [13, 105, 133, 178], 'series': [14, 63, 99, 179], 'based': [15, 157], 'upon': [16, 158], 'its': [17], 'previous': [18, 111], 'values': [19, 27], 'as': [20, 22], 'well': [21], 'and': [25, 58, 163], 'past': [26], 'multiple': [29], 'driving': [30, 62, 98], '(exogenous)': [31], 'series,': [32], 'has': [33], 'been': [34, 46], 'studied': [35], 'for': [36, 177], 'decades.': [37], 'Despite': [38], 'fact': [40], 'that': [41, 170], 'various': [42], 'NARX': [43], 'models': [44], 'have': [45], 'developed,': [47], 'few': [48], 'them': [50], 'can': [51, 142, 149, 173], 'capture': [52], 'long-term': [54], 'temporal': [55, 122], 'dependencies': [56], 'appropriately': [57], 'select': [59, 126], 'relevant': [61, 97, 127], 'to': [64, 79, 94, 109, 125], 'make': [65, 145], 'predictions.': [66], 'In': [67, 84, 115], 'this': [68, 136], 'paper,': [69], 'we': [70, 88, 119], 'propose': [71], 'dual-stage': [73, 137], 'attention-based': [74], 'recurrent': [75], 'neural': [76], 'network': [77], '(DA-RNN)': [78], 'address': [80], 'these': [81], 'two': [82], 'issues.': [83], 'first': [86], 'stage,': [87, 118], 'introduce': [89], 'an': [90], 'input': [91, 101], 'attention': [92, 123, 138], 'mechanism': [93, 124], 'adaptively': [95], 'extract': [96], '(a.k.a.,': [100], 'features)': [102], 'at': [103], 'each': [104], 'step': [106], 'by': [107], 'referring': [108], 'encoder': [112, 128], 'hidden': [113, 129], 'state.': [114], 'second': [117], 'use': [120], 'states': [130], 'across': [131], 'all': [132], 'steps.': [134], 'With': [135], 'scheme,': [139], 'our': [140], 'model': [141], 'not': [143], 'only': [144], 'predictions': [146], 'effectively,': [147], 'but': [148], 'also': [150], 'be': [151], 'easily': [152], 'interpreted.': [153], 'Thorough': [154], 'empirical': [155], 'studies': [156], 'SML': [160], '2010': [161], 'dataset': [162, 168], 'NASDAQ': [165], '100': [166], 'Stock': [167], 'demonstrate': [169], 'DA-RNN': [172], 'outperform': [174], 'state-of-the-art': [175], 'methods': [176], 'prediction.': [180]}",2017,"['Nonlinear autoregressive exogenous model', 'Computer science', 'Recurrent neural network', 'Autoregressive model', 'Time series', 'Series (stratigraphy)', 'Dual (grammatical number)', 'Artificial intelligence', 'Artificial neural network', 'Machine learning', 'Encoder', 'Pattern recognition (psychology)', 'Econometrics', 'Mathematics', 'Operating system', 'Biology', 'Paleontology', 'Art', 'Literature']","The Nonlinear autoregressive exogenous (NARX) model, which predicts the current value of a time series based upon its previous values as well as the current and past values of multiple driving (exogenous) series, has been studied for decades. Despite the fact that various NARX models have been developed, few of them can capture the long-term temporal dependencies appropriately and select the relevant driving series to make predictions. In this paper, we propose a dual-stage attention-based recurrent neural network (DA-RNN) to address these two issues. In the first stage, we introduce an input attention mechanism to adaptively extract relevant driving series (a.k.a., input features) at each time step by referring to the previous encoder hidden state. In the second stage, we use a temporal attention mechanism to select relevant encoder hidden states across all time steps. With this dual-stage attention scheme, our model can not only make predictions effectively, but can also be easily interpreted. Thorough empirical studies based upon the SML 2010 dataset and the NASDAQ 100 Stock dataset demonstrate that the DA-RNN can outperform state-of-the-art methods for time series prediction."
https://openalex.org/W4293406525,ENet: A Deep Neural Network Architecture for Real-Time Semantic\n Segmentation,"{'The': [0], 'ability': [1], 'to': [2, 65], 'perform': [3], 'pixel-wise': [4], 'semantic': [5], 'segmentation': [6], 'in': [7, 12], 'real-time': [8], 'is': [9, 63], 'of\\nparamount': [10], 'importance': [11], 'mobile': [13], 'applications.': [14], 'Recent': [15], 'deep': [16, 47], 'neural': [17, 48, 53], 'networks': [18], 'aimed\\nat': [19], 'this': [20], 'task': [21], 'have': [22, 34, 84], 'the': [23, 114], 'disadvantage': [24], 'of': [25, 30, 107, 113], 'requiring': [26, 59], 'a': [27, 45, 108], 'large': [28], 'number': [29], 'floating\\npoint': [31], 'operations': [32], 'and': [33, 75, 90, 100, 104], 'long': [35], 'run-times': [36], 'that': [37, 124], 'hinder': [38], 'their': [39], 'usability.': [40], 'In': [41], 'this\\npaper,': [42], 'we': [43], 'propose': [44], 'novel': [46], 'network': [49], 'architecture': [50, 116], 'named': [51], 'ENet\\n(efficient': [52], 'network),': [54], 'created': [55], 'specifically': [56], 'for': [57], 'tasks': [58], 'low\\nlatency': [60], 'operation.': [61], 'ENet': [62, 127], 'up': [64], '18$\\\\times$': [66], 'faster,': [67], 'requires': [68], '75$\\\\times$': [69], 'less\\nFLOPs,': [70], 'has': [71], '79$\\\\times$': [72], 'less': [73], 'parameters,': [74], 'provides': [76], 'similar': [77], 'or': [78], 'better': [79], 'accuracy\\nto': [80], 'existing': [81, 97], 'models.': [82], 'We': [83, 110], 'tested': [85], 'it': [86], 'on': [87, 94, 117], 'CamVid,': [88], 'Cityscapes': [89], 'SUN': [91], 'datasets\\nand': [92], 'report': [93], 'comparisons': [95], 'with': [96], 'state-of-the-art': [98], 'methods,': [99], 'the\\ntrade-offs': [101], 'between': [102], 'accuracy': [103], 'processing': [105], 'time': [106], 'network.': [109], 'present\\nperformance': [111], 'measurements': [112], 'proposed': [115], 'embedded': [118], 'systems': [119], 'and\\nsuggest': [120], 'possible': [121], 'software': [122], 'improvements': [123], 'could': [125], 'make': [126], 'even': [128], 'faster.\\n': [129]}",2016,"['Computer science', 'Segmentation', 'Artificial neural network', 'Deep neural networks', 'FLOPS', 'Artificial intelligence', 'Architecture', 'Network architecture', 'Usability', 'Deep learning', 'Latency (audio)', 'Parallel computing', 'Telecommunications', 'Computer network', 'Visual arts', 'Human–computer interaction', 'Art']","The ability to perform pixel-wise semantic segmentation in real-time is of\nparamount importance in mobile applications. Recent deep neural networks aimed\nat this task have the disadvantage of requiring a large number of floating\npoint operations and have long run-times that hinder their usability. In this\npaper, we propose a novel deep neural network architecture named ENet\n(efficient neural network), created specifically for tasks requiring low\nlatency operation. ENet is up to 18$\\times$ faster, requires 75$\\times$ less\nFLOPs, has 79$\\times$ less parameters, and provides similar or better accuracy\nto existing models. We have tested it on CamVid, Cityscapes and SUN datasets\nand report on comparisons with existing state-of-the-art methods, and the\ntrade-offs between accuracy and processing time of a network. We present\nperformance measurements of the proposed architecture on embedded systems and\nsuggest possible software improvements that could make ENet even faster.\n"
https://openalex.org/W4223551334,DeepTMHMM predicts alpha and beta transmembrane proteins using deep neural networks,"{'Abstract': [0], 'Transmembrane': [1], 'proteins': [2, 45], 'span': [3], 'the': [4, 36], 'lipid': [5], 'bilayer': [6], 'and': [7, 18, 34, 42, 56], 'are': [8], 'divided': [9], 'into': [10], 'two': [11], 'major': [12], 'structural': [13], 'classes,': [14], 'namely': [15], 'alpha': [16, 40], 'helical': [17, 41], 'beta': [19, 43], 'barrels.': [20], 'We': [21], 'introduce': [22], 'DeepTMHMM,': [23], 'a': [24], 'deep': [25], 'learning': [26], 'protein': [27], 'language': [28], 'model-based': [29], 'algorithm': [30], 'that': [31], 'can': [32], 'detect': [33], 'predict': [35], 'topology': [37], 'of': [38, 60], 'both': [39], 'barrels': [44], 'with': [46], 'unprecedented': [47], 'accuracy.': [48], 'DeepTMHMM': [49], '(': [50], 'https://dtu.biolib.com/DeepTMHMM': [51], ')': [52], 'scales': [53], 'to': [54], 'proteomes': [55], 'covers': [57], 'all': [58], 'domains': [59], 'life,': [61], 'which': [62], 'makes': [63], 'it': [64], 'ideal': [65], 'for': [66], 'metagenomics': [67], 'analyses.': [68]}",2022,"['BETA (programming language)', 'Transmembrane protein', 'Alpha (finance)', 'Proteome', 'Deep learning', 'Artificial intelligence', 'Artificial neural network', 'Transmembrane domain', 'Computational biology', 'Computer science', 'Topology (electrical circuits)', 'Biology', 'Bioinformatics', 'Mathematics', 'Combinatorics', 'Biochemistry', 'Membrane', 'Statistics', 'Programming language', 'Receptor', 'Psychometrics', 'Construct validity']","Abstract Transmembrane proteins span the lipid bilayer and are divided into two major structural classes, namely alpha helical and beta barrels. We introduce DeepTMHMM, a deep learning protein language model-based algorithm that can detect and predict the topology of both alpha helical and beta barrels proteins with unprecedented accuracy. DeepTMHMM ( https://dtu.biolib.com/DeepTMHMM ) scales to proteomes and covers all domains of life, which makes it ideal for metagenomics analyses."
https://openalex.org/W2963854351,Multi-Task Deep Neural Networks for Natural Language Understanding,"{'In': [0], 'this': [1], 'paper,': [2], 'we': [3], 'present': [4], 'a': [5, 34, 63], 'Multi-Task': [6], 'Deep': [7], 'Neural': [8], 'Network': [9], '(MT-DNN)': [10], 'for': [11], 'learning': [12], 'representations': [13, 42, 126], 'across': [14], 'multiple': [15], 'natural': [16], 'language': [17, 67], 'understanding': [18], '(NLU)': [19], 'tasks.': [20], 'MT-DNN': [21, 51, 76, 129], 'not': [22], 'only': [23], 'leverages': [24], 'large': [25], 'amounts': [26], 'of': [27, 91, 105], 'cross-task': [28], 'data,': [29], 'but': [30], 'also': [31, 116], 'benefits': [32], 'from': [33], 'regularization': [35], 'effect': [36], 'that': [37, 124], 'leads': [38], 'to': [39, 43, 46, 99], 'more': [40], 'general': [41], 'help': [44], 'adapt': [45], 'new': [47, 78], 'tasks': [48], 'and': [49, 88, 121, 145], 'domains.': [50], 'extends': [52], 'the': [53, 96, 110, 119, 125, 139], 'model': [54], 'proposed': [55], 'in': [56], 'Liu': [57], 'et': [58, 73], 'al.': [59], '(2015)': [60], 'by': [61, 128], 'incorporating': [62], 'pre-trained': [64, 140, 146], 'bidirectional': [65], 'transformer': [66], 'model,': [68], 'known': [69], 'as': [70, 104], 'BERT': [71, 141], '(Devlin': [72], 'al.,': [74], '2018).': [75], 'obtains': [77], 'state-of-the-art': [79], 'results': [80], 'on': [81, 109], 'ten': [82], 'NLU': [83], 'tasks,': [84, 94], 'including': [85], 'SNLI,': [86], 'SciTail,': [87], 'eight': [89], 'out': [90], 'nine': [92], 'GLUE': [93, 97, 112], 'pushing': [95], 'benchmark': [98], '82.7%': [100], '(2.2%': [101], 'absolute': [102], 'improvement)': [103], 'February': [106], '25,': [107], '2019': [108], 'latest': [111], 'test': [113], 'set.': [114], 'We': [115], 'demonstrate': [117], 'using': [118], 'SNLI': [120], 'SciTail': [122], 'datasets': [123], 'learned': [127], 'allow': [130], 'domain': [131], 'adaptation': [132], 'with': [133], 'substantially': [134], 'fewer': [135], 'in-domain': [136], 'labels': [137], 'than': [138], 'representations.': [142], 'Our': [143], 'code': [144], 'models': [147], 'will': [148], 'be': [149], 'made': [150], 'publicly': [151], 'available.': [152]}",2019,"['Computer science', 'Domain adaptation', 'Transformer', 'Artificial intelligence', 'Benchmark (surveying)', 'Natural language understanding', 'Task (project management)', 'Artificial neural network', 'Regularization (linguistics)', 'Deep neural networks', 'Deep learning', 'Labeled data', 'Task analysis', 'Language model', 'Natural language processing', 'Test set', 'Machine learning', 'Natural language', 'Voltage', 'Geography', 'Classifier (UML)', 'Economics', 'Physics', 'Geodesy', 'Quantum mechanics', 'Management']","In this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for learning representations across multiple natural language understanding (NLU) tasks. MT-DNN not only leverages large amounts of cross-task data, but also benefits from a regularization effect that leads to more general representations to help adapt to new tasks and domains. MT-DNN extends the model proposed in Liu et al. (2015) by incorporating a pre-trained bidirectional transformer language model, known as BERT (Devlin et al., 2018). MT-DNN obtains new state-of-the-art results on ten NLU tasks, including SNLI, SciTail, and eight out of nine GLUE tasks, pushing the GLUE benchmark to 82.7% (2.2% absolute improvement) as of February 25, 2019 on the latest GLUE test set. We also demonstrate using the SNLI and SciTail datasets that the representations learned by MT-DNN allow domain adaptation with substantially fewer in-domain labels than the pre-trained BERT representations. Our code and pre-trained models will be made publicly available."
https://openalex.org/W2501369945,DeepFruits: A Fruit Detection System Using Deep Neural Networks,"{'This': [0, 111], 'paper': [1], 'presents': [2], 'a': [3, 29, 40, 62, 114], 'novel': [4, 115], 'approach': [5, 162], 'to': [6, 17, 58, 113, 125, 146, 158, 167, 192, 198, 212], 'fruit': [7, 24, 44, 83], 'detection': [8, 25, 84, 152, 201], 'using': [9, 85], 'deep': [10, 53], 'convolutional': [11], 'neural': [12, 54], 'networks.': [13], 'The': [14, 194], 'aim': [15], 'is': [16, 28, 39, 163, 185, 196], 'build': [18], 'an': [19, 33, 187], 'accurate,': [20], 'fast': [21], 'and': [22, 47, 93, 97, 108, 138, 214], 'reliable': [23], 'system,': [26], 'which': [27, 120, 132], 'vital': [30], 'element': [31, 42], 'of': [32, 61, 82, 153, 189, 202], 'autonomous': [34], 'agricultural': [35], 'robotic': [36], 'platform;': [37], 'it': [38, 173], 'key': [41], 'for': [43, 79, 103, 150, 169], 'yield': [45], 'estimation': [46], 'automated': [48], 'harvesting.': [49], 'Recent': [50], 'work': [51, 127], 'in': [52], 'networks': [55], 'has': [56], 'led': [57], 'the': [59, 80, 105, 129, 151, 200, 206, 216], 'development': [60], 'state-of-the-art': [63, 122], 'object': [64], 'detector': [65], 'termed': [66], 'Faster': [67, 117], 'Region-based': [68], 'CNN': [69], '(Faster': [70], 'R-CNN).': [71], 'We': [72], 'adapt': [73], 'this': [74, 161], 'model,': [75, 119], 'through': [76], 'transfer': [77], 'learning,': [78], 'task': [81], 'imagery': [86], 'obtained': [87], 'from': [88, 142], 'two': [89], 'modalities:': [90], 'colour': [91], '(RGB)': [92], 'Near-Infrared': [94], '(NIR).': [95], 'Early': [96], 'late': [98], 'fusion': [99], 'methods': [100], 'are': [101], 'explored': [102], 'combining': [104], 'multi-modal': [106, 116], '(RGB': [107], 'NIR)': [109], 'information.': [110], 'leads': [112], 'R-CNN': [118], 'achieves': [121], 'results': [123], 'compared': [124], 'prior': [126], 'with': [128, 205], 'F1': [130], 'score,': [131], 'takes': [133], 'into': [134], 'account': [135], 'both': [136], 'precision': [137], 'recall': [139], 'performances': [140], 'improving': [141], '0': [143, 147], '.': [144, 148], '807': [145], '838': [149], 'sweet': [154], 'pepper.': [155], 'In': [156], 'addition': [157], 'improved': [159], 'accuracy,': [160], 'also': [164], 'much': [165], 'quicker': [166, 191], 'deploy': [168], 'new': [170, 217], 'fruits,': [171, 204], 'as': [172], 'requires': [174], 'bounding': [175, 183], 'box': [176], 'annotation': [177, 181], 'rather': [178], 'than': [179], 'pixel-level': [180], '(annotating': [182], 'boxes': [184], 'approximately': [186], 'order': [188], 'magnitude': [190], 'perform).': [193], 'model': [195, 218], 'retrained': [197], 'perform': [199], 'seven': [203], 'entire': [207], 'process': [208], 'taking': [209], 'four': [210], 'hours': [211], 'annotate': [213], 'train': [215], 'per': [219], 'fruit.': [220]}",2016,"['Convolutional neural network', 'Computer science', 'Artificial intelligence', 'RGB color model', 'Deep learning', 'Object detection', 'Minimum bounding box', 'Bounding overwatch', 'Process (computing)', 'Pattern recognition (psychology)', 'Transfer of learning', 'Artificial neural network', 'Computer vision', 'Image (mathematics)', 'Operating system']","This paper presents a novel approach to fruit detection using deep convolutional neural networks. The aim is to build an accurate, fast and reliable fruit detection system, which is a vital element of an autonomous agricultural robotic platform; it is a key element for fruit yield estimation and automated harvesting. Recent work in deep neural networks has led to the development of a state-of-the-art object detector termed Faster Region-based CNN (Faster R-CNN). We adapt this model, through transfer learning, for the task of fruit detection using imagery obtained from two modalities: colour (RGB) and Near-Infrared (NIR). Early and late fusion methods are explored for combining the multi-modal (RGB and NIR) information. This leads to a novel multi-modal Faster R-CNN model, which achieves state-of-the-art results compared to prior work with the F1 score, which takes into account both precision and recall performances improving from 0 . 807 to 0 . 838 for the detection of sweet pepper. In addition to improved accuracy, this approach is also much quicker to deploy for new fruits, as it requires bounding box annotation rather than pixel-level annotation (annotating bounding boxes is approximately an order of magnitude quicker to perform). The model is retrained to perform the detection of seven fruits, with the entire process taking four hours to annotate and train the new model per fruit."
https://openalex.org/W2963017945,Adaptive Graph Convolutional Neural Networks,"{'Graph': [0], 'Convolutional': [1], 'Neural': [2], 'Networks': [3], '(Graph': [4], 'CNNs)': [5], 'are': [6, 29], 'generalizations': [7], 'of': [8, 62], 'classical': [9], 'CNNs': [10, 28], 'to': [11], 'handle': [12], 'graph': [13, 27, 35, 43, 58, 64, 74, 79], 'data': [14, 61, 80], 'such': [15], 'as': [16, 66], 'molecular': [17], 'data,': [18, 41], 'point': [19], 'could': [20], 'and': [21, 33, 49, 56, 110], 'social': [22], 'networks.': [23], 'Current': [24], 'filters': [25], 'in': [26, 46], 'built': [30], 'for': [31, 38, 77], 'fixed': [32], 'shared': [34], 'structure.': [36], 'However,': [37], 'most': [39], 'real': [40], 'the': [42, 86, 102], 'structures': [44], 'varies': [45], 'both': [47, 107], 'size': [48], 'connectivity.': [50], 'The': [51], 'paper': [52], 'proposes': [53], 'a': [54, 71, 88], 'generalized': [55], 'flexible': [57], 'CNN': [59], 'taking': [60], 'arbitrary': [63], 'structure': [65], 'input.': [67], 'In': [68], 'that': [69], 'way': [70], 'task-driven': [72], 'adaptive': [73], 'is': [75, 92], 'learned': [76], 'each': [78], 'while': [81], 'training.': [82], 'To': [83], 'efficiently': [84], 'learn': [85], 'graph,': [87], 'distance': [89], 'metric': [90], 'learning': [91], 'proposed.': [93], 'Extensive': [94], 'experiments': [95], 'on': [96, 106], 'nine': [97], 'graph-structured': [98], 'datasets': [99], 'have': [100], 'demonstrated': [101], 'superior': [103], 'performance': [104], 'improvement': [105], 'convergence': [108], 'speed': [109], 'predictive': [111], 'accuracy.': [112]}",2018,"['Computer science', 'Voltage graph', 'Graph', 'Null graph', 'Theoretical computer science', 'Strength of a graph', 'Butterfly graph', 'Line graph', 'Algorithm']","Graph Convolutional Neural Networks (Graph CNNs) are generalizations of classical CNNs to handle graph data such as molecular data, point could and social networks. Current filters in graph CNNs are built for fixed and shared graph structure. However, for most real data, the graph structures varies in both size and connectivity. The paper proposes a generalized and flexible graph CNN taking data of arbitrary graph structure as input. In that way a task-driven adaptive graph is learned for each graph data while training. To efficiently learn the graph, a distance metric learning is proposed. Extensive experiments on nine graph-structured datasets have demonstrated the superior performance improvement on both convergence speed and predictive accuracy."
https://openalex.org/W2766162919,Training Deep Neural Networks for the Inverse Design of Nanophotonic Structures,"{'Data': [0], 'inconsistency': [1], 'leads': [2], 'to': [3, 56, 76], 'a': [4, 45], 'slow': [5], 'training': [6], 'process': [7], 'when': [8], 'deep': [9, 54, 74], 'neural': [10], 'networks\\nare': [11], 'used': [12], 'for': [13, 72], 'the': [14, 70], 'inverse': [15, 31, 42], 'design': [16, 43, 77], 'of': [17, 27], 'photonic': [18, 79], 'devices,': [19], 'an': [20], 'issue': [21], 'that': [22, 36, 63, 81], 'arises': [23], 'from\\nthe': [24], 'fundamental': [25, 51], 'property': [26], 'non-uniqueness': [28], 'in': [29, 44], 'all': [30], 'scattering': [32, 66], 'problems.\\nHere': [33], 'we': [34], 'show': [35], 'by': [37, 60], 'combining': [38], 'forward': [39], 'modeling': [40], 'and': [41], 'tandem\\narchitecture,': [46], 'one': [47], 'can': [48], 'overcome': [49], 'this': [50], 'issue,': [52], 'allowing': [53], 'neural\\nnetworks': [55, 75], 'be': [57], 'effectively': [58], 'trained': [59], 'data': [61], 'sets': [62], 'contain': [64], 'non-unique\\nelectromagnetic': [65], 'instances.': [67], 'This': [68], 'paves': [69], 'way': [71], 'using': [73], 'complex': [78], 'structures': [80], 'requires': [82], 'large': [83], 'training\\nsets.\\n': [84]}",2018,"['Artificial neural network', 'Computer science', 'Nanophotonics', 'Inverse', 'Deep learning', 'Photonics', 'Inverse problem', 'Artificial intelligence', 'Process (computing)', 'Physics', 'Mathematics', 'Optics', 'Geometry', 'Operating system', 'Mathematical analysis']","Data inconsistency leads to a slow training process when deep neural networks\nare used for the inverse design of photonic devices, an issue that arises from\nthe fundamental property of non-uniqueness in all inverse scattering problems.\nHere we show that by combining forward modeling and inverse design in a tandem\narchitecture, one can overcome this fundamental issue, allowing deep neural\nnetworks to be effectively trained by data sets that contain non-unique\nelectromagnetic scattering instances. This paves the way for using deep neural\nnetworks to design complex photonic structures that requires large training\nsets.\n"
https://openalex.org/W2780099243,Classification using deep learning neural networks for brain tumors,"{'Deep': [0, 46], 'Learning': [1], 'is': [2, 51], 'a': [3, 10, 30, 59], 'new': [4], 'machine': [5, 32], 'learning': [6, 33], 'field': [7], 'that': [8], 'gained': [9], 'lot': [11], 'of': [12, 37, 53, 61, 100], 'interest': [13], 'over': [14, 106], 'the': [15, 38, 54, 82, 87, 98, 101, 108], 'past': [16], 'few': [17], 'years.': [18], 'It': [19], 'was': [20, 79, 103], 'widely': [21], 'applied': [22], 'to': [23, 28], 'several': [24], 'applications': [25], 'and': [26, 72, 92, 97], 'proven': [27], 'be': [29], 'powerful': [31, 88], 'tool': [34, 91], 'for': [35, 57], 'many': [36], 'complex': [39], 'problems.': [40], 'In': [41], 'this': [42], 'paper': [43], 'we': [44], 'used': [45], 'Neural': [47], 'Network': [48], 'classifier': [49, 78], 'which': [50], 'one': [52], 'DL': [55], 'architectures': [56], 'classifying': [58], 'dataset': [60], '66': [62], 'brain': [63], 'MRIs': [64], 'into': [65], '4': [66], 'classes': [67], 'e.g.': [68], 'normal,': [69], 'glioblastoma,': [70], 'sarcoma': [71], 'metastatic': [73], 'bronchogenic': [74], 'carcinoma': [75], 'tumors.': [76], 'The': [77], 'combined': [80], 'with': [81], 'discrete': [83], 'wavelet': [84], 'transform': [85], '(DWT)': [86], 'feature': [89], 'extraction': [90], 'principal': [93], 'components': [94], 'analysis': [95], '(PCA)': [96], 'evaluation': [99], 'performance': [102, 109], 'quite': [104], 'good': [105], 'all': [107], 'measures.': [110]}",2017,"['Artificial intelligence', 'Deep learning', 'Computer science', 'Bronchogenic carcinoma', 'Classifier (UML)', 'Artificial neural network', 'Pattern recognition (psychology)', 'Machine learning', 'Feature extraction', 'Discrete wavelet transform', 'Wavelet', 'Wavelet transform', 'Carcinoma', 'Pathology', 'Medicine']","Deep Learning is a new machine learning field that gained a lot of interest over the past few years. It was widely applied to several applications and proven to be a powerful machine learning tool for many of the complex problems. In this paper we used Deep Neural Network classifier which is one of the DL architectures for classifying a dataset of 66 brain MRIs into 4 classes e.g. normal, glioblastoma, sarcoma and metastatic bronchogenic carcinoma tumors. The classifier was combined with the discrete wavelet transform (DWT) the powerful feature extraction tool and principal components analysis (PCA) and the evaluation of the performance was quite good over all the performance measures."
https://openalex.org/W2467173223,Abstractive Sentence Summarization with Attentive Recurrent Neural Networks,"{'Abstractive': [0], 'Sentence': [1], 'Summarization': [2], 'generates': [3, 25], 'a': [4, 8, 18, 26, 36], 'shorter': [5], 'version': [6], 'of': [7, 28, 55], 'given': [9], 'sentence': [10], 'while': [11, 92], 'attempting': [12], 'to': [13, 66], 'preserve': [14], 'its': [15], 'meaning.We': [16], 'introduce': [17], 'conditional': [19], 'recurrent': [20], 'neural': [21], 'network': [22], '(RNN)': [23], 'which': [24, 41], 'summary': [27], 'an': [29, 69], 'input': [30, 50], 'sentence.The': [31], 'conditioning': [32], 'is': [33, 64], 'provided': [34], 'by': [35], 'novel': [37], 'convolutional': [38], 'attention-based': [39], 'encoder': [40], 'ensures': [42], 'that': [43, 78], 'the': [44, 48, 79, 83, 89, 96], 'decoder': [45], 'focuses': [46], 'on': [47, 60, 72, 88, 95], 'appropriate': [49], 'words': [51], 'at': [52], 'each': [53], 'step': [54], 'generation.Our': [56], 'model': [57, 80], 'relies': [58], 'only': [59], 'learned': [61], 'features': [62], 'and': [63], 'easy': [65], 'train': [67], 'in': [68], 'end-to-end': [70], 'fashion': [71], 'large': [73], 'data': [74], 'sets.Our': [75], 'experiments': [76], 'show': [77], 'significantly': [81], 'outperforms': [82], 'recently': [84], 'proposed': [85], 'state-of-the-art': [86], 'method': [87], 'Gigaword': [90], 'corpus': [91], 'performing': [93], 'competitively': [94], 'DUC-2004': [97], 'shared': [98], 'task.': [99]}",2016,"['Automatic summarization', 'Computer science', 'Sentence', 'Artificial intelligence', 'Natural language processing', 'Recurrent neural network', 'Artificial neural network']",Abstractive Sentence Summarization generates a shorter version of a given sentence while attempting to preserve its meaning.We introduce a conditional recurrent neural network (RNN) which generates a summary of an input sentence.The conditioning is provided by a novel convolutional attention-based encoder which ensures that the decoder focuses on the appropriate input words at each step of generation.Our model relies only on learned features and is easy to train in an end-to-end fashion on large data sets.Our experiments show that the model significantly outperforms the recently proposed state-of-the-art method on the Gigaword corpus while performing competitively on the DUC-2004 shared task.
https://openalex.org/W2963266340,A theoretically grounded application of dropout in recurrent neural networks,"{'Recurrent': [0], 'neural': [1], 'networks': [2], '(RNNs)': [3], 'stand': [4], 'at': [5, 39], 'the': [6, 40, 72, 78, 116, 123, 131], 'forefront': [7], 'of': [8, 42, 52, 62, 71, 80, 118, 141], 'many': [9], 'recent': [10], 'developments': [11], 'in': [12, 64, 94, 127, 144], 'deep': [13, 46, 54, 145], 'learning.': [14, 146], 'Yet': [15], 'a': [16, 49], 'major': [17], 'difficulty': [18], 'with': [19, 27, 82, 130], 'these': [20], 'models': [21], 'is': [22], 'their': [23], 'tendency': [24], 'to': [25, 30, 34, 115], 'overfit,': [26], 'dropout': [28, 63, 81, 92], 'shown': [29], 'fail': [31], 'when': [32], 'applied': [33], 'recurrent': [35], 'layers.': [36], 'Recent': [37], 'results': [38], 'intersection': [41], 'Bayesian': [43, 50, 66], 'modelling': [44, 103, 129], 'and': [45, 96, 104, 114], 'learning': [47, 55], 'offer': [48], 'interpretation': [51], 'common': [53], 'techniques': [56], 'such': [57], 'as': [58], 'dropout.': [59], 'This': [60, 137], 'grounding': [61], 'approximate': [65], 'inference': [67, 90], 'suggests': [68], 'an': [69], 'extension': [70], 'theoretical': [73], 'results,': [74], 'offering': [75], 'insights': [76], 'into': [77], 'use': [79], 'RNN': [83], 'models.': [84], 'We': [85], 'apply': [86], 'this': [87], 'new': [88, 109], 'variational': [89, 142], 'based': [91], 'technique': [93], 'LSTM': [95], 'GRU': [97], 'models,': [98], 'assessing': [99], 'it': [100], 'on': [101, 122], 'language': [102, 128], 'sentiment': [105], 'analysis': [106], 'tasks.': [107], 'The': [108], 'approach': [110], 'outperforms': [111], 'existing': [112], 'techniques,': [113], 'best': [117], 'our': [119, 139], 'knowledge': [120], 'improves': [121], 'single': [124], 'model': [125], 'state-of-the-art': [126], 'Penn': [132], 'Treebank': [133], '(73.4': [134], 'test': [135], 'perplexity).': [136], 'extends': [138], 'arsenal': [140], 'tools': [143]}",2016,"['Dropout (neural networks)', 'Perplexity', 'Computer science', 'Artificial intelligence', 'Overfitting', 'Machine learning', 'Deep learning', 'Inference', 'Language model', 'Recurrent neural network', 'Bayesian inference', 'Artificial neural network', 'Bayesian probability']","Recurrent neural networks (RNNs) stand at the forefront of many recent developments in deep learning. Yet a major difficulty with these models is their tendency to overfit, with dropout shown to fail when applied to recurrent layers. Recent results at the intersection of Bayesian modelling and deep learning offer a Bayesian interpretation of common deep learning techniques such as dropout. This grounding of dropout in approximate Bayesian inference suggests an extension of the theoretical results, offering insights into the use of dropout with RNN models. We apply this new variational inference based dropout technique in LSTM and GRU models, assessing it on language modelling and sentiment analysis tasks. The new approach outperforms existing techniques, and to the best of our knowledge improves on the single model state-of-the-art in language modelling with the Penn Treebank (73.4 test perplexity). This extends our arsenal of variational tools in deep learning."
https://openalex.org/W2962843949,Interpretation of Neural Networks Is Fragile,"{'In': [0, 89, 142], 'order': [1], 'for': [2, 46], 'machine': [3, 22], 'learning': [4, 23], 'to': [5, 14, 17, 39, 61, 63, 75, 95, 153, 165, 178, 199], 'be': [6, 15, 69, 81], 'trusted': [7], 'in': [8], 'many': [9], 'applications,': [10], 'it': [11, 58], 'is': [12, 59, 195], 'critical': [13], 'able': [16], 'reliably': [18], 'explain': [19], 'why': [20, 193], 'the': [21, 67, 76, 107, 119, 159, 184, 187], 'algorithm': [24], 'makes': [25], 'certain': [26], 'predictions.': [27], 'For': [28, 51], 'this': [29, 90], 'reason,': [30], 'a': [31, 196], 'variety': [32], 'of': [33, 121, 183, 186], 'methods': [34, 130], 'have': [35, 112], 'been': [36], 'developed': [37], 'recently': [38], 'interpret': [40], 'neural': [41], 'network': [42], 'predictions': [43], 'by': [44, 71, 83, 86, 124], 'providing,': [45], 'example,': [47], 'feature': [48, 127], 'importance': [49, 128, 132], 'maps.': [50], 'both': [52], 'scientific': [53], 'robustness': [54, 120, 194], 'and': [55, 136, 140], 'security': [56], 'reasons,': [57], 'important': [60], 'know': [62], 'what': [64], 'extent': [65], 'can': [66, 151], 'interpretations': [68, 122, 156, 168], 'altered': [70], 'small': [72], 'systematic': [73, 149], 'perturbations': [74, 98, 150], 'input': [77], 'data,': [78], 'which': [79], 'might': [80], 'generated': [82, 123], 'adversaries': [84], 'or': [85], 'measurement': [87], 'biases.': [88], 'paper,': [91], 'we': [92], 'demonstrate': [93], 'how': [94], 'generate': [96], 'adversarial': [97, 179], 'that': [99, 104, 148, 167], 'produce': [100], 'perceptively': [101], 'indistinguishable': [102], 'inputs': [103], 'are': [105, 175], 'assigned': [106], 'same': [108], 'predicted': [109], 'label,': [110], 'yet': [111], 'very': [113], 'different': [114, 155], 'interpretations.': [115], 'We': [116, 161], 'systematically': [117], 'characterize': [118], 'several': [125], 'widely-used': [126], 'interpretation': [129, 201], '(feature': [131], 'maps,': [133], 'integrated': [134], 'gradients,': [135], 'DeepLIFT)': [137], 'on': [138, 170, 192], 'ImageNet': [139], 'CIFAR-10.': [141], 'all': [143], 'cases,': [144], 'our': [145], 'experiments': [146], 'show': [147, 166], 'lead': [152], 'dramatically': [154], 'without': [157], 'changing': [158], 'label.': [160], 'extend': [162], 'these': [163], 'results': [164], 'based': [169], 'exemplars': [171], '(e.g.': [172], 'influence': [173], 'functions)': [174], 'similarly': [176], 'susceptible': [177], 'attack.': [180], 'Our': [181], 'analysis': [182], 'geometry': [185], 'Hessian': [188], 'matrix': [189], 'gives': [190], 'insight': [191], 'general': [197], 'challenge': [198], 'current': [200], 'approaches.': [202]}",2019,"['Robustness (evolution)', 'Computer science', 'Artificial intelligence', 'Adversarial system', 'Hessian matrix', 'Machine learning', 'Artificial neural network', 'Interpretation (philosophy)', 'Deep neural networks', 'Feature (linguistics)', 'Pattern recognition (psychology)', 'Mathematics', 'Biochemistry', 'Philosophy', 'Applied mathematics', 'Gene', 'Chemistry', 'Programming language', 'Linguistics']","In order for machine learning to be trusted in many applications, it is critical to be able to reliably explain why the machine learning algorithm makes certain predictions. For this reason, a variety of methods have been developed recently to interpret neural network predictions by providing, for example, feature importance maps. For both scientific robustness and security reasons, it is important to know to what extent can the interpretations be altered by small systematic perturbations to the input data, which might be generated by adversaries or by measurement biases. In this paper, we demonstrate how to generate adversarial perturbations that produce perceptively indistinguishable inputs that are assigned the same predicted label, yet have very different interpretations. We systematically characterize the robustness of interpretations generated by several widely-used feature importance interpretation methods (feature importance maps, integrated gradients, and DeepLIFT) on ImageNet and CIFAR-10. In all cases, our experiments show that systematic perturbations can lead to dramatically different interpretations without changing the label. We extend these results to show that interpretations based on exemplars (e.g. influence functions) are similarly susceptible to adversarial attack. Our analysis of the geometry of the Hessian matrix gives insight on why robustness is a general challenge to current interpretation approaches."
https://openalex.org/W2579495707,Learning Traffic as Images: A Deep Convolutional Neural Network for Large-Scale Transportation Network Speed Prediction,"{'This': [0], 'paper': [1], 'proposes': [2], 'a': [3, 21, 41, 155], 'convolutional': [4], 'neural': [5, 106, 120], 'network': [6, 86], '(CNN)-based': [7], 'method': [8, 70, 94, 132], 'that': [9, 129], 'learns': [10], 'traffic': [11, 18, 25, 38, 57, 62], 'as': [12, 89], 'images': [13, 30], 'and': [14, 34, 60, 83, 91, 108, 111, 122], 'predicts': [15], 'large-scale,': [16], 'network-wide': [17, 61], 'speed': [19, 63], 'with': [20, 95], 'high': [22], 'accuracy.': [23], 'Spatiotemporal': [24], 'dynamics': [26], 'are': [27], 'converted': [28], 'to': [29, 49], 'describing': [31], 'the': [32, 50, 68, 79, 93, 130, 152], 'time': [33, 157], 'space': [35], 'relations': [36], 'of': [37, 67, 141], 'flow': [39], 'via': [40], 'two-dimensional': [42], 'time-space': [43], 'matrix.': [44], 'A': [45], 'CNN': [46, 149], 'is': [47, 71, 160], 'applied': [48], 'image': [51], 'following': [52], 'two': [53, 75], 'consecutive': [54], 'steps:': [55], 'abstract': [56], 'feature': [58], 'extraction': [59], 'prediction.': [64], 'The': [65, 126, 148], 'effectiveness': [66], 'proposed': [69, 131], 'evaluated': [72], 'by': [73, 136], 'taking': [74], 'real-world': [76], 'transportation': [77, 85, 164], 'networks,': [78], 'second': [80], 'ring': [81], 'road': [82], 'north-east': [84], 'in': [87, 154], 'Beijing,': [88], 'examples,': [90], 'comparing': [92], 'four': [96], 'prevailing': [97], 'algorithms,': [98], 'namely,': [99, 116], 'ordinary': [100], 'least': [101], 'squares,': [102], 'k-nearest': [103], 'neighbors,': [104], 'artificial': [105], 'network,': [107, 121], 'random': [109], 'forest,': [110], 'three': [112], 'deep': [113], 'learning': [114], 'architectures,': [115], 'stacked': [117], 'autoencoder,': [118], 'recurrent': [119], 'long-short-term': [123], 'memory': [124], 'network.': [125], 'results': [127], 'show': [128], 'outperforms': [133], 'other': [134], 'algorithms': [135], 'an': [137, 144], 'average': [138], 'accuracy': [139], 'improvement': [140], '42.91%': [142], 'within': [143], 'acceptable': [145], 'execution': [146], 'time.': [147], 'can': [150], 'train': [151], 'model': [153], 'reasonable': [156], 'and,': [158], 'thus,': [159], 'suitable': [161], 'for': [162], 'large-scale': [163], 'networks.': [165]}",2017,"['Autoencoder', 'Convolutional neural network', 'Computer science', 'Artificial intelligence', 'Deep learning', 'Traffic flow (computer networking)', 'Artificial neural network', 'Floating car data', 'Traffic classification', 'Traffic generation model', 'Intelligent transportation system', 'Data mining', 'Pattern recognition (psychology)', 'Real-time computing', 'Traffic congestion', 'Engineering', 'Network packet', 'Computer network', 'Transport engineering', 'Civil engineering']","This paper proposes a convolutional neural network (CNN)-based method that learns traffic as images and predicts large-scale, network-wide traffic speed with a high accuracy. Spatiotemporal traffic dynamics are converted to images describing the time and space relations of traffic flow via a two-dimensional time-space matrix. A CNN is applied to the image following two consecutive steps: abstract traffic feature extraction and network-wide traffic speed prediction. The effectiveness of the proposed method is evaluated by taking two real-world transportation networks, the second ring road and north-east transportation network in Beijing, as examples, and comparing the method with four prevailing algorithms, namely, ordinary least squares, k-nearest neighbors, artificial neural network, and random forest, and three deep learning architectures, namely, stacked autoencoder, recurrent neural network, and long-short-term memory network. The results show that the proposed method outperforms other algorithms by an average accuracy improvement of 42.91% within an acceptable execution time. The CNN can train the model in a reasonable time and, thus, is suitable for large-scale transportation networks."
https://openalex.org/W1999183681,Neural networks,"{'article': [0], 'Free': [1], 'Access': [2], 'Share': [3], 'on': [4, 108], 'Neural': [5], 'networks:': [6], 'applications': [7], 'in': [8, 118], 'industry,': [9], 'business': [10], 'and': [11, 85], 'science': [12], 'Authors:': [13], 'Bernard': [14], 'Widrow': [15], 'Stanford': [16, 20, 29, 33, 42, 46], 'Univ.,': [17, 21, 30, 34, 43, 47], 'Stanford,': [18, 22, 31, 35, 44, 48], 'CA': [19, 32, 45], 'CAView': [23, 36, 49], 'Profile': [24, 37, 50], ',': [25, 38], 'David': [26], 'E.': [27], 'Rumelhart': [28], 'Michael': [39], 'A.': [40], 'Lehr': [41], 'Authors': [51], 'Info': [52], '&': [53], 'Claims': [54], 'Communications': [55], 'of': [56], 'the': [57, 109], 'ACMVolume': [58], '37Issue': [59], '3March': [60], '1994': [61], 'pp': [62], '93–105https://doi.org/10.1145/175247.175257Published:01': [63], 'March': [64], '1994Publication': [65], 'History': [66], '328citation4,083DownloadsMetricsTotal': [67], 'Citations328Total': [68], 'Downloads4,083Last': [69], '12': [70], 'Months53Last': [71], '6': [72], 'weeks8': [73], 'Get': [74], 'Citation': [75, 77, 115], 'AlertsNew': [76], 'Alert': [78], 'added!This': [79], 'alert': [80, 105], 'has': [81, 100], 'been': [82, 101], 'successfully': [83], 'added': [84], 'will': [86, 90], 'be': [87, 91], 'sent': [88], 'to:You': [89], 'notified': [92], 'whenever': [93], 'a': [94, 127], 'record': [95], 'that': [96], 'you': [97], 'have': [98], 'chosen': [99], 'cited.To': [102], 'manage': [103], 'your': [104, 120], 'preferences,': [106], 'click': [107], 'button': [110], 'below.Manage': [111], 'my': [112], 'Alerts': [113], 'New': [114, 128], 'Alert!Please': [116], 'log': [117], 'to': [119, 123, 125], 'account': [121], 'Save': [122], 'BinderSave': [124], 'BinderCreate': [126], 'BinderNameCancelCreateExport': [129], 'CitationPublisher': [130], 'SiteeReaderPDF': [131]}",1994,"['Citation', 'Computer science', 'Library science', 'Artificial neural network', 'Operations research', 'Artificial intelligence', 'Engineering']","article Free Access Share on Neural networks: applications in industry, business and science Authors: Bernard Widrow Stanford Univ., Stanford, CA Stanford Univ., Stanford, CAView Profile , David E. Rumelhart Stanford Univ., Stanford, CA Stanford Univ., Stanford, CAView Profile , Michael A. Lehr Stanford Univ., Stanford, CA Stanford Univ., Stanford, CAView Profile Authors Info & Claims Communications of the ACMVolume 37Issue 3March 1994 pp 93–105https://doi.org/10.1145/175247.175257Published:01 March 1994Publication History 328citation4,083DownloadsMetricsTotal Citations328Total Downloads4,083Last 12 Months53Last 6 weeks8 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF"
https://openalex.org/W2140609507,DeepID3: Face Recognition with Very Deep Neural Networks,"{'The': [0], 'state-of-the-art': [1], 'of': [2, 12, 28, 102, 124], 'face': [3, 41, 57, 81, 84, 110, 117, 126], 'recognition': [4, 26], 'has': [5], 'been': [6], 'significantly': [7], 'advanced': [8], 'by': [9], 'the': [10, 103, 132], 'emergence': [11], 'deep': [13, 16, 48], 'learning.': [14], 'Very': [15], 'neural': [17, 49], 'networks': [18], 'recently': [19], 'achieved': [20], 'great': [21], 'success': [22], 'on': [23, 40], 'general': [24], 'object': [25], 'because': [27], 'their': [29, 38], 'superb': [30], 'learning': [31], 'capacity.': [32], 'This': [33, 43], 'motivates': [34], 'us': [35], 'to': [36, 53, 76, 80, 90], 'investigate': [37], 'effectiveness': [39], 'recognition.': [42, 58, 82], 'paper': [44], 'proposes': [45], 'two': [46, 60, 105], 'very': [47], 'network': [50], 'architectures,': [51], 'referred': [52], 'as': [54], 'DeepID3,': [55], 'for': [56], 'These': [59], 'architectures': [61, 106], 'are': [62, 88], 'rebuilt': [63], 'from': [64], 'stacked': [65], 'convolution': [66], 'and': [67, 74, 93, 113], 'inception': [68], 'layers': [69, 97], 'proposed': [70, 104], 'in': [71, 131], 'VGG': [72], 'net': [73], 'GoogLeNet': [75], 'make': [77], 'them': [78], 'suitable': [79], 'Joint': [83], 'identification-verification': [85], 'supervisory': [86], 'signals': [87], 'added': [89], 'both': [91], 'intermediate': [92], 'final': [94], 'feature': [95], 'extraction': [96], 'during': [98], 'training.': [99], 'An': [100], 'ensemble': [101], 'achieves': [107], '99.53%': [108], 'LFW': [109, 115, 125], 'verification': [111, 127], 'accuracy': [112], '96.0%': [114], 'rank-1': [116], 'identification': [118], 'accuracy,': [119], 'respectively.': [120], 'A': [121], 'further': [122], 'discussion': [123], 'result': [128], 'is': [129], 'given': [130], 'end.': [133]}",2015,"['Artificial intelligence', 'Face (sociological concept)', 'Computer science', 'Facial recognition system', 'Deep learning', 'Convolution (computer science)', 'Convolutional neural network', 'Pattern recognition (psychology)', 'Identification (biology)', 'Artificial neural network', 'Feature extraction', 'Feature (linguistics)', 'Three-dimensional face recognition', 'Face detection', 'Sociology', 'Social science', 'Philosophy', 'Biology', 'Linguistics', 'Botany']","The state-of-the-art of face recognition has been significantly advanced by the emergence of deep learning. Very deep neural networks recently achieved great success on general object recognition because of their superb learning capacity. This motivates us to investigate their effectiveness on face recognition. This paper proposes two very deep neural network architectures, referred to as DeepID3, for face recognition. These two architectures are rebuilt from stacked convolution and inception layers proposed in VGG net and GoogLeNet to make them suitable to face recognition. Joint face identification-verification supervisory signals are added to both intermediate and final feature extraction layers during training. An ensemble of the proposed two architectures achieves 99.53% LFW face verification accuracy and 96.0% LFW rank-1 face identification accuracy, respectively. A further discussion of LFW face verification result is given in the end."
https://openalex.org/W3137147200,A Survey of Quantization Methods for Efficient Neural Network Inference,"{'As': [0], 'soon': [1], 'as': [2, 174], 'abstract': [3], 'mathematical': [4], 'computations': [5, 27, 188], 'were': [6], 'adapted': [7], 'to': [8, 30, 60, 69, 96, 103, 123, 137, 155, 198, 224, 240, 246], 'computation': [9], 'on': [10], 'digital': [11], 'computers,': [12], 'the': [13, 22, 31, 37, 62, 71, 74, 97, 104, 135, 139, 184, 199, 203, 212, 231, 248], 'problem': [14, 32, 38, 78, 200], 'of': [15, 21, 33, 39, 47, 58, 64, 73, 79, 107, 147, 153, 181, 187, 201, 214, 230, 250], 'efficient': [16, 185], 'representation,': [17], 'manipulation,': [18], 'and': [19, 67, 92, 117, 142, 177, 219, 239], 'communication': [20], 'numerical': [23, 34, 204], 'values': [24, 127, 205], 'in': [25, 41, 99, 111, 129, 150, 160, 162, 183, 206, 234, 253], 'those': [26], 'arose.Strongly': [28], 'related': [29, 118], 'representation': [35], 'is': [36, 81, 166], 'quantization:': [40], 'what': [42], 'manner': [43], 'should': [44], 'a': [45, 54, 145, 227], 'set': [46, 57], 'continuous': [48], 'real-valued': [49], 'numbers': [50, 59], 'be': [51], 'distributed': [52], 'over': [53], 'fixed': [55, 125], 'discrete': [56], 'minimize': [61], 'number': [63], 'bits': [65, 131], 'required': [66], 'also': [68], 'maximize': [70], 'accuracy': [72], 'attendant': [75], 'computations?This': [76], 'perennial': [77], 'quantization': [80, 170, 235], 'particularly': [82], 'relevant': [83], 'whenever': [84], 'memory': [85, 140], 'and/or': [86], 'computational': [87], 'resources': [88], 'are': [89, 157], 'severely': [90], 'restricted,': [91], 'it': [93, 165], 'has': [94, 171], 'come': [95], 'forefront': [98], 'recent': [100], 'years': [101], 'due': [102], 'remarkable': [105], 'performance': [106], 'Neural': [108, 191, 208, 237], 'Network': [109, 209], 'models': [110], 'computer': [112], 'vision,': [113], 'natural': [114], 'language': [115], 'processing,': [116], 'areas.Moving': [119], 'from': [120], 'floating-point': [121], 'representations': [122], 'low-precision': [124], 'integer': [126], 'represented': [128], 'four': [130], 'or': [132], 'less': [133], 'holds': [134], 'potential': [136], 'reduce': [138], 'footprint': [141], 'latency': [143], 'by': [144], 'factor': [146], '16x;': [148], 'and,': [149], 'fact,': [151], 'reductions': [152], '4x': [154], '8x': [156], 'often': [158], 'realized': [159], 'practice': [161], 'these': [163], 'applications.Thus,': [164], 'not': [167], 'surprising': [168], 'that': [169], 'emerged': [172], 'recently': [173], 'an': [175, 243], 'important': [176], 'very': [178], 'active': [179], 'sub-area': [180], 'research': [182, 233, 252], 'implementation': [186], 'associated': [189], 'with': [190], 'Networks.In': [192], 'this': [193, 217, 254], 'article,': [194], 'we': [195, 222], 'survey': [196, 218], 'approaches': [197], 'quantizing': [202], 'deep': [207], 'computations,': [210], 'covering': [211], 'advantages/disadvantages': [213], 'current': [215, 232], 'methods.With': [216], 'its': [220], 'organization,': [221], 'hope': [223], 'have': [225, 241], 'presented': [226], 'useful': [228], 'snapshot': [229], 'for': [236], 'Networks': [238], 'given': [242], 'intelligent': [244], 'organization': [245], 'ease': [247], 'evaluation': [249], 'future': [251], 'area.': [255]}",2022,"['Artificial neural network', 'Inference', 'Computer science', 'Quantization (signal processing)', 'Artificial intelligence', 'Algorithm']","As soon as abstract mathematical computations were adapted to computation on digital computers, the problem of efficient representation, manipulation, and communication of the numerical values in those computations arose.Strongly related to the problem of numerical representation is the problem of quantization: in what manner should a set of continuous real-valued numbers be distributed over a fixed discrete set of numbers to minimize the number of bits required and also to maximize the accuracy of the attendant computations?This perennial problem of quantization is particularly relevant whenever memory and/or computational resources are severely restricted, and it has come to the forefront in recent years due to the remarkable performance of Neural Network models in computer vision, natural language processing, and related areas.Moving from floating-point representations to low-precision fixed integer values represented in four bits or less holds the potential to reduce the memory footprint and latency by a factor of 16x; and, in fact, reductions of 4x to 8x are often realized in practice in these applications.Thus, it is not surprising that quantization has emerged recently as an important and very active sub-area of research in the efficient implementation of computations associated with Neural Networks.In this article, we survey approaches to the problem of quantizing the numerical values in deep Neural Network computations, covering the advantages/disadvantages of current methods.With this survey and its organization, we hope to have presented a useful snapshot of the current research in quantization for Neural Networks and to have given an intelligent organization to ease the evaluation of future research in this area."
https://openalex.org/W2592340788,Deep Forest: Towards An Alternative to Deep Neural Networks,"{'In': [0, 25], 'this': [1], 'paper,': [2], 'we': [3], 'propose': [4], 'gcForest,': [5], 'a': [6, 20], 'decision': [7], 'tree': [8], 'ensemble': [9], 'approach': [10], 'with': [11], 'performance': [12, 59], 'highly': [13], 'competitive': [14], 'to': [15, 27, 42, 49, 83, 98, 104], 'deep': [16, 28, 105], 'neural': [17, 29, 106], 'networks': [18, 30, 107], 'in': [19, 35, 55, 102], 'broad': [21], 'range': [22], 'of': [23, 67, 72], 'tasks.': [24], 'contrast': [26, 103], 'which': [31, 108], 'require': [32, 109], 'great': [33], 'effort': [34], 'hyper-parameter': [36], 'tuning,': [37], 'gcForest': [38, 73, 94, 113], 'is': [39, 47, 74, 95], 'much': [40], 'easier': [41], 'train;': [43], 'even': [44, 117], 'when': [45, 118], 'it': [46], 'applied': [48], 'different': [50, 53], 'data': [51], 'across': [52], 'domains': [54], 'our': [56], 'experiments,': [57], 'excellent': [58], 'can': [60, 78, 114], 'be': [61, 90], 'achieved': [62], 'by': [63], 'almost': [64], 'same': [65], 'settings': [66], 'hyper-parameters.': [68], 'The': [69, 87], 'training': [70, 80, 111, 123], 'process': [71], 'efficient,': [75], 'and': [76], 'users': [77], 'control': [79], 'cost': [81], 'according': [82], 'computational': [84], 'resource': [85], 'available.': [86], 'efficiency': [88], 'may': [89], 'further': [91], 'enhanced': [92], 'because': [93], 'naturally': [96], 'apt': [97], 'parallel': [99], 'implementation.': [100], 'Furthermore,': [101], 'large-scale': [110], 'data,': [112], 'work': [115], 'well': [116], 'there': [119], 'are': [120], 'only': [121], 'small-scale': [122], 'data.': [124]}",2017,"['Computer science', 'Artificial intelligence', 'Deep neural networks', 'Deep learning', 'Artificial neural network', 'Machine learning', 'Process (computing)', 'Contrast (vision)', 'Decision tree', 'Scale (ratio)', 'Range (aeronautics)', 'Training set', 'Training (meteorology)', 'Engineering', 'Aerospace engineering', 'Physics', 'Quantum mechanics', 'Operating system', 'Meteorology']","In this paper, we propose gcForest, a decision tree ensemble approach with performance highly competitive to deep neural networks in a broad range of tasks. In contrast to deep neural networks which require great effort in hyper-parameter tuning, gcForest is much easier to train; even when it is applied to different data across different domains in our experiments, excellent performance can be achieved by almost same settings of hyper-parameters. The training process of gcForest is efficient, and users can control training cost according to computational resource available. The efficiency may be further enhanced because gcForest is naturally apt to parallel implementation. Furthermore, in contrast to deep neural networks which require large-scale training data, gcForest can work well even when there are only small-scale training data."
https://openalex.org/W2170738476,Convolutional Neural Network Architectures for Matching Natural Language Sentences,"{'Semantic': [0], 'matching': [1, 14, 44, 79, 101, 117, 130], 'is': [2], 'of': [3, 23, 66, 103, 116, 122, 129], 'central': [4], 'importance': [5], 'to': [6, 17, 100, 135], 'many': [7], 'natural': [8], 'language': [9, 24], 'tasks': [10, 102, 118, 131], '\\cite{bordes2014semantic,RetrievalQA}.': [11], 'A': [12], 'successful': [13], 'algorithm': [15], 'needs': [16], 'adequately': [18], 'model': [19, 125], 'the': [20, 27, 49, 63, 77, 120, 123], 'internal': [21], 'structures': [22, 65], 'objects': [25], 'and': [26, 54, 72, 95, 106, 132], 'interaction': [28], 'between': [29], 'them.': [30], 'As': [31], 'a': [32, 114, 127], 'step': [33], 'toward': [34], 'this': [35], 'goal,': [36], 'we': [37], 'propose': [38], 'convolutional': [39, 50], 'neural': [40], 'network': [41], 'models': [42, 58, 85], 'for': [43], 'two': [45], 'sentences,': [46], 'by': [47], 'adapting': [48], 'strategy': [51], 'in': [52, 107], 'vision': [53], 'speech.': [55], 'The': [56, 110], 'proposed': [57, 124], 'not': [59], 'only': [60], 'nicely': [61], 'represent': [62], 'hierarchical': [64], 'sentences': [67], 'with': [68], 'their': [69], 'layer-by-layer': [70], 'composition': [71], 'pooling,': [73], 'but': [74], 'also': [75], 'capture': [76], 'rich': [78], 'patterns': [80], 'at': [81], 'different': [82, 104, 108], 'levels.': [83], 'Our': [84], 'are': [86], 'rather': [87], 'generic,': [88], 'requiring': [89], 'no': [90], 'prior': [91], 'knowledge': [92], 'on': [93, 113, 126], 'language,': [94], 'can': [96], 'hence': [97], 'be': [98], 'applied': [99], 'nature': [105], 'languages.': [109], 'empirical': [111], 'study': [112], 'variety': [115, 128], 'demonstrates': [119], 'efficacy': [121], 'its': [133], 'superiority': [134], 'competitor': [136], 'models.': [137]}",2015,"['Computer science', 'Matching (statistics)', 'Variety (cybernetics)', 'Pooling', 'Artificial intelligence', 'Convolutional neural network', 'Natural language processing', 'Layer (electronics)', 'Semantic matching', 'Natural language', 'Organic chemistry', 'Mathematics', 'Chemistry', 'Statistics']","Semantic matching is of central importance to many natural language tasks \cite{bordes2014semantic,RetrievalQA}. A successful matching algorithm needs to adequately model the internal structures of language objects and the interaction between them. As a step toward this goal, we propose convolutional neural network models for matching two sentences, by adapting the convolutional strategy in vision and speech. The proposed models not only nicely represent the hierarchical structures of sentences with their layer-by-layer composition and pooling, but also capture the rich matching patterns at different levels. Our models are rather generic, requiring no prior knowledge on language, and can hence be applied to matching tasks of different nature and in different languages. The empirical study on a variety of matching tasks demonstrates the efficacy of the proposed model on a variety of matching tasks and its superiority to competitor models."
https://openalex.org/W2538244214,Convolutional Neural Networks for Large-Scale Remote-Sensing Image Classification,"{'International': [0], 'audience': [1]}",2016,"['Computer science', 'Convolutional neural network', 'Pattern recognition (psychology)', 'Artificial intelligence', 'Context (archaeology)', 'Contextual image classification', 'Scale (ratio)', 'Relevance (law)', 'Image (mathematics)', 'Cartography', 'Geography', 'Law', 'Archaeology', 'Political science']",International audience
https://openalex.org/W2766839578,A Survey of Model Compression and Acceleration for Deep Neural Networks,"{'Deep': [0], 'neural': [1, 17], 'networks': [2, 55, 155], '(DNNs)': [3], 'have': [4], 'recently': [5], 'achieved': [6], 'great': [7], 'success': [8], 'in': [9, 29, 36, 53, 72], 'many': [10], 'visual': [11], 'recognition': [12], 'tasks.': [13], 'However,': [14], 'existing': [15], 'deep': [16, 54], 'network': [18], 'models': [19], 'are': [20, 93, 116, 124], 'computationally': [21], 'expensive': [22], 'and': [23, 51, 85, 100, 107, 114, 140, 156, 176, 189], 'memory': [24, 33], 'intensive,': [25], 'hindering': [26], 'their': [27], 'deployment': [28], 'devices': [30], 'with': [31, 38], 'low': [32], 'resources': [34], 'or': [35], 'applications': [37], 'strict': [39], 'latency': [40], 'requirements.': [41], 'Therefore,': [42], 'a': [43], 'natural': [44], 'thought': [45], 'is': [46], 'to': [47], 'perform': [48], 'model': [49, 60, 174], 'compression': [50], 'acceleration': [52], 'without': [56], 'significantly': [57], 'decreasing': [58], 'the': [59, 63, 80, 121, 135, 164, 167, 173, 187], 'performance.': [61], 'During': [62], 'past': [64], 'five': [65], 'years,': [66], 'tremendous': [67], 'progress': [68], 'has': [69], 'been': [70], 'made': [71], 'this': [73, 76, 183], 'area.': [74], 'In': [75, 89], 'paper,': [77, 184], 'we': [78, 129, 143, 162, 181], 'review': [79], 'recent': [81, 148, 177], 'techniques': [82, 92, 123], 'for': [83, 151, 171, 192], 'compacting': [84], 'accelerating': [86], 'DNN': [87], 'models.': [88], 'general,': [90], 'these': [91], 'divided': [94], 'into': [95], 'four': [96], 'categories:': [97], 'parameter': [98, 112], 'pruning': [99, 113], 'quantization,': [101], 'low-rank': [102], 'factorization,': [103], 'transferred/compact': [104], 'convolutional': [105], 'filters,': [106], 'knowledge': [108], 'distillation.': [109], 'Methods': [110], 'of': [111], 'quantization': [115], 'described': [117], 'first,': [118], 'after': [119], 'that': [120], 'other': [122], 'introduced.': [125], 'For': [126], 'each': [127], 'category,': [128], 'also': [130], 'provide': [131], 'insightful': [132], 'analysis': [133], 'about': [134], 'performance,': [136, 175], 'related': [137], 'applications,': [138], 'advantages,': [139], 'drawbacks.': [141], 'Then': [142], 'go': [144], 'through': [145], 'some': [146], 'very': [147], 'successful': [149], 'methods,': [150], 'example,': [152], 'dynamic': [153], 'capacity': [154], 'stochastic': [157], 'depths': [158], 'networks.': [159], 'After': [160], 'that,': [161], 'survey': [163], 'evaluation': [165], 'matrices,': [166], 'main': [168], 'datasets': [169], 'used': [170], 'evaluating': [172], 'benchmark': [178], 'efforts.': [179], 'Finally,': [180], 'conclude': [182], 'discuss': [185], 'remaining': [186], 'challenges': [188], 'possible': [190], 'directions': [191], 'future': [193], 'work.': [194]}",2017,"['Acceleration', 'Artificial neural network', 'Compression (physics)', 'Computer science', 'Deep neural networks', 'Artificial intelligence', 'Physics', 'Thermodynamics', 'Classical mechanics']","Deep neural networks (DNNs) have recently achieved great success in many visual recognition tasks. However, existing deep neural network models are computationally expensive and memory intensive, hindering their deployment in devices with low memory resources or in applications with strict latency requirements. Therefore, a natural thought is to perform model compression and acceleration in deep networks without significantly decreasing the model performance. During the past five years, tremendous progress has been made in this area. In this paper, we review the recent techniques for compacting and accelerating DNN models. In general, these techniques are divided into four categories: parameter pruning and quantization, low-rank factorization, transferred/compact convolutional filters, and knowledge distillation. Methods of parameter pruning and quantization are described first, after that the other techniques are introduced. For each category, we also provide insightful analysis about the performance, related applications, advantages, and drawbacks. Then we go through some very recent successful methods, for example, dynamic capacity networks and stochastic depths networks. After that, we survey the evaluation matrices, the main datasets used for evaluating the model performance, and recent benchmark efforts. Finally, we conclude this paper, discuss remaining the challenges and possible directions for future work."
https://openalex.org/W2071928207,Neural Networks in Human Epilepsy: Evidence of and Implications for Treatment,"{'A': [0, 295, 2869], 'considerable': [1], 'amount': [2, 2378], 'of': [3, 17, 28, 41, 47, 57, 93, 126, 135, 155, 180, 195, 255, 261, 279, 293, 336, 345, 398, 407, 419, 452, 534, 595, 603, 609, 624, 636, 652, 662, 678, 688, 727, 739, 746, 751, 759, 767, 801, 831, 860, 944, 953, 960, 971, 1002, 1010, 1016, 1109, 1128, 1223, 1239, 1266, 1280, 1286, 1365, 1411, 1477, 1654, 1658, 1662, 1721, 1770, 1792, 1812, 1847, 1897, 1914, 1940, 1971, 1981, 1989, 2025, 2039, 2043, 2048, 2060, 2090, 2101, 2123, 2189, 2200, 2225, 2310, 2318, 2322, 2335, 2379, 2459, 2475, 2483, 2486, 2496, 2591, 2612, 2622, 2628, 2632, 2635, 2637, 2653, 2687, 2691, 2718, 2767, 2799, 2833, 2842, 2845, 2861, 2944, 2972, 2993, 3003, 3009, 3026, 3034, 3056, 3077, 3089, 3097, 3100, 3114, 3121, 3180, 3184, 3189, 3195, 3214, 3231, 3236, 3239, 3251, 3277, 3284, 3313, 3338, 3374, 3377, 3385, 3431, 3446, 3458, 3472, 3492, 3501, 3513, 3544, 3556, 3559, 3580, 3587, 3609, 3618, 3621, 3626, 3632, 3639, 3655, 3669, 3680, 3688, 3707, 3723, 3737, 3749, 3793, 3796, 3826, 3839, 3857, 3866, 3882], 'compelling': [4, 106], 'evidence': [5, 110, 464, 572, 596, 2069, 2393, 3004], 'exists,': [6], 'predominantly': [7], 'from': [8, 63, 242, 392, 660, 712, 749, 872, 901, 909, 1098, 1136, 1305, 1468, 1800, 1874, 1916, 2052, 2242, 2732, 2876, 3063, 3326, 3880], 'animal': [9], 'models': [10, 65], 'and': [11, 20, 26, 30, 51, 129, 149, 157, 161, 207, 219, 285, 309, 328, 339, 343, 450, 461, 496, 517, 519, 531, 538, 561, 588, 601, 621, 656, 680, 708, 776, 828, 839, 884, 890, 936, 946, 998, 1019, 1039, 1131, 1149, 1199, 1227, 1232, 1369, 1441, 1481, 1502, 1513, 1519, 1536, 1553, 1617, 1685, 1699, 1702, 1714, 1757, 1883, 1887, 1894, 1901, 1920, 1952, 1979, 2004, 2075, 2145, 2158, 2169, 2303, 2320, 2351, 2359, 2386, 2404, 2406, 2488, 2509, 2512, 2517, 2525, 2540, 2569, 2703, 2736, 2761, 2817, 2830, 2880, 2914, 2918, 2934, 2941, 2967, 2977, 3013, 3023, 3040, 3282, 3286, 3295, 3394, 3508, 3603, 3606, 3646, 3666, 3693, 3741, 3791, 3829, 3886, 3896, 3902], 'experimental': [12, 64], 'paradigms,': [13], 'for': [14, 216, 435, 465, 570, 1844, 2237, 2279, 2888, 3267, 3352, 3746, 3835], 'the': [15, 24, 39, 61, 71, 89, 109, 132, 174, 184, 196, 205, 209, 217, 234, 253, 262, 267, 276, 280, 290, 299, 302, 313, 334, 337, 341, 346, 369, 386, 399, 420, 432, 463, 477, 486, 490, 497, 503, 506, 521, 523, 525, 535, 539, 556, 562, 585, 589, 599, 607, 622, 633, 637, 641, 645, 650, 653, 683, 706, 740, 768, 773, 777, 813, 855, 858, 861, 868, 873, 898, 902, 906, 910, 917, 924, 933, 939, 950, 954, 961, 966, 972, 982, 989, 995, 1000, 1008, 1011, 1030, 1058, 1067, 1110, 1118, 1240, 1276, 1293, 1325, 1329, 1335, 1379, 1446, 1456, 1473, 1478, 1532, 1537, 1550, 1561, 1565, 1580, 1595, 1601, 1604, 1613, 1626, 1635, 1655, 1663, 1696, 1711, 1719, 1738, 1747, 1755, 1765, 1776, 1790, 1793, 1801, 1830, 1833, 1837, 1845, 1848, 1857, 1895, 1921, 1927, 1972, 1977, 1982, 2010, 2026, 2040, 2053, 2058, 2088, 2091, 2098, 2108, 2149, 2155, 2164, 2177, 2184, 2193, 2208, 2212, 2216, 2223, 2226, 2243, 2270, 2289, 2294, 2299, 2311, 2323, 2333, 2336, 2377, 2392, 2447, 2484, 2553, 2566, 2578, 2589, 2620, 2626, 2633, 2638, 2644, 2670, 2679, 2689, 2692, 2697, 2738, 2751, 2786, 2790, 2795, 2815, 2843, 2849, 2877, 2910, 2953, 2986, 3007, 3032, 3057, 3064, 3078, 3085, 3095, 3171, 3178, 3181, 3190, 3206, 3237, 3249, 3252, 3307, 3311, 3317, 3336, 3386, 3411, 3429, 3444, 3450, 3473, 3480, 3490, 3498, 3522, 3542, 3567, 3577, 3619, 3624, 3627, 3637, 3653, 3656, 3659, 3708, 3735, 3747, 3756, 3766, 3777, 3840, 3909], 'existence': [16, 342, 600, 3008, 3238, 3337], 'specific': [18, 259, 319, 467, 627, 676, 1664, 1892, 3058, 3453, 3459, 3721, 3832], 'cortical': [19, 156, 3379], 'subcortical': [21, 158, 2194, 3368, 3439, 3454, 3464], 'networks': [22, 50, 546, 605, 1893, 3622], 'in': [23, 70, 104, 163, 166, 172, 191, 204, 229, 257, 289, 306, 352, 385, 401, 416, 552, 582, 606, 649, 674, 705, 716, 735, 763, 809, 820, 897, 932, 938, 949, 981, 994, 1024, 1029, 1066, 1091, 1141, 1173, 1180, 1196, 1202, 1234, 1312, 1319, 1340, 1348, 1354, 1373, 1378, 1436, 1485, 1529, 1531, 1548, 1579, 1594, 1612, 1625, 1633, 1676, 1695, 1709, 1737, 1743, 1754, 1775, 1820, 1854, 1906, 1932, 1976, 1995, 2001, 2037, 2087, 2107, 2131, 2154, 2183, 2187, 2211, 2215, 2249, 2258, 2288, 2293, 2316, 2339, 2347, 2353, 2365, 2381, 2383, 2396, 2414, 2426, 2446, 2478, 2499, 2536, 2547, 2552, 2565, 2572, 2577, 2600, 2643, 2669, 2678, 2696, 2722, 2776, 2785, 2789, 2807, 2848, 2893, 2897, 2906, 2909, 2947, 2952, 2975, 2980, 2985, 3053, 3080, 3125, 3177, 3192, 3220, 3289, 3357, 3370, 3408, 3421, 3475, 3534, 3561, 3569, 3576, 3623, 3652, 3691, 3694, 3734, 3776, 3837, 3869, 3898], 'genesis': [25, 608, 1978], 'expression': [27, 292, 425, 651, 679, 808, 3033, 3050, 3086, 3250, 3625], 'partial-': [29], 'generalized-onset': [31], 'seizures': [32, 69, 235, 256, 350, 373, 625, 748, 804, 827, 835, 1230, 1372, 1488, 1497, 1643, 1671, 1680, 1781, 1831, 1870, 1905, 1934, 1946, 1996, 2049, 2319, 2995, 3183, 3215, 3232, 3254, 3288, 3301, 3328, 3670, 3897], '(1–13).': [33], 'My': [34], 'goal': [35], 'is': [36, 114, 122, 183, 198, 214, 232, 298, 485, 514, 573, 632, 692, 733, 877, 895, 957, 1055, 1080, 1089, 1154, 1164, 1193, 1253, 1278, 1299, 1338, 1400, 1568, 1592, 1609, 1622, 1650, 1751, 1815, 1842, 1852, 1935, 1993, 2050, 2153, 2205, 2345, 2363, 2373, 2394, 2400, 2419, 2603, 2614, 2641, 2684, 2715, 2838, 2999, 3031, 3233, 3319, 3332, 3416, 3426, 3664, 3775], 'to': [37, 52, 67, 78, 102, 145, 188, 251, 287, 312, 333, 368, 376, 626, 714, 788, 1061, 1186, 1208, 1391, 1455, 1925, 1937, 1950, 1960, 1999, 2009, 2179, 2456, 2472, 2587, 2618, 2794, 2884, 2996, 3017, 3020, 3204, 3323, 3406, 3413, 3443, 3482, 3553, 3584, 3615, 3686, 3758, 3762, 3812, 3816, 3845, 3851, 3862, 3890, 3907], 'present': [38, 2346, 2364, 2599], 'concept': [40, 297, 1769, 2089], 'human': [42, 72, 84, 136, 226, 453, 469, 493, 610, 1771, 2044, 2185, 3010, 3029, 3893], 'epilepsy': [43, 454, 470, 611, 1028, 1238, 1377, 1794, 2220, 2357, 2366, 2417, 2506, 2523, 2551, 2576, 2813, 2951, 2984, 3011, 3030, 3265, 3353, 3460, 3515, 3523, 3692, 3895], 'as': [44, 211, 437, 969, 1139, 1839, 2438, 2441, 2444, 2675, 2677, 2901, 3128, 3349, 3698, 3714, 3716, 3771, 3773], 'a': [45, 105, 123, 143, 147, 212, 318, 353, 402, 447, 717, 810, 1003, 1017, 1025, 1093, 1129, 1235, 1374, 1569, 1677, 1784, 1806, 1840, 1907, 2121, 2255, 2262, 2410, 2500, 2518, 2548, 2573, 2723, 2765, 2781, 2839, 2865, 2948, 2981, 3000, 3240, 3350, 3358, 3720, 3763, 3899], 'disorder': [46, 1984], 'large': [48, 239, 468, 1766], 'neural': [49, 240, 277, 314, 363, 1767], 'support': [53, 462, 598, 640, 1764], 'through': [54], 'several': [55, 747], 'lines': [56, 594], 'reasoning': [58, 3061], 'how': [59], 'applicable': [60], 'observations': [62, 638, 1762, 3093], 'are': [66, 325, 331, 383, 395, 474, 479, 547, 612, 744, 818, 888, 1048, 1258, 1409, 1782, 1832, 1911, 1967, 2022, 2066, 2084, 2469, 2494, 3162, 3174, 3342, 3381, 3441, 3456, 3489, 3539], 'localization-related': [68, 3751, 3894], 'disorder.': [73, 348, 3156, 3186], 'I': [74, 96, 100, 141, 459, 578], 'do': [75, 97, 579, 2174], 'not': [76, 115, 480, 580, 693, 1968, 2023, 2175, 2436, 2470, 3292, 3320], 'attempt': [77], 'define': [79, 2222, 3521, 3566], 'specifically': [80, 2031, 3322], 'every': [81], 'possible': [82, 2102, 3811], 'operational': [83, 178], 'network': [85, 144, 197, 210, 241, 315, 323, 408, 421, 487, 513, 560, 587, 642, 647, 741, 765, 795, 817, 865, 1768, 1838, 1918, 1923, 1973, 2041, 2054, 2093, 2111, 2244, 2314, 2487, 2505, 2522, 2745, 3191, 3474, 3524, 3568, 3657, 3827, 3841], 'or': [86, 91, 362, 405, 413, 426, 1638, 1823, 1825, 1885, 1958, 2440, 3074, 3087, 3119, 3145, 3147, 3272, 3390, 3674, 3850, 3853], 'even': [87, 551, 710, 3024], 'all': [88, 173, 1912, 1953, 2188, 3175], 'limits': [90], 'components': [92, 533, 766, 2224, 3828], 'those': [94, 310, 381, 1966, 2898, 3196, 3476], 'that': [95, 108, 186, 208, 222, 233, 247, 316, 357, 382, 390, 396, 597, 639, 1471, 1787, 1974, 1997, 2055, 2070, 2207, 2265, 2327, 2397, 2445, 2705, 3005, 3014, 3069, 3262, 3306, 3438, 3452, 3520, 3538, 3729, 3782, 3904], 'address,': [98], 'but': [99, 476, 576, 923, 1178, 1648, 1829, 1965, 2433, 3291], 'hope': [101], 'show': [103, 755, 1106, 1209, 2286, 2462, 2665, 2939], 'way': [107, 125, 356, 2686], 'we': [111, 223, 438, 501, 785, 1730, 2065, 2779, 3573, 3804, 3860, 3876, 3888], 'already': [112, 3877], 'have': [113, 431, 502, 999, 1862, 1880, 2006, 2127, 2176, 3224, 3574, 3683, 3727], 'consistent': [116, 2256, 2666, 2810], 'with': [117, 225, 271, 365, 446, 456, 489, 790, 805, 812, 913, 927, 1027, 1042, 1237, 1288, 1300, 1376, 1389, 1422, 1489, 1573, 1672, 1679, 1688, 1726, 1856, 2013, 2068, 2079, 2261, 2376, 2421, 2502, 2520, 2550, 2575, 2655, 2662, 2709, 2747, 2811, 2950, 2983, 3158, 3212, 3243, 3310, 3428, 3765], 'any': [118, 167, 192, 243, 258, 360, 417, 661, 703, 1951, 3054, 3070, 3081, 3117, 3193, 3246, 3705], 'other': [119, 265, 544, 1748, 2234, 2812, 3557, 3607, 3695, 3742], 'explanation.': [120], 'This': [121, 720, 942, 1493, 2683, 3060, 3166, 3304, 3753], 'new': [124, 3814, 3905], 'understanding,': [127], 'diagnosing,': [128], 'potentially': [130], 'treating': [131], 'various': [133, 664], 'forms': [134], 'epilepsy.': [137, 321, 1772, 2045, 2342, 3105, 3133, 3752], 'In': [138, 264, 854, 905, 1184, 1292, 1324, 1560, 1600, 1718, 1746, 2764, 2820], 'this': [139, 181, 230, 238, 756, 1990, 2198, 2238, 2259, 2434, 2777, 2907, 3155, 3185, 3730, 3794], 'context,': [140], 'consider': [142, 3554], 'be': [146, 658, 701, 2707, 3168, 3199, 3258, 3470, 3551, 3712, 3732, 3787, 3799, 3810], 'functionally': [148, 327], 'anatomically': [150], 'connected,': [151], 'bilaterally': [152], 'represented,': [153], 'set': [154], 'brain': [159, 2645, 3633], 'structures': [160, 278, 304, 324, 1661, 2003, 2681, 2809, 3140, 3143, 3369, 3440, 3465, 3634], 'regions': [162, 379, 1443, 1484, 2021, 2458, 2746, 2832, 2844, 3455, 3586, 3631, 3838], 'which': [164, 282, 500, 571, 577, 1073, 1961, 2196, 2461, 2640, 3244, 3327, 3341, 3378, 3564], 'activity': [165, 171, 190, 201, 273, 409, 655, 883, 887, 894, 930, 1116, 1192, 1318, 1333, 1434, 1576, 1591, 1608, 1734, 1753, 2074, 2326, 2399, 2630], 'one': [168, 193, 498, 737, 974, 1744, 1875, 2704, 3045, 3194, 3324], 'part': [169, 194, 260, 418, 738, 970, 1970, 2024, 3055, 3457, 3471], 'affects': [170], 'others.': [175], 'The': [176, 322, 429, 483, 510, 543, 593, 685, 823, 1053, 1162, 1427, 1521, 1690, 1796, 2019, 2246, 2609, 2742, 2991, 3208, 3330, 3361, 3462, 3831], 'essential': [177, 332], 'component': [179, 554], 'definition': [182], 'observation': [185, 1786], 'vulnerability': [187], 'seizure': [189, 272, 307, 338, 371, 424, 654, 690, 713, 715, 866, 908, 925, 956, 1023, 1054, 1115, 1163, 1211, 1297, 1337, 1429, 1448, 1867, 1941, 1983, 2073, 2186, 2476, 2629, 2727, 2800, 3049, 3090, 3314, 3402, 3432, 3589, 3724], 'influenced': [199], 'by': [200, 410, 837, 1057, 1121, 1167, 1315, 1351, 1510, 1517, 1682, 2163, 2729, 2859, 2931, 2964, 3051, 3335, 3404, 3467, 3636], 'everywhere': [202], 'else': [203], 'network,': [206, 281, 400, 707, 772, 775, 781, 1804, 2702, 3079, 3241, 3266], 'whole': [213, 1841, 1922], 'responsible': [215, 1843], 'clinical': [218, 613, 807, 1336, 1491, 1674, 1780, 1904, 1933, 2016], 'electrographic': [220], 'phenomena': [221, 3560], 'associate': [224], 'seizures.': [227, 294, 1849, 3027, 3207], 'Implicit': [228], 'idea': [231], 'may': [236, 672, 723, 3469, 3550, 3565, 3612, 3649, 3682, 3731], 'entrain': [237], 'given': [244, 718], 'part,': [245], 'such': [246, 2254, 3640], 'it': [248, 1623, 3415, 3774], 'becomes': [249], 'irrelevant': [250], 'discuss': [252, 581], '""onset""': [254, 699], 'network.': [263, 387, 509, 566, 592, 684, 964, 1033, 1244, 1381, 1665, 1795, 2028, 2229, 2556, 2580, 2853, 2955, 2990, 3059, 3778, 3872], 'words,': [266], 'electrical': [268, 667, 955, 1005, 1119, 1778, 1899, 2181, 2325, 3347], 'hyperexcitability': [269], 'associated': [270, 488, 2420], 'reverberates': [274], 'within': [275, 682, 1660], 'operate': [283], 'together': [284], 'inextricably': [286], 'culminate': [288], 'eventual': [291], 'singular': [296], 'distinction': [300, 1992], 'between': [301, 2402], 'anatomic': [303, 366, 619, 1962, 2889, 3160], 'involved': [305, 384, 2210], 'propagation,': [308], 'belonging': [311], 'underlies': [317], ""patient's"": [320], 'connected': [326, 3041], 'structurally;': [329], 'they': [330, 2095], 'development': [335, 1108, 2038, 3687], 'thus': [340], 'maintenance': [344, 1980], 'epileptic': [347, 2092, 2592, 3871], 'Independently,': [349], 'propagate': [351, 375, 1948], 'variably': [354, 1949, 2113], 'extensive': [355, 444, 3149], 'might': [358, 709, 3798, 3842], 'involve': [359], 'region': [361, 1458, 2674, 2695, 3543, 3706, 3764], 'structure': [364], 'connections': [367, 1963], 'primary': [370], 'network;': [372], 'can': [374, 657, 1947, 2096, 3153, 3257, 3298], 'many': [377], 'more': [378, 3146, 3660], 'than': [380, 2606, 3530, 3572, 3802], 'Important': [388], 'corollaries': [389, 430, 3065], 'derive': [391], 'these': [393, 604, 1102, 1486, 1642, 2190, 2250, 3278, 3483, 3493], 'ideas': [394, 3496], 'interruption': [397, 2309, 3188], 'structural': [403, 2308], 'sense,': [404], 'modification': [406, 3076], 'electrical,': [411, 3073], 'biochemical,': [412], 'metabolic': [414], 'influences': [415], 'will': [422, 439], 'alter': [423, 3048, 3084, 3205], 'its': [427, 663, 2076, 2266, 2615, 2647], 'occurrence.': [428], 'greatest': [433], 'implications': [434, 3491], 'treatment,': [436, 3022], 'see': [440, 976, 1731], 'later.': [441, 1218], 'Based': [442, 3873], 'on': [443, 1072, 1397, 2429, 2464, 2596, 2646, 3094, 3601, 3675, 3823, 3874], 'experience': [445], 'great': [448], 'number': [449], 'diversity': [451], 'patients': [455, 753, 1855, 2367, 2654, 2769, 3126, 3222, 3412, 3516], 'intractable': [457, 494, 1505, 3182, 3253], 'seizures,': [458, 1465, 3115, 3393, 3448], 'describe': [460], 'three': [466, 752], 'networks.': [471, 2593, 2819, 3461], 'Many': [472], 'others': [473, 3864], 'likely,': [475], 'data': [478, 2331, 3681], 'so': [481, 2085], 'extensive.': [482], 'first': [484, 856, 931, 1735, 2648], 'most': [491, 504, 634, 1045, 1155, 1254, 1401, 2150], 'common': [492, 3371], 'epilepsy,': [495, 2283, 2480, 2659], 'about': [499, 3409, 3892], 'information:': [505], 'medial': [507, 511, 536, 557, 769, 814, 862, 962, 1031, 1320, 1341, 1482, 1596, 1614, 1636, 1739, 1802, 1809, 1858, 2109, 2159, 2165, 2217, 2227, 2271, 2280, 2312, 2337, 2340, 2354, 2448, 2503, 2508, 2514, 2544, 2554, 2656, 2672, 2693, 2698, 2743, 2752, 2756, 2791, 2796, 3102, 3130, 3139, 3227], 'temporal/limbic': [508, 512, 963, 1032, 1803, 1859, 2110, 2228, 2272, 2313, 2341, 2449, 2504, 2555, 2744], 'bilateral,': [515, 1863], 'cortical,': [516], 'subcortical,': [518], 'includes': [520], 'hippocampi,': [522], 'amygdalae,': [524], 'entorhinal': [526, 903, 934, 967, 996, 1099, 1181, 1197, 1821], 'cortices,': [527], 'lateral': [528, 1826, 2156, 2510, 2541, 2758, 3142, 3150], 'temporal': [529, 559, 591, 770, 815, 863, 1437, 1698, 1716, 1740, 1756, 1810, 1827, 1865, 1884, 2133, 2157, 2160, 2218, 2281, 2301, 2355, 2515, 2526, 2570, 2657, 2680, 2699, 2725, 2759, 2797, 2831, 2867, 2912, 2940, 3103, 3122, 3131, 3137, 3151, 3217, 3228], 'neocortices,': [530], 'extratemporal': [532, 2457, 2479], 'thalamus': [537, 2338, 2385, 2403, 2792], 'inferior': [540, 2139, 2296], 'frontal': [541, 565, 780, 1243, 1321, 1342, 1483, 1555, 1597, 1615, 1886, 2011, 2015, 2020, 2140, 2170, 2297, 2852, 2978, 2989], 'lobes.': [542], 'two': [545, 802, 1103, 1224, 1366, 1463, 1487, 1669], 'less': [548, 2604, 3148, 3801], 'commonly': [549], 'identified,': [550], 'their': [553, 675, 3867], 'parts:': [555], 'occipital/lateral': [558], 'superior': [563, 778, 1241, 1306, 1355, 1479, 1581, 1627, 1639, 2850, 2987], 'parietal/medial': [564, 590, 779, 1242, 2851, 2988], 'Two': [567, 1219, 1361], 'additional': [568], 'networks,': [569, 3012, 3043, 3340, 3641], 'highly': [574], 'suggestive,': [575], 'detail,': [583], 'include': [584, 2750], 'bifrontal/pontine/subthalamic': [586], 'importance': [602, 2334], 'observations,': [614, 620], 'intracranial': [615, 1469, 1631, 3594], 'EEG,': [616], 'functional': [617, 2080, 2582, 3527, 3610, 3769], 'neuroimaging,': [618, 2030], 'response': [623, 2413, 2992, 3211], 'invasive': [628, 2997], 'treatments.': [629], 'Intracranial': [630], 'EEG': [631, 731, 761, 3595, 3644], 'significant': [635, 2151, 2783, 2903, 3684], 'hypothesis.': [643], 'Because': [644], 'entire': [646], 'participates': [648, 1975], 'entrained': [659], 'parts,': [665], 'initial': [666, 686, 760, 951, 1296, 1330, 1566, 1605, 2473], 'events': [668], '(at': [669], '""seizure': [670, 728, 3545, 3662], 'onset"")': [671], 'vary': [673, 711], 'location': [677, 1811], 'occurrence': [681], 'area': [687, 1308, 3325], 'apparent': [689], 'involvement': [691, 1659], 'really': [694], 'an': [695, 1267, 1281, 1412, 1703, 1722, 2716, 3260, 3264, 3870], 'onset': [696, 830, 1009, 1814, 1889], 'area,': [697, 1641], 'because': [698, 784, 1836, 2094, 2631, 3579, 3865], 'could': [700, 3046, 3786], 'expressed': [702], 'place': [704], 'patient.': [719], 'locational': [721, 757, 945, 1652], 'variability': [722, 758, 948, 980, 1653, 1774, 1896], 'produce': [724, 1926], 'different': [725, 764, 1917, 3900], 'morphologies': [726], 'onset""': [729, 3546], 'when': [730, 2064, 2660], 'recording': [732, 900, 1097, 1598, 1759], 'performed': [734], 'only': [736, 783, 977, 1200, 1618, 1634, 3334], '(14–19).': [742], '1-4': [743], 'examples': [745, 1798, 1913, 2495], 'each': [750, 1398, 1403, 1466], 'who': [754, 1861, 1879, 2773, 3223, 3478], 'change': [762, 1567], 'lobe/limbic': [771, 864], 'occipital/temporal': [774, 2027, 2521, 2816], 'visualized': [782], 'were': [786, 1508, 2774, 2882], 'able': [787], 'record': [789, 2180], 'electrodes': [791, 1041, 1388, 1632], 'implanted': [792, 1037, 1147, 1385, 1416], 'into': [793], 'multiple': [794, 1384, 2537, 2808, 2970, 3172, 3273], 'sites.': [796], 'Four': [797], 'consecutive': [798, 1220, 1362], '10-s': [799, 1014, 1126, 1221, 1363], 'intervals': [800, 1015, 1127, 1222, 1364], 'spontaneous': [803, 1018, 1130, 1225, 1464, 1670, 2072], 'identical': [806, 1229, 1371], 'patient': [811, 824, 912, 1026, 1138, 1236, 1375, 1494, 1678, 2501, 2519, 2549, 2574, 2949, 2982, 3884], 'limbic': [816, 2701], 'shown': [819], '1,': [821], '2.': [822], 'had': [825], 'febrile': [826], 'then': [829, 891, 937, 1206, 3044], 'uncontrolled': [832, 2994, 3101, 3750], 'complex': [833, 1021, 1133, 1686], 'partial': [834, 1022, 1134, 3287, 3447], 'characterized': [836, 1509, 1681], 'staring': [838], 'right-hand': [840], 'dystonia': [841], 'at': [842, 1007, 1077, 1498, 2625, 2770, 3245, 3367, 3532, 3541, 3704, 3719], 'age': [843, 1499], '3': [844, 1313, 1461, 1619], 'years.': [845], 'Magnetic': [846], 'resonance': [847, 2886], 'imaging': [848, 2887], '(MRI)': [849], 'showed': [850, 1545, 1707], 'left': [851, 1273, 1533, 1551, 1554, 2542], 'hippocampal': [852, 874, 918, 940, 983, 1068, 1174, 2370], 'atrophy.': [853], 'seizure,': [857, 1135, 1189, 1295, 1328, 1564, 1603, 1749], 'hallmark': [859], 'onset,': [867, 1868], 'periodic': [869, 919, 1063, 1169], 'discharge': [870, 921, 1065, 1076, 1088, 1303, 1353, 1453], 'recorded': [871, 1304, 1467, 1817], 'depth': [875, 984, 990, 1040, 1069, 1148, 1175], 'electrode': [876, 985, 991, 1070, 1096, 1176, 1256, 1399, 2711], 'seen.': [878], 'Shortly': [879], 'after,': [880], 'low-voltage': [881, 892, 928, 1074, 1086, 1190, 1301, 1316, 1331, 1432, 1570, 1574, 1589, 1606, 1732], 'fast': [882, 893, 929, 1075, 1087, 1191, 1210, 1302, 1317, 1332, 1433, 1575, 1590, 1607, 1733], 'sharp': [885], 'theta/alpha': [886], 'superimposed,': [889], 'seen': [896, 1090, 1171, 1195, 1339, 1593, 1624, 2401, 3728], 'contacts': [899, 968, 1047, 1257, 1287, 1322, 1344, 1742], 'cortex.': [904, 1100], 'second': [907, 1326, 1447], 'same': [911, 1137, 1834], 'clinically': [914, 1228, 1370, 1872, 1928, 3673], 'stereotyped': [915, 1004, 1908, 1929], 'manifestations,': [916], 'spike': [920, 1064, 1571], 'begins,': [922], '""starts""': [926], 'cortex,': [935, 1198], 'contacts.': [941, 1599, 1760], 'kind': [943, 2199, 3118, 3795], 'morphologic': [947, 979], 'manifestations': [952, 1675, 1846, 2017], 'extremely': [958, 1723], 'typical': [959, 1020, 1132, 1226], 'Without': [965], 'display,': [973], 'would': [975, 1644, 3083, 3198], 'minor': [978], '(or': [986, 3531], 'conversely,': [987], 'without': [988], 'recording,': [992], 'just': [993, 3713], 'electrode)': [997], 'sense': [1001], 'pattern': [1006], 'seizure.': [1012, 1745, 2868], 'Consecutive': [1013, 1125], 'A–J': [1034, 1144], 'represent': [1035, 1145, 1246, 1264, 1383], 'multicontact': [1036, 1146, 1248, 1386], 'subdural': [1038, 1094, 1150, 1249, 1270, 1387, 1417], 'position': [1043], '1': [1044, 1153, 1160, 1252, 1396, 1406], 'distal;': [1046, 1255, 1402], 'spaced': [1049, 1259], '8–10': [1050], 'mm': [1051, 1261], 'apart.': [1052, 1262], 'heralded': [1056, 1166], 'classical': [1059], '1-': [1060], '2-Hz': [1062], '(H3–H6),': [1071], '12–20': [1078], 'Hz': [1079], 'superimposed.': [1081], 'Within': [1082], '5': [1083], 's,': [1084], 'similar': [1085, 1352, 1451, 1490, 1588, 1673, 2840], 'B3–6,': [1092], 'strip': [1095], 'Subsequently,': [1101], 'nearby': [1104], 'locations': [1105], 'asynchronous': [1107], 'high-frequency': [1111], 'ictal': [1112, 1452, 1538, 1704, 1898, 2733, 2824, 2846, 2878, 3604], 'discharge.': [1113], 'Clinical': [1114, 1761], 'follows': [1117], 'changes': [1120, 1547, 2182], 'nearly': [1122], '30': [1123, 1216], 's.': [1124, 1161, 1407], 'illustrated': [1140, 1188, 1563], 'Fig.': [1142], '1.': [1143], 'electrodes;': [1151, 1250], 'contact': [1152, 1251, 1357, 1395], 'distal.': [1156], 'Each': [1157], 'division': [1158, 1404], 'equals': [1159, 1405], 'again': [1165], '1-Hz': [1168], 'spikes': [1170], 'best': [1172, 1797, 3481], '(H3–6)': [1177], 'also': [1179, 1763, 1890, 1902, 2418, 2584, 3015, 3780, 3808], 'cortex': [1182, 1343, 1421, 1822], '(B3–6).': [1183], 'contrast': [1185], 'prior': [1187], 'next': [1194], 'subsequently': [1201], 'hippocampus;': [1203], 'both': [1204, 1549, 1710, 2304, 2916], 'sites': [1205], 'continue': [1207], 'buildup': [1212], 'before': [1213, 3658, 3671], 'sudden': [1214], 'cessation': [1215, 2317, 2321, 3113, 3213], 's': [1217, 1314, 1350, 1586, 1620], '(top': [1231], 'bottom)': [1233], 'B–H': [1245], 'implanted,': [1247, 1268], '8': [1260, 1282, 1284, 1413, 1415, 1500], 'I–K': [1263], 'portions': [1265], '64-contact': [1269], 'grid': [1271, 1277, 1418], 'over': [1272, 1419], 'frontotemporoparietal': [1274], 'cortex;': [1275], 'composed': [1279], '×': [1283, 1414], 'arrangement': [1285], '10-mm': [1289, 1392, 1424], 'intercontact': [1290, 1393, 1425], 'spacing.': [1291, 1426], 'top': [1294, 1428, 1562], 'manifestation': [1298, 3445, 3672], 'parietal': [1307, 1356, 1480, 1534, 1552, 1582, 1628, 1640, 1888, 2976], '(last': [1309, 1359], 'channel)': [1310], 'followed': [1311, 1347, 1516, 2162], '(B7).': [1323], '(bottom)': [1327, 1449], 'preceding': [1334], '(B5,': [1345], '7)': [1346], '4': [1349, 1585, 1667], 'K16': [1358], 'channel).': [1360], 'spontaneous,': [1367], 'typical,': [1368], 'occipitotemporal': [1380, 2579, 2954], 'A–I': [1382], '8-': [1390], 'spacing;': [1394], 'J–M': [1408], 'parts': [1410], 'parietooccipital': [1420], 'uniform': [1423], 'shows': [1430, 1450, 1462, 1668, 2969], 'simultaneous': [1431, 1752], 'developing': [1435], '(electrodes': [1438], 'B,': [1439], 'D)': [1440], 'occipital': [1442, 1457, 1700, 1713, 1758, 1882, 2002, 2568, 2829, 2942], '(J),': [1444], 'whereas': [1445], 'restricted': [1454], '(J).': [1459], 'Figure': [1460, 1666, 2713, 2821, 2836], 'electrodes,': [1470], 'demonstrate': [1472], 'variable': [1474, 1881, 2007, 2014], 'participatory': [1475, 1656], 'order': [1476, 1657], 'manifestations.': [1492], 'began': [1495], 'having': [1496, 3129], 'years': [1501], 'was': [1503, 1558, 2873, 2895], 'medically': [1504], 'immediately.': [1506], 'Seizures': [1507], 'right': [1511, 1697, 1712, 1715, 2513, 2545, 2567, 2724, 2866, 2911], 'foot': [1512], 'leg': [1514], 'heaviness': [1515], 'tingling': [1518], 'rigidity.': [1520], 'positron': [1522], 'emission': [1523, 1540, 2529, 2558, 2925, 2958], 'tomography': [1524, 1542, 2530, 2559, 2927, 2960], '(PET)': [1525], 'scan': [1526, 1692], 'demonstrated': [1527, 1611, 1693, 2428, 2806], 'reduction': [1528, 2380, 3420, 3433], 'metabolism': [1530, 2119, 2382, 2427], 'lobe,': [1535, 2141, 2298, 3138], 'single-photon': [1539, 2924, 2957], 'computed': [1541, 2926, 2959], '(SPECT)': [1543], 'study': [1544, 1706, 2532, 2561, 2872, 3555], 'perfusion': [1546, 2734, 2787, 2894, 2904, 2946, 2973], 'regions.': [1556, 1717], 'MRI': [1557], 'negative.': [1559], 'discharge,': [1572], 'rapidly': [1577], 'superimposed': [1578], 'region.': [1583, 1629], 'About': [1584], 'later,': [1587], 'bottom': [1602], 'clearly': [1610], 'contacts,': [1616], 'later': [1621], 'With': [1630], 'hemispheric': [1637], 'appear': [1645, 1871, 1998], 'electrically': [1646], 'identical,': [1647], 'there': [1649, 1750], 'clear': [1651], 'flashing': [1683], 'lights': [1684], 'behavior': [1687, 3654], 'falls.': [1689], 'PET': [1691, 2104, 2284, 2431, 2467, 2607], 'hypometabolism': [1694, 2130, 2152, 2214, 2248, 2290, 2463, 2498, 2535, 2564], 'regions,': [1701, 2161, 3372], 'SPECT': [1705, 2581, 2613, 2651, 2825], 'hypoperfusion': [1708, 2595], 'setting': [1720], 'abnormal': [1724], 'background': [1725, 3597], 'multifocal': [1727], 'spike-and-wave': [1728], 'activity,': [1729, 3605], 'develop': [1736, 3813], 'lobe': [1741, 1866, 2219, 2282, 2356, 2658, 2700, 2726, 2798, 3104, 3123, 3132, 3218, 3229], 'Despite': [1773], 'early': [1777, 2663, 2863], 'patterns,': [1779, 3598], 'stereotyped,': [1783], 'key': [1785, 3442], 'truly': [1788, 3847], 'reflects': [1789], 'operation': [1791], 'come': [1799], 'where': [1805], 'variable,': [1807], 'specific,': [1808, 3035], 'manifest': [1813], 'often': [1816, 2115], '(for': [1818], 'example,': [1819, 3268, 3592, 3836], 'hippocampus': [1824], 'neocortex),': [1828], 'clinically,': [1835], 'Another': [1850], 'example': [1851, 1988, 3235], 'found': [1853, 1994, 2780], 'syndrome': [1860, 2221, 2450], 'independent': [1864, 3226, 3373], 'although': [1869, 2598, 3316], 'indistinguishable': [1873], 'another': [1876, 2481, 2685, 2823, 3234], '(20–22).': [1877], 'Patients': [1878], 'reflect': [1891, 1938], 'expression,': [1900], 'express': [1903], 'way.': [1909, 3360], 'These': [1910, 3435, 3495, 3678], 'entrainment': [1915], 'sites,': [1919], 'acting': [1924], 'events.': [1930], 'Variability': [1931], 'likely': [1936, 2206, 3768], 'propagation': [1939, 2008, 2047, 2061, 2477, 2489], 'activity.': [1942, 2801, 3091, 3725], 'As': [1943], 'noted': [1944], 'earlier,': [1945, 3067], 'areas': [1954, 2209, 2251, 2474, 2490, 2538, 2899, 2943, 2971, 3173, 3197, 3380], 'unilaterally,': [1955], 'bilaterally,': [1956], 'cortically,': [1957], 'subcortically': [1959], 'exist,': [1964], 'necessarily': [1969], 'per': [1985], 'se.': [1986], 'An': [1987], 'difficult': [1991], 'originate': [2000], 'yet': [2005], 'lobes': [2012, 2571, 2979], '(23–25).': [2018], 'Functional': [2029], 'PET,': [2032, 3526], 'has': [2033, 2231, 2252, 2435, 2585, 2804, 3354, 3363], 'been': [2034, 2232, 2253, 2437, 2805, 3355, 3364], 'very': [2035, 3499], 'influential': [2036], 'hypothesis': [2042], 'Although': [2046], 'distinct': [2051], 'generates': [2056], 'them,': [2057], 'question': [2059, 3497], 'frequently': [2062], 'arises': [2063], 'dealing': [2067], 'involves': [2071], 'evolution.': [2077], 'Observations': [2078], 'neuroimaging': [2081, 2583], '(specifically': [2082, 3525], 'PET)': [2083], 'important': [2086], 'avoid': [2097], 'confounding': [2099], 'influence': [2100], 'propagation.': [2103], 'demonstrates,': [2105], 'especially': [2106], 'syndrome,': [2112, 2260], 'extensive,': [2114, 2424], 'multilobar,': [2116], 'reduced': [2117], 'interictal': [2118, 2129, 2213, 2247, 2430, 2465, 2497, 2534, 2563, 2731, 2871, 3602], 'involving': [2120, 3135], 'variety': [2122], 'structures.': [2124, 2763], 'Various': [2125], 'authors': [2126], 'confirmed': [2128, 2708], 'ipsilateral': [2132, 2135, 2142, 2295, 2300, 2348, 2671, 2793], 'neocortex,': [2134, 2302, 2760], 'hippocampus,': [2136, 2138, 2405, 2915], 'contralateral': [2137], 'dorsomedial': [2143], 'thalamus,': [2144, 2166, 2349, 2757], 'amygdala': [2146, 2352], '(26–32).': [2147], 'Quantitatively,': [2148], 'basal': [2167, 2387], 'ganglia,': [2168], 'lobe.': [2171], 'We': [2172, 3726], 'usually': [2173], 'opportunity': [2178], 'areas,': [2191], 'particularly': [2192, 2202], 'ones,': [2195], 'makes': [2197], 'information': [2201], 'valuable.': [2203], 'It': [2204, 3549, 3779, 3807], 'There': [2230], 'no': [2233, 3159], 'satisfactory': [2235], 'explanation': [2236], 'widespread': [2239], 'hypometabolism,': [2240], 'aside': [2241], 'concept.': [2245], 'finding': [2257], 'sensitivity': [2263, 2455], '90%,': [2264], 'absence': [2267], 'actually': [2268], 'questions': [2269], 'diagnosis.': [2273], 'After': [2274], 'successful': [2275, 3164], '(i.e.,': [2276], 'curative)': [2277], 'surgery': [2278, 3308], 'scans': [2285, 2468], 'improvement': [2287], 'observed': [2291], 'preoperatively': [2292], 'thalami': [2305], '(32–34).': [2306], 'Thus': [2307], 'results': [2315, 3436], 'reverberating': [2324], 'accompanied': [2328], 'them.': [2329], 'Anatomic': [2330], 'confirm': [2332], 'Volume': [2343], 'loss': [2344, 2362], 'caudate,': [2350], '(35,36),': [2358], 'thalamic': [2360, 2407, 2673, 2694, 3422, 3739], 'cell': [2361, 2371], '(37,38).': [2368], 'Furthermore,': [2369], 'density': [2372], 'significantly': [2374], 'correlated': [2375, 3427], 'bilateral': [2384, 2755, 2919, 3225], 'ganglia': [2388], '(39).': [2389], 'Functionally,': [2390], 'also,': [2391], 'consistent,': [2395], 'synchronous': [2398], 'stimulation': [2408, 3348, 3362, 3384, 3399, 3468, 3486], 'gives': [2409], 'monosynaptic': [2411], 'excitatory': [2412], 'hippocampus.': [2415], 'Extratemporal': [2416], 'multifocal,': [2422], 'sometimes': [2423], 'reductions': [2425], 'studies,': [2432, 2466, 3887], 'reproducible': [2439], 'well': [2442, 2676], 'documented': [2443], '(29).': [2451, 2491], 'Interestingly,': [2452], 'despite': [2453], 'high': [2454], 'epileptogenicity,': [2460], 'sensitive': [2471, 2605], 'demonstration': [2482], 'nonequivalence': [2485], '5,': [2492], '6': [2493], '(left': [2507], 'temporal,': [2511, 2543], 'hypometabolism)': [2516], '(occipital': [2524], 'hypometabolism).': [2527], '18Fluorodeoxyglucose–positron': [2528, 2557], '(18FDG-PET)': [2531, 2560], 'demonstrates': [2533, 2562, 2828], '(medial': [2539], 'temporal)': [2546], 'helped': [2586], 'formulate': [2588], 'concepts': [2590, 3500], 'Interictal': [2594], 'SPECT,': [2597], 'some': [2601], 'cases,': [2602], '(40–42).': [2608], 'main': [2610], 'use': [2611, 3518, 3903], 'unique': [2616], 'ability': [2617], 'capture': [2619], 'status': [2621], 'blood': [2623, 2720, 3423], 'flow': [2624, 2721, 2749, 3424], 'time': [2627], 'lack': [2634], 'redistribution': [2636], 'radioisotope,': [2639], 'bound': [2642], 'pass.': [2649], 'Ictal': [2650, 2802, 2854, 2923, 2956], 'studies': [2652, 3519, 3537], 'obtained': [2661, 2728, 2858, 2930, 2963], 'injections,': [2664], 'blood-flow': [2667], 'increases': [2668], '(41–44).': [2682], 'demonstrating': [2688], 'participation': [2690, 3868], 'cannot': [2706, 3167], 'usual': [2710], 'placement.': [2712], '7': [2714], 'image': [2717, 2827, 2857], 'increased': [2719, 2748, 2834, 2945], 'subtracting': [2730], 'images': [2735], 'superimposing': [2737], 'differences': [2739, 2881], 'onto': [2740], 'MRI.': [2741], 'temporal/hippocampal': [2753], 'region,': [2754, 3082], 'midbrain': [2762, 2920], 'group': [2766], '18': [2768], 'our': [2771, 3375, 3581, 3616, 3783, 3824], 'center': [2772], 'analyzed': [2775], 'manner,': [2778], 'statistically': [2782], 'increase': [2784, 2892, 2974], 'measured': [2788], 'hyperperfusion': [2803, 2847], 'networks:': [2814], 'parietal/frontal': [2818], '8,': [2822], 'difference': [2826], 'perfusion.': [2835], '9': [2837], 'depiction': [2841], '[99Tc]-HMPAO-SPECT': [2855], 'subtraction': [2856, 2928, 2961], 'injection': [2860], 'HMPAO': [2862], 'during': [2864], 'normalized': [2870], 'digitally': [2874], 'subtracted': [2875], 'study,': [2879], 'coregistered': [2883], 'magnetic': [2885], 'detail.': [2890], 'Percentage': [2891], 'calculated': [2896], 'identified': [2900, 3127], 'showing': [2902], 'changes,': [2905], 'case,': [2908], 'neocortex': [2913], 'thalami,': [2917], 'reticular': [2921], 'formation.': [2922], 'images,': [2929], 'subtraction,': [2932, 2965], 'normalization,': [2933, 2966], 'coregistration': [2935], '(see': [2936], 'earlier': [2937], 'figures),': [2938], 'image,': [2962], 'coregistration,': [2968], 'therapy': [2998, 3761, 3849], 'final': [3001], 'line': [3002], 'supports': [3006], 'leads': [3016], 'novel': [3018], 'approaches': [3019, 3815, 3821], 'diagnosis,': [3021], 'prediction': [3025, 3668], 'If': [3028], 'abnormally': [3036], 'active,': [3037], 'intrinsically': [3038], 'defined': [3039], 'cortical/subcortical/bilateral': [3042], 'theoretically': [3047, 3711], 'intervening': [3052], 'grows': [3062], 'presented': [3066], 'indicating': [3068], 'structural,': [3071], 'metabolic,': [3072], 'chemical': [3075], 'frequency': [3088, 3281, 3403], 'Consider': [3092], 'outcome': [3096], 'surgical': [3098, 3760], 'treatment': [3099, 3351, 3702, 3748, 3817], 'Published': [3106], 'reports': [3107], 'document': [3108], '60–90%': [3109], 'excellent': [3110, 3210], 'response,': [3111], 'meaning': [3112], 'after': [3116, 3216], 'extent': [3120], 'resection': [3124, 3152, 3219], 'Operations': [3134], 'anterior': [3136], 'only,': [3141, 3144], 'cure': [3154], 'Procedures': [3157], 'overlap': [3161], 'similarly': [3163, 3209], '(45–47).': [3165], 'explained': [3169], 'unless': [3170], 'critical': [3176], 'production': [3179], 'Then': [3187], '(and': [3200], 'apparently': [3201], 'is)': [3202], 'sufficient': [3203], 'well-selected': [3221], 'origin': [3230], 'interference': [3242], 'site': [3247], 'alters': [3248], '(20,21).': [3255], 'Disconnection': [3256], 'considered': [3259], 'intervention': [3261], 'targets': [3263], 'corpus': [3269], 'callosum': [3270], 'section': [3271], 'subpial': [3274], 'transection.': [3275], 'Both': [3276], 'procedures': [3279, 3785], 'reduce': [3280], 'intensity': [3283], 'generalized': [3285, 3392], 'many,': [3290], 'all,': [3293], 'patients,': [3294, 3563], 'either': [3296], 'procedure': [3297, 3318], '(rarely)': [3299], 'stop': [3300], 'entirely': [3302], '(48–52).': [3303], 'suggests': [3305], 'interferes': [3309], 'mode': [3312], 'generation,': [3315], 'targeted': [3321, 3463, 3540], '""arise.""': [3329], 'result': [3331], 'explainable': [3333], 'intrinsic': [3339], 'structurally': [3343], 'disrupted.': [3344], 'So': [3345], 'far,': [3346], 'used': [3356], 'nontargeted': [3359, 3744], '(presumably)': [3365], 'directed': [3366, 3718], 'knowledge': [3376, 3825, 3875], 'involved.': [3382], 'Prolonged': [3383], 'centromedian': [3387], 'nucleus': [3388], 'reduces': [3389, 3401], 'controls': [3391], 'prolonged': [3395], 'intermittent': [3396], 'vagal': [3397], 'nerve': [3398], '(VNS)': [3400], 'up': [3405], '50%': [3407], 'half': [3410], 'whom': [3414], 'applied': [3417, 3701], '(53–55).': [3418], 'VNS-induced': [3419], '(bilaterally)': [3425], 'degree': [3430], '(56).': [3434], 'imply': [3437], 'supporting': [3449], 'contention': [3451], 'affected': [3466], 'individuals': [3477], 'respond': [3479], 'various,': [3484], '""nontargeted,""': [3485], 'therapies.': [3487], 'What': [3488], 'observations?': [3494], 'epileptogenic': [3502], 'zone,': [3503, 3505, 3507], 'irritative': [3504], 'symptomatogenic': [3506], 'ictal-onset': [3509], 'zone.': [3510], 'Our': [3511], 'evaluation': [3512, 3797, 3885], 'refractory': [3514], 'should': [3517, 3710, 3809], 'MRI)': [3528], 'rather': [3529], 'least': [3533, 3767], 'addition': [3535], 'to)': [3536], 'like': [3547], 'EEG.': [3548, 3677], 'pertinent': [3552], 'kinds': [3558, 3679], 'individual': [3562], 'better': [3570], 'terms': [3571], 'sought': [3575], 'past': [3578], 'single-minded': [3582], 'attention': [3583], 'defining': [3585], 'so-called': [3588], 'onset.': [3590], 'For': [3591], 'quantitative': [3593, 3643], 'analysis,': [3596], 'sleep': [3599], 'effects': [3600], 'types': [3608], 'assessments': [3611], 'contribute': [3613], 'considerably': [3614, 3800], 'understanding': [3617], 'role': [3620], 'epilepsies.': [3628], 'Studying': [3629], 'broad': [3630], 'related': [3635], 'presence': [3638], 'using': [3642], 'analyses': [3645], 'sophisticated': [3647], 'approaches,': [3648], 'detect': [3650], 'alterations': [3651], 'traditional': [3661, 3676], 'discharge""': [3663], 'seen,': [3665], 'allow': [3667, 3843], 'applicability': [3685], 'further': [3689], 'therapy,': [3690], 'neurologic': [3696], 'diseases': [3697], 'well.': [3699], 'Broadly': [3700], '(directed': [3703], 'network)': [3709], 'effective': [3715], 'treatments': [3717], '""focus""': [3722], 'true': [3733], 'application': [3736], 'VNS,': [3738], 'stimulation,': [3740], 'relatively': [3743], 'interventions': [3745], 'approach': [3754], 'opens': [3755], 'door': [3757], 'directing': [3759], 'consequences,': [3770], 'long': [3772], 'means': [3781], 'patient-evaluation': [3784], 'revamped': [3788], 'entirely.': [3789], 'Cost': [3790], 'risk': [3792]}",2002,"['Epilepsy', 'Neuroscience', 'Psychology', 'Medicine']","A considerable amount of compelling evidence exists, predominantly from animal models and experimental paradigms, for the existence of specific cortical and subcortical networks in the genesis and expression of partial- and generalized-onset seizures (1–13). My goal is to present the concept of human epilepsy as a disorder of large neural networks and to support through several lines of reasoning how applicable the observations from experimental models are to localization-related seizures in the human disorder. I do not attempt to define specifically every possible operational human network or even all the limits or components of those that I do address, but I hope to show in a compelling way that the evidence we already have is not consistent with any other explanation. This is a new way of understanding, diagnosing, and potentially treating the various forms of human epilepsy. In this context, I consider a network to be a functionally and anatomically connected, bilaterally represented, set of cortical and subcortical brain structures and regions in which activity in any one part affects activity in all the others. The essential operational component of this definition is the observation that vulnerability to seizure activity in any one part of the network is influenced by activity everywhere else in the network, and that the network as a whole is responsible for the clinical and electrographic phenomena that we associate with human seizures. Implicit in this idea is that the seizures may entrain this large neural network from any given part, such that it becomes irrelevant to discuss the ""onset"" of seizures in any specific part of the network. In other words, the electrical hyperexcitability associated with seizure activity reverberates within the neural structures of the network, which operate together and inextricably to culminate in the eventual expression of seizures. A singular concept is the distinction between the anatomic structures involved in seizure propagation, and those belonging to the neural network that underlies a specific patient's epilepsy. The network structures are connected functionally and structurally; they are essential to the development of the seizure and thus the existence and maintenance of the epileptic disorder. Independently, seizures propagate in a variably extensive way that might involve any region or neural structure with anatomic connections to the primary seizure network; seizures can propagate to many more regions than those that are involved in the network. Important corollaries that derive from these ideas are that interruption of the network, in a structural sense, or modification of network activity by electrical, biochemical, or metabolic influences in any part of the network will alter seizure expression or its occurrence. The corollaries have the greatest implications for treatment, as we will see later. Based on extensive experience with a great number and diversity of human epilepsy patients with intractable seizures, I describe and support the evidence for three specific large human epilepsy networks. Many others are likely, but the data are not so extensive. The first is the network associated with the most common human intractable epilepsy, and the one about which we have the most information: the medial temporal/limbic network. The medial temporal/limbic network is bilateral, cortical, and subcortical, and includes the hippocampi, the amygdalae, the entorhinal cortices, lateral temporal neocortices, and extratemporal components of the medial thalamus and the inferior frontal lobes. The other two networks are less commonly identified, even in their component parts: the medial occipital/lateral temporal network and the superior parietal/medial frontal network. Two additional networks, for which evidence is highly suggestive, but which I do not discuss in detail, include the bifrontal/pontine/subthalamic network and the parietal/medial temporal network. The lines of evidence that support the existence and importance of these networks in the genesis of human epilepsy are clinical observations, intracranial EEG, functional neuroimaging, anatomic observations, and the response of seizures to specific invasive treatments. Intracranial EEG is the most significant of the observations that support the network hypothesis. Because the entire network participates in the expression of the seizure activity and can be entrained from any of its various parts, initial electrical events (at ""seizure onset"") may vary in their specific location of expression and occurrence within the network. The initial area of apparent seizure involvement is not really an onset area, because ""onset"" could be expressed any place in the network, and might even vary from seizure to seizure in a given patient. This locational variability may produce different morphologies of ""seizure onset"" when EEG recording is performed in only one part of the network (14–19). 1-4 are examples of several seizures from each of three patients who show this locational variability of initial EEG change in different network components of the medial temporal lobe/limbic network, the occipital/temporal network, and the superior parietal/medial frontal network, visualized only because we were able to record with electrodes implanted into multiple network sites. Four consecutive 10-s intervals of two spontaneous seizures with identical clinical expression in a patient with the medial temporal limbic network are shown in 1, 2. The patient had febrile seizures and then onset of uncontrolled complex partial seizures characterized by staring and right-hand dystonia at age 3 years. Magnetic resonance imaging (MRI) showed left hippocampal atrophy. In the first seizure, the hallmark of the medial temporal lobe/limbic network seizure onset, the periodic discharge recorded from the hippocampal depth electrode is seen. Shortly after, low-voltage fast activity and sharp theta/alpha activity are superimposed, and then low-voltage fast activity is seen in the contacts recording from the entorhinal cortex. In the second seizure from the same patient with clinically stereotyped manifestations, the hippocampal periodic spike discharge begins, but the seizure ""starts"" with low-voltage fast activity first in the entorhinal cortex, and then in the hippocampal contacts. This kind of locational and morphologic variability in the initial manifestations of the electrical seizure is extremely typical of the medial temporal/limbic network. Without the entorhinal contacts as part of the display, one would see only minor morphologic variability in the hippocampal depth electrode (or conversely, without the depth electrode recording, just in the entorhinal electrode) and have the sense of a stereotyped electrical pattern at the onset of the seizure. Consecutive 10-s intervals of a spontaneous and typical complex partial seizure in a patient with epilepsy in the medial temporal/limbic network. A–J represent multicontact implanted subdural and depth electrodes with position 1 most distal; contacts are spaced 8–10 mm apart. The seizure is heralded by the classical 1- to 2-Hz periodic spike discharge in the hippocampal depth electrode (H3–H6), on which low-voltage fast discharge at 12–20 Hz is superimposed. Within 5 s, similar low-voltage fast discharge is seen in B3–6, a subdural strip electrode recording from entorhinal cortex. Subsequently, these two nearby locations show asynchronous development of the high-frequency ictal discharge. Clinical seizure activity follows the electrical changes by nearly 30 s. Consecutive 10-s intervals of a spontaneous and typical complex partial seizure, from same patient as illustrated in Fig. 1. A–J represent multicontact implanted depth and subdural electrodes; contact 1 is most distal. Each division equals 1 s. The seizure is again heralded by 1-Hz periodic spikes seen best in hippocampal depth electrode (H3–6) but also in entorhinal cortex (B3–6). In contrast to prior illustrated seizure, low-voltage fast activity is next seen in entorhinal cortex, and only subsequently in hippocampus; both sites then continue to show fast seizure buildup before sudden cessation 30 s later. Two consecutive 10-s intervals of two spontaneous typical and clinically identical seizures (top and bottom) in a patient with epilepsy of the superior parietal/medial frontal network. B–H represent implanted, multicontact subdural electrodes; contact 1 is most distal; electrode contacts are spaced 8 mm apart. I–K represent portions of an implanted, 64-contact subdural grid over left frontotemporoparietal cortex; the grid is composed of an 8 × 8 arrangement of contacts with 10-mm intercontact spacing. In the top seizure, initial seizure manifestation is with low-voltage fast discharge recorded from superior parietal area (last channel) followed in 3 s by low-voltage fast activity in medial frontal contacts (B7). In the second (bottom) seizure, the initial low-voltage fast activity preceding the clinical seizure is seen in medial frontal cortex contacts (B5, 7) followed in 4 s by similar discharge in superior parietal contact K16 (last channel). Two consecutive 10-s intervals of two spontaneous, typical, and clinically identical seizures in a patient with epilepsy in the occipitotemporal network. A–I represent multiple implanted multicontact subdural electrodes with 8- to 10-mm intercontact spacing; contact 1 on each electrode is most distal; each division equals 1 s. J–M are parts of an 8 × 8 implanted subdural grid over parietooccipital cortex with uniform 10-mm intercontact spacing. The top seizure shows simultaneous low-voltage fast activity developing in temporal (electrodes B, D) and occipital regions (J), whereas the second seizure (bottom) shows similar ictal discharge restricted to the occipital region (J). Figure 3 shows two spontaneous seizures, each recorded from intracranial electrodes, that demonstrate the variable participatory order of the superior parietal and medial frontal regions in these two seizures with similar clinical manifestations. This patient began having seizures at age 8 years and was medically intractable immediately. Seizures were characterized by right foot and leg heaviness followed by tingling and rigidity. The positron emission tomography (PET) scan demonstrated reduction in metabolism in the left parietal lobe, and the ictal single-photon emission computed tomography (SPECT) study showed perfusion changes in both the left parietal and left frontal regions. MRI was negative. In the top illustrated seizure, the initial change is a low-voltage spike discharge, with low-voltage fast activity rapidly superimposed in the superior parietal region. About 4 s later, similar low-voltage fast activity is seen in the medial frontal recording contacts. In the bottom seizure, the initial low-voltage fast activity is clearly demonstrated in the medial frontal contacts, and only 3 s later is it seen in the superior parietal region. With intracranial electrodes in only the medial hemispheric or superior parietal area, these seizures would appear electrically identical, but there is clear locational variability of the participatory order of involvement within structures of the specific network. Figure 4 shows two spontaneous seizures with similar clinical manifestations in a patient with seizures characterized by flashing lights and complex behavior with falls. The PET scan demonstrated hypometabolism in the right temporal and occipital regions, and an ictal SPECT study showed hypoperfusion in both the right occipital and right temporal regions. In the setting of an extremely abnormal background with multifocal spike-and-wave activity, we see low-voltage fast activity first develop in the medial temporal lobe contacts in one seizure. In the other seizure, there is simultaneous activity in the temporal and occipital recording contacts. Clinical observations also support the large neural network concept of human epilepsy. Despite variability in the early electrical patterns, clinical seizures are stereotyped, a key observation that truly reflects the operation of the epilepsy network. The best examples come from the medial temporal/limbic network, where a variable, specific, medial temporal location of manifest onset is often recorded (for example, in entorhinal cortex or hippocampus or lateral temporal neocortex), but the seizures are the same clinically, because the network as a whole is responsible for the manifestations of the seizures. Another example is found in patients with the medial temporal/limbic syndrome who have bilateral, independent temporal lobe seizure onset, although seizures appear clinically indistinguishable from one another (20–22). Patients who have variable occipital and temporal or frontal and parietal onset also reflect specific networks and the variability of ictal electrical expression, and also express clinical seizures in a stereotyped way. These are all examples of entrainment from different network sites, and the whole network acting to produce the clinically stereotyped events. Variability in clinical seizures is likely to reflect propagation of seizure activity. As noted earlier, seizures can propagate variably to any and all areas unilaterally, bilaterally, cortically, or subcortically to which anatomic connections exist, but those are not necessarily part of the network that participates in the genesis and maintenance of the seizure disorder per se. An example of this difficult distinction is found in seizures that appear to originate in occipital structures and yet have variable propagation to the frontal lobes with variable frontal clinical manifestations (23–25). The frontal regions are not part of the occipital/temporal network. Functional neuroimaging, specifically PET, has been very influential in development of the network hypothesis of human epilepsy. Although propagation of seizures is distinct from the network that generates them, the question of propagation frequently arises when we are dealing with evidence that involves spontaneous seizure activity and its evolution. Observations with functional neuroimaging (specifically PET) are so important in the concept of the epileptic network because they can avoid the confounding influence of possible propagation. PET demonstrates, especially in the medial temporal/limbic network syndrome, variably extensive, often multilobar, reduced interictal metabolism involving a variety of structures. Various authors have confirmed interictal hypometabolism in ipsilateral temporal neocortex, ipsilateral hippocampus, contralateral hippocampus, inferior frontal lobe, ipsilateral dorsomedial thalamus, and amygdala (26–32). Quantitatively, the most significant hypometabolism is in the lateral temporal and medial temporal regions, followed by the medial thalamus, basal ganglia, and frontal lobe. We usually do not have the opportunity to record electrical changes in the human seizure in all of these areas, particularly the subcortical ones, which makes this kind of information particularly valuable. It is likely that the areas involved in the interictal hypometabolism in the medial temporal lobe epilepsy syndrome define the components of the medial temporal/limbic network. There has been no other satisfactory explanation for this widespread hypometabolism, aside from the network concept. The interictal hypometabolism in these areas has been such a consistent finding in this syndrome, with a sensitivity 90%, that its absence actually questions the medial temporal/limbic diagnosis. After successful (i.e., curative) surgery for medial temporal lobe epilepsy, PET scans show improvement in the hypometabolism observed preoperatively in the ipsilateral inferior frontal lobe, the ipsilateral temporal neocortex, and both thalami (32–34). Thus structural interruption of the medial temporal/limbic network results in cessation of seizures and cessation of the reverberating electrical activity that accompanied them. Anatomic data confirm the importance of the medial thalamus in medial temporal/limbic epilepsy. Volume loss is present in ipsilateral thalamus, caudate, and amygdala in medial temporal lobe epilepsy (35,36), and thalamic cell loss is present in epilepsy patients (37,38). Furthermore, hippocampal cell density is significantly correlated with the amount of reduction in metabolism in bilateral thalamus and basal ganglia (39). Functionally, also, the evidence is consistent, in that synchronous activity is seen between thalamus and hippocampus, and thalamic stimulation gives a monosynaptic excitatory response in hippocampus. Extratemporal epilepsy also is associated with multifocal, sometimes extensive, reductions in metabolism demonstrated on interictal PET studies, but this has not been as reproducible or as well documented as that in the medial temporal/limbic syndrome (29). Interestingly, despite high sensitivity to extratemporal regions of epileptogenicity, which show hypometabolism on interictal studies, PET scans are not sensitive to initial areas of seizure propagation in extratemporal epilepsy, another demonstration of the nonequivalence of network and propagation areas (29). 5, 6 are examples of interictal hypometabolism in a patient with medial temporal/limbic network epilepsy (left medial and lateral temporal, and right medial temporal hypometabolism) and a patient with occipital/temporal network epilepsy (occipital and temporal hypometabolism). 18Fluorodeoxyglucose–positron emission tomography (18FDG-PET) study demonstrates interictal hypometabolism in multiple areas (medial and lateral left temporal, medial right temporal) in a patient with epilepsy in the medial temporal/limbic network. 18Fluorodeoxyglucose–positron emission tomography (18FDG-PET) study demonstrates interictal hypometabolism in the right occipital and temporal lobes in a patient with epilepsy in the occipitotemporal network. SPECT functional neuroimaging also has helped to formulate the concepts of epileptic networks. Interictal hypoperfusion on SPECT, although present in some cases, is less sensitive than PET (40–42). The main use of SPECT is its unique ability to capture the status of blood flow at the time of seizure activity because of the lack of redistribution of the radioisotope, which is bound in the brain on its first pass. Ictal SPECT studies of patients with medial temporal lobe epilepsy, when obtained with early injections, show consistent blood-flow increases in the ipsilateral medial thalamic region as well as in the temporal structures (41–44). This is another way of demonstrating the participation of the medial thalamic region in the medial temporal lobe limbic network, and one that cannot be confirmed with usual electrode placement. Figure 7 is an image of increased blood flow in a right temporal lobe seizure obtained by subtracting interictal from ictal perfusion images and superimposing the differences onto MRI. The medial temporal/limbic network regions with increased flow include the medial temporal/hippocampal region, bilateral medial thalamus, lateral temporal neocortex, and midbrain structures. In a group of 18 patients at our center who were analyzed in this manner, we found a statistically significant increase in the perfusion measured in the medial thalamus ipsilateral to the medial temporal lobe of seizure activity. Ictal hyperperfusion has been demonstrated in multiple structures consistent with other epilepsy networks: the occipital/temporal and parietal/frontal networks. In Figure 8, another ictal SPECT difference image demonstrates occipital and temporal regions of increased perfusion. Figure 9 is a similar depiction of the regions of ictal hyperperfusion in the superior parietal/medial frontal network. Ictal [99Tc]-HMPAO-SPECT subtraction image obtained by injection of HMPAO early during a right temporal seizure. A normalized interictal study was digitally subtracted from the ictal study, and differences were coregistered to magnetic resonance imaging for anatomic detail. Percentage increase in perfusion was calculated in those areas identified as showing significant perfusion changes, in this case, in the right temporal neocortex and hippocampus, both thalami, and bilateral midbrain reticular formation. Ictal single-photon emission computed tomography subtraction images, obtained by subtraction, normalization, and coregistration (see earlier figures), show temporal and occipital areas of increased perfusion in a patient with epilepsy in the occipitotemporal network. Ictal single-photon emission computed tomography subtraction image, obtained by subtraction, normalization, and coregistration, shows multiple areas of perfusion increase in parietal and frontal lobes in a patient with epilepsy in the superior parietal/medial frontal network. The response of uncontrolled seizures to invasive therapy is a final line of evidence that supports the existence of human epilepsy networks, and that also leads to novel approaches to diagnosis, treatment, and even prediction of seizures. If human epilepsy is the expression of specific, abnormally active, intrinsically defined and connected cortical/subcortical/bilateral networks, then one could theoretically alter seizure expression by intervening in any part of the specific network. This reasoning grows from the corollaries presented earlier, indicating that any structural, metabolic, electrical, or chemical modification of the network, in any region, would alter the expression or frequency of seizure activity. Consider observations on the outcome of surgical treatment of uncontrolled medial temporal lobe epilepsy. Published reports document 60–90% excellent response, meaning cessation of seizures, after any kind or extent of temporal lobe resection in patients identified as having medial temporal lobe epilepsy. Operations involving anterior temporal lobe, medial structures only, lateral structures only, or more or less extensive lateral temporal resection can cure this disorder. Procedures with no anatomic overlap are similarly successful (45–47). This cannot be explained unless the multiple areas are all critical in the production of the intractable seizures of this disorder. Then interruption of the network in any one of those areas would be (and apparently is) sufficient to alter the seizures. The similarly excellent response with cessation of seizures after temporal lobe resection in well-selected patients who have bilateral independent medial temporal lobe origin of seizures is another example of the existence of a network, interference with which at any site alters the expression of the intractable seizures (20,21). Disconnection can be considered an intervention that targets an epilepsy network, for example, corpus callosum section or multiple subpial transection. Both of these procedures reduce frequency and intensity of generalized and partial seizures in many, but not all, patients, and either procedure can (rarely) stop seizures entirely (48–52). This suggests that the surgery interferes with the mode of seizure generation, although the procedure is not targeted specifically to one area from which seizures ""arise."" The result is explainable only by the existence of intrinsic networks, which are structurally disrupted. So far, electrical stimulation as a treatment for epilepsy has been used in a nontargeted way. The stimulation has been (presumably) directed at subcortical structures in common regions, independent of our knowledge of which cortical areas are involved. Prolonged stimulation of the centromedian nucleus reduces or controls generalized seizures, and prolonged intermittent vagal nerve stimulation (VNS) reduces seizure frequency by up to 50% in about half the patients to whom it is applied (53–55). VNS-induced reduction in thalamic blood flow (bilaterally) is correlated with the degree of seizure reduction (56). These results imply that subcortical structures are key to the manifestation of partial seizures, supporting the contention that specific subcortical regions are part of specific epilepsy networks. The targeted subcortical structures affected by stimulation may be part of the network in those individuals who respond the best to these various, ""nontargeted,"" stimulation therapies. What are the implications of these observations? These ideas question the very concepts of epileptogenic zone, irritative zone, symptomatogenic zone, and ictal-onset zone. Our evaluation of refractory epilepsy patients should use studies that define the epilepsy network (specifically PET, functional MRI) rather than (or at least in addition to) studies that are targeted at the region of ""seizure onset"" like EEG. It may be pertinent to consider study of other kinds of phenomena in individual patients, which may define the network in better terms than we have sought in the past because of our single-minded attention to defining regions of so-called seizure onset. For example, quantitative intracranial EEG analysis, background patterns, sleep effects on interictal and ictal activity, and other types of functional assessments may contribute considerably to our understanding of the role of networks in the expression of the epilepsies. Studying broad regions of brain structures related by the presence of such networks, using quantitative EEG analyses and sophisticated approaches, may detect alterations in the behavior of the network before the more traditional ""seizure discharge"" is seen, and allow prediction of seizures before manifestation clinically or on traditional EEG. These kinds of data may have significant applicability to development of further therapy, in epilepsy and in other neurologic diseases as well. Broadly applied treatment (directed at any region of the network) should theoretically be just as effective as treatments directed at a specific ""focus"" of seizure activity. We have seen that this may be true in the application of VNS, thalamic stimulation, and other relatively nontargeted interventions for the treatment of uncontrolled localization-related epilepsy. This approach opens the door to directing surgical therapy to a region with the least likely functional consequences, as long as it is in the network. It also means that our patient-evaluation procedures could be revamped entirely. Cost and risk of this kind of evaluation might be considerably less than we It also should be possible to develop new approaches to treatment approaches on our knowledge of network components and The specific for example, in regions of the network might allow to truly therapy or to or of we to others because of their participation in an epileptic network. Based on knowledge we already from of patient evaluation and studies, we to about human localization-related epilepsy and seizures in a different and use that new to the"
https://openalex.org/W2407776548,Recurrent Neural Network for Text Classification with Multi-Task Learning,"{'Neural': [0], 'network': [1, 76], 'based': [2, 25], 'methods': [3], 'have': [4], 'obtained': [5], 'great': [6], 'progress': [7], 'on': [8, 26, 54, 80, 85], 'a': [9, 101], 'variety': [10], 'of': [11, 63, 100, 106], 'natural': [12], 'language': [13], 'processing': [14], 'tasks.': [15, 52, 83, 109], 'However,': [16], 'in': [17], 'most': [18], 'previous': [19], 'works,': [20], 'the': [21, 42, 98, 104], 'models': [22, 95], 'are': [23], 'learned': [24], 'single-task': [27], 'supervised': [28], 'objectives,': [29], 'which': [30], 'often': [31], 'suffer': [32], 'from': [33], 'insufficient': [34], 'training': [35], 'data.': [36], 'In': [37], 'this': [38], 'paper,': [39], 'we': [40, 58], 'use': [41], 'multi-task': [43], 'learning': [44], 'framework': [45], 'to': [46, 66], 'jointly': [47, 79], 'learn': [48], 'across': [49], 'multiple': [50], 'related': [51, 108], 'Based': [53], 'recurrent': [55], 'neural': [56], 'network,': [57], 'propose': [59], 'three': [60], 'different': [61], 'mechanisms': [62], 'sharing': [64], 'information': [65], 'model': [67], 'text': [68, 88], 'with': [69, 103], 'task-specific': [70], 'and': [71], 'shared': [72], 'layers.': [73], 'The': [74], 'entire': [75], 'is': [77], 'trained': [78], 'all': [81], 'these': [82], 'Experiments': [84], 'four': [86], 'benchmark': [87], 'classification': [89], 'tasks': [90], 'show': [91], 'that': [92], 'our': [93], 'proposed': [94], 'can': [96], 'improve': [97], 'performance': [99], 'task': [102], 'help': [105], 'other': [107]}",2016,"['Computer science', 'Task (project management)', 'Variety (cybernetics)', 'Benchmark (surveying)', 'Artificial intelligence', 'Machine learning', 'Artificial neural network', 'Recurrent neural network', 'Multi-task learning', 'Natural language processing', 'Economics', 'Geodesy', 'Management', 'Geography']","Neural network based methods have obtained great progress on a variety of natural language processing tasks. However, in most previous works, the models are learned based on single-task supervised objectives, which often suffer from insufficient training data. In this paper, we use the multi-task learning framework to jointly learn across multiple related tasks. Based on recurrent neural network, we propose three different mechanisms of sharing information to model text with task-specific and shared layers. The entire network is trained jointly on all these tasks. Experiments on four benchmark text classification tasks show that our proposed models can improve the performance of a task with the help of other related tasks."
https://openalex.org/W4383218913,Accurate medium-range global weather forecasting with 3D neural networks,"{'Abstract': [0], 'Weather': [1, 165], 'forecasting': [2, 61, 157], 'is': [3, 16, 48, 70, 193], 'important': [4], 'for': [5, 85, 163], 'science': [6], 'and': [7, 30, 111, 179], 'society.': [8], 'At': [9], 'present,': [10], 'the': [11, 17, 38, 67, 149, 154, 160, 187], 'most': [12], 'accurate': [13], 'forecast': [14, 68, 137], 'system': [15, 158], 'numerical': [18], 'weather': [19, 60, 89, 109, 177], 'prediction': [20], '(NWP)': [21], 'method,': [22], 'which': [23], 'represents': [24], 'atmospheric': [25], 'states': [26, 42], 'as': [27], 'discretized': [28], 'grids': [29], 'numerically': [31], 'solves': [32], 'partial': [33], 'differential': [34], 'equations': [35], 'that': [36, 75, 93, 112, 197], 'describe': [37], 'transition': [39], 'between': [40], 'those': [41], '1': [43], '.': [44, 169], 'However,': [45], 'this': [46], 'procedure': [47], 'computationally': [49], 'expensive.': [50], 'Recently,': [51], 'artificial-intelligence-based': [52, 83], 'methods': [53], '2': [54], 'have': [55], 'shown': [56], 'potential': [57], 'in': [58, 108, 121, 142], 'accelerating': [59], 'by': [62], 'orders': [63], 'of': [64, 76, 128, 159, 189, 198], 'magnitude,': [65], 'but': [66], 'accuracy': [69, 188], 'still': [71], 'significantly': [72], 'lower': [73], 'than': [74, 196], 'NWP': [77, 152], 'methods.': [78], 'Here': [79], 'we': [80], 'introduce': [81], 'an': [82], 'method': [84, 171], 'accurate,': [86], 'medium-range': [87, 122], 'global': [88, 129], 'forecasting.': [90, 123], 'We': [91], 'show': [92], 'three-dimensional': [94], 'deep': [95], 'networks': [96], 'equipped': [97], 'with': [98, 105, 148, 175, 184], 'Earth-specific': [99], 'priors': [100], 'are': [101], 'effective': [102], 'at': [103], 'dealing': [104], 'complex': [106], 'patterns': [107], 'data,': [110, 130, 186], 'a': [113], 'hierarchical': [114], 'temporal': [115], 'aggregation': [116], 'strategy': [117], 'reduces': [118], 'accumulation': [119], 'errors': [120], 'Trained': [124], 'on': [125, 139], '39': [126], 'years': [127], 'our': [131], 'program,': [132], 'Pangu-Weather,': [133], 'obtains': [134], 'stronger': [135], 'deterministic': [136], 'results': [138], 'reanalysis': [140, 185], 'data': [141], 'all': [143], 'tested': [144], 'variables': [145], 'when': [146], 'compared': [147], 'world’s': [150], 'best': [151], 'system,': [153], 'operational': [155], 'integrated': [156], 'European': [161], 'Centre': [162], 'Medium-Range': [164], 'Forecasts': [166], '(ECMWF)': [167], '3': [168], 'Our': [170], 'also': [172, 194], 'works': [173], 'well': [174], 'extreme': [176], 'forecasts': [178], 'ensemble': [180], 'forecasts.': [181], 'When': [182], 'initialized': [183], 'tracking': [190], 'tropical': [191], 'cyclones': [192], 'higher': [195], 'ECMWF-HRES.': [199]}",2023,"['Numerical weather prediction', 'Global Forecast System', 'Weather forecasting', 'Meteorology', 'Tropical cyclone forecast model', 'Range (aeronautics)', 'North American Mesoscale Model', 'Computer science', 'Model output statistics', 'Artificial neural network', 'Weather prediction', 'Probabilistic forecasting', 'Discretization', 'Environmental science', 'Artificial intelligence', 'Geography', 'Mathematics', 'Probabilistic logic', 'Mathematical analysis', 'Materials science', 'Composite material']","Abstract Weather forecasting is important for science and society. At present, the most accurate forecast system is the numerical weather prediction (NWP) method, which represents atmospheric states as discretized grids and numerically solves partial differential equations that describe the transition between those states 1 . However, this procedure is computationally expensive. Recently, artificial-intelligence-based methods 2 have shown potential in accelerating weather forecasting by orders of magnitude, but the forecast accuracy is still significantly lower than that of NWP methods. Here we introduce an artificial-intelligence-based method for accurate, medium-range global weather forecasting. We show that three-dimensional deep networks equipped with Earth-specific priors are effective at dealing with complex patterns in weather data, and that a hierarchical temporal aggregation strategy reduces accumulation errors in medium-range forecasting. Trained on 39 years of global data, our program, Pangu-Weather, obtains stronger deterministic forecast results on reanalysis data in all tested variables when compared with the world’s best NWP system, the operational integrated forecasting system of the European Centre for Medium-Range Weather Forecasts (ECMWF) 3 . Our method also works well with extreme weather forecasts and ensemble forecasts. When initialized with reanalysis data, the accuracy of tracking tropical cyclones is also higher than that of ECMWF-HRES."
https://openalex.org/W2251124635,Adaptive Recursive Neural Network for Target-dependent Twitter Sentiment Classification,"{'We': [0], 'propose': [1], 'Adaptive': [2], 'Recursive': [3], 'Neural': [4], 'Network': [5], '(AdaRNN)': [6], 'for': [7, 64], 'target-dependent': [8, 65], 'Twitter': [9, 66], 'sentiment': [10, 41, 67], 'classification.AdaRNN': [11], 'adaptively': [12], 'propagates': [13], 'the': [14, 22, 39, 55], 'sentiments': [15], 'of': [16, 30], 'words': [17], 'to': [18], 'target': [19], 'depending': [20], 'on': [21], 'context': [23], 'and': [24, 36], 'syntactic': [25], 'relationships': [26], 'between': [27], 'them.It': [28], 'consists': [29], 'more': [31], 'than': [32], 'one': [33], 'composition': [34, 47], 'functions,': [35], 'we': [37, 58], 'model': [38], 'adaptive': [40], 'propagations': [42], 'as': [43], 'distributions': [44], 'over': [45], 'these': [46], 'functions.The': [48], 'experimental': [49], 'studies': [50], 'illustrate': [51], 'that': [52], 'AdaRNN': [53], 'improves': [54], 'baseline': [56], 'methods.Furthermore,': [57], 'introduce': [59], 'a': [60], 'manually': [61], 'annotated': [62], 'dataset': [63], 'analysis.': [68]}",2014,"['Computer science', 'Sentiment analysis', 'Artificial neural network', 'Artificial intelligence', 'Machine learning']","We propose Adaptive Recursive Neural Network (AdaRNN) for target-dependent Twitter sentiment classification.AdaRNN adaptively propagates the sentiments of words to target depending on the context and syntactic relationships between them.It consists of more than one composition functions, and we model the adaptive sentiment propagations as distributions over these composition functions.The experimental studies illustrate that AdaRNN improves the baseline methods.Furthermore, we introduce a manually annotated dataset for target-dependent Twitter sentiment analysis."
https://openalex.org/W2808168148,Soft Filter Pruning for Accelerating Deep Convolutional Neural Networks,"{'This': [0], 'paper': [1], 'proposed': [2, 22], 'a': [3, 73], 'Soft': [4], 'Filter': [5], 'Pruning': [6], '(SFP)': [7], 'method': [8, 71], 'to': [9, 28, 63, 77, 94, 119], 'accelerate': [10], 'the': [11, 21, 25, 33, 61, 66, 80, 87, 100, 113, 116, 128, 165], 'inference': [12], 'procedure': [13], 'of': [14, 115], 'deep': [15], 'Convolutional': [16], 'Neural': [17], 'Networks': [18], '(CNNs).': [19], 'Specifically,': [20], 'SFP': [23, 37, 93, 124, 148], 'enables': [24, 92], 'pruned': [26, 50], 'filters': [27, 51, 62], 'be': [29, 110], 'updated': [30], 'when': [31], 'training': [32, 81], 'model': [34, 46, 75, 101, 118], 'after': [35], 'pruning.': [36], 'has': [38, 72, 136, 163], 'two': [39], 'advantages': [40], 'over': [41], 'previous': [42, 105, 129], 'works:': [43], '(1)': [44], 'Larger': [45], 'capacity.': [47], 'Updating': [48], 'previously': [49], 'provides': [52], 'our': [53, 70, 134], 'approach': [54, 135], 'with': [55, 156], 'larger': [56, 74], 'optimization': [57], 'space': [58], 'than': [59, 151], 'fixing': [60], 'zero.': [64], 'Therefore,': [65], 'network': [67], 'trained': [68], 'by': [69], 'capacity': [76, 91], 'learn': [78], 'from': [79, 96, 125], 'data.': [82], '(2)': [83], 'Less': [84], 'dependence': [85], 'on': [86, 112, 146, 154, 171], 'pretrained': [88], 'model.': [89], 'Large': [90], 'train': [95], 'scratch': [97, 126], 'and': [98], 'prune': [99], 'simultaneously.': [102], 'In': [103], 'contrast,': [104], 'filter': [106, 130], 'pruning': [107, 131], 'methods': [108], 'should': [109], 'conducted': [111], 'basis': [114], 'pre-trained': [117], 'guarantee': [120], 'their': [121], 'performance.': [122], 'Empirically,': [123], 'outperforms': [127], 'methods.': [132], 'Moreover,': [133], 'been': [137], 'demonstrated': [138], 'effective': [139], 'for': [140], 'many': [141], 'advanced': [142, 164], 'CNN': [143], 'architectures.': [144], 'Notably,': [145], 'ILSCRC-2012,': [147], 'reduces': [149], 'more': [150], '42%': [152], 'FLOPs': [153], 'ResNet-101': [155], 'even': [157], '0.2%': [158], 'top-5': [159], 'accuracy': [160], 'improvement,': [161], 'which': [162], 'state-of-the-art.': [166], 'Code': [167], 'is': [168], 'publicly': [169], 'available': [170], 'GitHub:': [172], 'https://github.com/he-y/softfilter-pruning': [173]}",2018,"['Pruning', 'Computer science', 'Convolutional neural network', 'Filter (signal processing)', 'Artificial intelligence', 'FLOPS', 'Inference', 'Machine learning', 'Code (set theory)', 'Deep learning', 'Artificial neural network', 'Pattern recognition (psychology)', 'Parallel computing', 'Computer vision', 'Biology', 'Agronomy', 'Programming language', 'Set (abstract data type)']","This paper proposed a Soft Filter Pruning (SFP) method to accelerate the inference procedure of deep Convolutional Neural Networks (CNNs). Specifically, the proposed SFP enables the pruned filters to be updated when training the model after pruning. SFP has two advantages over previous works: (1) Larger model capacity. Updating previously pruned filters provides our approach with larger optimization space than fixing the filters to zero. Therefore, the network trained by our method has a larger model capacity to learn from the training data. (2) Less dependence on the pretrained model. Large capacity enables SFP to train from scratch and prune the model simultaneously. In contrast, previous filter pruning methods should be conducted on the basis of the pre-trained model to guarantee their performance. Empirically, SFP from scratch outperforms the previous filter pruning methods. Moreover, our approach has been demonstrated effective for many advanced CNN architectures. Notably, on ILSCRC-2012, SFP reduces more than 42% FLOPs on ResNet-101 with even 0.2% top-5 accuracy improvement, which has advanced the state-of-the-art. Code is publicly available on GitHub: https://github.com/he-y/softfilter-pruning"
https://openalex.org/W2621826044,Spatio-Temporal Backpropagation for Training High-Performance Spiking Neural Networks,"{'Spiking': [0], 'neural': [1, 24], 'networks': [2, 25], '(SNNs)': [3], 'are': [4, 12, 60], 'promising': [5], 'in': [6, 57, 95], 'ascertaining': [7], 'brain-like': [8, 218], 'behaviors': [9], 'since': [10], 'spikes': [11], 'capable': [13], 'of': [14, 39, 74, 98, 121], 'encoding': [15], 'spatio-temporal': [16, 106, 223], 'information.': [17], 'Recent': [18], 'schemes,': [19], 'e.g.,': [20], 'pre-training': [21], 'from': [22], 'artificial': [23], '(ANNs)': [26], 'or': [27], 'direct': [28], 'training': [29, 38, 75, 97, 111], 'based': [30], 'on': [31, 49, 173, 202], 'backpropagation': [32, 107], '(BP),': [33], 'make': [34], 'the': [35, 55, 69, 86, 118, 141, 147, 167, 174, 184, 194, 213], 'high-performance': [36, 112, 214], 'supervised': [37, 96], 'SNNs': [40, 215], 'possible.': [41], 'However,': [42], 'these': [43], 'methods': [44], 'primarily': [45], 'fasten': [46], 'more': [47, 93], 'attention': [48], 'its': [50], 'spatial': [51, 143], 'domain': [52, 59, 144, 150], 'information,': [53], 'and': [54, 72, 146, 152, 170, 183], 'dynamics': [56], 'temporal': [58, 149], 'attached': [61], 'less': [62], 'significance.': [63], 'Consequently,': [64], 'this': [65, 101, 162], 'might': [66], 'lead': [67], 'to': [68, 116, 211], 'performance': [70], 'bottleneck,': [71], 'scores': [73], 'techniques': [76], 'shall': [77], 'be': [78], 'additionally': [79], 'required.': [80], 'Another': [81], 'underlying': [82], 'problem': [83, 120], 'is': [84, 89, 129], 'that': [85, 190], 'spike': [87, 127], 'activity': [88, 128], 'naturally': [90], 'non-differentiable,': [91], 'raising': [92], 'difficulties': [94], 'SNNs.': [99, 113], 'In': [100, 114], 'paper,': [102], 'we': [103], 'propose': [104], 'a': [105, 178, 208], '(STBP)': [108], 'algorithm': [109, 139], 'for': [110, 126, 133, 216], 'order': [115], 'solve': [117], 'non-differentiable': [119], 'SNNs,': [122], 'an': [123], 'approximated': [124], 'derivative': [125], 'proposed,': [130], 'being': [131], 'appropriate': [132], 'gradient': [134], 'descent': [135], 'training.': [136], 'The': [137], 'STBP': [138], 'combines': [140], 'layer-by-layer': [142], '(SD)': [145], 'timing-dependent': [148], '(TD),': [151], 'does': [153], 'not': [154], 'require': [155], 'any': [156], 'additional': [157], 'complicated': [158], 'skill.': [159], 'We': [160], 'evaluate': [161], 'method': [163], 'through': [164], 'adopting': [165], 'both': [166], 'fully': [168], 'connected': [169], 'convolutional': [171], 'architecture': [172], 'static': [175], 'MNIST': [176], 'dataset,': [177, 182], 'custom': [179], 'object': [180], 'detection': [181], 'dynamic': [185], 'N-MNIST': [186], 'dataset.': [187], 'Results': [188], 'bespeak': [189], 'our': [191], 'approach': [192], 'achieves': [193], 'best': [195], 'accuracy': [196], 'compared': [197], 'with': [198, 221], 'existing': [199], 'state-of-the-art': [200], 'algorithms': [201], 'spiking': [203], 'networks.': [204], 'This': [205], 'work': [206], 'provides': [207], 'new': [209], 'perspective': [210], 'investigate': [212], 'future': [217], 'computing': [219], 'paradigm': [220], 'rich': [222], 'dynamics.': [224]}",2018,"['MNIST database', 'Computer science', 'Backpropagation', 'Artificial intelligence', 'Convolutional neural network', 'Spiking neural network', 'Gradient descent', 'Artificial neural network', 'Pattern recognition (psychology)', 'Machine learning', 'Domain (mathematical analysis)', 'Mathematical analysis', 'Mathematics']","Spiking neural networks (SNNs) are promising in ascertaining brain-like behaviors since spikes are capable of encoding spatio-temporal information. Recent schemes, e.g., pre-training from artificial neural networks (ANNs) or direct training based on backpropagation (BP), make the high-performance supervised training of SNNs possible. However, these methods primarily fasten more attention on its spatial domain information, and the dynamics in temporal domain are attached less significance. Consequently, this might lead to the performance bottleneck, and scores of training techniques shall be additionally required. Another underlying problem is that the spike activity is naturally non-differentiable, raising more difficulties in supervised training of SNNs. In this paper, we propose a spatio-temporal backpropagation (STBP) algorithm for training high-performance SNNs. In order to solve the non-differentiable problem of SNNs, an approximated derivative for spike activity is proposed, being appropriate for gradient descent training. The STBP algorithm combines the layer-by-layer spatial domain (SD) and the timing-dependent temporal domain (TD), and does not require any additional complicated skill. We evaluate this method through adopting both the fully connected and convolutional architecture on the static MNIST dataset, a custom object detection dataset, and the dynamic N-MNIST dataset. Results bespeak that our approach achieves the best accuracy compared with existing state-of-the-art algorithms on spiking networks. This work provides a new perspective to investigate the high-performance SNNs for future brain-like computing paradigm with rich spatio-temporal dynamics."
https://openalex.org/W2419448466,ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation,"{'The': [0], 'ability': [1], 'to': [2, 71, 88], 'perform': [3], 'pixel-wise': [4], 'semantic': [5], 'segmentation': [6], 'in': [7, 13], 'real-time': [8], 'is': [9, 69], 'of': [10, 27, 32, 117, 124], 'paramount': [11], 'importance': [12], 'mobile': [14], 'applications.': [15], 'Recent': [16], 'deep': [17, 51], 'neural': [18, 52, 58], 'networks': [19], 'aimed': [20], 'at': [21], 'this': [22, 45], 'task': [23], 'have': [24, 37, 92], 'the': [25, 110, 125], 'disadvantage': [26], 'requiring': [28, 64], 'a': [29, 49, 118], 'large': [30], 'number': [31], 'floating': [33], 'point': [34], 'operations': [35], 'and': [36, 82, 98, 101, 109, 114, 131], 'long': [38], 'run-times': [39], 'that': [40, 136], 'hinder': [41], 'their': [42], 'usability.': [43], 'In': [44], 'paper,': [46], 'we': [47], 'propose': [48], 'novel': [50], 'network': [53], 'architecture': [54, 127], 'named': [55], 'ENet': [56, 68, 139], '(efficient': [57], 'network),': [59], 'created': [60], 'specifically': [61], 'for': [62], 'tasks': [63], 'low': [65], 'latency': [66], 'operation.': [67], 'up': [70], '18$\\times$': [72], 'faster,': [73], 'requires': [74], '75$\\times$': [75], 'less': [76, 80], 'FLOPs,': [77], 'has': [78], '79$\\times$': [79], 'parameters,': [81], 'provides': [83], 'similar': [84], 'or': [85], 'better': [86], 'accuracy': [87, 113], 'existing': [89, 106], 'models.': [90], 'We': [91, 120], 'tested': [93], 'it': [94], 'on': [95, 103, 128], 'CamVid,': [96], 'Cityscapes': [97], 'SUN': [99], 'datasets': [100], 'report': [102], 'comparisons': [104], 'with': [105], 'state-of-the-art': [107], 'methods,': [108], 'trade-offs': [111], 'between': [112], 'processing': [115], 'time': [116], 'network.': [119], 'present': [121], 'performance': [122], 'measurements': [123], 'proposed': [126], 'embedded': [129], 'systems': [130], 'suggest': [132], 'possible': [133], 'software': [134], 'improvements': [135], 'could': [137], 'make': [138], 'even': [140], 'faster.': [141]}",2016,"['Computer science', 'Artificial neural network', 'Segmentation', 'Deep neural networks', 'FLOPS', 'Artificial intelligence', 'Architecture', 'Usability', 'Network architecture', 'Deep learning', 'Latency (audio)', 'Real-time computing', 'Parallel computing', 'Telecommunications', 'Art', 'Human–computer interaction', 'Visual arts', 'Computer security']","The ability to perform pixel-wise semantic segmentation in real-time is of paramount importance in mobile applications. Recent deep neural networks aimed at this task have the disadvantage of requiring a large number of floating point operations and have long run-times that hinder their usability. In this paper, we propose a novel deep neural network architecture named ENet (efficient neural network), created specifically for tasks requiring low latency operation. ENet is up to 18$\times$ faster, requires 75$\times$ less FLOPs, has 79$\times$ less parameters, and provides similar or better accuracy to existing models. We have tested it on CamVid, Cityscapes and SUN datasets and report on comparisons with existing state-of-the-art methods, and the trade-offs between accuracy and processing time of a network. We present performance measurements of the proposed architecture on embedded systems and suggest possible software improvements that could make ENet even faster."
https://openalex.org/W2244142460,Going deeper in facial expression recognition using deep neural networks,"{'Automated': [0], 'Facial': [1], 'Expression': [2], 'Recognition': [3], '(FER)': [4], 'has': [5], 'remained': [6], 'a': [7, 60, 64, 84, 118], 'challenging': [8], 'and\\ninteresting': [9], 'problem.': [10], 'Despite': [11], 'efforts': [12], 'made': [13], 'in': [14, 33, 179], 'developing': [15], 'various': [16], 'methods': [17, 171], 'for\\nFER,': [18], 'existing': [19], 'approaches': [20], 'traditionally': [21], 'lack': [22], 'generalizability': [23], 'when': [24, 75], 'applied': [25, 78], 'to\\nunseen': [26], 'images': [27, 125], 'or': [28, 63, 137, 166], 'those': [29], 'that': [30], 'are': [31, 40, 53, 72, 77, 163], 'captured': [32], 'wild': [34], 'setting.': [35], 'Most': [36], 'of': [37, 67, 102, 161], 'the': [38, 70, 91, 127, 138, 169], 'existing\\napproaches': [39], 'based': [41], 'on': [42, 144], 'engineered': [43], 'features': [44], '(e.g.': [45], 'HOG,': [46], 'LBPH,': [47], 'and': [48, 129, 157, 178], 'Gabor)': [49], 'where\\nthe': [50], ""classifier's"": [51], 'hyperparameters': [52], 'tuned': [54], 'to': [55, 79, 89, 165], 'give': [56], 'best': [57], 'recognition': [58], 'accuracies\\nacross': [59], 'single': [61, 119], 'database,': [62], 'small': [65], 'collection': [66], 'similar': [68], 'databases.\\nNevertheless,': [69], 'results': [71, 160], 'not': [73], 'significant': [74], 'they': [76], 'novel\\ndata.': [80], 'This': [81], 'paper': [82], 'proposes': [83], 'deep': [85], 'neural': [86, 176], 'network': [87, 116], 'architecture': [88, 121], 'address': [90], 'FER\\nproblem': [92], 'across': [93], 'multiple': [94], 'well-known': [95], 'standard': [96], 'face': [97], 'datasets.': [98], 'Specifically,': [99], 'our\\nnetwork': [100], 'consists': [101], 'two': [103], 'convolutional': [104, 175], 'layers': [105], 'each': [106], 'followed': [107], 'by': [108], 'max': [109], 'pooling': [110], 'and\\nthen': [111], 'four': [112], 'Inception': [113], 'layers.': [114], 'The': [115, 159], 'is': [117], 'component': [120], 'that\\ntakes': [122], 'registered': [123], 'facial': [124, 148], 'as': [126], 'input': [128], 'classifies': [130], 'them': [131], 'into': [132], 'either': [133], 'of\\nthe': [134], 'six': [135], 'basic': [136], 'neutral': [139], 'expressions.': [140], 'We': [141], 'conducted': [142], 'comprehensive\\nexperiments': [143], 'seven': [145], 'publically': [146], 'available': [147], 'expression': [149], 'databases,': [150], 'viz.\\nMultiPIE,': [151], 'MMI,': [152], 'CK+,': [153], 'DISFA,': [154], 'FERA,': [155], 'SFEW,': [156], 'FER2013.': [158], 'proposed\\narchitecture': [162], 'comparable': [164], 'better': [167], 'than': [168, 173], 'state-of-the-art': [170], 'and\\nbetter': [172], 'traditional': [174], 'networks': [177], 'both': [180], 'accuracy': [181], 'and\\ntraining': [182], 'time.\\n': [183]}",2016,"['Convolutional neural network', 'Computer science', 'Artificial intelligence', 'Pooling', 'Generalizability theory', 'Pattern recognition (psychology)', 'Classifier (UML)', 'Facial recognition system', 'Facial expression', 'Architecture', 'Deep learning', 'Network architecture', 'Artificial neural network', 'Facial expression recognition', 'Face (sociological concept)', 'Machine learning', 'Mathematics', 'Social science', 'Statistics', 'Sociology', 'Visual arts', 'Computer security', 'Art']","Automated Facial Expression Recognition (FER) has remained a challenging and\ninteresting problem. Despite efforts made in developing various methods for\nFER, existing approaches traditionally lack generalizability when applied to\nunseen images or those that are captured in wild setting. Most of the existing\napproaches are based on engineered features (e.g. HOG, LBPH, and Gabor) where\nthe classifier's hyperparameters are tuned to give best recognition accuracies\nacross a single database, or a small collection of similar databases.\nNevertheless, the results are not significant when they are applied to novel\ndata. This paper proposes a deep neural network architecture to address the FER\nproblem across multiple well-known standard face datasets. Specifically, our\nnetwork consists of two convolutional layers each followed by max pooling and\nthen four Inception layers. The network is a single component architecture that\ntakes registered facial images as the input and classifies them into either of\nthe six basic or the neutral expressions. We conducted comprehensive\nexperiments on seven publically available facial expression databases, viz.\nMultiPIE, MMI, CK+, DISFA, FERA, SFEW, and FER2013. The results of proposed\narchitecture are comparable to or better than the state-of-the-art methods and\nbetter than traditional convolutional neural networks and in both accuracy and\ntraining time.\n"
https://openalex.org/W1715013381,Deep Neural Networks Reveal a Gradient in the Complexity of Neural Representations across the Ventral Stream,"{'Converging': [0], 'evidence': [1], 'suggests': [2], 'that': [3, 20, 99, 105, 122], 'the': [4, 31, 35, 51, 71, 91, 94, 120, 130, 134], 'primate': [5, 135], 'ventral': [6, 32, 72, 136], 'visual': [7], 'pathway': [8, 33], 'encodes': [9], 'increasingly': [10], 'complex': [11], 'stimulus': [12, 45], 'features': [13, 46, 98], 'in': [14, 30, 129], 'downstream': [15, 68], 'areas.': [16], 'We': [17], 'quantitatively': [18], 'show': [19], 'there': [21], 'indeed': [22], 'exists': [23], 'an': [24, 85], 'explicit': [25], 'gradient': [26], 'for': [27, 112, 119], 'feature': [28], 'complexity': [29, 49], 'of': [34, 44, 47, 67, 70, 78, 88, 93, 133], 'human': [36, 81], 'brain.': [37], 'This': [38, 115], 'was': [39], 'achieved': [40], 'by': [41], 'mapping': [42], 'thousands': [43], 'increasing': [48], 'across': [50], 'cortical': [52], 'sheet': [53], 'using': [54], 'a': [55, 63, 126], 'deep': [56], 'neural': [57, 102], 'network.': [58], 'Our': [59], 'approach': [60], 'also': [61], 'revealed': [62], 'fine-grained': [64], 'functional': [65, 131], 'specialization': [66], 'areas': [69], 'stream.': [73, 137], 'Furthermore,': [74], 'it': [75], 'allowed': [76], 'decoding': [77], 'representations': [79], 'from': [80], 'brain': [82], 'activity': [83], 'at': [84], 'unsurpassed': [86], 'degree': [87], 'accuracy,': [89], 'confirming': [90], 'quality': [92], 'developed': [95], 'approach.': [96], 'Stimulus': [97], 'successfully': [100], 'explained': [101], 'responses': [103], 'indicate': [104], 'population': [106], 'receptive': [107], 'fields': [108], 'were': [109], 'explicitly': [110], 'tuned': [111], 'object': [113, 123], 'categorization.': [114], 'provides': [116], 'strong': [117], 'support': [118], 'hypothesis': [121], 'categorization': [124], 'is': [125], 'guiding': [127], 'principle': [128], 'organization': [132]}",2015,"['Categorization', 'Stimulus (psychology)', 'Neuroscience', 'Functional connectivity', 'Artificial neural network', 'Artificial intelligence', 'Cognitive neuroscience of visual object recognition', 'Computer science', 'Biology', 'Pattern recognition (psychology)', 'Psychology', 'Object (grammar)', 'Cognitive psychology']","Converging evidence suggests that the primate ventral visual pathway encodes increasingly complex stimulus features in downstream areas. We quantitatively show that there indeed exists an explicit gradient for feature complexity in the ventral pathway of the human brain. This was achieved by mapping thousands of stimulus features of increasing complexity across the cortical sheet using a deep neural network. Our approach also revealed a fine-grained functional specialization of downstream areas of the ventral stream. Furthermore, it allowed decoding of representations from human brain activity at an unsurpassed degree of accuracy, confirming the quality of the developed approach. Stimulus features that successfully explained neural responses indicate that population receptive fields were explicitly tuned for object categorization. This provides strong support for the hypothesis that object categorization is a guiding principle in the functional organization of the primate ventral stream."
https://openalex.org/W2011459128,Synchrony in Excitatory Neural Networks,"{'Synchronization': [0], 'properties': [1], 'of': [2, 6, 24, 32, 40, 76, 95, 119, 128, 144, 152, 184, 194, 208], 'fully': [3], 'connected': [4], 'networks': [5], 'identical': [7], 'oscillatory': [8], 'neurons': [9, 34, 48, 115], 'are': [10, 42, 135, 139], 'studied,': [11], 'assuming': [12], 'purely': [13], 'excitatory': [14, 64], 'interactions.': [15], 'We': [16, 107, 179], 'analyze': [17], 'their': [18], 'dependence': [19], 'on': [20, 29, 141, 191], 'the': [21, 25, 30, 33, 45, 56, 60, 70, 74, 77, 89, 132, 146, 150, 157, 170, 182, 192, 202, 206, 224], 'time': [22, 87], 'course': [23], 'synaptic': [26, 133], 'interaction': [27], 'and': [28, 156, 205, 215], 'response': [31, 118], 'to': [35, 51], 'small': [36, 52], 'depolarizations.': [37], 'Two': [38], 'types': [39, 94], 'responses': [41, 96, 127], 'distinguished.': [43], 'In': [44, 59], 'first': [46, 171], 'type,': [47, 62], 'always': [49], 'respond': [50], 'depolarization': [53], 'by': [54], 'advancing': [55], 'next': [57, 78], 'spike.': [58], 'second': [61], 'an': [63, 81], 'postsynaptic': [65], 'potential': [66], '(EPSP)': [67], 'received': [68, 83], 'after': [69], 'refractory': [71], 'period': [72], 'delays': [73], 'firing': [75], 'spike,': [79], 'while': [80], 'EPSP': [82], 'at': [84, 167, 212], 'a': [85, 117, 163], 'later': [86], 'advances': [88], 'firing.': [90], 'For': [91], 'these': [92, 185], 'two': [93, 172], 'we': [97, 200], 'derive': [98], 'general': [99], 'conditions': [100], 'under': [101], 'which': [102], 'excitation': [103, 110, 218], 'destabilizes': [104], 'in-phase': [105], 'synchrony.': [106], 'show': [108, 216], 'that': [109, 174, 197, 217], 'is': [111], 'generally': [112], 'desynchronizing': [113, 221], 'for': [114, 126, 187], 'with': [116, 169], 'type': [120, 129, 164, 176], 'I': [121, 177], 'but': [122], 'can': [123, 219], 'be': [124, 220], 'synchronizing': [125], 'II': [130, 165], 'when': [131], 'interactions': [134], 'fast.': [136], 'These': [137], 'results': [138, 186], 'illustrated': [140], 'three': [142], 'models': [143], 'neurons:': [145], 'Lapicque': [147, 203], 'integrate-and-fire': [148], 'model,': [149], 'model': [151, 204, 207], 'Connor': [153, 209], 'et': [154, 210], 'al.,': [155], 'Hodgkin-Huxley': [158], 'model.': [159], 'The': [160], 'latter': [161], 'exhibits': [162], 'response,': [166], 'variance': [168], 'models,': [173], 'have': [175], 'responses.': [178], 'then': [180], 'examine': [181], 'consequences': [183], 'large': [188, 213], 'networks,': [189], 'focusing': [190], 'states': [193], 'partial': [195], 'coherence': [196], 'emerge.': [198], 'Finally,': [199], 'study': [201], 'al.': [211], 'coupling': [214, 226], 'even': [222], 'beyond': [223], 'weak': [225], 'regime.': [227]}",1995,"['Excitatory postsynaptic potential', 'Neuroscience', 'Physics', 'Synchronizing', 'Coupling (piping)', 'Depolarization', 'Postsynaptic potential', 'Synchronization (alternating current)', 'Computer science', 'Topology (electrical circuits)', 'Inhibitory postsynaptic potential', 'Mathematics', 'Psychology', 'Chemistry', 'Biology', 'Transmission (telecommunications)', 'Biophysics', 'Combinatorics', 'Telecommunications', 'Biochemistry', 'Receptor', 'Mechanical engineering', 'Engineering']","Synchronization properties of fully connected networks of identical oscillatory neurons are studied, assuming purely excitatory interactions. We analyze their dependence on the time course of the synaptic interaction and on the response of the neurons to small depolarizations. Two types of responses are distinguished. In the first type, neurons always respond to small depolarization by advancing the next spike. In the second type, an excitatory postsynaptic potential (EPSP) received after the refractory period delays the firing of the next spike, while an EPSP received at a later time advances the firing. For these two types of responses we derive general conditions under which excitation destabilizes in-phase synchrony. We show that excitation is generally desynchronizing for neurons with a response of type I but can be synchronizing for responses of type II when the synaptic interactions are fast. These results are illustrated on three models of neurons: the Lapicque integrate-and-fire model, the model of Connor et al., and the Hodgkin-Huxley model. The latter exhibits a type II response, at variance with the first two models, that have type I responses. We then examine the consequences of these results for large networks, focusing on the states of partial coherence that emerge. Finally, we study the Lapicque model and the model of Connor et al. at large coupling and show that excitation can be desynchronizing even beyond the weak coupling regime."
https://openalex.org/W2137356002,Review on Methods to Fix Number of Hidden Neurons in Neural Networks,"{'This': [0, 58], 'paper': [1, 59], 'reviews': [2], 'methods': [3], 'to': [4, 26], 'fix': [5, 27, 67], 'a': [6, 23, 46], 'number': [7, 47], 'of': [8, 45, 48, 63, 95, 113, 149, 167], 'hidden': [9, 29, 49, 68, 150, 168], 'neurons': [10, 30, 50, 151, 169], 'in': [11, 31, 38, 152, 170], 'neural': [12, 97, 153], 'networks': [13, 33], 'for': [14, 34, 137, 146, 165], 'the': [15, 28, 61, 77, 87, 96, 101, 111, 114, 131, 147], 'past': [16], '20': [17], 'years.': [18], 'And': [19], 'it': [20], 'also': [21], 'proposes': [22, 60], 'new': [24], 'method': [25], 'Elman': [32, 171], 'wind': [35, 121, 138], 'speed': [36, 139], 'prediction': [37], 'renewable': [39], 'energy': [40], 'systems.': [41], 'The': [42, 80, 92, 123, 141, 155], 'random': [43], 'selection': [44, 102], 'might': [51], 'cause': [52], 'either': [53], 'overfitting': [54], 'or': [55], 'underfitting': [56], 'problems.': [57, 65], 'solution': [62], 'these': [64], 'To': [66, 109], 'neurons,': [69], '101': [70], 'various': [71], 'criteria': [72, 103], 'are': [73], 'tested': [74], 'based': [75, 99], 'on': [76, 100, 119], 'statistical': [78], 'errors.': [79], 'results': [81, 125], 'show': [82, 126], 'that': [83, 127], 'proposed': [84, 132, 156], 'model': [85, 157], 'improves': [86], 'accuracy': [88], 'and': [89, 163], 'minimal': [90, 161], 'error.': [91], 'perfect': [93], 'design': [94], 'network': [98], 'is': [104, 158], 'substantiated': [105], 'using': [106], 'convergence': [107], 'theorem.': [108], 'verify': [110], 'effectiveness': [112], 'model,': [115], 'simulations': [116], 'were': [117], 'conducted': [118], 'real-time': [120], 'data.': [122], 'experimental': [124], 'with': [128, 160], 'minimum': [129], 'errors': [130], 'approach': [133], 'can': [134], 'be': [135], 'used': [136], 'prediction.': [140], 'survey': [142], 'has': [143], 'been': [144], 'made': [145], 'fixation': [148, 166], 'networks.': [154, 172], 'simple,': [159], 'error,': [162], 'efficient': [164]}",2013,"['Overfitting', 'Artificial neural network', 'Computer science', 'Selection (genetic algorithm)', 'Artificial intelligence', 'Machine learning', 'Convergence (economics)', 'Simple (philosophy)', 'Fixation (population genetics)', 'Population', 'Philosophy', 'Demography', 'Sociology', 'Economics', 'Economic growth', 'Epistemology']","This paper reviews methods to fix a number of hidden neurons in neural networks for the past 20 years. And it also proposes a new method to fix the hidden neurons in Elman networks for wind speed prediction in renewable energy systems. The random selection of a number of hidden neurons might cause either overfitting or underfitting problems. This paper proposes the solution of these problems. To fix hidden neurons, 101 various criteria are tested based on the statistical errors. The results show that proposed model improves the accuracy and minimal error. The perfect design of the neural network based on the selection criteria is substantiated using convergence theorem. To verify the effectiveness of the model, simulations were conducted on real-time wind data. The experimental results show that with minimum errors the proposed approach can be used for wind speed prediction. The survey has been made for the fixation of hidden neurons in neural networks. The proposed model is simple, with minimal error, and efficient for fixation of hidden neurons in Elman networks."
https://openalex.org/W1939575207,Simultaneous feature learning and hash coding with deep neural networks,"{'Similarity-preserving': [0], 'hashing': [1, 17, 56], 'is': [2, 20, 134], 'a': [3, 24, 62, 92, 95, 107, 125], 'widely-used': [4], 'method': [5], 'for': [6, 65], 'nearest': [7], 'neighbour\\nsearch': [8], 'in': [9, 68], 'large-scale': [10], 'image': [11, 19, 104, 113, 133, 140, 150], 'retrieval': [12], 'tasks.': [13], 'For': [14], 'most': [15], 'existing': [16], 'methods,\\nan': [18], 'first': [21], 'encoded': [22], 'as': [23], 'vector': [25], 'of': [26, 82, 88, 97], 'hand-engineering': [27], 'visual': [28, 42], 'features,\\nfollowed': [29], 'by': [30], 'another': [31], 'separate': [32], 'projection': [33], 'or': [34, 168], 'quantization': [35], 'step': [36], 'that': [37, 153], 'generates\\nbinary': [38], 'codes.': [39], 'However,': [40], 'such': [41], 'feature': [43, 156], 'vectors': [44], 'may': [45], 'not': [46], 'be': [47], 'optimally\\ncompatible': [48], 'with': [49, 94], 'the': [50, 83, 111, 138, 143, 154], 'coding': [51, 160], 'process,': [52], 'thus': [53], 'producing': [54], 'sub-optimal': [55], 'codes.\\nIn': [57], 'this': [58], 'paper,': [59], 'we': [60], 'propose': [61], 'deep': [63, 78, 85], 'architecture': [64, 86], 'supervised': [66, 167], 'hashing,': [67], 'which\\nimages': [69], 'are': [70], 'mapped': [71], 'into': [72, 115], 'binary': [73], 'codes': [74], 'via': [75], 'carefully': [76], 'designed': [77, 129], 'neural\\nnetworks.': [79], 'The': [80], 'pipeline': [81, 161], 'proposed': [84], 'consists': [87], 'three\\nbuilding': [89], 'blocks:': [90], '1)': [91], 'sub-network': [93], 'stack': [96], 'convolution': [98], 'layers': [99], 'to': [100, 130, 137, 142], 'produce\\nthe': [101], 'effective': [102], 'intermediate': [103, 112], 'features;': [105], '2)': [106], 'divide-and-encode': [108], 'module': [109], 'to\\ndivide': [110], 'features': [114], 'multiple': [116], 'branches,': [117], 'each': [118], 'encoded\\ninto': [119], 'one': [120], 'hash': [121, 159], 'bit;': [122], 'and': [123, 158], '3)': [124], 'triplet': [126], 'ranking': [127], 'loss': [128], 'characterize': [131], 'that\\none': [132], 'more': [135], 'similar': [136], 'second': [139], 'than': [141], 'third': [144], 'one.': [145], 'Extensive\\nevaluations': [146], 'on': [147], 'several': [148], 'benchmark': [149], 'datasets': [151], 'show': [152], 'proposed\\nsimultaneous': [155], 'learning': [157], 'brings': [162], 'substantial\\nimprovements': [163], 'over': [164], 'other': [165], 'state-of-the-art': [166], 'unsupervised': [169], 'hashing\\nmethods.\\n': [170]}",2015,"['Feature hashing', 'Computer science', 'Hash function', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Binary code', 'Image retrieval', 'Deep learning', 'Feature vector', 'Convolutional neural network', 'Quantization (signal processing)', 'Feature extraction', 'Hash table', 'Binary number', 'Computer vision', 'Image (mathematics)', 'Double hashing', 'Mathematics', 'Computer security', 'Arithmetic']","Similarity-preserving hashing is a widely-used method for nearest neighbour\nsearch in large-scale image retrieval tasks. For most existing hashing methods,\nan image is first encoded as a vector of hand-engineering visual features,\nfollowed by another separate projection or quantization step that generates\nbinary codes. However, such visual feature vectors may not be optimally\ncompatible with the coding process, thus producing sub-optimal hashing codes.\nIn this paper, we propose a deep architecture for supervised hashing, in which\nimages are mapped into binary codes via carefully designed deep neural\nnetworks. The pipeline of the proposed deep architecture consists of three\nbuilding blocks: 1) a sub-network with a stack of convolution layers to produce\nthe effective intermediate image features; 2) a divide-and-encode module to\ndivide the intermediate image features into multiple branches, each encoded\ninto one hash bit; and 3) a triplet ranking loss designed to characterize that\none image is more similar to the second image than to the third one. Extensive\nevaluations on several benchmark image datasets show that the proposed\nsimultaneous feature learning and hash coding pipeline brings substantial\nimprovements over other state-of-the-art supervised or unsupervised hashing\nmethods.\n"
https://openalex.org/W2116453050,Partially Overlapping Neural Networks for Real and Imagined Hand Movements,"{'Neuroimagery': [0], 'findings': [1], 'have': [2], 'shown': [3], 'similar': [4], 'cerebral': [5], 'networks': [6, 27], 'associated': [7], 'with': [8, 51], 'imagination': [9, 53], 'and': [10, 54, 62, 67, 94, 99], 'execution': [11, 55], 'of': [12, 21, 116], 'a': [13, 107], 'movement.': [14], 'On': [15], 'the': [16, 35, 73, 100, 114], 'other': [17], 'hand,': [18], 'neuropsychological': [19], 'studies': [20], 'parietal-lesioned': [22], 'patients': [23], 'suggest': [24, 105], 'that': [25, 78, 106], 'these': [26], 'may': [28], 'be': [29], 'at': [30], 'least': [31], 'partly': [32], 'distinct.': [33], 'In': [34], 'present': [36], 'study,': [37], 'normal': [38], 'subjects': [39], 'were': [40, 82], 'asked': [41], 'to': [42], 'either': [43], 'imagine': [44], 'or': [45], 'execute': [46], 'auditory-cued': [47], 'hand': [48, 117], 'movements.': [49], 'Compared': [50], 'rest,': [52], 'showed': [56, 77], 'overlapping': [57], 'networks,': [58], 'including': [59, 88], 'bilateral': [60, 89], 'premotor': [61], 'parietal': [63, 97], 'areas,': [64, 98], 'basal': [65], 'ganglia': [66], 'cerebellum.': [68], 'However,': [69], 'direct': [70], 'comparison': [71], 'between': [72], 'two': [74], 'experimental': [75], 'conditions': [76], 'specific': [79, 108], 'cortico-subcortical': [80], 'areas': [81], 'more': [83], 'engaged': [84], 'in': [85, 113], 'mental': [86], 'simulation,': [87], 'premotor,': [90], 'prefrontal,': [91], 'supplementary': [92], 'motor': [93, 118], 'left': [95], 'posterior': [96], 'caudate': [101], 'nuclei.': [102], 'These': [103], 'results': [104], 'neuronal': [109], 'substrate': [110], 'is': [111], 'involved': [112], 'processing': [115], 'representations.': [119]}",2000,"['Basal ganglia', 'Neuroscience', 'Neural substrate', 'Psychology', 'Neuropsychology', 'Supplementary motor area', 'Parietal lobe', 'Cued speech', 'Premotor cortex', 'Cerebellum', 'Posterior parietal cortex', 'Movement (music)', 'Cognitive psychology', 'Functional magnetic resonance imaging', 'Central nervous system', 'Cognition', 'Anatomy', 'Medicine', 'Dorsum', 'Philosophy', 'Aesthetics']","Neuroimagery findings have shown similar cerebral networks associated with imagination and execution of a movement. On the other hand, neuropsychological studies of parietal-lesioned patients suggest that these networks may be at least partly distinct. In the present study, normal subjects were asked to either imagine or execute auditory-cued hand movements. Compared with rest, imagination and execution showed overlapping networks, including bilateral premotor and parietal areas, basal ganglia and cerebellum. However, direct comparison between the two experimental conditions showed that specific cortico-subcortical areas were more engaged in mental simulation, including bilateral premotor, prefrontal, supplementary motor and left posterior parietal areas, and the caudate nuclei. These results suggest that a specific neuronal substrate is involved in the processing of hand motor representations."
https://openalex.org/W2516574342,Towards Evaluating the Robustness of Neural Networks,"{'Neural': [0], 'networks': [1, 12, 52, 106, 122, 197], 'provide': [2], 'state-of-the-art': [3], 'results': [4], 'for': [5], 'most': [6], 'machine': [7], 'learning': [8], 'tasks.': [9], 'Unfortunately,': [10], 'neural': [11, 51, 68, 105, 121, 196], 'are': [13, 114, 128, 150], 'vulnerable': [14], 'to': [15, 30, 39, 49, 82, 88, 130, 142, 176, 194], 'adversarial': [16, 84, 144, 163, 200], 'examples:': [17], 'given': [18], 'an': [19, 66], 'input': [20, 34], '$x$': [21, 40], 'and': [22, 70, 119, 139], 'any': [23], 'target': [24], 'classification': [25], '$t$,': [26], 'it': [27, 47], 'is': [28, 37, 58], 'possible': [29], 'find': [31, 83], 'a': [32, 59, 166, 188], 'new': [33, 110], ""$x'$"": [35], 'that': [36, 63, 95, 113, 198], 'similar': [38], 'but': [41], 'classified': [42], 'as': [43, 187], '$t$.': [44], 'This': [45], 'makes': [46], 'difficult': [48], 'apply': [50], 'in': [53, 136, 165, 190], 'security-critical': [54], 'areas.': [55], 'Defensive': [56], 'distillation': [57, 97], 'recently': [60], 'proposed': [61], 'approach': [62], 'can': [64, 172], 'take': [65], 'arbitrary': [67], 'network,': [69], 'increase': [71, 101], 'its': [72], 'robustness,': [73], 'reducing': [74], 'the': [75, 102, 137], 'success': [76], 'rate': [77], 'of': [78, 104], 'current': [79], ""attacks'"": [80], 'ability': [81], 'examples': [85, 164], 'from': [86], '$95\\%$': [87], '$0.5\\%$.': [89], 'In': [90], 'this': [91], 'paper,': [92], 'we': [93, 159, 170], 'demonstrate': [94], 'defensive': [96, 178], 'does': [98], 'not': [99], 'significantly': [100], 'robustness': [103], 'by': [107], 'introducing': [108], 'three': [109, 131], 'attack': [111], 'algorithms': [112], 'successful': [115], 'on': [116], 'both': [117], 'distilled': [118], 'undistilled': [120], 'with': [123], '$100\\%$': [124], 'probability.': [125], 'Our': [126], 'attacks': [127, 149, 183], 'tailored': [129], 'distance': [132], 'metrics': [133], 'used': [134, 175, 186], 'previously': [135], 'literature,': [138], 'when': [140], 'compared': [141], 'previous': [143], 'example': [145], 'generation': [146], 'algorithms,': [147], 'our': [148, 182], 'often': [151], 'much': [152], 'more': [153], 'effective': [154], '(and': [155], 'never': [156], 'worse).': [157], 'Furthermore,': [158], 'propose': [160], 'using': [161], 'high-confidence': [162], 'simple': [167], 'transferability': [168], 'test': [169], 'show': [171], 'also': [173], 'be': [174, 185], 'break': [177], 'distillation.': [179], 'We': [180], 'hope': [181], 'will': [184], 'benchmark': [189], 'future': [191], 'defense': [192], 'attempts': [193], 'create': [195], 'resist': [199], 'examples.': [201]}",2017,"['Adversarial system', 'Artificial neural network', 'Robustness (evolution)', 'Computer science', 'Deep neural networks', 'Artificial intelligence', 'Machine learning', 'Transferability', 'Distillation', 'Gene', 'Chemistry', 'Biochemistry', 'Logit', 'Organic chemistry']","Neural networks provide state-of-the-art results for most machine learning tasks. Unfortunately, neural networks are vulnerable to adversarial examples: given an input $x$ and any target classification $t$, it is possible to find a new input $x'$ that is similar to $x$ but classified as $t$. This makes it difficult to apply neural networks in security-critical areas. Defensive distillation is a recently proposed approach that can take an arbitrary neural network, and increase its robustness, reducing the success rate of current attacks' ability to find adversarial examples from $95\%$ to $0.5\%$. In this paper, we demonstrate that defensive distillation does not significantly increase the robustness of neural networks by introducing three new attack algorithms that are successful on both distilled and undistilled neural networks with $100\%$ probability. Our attacks are tailored to three distance metrics used previously in the literature, and when compared to previous adversarial example generation algorithms, our attacks are often much more effective (and never worse). Furthermore, we propose using high-confidence adversarial examples in a simple transferability test we show can also be used to break defensive distillation. We hope our attacks will be used as a benchmark in future defense attempts to create neural networks that resist adversarial examples."
https://openalex.org/W2563786098,Deep Neural Networks for No-Reference and Full-Reference Image Quality Assessment,"{'We': [0, 129], 'present': [1], 'a': [2, 62, 69, 168, 177], 'deep': [3], 'neural': [4], 'network-based': [5], 'approach': [6, 103, 133], 'to': [7, 93, 157, 171], 'image': [8, 127, 149], 'quality': [9, 83, 92, 96, 150], 'assessment': [10], '(IQA).': [11], 'The': [12], 'network': [13], 'is': [14, 104], 'trained': [15], 'end-to-end': [16], 'and': [17, 22, 29, 74, 84, 107, 138, 153, 160], 'comprises': [18], 'ten': [19], 'convolutional': [20], 'layers': [21, 25, 33], 'five': [23], 'pooling': [24], 'for': [26, 34, 78], 'feature': [27], 'extraction,': [28], 'two': [30], 'fully': [31], 'connected': [32], 'regression,': [35], 'which': [36], 'makes': [37], 'it': [38, 57, 76], 'significantly': [39], 'deeper': [40], 'than': [41], 'related': [42], 'IQA': [43, 72, 162], 'models.': [44], 'Unique': [45], 'features': [46, 113], 'of': [47, 81, 90, 117, 180], 'the': [48, 94, 122, 131, 135, 144, 147, 181], 'proposed': [49, 132], 'architecture': [50], 'are': [51], 'that:': [52], '1)': [53], 'with': [54], 'slight': [55], 'adaptations': [56], 'can': [58], 'be': [59], 'used': [60], 'in': [61, 68, 98], 'no-reference': [63], '(NR)': [64], 'as': [65, 67, 141, 143], 'well': [66, 142], 'full-reference': [70], '(FR)': [71], 'setting': [73], '2)': [75], 'allows': [77], 'joint': [79], 'learning': [80], 'local': [82, 85, 91], 'weights,': [86], 'i.e.,': [87], 'relative': [88], 'importance': [89], 'global': [95], 'estimate,': [97], 'an': [99], 'unified': [100], 'framework.': [101], 'Our': [102], 'purely': [105], 'data-driven': [106], 'does': [108], 'not': [109], 'rely': [110], 'on': [111, 134], 'hand-crafted': [112], 'or': [114, 126], 'other': [115], 'types': [116], 'prior': [118], 'domain': [119], 'knowledge': [120], 'about': [121], 'human': [123], 'visual': [124], 'system': [125], 'statistics.': [128], 'evaluate': [130], 'LIVE,': [136], 'CISQ,': [137], 'TID2013': [139], 'databases': [140], 'LIVE': [145], 'In': [146], 'wild': [148], 'challenge': [151], 'database': [152], 'show': [154], 'superior': [155], 'performance': [156], 'state-of-the-art': [158], 'NR': [159], 'FR': [161], 'methods.': [163], 'Finally,': [164], 'cross-database': [165], 'evaluation': [166], 'shows': [167], 'high': [169, 178], 'ability': [170], 'generalize': [172], 'between': [173], 'different': [174], 'databases,': [175], 'indicating': [176], 'robustness': [179], 'learned': [182], 'features.': [183]}",2017,[],"We present a deep neural network-based approach to image quality assessment (IQA). The network is trained end-to-end and comprises ten convolutional layers and five pooling layers for feature extraction, and two fully connected layers for regression, which makes it significantly deeper than related IQA models. Unique features of the proposed architecture are that: 1) with slight adaptations it can be used in a no-reference (NR) as well as in a full-reference (FR) IQA setting and 2) it allows for joint learning of local quality and local weights, i.e., relative importance of local quality to the global quality estimate, in an unified framework. Our approach is purely data-driven and does not rely on hand-crafted features or other types of prior domain knowledge about the human visual system or image statistics. We evaluate the proposed approach on the LIVE, CISQ, and TID2013 databases as well as the LIVE In the wild image quality challenge database and show superior performance to state-of-the-art NR and FR IQA methods. Finally, cross-database evaluation shows a high ability to generalize between different databases, indicating a high robustness of the learned features."
https://openalex.org/W2144041313,Computing the stereo matching cost with a convolutional neural network,"{'We': [0, 13], 'present': [1], 'a': [2, 9, 15, 49], 'method': [3, 62, 83], 'for': [4], 'extracting': [5], 'depth': [6], 'informa-tion': [7], 'from': [8], 'rectified': [10], 'image': [11], 'pair.': [12], 'train': [14], 'convo-lutional': [16], 'neural': [17], 'network': [18], 'to': [19, 30, 53], 'predict': [20], 'how': [21], 'well': [22], 'two': [23], 'im-age': [24], 'patches': [25], 'match': [26], 'and': [27, 44, 75], 'use': [28], 'it': [29], 'compute': [31], 'the': [32, 57, 71, 80], 'stereo': [33, 61, 73], 'matching': [34], 'cost.': [35], 'The': [36], 'cost': [37, 42], 'is': [38, 76], 'refined': [39], 'by': [40, 48], 'cross-based': [41], 'aggregation': [43], 'semiglobal': [45], 'matching,': [46], 'followed': [47], 'left-right': [50], 'consistency': [51], 'check': [52], 'eliminate': [54], 'errors': [55], 'in': [56], 'occluded': [58], 'regions.': [59], 'Our': [60], 'achieves': [63], 'an': [64], 'er-ror': [65], 'rate': [66], 'of': [67], '2.61': [68], '%': [69], 'on': [70, 84], 'KITTI': [72], 'dataset': [74], 'currently': [77], '(August': [78], '2014)': [79], 'top': [81], 'performing': [82], 'this': [85], 'dataset.': [86], '1': [87]}",2015,"['Convolutional neural network', 'Artificial intelligence', 'Computer science', 'Matching (statistics)', 'Consistency (knowledge bases)', 'Computer vision', 'Word error rate', 'Artificial neural network', 'Image (mathematics)', 'Pattern recognition (psychology)', 'Mathematics', 'Statistics']","We present a method for extracting depth informa-tion from a rectified image pair. We train a convo-lutional neural network to predict how well two im-age patches match and use it to compute the stereo matching cost. The cost is refined by cross-based cost aggregation and semiglobal matching, followed by a left-right consistency check to eliminate errors in the occluded regions. Our stereo method achieves an er-ror rate of 2.61 % on the KITTI stereo dataset and is currently (August 2014) the top performing method on this dataset. 1"
https://openalex.org/W2125930537,Exact solutions to the nonlinear dynamics of learning in deep linear neural networks,"{'Despite': [0, 52], 'the': [1, 13, 28, 31, 44, 53, 71, 136, 147, 152, 173, 199, 270], 'widespread': [2], 'practical': [3], 'success': [4], 'of': [5, 12, 15, 35, 47, 55, 73, 94, 127, 139, 154, 169, 209, 224, 252, 272], 'deep': [6, 18, 36, 48, 81, 140, 176, 256], 'learning': [7, 16, 37, 41, 86, 159, 186, 238], 'methods,': [8], 'our': [9], 'theoretical': [10, 143], 'understanding': [11], 'dynamics': [14, 42, 65, 138], 'in': [17, 92, 185, 255, 264], 'neural': [19, 50], 'networks': [20, 60, 83, 177], 'remains': [21], 'quite': [22], 'sparse.': [23], 'We': [24, 78, 122, 192, 218, 240], 'attempt': [25], 'to': [26, 89, 104, 135, 189, 249], 'bridge': [27], 'gap': [29], 'between': [30], 'theory': [32], 'and': [33, 108], 'practice': [34], 'by': [38, 101, 130], 'systematically': [39], 'analyzing': [40], 'for': [43, 165], 'restricted': [45], 'case': [46], 'linear': [49, 82], 'networks.': [51, 191], 'linearity': [54], 'their': [56], 'input-output': [57], 'map,': [58], 'such': [59], 'have': [61], 'nonlinear': [62, 85, 95, 137, 257], 'gradient': [63], 'descent': [64], 'on': [66, 172, 198, 229], 'weights': [67, 230], 'that': [68, 80, 150, 243], 'change': [69], 'with': [70], 'addition': [72], 'each': [74], 'new': [75, 132, 222], 'hidden': [76], 'layer.': [77], 'show': [79, 193, 242], 'exhibit': [84, 220], 'phenomena': [87, 129], 'similar': [88], 'those': [90], 'seen': [91], 'simulations': [93], 'networks,': [96, 258], 'including': [97], 'long': [98, 260], 'plateaus': [99], 'followed': [100], 'rapid': [102], 'transitions': [103], 'lower': [105], 'error': [106], 'solutions,': [107], 'faster': [109], 'convergence': [110], 'from': [111, 118], 'greedy': [112], 'unsupervised': [113, 202, 233], 'pretraining': [114, 203], 'initial': [115, 120, 170, 210, 227, 245], 'conditions': [116, 171, 197, 228, 246], 'than': [117], 'random': [119, 214, 225], 'conditions.': [121], 'provide': [123], 'an': [124], 'analytical': [125], 'description': [126], 'these': [128, 244], 'finding': [131, 149], 'exact': [133], 'solutions': [134], 'learning.': [141], 'Our': [142], 'analysis': [144], 'also': [145, 247], 'reveals': [146], 'surprising': [148], 'as': [151, 259, 261, 269], 'depth': [153, 182, 236], 'a': [155, 166, 180, 221, 265], 'network': [156], 'approaches': [157], 'infinity,': [158], 'speed': [160, 187], 'can': [161, 204], 'nevertheless': [162], 'remain': [163], 'finite:': [164], 'special': [167, 207, 266], 'class': [168, 208, 223], 'weights,': [174], 'very': [175], 'incur': [178], 'only': [179], 'finite,': [181], 'independent,': [183], 'delay': [184], 'relative': [188], 'shallow': [190], 'that,': [194, 231], 'under': [195], 'certain': [196], 'training': [200], 'data,': [201], 'find': [205], 'this': [206], 'conditions,': [211], 'while': [212], 'scaled': [213], 'Gaussian': [215], 'initializations': [216], 'cannot.': [217], 'further': [219, 241], 'orthogonal': [226], 'like': [232], 'pre-training,': [234], 'enjoys': [235], 'independent': [237], 'times.': [239], 'lead': [248], 'faithful': [250], 'propagation': [251], 'gradients': [253], 'even': [254], 'they': [262], 'operate': [263], 'regime': [267], 'known': [268], 'edge': [271], 'chaos.': [273]}",2013,"['Nonlinear system', 'Deep learning', 'Artificial neural network', 'Computer science', 'Artificial intelligence', 'Convergence (economics)', 'Unsupervised learning', 'Gradient descent', 'Gaussian', 'Mathematics', 'Applied mathematics', 'Statistical physics', 'Physics', 'Economics', 'Quantum mechanics', 'Economic growth']","Despite the widespread practical success of deep learning methods, our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse. We attempt to bridge the gap between the theory and practice of deep learning by systematically analyzing learning dynamics for the restricted case of deep linear neural networks. Despite the linearity of their input-output map, such networks have nonlinear gradient descent dynamics on weights that change with the addition of each new hidden layer. We show that deep linear networks exhibit nonlinear learning phenomena similar to those seen in simulations of nonlinear networks, including long plateaus followed by rapid transitions to lower error solutions, and faster convergence from greedy unsupervised pretraining initial conditions than from random initial conditions. We provide an analytical description of these phenomena by finding new exact solutions to the nonlinear dynamics of deep learning. Our theoretical analysis also reveals the surprising finding that as the depth of a network approaches infinity, learning speed can nevertheless remain finite: for a special class of initial conditions on the weights, very deep networks incur only a finite, depth independent, delay in learning speed relative to shallow networks. We show that, under certain conditions on the training data, unsupervised pretraining can find this special class of initial conditions, while scaled random Gaussian initializations cannot. We further exhibit a new class of random orthogonal initial conditions on weights that, like unsupervised pre-training, enjoys depth independent learning times. We further show that these initial conditions also lead to faithful propagation of gradients even in deep nonlinear networks, as long as they operate in a special regime known as the edge of chaos."
https://openalex.org/W1479807131,Semi-Supervised Learning,"{'A': [0], 'comprehensive': [1, 95], 'review': [2], 'of': [3, 6, 14, 24, 38, 78, 97, 104, 140, 146, 157, 194, 214], 'an': [4, 155], 'area': [5], 'machine': [7, 39], 'learning': [8, 42, 50, 60, 219], 'that': [9, 164, 174], 'deals': [10], 'with': [11, 211], 'the': [12, 25, 36, 45, 105, 121, 127, 141, 144, 160, 166, 192, 199, 215], 'use': [13], 'unlabeled': [15, 83], 'data': [16, 65, 84], 'in': [17, 69, 73, 81], 'classification': [18], 'problems:': [19], 'state-of-the-art': [20, 100], 'algorithms,': [21, 101], 'a': [22, 102, 212], 'taxonomy': [23, 103], 'field,': [26, 106], 'applications,': [27, 108], 'benchmark': [28, 109, 196], 'experiments,': [29, 110], 'and': [30, 58, 91, 111, 115, 124, 136, 172, 184, 220], 'directions': [31, 204], 'for': [32, 187, 205], 'future': [33, 116], 'research.': [34, 207], 'In': [35], 'field': [37], 'learning,': [40], 'semi-supervised': [41, 218], '(SSL)': [43], 'occupies': [44], 'middle': [46], 'ground,': [47], 'between': [48, 217], 'supervised': [49], '(in': [51, 61], 'which': [52, 62, 82], 'all': [53], 'training': [54], 'examples': [55], 'are': [56, 66, 85], 'labeled)': [57], 'unsupervised': [59], 'no': [63], 'label': [64], 'given).': [67], 'Interest': [68], 'SSL': [70, 98, 147, 182, 188, 206], 'has': [71], 'increased': [72], 'recent': [74], 'years,': [75], 'particularly': [76], 'because': [77], 'application': [79], 'domains': [80], 'plentiful,': [86], 'such': [87], 'as': [88], 'images,': [89], 'text,': [90], 'bioinformatics.': [92], 'This': [93], 'first': [94, 119], 'overview': [96], 'presents': [99, 120], 'selected': [107], 'perspectives': [112], 'on': [113], 'ongoing': [114], 'research.Semi-Supervised': [117], 'Learning': [118], 'key': [122], 'assumptions': [123], 'ideas': [125], 'underlying': [126], 'field:': [128], 'smoothness,': [129], 'cluster': [130], 'or': [131], 'low-density': [132, 167], 'separation,': [133], 'manifold': [134], 'structure,': [135], 'transduction.': [137, 221], 'The': [138, 178, 208], 'core': [139], 'book': [142, 161, 179, 200, 209], 'is': [143], 'presentation': [145], 'methods,': [148, 171], 'organized': [149], 'according': [150], 'to': [151], 'algorithmic': [152], 'strategies.': [153], 'After': [154], 'examination': [156], 'generative': [158], 'models,': [159], 'describes': [162], 'algorithms': [163, 173], 'implement': [165], 'separation': [168], 'assumption,': [169], 'graph-based': [170], 'perform': [175], 'two-step': [176], 'learning.': [177], 'then': [180], 'discusses': [181], 'applications': [183], 'offers': [185], 'guidelines': [186], 'practitioners': [189], 'by': [190], 'analyzing': [191], 'results': [193], 'extensive': [195], 'experiments.': [197], 'Finally,': [198], 'looks': [201], 'at': [202], 'interesting': [203], 'closes': [210], 'discussion': [213], 'relationship': [216]}",2006,"['Computer science', 'Artificial intelligence', 'Machine learning', 'Benchmark (surveying)', 'Field (mathematics)', 'Unsupervised learning', 'Semi-supervised learning', 'Graph', 'Taxonomy (biology)', 'Theoretical computer science', 'Mathematics', 'Pure mathematics', 'Biology', 'Geodesy', 'Botany', 'Geography']","A comprehensive review of an area of machine learning that deals with the use of unlabeled data in classification problems: state-of-the-art algorithms, a taxonomy of the field, applications, benchmark experiments, and directions for future research. In the field of machine learning, semi-supervised learning (SSL) occupies the middle ground, between supervised learning (in which all training examples are labeled) and unsupervised learning (in which no label data are given). Interest in SSL has increased in recent years, particularly because of application domains in which unlabeled data are plentiful, such as images, text, and bioinformatics. This first comprehensive overview of SSL presents state-of-the-art algorithms, a taxonomy of the field, selected applications, benchmark experiments, and perspectives on ongoing and future research.Semi-Supervised Learning first presents the key assumptions and ideas underlying the field: smoothness, cluster or low-density separation, manifold structure, and transduction. The core of the book is the presentation of SSL methods, organized according to algorithmic strategies. After an examination of generative models, the book describes algorithms that implement the low-density separation assumption, graph-based methods, and algorithms that perform two-step learning. The book then discusses SSL applications and offers guidelines for SSL practitioners by analyzing the results of extensive benchmark experiments. Finally, the book looks at interesting directions for SSL research. The book closes with a discussion of the relationship between semi-supervised learning and transduction."
https://openalex.org/W2136504847,Semi-Supervised Learning Literature Survey,"{'We': [0], 'review': [1], 'the': [2, 47, 53, 58, 64, 68, 72], 'literature': [3], 'on': [4, 27], 'semi-supervised': [5, 38], 'learning,': [6], 'which': [7], 'is': [8, 42], 'an': [9], 'area': [10], 'in': [11, 67], 'machine': [12], 'learning': [13], 'and': [14, 34], 'more': [15], 'generally,': [16], 'artificial': [17], 'intelligence.': [18], 'There': [19], 'has': [20], 'been': [21], 'a': [22, 43], 'whole&#13;\\nspectrum': [23], 'of': [24], 'interesting': [25], 'ideas': [26], 'how': [28], 'to': [29, 56, 62], 'learn': [30], 'from': [31, 46], 'both': [32], 'labeled': [33], 'unlabeled': [35], 'data,': [36], 'i.e.': [37], 'learning.': [39], 'This': [40], 'document': [41], 'chapter': [44], 'excerpt': [45], 'author’s&#13;\\ndoctoral': [48], 'thesis': [49], '(Zhu,': [50], '2005).': [51], 'However': [52], 'author': [54], 'plans': [55], 'update': [57], 'online': [59], 'version': [60], 'frequently': [61], 'incorporate': [63], 'latest': [65], 'development': [66], 'field.': [69], 'Please': [70], 'obtain': [71], 'latest&#13;\\nversion': [73], 'at': [74], 'http://www.cs.wisc.edu/~jerryzhu/pub/ssl_survey.pdf': [75]}",2005,"['Computer science', 'Artificial intelligence']","We review the literature on semi-supervised learning, which is an area in machine learning and more generally, artificial intelligence. There has been a whole&#13;\nspectrum of interesting ideas on how to learn from both labeled and unlabeled data, i.e. semi-supervised learning. This document is a chapter excerpt from the author’s&#13;\ndoctoral thesis (Zhu, 2005). However the author plans to update the online version frequently to incorporate the latest development in the field. Please obtain the latest&#13;\nversion at http://www.cs.wisc.edu/~jerryzhu/pub/ssl_survey.pdf"
https://openalex.org/W2996428491,ALBERT: A Lite BERT for Self-supervised Learning of Language\n Representations,"{'Increasing': [0], 'model': [1, 19, 92], 'size': [2], 'when': [3], 'pretraining': [4], 'natural': [5], 'language': [6], 'representations': [7], 'often\\nresults': [8], 'in': [9], 'improved': [10], 'performance': [11], 'on': [12, 75, 96], 'downstream': [13, 83], 'tasks.': [14], 'However,': [15], 'at': [16, 116], 'some': [17], 'point\\nfurther': [18], 'increases': [20], 'become': [21], 'harder': [22], 'due': [23], 'to': [24, 39, 57, 64, 107], 'GPU/TPU': [25], 'memory': [26, 41], 'limitations': [27], 'and\\nlonger': [28], 'training': [29], 'times.': [30], 'To': [31], 'address': [32], 'these': [33], 'problems,': [34], 'we': [35], 'present': [36], 'two\\nparameter-reduction': [37], 'techniques': [38], 'lower': [40], 'consumption': [42], 'and': [43, 78, 100, 111], 'increase': [44], 'the\\ntraining': [45], 'speed': [46], 'of': [47], 'BERT.': [48], 'Comprehensive': [49], 'empirical': [50], 'evidence': [51], 'shows': [52], 'that': [53, 59, 73], 'our\\nproposed': [54], 'methods': [55], 'lead': [56], 'models': [58, 114], 'scale': [60], 'much': [61], 'better': [62], 'compared': [63, 106], 'the': [65, 97, 112], 'original\\nBERT.': [66], 'We': [67], 'also': [68], 'use': [69], 'a': [70, 88], 'self-supervised': [71], 'loss': [72], 'focuses': [74], 'modeling\\ninter-sentence': [76], 'coherence,': [77], 'show': [79], 'it': [80], 'consistently': [81], 'helps': [82], 'tasks': [84], 'with\\nmulti-sentence': [85], 'inputs.': [86], 'As': [87], 'result,': [89], 'our': [90], 'best': [91], 'establishes': [93], 'new\\nstate-of-the-art': [94], 'results': [95], 'GLUE,': [98], 'RACE,': [99], '\\\\squad': [101], 'benchmarks': [102], 'while': [103], 'having\\nfewer': [104], 'parameters': [105], 'BERT-large.': [108], 'The': [109], 'code': [110], 'pretrained': [113], 'are\\navailable': [115], 'https://github.com/google-research/ALBERT.\\n': [117]}",2019,"['Computer science', 'Sentence', 'Language model', 'Artificial intelligence', 'Code (set theory)', 'Natural language processing', 'Point (geometry)', 'Coherence (philosophical gambling strategy)', 'Machine learning', 'Programming language', 'Set (abstract data type)', 'Physics', 'Geometry', 'Mathematics', 'Quantum mechanics']","Increasing model size when pretraining natural language representations often\nresults in improved performance on downstream tasks. However, at some point\nfurther model increases become harder due to GPU/TPU memory limitations and\nlonger training times. To address these problems, we present two\nparameter-reduction techniques to lower memory consumption and increase the\ntraining speed of BERT. Comprehensive empirical evidence shows that our\nproposed methods lead to models that scale much better compared to the original\nBERT. We also use a self-supervised loss that focuses on modeling\ninter-sentence coherence, and show it consistently helps downstream tasks with\nmulti-sentence inputs. As a result, our best model establishes new\nstate-of-the-art results on the GLUE, RACE, and \\squad benchmarks while having\nfewer parameters compared to BERT-large. The code and the pretrained models are\navailable at https://github.com/google-research/ALBERT.\n"
https://openalex.org/W2984353870,A survey on semi-supervised learning,"{'Abstract': [0], 'Semi-supervised': [1], 'learning': [2, 8, 21, 134, 157, 244], 'is': [3], 'the': [4, 33, 62, 83, 114, 152, 171, 184, 191, 199, 220, 231, 238, 257], 'branch': [5], 'of': [6, 36, 50, 97, 116, 132, 155, 183, 212], 'machine': [7, 67], 'concerned': [9], 'with': [10, 46, 69, 179, 195], 'using': [11], 'labelled': [12, 51], 'as': [13, 15, 139, 141, 173, 175], 'well': [14, 140, 174], 'unlabelled': [16, 37, 228], 'data': [17, 38, 229], 'to': [18, 107, 121, 164, 170, 249, 256], 'perform': [19], 'certain': [20], 'tasks.': [22], 'Conceptually': [23], 'situated': [24], 'between': [25], 'supervised': [26], 'and': [27, 77, 90, 100, 109, 118, 167, 187, 202, 223, 252], 'unsupervised': [28], 'learning,': [29, 68], 'it': [30], 'permits': [31], 'harnessing': [32], 'large': [34, 153], 'amounts': [35], 'available': [39], 'in': [40, 44, 57, 66, 88], 'many': [41], 'use': [42], 'cases': [43], 'combination': [45], 'typically': [47], 'smaller': [48], 'sets': [49], 'data.': [52], 'In': [53], 'recent': [54, 104, 143], 'years,': [55], 'research': [56, 158], 'this': [58, 111, 125], 'area': [59], 'has': [60, 85], 'followed': [61], 'general': [63], 'trends': [64], 'observed': [65], 'much': [70], 'attention': [71], 'directed': [72], 'at': [73], 'neural': [74], 'network-based': [75], 'models': [76], 'generative': [78], 'learning.': [79], 'The': [80], 'literature': [81], 'on': [82, 148, 198, 219], 'topic': [84], 'also': [86], 'expanded': [87], 'volume': [89], 'scope,': [91], 'now': [92], 'encompassing': [93], 'a': [94, 180, 209], 'broad': [95], 'spectrum': [96], 'theory,': [98], 'algorithms': [99, 188, 245], 'applications.': [101], 'However,': [102], 'no': [103], 'surveys': [105], 'exist': [106], 'collect': [108], 'organize': [110], 'knowledge,': [112], 'impeding': [113], 'ability': [115], 'researchers': [117, 166], 'engineers': [119], 'alike': [120], 'utilize': [122], 'it.': [123], 'Filling': [124], 'void,': [126], 'we': [127, 207, 235], 'present': [128], 'an': [129, 196], 'up-to-date': [130], 'overview': [131], 'semi-supervised': [133, 149, 156, 213, 243, 259], 'methods,': [135], 'covering': [136], 'earlier': [137], 'work': [138], 'more': [142, 176], 'advances.': [144], 'We': [145], 'focus': [146], 'primarily': [147], 'classification,': [150], 'where': [151], 'majority': [154], 'takes': [159], 'place.': [160], 'Our': [161], 'survey': [162], 'aims': [163], 'provide': [165], 'practitioners': [168], 'new': [169, 210], 'field': [172], 'advanced': [177], 'readers': [178], 'solid': [181], 'understanding': [182], 'main': [185], 'approaches': [186, 225], 'developed': [189], 'over': [190], 'past': [192], 'two': [193], 'decades,': [194], 'emphasis': [197], 'most': [200, 242], 'prominent': [201], 'currently': [203], 'relevant': [204], 'work.': [205], 'Furthermore,': [206], 'propose': [208], 'taxonomy': [211], 'classification': [214], 'algorithms,': [215], 'which': [216], 'sheds': [217], 'light': [218], 'different': [221], 'conceptual': [222], 'methodological': [224], 'for': [226], 'incorporating': [227], 'into': [230], 'training': [232], 'process.': [233], 'Lastly,': [234], 'show': [236], 'how': [237, 253], 'fundamental': [239], 'assumptions': [240], 'underlying': [241], 'are': [246], 'closely': [247], 'connected': [248], 'each': [250], 'other,': [251], 'they': [254], 'relate': [255], 'well-known': [258], 'clustering': [260], 'assumption.': [261]}",2019,"['Artificial intelligence', 'Machine learning', 'Computer science', 'Supervised learning', 'Unsupervised learning', 'Scope (computer science)', 'Semi-supervised learning', 'Artificial neural network', 'Field (mathematics)', 'Data science', 'Mathematics', 'Programming language', 'Pure mathematics']","Abstract Semi-supervised learning is the branch of machine learning concerned with using labelled as well as unlabelled data to perform certain learning tasks. Conceptually situated between supervised and unsupervised learning, it permits harnessing the large amounts of unlabelled data available in many use cases in combination with typically smaller sets of labelled data. In recent years, research in this area has followed the general trends observed in machine learning, with much attention directed at neural network-based models and generative learning. The literature on the topic has also expanded in volume and scope, now encompassing a broad spectrum of theory, algorithms and applications. However, no recent surveys exist to collect and organize this knowledge, impeding the ability of researchers and engineers alike to utilize it. Filling this void, we present an up-to-date overview of semi-supervised learning methods, covering earlier work as well as more recent advances. We focus primarily on semi-supervised classification, where the large majority of semi-supervised learning research takes place. Our survey aims to provide researchers and practitioners new to the field as well as more advanced readers with a solid understanding of the main approaches and algorithms developed over the past two decades, with an emphasis on the most prominent and currently relevant work. Furthermore, we propose a new taxonomy of semi-supervised classification algorithms, which sheds light on the different conceptual and methodological approaches for incorporating unlabelled data into the training process. Lastly, we show how the fundamental assumptions underlying most semi-supervised learning algorithms are closely connected to each other, and how they relate to the well-known semi-supervised clustering assumption."
https://openalex.org/W3035060554,Bootstrap your own latent: A new approach to self-supervised Learning,"{'We': [0, 119], 'introduce': [1], 'Bootstrap': [2], 'Your': [3], 'Own': [4], 'Latent': [5], '(BYOL),': [6], 'a': [7, 58, 72, 89, 106, 110, 116], 'new': [8, 90], 'approach': [9], 'to': [10, 22, 47], 'self-supervised': [11], 'image': [12, 56], 'representation': [13, 52], 'learning.': [14], 'BYOL': [15, 87, 97, 122], 'relies': [16], 'on': [17, 84, 103, 124, 135, 148], 'two': [18], 'neural': [19], 'networks,': [20, 27], 'referred': [21], 'as': [23], 'online': [24, 45, 77], 'and': [25, 30, 113, 138, 143], 'target': [26, 50, 69], 'that': [28, 121], 'interact': [29], 'learn': [31], 'from': [32], 'each': [33], 'other.': [34], 'From': [35], 'an': [36, 40], 'augmented': [37, 60], 'view': [38], 'of': [39, 53, 75, 92, 132], 'image,': [41], 'we': [42, 66], 'train': [43], 'the': [44, 49, 54, 63, 68, 76, 93, 129, 133], 'network': [46, 51, 70], 'predict': [48], 'same': [55, 64], 'under': [57], 'different': [59], 'view.': [61], 'At': [62], 'time,': [65], 'update': [67], 'with': [71, 109, 115], 'slow-moving': [73], 'average': [74], 'network.': [78], 'While': [79], 'state-of-the': [80], 'art': [81, 94, 134], 'methods': [82], 'rely': [83], 'negative': [85], 'pairs,': [86], 'achieves': [88], 'state': [91, 131], 'without': [95], 'them.': [96], 'reaches': [98], '$74.3\\%$': [99], 'top-1': [100], 'classification': [101], 'accuracy': [102], 'ImageNet': [104], 'using': [105], 'linear': [107], 'evaluation': [108], 'ResNet-50': [111], 'architecture': [112], '$79.6\\%$': [114], 'larger': [117], 'ResNet.': [118], 'show': [120], 'performs': [123], 'par': [125], 'or': [126], 'better': [127], 'than': [128], 'current': [130], 'both': [136], 'transfer': [137], 'semi-supervised': [139], 'benchmarks.': [140], 'Our': [141], 'implementation': [142], 'pretrained': [144], 'models': [145], 'are': [146], 'given': [147], 'GitHub.': [149]}",2020,"['Computer science', 'Artificial intelligence', 'Machine learning', 'Econometrics', 'Psychology', 'Mathematics']","We introduce Bootstrap Your Own Latent (BYOL), a new approach to self-supervised image representation learning. BYOL relies on two neural networks, referred to as online and target networks, that interact and learn from each other. From an augmented view of an image, we train the online network to predict the target network representation of the same image under a different augmented view. At the same time, we update the target network with a slow-moving average of the online network. While state-of-the art methods rely on negative pairs, BYOL achieves a new state of the art without them. BYOL reaches $74.3\%$ top-1 classification accuracy on ImageNet using a linear evaluation with a ResNet-50 architecture and $79.6\%$ with a larger ResNet. We show that BYOL performs on par or better than the current state of the art on both transfer and semi-supervised benchmarks. Our implementation and pretrained models are given on GitHub."
https://openalex.org/W2530395818,Equality of Opportunity in Supervised Learning,"{'We': [0, 116, 142], 'propose': [1], 'a': [2, 7, 147], 'criterion': [3], 'for': [4], 'discrimination': [5, 53], 'against': [6], 'specified': [8], 'sensitive': [9], 'attribute': [10], 'in': [11, 34], 'supervised': [12], 'learning,': [13], 'where': [14], 'the': [15, 29, 35, 65, 74, 82, 98, 102, 104, 107, 118], 'goal': [16], 'is': [17, 92], 'to': [18, 43, 51, 55, 73], 'predict': [19], 'some': [20], 'target': [21, 105], 'based': [22, 126], 'on': [23, 97, 112, 127], 'available': [24], 'features.': [25], 'Assuming': [26], 'data': [27], 'about': [28], 'predictor,': [30, 103], 'target,': [31], 'and': [32, 106, 123, 134], 'membership': [33], 'protected': [36, 108], 'group': [37], 'are': [38], 'available,': [39], 'we': [40], 'show': [41], 'how': [42], 'optimally': [44], 'adjust': [45], 'any': [46], 'learned': [47], 'predictor': [48], 'so': [49], 'as': [50], 'remove': [52], 'according': [54], 'our': [56, 90, 144], 'definition.': [57], 'Our': [58], 'framework': [59], 'also': [60], 'improves': [61], 'incentives': [62], 'by': [63, 80], 'shifting': [64], 'cost': [66], 'of': [67, 101, 114, 121, 150], 'poor': [68], 'classification': [69, 83], 'from': [70, 138], 'disadvantaged': [71], 'groups': [72], 'decision': [75], 'maker,': [76], 'who': [77], 'can': [78, 133], 'respond': [79], 'improving': [81], 'accuracy.': [84], 'In': [85], 'line': [86], 'with': [87], 'other': [88], 'studies,': [89], 'notion': [91, 145], 'oblivious:': [93], 'it': [94], 'depends': [95], 'only': [96], 'joint': [99], 'statistics': [100], 'attribute,': [109], 'but': [110], 'not': [111], 'interpretation': [113], 'individualfeatures.': [115], 'study': [117, 149], 'inherent': [119], 'limits': [120], 'defining': [122], 'identifying': [124], 'biases': [125], 'such': [128], 'oblivious': [129, 140], 'measures,': [130], 'outlining': [131], 'what': [132], 'cannot': [135], 'be': [136], 'inferred': [137], 'different': [139], 'tests.': [141], 'illustrate': [143], 'using': [146], 'case': [148], 'FICO': [151], 'credit': [152], 'scores.': [153]}",2016,"['Computer science', 'Interpretation (philosophy)', 'Disadvantaged', 'Machine learning', 'Artificial intelligence', 'Incentive', 'Decision maker', 'Line (geometry)', 'Mathematics', 'Microeconomics', 'Operations research', 'Economics', 'Programming language', 'Economic growth', 'Geometry']","We propose a criterion for discrimination against a specified sensitive attribute in supervised learning, where the goal is to predict some target based on available features. Assuming data about the predictor, target, and membership in the protected group are available, we show how to optimally adjust any learned predictor so as to remove discrimination according to our definition. Our framework also improves incentives by shifting the cost of poor classification from disadvantaged groups to the decision maker, who can respond by improving the classification accuracy. In line with other studies, our notion is oblivious: it depends only on the joint statistics of the predictor, the target and the protected attribute, but not on interpretation of individualfeatures. We study the inherent limits of defining and identifying biases based on such oblivious measures, outlining what can and cannot be inferred from different oblivious tests. We illustrate our notion using a case study of FICO credit scores."
https://openalex.org/W3001197829,FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence,"{'Semi-supervised': [0], 'learning': [1, 100], '(SSL)': [2], 'provides': [3], 'an': [4, 137], 'effective': [5], 'means': [6], 'of': [7, 23, 27, 80, 97], 'leveraging': [8], 'unlabeled': [9, 48], 'data': [10], 'to': [11, 71, 126, 141, 151], 'improve': [12], 'a': [13, 24, 51, 63, 77, 95], ""model's"": [14, 44], 'performance.': [15], 'In': [16], 'this': [17], 'paper,': [18], 'we': [19, 87, 134], 'demonstrate': [20], 'the': [21, 43, 54, 60, 73, 81, 144], 'power': [22], 'simple': [25], 'combination': [26], 'two': [28], 'common': [29], 'SSL': [30, 128], 'methods:': [31], 'consistency': [32], 'regularization': [33], 'and': [34, 110], 'pseudo-labeling.': [35], 'Our': [36], 'algorithm,': [37], 'FixMatch,': [38], 'first': [39], 'generates': [40], 'pseudo-labels': [41], 'using': [42], 'predictions': [45], 'on': [46, 105], 'weakly-augmented': [47], 'images.': [49], 'For': [50], 'given': [52], 'image,': [53], 'pseudo-label': [55, 74], 'is': [56, 68], 'only': [57], 'retained': [58], 'if': [59], 'model': [61, 67], 'produces': [62], 'high-confidence': [64], 'prediction.': [65], 'The': [66], 'then': [69], 'trained': [70], 'predict': [72], 'when': [75], 'fed': [76], 'strongly-augmented': [78], 'version': [79], 'same': [82], 'image.': [83], 'Despite': [84], 'its': [85], 'simplicity,': [86], 'show': [88], 'that': [89, 130, 147], 'FixMatch': [90, 122], 'achieves': [91], 'state-of-the-art': [92], 'performance': [93], 'across': [94], 'variety': [96], 'standard': [98], 'semi-supervised': [99], 'benchmarks,': [101], 'including': [102], '94.93%': [103], 'accuracy': [104, 112], 'CIFAR-10': [106], 'with': [107, 113], '250': [108], 'labels': [109, 118], '88.61%': [111], '40': [114], '--': [115], 'just': [116], '4': [117], 'per': [119], 'class.': [120], 'Since': [121], 'bears': [123], 'many': [124], 'similarities': [125], 'existing': [127], 'methods': [129], 'achieve': [131], 'worse': [132], 'performance,': [133], 'carry': [135], 'out': [136], 'extensive': [138], 'ablation': [139], 'study': [140], 'tease': [142], 'apart': [143], 'experimental': [145], 'factors': [146], 'are': [148], 'most': [149], 'important': [150], ""FixMatch's"": [152], 'success.': [153], 'We': [154], 'make': [155], 'our': [156], 'code': [157], 'available': [158], 'at': [159], 'https://github.com/google-research/fixmatch.': [160]}",2020,"['Computer science', 'Consistency (knowledge bases)', 'Regularization (linguistics)', 'Code (set theory)', 'Artificial intelligence', 'Class (philosophy)', 'Machine learning', 'Simplicity', 'Semi-supervised learning', 'Image (mathematics)', 'Pattern recognition (psychology)', 'Simple (philosophy)', 'Programming language', 'Philosophy', 'Set (abstract data type)', 'Epistemology']","Semi-supervised learning (SSL) provides an effective means of leveraging unlabeled data to improve a model's performance. In this paper, we demonstrate the power of a simple combination of two common SSL methods: consistency regularization and pseudo-labeling. Our algorithm, FixMatch, first generates pseudo-labels using the model's predictions on weakly-augmented unlabeled images. For a given image, the pseudo-label is only retained if the model produces a high-confidence prediction. The model is then trained to predict the pseudo-label when fed a strongly-augmented version of the same image. Despite its simplicity, we show that FixMatch achieves state-of-the-art performance across a variety of standard semi-supervised learning benchmarks, including 94.93% accuracy on CIFAR-10 with 250 labels and 88.61% accuracy with 40 -- just 4 labels per class. Since FixMatch bears many similarities to existing SSL methods that achieve worse performance, we carry out an extensive ablation study to tease apart the experimental factors that are most important to FixMatch's success. We make our code available at https://github.com/google-research/fixmatch."
https://openalex.org/W3036601975,wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations,"{'We': [0], 'show': [1], 'for': [2], 'the': [3, 22, 33, 37, 50, 68, 74, 85, 89, 92, 124], 'first': [4], 'time': [5], 'that': [6], 'learning': [7], 'powerful': [8], 'representations': [9, 52], 'from': [10], 'speech': [11, 19, 34, 127], 'audio': [12], 'alone': [13], 'followed': [14], 'by': [15], 'fine-tuning': [16], 'on': [17, 67, 91, 112], 'transcribed': [18], 'can': [20], 'outperform': [21], 'best': [23], 'semi-supervised': [24], 'methods': [25], 'while': [26, 96], 'being': [27], 'conceptually': [28], 'simpler.': [29], 'wav2vec': [30, 82], '2.0': [31, 83], 'masks': [32], 'input': [35], 'in': [36], 'latent': [38, 51], 'space': [39], 'and': [40, 110], 'solves': [41], 'a': [42, 47], 'contrastive': [43], 'task': [44], 'defined': [45], 'over': [46], 'quantization': [48], 'of': [49, 62, 76, 88, 107, 115, 126, 132], 'which': [53], 'are': [54], 'jointly': [55], 'learned.': [56], 'Experiments': [57], 'using': [58, 97], 'all': [59], 'labeled': [60, 77, 101, 108, 133], 'data': [61, 78, 109, 117], 'Librispeech': [63], 'achieve': [64], '1.8/3.3': [65], 'WER': [66], 'clean/other': [69], 'test': [70], 'sets.': [71], 'When': [72], 'lowering': [73], 'amount': [75], 'to': [79], 'one': [80], 'hour,': [81], 'outperforms': [84], 'previous': [86], 'state': [87], 'art': [90], '100': [93, 98], 'hour': [94], 'subset': [95], 'times': [99], 'less': [100], 'data.': [102, 134], 'Using': [103], 'just': [104], 'ten': [105], 'minutes': [106], 'pre-training': [111], '53k': [113], 'hours': [114], 'unlabeled': [116], 'still': [118], 'achieves': [119], '4.8/8.2': [120], 'WER.': [121], 'This': [122], 'demonstrates': [123], 'feasibility': [125], 'recognition': [128], 'with': [129], 'limited': [130], 'amounts': [131]}",2020,"['Computer science', 'Natural language processing', 'Self representation', 'Artificial intelligence', 'Speech recognition', 'Art', 'Humanities']","We show for the first time that learning powerful representations from speech audio alone followed by fine-tuning on transcribed speech can outperform the best semi-supervised methods while being conceptually simpler. wav2vec 2.0 masks the speech input in the latent space and solves a contrastive task defined over a quantization of the latent representations which are jointly learned. Experiments using all labeled data of Librispeech achieve 1.8/3.3 WER on the clean/other test sets. When lowering the amount of labeled data to one hour, wav2vec 2.0 outperforms the previous state of the art on the 100 hour subset while using 100 times less labeled data. Using just ten minutes of labeled data and pre-training on 53k hours of unlabeled data still achieves 4.8/8.2 WER. This demonstrates the feasibility of speech recognition with limited amounts of labeled data."
https://openalex.org/W2964051675,Deeper Insights Into Graph Convolutional Networks for Semi-Supervised Learning,"{'Many': [0], 'interesting': [1], 'problems': [2], 'in': [3, 36, 151], 'machine': [4], 'learning': [5, 12, 152], 'are': [6, 52], 'being': [7], 'revisited': [8], 'with': [9, 46, 120, 133, 153], 'new': [10], 'deep': [11], 'tools.': [13], 'For': [14], 'graph-based': [15], 'semi-supervised': [16], 'learning,': [17], 'a': [18, 98], 'recent': [19], 'important': [20], 'development': [21], 'is': [22, 96, 105], 'graph': [23, 34, 90], 'convolutional': [24, 38, 122], 'networks': [25], '(GCNs),': [26], 'which': [27, 104], 'nicely': [28], 'integrate': [29], 'local': [30], 'vertex': [31], 'features': [32], 'and': [33, 55, 66, 80, 140, 157, 174], 'topology': [35], 'the': [37, 41, 77, 89, 93, 106, 127, 130], 'layers.': [39, 123], 'Although': [40], 'GCN': [42, 78, 94, 131], 'model': [43, 67, 79, 95, 132], 'compares': [44], 'favorably': [45], 'other': [47], 'state-of-the-art': [48], 'methods,': [49], 'its': [50, 82], 'mechanisms': [51], 'not': [53], 'clear': [54], 'it': [56, 113], 'still': [57], 'requires': [58], 'considerable': [59], 'amount': [60], 'of': [61, 92, 101, 118, 129], 'labeled': [62], 'data': [63], 'for': [64, 164], 'validation': [65], 'selection.': [68], 'In': [69], 'this': [70], 'paper,': [71], 'we': [72, 86, 136], 'develop': [73], 'deeper': [74], 'insights': [75], 'into': [76], 'address': [81], 'fundamental': [83], 'limits.': [84], 'First,': [85], 'show': [87], 'that': [88], 'convolution': [91], 'actually': [97], 'special': [99], 'form': [100], 'Laplacian': [102], 'smoothing,': [103], 'key': [107], 'reason': [108], 'why': [109], 'GCNs': [110, 150], 'work,': [111], 'but': [112], 'also': [114], 'brings': [115], 'potential': [116], 'concerns': [117], 'over-smoothing': [119], 'many': [121], 'Second,': [124], 'to': [125, 143], 'overcome': [126], 'limits': [128], 'shallow': [134], 'architectures,': [135], 'propose': [137], 'both': [138], 'co-training': [139], 'self-training': [141], 'approaches': [142, 147], 'train': [144], 'GCNs.': [145], 'Our': [146], 'significantly': [148], 'improve': [149], 'very': [154], 'few': [155], 'labels,': [156], 'exempt': [158], 'them': [159], 'from': [160], 'requiring': [161], 'additional': [162], 'labels': [163], 'validation.': [165], 'Extensive': [166], 'experiments': [167], 'on': [168], 'benchmarks': [169], 'have': [170], 'verified': [171], 'our': [172], 'theory': [173], 'proposals.': [175]}",2018,"['Computer science', 'Graph', 'Machine learning', 'Artificial intelligence', 'Deep learning', 'Smoothing', 'Convolutional neural network', 'Theoretical computer science', 'Laplacian matrix', 'Computer vision']","Many interesting problems in machine learning are being revisited with new deep learning tools. For graph-based semi-supervised learning, a recent important development is graph convolutional networks (GCNs), which nicely integrate local vertex features and graph topology in the convolutional layers. Although the GCN model compares favorably with other state-of-the-art methods, its mechanisms are not clear and it still requires considerable amount of labeled data for validation and model selection. In this paper, we develop deeper insights into the GCN model and address its fundamental limits. First, we show that the graph convolution of the GCN model is actually a special form of Laplacian smoothing, which is the key reason why GCNs work, but it also brings potential concerns of over-smoothing with many convolutional layers. Second, to overcome the limits of the GCN model with shallow architectures, we propose both co-training and self-training approaches to train GCNs. Our approaches significantly improve GCNs in learning with very few labels, and exempt them from requiring additional labels for validation. Extensive experiments on benchmarks have verified our theory and proposals."
https://openalex.org/W2746791238,A brief introduction to weakly supervised learning,"{'Supervised': [0], 'learning': [1, 7], 'techniques': [2, 28, 67], 'construct': [3], 'predictive': [4], 'models': [5], 'by': [6], 'from': [8], 'a': [9, 20, 95], 'large': [10], 'number': [11], 'of': [12, 57, 79, 88, 97], 'training': [13, 17, 98, 108], 'examples,': [14], 'where': [15, 93, 106, 119], 'each': [16], 'example': [18], 'has': [19], 'label': [21], 'indicating': [22], 'its': [23], 'ground-truth': [24, 50], 'output.': [25], 'Though': [26], 'current': [27], 'have': [29], 'achieved': [30], 'great': [31], 'success,': [32], 'it': [33, 40, 62], 'is': [34, 41, 63, 100], 'noteworthy': [35], 'that': [36], 'in': [37], 'many': [38], 'tasks': [39], 'difficult': [42], 'to': [43, 53, 68], 'get': [44], 'strong': [45], 'supervision': [46], 'information': [47], 'like': [48], 'fully': [49], 'labels': [51, 122], 'due': [52], 'the': [54, 58, 107, 120], 'high': [55], 'cost': [56], 'data-labeling': [59], 'process.': [60], 'Thus,': [61], 'desirable': [64], 'for': [65], 'machine-learning': [66], 'work': [69], 'with': [70, 102, 112], 'weak': [71, 89], 'supervision.': [72], 'This': [73], 'article': [74], 'reviews': [75], 'some': [76], 'research': [77], 'progress': [78], 'weakly': [80], 'supervised': [81], 'learning,': [82], 'focusing': [83], 'on': [84], 'three': [85], 'typical': [86], 'types': [87], 'supervision:': [90], 'incomplete': [91], 'supervision,': [92, 105, 118], 'only': [94, 113], 'subset': [96], 'data': [99, 109], 'given': [101, 111, 121], 'labels;': [103, 115], 'inexact': [104], 'are': [110, 123], 'coarse-grained': [114], 'and': [116], 'inaccurate': [117], 'not': [124], 'always': [125], 'ground-truth.': [126]}",2017,"['Ground truth', 'Computer science', 'Construct (python library)', 'Process (computing)', 'Training set', 'Machine learning', 'Artificial intelligence', 'Labeled data', 'Supervised learning', 'Common ground', 'Semi-supervised learning', 'Training (meteorology)', 'Psychology', 'Artificial neural network', 'Social psychology', 'Physics', 'Meteorology', 'Operating system', 'Programming language']","Supervised learning techniques construct predictive models by learning from a large number of training examples, where each training example has a label indicating its ground-truth output. Though current techniques have achieved great success, it is noteworthy that in many tasks it is difficult to get strong supervision information like fully ground-truth labels due to the high cost of the data-labeling process. Thus, it is desirable for machine-learning techniques to work with weak supervision. This article reviews some research progress of weakly supervised learning, focusing on three typical types of weak supervision: incomplete supervision, where only a subset of training data is given with labels; inexact supervision, where the training data are given with only coarse-grained labels; and inaccurate supervision, where the given labels are not always ground-truth."
https://openalex.org/W2951970475,Temporal Ensembling for Semi-Supervised Learning,"{'In': [0], 'this': [1], 'paper,': [2], 'we': [3, 33, 101, 173], 'present': [4], 'a': [5, 16, 21, 35, 69, 94, 150], 'simple': [6], 'and': [7, 51, 57, 88, 126, 136, 140], 'efficient': [8], 'method': [9], 'for': [10, 72, 96, 105], 'training': [11, 25, 86], 'deep': [12], 'neural': [13], 'networks': [14], 'in': [15, 121, 131, 153], 'semi-supervised': [17, 108], 'setting': [18], 'where': [19, 32], 'only': [20], 'small': [22], 'portion': [23], 'of': [24, 38, 45, 79], 'data': [26], 'is': [27], 'labeled.': [28], 'We': [29, 147], 'introduce': [30], 'self-ensembling,': [31], 'form': [34], 'consensus': [36], 'prediction': [37, 63], 'the': [39, 43, 46, 73, 77, 80, 83, 112, 144, 162], 'unknown': [40, 74], 'labels': [41, 75, 125], 'using': [42, 158], 'outputs': [44], 'network-in-training': [47], 'on': [48], 'different': [49, 55], 'epochs,': [50], 'most': [52, 84], 'importantly,': [53], 'under': [54], 'regularization': [56], 'input': [58], 'augmentation': [59], 'conditions.': [60], 'This': [61], 'ensemble': [62], 'can': [64, 89], 'be': [65, 68, 91], 'expected': [66], 'to': [67, 119, 129, 138, 177], 'better': [70], 'predictor': [71], 'than': [76], 'output': [78], 'network': [81], 'at': [82], 'recent': [85], 'epoch,': [87], 'thus': [90], 'used': [92], 'as': [93, 166], 'target': [95], 'training.': [97, 171], 'Using': [98], 'our': [99], 'method,': [100], 'set': [102], 'new': [103], 'records': [104], 'two': [106], 'standard': [107, 145], 'learning': [109], 'benchmarks,': [110], 'reducing': [111], '(non-augmented)': [113], 'classification': [114, 155], 'error': [115], 'rate': [116], 'from': [117, 127, 161], '18.44%': [118], '7.05%': [120], 'SVHN': [122], 'with': [123, 133], '500': [124], '18.63%': [128], '16.55%': [130], 'CIFAR-10': [132], '4000': [134], 'labels,': [135], 'further': [137], '5.12%': [139], '12.16%': [141], 'by': [142, 157], 'enabling': [143], 'augmentations.': [146], 'additionally': [148], 'obtain': [149], 'clear': [151], 'improvement': [152], 'CIFAR-100': [154], 'accuracy': [156], 'random': [159], 'images': [160], 'Tiny': [163], 'Images': [164], 'dataset': [165], 'unlabeled': [167], 'extra': [168], 'inputs': [169], 'during': [170], 'Finally,': [172], 'demonstrate': [174], 'good': [175], 'tolerance': [176], 'incorrect': [178], 'labels.': [179]}",2016,"['Computer science', 'Regularization (linguistics)', 'Artificial intelligence', 'Machine learning', 'Training set', 'Artificial neural network', 'Set (abstract data type)', 'Deep neural networks', 'Supervised learning', 'Labeled data', 'Pattern recognition (psychology)', 'Programming language']","In this paper, we present a simple and efficient method for training deep neural networks in a semi-supervised setting where only a small portion of training data is labeled. We introduce self-ensembling, where we form a consensus prediction of the unknown labels using the outputs of the network-in-training on different epochs, and most importantly, under different regularization and input augmentation conditions. This ensemble prediction can be expected to be a better predictor for the unknown labels than the output of the network at the most recent training epoch, and can thus be used as a target for training. Using our method, we set new records for two standard semi-supervised learning benchmarks, reducing the (non-augmented) classification error rate from 18.44% to 7.05% in SVHN with 500 labels and from 18.63% to 16.55% in CIFAR-10 with 4000 labels, and further to 5.12% and 12.16% by enabling the standard augmentations. We additionally obtain a clear improvement in CIFAR-100 classification accuracy by using random images from the Tiny Images dataset as unlabeled extra inputs during training. Finally, we demonstrate good tolerance to incorrect labels."
https://openalex.org/W3114632476,A Survey on Contrastive Self-Supervised Learning,"{'Self-supervised': [0], 'learning': [1, 37, 46, 104], 'has': [2, 38], 'gained': [3], 'popularity': [4], 'because': [5], 'of': [6, 13, 20, 63, 86, 122, 144], 'its': [7], 'ability': [8], 'to': [9, 68, 73, 157], 'avoid': [10], 'the': [11, 28, 64, 91, 142, 145, 149], 'cost': [12], 'annotating': [14], 'large-scale': [15], 'datasets.': [16], 'It': [17, 57], 'is': [18], 'capable': [19], 'adopting': [21], 'self-defined': [22], 'pseudolabels': [23], 'as': [24, 130], 'supervision': [25], 'and': [26, 54, 135, 148, 154], 'use': [27], 'learned': [29], 'representations': [30], 'for': [31, 47, 125, 151], 'several': [32], 'downstream': [33, 127], 'tasks.': [34], 'Specifically,': [35], 'contrastive': [36, 92, 103], 'recently': [39], 'become': [40], 'a': [41, 102, 119], 'dominant': [42], 'component': [43], 'in': [44, 101], 'self-supervised': [45, 87], 'computer': [48], 'vision,': [49], 'natural': [50], 'language': [51], 'processing': [52], '(NLP),': [53], 'other': [55, 70], 'domains.': [56], 'aims': [58], 'at': [59], 'embedding': [60], 'augmented': [61], 'versions': [62], 'same': [65], 'sample': [66], 'close': [67], 'each': [69], 'while': [71], 'trying': [72], 'push': [74], 'away': [75], 'embeddings': [76], 'from': [77], 'different': [78, 108, 123], 'samples.': [79], 'This': [80], 'paper': [81], 'provides': [82], 'an': [83], 'extensive': [84], 'review': [85], 'methods': [88, 124, 147], 'that': [89, 110], 'follow': [90], 'approach.': [93], 'The': [94], 'work': [95], 'explains': [96], 'commonly': [97], 'used': [98], 'pretext': [99], 'tasks': [100, 128], 'setup,': [105], 'followed': [106], 'by': [107], 'architectures': [109], 'have': [111], 'been': [112], 'proposed': [113], 'so': [114], 'far.': [115], 'Next,': [116], 'we': [117, 139], 'present': [118], 'performance': [120], 'comparison': [121], 'multiple': [126], 'such': [129], 'image': [131], 'classification,': [132], 'object': [133], 'detection,': [134], 'action': [136], 'recognition.': [137], 'Finally,': [138], 'conclude': [140], 'with': [141], 'limitations': [143], 'current': [146], 'need': [150], 'further': [152], 'techniques': [153], 'future': [155], 'directions': [156], 'make': [158], 'meaningful': [159], 'progress.': [160]}",2020,"['Computer science', 'Artificial intelligence', 'Pretext', 'Machine learning', 'Embedding', 'Popularity', 'Supervised learning', 'Sample (material)', 'Natural language processing', 'Artificial neural network', 'Psychology', 'Politics', 'Chemistry', 'Political science', 'Chromatography', 'Law', 'Social psychology']","Self-supervised learning has gained popularity because of its ability to avoid the cost of annotating large-scale datasets. It is capable of adopting self-defined pseudolabels as supervision and use the learned representations for several downstream tasks. Specifically, contrastive learning has recently become a dominant component in self-supervised learning for computer vision, natural language processing (NLP), and other domains. It aims at embedding augmented versions of the same sample close to each other while trying to push away embeddings from different samples. This paper provides an extensive review of self-supervised methods that follow the contrastive approach. The work explains commonly used pretext tasks in a contrastive learning setup, followed by different architectures that have been proposed so far. Next, we present a performance comparison of different methods for multiple downstream tasks such as image classification, object detection, and action recognition. Finally, we conclude with the limitations of the current methods and the need for further techniques and future directions to make meaningful progress."
https://openalex.org/W2108501770,Semi-Supervised Learning with Deep Generative Models,"{'The': [0], 'ever-increasing': [1], 'size': [2], 'of': [3, 11, 20, 23], 'modern': [4, 28], 'data': [5, 29, 53], 'sets': [6, 54], 'combined': [7], 'with': [8, 38], 'the': [9, 21, 33], 'difficulty': [10], 'obtaining': [12], 'label': [13], 'information': [14], 'has': [15], 'made': [16], 'semi-supervised': [17, 36, 99], 'learning': [18, 37], 'one': [19], 'problems': [22], 'significant': [24, 91], 'practical': [25], 'importance': [26], 'in': [27, 83], 'analysis.': [30], 'We': [31, 70], 'revisit': [32], 'approach': [34], 'to': [35, 55, 89], 'generative': [39, 74, 94], 'models': [40, 44, 75], 'and': [41, 76], 'develop': [42], 'new': [43], 'that': [45, 72], 'allow': [46], 'for': [47, 98], 'effective': [48], 'generalisation': [49], 'from': [50], 'small': [51], 'labelled': [52], 'large': [56], 'unlabelled': [57], 'ones.': [58], 'Generative': [59], 'approaches': [60, 95], 'have': [61], 'thus': [62], 'far': [63], 'been': [64], 'either': [65], 'inflexible,': [66], 'inefficient': [67], 'or': [68], 'non-scalable.': [69], 'show': [71], 'deep': [73], 'approximate': [77], 'Bayesian': [78], 'inference': [79], 'exploiting': [80], 'recent': [81], 'advances': [82], 'variational': [84], 'methods': [85], 'can': [86], 'be': [87], 'used': [88], 'provide': [90], 'improvements,': [92], 'making': [93], 'highly': [96], 'competitive': [97], 'learning.': [100]}",2014,"['Generative grammar', 'Artificial intelligence', 'Machine learning', 'Computer science', 'Inference', 'Generative model', 'Scalability', 'Deep learning', 'Semi-supervised learning', 'Supervised learning', 'Bayesian probability', 'Bayesian inference', 'Artificial neural network', 'Database']","The ever-increasing size of modern data sets combined with the difficulty of obtaining label information has made semi-supervised learning one of the problems of significant practical importance in modern data analysis. We revisit the approach to semi-supervised learning with generative models and develop new models that allow for effective generalisation from small labelled data sets to large unlabelled ones. Generative approaches have thus far been either inflexible, inefficient or non-scalable. We show that deep generative models and approximate Bayesian inference exploiting recent advances in variational methods can be used to provide significant improvements, making generative approaches highly competitive for semi-supervised learning."
https://openalex.org/W3177500196,ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning,"{'Computational': [0], 'biology': [1], 'and': [2, 41, 53, 75, 136], 'bioinformatics': [3], 'provide': [4], 'vast': [5], 'data': [6, 50, 90], 'gold-mines': [7], 'from': [8, 17, 51, 88], 'protein': [9, 63, 96, 119, 130], 'sequences,': [10], 'ideal': [11], 'for': [12, 25, 109, 151], 'Language': [13, 19], 'Models': [14], '(LMs)': [15], 'taken': [16], 'Natural': [18], 'Processing': [20], '(NLP).': [21], 'These': [22], 'LMs': [23, 64], 'reach': [24], 'new': [26], 'prediction': [27, 117], 'frontiers': [28], 'at': [29], 'low': [30], 'inference': [31], 'costs.': [32], 'Here,': [33], 'we': [34], 'trained': [35, 67], 'two': [36], 'auto-regressive': [37], 'models': [38, 44, 190], '(Transformer-XL,': [39], 'XLNet)': [40], 'four': [42], 'auto-encoder': [43], '(BERT,': [45], 'Albert,': [46], 'Electra,': [47], 'T5)': [48], 'on': [49, 68], 'UniRef': [52], 'BFD': [54], 'containing': [55], 'up': [56], 'to': [57], '393': [58], 'billion': [59], 'amino': [60], 'acids.': [61], 'The': [62], '(pLMs)': [65], 'were': [66], 'the': [69, 85, 100, 104, 146, 152, 156, 173, 181, 184], 'Summit': [70], 'supercomputer': [71], 'using': [72, 103], '5616': [73], 'GPUs': [74], 'TPU': [76], 'Pod': [77], 'up-to': [78], '1024': [79], 'cores.': [80], 'Dimensionality': [81], 'reduction': [82], 'revealed': [83], 'that': [84, 176], 'raw': [86], 'pLM-embeddings': [87], 'unlabeled': [89], 'captured': [91], 'some': [92, 179], 'biophysical': [93], 'features': [94], 'of': [95, 102, 118, 129, 180, 183, 186], 'sequences.': [97], 'We': [98], 'validated': [99], 'advantage': [101], 'embeddings': [105, 149], 'as': [106], 'exclusive': [107], 'input': [108], 'several': [110], 'subsequent': [111], 'tasks:': [112], '(1)': [113], 'a': [114], 'per-residue': [115], '(per-token)': [116], 'secondary': [120, 144], 'structure': [121], '(3-state': [122], 'accuracy': [123, 141], 'Q3=81%-87%);': [124], '(2)': [125], 'per-protein': [126], '(pooling)': [127], 'predictions': [128], 'sub-cellular': [131], 'location': [132], '(ten-state': [133], 'accuracy:': [134], 'Q10=81%)': [135], 'membrane': [137], 'versus': [138], 'water-soluble': [139], '(2-state': [140], 'Q2=91%).': [142], 'For': [143], 'structure,': [145], 'most': [147], 'informative': [148], '(ProtT5)': [150], 'first': [153], 'time': [154], 'outperformed': [155], 'state-of-the-art': [157], 'without': [158], 'multiple': [159], 'sequence': [160], 'alignments': [161], '(MSAs)': [162], 'or': [163], 'evolutionary': [164], 'information': [165], 'thereby': [166], 'bypassing': [167], 'expensive': [168], 'database': [169], 'searches.': [170], 'Taken': [171], 'together,': [172], 'results': [174], 'implied': [175], 'pLMs': [177], 'learned': [178], 'grammar': [182], 'language': [185], 'life.': [187], 'All': [188], 'our': [189], 'are': [191], 'available': [192], 'through': [193], 'https://github.com/agemagician/ProtTrans.': [194]}",2021,"['Computer science', 'Artificial intelligence', 'Machine learning', 'Language acquisition', 'Natural language processing', 'Psychology', 'Mathematics education']","Computational biology and bioinformatics provide vast data gold-mines from protein sequences, ideal for Language Models (LMs) taken from Natural Language Processing (NLP). These LMs reach for new prediction frontiers at low inference costs. Here, we trained two auto-regressive models (Transformer-XL, XLNet) and four auto-encoder models (BERT, Albert, Electra, T5) on data from UniRef and BFD containing up to 393 billion amino acids. The protein LMs (pLMs) were trained on the Summit supercomputer using 5616 GPUs and TPU Pod up-to 1024 cores. Dimensionality reduction revealed that the raw pLM-embeddings from unlabeled data captured some biophysical features of protein sequences. We validated the advantage of using the embeddings as exclusive input for several subsequent tasks: (1) a per-residue (per-token) prediction of protein secondary structure (3-state accuracy Q3=81%-87%); (2) per-protein (pooling) predictions of protein sub-cellular location (ten-state accuracy: Q10=81%) and membrane versus water-soluble (2-state accuracy Q2=91%). For secondary structure, the most informative embeddings (ProtT5) for the first time outperformed the state-of-the-art without multiple sequence alignments (MSAs) or evolutionary information thereby bypassing expensive database searches. Taken together, the results implied that pLMs learned some of the grammar of the language of life. All our models are available through https://github.com/agemagician/ProtTrans."
https://openalex.org/W2963918774,Supervised Learning of Universal Sentence Representations from Natural\n Language Inference Data,"{'Many': [0], 'modern': [1], 'NLP': [2, 115], 'systems': [3], 'rely': [4], 'on': [5, 13, 78], 'word': [6], 'embeddings,': [7], 'previously': [8], 'trained': [9], 'in': [10], 'an\\nunsupervised': [11], 'manner': [12], 'large': [14], 'corpora,': [15], 'as': [16, 28], 'base': [17], 'features.': [18], 'Efforts': [19], 'to': [20, 48, 98], 'obtain\\nembeddings': [21], 'for': [22, 111], 'larger': [23], 'chunks': [24], 'of': [25, 64, 81, 107], 'text,': [26], 'such': [27], 'sentences,': [29], 'have': [30, 42], 'however': [31], 'not': [32, 43], 'been\\nso': [33], 'successful.': [34], 'Several': [35], 'attempts': [36], 'at': [37], 'learning': [38], 'unsupervised': [39, 73], 'representations': [40, 59], 'of\\nsentences': [41], 'reached': [44], 'satisfactory': [45], 'enough': [46], 'performance': [47], 'be': [49, 96], 'widely\\nadopted.': [50], 'In': [51], 'this': [52], 'paper,': [53], 'we': [54], 'show': [55], 'how': [56, 86], 'universal': [57], 'sentence': [58], 'trained\\nusing': [60], 'the': [61, 65, 105], 'supervised': [62], 'data': [63], 'Stanford': [66], 'Natural': [67], 'Language': [68], 'Inference': [69], 'datasets\\ncan': [70], 'consistently': [71], 'outperform': [72], 'methods': [74], 'like': [75, 85], 'SkipThought': [76], 'vectors': [77], 'a\\nwide': [79], 'range': [80], 'transfer': [82, 112], 'tasks.': [83, 116], 'Much': [84], 'computer': [87], 'vision': [88], 'uses': [89], 'ImageNet': [90], 'to\\nobtain': [91], 'features,': [92], 'which': [93], 'can': [94], 'then': [95], 'transferred': [97], 'other': [99, 114], 'tasks,': [100], 'our': [101], 'work': [102], 'tends\\nto': [103], 'indicate': [104], 'suitability': [106], 'natural': [108], 'language': [109], 'inference': [110], 'learning\\nto': [113], 'Our': [117], 'encoder': [118], 'is': [119], 'publicly': [120], 'available.\\n': [121]}",2017,"['Computer science', 'Artificial intelligence', 'Natural language processing', 'Inference', 'Sentence', 'Unsupervised learning', 'Transfer of learning', 'Natural language', 'Word (group theory)', 'Machine learning', 'Linguistics', 'Philosophy']","Many modern NLP systems rely on word embeddings, previously trained in an\nunsupervised manner on large corpora, as base features. Efforts to obtain\nembeddings for larger chunks of text, such as sentences, have however not been\nso successful. Several attempts at learning unsupervised representations of\nsentences have not reached satisfactory enough performance to be widely\nadopted. In this paper, we show how universal sentence representations trained\nusing the supervised data of the Stanford Natural Language Inference datasets\ncan consistently outperform unsupervised methods like SkipThought vectors on a\nwide range of transfer tasks. Much like how computer vision uses ImageNet to\nobtain features, which can then be transferred to other tasks, our work tends\nto indicate the suitability of natural language inference for transfer learning\nto other NLP tasks. Our encoder is publicly available.\n"
https://openalex.org/W3035725276,Self-supervised Learning: Generative or Contrastive,"{'Deep': [0], 'supervised': [1], 'learning': [2, 35, 45, 53, 78, 128], 'has': [3], 'achieved': [4], 'great': [5], 'success': [6], 'in': [7, 46, 82], 'the': [8, 47, 94, 146], 'last': [9, 48], 'decade.': [10], 'However,': [11], 'its': [12, 40], 'deficiencies': [13], 'of': [14, 65], 'dependence': [15], 'on': [16, 43, 125], 'manual': [17], 'labels': [18], 'and': [19, 60, 88, 98, 111, 136], 'vulnerability': [20], 'to': [21, 26, 106, 121], 'attacks': [22], 'have': [23], 'driven': [24], 'people': [25], 'explore': [27], 'a': [28, 73], 'better': [29], 'solution.': [30], 'As': [31], 'an': [32], 'alternative,': [33], 'self-supervised': [34, 77, 127, 140], 'attracts': [36], 'many': [37], 'researchers': [38], 'for': [39, 80, 139, 145], 'soaring': [41], 'performance': [42], 'representation': [44, 52, 81], 'several': [49], 'years.': [50], 'Self-supervised': [51], 'leverages': [54], 'input': [55], 'data': [56], 'itself': [57], 'as': [58], 'supervision': [59], 'benefits': [61], 'almost': [62], 'all': [63], 'types': [64], 'downstream': [66], 'tasks.': [67], 'In': [68], 'this': [69], 'survey,': [70], 'we': [71, 131], 'take': [72], 'look': [74], 'into': [75, 101], 'new': [76], 'methods': [79, 97], 'computer': [83], 'vision,': [84], 'natural': [85], 'language': [86], 'processing,': [87], 'graph': [89], 'learning.': [90, 141], 'We': [91, 114], 'comprehensively': [92], 'review': [93], 'existing': [95], 'empirical': [96], 'summarize': [99], 'them': [100], 'three': [102], 'main': [103], 'categories': [104], 'according': [105], 'their': [107], 'objectives:': [108], 'generative,': [109], 'contrastive,': [110], 'generative-contrastive': [112], '(adversarial).': [113], 'further': [115], 'investigate': [116], 'related': [117], 'theoretical': [118], 'analysis': [119], 'work': [120], 'provide': [122], 'deeper': [123], 'thoughts': [124], 'how': [126], 'works.': [129], 'Finally,': [130], 'briefly': [132], 'discuss': [133], 'open': [134], 'problems': [135], 'future': [137], 'directions': [138], 'An': [142], 'outline': [143], 'slide': [144], 'survey': [147], 'is': [148], 'provided.': [149]}",2021,[],"Deep supervised learning has achieved great success in the last decade. However, its deficiencies of dependence on manual labels and vulnerability to attacks have driven people to explore a better solution. As an alternative, self-supervised learning attracts many researchers for its soaring performance on representation learning in the last several years. Self-supervised representation learning leverages input data itself as supervision and benefits almost all types of downstream tasks. In this survey, we take a look into new self-supervised learning methods for representation in computer vision, natural language processing, and graph learning. We comprehensively review the existing empirical methods and summarize them into three main categories according to their objectives: generative, contrastive, and generative-contrastive (adversarial). We further investigate related theoretical analysis work to provide deeper thoughts on how self-supervised learning works. Finally, we briefly discuss open problems and future directions for self-supervised learning. An outline slide for the survey is provided."
https://openalex.org/W2975059944,ALBERT: A Lite BERT for Self-supervised Learning of Language Representations,"{'Increasing': [0], 'model': [1, 21, 101], 'size': [2], 'when': [3], 'pretraining': [4], 'natural': [5], 'language': [6], 'representations': [7], 'often': [8], 'results': [9, 105], 'in': [10], 'improved': [11], 'performance': [12], 'on': [13, 82, 106], 'downstream': [14, 91], 'tasks.': [15], 'However,': [16], 'at': [17, 128], 'some': [18], 'point': [19], 'further': [20], 'increases': [22], 'become': [23], 'harder': [24], 'due': [25], 'to': [26, 43, 63, 70, 118], 'GPU/TPU': [27], 'memory': [28, 45], 'limitations': [29], 'and': [30, 47, 86, 110, 122], 'longer': [31], 'training': [32, 50], 'times.': [33], 'To': [34], 'address': [35], 'these': [36], 'problems,': [37], 'we': [38], 'present': [39], 'two': [40], 'parameter-reduction': [41], 'techniques': [42], 'lower': [44], 'consumption': [46], 'increase': [48], 'the': [49, 71, 107, 123], 'speed': [51], 'of': [52], 'BERT.': [53, 73], 'Comprehensive': [54], 'empirical': [55], 'evidence': [56], 'shows': [57], 'that': [58, 65, 80], 'our': [59, 99], 'proposed': [60], 'methods': [61], 'lead': [62], 'models': [64, 125], 'scale': [66], 'much': [67], 'better': [68], 'compared': [69, 117], 'original': [72], 'We': [74], 'also': [75], 'use': [76], 'a': [77, 97], 'self-supervised': [78], 'loss': [79], 'focuses': [81], 'modeling': [83], 'inter-sentence': [84], 'coherence,': [85], 'show': [87], 'it': [88], 'consistently': [89], 'helps': [90], 'tasks': [92], 'with': [93], 'multi-sentence': [94], 'inputs.': [95], 'As': [96], 'result,': [98], 'best': [100], 'establishes': [102], 'new': [103], 'state-of-the-art': [104], 'GLUE,': [108], 'RACE,': [109], '\\squad': [111], 'benchmarks': [112], 'while': [113], 'having': [114], 'fewer': [115], 'parameters': [116], 'BERT-large.': [119], 'The': [120], 'code': [121], 'pretrained': [124], 'are': [126], 'available': [127], 'https://github.com/google-research/ALBERT.': [129]}",2019,"['Computer science', 'Sentence', 'Language model', 'Code (set theory)', 'Artificial intelligence', 'Point (geometry)', 'Natural language processing', 'Coherence (philosophical gambling strategy)', 'Machine learning', 'Programming language', 'Set (abstract data type)', 'Physics', 'Quantum mechanics', 'Geometry', 'Mathematics']","Increasing model size when pretraining natural language representations often results in improved performance on downstream tasks. However, at some point further model increases become harder due to GPU/TPU memory limitations and longer training times. To address these problems, we present two parameter-reduction techniques to lower memory consumption and increase the training speed of BERT. Comprehensive empirical evidence shows that our proposed methods lead to models that scale much better compared to the original BERT. We also use a self-supervised loss that focuses on modeling inter-sentence coherence, and show it consistently helps downstream tasks with multi-sentence inputs. As a result, our best model establishes new state-of-the-art results on the GLUE, RACE, and \squad benchmarks while having fewer parameters compared to BERT-large. The code and the pretrained models are available at https://github.com/google-research/ALBERT."
https://openalex.org/W830076066,Semi-Supervised Learning with Ladder Networks,"{'We': [0, 55], 'combine': [1], 'supervised': [2, 22], 'learning': [3, 6], 'with': [4, 53, 76], 'unsupervised': [5, 24], 'in': [7, 64, 70], 'deep': [8], 'neural': [9], 'networks.': [10], 'The': [11], 'proposed': [12, 42], 'model': [13, 52, 60], 'is': [14], 'trained': [15], 'to': [16, 72], 'simultaneously': [17], 'minimize': [18], 'the': [19, 30, 39, 51, 58], 'sum': [20], 'of': [21], 'and': [23, 67], 'cost': [25], 'functions': [26], 'by': [27, 43, 49], 'backpropagation,': [28], 'avoiding': [29], 'need': [31], 'for': [32], 'layer-wise': [33], 'pre-training.': [34], 'Our': [35], 'work': [36], 'builds': [37], 'on': [38], 'Ladder': [40], 'network': [41], 'Valpola': [44], '(2015),': [45], 'which': [46], 'we': [47], 'extend': [48], 'combining': [50], 'supervision.': [54], 'show': [56], 'that': [57], 'resulting': [59], 'reaches': [61], 'state-of-the-art': [62], 'performance': [63], 'semi-supervised': [65], 'MNIST': [66, 74], 'CIFAR-10': [68], 'classification,': [69], 'addition': [71], 'permutation-invariant': [73], 'classification': [75], 'all': [77], 'labels.': [78]}",2015,"['MNIST database', 'Artificial intelligence', 'Computer science', 'Machine learning', 'Supervised learning', 'Backpropagation', 'Artificial neural network', 'Unsupervised learning', 'Permutation (music)', 'Semi-supervised learning', 'Deep learning', 'Pattern recognition (psychology)', 'Acoustics', 'Physics']","We combine supervised learning with unsupervised learning in deep neural networks. The proposed model is trained to simultaneously minimize the sum of supervised and unsupervised cost functions by backpropagation, avoiding the need for layer-wise pre-training. Our work builds on the Ladder network proposed by Valpola (2015), which we extend by combining the model with supervision. We show that the resulting model reaches state-of-the-art performance in semi-supervised MNIST and CIFAR-10 classification, in addition to permutation-invariant MNIST classification with all labels."
https://openalex.org/W3134652006,Barlow Twins: Self-Supervised Learning via Redundancy Reduction,"{'Self-supervised': [0], 'learning': [1], '(SSL)': [2], 'is': [3, 21, 41, 123, 192], 'rapidly': [4], 'closing': [5], 'the': [6, 31, 42, 69, 73, 92, 99, 113, 116, 151, 166, 188, 199], 'gap': [7], 'with': [8, 38, 80, 195, 204], 'supervised': [9], 'methods': [10, 50, 181], 'on': [11, 165, 182, 193], 'large': [12, 146], 'computer': [13], 'vision': [14], 'benchmarks.': [15], 'A': [16], 'successful': [17], 'approach': [18, 40], 'to': [19, 22, 28, 91, 108, 128, 135], 'SSL': [20], 'learn': [23], 'embeddings': [24], 'which': [25], 'are': [26], 'invariant': [27], 'distortions': [29], 'of': [30, 44, 75, 83, 102, 105, 118, 138, 198, 213], 'input': [32], 'sample.': [33], 'However,': [34], 'a': [35, 84, 106, 136, 156, 162, 205], 'recurring': [36], 'issue': [37], 'this': [39], 'existence': [43], 'trivial': [45], 'constant': [46], 'solutions.': [47], 'Most': [48], 'current': [49, 196], 'avoid': [51], 'such': [52, 154], 'solutions': [53], 'by': [54, 67], 'careful': [55], 'implementation': [56], 'details.': [57], 'We': [58], 'propose': [59], 'an': [60], 'objective': [61], 'function': [62], 'that': [63], 'naturally': [64], 'avoids': [65], 'collapse': [66], 'measuring': [68], 'cross-correlation': [70], 'matrix': [71, 94], 'between': [72, 115, 150], 'outputs': [74], 'two': [76], 'identical': [77, 139], 'networks': [78], 'fed': [79], 'distorted': [81, 103], 'versions': [82, 104], 'sample,': [85], 'and': [86, 191, 209, 215], 'making': [87], 'it': [88, 170], 'as': [89, 95, 155], 'close': [90], 'identity': [93], 'possible.': [96], 'This': [97], 'causes': [98], 'embedding': [100], 'vectors': [101], 'sample': [107], 'be': [109], 'similar,': [110], 'while': [111], 'minimizing': [112], 'redundancy': [114], 'components': [117], 'these': [119], 'vectors.': [120, 176], 'The': [121], 'method': [122], 'called': [124], 'Barlow': [125, 141, 177], 'Twins,': [126], 'owing': [127], 'neuroscientist': [129], 'H.': [130], ""Barlow's"": [131], 'redundancy-reduction': [132], 'principle': [133], 'applied': [134], 'pair': [137], 'networks.': [140], 'Twins': [142, 178], 'does': [143], 'not': [144], 'require': [145], 'batches': [147], 'nor': [148], 'asymmetry': [149], 'network': [152], 'twins': [153], 'predictor': [157], 'network,': [158], 'gradient': [159], 'stopping,': [160], 'or': [161], 'moving': [163], 'average': [164], 'weight': [167], 'updates.': [168], 'Intriguingly': [169], 'benefits': [171], 'from': [172], 'very': [173], 'high-dimensional': [174], 'output': [175], 'outperforms': [179], 'previous': [180], 'ImageNet': [183, 202], 'for': [184, 201, 210], 'semi-supervised': [185], 'classification': [186, 203, 214], 'in': [187], 'low-data': [189], 'regime,': [190], 'par': [194], 'state': [197], 'art': [200], 'linear': [206], 'classifier': [207], 'head,': [208], 'transfer': [211], 'tasks': [212], 'object': [216], 'detection.': [217]}",2021,"['Artificial intelligence', 'Computer science', 'Redundancy (engineering)', 'Pattern recognition (psychology)', 'Classifier (UML)', 'Embedding', 'Machine learning', 'Algorithm', 'Mathematics', 'Operating system']","Self-supervised learning (SSL) is rapidly closing the gap with supervised methods on large computer vision benchmarks. A successful approach to SSL is to learn embeddings which are invariant to distortions of the input sample. However, a recurring issue with this approach is the existence of trivial constant solutions. Most current methods avoid such solutions by careful implementation details. We propose an objective function that naturally avoids collapse by measuring the cross-correlation matrix between the outputs of two identical networks fed with distorted versions of a sample, and making it as close to the identity matrix as possible. This causes the embedding vectors of distorted versions of a sample to be similar, while minimizing the redundancy between the components of these vectors. The method is called Barlow Twins, owing to neuroscientist H. Barlow's redundancy-reduction principle applied to a pair of identical networks. Barlow Twins does not require large batches nor asymmetry between the network twins such as a predictor network, gradient stopping, or a moving average on the weight updates. Intriguingly it benefits from very high-dimensional output vectors. Barlow Twins outperforms previous methods on ImageNet for semi-supervised classification in the low-data regime, and is on par with current state of the art for ImageNet classification with a linear classifier head, and for transfer tasks of classification and object detection."
https://openalex.org/W2943865428,MixMatch: A Holistic Approach to Semi-Supervised Learning,"{'Semi-supervised': [0], 'learning': [1, 32], 'has': [2], 'proven': [3], 'to': [4, 13, 33, 93, 125], 'be': [5], 'a': [6, 35, 65, 87, 97, 111], 'powerful': [7], 'paradigm': [8], 'for': [9, 30, 45, 116, 135], 'leveraging': [10], 'unlabeled': [11, 47, 53], 'data': [12, 54, 73], 'mitigate': [14], 'the': [15, 26], 'reliance': [16], 'on': [17, 77, 101], 'large': [18, 66], 'labeled': [19, 51, 72], 'datasets.': [20], 'In': [21], 'this': [22], 'work,': [23], 'we': [24, 82, 120], 'unify': [25], 'current': [27], 'dominant': [28], 'approaches': [29], 'semi-supervised': [31], 'produce': [34], 'new': [36], 'algorithm,': [37], 'MixMatch,': [38], 'that': [39, 59], 'works': [40], 'by': [41, 64, 86, 96], 'guessing': [42], 'low-entropy': [43], 'labels': [44], 'data-augmented': [46], 'examples': [48], 'and': [49, 52, 71, 95], 'mixing': [50], 'using': [55], 'MixUp.': [56], 'We': [57, 103], 'show': [58], 'MixMatch': [60, 107, 131], 'obtains': [61], 'state-of-the-art': [62], 'results': [63], 'margin': [67], 'across': [68], 'many': [69], 'datasets': [70], 'amounts.': [74], 'For': [75], 'example,': [76], 'CIFAR-10': [78], 'with': [79], '250': [80], 'labels,': [81], 'reduce': [83], 'error': [84], 'rate': [85], 'factor': [88, 98], 'of': [89, 99, 130], '4': [90], '(from': [91], '38%': [92], '11%)': [94], '2': [100], 'STL-10.': [102], 'also': [104], 'demonstrate': [105], 'how': [106], 'can': [108], 'help': [109], 'achieve': [110], 'dramatically': [112], 'better': [113], 'accuracy-privacy': [114], 'trade-off': [115], 'differential': [117], 'privacy.': [118], 'Finally,': [119], 'perform': [121], 'an': [122], 'ablation': [123], 'study': [124], 'tease': [126], 'apart': [127], 'which': [128], 'components': [129], 'are': [132], 'most': [133], 'important': [134], 'its': [136], 'success.': [137]}",2019,"['Computer science', 'Margin (machine learning)', 'Labeled data', 'Semi-supervised learning', 'Machine learning', 'Artificial intelligence', 'Supervised learning', 'Factor (programming language)', 'Entropy (arrow of time)', 'Training set', 'Word error rate', 'Data mining', 'Artificial neural network', 'Quantum mechanics', 'Physics', 'Programming language']","Semi-supervised learning has proven to be a powerful paradigm for leveraging unlabeled data to mitigate the reliance on large labeled datasets. In this work, we unify the current dominant approaches for semi-supervised learning to produce a new algorithm, MixMatch, that works by guessing low-entropy labels for data-augmented unlabeled examples and mixing labeled and unlabeled data using MixUp. We show that MixMatch obtains state-of-the-art results by a large margin across many datasets and labeled data amounts. For example, on CIFAR-10 with 250 labels, we reduce error rate by a factor of 4 (from 38% to 11%) and by a factor of 2 on STL-10. We also demonstrate how MixMatch can help achieve a dramatically better accuracy-privacy trade-off for differential privacy. Finally, we perform an ablation study to tease apart which components of MixMatch are most important for its success."
https://openalex.org/W2412510955,Semi-Supervised Learning with Generative Adversarial Networks,"{'We': [0, 19, 69], 'extend': [1], 'Generative': [2], 'Adversarial': [3], 'Networks': [4], '(GANs)': [5], 'to': [6, 15, 35, 46, 62, 64, 77], 'the': [7, 12, 52, 65], 'semi-supervised': [8], 'context': [9], 'by': [10], 'forcing': [11], 'discriminator': [13, 27], 'network': [14], 'output': [16], 'class': [17, 59], 'labels.': [18], 'train': [20], 'a': [21, 26, 30, 79, 93], 'generative': [22], 'model': [23], 'G': [24], 'and': [25, 83], 'D': [28, 43], 'on': [29], 'dataset': [31], 'with': [32], 'inputs': [33], 'belonging': [34], 'one': [36], 'of': [37, 49, 67], 'N': [38], 'classes.': [39], 'At': [40], 'training': [41], 'time,': [42], 'is': [44, 60], 'made': [45], 'predict': [47], 'which': [48], 'N+1': [50], 'classes': [51], 'input': [53], 'belongs': [54], 'to,': [55], 'where': [56], 'an': [57], 'extra': [58], 'added': [61], 'correspond': [63], 'outputs': [66], 'G.': [68], 'show': [70], 'that': [71, 84], 'this': [72], 'method': [73], 'can': [74], 'be': [75], 'used': [76], 'create': [78], 'more': [80], 'data-efficient': [81], 'classifier': [82], 'it': [85], 'allows': [86], 'for': [87], 'generating': [88], 'higher': [89], 'quality': [90], 'samples': [91], 'than': [92], 'regular': [94], 'GAN.': [95]}",2016,"['Discriminator', 'Generative grammar', 'Adversarial system', 'Classifier (UML)', 'Computer science', 'Artificial intelligence', 'Class (philosophy)', 'Machine learning', 'Generative adversarial network', 'Forcing (mathematics)', 'Context (archaeology)', 'Supervised learning', 'Deep learning', 'Artificial neural network', 'Mathematics', 'Geography', 'Detector', 'Mathematical analysis', 'Archaeology', 'Telecommunications']","We extend Generative Adversarial Networks (GANs) to the semi-supervised context by forcing the discriminator network to output class labels. We train a generative model G and a discriminator D on a dataset with inputs belonging to one of N classes. At training time, D is made to predict which of N+1 classes the input belongs to, where an extra class is added to correspond to the outputs of G. We show that this method can be used to create a more data-efficient classifier and that it allows for generating higher quality samples than a regular GAN."
https://openalex.org/W3134210100,Graph Self-Supervised Learning: A Survey,"{'Deep': [0], 'learning': [1, 37, 58], 'on': [2, 16, 49, 66, 77], 'graphs': [3, 78], 'has': [4, 52, 79], 'attracted': [5], 'significant': [6], 'interests': [7], 'recently.': [8], 'However,': [9], 'most': [10], 'of': [11, 90, 101, 122, 129, 151, 171], 'the': [12, 88, 102, 120, 127, 149, 160, 177], 'works': [13], 'have': [14], 'focused': [15], '(semi-)': [17], 'supervised': [18], 'learning,': [19, 93], 'resulting': [20], 'in': [21, 184], 'shortcomings': [22], 'including': [23], 'heavy': [24], 'label': [25], 'reliance,': [26], 'poor': [27], 'generalization,': [28], 'and': [29, 56, 72, 85, 98, 143, 158, 168, 180], 'weak': [30], 'robustness.': [31], 'To': [32], 'address': [33], 'these': [34, 134], 'issues,': [35], 'self-supervised': [36, 92], '(SSL),': [38], 'which': [39, 105], 'extracts': [40], 'informative': [41], 'knowledge': [42], 'through': [43], 'well-designed': [44], 'pretext': [45, 130], 'tasks': [46], 'without': [47], 'relying': [48], 'manual': [50], 'labels,': [51], 'become': [53], 'a': [54, 96, 114], 'promising': [55], 'trending': [57], 'paradigm': [59, 121], 'for': [60, 109], 'graph': [61, 91, 110, 123, 152, 172], 'data.': [62, 111], 'Different': [63], 'from': [64], 'SSL': [65, 76, 107, 153], 'other': [67], 'domains': [68], 'like': [69], 'computer': [70], 'vision': [71], 'natural': [73], 'language': [74], 'processing,': [75], 'an': [80], 'exclusive': [81], 'background,': [82], 'design': [83], 'ideas,': [84], 'taxonomies.': [86], 'Under': [87], 'umbrella': [89], 'we': [94, 132, 175], 'present': [95], 'timely': [97], 'comprehensive': [99], 'review': [100], 'existing': [103], 'approaches': [104, 135], 'employ': [106], 'techniques': [108], 'We': [112, 146], 'construct': [113], 'unified': [115], 'framework': [116], 'that': [117], 'mathematically': [118], 'formalizes': [119], 'SSL.': [124, 173], 'According': [125], 'to': [126], 'objectives': [128], 'tasks,': [131], 'divide': [133], 'into': [136], 'four': [137], 'categories:': [138], 'generation-based,': [139], 'auxiliary': [140], 'property-based,': [141], 'contrast-based,': [142], 'hybrid': [144], 'approaches.': [145], 'further': [147], 'describe': [148], 'applications': [150], 'across': [154], 'various': [155], 'research': [156, 186], 'fields': [157], 'summarize': [159], 'commonly': [161], 'used': [162], 'datasets,': [163], 'evaluation': [164], 'benchmark,': [165], 'performance': [166], 'comparison': [167], 'open-source': [169], 'codes': [170], 'Finally,': [174], 'discuss': [176], 'remaining': [178], 'challenges': [179], 'potential': [181], 'future': [182], 'directions': [183], 'this': [185], 'field.': [187], 'IEEE': [188]}",2022,"['Computer science', 'Artificial intelligence', 'Machine learning', 'Graph', 'Theoretical computer science', 'Robustness (evolution)', 'Semi-supervised learning', 'Chemistry', 'Gene', 'Biochemistry']","Deep learning on graphs has attracted significant interests recently. However, most of the works have focused on (semi-) supervised learning, resulting in shortcomings including heavy label reliance, poor generalization, and weak robustness. To address these issues, self-supervised learning (SSL), which extracts informative knowledge through well-designed pretext tasks without relying on manual labels, has become a promising and trending learning paradigm for graph data. Different from SSL on other domains like computer vision and natural language processing, SSL on graphs has an exclusive background, design ideas, and taxonomies. Under the umbrella of graph self-supervised learning, we present a timely and comprehensive review of the existing approaches which employ SSL techniques for graph data. We construct a unified framework that mathematically formalizes the paradigm of graph SSL. According to the objectives of pretext tasks, we divide these approaches into four categories: generation-based, auxiliary property-based, contrast-based, and hybrid approaches. We further describe the applications of graph SSL across various research fields and summarize the commonly used datasets, evaluation benchmark, performance comparison and open-source codes of graph SSL. Finally, we discuss the remaining challenges and potential future directions in this research field. IEEE"
https://openalex.org/W2996108195,DivideMix: Learning with Noisy Labels as Semi-supervised Learning,"{'Deep': [0], 'neural': [1], 'networks': [2, 113], 'are': [3], 'known': [4], 'to': [5, 13, 69], 'be': [6], 'annotation-hungry.': [7], 'Numerous': [8], 'efforts': [9], 'have': [10], 'been': [11], 'devoted': [12], 'reducing': [14], 'the': [15, 61, 72, 91, 95, 118, 122, 126, 132], 'annotation': [16], 'cost': [17], 'when': [18], 'learning': [19, 27, 33, 48, 55], 'with': [20, 28, 49, 65, 79, 86], 'deep': [21], 'networks.': [22], 'Two': [23], 'prominent': [24], 'directions': [25], 'include': [26], 'noisy': [29, 50, 87], 'labels': [30, 51], 'and': [31, 82, 89, 97, 139, 144], 'semi-supervised': [32, 54, 102, 127], 'by': [34, 52, 135], 'exploiting': [35], 'unlabeled': [36, 84, 98, 145], 'data.': [37], 'In': [38, 57], 'this': [39], 'work,': [40], 'we': [41, 108, 130], 'propose': [42], 'DivideMix,': [43], 'a': [44, 66, 76, 101], 'novel': [45], 'framework': [46], 'for': [47], 'leveraging': [53], 'techniques.': [56], 'particular,': [58], 'DivideMix': [59], 'models': [60], 'per-sample': [62], 'loss': [63], 'distribution': [64], 'mixture': [67], 'model': [68, 92], 'dynamically': [70], 'divide': [71], 'training': [73, 128], 'data': [74, 99], 'into': [75], 'labeled': [77, 96, 143], 'set': [78, 85], 'clean': [80], 'samples': [81], 'an': [83], 'samples,': [88, 146], 'trains': [90], 'on': [93, 142, 149], 'both': [94], 'in': [100], 'manner.': [103], 'To': [104], 'avoid': [105], 'confirmation': [106], 'bias,': [107], 'simultaneously': [109], 'train': [110], 'two': [111], 'diverged': [112], 'where': [114], 'each': [115], 'network': [116], 'uses': [117], 'dataset': [119], 'division': [120], 'from': [121], 'other': [123], 'network.': [124], 'During': [125], 'phase,': [129], 'improve': [131], 'MixMatch': [133], 'strategy': [134], 'performing': [136], 'label': [137, 140], 'co-refinement': [138], 'co-guessing': [141], 'respectively.': [147], 'Experiments': [148], 'multiple': [150], 'benchmark': [151], 'datasets': [152], 'demonstrate': [153], 'substantial': [154], 'improvements': [155], 'over': [156], 'state-of-the-art': [157], 'methods.': [158], 'Code': [159], 'is': [160], 'available': [161], 'at': [162], 'https://github.com/LiJunnan1992/DivideMix': [163], '.': [164]}",2020,"['Computer science', 'Artificial intelligence', 'Benchmark (surveying)', 'Annotation', 'Machine learning', 'Semi-supervised learning', 'Supervised learning', 'Deep learning', 'Labeled data', 'Artificial neural network', 'Set (abstract data type)', 'Sample (material)', 'Code (set theory)', 'Pattern recognition (psychology)', 'Programming language', 'Geography', 'Chemistry', 'Geodesy', 'Chromatography']","Deep neural networks are known to be annotation-hungry. Numerous efforts have been devoted to reducing the annotation cost when learning with deep networks. Two prominent directions include learning with noisy labels and semi-supervised learning by exploiting unlabeled data. In this work, we propose DivideMix, a novel framework for learning with noisy labels by leveraging semi-supervised learning techniques. In particular, DivideMix models the per-sample loss distribution with a mixture model to dynamically divide the training data into a labeled set with clean samples and an unlabeled set with noisy samples, and trains the model on both the labeled and unlabeled data in a semi-supervised manner. To avoid confirmation bias, we simultaneously train two diverged networks where each network uses the dataset division from the other network. During the semi-supervised training phase, we improve the MixMatch strategy by performing label co-refinement and label co-guessing on labeled and unlabeled samples, respectively. Experiments on multiple benchmark datasets demonstrate substantial improvements over state-of-the-art methods. Code is available at https://github.com/LiJunnan1992/DivideMix ."
https://openalex.org/W2950538796,Equality of Opportunity in Supervised Learning,"{'We': [0, 116], 'propose': [1], 'a': [2, 7, 147], 'criterion': [3], 'for': [4], 'discrimination': [5, 53], 'against': [6], 'specified': [8], 'sensitive': [9], 'attribute': [10], 'in': [11, 34], 'supervised': [12], 'learning,': [13], 'where': [14], 'the': [15, 29, 35, 65, 74, 82, 98, 102, 104, 107, 118], 'goal': [16], 'is': [17, 92], 'to': [18, 43, 51, 55, 73], 'predict': [19], 'some': [20], 'target': [21, 105], 'based': [22, 126], 'on': [23, 97, 112, 127], 'available': [24], 'features.': [25], 'Assuming': [26], 'data': [27], 'about': [28], 'predictor,': [30, 103], 'target,': [31], 'and': [32, 106, 123, 134], 'membership': [33], 'protected': [36, 108], 'group': [37], 'are': [38], 'available,': [39], 'we': [40], 'show': [41], 'how': [42], 'optimally': [44], 'adjust': [45], 'any': [46], 'learned': [47], 'predictor': [48], 'so': [49], 'as': [50], 'remove': [52], 'according': [54], 'our': [56, 90, 144], 'definition.': [57], 'Our': [58], 'framework': [59], 'also': [60], 'improves': [61], 'incentives': [62], 'by': [63, 80], 'shifting': [64], 'cost': [66], 'of': [67, 101, 114, 121, 150], 'poor': [68], 'classification': [69, 83], 'from': [70, 138], 'disadvantaged': [71], 'groups': [72], 'decision': [75], 'maker,': [76], 'who': [77], 'can': [78, 133], 'respond': [79], 'improving': [81], 'accuracy.': [84], '\r\nIn': [85], 'line': [86], 'with': [87], 'other': [88], 'studies,': [89], 'notion': [91, 145], 'oblivious:': [93], 'it': [94], 'depends': [95], 'only': [96], 'joint': [99], 'statistics': [100], 'attribute,': [109], 'but': [110], 'not': [111], 'interpretation': [113], 'individualfeatures.': [115], 'study': [117, 149], 'inherent': [119], 'limits': [120], 'defining': [122], 'identifying': [124], 'biases': [125], 'such': [128], 'oblivious': [129, 140], 'measures,': [130], 'outlining': [131], 'what': [132], 'cannot': [135], 'be': [136], 'inferred': [137], 'different': [139], 'tests.': [141], '\r\nWe': [142], 'illustrate': [143], 'using': [146], 'case': [148], 'FICO': [151], 'credit': [152], 'scores.': [153]}",2016,"['Computer science', 'Machine learning', 'Disadvantaged', 'Interpretation (philosophy)', 'Artificial intelligence', 'Incentive', 'Decision maker', 'Line (geometry)', 'Mathematics', 'Microeconomics', 'Economics', 'Operations research', 'Programming language', 'Geometry', 'Economic growth']","We propose a criterion for discrimination against a specified sensitive attribute in supervised learning, where the goal is to predict some target based on available features. Assuming data about the predictor, target, and membership in the protected group are available, we show how to optimally adjust any learned predictor so as to remove discrimination according to our definition. Our framework also improves incentives by shifting the cost of poor classification from disadvantaged groups to the decision maker, who can respond by improving the classification accuracy. 
In line with other studies, our notion is oblivious: it depends only on the joint statistics of the predictor, the target and the protected attribute, but not on interpretation of individualfeatures. We study the inherent limits of defining and identifying biases based on such oblivious measures, outlining what can and cannot be inferred from different oblivious tests. 
We illustrate our notion using a case study of FICO credit scores."
https://openalex.org/W3135367836,Learning Transferable Visual Models From Natural Language Supervision,"{'State-of-the-art': [0], 'computer': [1, 135], 'vision': [2, 136], 'systems': [3], 'are': [4], 'trained': [5, 205], 'to': [6, 31, 77, 103, 118, 159, 194], 'predict': [7], 'a': [8, 45, 50, 85, 167], 'fixed': [9], 'set': [10], 'of': [11, 18, 54, 63, 87, 115, 125, 151, 185, 197], 'predetermined': [12], 'object': [13, 153], 'categories.': [14], 'This': [15], 'restricted': [16], 'form': [17], 'supervision': [19], 'limits': [20], 'their': [21], 'generality': [22], 'and': [23, 74, 148, 162, 211], 'usability': [24], 'since': [25], 'additional': [26], 'labeled': [27], 'data': [28], 'is': [29, 44, 71, 101, 163], 'needed': [30], 'specify': [32], 'any': [33, 175, 196], 'other': [34], 'visual': [35, 106], 'concept.': [36], 'Learning': [37], 'directly': [38], 'from': [39, 82, 94], 'raw': [40], 'text': [41], 'about': [42], 'images': [43], 'promising': [46], 'alternative': [47], 'which': [48, 65, 69], 'leverages': [49], 'much': [51], 'broader': [52], 'source': [53], 'supervision.': [55], 'We': [56, 121, 207], 'demonstrate': [57], 'that': [58], 'the': [59, 95, 116, 123, 172, 183, 186, 198], 'simple': [60], 'pre-training': [61], 'task': [62], 'predicting': [64], 'caption': [66], 'goes': [67], 'with': [68, 166], 'image': [70, 80], 'an': [72], 'efficient': [73], 'scalable': [75], 'way': [76], 'learn': [78], 'SOTA': [79], 'representations': [81], 'scratch': [83], 'on': [84, 130, 189], 'dataset': [86, 176], '400': [88], 'million': [89, 200], '(image,': [90], 'text)': [91], 'pairs': [92], 'collected': [93], 'internet.': [96], 'After': [97], 'pre-training,': [98], 'natural': [99], 'language': [100], 'used': [102], 'reference': [104], 'learned': [105], 'concepts': [107], '(or': [108], 'describe': [109], 'new': [110], 'ones)': [111], 'enabling': [112], 'zero-shot': [113, 191], 'transfer': [114], 'model': [117, 156, 213], 'downstream': [119], 'tasks.': [120], 'study': [122], 'performance': [124], 'this': [126], 'approach': [127], 'by': [128], 'benchmarking': [129], 'over': [131], '30': [132], 'different': [133], 'existing': [134], 'datasets,': [137], 'spanning': [138], 'tasks': [139, 161], 'such': [140], 'as': [141], 'OCR,': [142], 'action': [143], 'recognition': [144], 'in': [145], 'videos,': [146], 'geo-localization,': [147], 'many': [149], 'types': [150], 'fine-grained': [152], 'classification.': [154], 'The': [155], 'transfers': [157], 'non-trivially': [158], 'most': [160], 'often': [164], 'competitive': [165], 'fully': [168], 'supervised': [169], 'baseline': [170], 'without': [171, 192], 'need': [173], 'for': [174], 'specific': [177], 'training.': [178], 'For': [179], 'instance,': [180], 'we': [181], 'match': [182], 'accuracy': [184], 'original': [187], 'ResNet-50': [188], 'ImageNet': [190], 'needing': [193], 'use': [195], '1.28': [199], 'training': [201], 'examples': [202], 'it': [203], 'was': [204], 'on.': [206], 'release': [208], 'our': [209], 'code': [210], 'pre-trained': [212], 'weights': [214], 'at': [215], 'https://github.com/OpenAI/CLIP.': [216]}",2021,"['Computer science', 'Artificial intelligence', 'Generality', 'Transfer of learning', 'Task (project management)', 'Object (grammar)', 'Scalability', 'Natural language processing', 'Machine learning', 'Natural language', 'Set (abstract data type)', 'Usability', 'Human–computer interaction', 'Database', 'Programming language', 'Management', 'Psychotherapist', 'Psychology', 'Economics']","State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. Learning directly from raw text about images is a promising alternative which leverages a much broader source of supervision. We demonstrate that the simple pre-training task of predicting which caption goes with which image is an efficient and scalable way to learn SOTA image representations from scratch on a dataset of 400 million (image, text) pairs collected from the internet. After pre-training, natural language is used to reference learned visual concepts (or describe new ones) enabling zero-shot transfer of the model to downstream tasks. We study the performance of this approach by benchmarking on over 30 different existing computer vision datasets, spanning tasks such as OCR, action recognition in videos, geo-localization, and many types of fine-grained object classification. The model transfers non-trivially to most tasks and is often competitive with a fully supervised baseline without the need for any dataset specific training. For instance, we match the accuracy of the original ResNet-50 on ImageNet zero-shot without needing to use any of the 1.28 million training examples it was trained on. We release our code and pre-trained model weights at https://github.com/OpenAI/CLIP."
https://openalex.org/W2431080869,Regularization With Stochastic Transformations and Perturbations for Deep Semi-Supervised Learning,"{'Effective': [0], 'convolutional': [1, 57], 'neural': [2, 58], 'networks': [3], 'are': [4, 78], 'trained': [5, 79], 'on': [6, 143], 'large': [7, 14], 'sets': [8], 'of': [9, 42, 53, 85, 102, 114, 118, 128, 131], 'labeled': [10, 15, 43], 'data.': [11], 'However,': [12], 'creating': [13], 'datasets': [16], 'is': [17, 38], 'a': [18, 31, 39, 132], 'very': [19], 'costly': [20], 'and': [21, 67, 73, 121], 'time-consuming': [22], 'task.': [23], 'Semi-supervised': [24], 'learning': [25, 55], 'uses': [26], 'unlabeled': [27], 'data': [28, 44, 64], 'to': [29, 94, 98], 'train': [30], 'model': [32], 'with': [33, 56], 'higher': [34], 'accuracy': [35], 'when': [36], 'there': [37], 'limited': [40], 'set': [41], 'available.': [45], 'In': [46], 'this': [47], 'paper,': [48], 'we': [49], 'consider': [50], 'the': [51, 90, 99, 115, 123, 126, 136, 140], 'problem': [52], 'semi-supervised': [54], 'networks.': [59], 'Techniques': [60], 'such': [61], 'as': [62], 'randomized': [63], 'augmentation,': [65], 'dropout': [66], 'random': [68], 'max-pooling': [69], 'provide': [70], 'better': [71], 'generalization': [72], 'stability': [74], 'for': [75], 'classifiers': [76], 'that': [77, 111], 'using': [80], 'gradient': [81], 'descent.': [82], 'Multiple': [83], 'passes': [84, 130], 'an': [86, 107], 'individual': [87], 'sample': [88, 134], 'through': [89, 135], 'network': [91], 'might': [92], 'lead': [93], 'different': [95], 'predictions': [96, 127], 'due': [97], 'non-deterministic': [100], 'behavior': [101], 'these': [103, 119], 'techniques.': [104], 'We': [105, 138], 'propose': [106], 'unsupervised': [108], 'loss': [109], 'function': [110], 'takes': [112], 'advantage': [113], 'stochastic': [116], 'nature': [117], 'methods': [120], 'minimizes': [122], 'difference': [124], 'between': [125], 'multiple': [129], 'training': [133], 'network.': [137], 'evaluate': [139], 'proposed': [141], 'method': [142], 'several': [144], 'benchmark': [145], 'datasets.': [146]}",2016,"['Regularization (linguistics)', 'Artificial intelligence', 'Computer science', 'Deep learning', 'Machine learning']","Effective convolutional neural networks are trained on large sets of labeled data. However, creating large labeled datasets is a very costly and time-consuming task. Semi-supervised learning uses unlabeled data to train a model with higher accuracy when there is a limited set of labeled data available. In this paper, we consider the problem of semi-supervised learning with convolutional neural networks. Techniques such as randomized data augmentation, dropout and random max-pooling provide better generalization and stability for classifiers that are trained using gradient descent. Multiple passes of an individual sample through the network might lead to different predictions due to the non-deterministic behavior of these techniques. We propose an unsupervised loss function that takes advantage of the stochastic nature of these methods and minimizes the difference between the predictions of multiple passes of a training sample through the network. We evaluate the proposed method on several benchmark datasets."
https://openalex.org/W3065542300,S3-Rec: Self-Supervised Learning for Sequential Recommendation with Mutual Information Maximization,"{'Recently,': [0], 'significant': [1], 'progress': [2], 'has': [3, 57], 'been': [4, 59], 'made': [5], 'in': [6, 153], 'sequential': [7, 13, 64, 111], 'recommendation\\nwith': [8], 'deep': [9], 'learning.': [10], 'Existing': [11], 'neural': [12, 85], 'recommendation': [14], 'models': [15], 'usually\\nrely': [16], 'on': [17, 82, 159], 'the': [18, 29, 45, 71, 83, 95, 104, 123, 132, 143, 163], 'item': [19], 'prediction': [20], 'loss': [21, 34], 'to': [22, 37, 93, 121, 186], 'learn': [23, 122], 'model': [24, 30, 72], 'parameters': [25], 'or': [26, 49], 'data\\nrepresentations.': [27], 'However,': [28], 'trained': [31], 'with': [32], 'this': [33, 68], 'is': [35, 92], 'prone': [36], 'suffer\\nfrom': [38], 'data': [39, 53, 56, 97, 105], 'sparsity': [40], 'problem.': [41], 'Since': [42], 'it': [43], 'overemphasizes': [44], 'final': [46], 'performance,': [47], 'the\\nassociation': [48], 'fusion': [50], 'between': [51, 145], 'context': [52], 'and': [54, 61, 102, 128], 'sequence': [55, 129], 'not': [58], 'well\\ncaptured': [60], 'utilized': [62], 'for': [63, 76, 109], 'recommendation.': [65, 112], 'To': [66], 'tackle': [67], 'problem,': [69], 'we\\npropose': [70], 'S^3-Rec,': [73], 'which': [74, 150, 189], 'stands': [75], 'Self-Supervised': [77], 'learning': [78, 184], 'for\\nSequential': [79], 'Recommendation,': [80], 'based': [81], 'self-attentive': [84], 'architecture.': [86], 'The\\nmain': [87], 'idea': [88], 'of': [89, 148, 165], 'our': [90, 114, 154, 166, 182], 'approach': [91], 'utilize': [94], 'intrinsic': [96], 'correlation': [98, 144], 'to\\nderive': [99], 'self-supervision': [100], 'signals': [101], 'enhance': [103], 'representations': [106], 'via\\npre-training': [107], 'methods': [108], 'improving': [110], 'For': [113], 'task,': [115], 'we\\ndevise': [116], 'four': [117], 'auxiliary': [118], 'self-supervised': [119, 183], 'objectives': [120], 'correlations\\namong': [124], 'attribute,': [125], 'item,': [126], 'subsequence,': [127], 'by': [130], 'utilizing': [131], 'mutual\\ninformation': [133], 'maximization': [134], '(MIM)': [135], 'principle.': [136], 'MIM': [137], 'provides': [138], 'a': [139], 'unified': [140], 'way': [141], 'to\\ncharacterize': [142], 'different': [146], 'types': [147], 'data,': [149], 'is\\nparticularly': [151], 'suitable': [152], 'scenario.': [155], 'Extensive': [156], 'experiments': [157], 'conducted': [158], 'six\\nreal-world': [160], 'datasets': [161], 'demonstrate': [162], 'superiority': [164], 'proposed': [167], 'method': [168, 185], 'over\\nexisting': [169], 'state-of-the-art': [170], 'methods,': [171], 'especially': [172], 'when': [173], 'only': [174], 'limited': [175], 'training': [176], 'data\\nis': [177], 'available.': [178], 'Besides,': [179], 'we': [180], 'extend': [181], 'other\\nrecommendation': [187], 'models,': [188], 'also': [190], 'improve': [191], 'their': [192], 'performance.\\n': [193]}",2020,[],"Recently, significant progress has been made in sequential recommendation\nwith deep learning. Existing neural sequential recommendation models usually\nrely on the item prediction loss to learn model parameters or data\nrepresentations. However, the model trained with this loss is prone to suffer\nfrom data sparsity problem. Since it overemphasizes the final performance, the\nassociation or fusion between context data and sequence data has not been well\ncaptured and utilized for sequential recommendation. To tackle this problem, we\npropose the model S^3-Rec, which stands for Self-Supervised learning for\nSequential Recommendation, based on the self-attentive neural architecture. The\nmain idea of our approach is to utilize the intrinsic data correlation to\nderive self-supervision signals and enhance the data representations via\npre-training methods for improving sequential recommendation. For our task, we\ndevise four auxiliary self-supervised objectives to learn the correlations\namong attribute, item, subsequence, and sequence by utilizing the mutual\ninformation maximization (MIM) principle. MIM provides a unified way to\ncharacterize the correlation between different types of data, which is\nparticularly suitable in our scenario. Extensive experiments conducted on six\nreal-world datasets demonstrate the superiority of our proposed method over\nexisting state-of-the-art methods, especially when only limited training data\nis available. Besides, we extend our self-supervised learning method to other\nrecommendation models, which also improve their performance.\n"
https://openalex.org/W1981613567,Multimodal semi-supervised learning for image classification,"{'International': [0], 'audience': [1]}",2010,"['Artificial intelligence', 'Computer science', 'Support vector machine', 'Multiple kernel learning', 'Pattern recognition (psychology)', 'Classifier (UML)', 'Categorization', 'Pascal (unit)', 'Machine learning', 'Binary classification', 'Semi-supervised learning', 'Supervised learning', 'Labeled data', 'Contextual image classification', 'Image (mathematics)', 'Kernel method', 'Artificial neural network', 'Programming language']",International audience
https://openalex.org/W1900101064,A Scaled Conjugate Gradient Algorithm for Fast Supervised Learning,"{'&lt;p&gt;A': [0], 'supervised': [1], 'learning': [2], 'algorithm': [3, 15, 72, 85], '(Scaled': [4], 'Conjugate': [5, 31], 'Gradient,': [6], 'SCG)': [7], 'with': [8], 'superlinear': [9], 'convergence': [10, 106], 'rate': [11], 'is': [12, 16, 51, 63, 121, 198, 205], 'introduced.': [13], 'The': [14, 59, 101, 168], 'based': [17], 'upon': [18], 'a': [19, 89, 131, 160], 'class': [20], 'of': [21, 54, 61, 68, 91, 96, 159, 172], 'optimization': [22], 'techniques': [23], 'well': [24], 'known': [25], 'in': [26, 56, 114, 140, 143, 156], 'numerical': [27], 'analysis': [28], 'as': [29], 'the': [30, 40, 52, 57, 66, 69, 74, 80, 105, 109, 116, 118, 157, 165, 170, 173, 178, 181, 183, 186], 'Gradient': [32], 'Methods.': [33], 'SCG': [34, 62, 87, 120, 208], 'uses': [35], 'second': [36], 'order': [37, 95, 144], 'information': [38, 155], 'from': [39], 'neural': [41, 161, 174], 'network': [42, 162, 175], 'but': [43], 'requires': [44], 'only': [45], 'O(N)': [46], 'memory': [47], 'usage,': [48], 'where': [49], 'N': [50], 'number': [53], 'weights': [55], 'network.': [58], 'performance': [60, 67], 'benchmarked': [64], 'against': [65], 'standard': [70], 'backpropagation': [71, 77], '(BP),': [73], 'conjugate': [75], 'gradient': [76], '(CGB)': [78], 'and': [79, 129, 137], 'one-step': [81], 'Broyden-Fletcher-Goldfarb-Shanno': [82], 'memoryless': [83], 'quasi-Newton': [84], '(BFGS).': [86], 'yields': [88], 'speed-up': [90, 102], 'at': [92], 'least': [93], 'an': [94, 147], 'magnitude': [97], 'relative': [98, 176], 'to': [99, 145, 177], 'BP.': [100], 'depends': [103], 'on': [104, 200], 'criterion,': [107], 'i.e.,': [108], 'bigger': [110, 117, 182], 'demand': [111], 'for': [112], 'reduction': [113], 'error': [115], 'speed-up.': [119], 'fully': [122], 'automated': [123], 'including': [124], 'no': [125], 'user': [126], 'dependent': [127, 153], 'parameters': [128], 'avoids': [130], 'time': [132], 'consuming': [133], 'line-search,': [134], 'which': [135], 'CGB': [136], 'BFGS': [138], 'use': [139], 'each': [141], 'iteration': [142], 'determine': [146], 'appropriate': [148], 'step': [149], 'size.&lt;/p&gt;&lt;p&gt;': [150], '&lt;/p&gt;&lt;p&gt;Incorporating': [151], 'problem': [152, 179], 'structural': [154], 'architecture': [158], 'often': [163], 'lowers': [164], 'overall': [166], 'complexity.': [167], 'smaller': [169], 'complexity': [171], 'domain,': [180], 'possibility': [184], 'that': [185, 207], 'weight': [187], 'space': [188], 'contains': [189], 'long': [190], 'ravines': [191], 'characterized': [192], 'by': [193], 'sharp': [194], 'curvature.': [195], 'While': [196], 'BP': [197], 'inefficient': [199], 'these': [201], 'ravine': [202], 'phenomena,': [203], 'it': [204], 'shown': [206], 'handles': [209], 'them': [210], 'effectively.&lt;/p&gt;': [211]}",1990,"['Broyden–Fletcher–Goldfarb–Shanno algorithm', 'Conjugate gradient method', 'Backpropagation', 'Algorithm', 'Artificial neural network', 'Nonlinear conjugate gradient method', 'Convergence (economics)', 'Gradient method', 'Mathematics', 'Computer science', 'Gradient descent', 'Mathematical optimization', 'Artificial intelligence', 'Telecommunications', 'Asynchronous communication', 'Economic growth', 'Economics']","&lt;p&gt;A supervised learning algorithm (Scaled Conjugate Gradient, SCG) with superlinear convergence rate is introduced. The algorithm is based upon a class of optimization techniques well known in numerical analysis as the Conjugate Gradient Methods. SCG uses second order information from the neural network but requires only O(N) memory usage, where N is the number of weights in the network. The performance of SCG is benchmarked against the performance of the standard backpropagation algorithm (BP), the conjugate gradient backpropagation (CGB) and the one-step Broyden-Fletcher-Goldfarb-Shanno memoryless quasi-Newton algorithm (BFGS). SCG yields a speed-up of at least an order of magnitude relative to BP. The speed-up depends on the convergence criterion, i.e., the bigger demand for reduction in error the bigger the speed-up. SCG is fully automated including no user dependent parameters and avoids a time consuming line-search, which CGB and BFGS use in each iteration in order to determine an appropriate step size.&lt;/p&gt;&lt;p&gt; &lt;/p&gt;&lt;p&gt;Incorporating problem dependent structural information in the architecture of a neural network often lowers the overall complexity. The smaller the complexity of the neural network relative to the problem domain, the bigger the possibility that the weight space contains long ravines characterized by sharp curvature. While BP is inefficient on these ravine phenomena, it is shown that SCG handles them effectively.&lt;/p&gt;"
https://openalex.org/W1982978808,Short-Term Traffic Flow Forecasting: An Experimental Comparison of Time-Series Analysis and Supervised Learning,"{'The': [0, 63, 149], 'literature': [1], 'on': [2, 109], 'short-term': [3, 76], 'traffic': [4, 77, 132], 'flow': [5, 78, 133], 'forecasting': [6, 79], 'has': [7], 'undergone': [8], 'great': [9], 'development': [10], 'recently.': [11], 'Many': [12], 'works,': [13], 'describing': [14], 'a': [15, 52, 96, 110, 154], 'wide': [16], 'variety': [17], 'of': [18, 55, 60, 65, 85], 'different': [19, 40], 'approaches,': [20], 'which': [21, 94, 124], 'very': [22], 'often': [23], 'share': [24], 'similar': [25], 'features': [26], 'and': [27, 44, 58, 103, 135, 146], 'ideas,': [28], 'have': [29], 'been': [30], 'published.': [31], 'However,': [32], 'publications': [33], 'presenting': [34, 89], 'new': [35, 119], 'prediction': [36, 144], 'algorithms': [37], 'usually': [38], 'employ': [39], 'settings,': [41], 'data': [42, 113], 'sets,': [43], 'performance': [45, 101], 'measurements,': [46], 'making': [47], 'it': [48], 'difficult': [49], 'to': [50, 75, 107, 128, 138, 171], 'infer': [51], 'clear': [53], 'picture': [54], 'the': [56, 82, 105, 158, 163, 179], 'advantages': [57], 'limitations': [59], 'each': [61], 'model.': [62], 'aim': [64], 'this': [66], 'paper': [67], 'is': [68, 157], 'twofold.': [69], 'First,': [70], 'we': [71, 116], 'review': [72], 'existing': [73], 'approaches': [74], 'methods': [80], 'under': [81], 'common': [83, 97], 'view': [84], 'probabilistic': [86], 'graphical': [87], 'models,': [88, 123], 'an': [90, 140], 'extensive': [91], 'experimental': [92], 'comparison,': [93], 'proposes': [95], 'baseline': [98], 'for': [99], 'their': [100], 'analysis': [102], 'provides': [104], 'infrastructure': [106], 'operate': [108], 'publicly': [111], 'available': [112], 'set.': [114], 'Second,': [115], 'present': [117], 'two': [118], 'support': [120, 166], 'vector': [121, 167], 'regression': [122], 'are': [125, 136], 'specifically': [126], 'devised': [127], 'benefit': [129], 'from': [130], 'typical': [131], 'seasonality': [134], 'shown': [137], 'represent': [139], 'interesting': [141], 'compromise': [142], 'between': [143], 'accuracy': [145], 'computational': [147], 'efficiency.': [148], 'SARIMA': [150], 'model': [151], 'coupled': [152], 'with': [153], 'Kalman': [155], 'filter': [156], 'most': [159, 180], 'accurate': [160], 'model;': [161], 'however,': [162], 'proposed': [164], 'seasonal': [165], 'regressor': [168], 'turns': [169], 'out': [170], 'be': [172], 'highly': [173], 'competitive': [174], 'when': [175], 'performing': [176], 'forecasts': [177], 'during': [178], 'congested': [181], 'periods.': [182], '©': [183], '2011': [184], 'IEEE.': [185]}",2013,"['Computer science', 'Kalman filter', 'Traffic flow (computer networking)', 'Probabilistic forecasting', 'Term (time)', 'Probabilistic logic', 'Time series', 'Machine learning', 'Set (abstract data type)', 'Data mining', 'Graphical model', 'Artificial intelligence', 'Programming language', 'Physics', 'Computer security', 'Quantum mechanics']","The literature on short-term traffic flow forecasting has undergone great development recently. Many works, describing a wide variety of different approaches, which very often share similar features and ideas, have been published. However, publications presenting new prediction algorithms usually employ different settings, data sets, and performance measurements, making it difficult to infer a clear picture of the advantages and limitations of each model. The aim of this paper is twofold. First, we review existing approaches to short-term traffic flow forecasting methods under the common view of probabilistic graphical models, presenting an extensive experimental comparison, which proposes a common baseline for their performance analysis and provides the infrastructure to operate on a publicly available data set. Second, we present two new support vector regression models, which are specifically devised to benefit from typical traffic flow seasonality and are shown to represent an interesting compromise between prediction accuracy and computational efficiency. The SARIMA model coupled with a Kalman filter is the most accurate model; however, the proposed seasonal support vector regressor turns out to be highly competitive when performing forecasts during the most congested periods. © 2011 IEEE."
https://openalex.org/W2620474507,SuperSpike: Supervised Learning in Multilayer Spiking Neural Networks,"{'A': [0], 'vast': [1], 'majority': [2], 'of': [3, 17, 25, 56, 83, 87, 111, 145, 167], 'computation': [4, 170], 'in': [5, 34, 45, 49, 59, 171], 'the': [6, 15, 54, 109, 159], 'brain': [7], 'is': [8], 'performed': [9], 'by': [10, 67, 101, 175], 'spiking': [11, 28, 47, 63, 172], 'neural': [12, 29, 64, 173], 'networks.': [13, 65], 'Despite': [14], 'ubiquity': [16], 'such': [18, 43], 'spiking,': [19], 'we': [20, 40, 52, 73, 107, 128], 'currently': [21], 'lack': [22], 'an': [23], 'understanding': [24, 166], 'how': [26, 39], 'biological': [27], 'circuits': [30, 48], 'learn': [31], 'and': [32, 132, 169], 'compute': [33], 'vivo,': [35], 'as': [36, 38], 'well': [37], 'can': [41, 139], 'instantiate': [42], 'capabilities': [44], 'artificial': [46], 'silico.': [50], 'Here': [51], 'revisit': [53], 'problem': [55], 'supervised': [57], 'learning': [58, 80, 113, 168], 'temporally': [60], 'coding': [61], 'multilayer': [62, 85], 'First,': [66], 'using': [68], 'a': [69, 76, 163], 'surrogate': [70], 'gradient': [71], 'approach,': [72], 'derive': [74], 'SuperSpike,': [75], 'nonlinear': [77, 93, 184], 'voltage-based': [78], 'three-factor': [79], 'rule': [81, 114], 'capable': [82], 'training': [84], 'networks': [86, 174], 'deterministic': [88], 'integrate-and-fire': [89], 'neurons': [90], 'to': [91, 124, 161, 179, 182], 'perform': [92], 'computations': [94], 'on': [95, 104], 'spatiotemporal': [96, 190], 'spike': [97, 191], 'patterns.': [98, 193], 'Second,': [99], 'inspired': [100], 'recent': [102], 'results': [103, 157], 'feedback': [105], 'alignment,': [106], 'compare': [108], 'performance': [110], 'our': [112, 156, 177], 'under': [115], 'different': [116, 189], 'credit': [117], 'assignment': [118], 'strategies': [119], 'for': [120], 'propagating': [121], 'output': [122], 'errors': [123], 'hidden': [125], 'units.': [126], 'Specifically,': [127], 'test': [129], 'uniform,': [130], 'symmetric,': [131], 'random': [133], 'feedback,': [134, 146], 'finding': [135], 'that': [136], 'simpler': [137], 'tasks': [138, 150], 'be': [140], 'solved': [141], 'with': [142], 'any': [143], 'type': [144], 'while': [147], 'more': [148], 'complex': [149], 'require': [151], 'symmetric': [152], 'feedback.': [153], 'In': [154], 'summary,': [155], 'open': [158], 'door': [160], 'obtaining': [162], 'better': [164], 'scientific': [165], 'advancing': [176], 'ability': [178], 'train': [180], 'them': [181], 'solve': [183], 'problems': [185], 'involving': [186], 'transformations': [187], 'between': [188], 'time': [192]}",2018,[],"A vast majority of computation in the brain is performed by spiking neural networks. Despite the ubiquity of such spiking, we currently lack an understanding of how biological spiking neural circuits learn and compute in vivo, as well as how we can instantiate such capabilities in artificial spiking circuits in silico. Here we revisit the problem of supervised learning in temporally coding multilayer spiking neural networks. First, by using a surrogate gradient approach, we derive SuperSpike, a nonlinear voltage-based three-factor learning rule capable of training multilayer networks of deterministic integrate-and-fire neurons to perform nonlinear computations on spatiotemporal spike patterns. Second, inspired by recent results on feedback alignment, we compare the performance of our learning rule under different credit assignment strategies for propagating output errors to hidden units. Specifically, we test uniform, symmetric, and random feedback, finding that simpler tasks can be solved with any type of feedback, while more complex tasks require symmetric feedback. In summary, our results open the door to obtaining a better scientific understanding of learning and computation in spiking neural networks by advancing our ability to train them to solve nonlinear problems involving transformations between different spatiotemporal spike time patterns."
https://openalex.org/W3205500251,FlexMatch: Boosting Semi-Supervised Learning with Curriculum Pseudo Labeling,"{'The': [0, 74], 'recently': [1], 'proposed': [2], 'FixMatch': [3, 19, 116, 161, 192], 'achieved': [4], 'state-of-the-art': [5, 125], 'results': [6], 'on': [7, 127, 162], 'most': [8], 'semi-supervised': [9], 'learning': [10, 42, 45, 62, 72], '(SSL)': [11], 'benchmarks.': [12], 'However,': [13], 'like': [14], 'other': [15, 208], 'modern': [16], 'SSL': [17, 131, 209], 'algorithms,': [18], 'uses': [20], 'a': [21, 60, 128], 'pre-defined': [22], 'constant': [23], 'threshold': [24], 'for': [25, 83], 'all': [26], 'classes': [27, 85], 'to': [28, 34, 39, 64, 69, 79, 90, 115, 193, 207], 'select': [29], 'unlabeled': [30, 66, 94], 'data': [31, 67, 95, 140], 'that': [32, 201], 'contribute': [33], 'the': [35, 70, 138, 146, 180], 'training,': [36], 'thus': [37], 'failing': [38], 'consider': [40], 'different': [41, 48, 84], 'status': [43], 'and': [44, 96, 117, 155, 164, 211], 'difficulties': [46], 'of': [47, 76, 130, 191], 'classes.': [49], 'To': [50], 'address': [51], 'this': [52], 'issue,': [53], 'we': [54, 199], 'propose': [55], 'Curriculum': [56], 'Pseudo': [57], 'Labeling': [58], '(CPL),': [59], 'curriculum': [61], 'approach': [63], 'leverage': [65], 'according': [68], ""model's"": [71], 'status.': [73], 'core': [75], 'CPL': [77, 100, 114, 176, 202], 'is': [78, 148], 'flexibly': [80], 'adjust': [81], 'thresholds': [82], 'at': [86, 220], 'each': [87], 'time': [88, 190], 'step': [89], 'let': [91], 'pass': [92], 'informative': [93], 'their': [97, 214], 'pseudo': [98], 'labels.': [99], 'does': [101], 'not': [102], 'introduce': [103], 'additional': [104], 'parameters': [105], 'or': [106, 109, 144], 'computations': [107], '(forward': [108], 'backward': [110], 'propagation).': [111], 'We': [112, 216], 'apply': [113], 'call': [118], 'our': [119, 218], 'improved': [120], 'algorithm': [121], 'FlexMatch.': [122], 'FlexMatch': [123, 152, 184], 'achieves': [124, 153], 'performance': [126], 'variety': [129], 'benchmarks,': [132], 'with': [133], 'especially': [134], 'strong': [135], 'performances': [136], 'when': [137, 145, 168], 'labeled': [139], 'are': [141, 170], 'extremely': [142], 'limited': [143], 'task': [147], 'challenging.': [149], 'For': [150], 'example,': [151], '13.96%': [154], '18.96%': [156], 'error': [157], 'rate': [158], 'reduction': [159], 'over': [160], 'CIFAR-100': [163], 'STL-10': [165], 'datasets': [166], 'respectively,': [167], 'there': [169], 'only': [171, 187], '4': [172], 'labels': [173], 'per': [174], 'class.': [175], 'also': [177], 'significantly': [178], 'boosts': [179], 'convergence': [181], 'speed,': [182], 'e.g.,': [183], 'can': [185, 203], 'use': [186], '1/5': [188], 'training': [189], 'achieve': [194], 'even': [195], 'better': [196], 'performance.': [197], 'Furthermore,': [198], 'show': [200], 'be': [204], 'easily': [205], 'adapted': [206], 'algorithms': [210], 'remarkably': [212], 'improve': [213], 'performances.': [215], 'open-source': [217], 'code': [219], 'https://github.com/TorchSSL/TorchSSL.': [221]}",2021,"['Computer science', 'Boosting (machine learning)', 'Leverage (statistics)', 'Machine learning', 'Artificial intelligence', 'Semi-supervised learning', 'Computation', 'Class (philosophy)', 'Algorithm']","The recently proposed FixMatch achieved state-of-the-art results on most semi-supervised learning (SSL) benchmarks. However, like other modern SSL algorithms, FixMatch uses a pre-defined constant threshold for all classes to select unlabeled data that contribute to the training, thus failing to consider different learning status and learning difficulties of different classes. To address this issue, we propose Curriculum Pseudo Labeling (CPL), a curriculum learning approach to leverage unlabeled data according to the model's learning status. The core of CPL is to flexibly adjust thresholds for different classes at each time step to let pass informative unlabeled data and their pseudo labels. CPL does not introduce additional parameters or computations (forward or backward propagation). We apply CPL to FixMatch and call our improved algorithm FlexMatch. FlexMatch achieves state-of-the-art performance on a variety of SSL benchmarks, with especially strong performances when the labeled data are extremely limited or when the task is challenging. For example, FlexMatch achieves 13.96% and 18.96% error rate reduction over FixMatch on CIFAR-100 and STL-10 datasets respectively, when there are only 4 labels per class. CPL also significantly boosts the convergence speed, e.g., FlexMatch can use only 1/5 training time of FixMatch to achieve even better performance. Furthermore, we show that CPL can be easily adapted to other SSL algorithms and remarkably improve their performances. We open-source our code at https://github.com/TorchSSL/TorchSSL."
https://openalex.org/W2189089430,Weakly Supervised Learning of Semantic Parsers for Mapping Instructions to Actions,"{'The': [0, 55], 'context': [1, 41], 'in': [2], 'which': [3], 'language': [4, 47], 'is': [5], 'used': [6, 25], 'provides': [7, 58], 'a': [8, 27, 35, 95], 'strong': [9, 100], 'signal': [10], 'for': [11, 42, 85], 'learning': [12], 'to': [13, 72, 89, 115], 'recover': [14], 'its': [15], 'meaning.': [16], 'In': [17], 'this': [18], 'paper,': [19], 'we': [20], 'show': [21], 'it': [22], 'can': [23], 'be': [24], 'within': [26], 'grounded': [28], 'CCG': [29], 'semantic': [30], 'parsing': [31], 'approach': [32], 'that': [33, 80], 'learns': [34], 'joint': [36, 56], 'model': [37], 'of': [38, 52, 69, 105, 119], 'meaning': [39], 'and': [40, 44], 'interpreting': [43], 'executing': [45, 83, 109], 'natural': [46], 'instructions,': [48, 84], 'using': [49], 'various': [50], 'types': [51], 'weak': [53], 'supervision.': [54], 'nature': [57], 'crucial': [59], 'benefits': [60], 'by': [61, 87], 'allowing': [62], 'situated': [63], 'cues,': [64], 'such': [65], 'as': [66], 'the': [67, 116, 120], 'set': [68], 'visible': [70], 'objects,': [71], 'directly': [73], 'influence': [74], 'learning.': [75], 'It': [76], 'also': [77], 'enables': [78], 'algorithms': [79], 'learn': [81], 'while': [82], 'example': [86], 'trying': [88], 'replicate': [90], 'human': [91], 'actions.': [92], 'Experiments': [93], 'on': [94], 'benchmark': [96], 'navigational': [97], 'dataset': [98], 'demonstrate': [99], 'performance': [101], 'under': [102], 'differing': [103], 'forms': [104], 'supervision,': [106], 'including': [107], 'correctly': [108], '60%': [110], 'more': [111], 'instruction': [112], 'sets': [113], 'relative': [114], 'previous': [117], 'state': [118], 'art.': [121]}",2013,"['Computer science', 'Benchmark (surveying)', 'Parsing', 'Meaning (existential)', 'Natural language processing', 'Artificial intelligence', 'Context (archaeology)', 'Set (abstract data type)', 'Situated', 'Natural language', 'Replicate', 'Programming language', 'Biology', 'Psychology', 'Geography', 'Mathematics', 'Psychotherapist', 'Paleontology', 'Statistics', 'Geodesy']","The context in which language is used provides a strong signal for learning to recover its meaning. In this paper, we show it can be used within a grounded CCG semantic parsing approach that learns a joint model of meaning and context for interpreting and executing natural language instructions, using various types of weak supervision. The joint nature provides crucial benefits by allowing situated cues, such as the set of visible objects, to directly influence learning. It also enables algorithms that learn while executing instructions, for example by trying to replicate human actions. Experiments on a benchmark navigational dataset demonstrate strong performance under differing forms of supervision, including correctly executing 60% more instruction sets relative to the previous state of the art."
https://openalex.org/W2158049734,Semi-Supervised Learning for Natural Language,"{'Statistical': [0], 'supervised': [1, 158], 'learning': [2], 'techniques': [3], 'have': [4], 'been': [5, 116], 'successful': [6], 'for': [7], 'many': [8], 'natural': [9, 62], 'language': [10, 63], 'processing': [11], 'tasks,': [12, 54, 73], 'but': [13], 'they': [14], 'require': [15], 'labeled': [16], 'datasets,': [17], 'which': [18], 'can': [19], 'be': [20], 'expensive': [21], 'to': [22, 86, 106, 138], 'obtain.': [23], 'On': [24], 'the': [25, 48, 108], 'other': [26], 'hand,': [27], 'unlabeled': [28], 'data': [29, 42], '(raw': [30], 'text)': [31], 'is': [32, 85, 105, 127, 151], 'often': [33], 'available': [34], '“for': [35], 'free': [36], '”': [37], 'in': [38, 46, 96, 111, 156], 'large': [39], 'quantities.': [40], 'Unlabeled': [41], 'has': [43, 115], 'shown': [44], 'promise': [45], 'improving': [47], 'performance': [49], 'of': [50, 53, 82, 91, 101, 121, 148], 'a': [51, 97, 112, 119, 131, 157, 161], 'number': [52], 'e.g.': [55], 'word': [56, 78, 103, 109], 'sense': [57], 'disambiguation,': [58], 'information': [59, 144], 'extraction,': [60], 'and': [61, 76, 88, 94, 141], 'parsing.': [64], 'In': [65, 130], 'this': [66, 149], 'thesis,': [67], 'we': [68, 134], 'focus': [69], 'on': [70], 'two': [71], 'segmentation': [72, 104], 'named-entity': [74, 83], 'recognition': [75, 84], 'Chinese': [77, 102], 'segmentation.': [79], 'The': [80, 99, 146], 'goal': [81, 100], 'detect': [87], 'classify': [89], 'names': [90], 'people,': [92], 'organizations,': [93], 'locations': [95], 'sentence.': [98], 'find': [107], 'boundaries': [110], 'sentence': [113], 'that': [114], 'written': [117], 'as': [118, 128, 154], 'string': [120], 'characters': [122], 'without': [123], 'spaces.': [124], 'Our': [125], 'approach': [126], 'follows:': [129], 'preprocessing': [132], 'step,': [133], 'use': [135], 'raw': [136], 'text': [137], 'cluster': [139], 'words': [140], 'calculate': [142], 'mutual': [143], 'statistics.': [145], 'output': [147], 'step': [150], 'then': [152], 'used': [153], 'features': [155], 'model,': [159], 'specifically': [160], 'global': [162], 'linear': [163], 'model': [164], 'trained': [165], 'using': [166]}",2005,"['Natural (archaeology)', 'Natural language processing', 'Natural language', 'Artificial intelligence', 'Computer science', 'Linguistics', 'Geography', 'Philosophy', 'Archaeology']","Statistical supervised learning techniques have been successful for many natural language processing tasks, but they require labeled datasets, which can be expensive to obtain. On the other hand, unlabeled data (raw text) is often available “for free ” in large quantities. Unlabeled data has shown promise in improving the performance of a number of tasks, e.g. word sense disambiguation, information extraction, and natural language parsing. In this thesis, we focus on two segmentation tasks, named-entity recognition and Chinese word segmentation. The goal of named-entity recognition is to detect and classify names of people, organizations, and locations in a sentence. The goal of Chinese word segmentation is to find the word boundaries in a sentence that has been written as a string of characters without spaces. Our approach is as follows: In a preprocessing step, we use raw text to cluster words and calculate mutual information statistics. The output of this step is then used as features in a supervised model, specifically a global linear model trained using"
https://openalex.org/W2784814091,Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning,"{'Many': [0], 'interesting': [1], 'problems': [2], 'in': [3, 36, 152], 'machine': [4], 'learning': [5, 12, 153], 'are': [6, 52], 'being': [7], 'revisited': [8], 'with': [9, 46, 121, 134, 154], 'new': [10], 'deep': [11], 'tools.': [13], 'For': [14], 'graph-based': [15], 'semisupervised': [16], 'learning,': [17], 'a': [18, 59, 99], 'recent': [19], 'important': [20], 'development': [21], 'is': [22, 97, 106], 'graph': [23, 34, 91], 'convolutional': [24, 38, 123], 'networks': [25], '(GCNs),': [26], 'which': [27, 105], 'nicely': [28], 'integrate': [29], 'local': [30], 'vertex': [31], 'features': [32], 'and': [33, 55, 67, 81, 141, 158, 175], 'topology': [35], 'the': [37, 41, 78, 90, 94, 107, 128, 131], 'layers.': [39, 124], 'Although': [40], 'GCN': [42, 79, 95, 132], 'model': [43, 68, 80, 96, 133], 'compares': [44], 'favorably': [45], 'other': [47], 'state-of-the-art': [48], 'methods,': [49], 'its': [50, 83], 'mechanisms': [51], 'not': [53], 'clear': [54], 'it': [56, 114], 'still': [57], 'requires': [58], 'considerable': [60], 'amount': [61], 'of': [62, 93, 102, 119, 130], 'labeled': [63], 'data': [64], 'for': [65, 165], 'validation': [66], 'selection.': [69], 'In': [70], 'this': [71], 'paper,': [72], 'we': [73, 87, 137], 'develop': [74], 'deeper': [75], 'insights': [76], 'into': [77], 'address': [82], 'fundamental': [84], 'limits.': [85], 'First,': [86], 'show': [88], 'that': [89], 'convolution': [92], 'actually': [98], 'special': [100], 'form': [101], 'Laplacian': [103], 'smoothing,': [104], 'key': [108], 'reason': [109], 'why': [110], 'GCNs': [111, 151], 'work,': [112], 'but': [113], 'also': [115], 'brings': [116], 'potential': [117], 'concerns': [118], 'over-smoothing': [120], 'many': [122], 'Second,': [125], 'to': [126, 144], 'overcome': [127], 'limits': [129], 'shallow': [135], 'architectures,': [136], 'propose': [138], 'both': [139], 'co-training': [140], 'self-training': [142], 'approaches': [143, 148], 'train': [145], 'GCNs.': [146], 'Our': [147], 'significantly': [149], 'improve': [150], 'very': [155], 'few': [156], 'labels,': [157], 'exempt': [159], 'them': [160], 'from': [161], 'requiring': [162], 'additional': [163], 'labels': [164], 'validation.': [166], 'Extensive': [167], 'experiments': [168], 'on': [169], 'benchmarks': [170], 'have': [171], 'verified': [172], 'our': [173], 'theory': [174], 'proposals.': [176]}",2018,"['Computer science', 'Graph', 'Artificial intelligence', 'Machine learning', 'Smoothing', 'Deep learning', 'Convolutional neural network', 'Theoretical computer science', 'Convolution (computer science)', 'Artificial neural network', 'Computer vision']","Many interesting problems in machine learning are being revisited with new deep learning tools. For graph-based semisupervised learning, a recent important development is graph convolutional networks (GCNs), which nicely integrate local vertex features and graph topology in the convolutional layers. Although the GCN model compares favorably with other state-of-the-art methods, its mechanisms are not clear and it still requires a considerable amount of labeled data for validation and model selection. In this paper, we develop deeper insights into the GCN model and address its fundamental limits. First, we show that the graph convolution of the GCN model is actually a special form of Laplacian smoothing, which is the key reason why GCNs work, but it also brings potential concerns of over-smoothing with many convolutional layers. Second, to overcome the limits of the GCN model with shallow architectures, we propose both co-training and self-training approaches to train GCNs. Our approaches significantly improve GCNs in learning with very few labels, and exempt them from requiring additional labels for validation. Extensive experiments on benchmarks have verified our theory and proposals."
https://openalex.org/W2943152387,Billion-scale semi-supervised learning for image classification,"{'This': [0], 'paper': [1], 'presents': [2], 'a': [3, 14, 18, 23, 42, 80], 'study': [4], 'of': [5, 26, 55, 59], 'semi-supervised': [6, 77], 'learning': [7], 'with': [8, 76], 'large': [9, 24], 'convolutional': [10], 'networks.': [11], 'We': [12, 50], 'propose': [13], 'pipeline,': [15], 'based': [16], 'on': [17, 112], 'teacher/student': [19], 'paradigm,': [20], 'that': [21], 'leverages': [22], 'collection': [25], 'unlabelled': [27, 102], 'images': [28], '(up': [29], 'to': [30, 37, 65, 69, 87], '1': [31], 'billion).': [32], 'Our': [33], 'main': [34], 'goal': [35], 'is': [36], 'improve': [38], 'the': [39, 56, 113], 'performance': [40], 'for': [41, 73, 90], 'given': [43], 'target': [44], 'architecture,': [45], 'like': [46], 'ResNet-50': [47, 107], 'or': [48], 'ResNext.': [49], 'provide': [51], 'an': [52], 'extensive': [53], 'analysis': [54], 'success': [57], 'factors': [58], 'our': [60, 82, 104], 'approach,': [61], 'which': [62], 'leads': [63], 'us': [64], 'formulate': [66], 'some': [67], 'recommendations': [68], 'produce': [70], 'high-accuracy': [71], 'models': [72], 'image': [74], 'classification': [75], 'learning.': [78], 'As': [79], 'result,': [81], 'approach': [83], 'brings': [84], 'important': [85], 'gains': [86], 'standard': [88], 'architectures': [89], 'image,': [91], 'video': [92], 'and': [93], 'fine-grained': [94], 'classification.': [95], 'For': [96], 'instance,': [97], 'by': [98], 'leveraging': [99], 'one': [100], 'billion': [101], 'images,': [103], 'learned': [105], 'vanilla': [106], 'achieves': [108], '81.2%': [109], 'top-1': [110], 'accuracy': [111], 'ImageNet': [114], 'benchmark.': [115]}",2019,"['Scale (ratio)', 'Computer science', 'Artificial intelligence', 'Image (mathematics)', 'Supervised learning', 'Pattern recognition (psychology)', 'Machine learning', 'Geography', 'Cartography', 'Artificial neural network']","This paper presents a study of semi-supervised learning with large convolutional networks. We propose a pipeline, based on a teacher/student paradigm, that leverages a large collection of unlabelled images (up to 1 billion). Our main goal is to improve the performance for a given target architecture, like ResNet-50 or ResNext. We provide an extensive analysis of the success factors of our approach, which leads us to formulate some recommendations to produce high-accuracy models for image classification with semi-supervised learning. As a result, our approach brings important gains to standard architectures for image, video and fine-grained classification. For instance, by leveraging one billion unlabelled images, our learned vanilla ResNet-50 achieves 81.2% top-1 accuracy on the ImageNet benchmark."
https://openalex.org/W1529410181,Weakly- and Semi-Supervised Learning of a DCNN for Semantic Image Segmentation,"{'Deep': [0], 'convolutional': [1], 'neural': [2], 'networks': [3], '(DCNNs)': [4], 'trained': [5], 'on': [6, 104], 'a': [7, 55], 'large': [8], 'number': [9], 'of': [10, 32, 57], 'images': [11], 'with': [12], 'strong': [13], 'pixel-level': [14], 'annotations': [15], 'have': [16], 'recently': [17], 'significantly': [18, 115], 'pushed': [19], 'the': [20, 28, 95, 105, 124], 'state-of-art': [21], 'in': [22], 'semantic': [23, 36, 78], 'image': [24, 37, 79, 110], 'segmentation.': [25], 'We': [26, 72, 119], 'study': [27], 'more': [29], 'challenging': [30, 106], 'problem': [31], 'learning': [33], 'DCNNs': [34], 'for': [35, 77], 'segmentation': [38, 80, 111], 'from': [39, 67], 'either': [40], '(1)': [41], 'weakly': [42, 63, 85], 'annotated': [43], 'training': [44, 82], 'data': [45], 'such': [46], 'as': [47], 'bounding': [48], 'boxes': [49], 'or': [50, 53, 69], 'image-level': [51], 'labels': [52], '(2)': [54], 'combination': [56], 'few': [58], 'strongly': [59], 'labeled': [60, 64], 'and': [61, 87], 'many': [62], 'images,': [65], 'sourced': [66], 'one': [68], 'multiple': [70], 'datasets.': [71], 'develop': [73], 'Expectation-Maximization': [74], '(EM)': [75], 'methods': [76], 'model': [81], 'under': [83], 'these': [84], 'supervised': [86], 'semi-supervised': [88], 'settings.': [89], 'Extensive': [90], 'experimental': [91], 'evaluation': [92], 'shows': [93], 'that': [94], 'proposed': [96, 125], 'techniques': [97], 'can': [98], 'learn': [99], 'models': [100], 'delivering': [101], 'competitive': [102], 'results': [103], 'PASCAL': [107], 'VOC': [108], '2012': [109], 'benchmark,': [112], 'while': [113], 'requiring': [114], 'less': [116], 'annotation': [117], 'effort.': [118], 'share': [120], 'source': [121], 'code': [122], 'implementing': [123], 'system': [126], 'at': [127], 'https://bitbucket.org/deeplab/deeplab-public.': [128]}",2015,"['Segmentation', 'Artificial intelligence', 'Image (mathematics)', 'Computer science', 'Pattern recognition (psychology)', 'Natural language processing']","Deep convolutional neural networks (DCNNs) trained on a large number of images with strong pixel-level annotations have recently significantly pushed the state-of-art in semantic image segmentation. We study the more challenging problem of learning DCNNs for semantic image segmentation from either (1) weakly annotated training data such as bounding boxes or image-level labels or (2) a combination of few strongly labeled and many weakly labeled images, sourced from one or multiple datasets. We develop Expectation-Maximization (EM) methods for semantic image segmentation model training under these weakly supervised and semi-supervised settings. Extensive experimental evaluation shows that the proposed techniques can learn models delivering competitive results on the challenging PASCAL VOC 2012 image segmentation benchmark, while requiring significantly less annotation effort. We share source code implementing the proposed system at https://bitbucket.org/deeplab/deeplab-public."
https://openalex.org/W3021542222,A Simple Semi-Supervised Learning Framework for Object Detection,"{'Semi-supervised': [0], 'learning': [1, 13], '(SSL)': [2], 'has': [3, 20, 31], 'a': [4, 44, 56], 'potential': [5], 'to': [6, 87, 116], 'improve': [7], 'the': [8, 25, 75, 89, 99, 112], 'predictive': [9], 'performance': [10, 90], 'of': [11, 27, 66, 91, 101], 'machine': [12], 'models': [14], 'using': [15, 95, 130, 141], 'unlabeled': [16, 71], 'data.': [17, 144], 'Although': [18], 'there': [19], 'been': [21, 33], 'remarkable': [22], 'recent': [23], 'progress,': [24], 'scope': [26], 'demonstration': [28], 'in': [29], 'SSL': [30, 48], 'mainly': [32], 'on': [34, 103, 118], 'image': [35, 72], 'classification': [36], 'tasks.': [37], 'In': [38], 'this': [39], 'paper,': [40], 'we': [41], 'propose': [42, 84], 'STAC,': [43], 'simple': [45], 'yet': [46], 'effective': [47], 'framework': [49], 'for': [50], 'visual': [51], 'object': [52, 93], 'detection': [53, 94], 'along': [54], 'with': [55], 'data': [57, 124, 134], 'augmentation': [58], 'strategy.': [59], 'STAC': [60, 102, 110, 120], 'deploys': [61], 'highly': [62], 'confident': [63], 'pseudo': [64], 'labels': [65], 'localized': [67], 'objects': [68], 'from': [69, 114], 'an': [70], 'and': [73, 97, 106], 'updates': [74], 'model': [76], 'by': [77, 126], 'enforcing': [78], 'consistency': [79], 'via': [80], 'strong': [81], 'augmentations.': [82], 'We': [83], 'experimental': [85], 'protocols': [86], 'evaluate': [88], 'semi-supervised': [92], 'MS-COCO': [96, 105], 'show': [98], 'efficacy': [100], 'both': [104], 'VOC07.': [107], 'On': [108], 'VOC07,': [109], 'improves': [111], 'AP$^{0.5}$': [113], '$76.30$': [115], '$79.08$;': [117], 'MS-COCO,': [119], 'demonstrates': [121], '$2{\\times}$': [122], 'higher': [123], 'efficiency': [125], 'achieving': [127], '24.38': [128], 'mAP': [129], 'only': [131], '5\\%': [132], 'labeled': [133, 143], 'than': [135], 'supervised': [136], 'baseline': [137], 'that': [138], 'marks': [139], '23.86\\%': [140], '10\\%': [142], 'The': [145], 'code': [146], 'is': [147], 'available': [148], 'at': [149], 'https://github.com/google-research/ssl_detection/.': [150]}",2020,"['Simple (philosophy)', 'Computer science', 'Artificial intelligence', 'Object (grammar)', 'Machine learning', 'Pattern recognition (psychology)', 'Epistemology', 'Philosophy']","Semi-supervised learning (SSL) has a potential to improve the predictive performance of machine learning models using unlabeled data. Although there has been remarkable recent progress, the scope of demonstration in SSL has mainly been on image classification tasks. In this paper, we propose STAC, a simple yet effective SSL framework for visual object detection along with a data augmentation strategy. STAC deploys highly confident pseudo labels of localized objects from an unlabeled image and updates the model by enforcing consistency via strong augmentations. We propose experimental protocols to evaluate the performance of semi-supervised object detection using MS-COCO and show the efficacy of STAC on both MS-COCO and VOC07. On VOC07, STAC improves the AP$^{0.5}$ from $76.30$ to $79.08$; on MS-COCO, STAC demonstrates $2{\times}$ higher data efficiency by achieving 24.38 mAP using only 5\% labeled data than supervised baseline that marks 23.86\% using 10\% labeled data. The code is available at https://github.com/google-research/ssl_detection/."
https://openalex.org/W2963250052,Unsupervised and Semi-supervised Learning with Categorical Generative\n Adversarial Networks,"{'In': [0], 'this': [1], 'paper': [2], 'we': [3, 84], 'present': [4], 'a': [5, 9, 52], 'method': [6, 81], 'for': [7], 'learning': [8], 'discriminative': [10], 'classifier\\nfrom': [11], 'unlabeled': [12], 'or': [13, 61], 'partially': [14], 'labeled': [15], 'data.': [16], 'Our': [17], 'approach': [18], 'is': [19, 121], 'based': [20], 'on': [21, 92, 98], 'an': [22, 41, 63, 75], 'objective\\nfunction': [23], 'that': [24, 120], 'trades-off': [25], 'mutual': [26], 'information': [27, 68], 'between': [28, 129], 'observed': [29], 'examples': [30], 'and': [31, 126, 133], 'their\\npredicted': [32], 'categorical': [33, 86], 'class': [34], 'distribution,': [35], 'against': [36, 74], 'robustness': [37, 104], 'of': [38, 55, 65, 105, 114], 'the': [39, 56, 66, 103, 106, 112, 117, 124, 130], 'classifier\\nto': [40], 'adversarial': [42, 58, 118], 'generative': [43, 57], 'model.': [44], 'The': [45], 'resulting': [46], 'algorithm': [47], 'can': [48], 'either': [49], 'be\\ninterpreted': [50], 'as': [51, 62, 95, 97, 137], 'natural': [53], 'generalization': [54], 'networks\\n(GAN)': [59], 'framework': [60, 70], 'extension': [64], 'regularized': [67], 'maximization\\n(RIM)': [69], 'to': [71], 'robust': [72], 'classification': [73, 100], 'optimal': [76], 'adversary.': [77], 'We\\nempirically': [78], 'evaluate': [79], 'our': [80], '-': [82, 91], 'which': [83], 'dub': [85], 'generative\\nadversarial': [87], 'networks': [88], '(or': [89], 'CatGAN)': [90], 'synthetic': [93], 'data': [94], 'well': [96], 'challenging\\nimage': [99], 'tasks,': [101], 'demonstrating': [102], 'learned\\nclassifiers.': [107], 'We': [108], 'further': [109], 'qualitatively': [110], 'assess': [111], 'fidelity': [113], 'samples': [115], 'generated\\nby': [116], 'generator': [119], 'learned': [122], 'alongside': [123], 'discriminative\\nclassifier,': [125], 'identify': [127], 'links': [128], 'CatGAN': [131], 'objective': [132], 'discriminative\\nclustering': [134], 'algorithms': [135], '(such': [136], 'RIM).\\n': [138]}",2015,"['Discriminative model', 'Artificial intelligence', 'Generative grammar', 'Classifier (UML)', 'Computer science', 'Adversarial system', 'Machine learning', 'Categorical variable', 'Pattern recognition (psychology)', 'Robustness (evolution)', 'Cluster analysis', 'Chemistry', 'Gene', 'Biochemistry']","In this paper we present a method for learning a discriminative classifier\nfrom unlabeled or partially labeled data. Our approach is based on an objective\nfunction that trades-off mutual information between observed examples and their\npredicted categorical class distribution, against robustness of the classifier\nto an adversarial generative model. The resulting algorithm can either be\ninterpreted as a natural generalization of the generative adversarial networks\n(GAN) framework or as an extension of the regularized information maximization\n(RIM) framework to robust classification against an optimal adversary. We\nempirically evaluate our method - which we dub categorical generative\nadversarial networks (or CatGAN) - on synthetic data as well as on challenging\nimage classification tasks, demonstrating the robustness of the learned\nclassifiers. We further qualitatively assess the fidelity of samples generated\nby the adversarial generator that is learned alongside the discriminative\nclassifier, and identify links between the CatGAN objective and discriminative\nclustering algorithms (such as RIM).\n"
https://openalex.org/W2315403234,Revisiting Semi-Supervised Learning with Graph Embeddings,"{'We': [0, 35], 'present': [1], 'a': [2, 11, 76, 95], 'semi-supervised': [3], 'learning': [4], 'framework': [5], 'based': [6], 'on': [7, 88], 'graph': [8, 12], 'embeddings.': [9], 'Given': [10], 'between': [13], 'instances,': [14], 'we': [15, 113], 'train': [16], 'an': [17], 'embedding': [18], 'for': [19], 'each': [20], 'instance': [21], 'to': [22], 'jointly': [23], 'predict': [24], 'the': [25, 29, 33, 46, 52, 59, 68, 71, 80, 120], 'class': [26, 53], 'label': [27], 'and': [28, 39, 62, 97, 110], 'neighborhood': [30], 'context': [31], 'in': [32, 67], 'graph.': [34], 'develop': [36], 'both': [37, 58], 'transductive': [38, 47], 'inductive': [40, 69], 'variants': [41], 'of': [42, 49, 79, 100, 119], 'our': [43, 50], 'method.': [44], 'In': [45], 'variant': [48], 'method,': [51], 'labels': [54], 'are': [55, 73], 'determined': [56], 'by': [57], 'learned': [60], 'embeddings': [61, 72], 'input': [63], 'feature': [64, 81], 'vectors,': [65, 82], 'while': [66], 'variant,': [70], 'defined': [74], 'as': [75], 'parametric': [77], 'function': [78], 'so': [83], 'predictions': [84], 'can': [85], 'be': [86], 'made': [87], 'instances': [89], 'not': [90], 'seen': [91], 'during': [92], 'training.': [93], 'On': [94], 'large': [96], 'diverse': [98], 'set': [99], 'benchmark': [101], 'tasks,': [102], 'including': [103], 'text': [104], 'classification,': [105, 112], 'distantly': [106], 'supervised': [107], 'entity': [108, 111], 'extraction,': [109], 'show': [114], 'improved': [115], 'performance': [116], 'over': [117], 'many': [118], 'existing': [121], 'models.': [122]}",2016,"['Computer science', 'Embedding', 'Graph', 'Artificial intelligence', 'Supervised learning', 'Machine learning', 'Semi-supervised learning', 'Benchmark (surveying)', 'Graph embedding', 'Class (philosophy)', 'Pattern recognition (psychology)', 'Theoretical computer science', 'Artificial neural network', 'Geography', 'Geodesy']","We present a semi-supervised learning framework based on graph embeddings. Given a graph between instances, we train an embedding for each instance to jointly predict the class label and the neighborhood context in the graph. We develop both transductive and inductive variants of our method. In the transductive variant of our method, the class labels are determined by both the learned embeddings and input feature vectors, while in the inductive variant, the embeddings are defined as a parametric function of the feature vectors, so predictions can be made on instances not seen during training. On a large and diverse set of benchmark tasks, including text classification, distantly supervised entity extraction, and entity classification, we show improved performance over many of the existing models."
https://openalex.org/W2022732522,Semi-supervised learning for potential human microRNA-disease associations inference,"{'MicroRNAs': [0], 'play': [1], 'critical': [2], 'role': [3], 'in': [4, 26, 33, 157, 164], 'the': [5, 27, 31, 47, 79, 91, 112, 165], 'development': [6], 'and': [7, 51, 72, 103, 106, 121, 130], 'progression': [8], 'of': [9, 19, 94, 125, 132], 'various': [10], 'diseases.': [11], 'Predicting': [12], 'potential': [13, 135, 168], 'miRNA-disease': [14], 'associations': [15, 76, 136, 180], 'from': [16], 'vast': [17], 'amount': [18], 'biological': [20, 145], 'data': [21], 'is': [22, 64, 187], 'an': [23], 'important': [24], 'problem': [25], 'biomedical': [28, 198], 'research.': [29], 'Considering': [30], 'limitations': [32], 'previous': [34], 'methods,': [35], 'we': [36], 'developed': [37], 'Regularized': [38], 'Least': [39], 'Squares': [40], 'for': [41, 56, 77, 110, 175, 197], 'MiRNA-Disease': [42], 'Association': [43], '(RLSMDA)': [44], 'to': [45, 100, 151], 'uncover': [46], 'relationship': [48], 'between': [49], 'diseases': [50, 57, 80, 113, 152], 'miRNAs.': [52, 61], 'RLSMDA': [53, 99, 150, 174, 190], 'can': [54], 'work': [55], 'without': [58, 153], 'known': [59, 154], 'related': [60, 155, 169], 'Furthermore,': [62], 'it': [63], 'a': [65, 116, 162, 193], 'semi-supervised': [66], '(does': [67], 'not': [68], 'need': [69], 'negative': [70], 'samples)': [71], 'global': [73, 108, 139], 'method': [74], '(prioritize': [75], 'all': [78, 111], 'simultaneously).': [81], 'Based': [82], 'on': [83, 138], 'leave-one-out': [84], 'cross': [85], 'validation,': [86], 'reliable': [87, 92], 'AUC': [88], 'have': [89, 141], 'demonstrated': [90], 'performance': [93], 'RLSMDA.': [95], 'We': [96, 147], 'also': [97, 148], 'applied': [98, 149], 'Hepatocellular': [101], 'cancer': [102, 105], 'Lung': [104], 'implemented': [107], 'prediction': [109, 140], 'simultaneously.': [114], 'As': [115, 161], 'result,': [117, 163], '80%': [118], '(Hepatocellular': [119], 'cancer)': [120, 124], '84%': [122], '(Lung': [123], 'top': [126, 133, 166], '50': [127], 'predicted': [128, 172], 'miRNAs': [129, 156], '75%': [131], '20': [134], 'based': [137], 'been': [142], 'confirmed': [143, 183], 'by': [144, 173, 184], 'experiments.': [146, 185], 'golden': [158], 'standard': [159], 'dataset.': [160], '3': [167], 'miRNA': [170], 'list': [171], '32': [176], 'diseases,': [177], '34': [178], 'disease-miRNA': [179], 'were': [181], 'successfully': [182], 'It': [186], 'anticipated': [188], 'that': [189], 'would': [191], 'be': [192], 'useful': [194], 'bioinformatics': [195], 'resource': [196], 'researches.': [199]}",2014,"['Inference', 'microRNA', 'Disease', 'Computational biology', 'Lung cancer', 'Bioinformatics', 'Cancer', 'Machine learning', 'Computer science', 'Biology', 'Medicine', 'Artificial intelligence', 'Oncology', 'Pathology', 'Genetics', 'Gene']","MicroRNAs play critical role in the development and progression of various diseases. Predicting potential miRNA-disease associations from vast amount of biological data is an important problem in the biomedical research. Considering the limitations in previous methods, we developed Regularized Least Squares for MiRNA-Disease Association (RLSMDA) to uncover the relationship between diseases and miRNAs. RLSMDA can work for diseases without known related miRNAs. Furthermore, it is a semi-supervised (does not need negative samples) and global method (prioritize associations for all the diseases simultaneously). Based on leave-one-out cross validation, reliable AUC have demonstrated the reliable performance of RLSMDA. We also applied RLSMDA to Hepatocellular cancer and Lung cancer and implemented global prediction for all the diseases simultaneously. As a result, 80% (Hepatocellular cancer) and 84% (Lung cancer) of top 50 predicted miRNAs and 75% of top 20 potential associations based on global prediction have been confirmed by biological experiments. We also applied RLSMDA to diseases without known related miRNAs in golden standard dataset. As a result, in the top 3 potential related miRNA list predicted by RLSMDA for 32 diseases, 34 disease-miRNA associations were successfully confirmed by experiments. It is anticipated that RLSMDA would be a useful bioinformatics resource for biomedical researches."
https://openalex.org/W2869264951,Computational Principles of Supervised Learning in the Cerebellum,"{'Supervised': [0], 'learning': [1, 22, 56, 145], 'plays': [2], 'a': [3, 35], 'key': [4], 'role': [5], 'in': [6, 123, 128], 'the': [7, 18, 26, 33, 52, 58, 116], 'operation': [8], 'of': [9, 17, 32, 66, 99, 115], 'many': [10], 'biological': [11], 'and': [12, 29, 43, 92, 104, 127, 146], 'artificial': [13, 129], 'neural': [14, 130], 'networks.': [15], 'Analysis': [16], 'computations': [19], 'underlying': [20], 'supervised': [21, 55, 144], 'is': [23], 'facilitated': [24], 'by': [25], 'relatively': [27], 'simple': [28], 'uniform': [30], 'architecture': [31], 'cerebellum,': [34], 'brain': [36, 125], 'area': [37], 'that': [38, 51, 88], 'supports': [39], 'numerous': [40], 'motor,': [41], 'sensory,': [42], 'cognitive': [44], 'functions.': [45], 'We': [46], 'highlight': [47], 'recent': [48], 'discoveries': [49], 'indicating': [50], 'cerebellum': [53, 117], 'implements': [54], 'using': [57], 'following': [59], 'organizational': [60], 'principles:': [61], '(': [62, 72, 78, 83, 95, 105], 'a)': [63], 'extensive': [64], 'preprocessing': [65], 'input': [67], 'representations': [68], '(i.e.,': [69], 'feature': [70], 'engineering),': [71], 'b)': [73], 'massively': [74], 'recurrent': [75], 'circuit': [76], 'architecture,': [77], 'c)': [79], 'linear': [80], 'input–output': [81], 'computations,': [82], 'd)': [84], 'sophisticated': [85], 'instructive': [86], 'signals': [87], 'can': [89, 139], 'be': [90], 'regulated': [91], 'are': [93], 'predictive,': [94], 'e)': [96], 'adaptive': [97], 'mechanisms': [98], 'plasticity': [100], 'with': [101, 121], 'multiple': [102], 'timescales,': [103], 'f)': [106], 'task-specific': [107], 'hardware': [108], 'specializations.': [109], 'The': [110], 'principles': [111], 'emerging': [112], 'from': [113], 'studies': [114], 'have': [118], 'striking': [119], 'parallels': [120], 'those': [122], 'other': [124], 'areas': [126], 'networks,': [131], 'as': [132, 134], 'well': [133], 'some': [135], 'notable': [136], 'differences,': [137], 'which': [138], 'inform': [140], 'future': [141], 'research': [142], 'on': [143], 'inspire': [147], 'next-generation': [148], 'machine-based': [149], 'algorithms.': [150]}",2018,"['Computer science', 'Artificial intelligence', 'Machine learning', 'Supervised learning', 'Motor learning', 'Artificial neural network', 'Neuroscience', 'Cerebellum', 'Psychology']","Supervised learning plays a key role in the operation of many biological and artificial neural networks. Analysis of the computations underlying supervised learning is facilitated by the relatively simple and uniform architecture of the cerebellum, a brain area that supports numerous motor, sensory, and cognitive functions. We highlight recent discoveries indicating that the cerebellum implements supervised learning using the following organizational principles: ( a) extensive preprocessing of input representations (i.e., feature engineering), ( b) massively recurrent circuit architecture, ( c) linear input–output computations, ( d) sophisticated instructive signals that can be regulated and are predictive, ( e) adaptive mechanisms of plasticity with multiple timescales, and ( f) task-specific hardware specializations. The principles emerging from studies of the cerebellum have striking parallels with those in other brain areas and in artificial neural networks, as well as some notable differences, which can inform future research on supervised learning and inspire next-generation machine-based algorithms."
https://openalex.org/W2996501936,ReMixMatch: Semi-Supervised Learning with Distribution Matching and Augmentation Anchoring,"{'We': [0], 'improve': [1], 'the': [2, 22, 34, 52, 62, 69, 84, 88, 116], 'recently-proposed': [3], '``MixMatch': [4], 'semi-supervised': [5], 'learning': [6], 'algorithm': [7], 'by': [8], 'introducing': [9], 'two': [10], 'new': [11, 94], 'techniques:': [12], 'distribution': [13, 24, 36], 'alignment': [14, 20], 'and': [15, 54, 109, 140], 'augmentation': [16, 85], 'anchoring.': [17], '-': [18, 40], 'Distribution': [19], 'encourages': [21, 55], 'marginal': [23, 35], 'of': [25, 37, 48, 68, 80, 135, 144], 'predictions': [26], 'on': [27, 121], 'unlabeled': [28], 'data': [29, 113], 'to': [30, 33, 58, 61, 114, 132], 'be': [31, 59], 'close': [32, 60], 'ground-truth': [38], 'labels.': [39], 'Augmentation': [41], 'anchoring}': [42], 'feeds': [43], 'multiple': [44], 'strongly': [45], 'augmented': [46], 'versions': [47], 'an': [49], 'input': [50], 'into': [51], 'model': [53, 89], 'each': [56], 'output': [57], 'prediction': [63], 'for': [64], 'a': [65, 78, 141], 'weakly-augmented': [66], 'version': [67], 'same': [70, 117], 'input.': [71], 'To': [72], 'produce': [73], 'strong': [74], 'augmentations,': [75], 'we': [76, 127], 'propose': [77], 'variant': [79], 'AutoAugment': [81], 'which': [82], 'learns': [83], 'policy': [86], 'while': [87], 'is': [90, 98], 'being': [91], 'trained.': [92], 'Our': [93], 'algorithm,': [95], 'dubbed': [96], 'ReMixMatch,': [97], 'significantly': [99], 'more': [100], 'data-efficient': [101], 'than': [102], 'prior': [103], 'work,': [104], 'requiring': [105], 'between': [106], '5': [107], 'times': [108, 111], '16': [110], 'less': [112], 'reach': [115, 128], 'accuracy.': [118], 'For': [119], 'example,': [120], 'CIFAR-10': [122], 'with': [123, 137, 146], '250': [124], 'labeled': [125], 'examples': [126], '93.73%': [129], 'accuracy': [130, 134, 143], '(compared': [131], ""MixMatch's"": [133], '93.58%': [136], '4000': [138], 'examples)': [139], 'median': [142], '84.92%': [145], 'just': [147], 'four': [148], 'labels': [149], 'per': [150], 'class.': [151]}",2020,"['Anchoring', 'Matching (statistics)', 'Computer science', 'Ground truth', 'Artificial intelligence', 'Labeled data', 'Class (philosophy)', 'Distribution (mathematics)', 'Pattern recognition (psychology)', 'Algorithm', 'Machine learning', 'Mathematics', 'Statistics', 'Engineering', 'Mathematical analysis', 'Structural engineering']","We improve the recently-proposed ``MixMatch semi-supervised learning algorithm by introducing two new techniques: distribution alignment and augmentation anchoring. - Distribution alignment encourages the marginal distribution of predictions on unlabeled data to be close to the marginal distribution of ground-truth labels. - Augmentation anchoring} feeds multiple strongly augmented versions of an input into the model and encourages each output to be close to the prediction for a weakly-augmented version of the same input. To produce strong augmentations, we propose a variant of AutoAugment which learns the augmentation policy while the model is being trained. Our new algorithm, dubbed ReMixMatch, is significantly more data-efficient than prior work, requiring between 5 times and 16 times less data to reach the same accuracy. For example, on CIFAR-10 with 250 labeled examples we reach 93.73% accuracy (compared to MixMatch's accuracy of 93.58% with 4000 examples) and a median accuracy of 84.92% with just four labels per class."
https://openalex.org/W3034749675,An Overview of Deep Semi-Supervised Learning,"{'Deep': [0], 'neural': [1, 97], 'networks': [2, 98], 'demonstrated': [3], 'their': [4], 'ability': [5], 'to': [6, 75, 95, 99, 139], 'provide': [7, 127], 'remarkable': [8], 'performances': [9], 'on': [10, 23], 'a': [11, 37, 67, 85, 119, 128, 144], 'wide': [12], 'range': [13], 'of': [14, 26, 40, 61, 103, 131, 146], 'supervised': [15], 'learning': [16, 64, 73, 91, 116, 121], 'tasks': [17], '(e.g.,': [18, 29], 'image': [19], 'classification)': [20], 'when': [21], 'trained': [22], 'extensive': [24], 'collections': [25], 'labeled': [27, 104], 'data': [28, 105], 'ImageNet).': [30], 'However,': [31], 'creating': [32], 'such': [33], 'large': [34, 80], 'datasets': [35], 'requires': [36], 'considerable': [38], 'amount': [39, 102], 'resources,': [41], 'time,': [42], 'and': [43, 58, 92], 'effort.': [44], 'Such': [45], 'resources': [46], 'may': [47], 'not': [48], 'be': [49], 'available': [50], 'in': [51, 89, 151], 'many': [52, 62], 'practical': [53], 'cases,': [54], 'limiting': [55], 'the': [56, 59, 77, 101, 140, 147], 'adoption': [57], 'application': [60], 'deep': [63, 72, 96, 120, 132, 152], 'methods.': [65], 'In': [66, 123], 'search': [68], 'for': [69, 79, 118], 'more': [70], 'data-efficient': [71], 'methods': [74, 111], 'overcome': [76], 'need': [78], 'annotated': [81], 'datasets,': [82], 'there': [83], 'is': [84], 'rising': [86], 'research': [87], 'interest': [88], 'semi-supervised': [90, 115, 133, 149], 'its': [93], 'applications': [94], 'reduce': [100], 'required,': [106], 'by': [107, 143], 'either': [108], 'developing': [109], 'novel': [110], 'or': [112], 'adopting': [113], 'existing': [114], 'frameworks': [117], 'setting.': [122], 'this': [124], 'paper,': [125], 'we': [126], 'comprehensive': [129], 'overview': [130], 'learning,': [134], 'starting': [135], 'with': [136], 'an': [137], 'introduction': [138], 'field,': [141], 'followed': [142], 'summarization': [145], 'dominant': [148], 'approaches': [150], 'learning.': [153]}",2020,"['Deep learning', 'Artificial intelligence', 'Computer science', 'Machine learning', 'Automatic summarization', 'Semi-supervised learning', 'Supervised learning', 'Field (mathematics)', 'Deep neural networks', 'Limiting', 'Artificial neural network', 'Engineering', 'Mathematics', 'Pure mathematics', 'Mechanical engineering']","Deep neural networks demonstrated their ability to provide remarkable performances on a wide range of supervised learning tasks (e.g., image classification) when trained on extensive collections of labeled data (e.g., ImageNet). However, creating such large datasets requires a considerable amount of resources, time, and effort. Such resources may not be available in many practical cases, limiting the adoption and the application of many deep learning methods. In a search for more data-efficient deep learning methods to overcome the need for large annotated datasets, there is a rising research interest in semi-supervised learning and its applications to deep neural networks to reduce the amount of labeled data required, by either developing novel methods or adopting existing semi-supervised learning frameworks for a deep learning setting. In this paper, we provide a comprehensive overview of deep semi-supervised learning, starting with an introduction to the field, followed by a summarization of the dominant semi-supervised approaches in deep learning."
https://openalex.org/W2178768799,Unsupervised and Semi-supervised Learning with Categorical Generative Adversarial Networks,"{'In': [0], 'this': [1], 'paper': [2], 'we': [3, 92], 'present': [4], 'a': [5, 9, 57], 'method': [6, 89], 'for': [7], 'learning': [8], 'discriminative': [10, 137, 147], 'classifier': [11, 43], 'from': [12], 'unlabeled': [13], 'or': [14, 67], 'partially': [15], 'labeled': [16], 'data.': [17], 'Our': [18], 'approach': [19], 'is': [20, 133], 'based': [21], 'on': [22, 101, 107], 'an': [23, 45, 69, 82], 'objective': [24, 145], 'function': [25], 'that': [26, 132], 'trades-off': [27], 'mutual': [28], 'information': [29, 74], 'between': [30, 142], 'observed': [31], 'examples': [32], 'and': [33, 139, 146], 'their': [34], 'predicted': [35], 'categorical': [36, 94], 'class': [37], 'distribution,': [38], 'against': [39, 81], 'robustness': [40, 114], 'of': [41, 60, 71, 115, 125], 'the': [42, 61, 72, 113, 116, 123, 129, 136, 143], 'to': [44, 78], 'adversarial': [46, 63, 96, 130], 'generative': [47, 62, 95], 'model.': [48], 'The': [49], 'resulting': [50], 'algorithm': [51], 'can': [52], 'either': [53], 'be': [54], 'interpreted': [55], 'as': [56, 68, 104, 106, 151], 'natural': [58], 'generalization': [59], 'networks': [64, 97], '(GAN)': [65], 'framework': [66, 77], 'extension': [70], 'regularized': [73], 'maximization': [75], '(RIM)': [76], 'robust': [79], 'classification': [80, 110], 'optimal': [83], 'adversary.': [84], 'We': [85, 119], 'empirically': [86], 'evaluate': [87], 'our': [88], '-': [90, 100], 'which': [91], 'dub': [93], '(or': [98], 'CatGAN)': [99], 'synthetic': [102], 'data': [103], 'well': [105], 'challenging': [108], 'image': [109], 'tasks,': [111], 'demonstrating': [112], 'learned': [117, 134], 'classifiers.': [118], 'further': [120], 'qualitatively': [121], 'assess': [122], 'fidelity': [124], 'samples': [126], 'generated': [127], 'by': [128], 'generator': [131], 'alongside': [135], 'classifier,': [138], 'identify': [140], 'links': [141], 'CatGAN': [144], 'clustering': [148], 'algorithms': [149], '(such': [150], 'RIM).': [152]}",2015,"['Discriminative model', 'Artificial intelligence', 'Generative grammar', 'Classifier (UML)', 'Computer science', 'Adversarial system', 'Machine learning', 'Categorical variable', 'Pattern recognition (psychology)', 'Robustness (evolution)', 'Cluster analysis', 'Gene', 'Biochemistry', 'Chemistry']","In this paper we present a method for learning a discriminative classifier from unlabeled or partially labeled data. Our approach is based on an objective function that trades-off mutual information between observed examples and their predicted categorical class distribution, against robustness of the classifier to an adversarial generative model. The resulting algorithm can either be interpreted as a natural generalization of the generative adversarial networks (GAN) framework or as an extension of the regularized information maximization (RIM) framework to robust classification against an optimal adversary. We empirically evaluate our method - which we dub categorical generative adversarial networks (or CatGAN) - on synthetic data as well as on challenging image classification tasks, demonstrating the robustness of the learned classifiers. We further qualitatively assess the fidelity of samples generated by the adversarial generator that is learned alongside the discriminative classifier, and identify links between the CatGAN objective and discriminative clustering algorithms (such as RIM)."
https://openalex.org/W3129850062,Self-Supervised Learning of Graph Neural Networks: A Unified Review,"{'Deep': [0], 'models': [1], 'trained': [2], 'in': [3, 110, 154, 171], 'supervised': [4], 'mode': [5], 'have': [6], 'achieved': [7, 40], 'remarkable': [8], 'success': [9, 58], 'on': [10, 43, 126], 'a': [11, 26, 53, 72, 98, 166], 'variety': [12], 'of': [13, 32, 35, 75, 78, 119, 131, 175], 'tasks.': [14, 49], 'When': [15], 'labeled': [16], 'samples': [17], 'are': [18], 'limited,': [19], 'self-supervised': [20], 'learning': [21, 48], '(SSL)': [22], 'is': [23, 52], 'emerging': [24], 'as': [25, 103, 105], 'new': [27, 139], 'paradigm': [28], 'for': [29, 101, 122, 137, 169], 'making': [30], 'use': [31], 'large': [33], 'amounts': [34], 'unlabeled': [36], 'samples.': [37], 'SSL': [38, 86, 120, 147, 170], 'has': [39], 'promising': [41], 'performance': [42], 'natural': [44], 'language': [45], 'and': [46, 90, 129, 141, 149, 161, 180], 'image': [47], 'Recently,': [50], 'there': [51], 'trend': [54], 'to': [55, 59], 'extend': [56], 'such': [57], 'graph': [60, 63], 'data': [61], 'using': [62, 81], 'neural': [64], 'networks': [65], '(GNNs).': [66], 'In': [67, 93], 'this': [68], 'survey,': [69], 'we': [70, 84, 96, 164], 'provide': [71, 97], 'unified': [73, 99, 117], 'review': [74], 'different': [76, 146], 'ways': [77], 'training': [79], 'GNNs': [80, 123], 'SSL.': [82], 'Specifically,': [83], 'categorize': [85], 'methods': [87, 102, 108, 121, 140], 'into': [88], 'contrastive': [89], 'predictive': [91], 'models.': [92], 'either': [94], 'category,': [95], 'framework': [100], 'well': [104], 'how': [106], 'these': [107], 'differ': [109], 'each': [111, 155], 'component': [112], 'under': [113], 'the': [114, 127, 135, 150], 'framework.': [115], 'Our': [116], 'treatment': [118], 'sheds': [124], 'light': [125], 'similarities': [128], 'differences': [130], 'various': [132], 'methods,': [133, 178], 'setting': [134], 'stage': [136], 'developing': [138], 'algorithms.': [142], 'We': [143], 'also': [144], 'summarize': [145], 'settings': [148], 'corresponding': [151], 'datasets': [152], 'used': [153], 'setting.': [156], 'To': [157], 'facilitate': [158], 'methodological': [159], 'development': [160], 'empirical': [162], 'comparison,': [163], 'develop': [165], 'standardized': [167], 'testbed': [168], 'GNNs,': [172], 'including': [173], 'implementations': [174], 'common': [176], 'baseline': [177], 'datasets,': [179], 'evaluation': [181], 'metrics.': [182]}",2022,"['Computer science', 'Artificial intelligence', 'Machine learning', 'Categorization', 'Graph', 'Testbed', 'Artificial neural network', 'Theoretical computer science', 'Computer network']","Deep models trained in supervised mode have achieved remarkable success on a variety of tasks. When labeled samples are limited, self-supervised learning (SSL) is emerging as a new paradigm for making use of large amounts of unlabeled samples. SSL has achieved promising performance on natural language and image learning tasks. Recently, there is a trend to extend such success to graph data using graph neural networks (GNNs). In this survey, we provide a unified review of different ways of training GNNs using SSL. Specifically, we categorize SSL methods into contrastive and predictive models. In either category, we provide a unified framework for methods as well as how these methods differ in each component under the framework. Our unified treatment of SSL methods for GNNs sheds light on the similarities and differences of various methods, setting the stage for developing new methods and algorithms. We also summarize different SSL settings and the corresponding datasets used in each setting. To facilitate methodological development and empirical comparison, we develop a standardized testbed for SSL in GNNs, including implementations of common baseline methods, datasets, and evaluation metrics."
https://openalex.org/W3133518153,Anomaly Detection on Attributed Networks via Contrastive Self-Supervised Learning,"{'Anomaly': [0, 114], 'detection': [1, 29, 79, 115], 'on': [2, 39, 116, 265], 'attributed': [3, 14, 117], 'networks': [4, 15, 40, 90, 118, 251], 'attracts': [5], 'considerable': [6], 'research': [7], 'interests': [8], 'due': [9, 91], 'to': [10, 86, 88, 92, 169, 203, 249], 'wide': [11, 19], 'applications': [12], 'of': [13, 21, 64, 137, 183, 207, 231, 237, 241], 'in': [16, 68, 80, 102, 153], 'modeling': [17], 'a': [18, 107, 134, 158, 222], 'range': [20], 'complex': [22, 45], 'systems.': [23], 'Recently,': [24], 'the': [25, 61, 65, 93, 126, 144, 181, 196, 205, 216, 229, 232, 242, 261], 'deep': [26], 'learning-based': [27], 'anomaly': [28, 78, 224], 'methods': [30, 73, 264], 'have': [31], 'shown': [32], 'promising': [33], 'results': [34, 254], 'over': [35], 'shallow': [36], 'approaches,': [37, 49], 'especially': [38], 'with': [41, 187, 210], 'high-dimensional': [42, 174], 'attributes': [43, 175], 'and': [44, 84, 149, 176, 179], 'structures.': [46], 'However,': [47], 'existing': [48], 'which': [50, 141], 'employ': [51], 'graph': [52, 95, 160], 'autoencoder': [53], 'as': [54], 'their': [55, 81], 'backbone,': [56], 'do': [57, 74], 'not': [58, 75], 'fully': [59, 124], 'exploit': [60], 'rich': [62], 'information': [63, 128], 'network,': [66, 244], 'resulting': [67], 'suboptimal': [69], 'performance.': [70], 'Furthermore,': [71, 227], 'these': [72, 100], 'directly': [76], 'target': [77], 'learning': [82, 165, 198, 217], 'objective': [83], 'fail': [85], 'scale': [87], 'large': [89, 250], 'full': [94, 243], 'training': [96], 'mechanism.': [97], 'To': [98], 'overcome': [99], 'limitations,': [101], 'this': [103, 214], 'article,': [104], 'we': [105], 'present': [106], 'novel': [108, 135], 'Contrastive': [109], 'self-supervised': [110], 'Learning': [111], 'framework': [112, 123, 246, 259], 'for': [113, 120], '(CoLA': [119], 'abbreviation).': [121], 'Our': [122], 'exploits': [125], 'local': [127, 177], 'from': [129, 173], 'network': [130, 162], 'data': [131, 269], 'by': [132, 195, 221], 'sampling': [133], 'type': [136], 'contrastive': [138, 164, 197], 'instance': [139, 185, 238], 'pair,': [140], 'can': [142, 247], 'capture': [143], 'relationship': [145], 'between': [146], 'each': [147, 184, 208], 'node': [148, 209], 'its': [150, 188], 'neighboring': [151], 'substructure': [152], 'an': [154], 'unsupervised': [155], 'way.': [156], 'Meanwhile,': [157], 'well-designed': [159], 'neural': [161], '(GNN)-based': [163], 'model': [166, 199, 218], 'is': [167, 219, 235], 'proposed': [168, 258], 'learn': [170], 'informative': [171], 'embedding': [172], 'structure': [178], 'measure': [180], 'agreement': [182], 'pairs': [186, 239], 'outputted': [189], 'scores.': [190], 'The': [191], 'multiround': [192], 'predicted': [193], 'scores': [194], 'are': [200], 'further': [201], 'used': [202], 'evaluate': [204], 'abnormality': [206], 'statistical': [211], 'estimation.': [212], 'In': [213], 'way,': [215], 'trained': [220], 'specific': [223], 'detection-aware': [225], 'target.': [226], 'since': [228], 'input': [230], 'GNN': [233], 'module': [234], 'batches': [236], 'instead': [240], 'our': [245, 257], 'adapt': [248], 'flexibly.': [252], 'Experimental': [253], 'show': [255], 'that': [256], 'outperforms': [260], 'state-of-the-art': [262], 'baseline': [263], 'all': [266], 'seven': [267], 'benchmark': [268], 'sets.': [270]}",2021,"['Computer science', 'Anomaly detection', 'Autoencoder', 'Artificial intelligence', 'Exploit', 'Graph', 'Anomaly (physics)', 'Deep learning', 'Machine learning', 'Unsupervised learning', 'Feature learning', 'Pattern recognition (psychology)', 'Data mining', 'Theoretical computer science', 'Physics', 'Condensed matter physics', 'Computer security']","Anomaly detection on attributed networks attracts considerable research interests due to wide applications of attributed networks in modeling a wide range of complex systems. Recently, the deep learning-based anomaly detection methods have shown promising results over shallow approaches, especially on networks with high-dimensional attributes and complex structures. However, existing approaches, which employ graph autoencoder as their backbone, do not fully exploit the rich information of the network, resulting in suboptimal performance. Furthermore, these methods do not directly target anomaly detection in their learning objective and fail to scale to large networks due to the full graph training mechanism. To overcome these limitations, in this article, we present a novel Contrastive self-supervised Learning framework for Anomaly detection on attributed networks (CoLA for abbreviation). Our framework fully exploits the local information from network data by sampling a novel type of contrastive instance pair, which can capture the relationship between each node and its neighboring substructure in an unsupervised way. Meanwhile, a well-designed graph neural network (GNN)-based contrastive learning model is proposed to learn informative embedding from high-dimensional attributes and local structure and measure the agreement of each instance pairs with its outputted scores. The multiround predicted scores by the contrastive learning model are further used to evaluate the abnormality of each node with statistical estimation. In this way, the learning model is trained by a specific anomaly detection-aware target. Furthermore, since the input of the GNN module is batches of instance pairs instead of the full network, our framework can adapt to large networks flexibly. Experimental results show that our proposed framework outperforms the state-of-the-art baseline methods on all seven benchmark data sets."
https://openalex.org/W3099025572,Multi-task Self-Supervised Learning for Human Activity Detection,"{'Deep': [0], 'learning': [1, 77, 79, 112, 192, 218, 285], 'methods': [2], 'are': [3, 59, 259], 'successfully': [4], 'used': [5], 'in': [6, 48, 160, 187, 313], 'applications': [7], 'pertaining': [8], 'to': [9, 36, 39, 50, 89, 121, 137, 200, 307], 'ubiquitous': [10], 'computing,': [11], 'pervasive': [12], 'intelligence,': [13], 'health,': [14], 'and': [15, 31, 71, 190, 211, 281, 303], 'well-being.': [16], 'Specifically,': [17], 'the': [18, 29, 83, 91, 156, 170, 176, 223, 226, 231, 257, 269, 277, 295, 298], 'area': [19], 'of': [20, 56, 86, 94, 124, 155, 271, 311], 'human': [21], 'activity': [22, 128, 209, 273], 'recognition': [23], '(HAR)': [24], 'is': [25, 62, 85, 301], 'primarily': [26], 'transformed': [27], 'by': [28, 68, 98, 234], 'convolutional': [30, 135], 'recurrent': [32], 'neural': [33], 'networks,': [34], 'thanks': [35], 'their': [37], 'ability': [38], 'learn': [40, 131], 'semantic': [41, 125], 'representations': [42], 'directly': [43, 207], 'from': [44, 113, 261], 'raw': [45], 'input.': [46], 'However,': [47], 'order': [49], 'extract': [51], 'generalizable': [52], 'features': [53, 168, 228, 258], 'massive': [54], 'amounts': [55], 'well-curated': [57], 'data': [58, 96, 115, 264], 'required,': [60], 'which': [61], 'a': [63, 106, 132, 161, 236, 262, 308], 'notoriously': [64], 'challenging': [65], 'task;': [66], 'hindered': [67], 'privacy': [69], 'issues': [70], 'annotation': [72], 'costs.': [73], 'Therefore,': [74], 'unsupervised': [75, 217, 282], 'representation': [76], '(i.e.,': [78], 'without': [80], 'manually': [81], 'labeling': [82], 'instances)': [84], 'prime': [87], 'importance': [88], 'leverage': [90], 'vast': [92], 'amount': [93], 'unlabeled': [95], 'produced': [97], 'smart': [99], 'devices.': [100], 'In': [101], 'this': [102, 289], 'work,': [103], 'we': [104, 149], 'propose': [105], 'novel': [107], 'self-supervised': [108, 227], 'technique': [109], 'for': [110, 165, 169, 184, 222, 284], 'feature': [111], 'sensory': [114], 'that': [116, 151], 'does': [117], 'not': [118], 'require': [119], 'access': [120], 'any': [122], 'form': [123], 'labels,': [126, 210], 'i.e.,': [127], 'classes.': [129], 'We': [130, 173, 250], 'multi-task': [133], 'temporal': [134], 'network': [136], 'recognize': [138], 'transformations': [139], 'applied': [140, 306], 'on': [141, 179, 292], 'an': [142], 'input': [143], 'signal.': [144], 'By': [145], 'exploiting': [146], 'these': [147], 'transformations,': [148], 'demonstrate': [150], 'simple': [152], 'auxiliary': [153], 'tasks': [154], 'binary': [157], 'classification': [158], 'result': [159], 'strong': [162], 'supervisory': [163], 'signal': [164], 'extracting': [166], 'useful': [167], 'down-stream': [171], 'task.': [172], 'extensively': [174], 'evaluate': [175], 'proposed': [177, 299], 'approach': [178, 300], 'several': [180], 'publicly': [181], 'available': [182], 'datasets': [183], 'smartphone-based': [185], 'HAR': [186, 293], 'unsupervised,': [188], 'semi-supervised': [189, 224], 'transfer': [191], 'settings.': [193], 'Our': [194], 'method': [195], 'achieves': [196], 'performance': [197, 254], 'levels': [198], 'superior': [199], 'or': [201], 'comparable': [202], 'with': [203, 208, 243], 'fully-supervised': [204], 'networks': [205], 'trained': [206], 'it': [212], 'performs': [213], 'significantly': [214], 'better': [215], 'than': [216], 'through': [219], 'autoencoders.': [220], 'Notably,': [221], 'case,': [225], 'substantially': [229], 'boost': [230], 'detection': [232], 'rate': [233], 'attaining': [235], 'kappa': [237], 'score': [238], 'between': [239, 279], '0.7': [240], '-': [241], '0.8': [242], 'only': [244], '10': [245], 'labeled': [246, 272], 'examples': [247], 'per': [248], 'class.': [249], 'get': [251], 'similar': [252], 'impressive': [253], 'even': [255], 'if': [256], 'transferred': [260], 'different': [263], 'source.': [265], 'Self-supervision': [266], 'drastically': [267], 'reduces': [268], 'requirement': [270], 'data,': [274], 'effectively': [275], 'narrowing': [276], 'gap': [278], 'supervised': [280], 'techniques': [283], 'meaningful': [286], 'representations.': [287], 'While': [288], 'paper': [290], 'focuses': [291], 'as': [294], 'application': [296], 'domain,': [297], 'general': [302], 'could': [304], 'be': [305], 'wide': [309], 'variety': [310], 'problems': [312], 'other': [314], 'areas.': [315]}",2019,"['Computer science', 'Artificial intelligence', 'Leverage (statistics)', 'Feature learning', 'Transfer of learning', 'Machine learning', 'Convolutional neural network', 'Supervised learning', 'Task (project management)', 'Deep learning', 'Labeled data', 'Binary classification', 'Unsupervised learning', 'Semi-supervised learning', 'Pattern recognition (psychology)', 'Artificial neural network', 'Support vector machine', 'Economics', 'Management']","Deep learning methods are successfully used in applications pertaining to ubiquitous computing, pervasive intelligence, health, and well-being. Specifically, the area of human activity recognition (HAR) is primarily transformed by the convolutional and recurrent neural networks, thanks to their ability to learn semantic representations directly from raw input. However, in order to extract generalizable features massive amounts of well-curated data are required, which is a notoriously challenging task; hindered by privacy issues and annotation costs. Therefore, unsupervised representation learning (i.e., learning without manually labeling the instances) is of prime importance to leverage the vast amount of unlabeled data produced by smart devices. In this work, we propose a novel self-supervised technique for feature learning from sensory data that does not require access to any form of semantic labels, i.e., activity classes. We learn a multi-task temporal convolutional network to recognize transformations applied on an input signal. By exploiting these transformations, we demonstrate that simple auxiliary tasks of the binary classification result in a strong supervisory signal for extracting useful features for the down-stream task. We extensively evaluate the proposed approach on several publicly available datasets for smartphone-based HAR in unsupervised, semi-supervised and transfer learning settings. Our method achieves performance levels superior to or comparable with fully-supervised networks trained directly with activity labels, and it performs significantly better than unsupervised learning through autoencoders. Notably, for the semi-supervised case, the self-supervised features substantially boost the detection rate by attaining a kappa score between 0.7 - 0.8 with only 10 labeled examples per class. We get similar impressive performance even if the features are transferred from a different data source. Self-supervision drastically reduces the requirement of labeled activity data, effectively narrowing the gap between supervised and unsupervised techniques for learning meaningful representations. While this paper focuses on HAR as the application domain, the proposed approach is general and could be applied to a wide variety of problems in other areas."
https://openalex.org/W2954540134,Using Self-Supervised Learning Can Improve Model Robustness and Uncertainty,"{'Self-supervision': [0], 'provides': [1], 'effective': [2], 'representations': [3], 'for': [4, 30, 84, 99], 'downstream': [5], 'tasks': [6, 93], 'without': [7], 'requiring': [8], 'labels.': [9], 'However,': [10], 'existing': [11], 'approaches': [12], 'lag': [13], 'behind': [14], 'fully': [15, 74], 'supervised': [16, 75], 'training': [17], 'and': [18, 51, 87, 90], 'are': [19], 'often': [20], 'not': [21], 'thought': [22], 'beneficial': [23], 'beyond': [24], 'obviating': [25], 'or': [26], 'reducing': [27], 'the': [28, 71, 80], 'need': [29], 'annotations.': [31], 'We': [32], 'find': [33], 'that': [34, 68], 'self-supervision': [35, 56, 83], 'can': [36], 'benefit': [37], 'robustness': [38, 45, 86], 'in': [39], 'a': [40], 'variety': [41], 'of': [42, 73, 82, 97], 'ways,': [43], 'including': [44], 'to': [46], 'adversarial': [47], 'examples,': [48], 'label': [49], 'corruption,': [50], 'common': [52], 'input': [53], 'corruptions.': [54], 'Additionally,': [55], 'greatly': [57], 'benefits': [58], 'out-of-distribution': [59], 'detection': [60], 'on': [61], 'difficult,': [62], 'near-distribution': [63], 'outliers,': [64], 'so': [65, 67], 'much': [66], 'it': [69], 'exceeds': [70], 'performance': [72], 'methods.': [76], 'These': [77], 'results': [78], 'demonstrate': [79], 'promise': [81], 'improving': [85], 'uncertainty': [88], 'estimation': [89], 'establish': [91], 'these': [92], 'as': [94], 'new': [95], 'axes': [96], 'evaluation': [98], 'future': [100], 'self-supervised': [101], 'learning': [102], 'research.': [103]}",2019,"['Robustness (evolution)', 'Outlier', 'Computer science', 'Machine learning', 'Artificial intelligence', 'Adversarial system', 'Chemistry', 'Gene', 'Biochemistry']","Self-supervision provides effective representations for downstream tasks without requiring labels. However, existing approaches lag behind fully supervised training and are often not thought beneficial beyond obviating or reducing the need for annotations. We find that self-supervision can benefit robustness in a variety of ways, including robustness to adversarial examples, label corruption, and common input corruptions. Additionally, self-supervision greatly benefits out-of-distribution detection on difficult, near-distribution outliers, so much so that it exceeds the performance of fully supervised methods. These results demonstrate the promise of self-supervision for improving robustness and uncertainty estimation and establish these tasks as new axes of evaluation for future self-supervised learning research."
https://openalex.org/W2979476256,vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations,"{'We': [0], 'propose': [1], 'vq-wav2vec': [2], 'to': [3, 28], 'learn': [4], 'discrete': [5, 46], 'representations': [6], 'of': [7, 38, 57], 'audio': [8], 'segments': [9], 'through': [10], 'a': [11, 21, 54], 'wav2vec-style': [12], 'self-supervised': [13], 'context': [14], 'prediction': [15], 'task.': [16], 'The': [17], 'algorithm': [18], 'uses': [19], 'either': [20], 'gumbel': [22], 'softmax': [23], 'or': [24], 'online': [25], 'k-means': [26], 'clustering': [27], 'quantize': [29], 'the': [30, 35, 41, 58], 'dense': [31], 'representations.': [32], 'Discretization': [33], 'enables': [34], 'direct': [36], 'application': [37], 'algorithms': [39], 'from': [40], 'NLP': [42], 'community': [43], 'which': [44], 'require': [45], 'inputs.': [47], 'Experiments': [48], 'show': [49], 'that': [50], 'BERT': [51], 'pre-training': [52], 'achieves': [53], 'new': [55], 'state': [56], 'art': [59], 'on': [60], 'TIMIT': [61], 'phoneme': [62], 'classification': [63], 'and': [64], 'WSJ': [65], 'speech': [66], 'recognition.': [67]}",2019,"['TIMIT', 'Softmax function', 'Computer science', 'Speech recognition', 'Artificial intelligence', 'Cluster analysis', 'Task (project management)', 'Discretization', 'Context (archaeology)', 'Pattern recognition (psychology)', 'Natural language processing', 'Hidden Markov model', 'Artificial neural network', 'Mathematics', 'Mathematical analysis', 'Paleontology', 'Management', 'Economics', 'Biology']",We propose vq-wav2vec to learn discrete representations of audio segments through a wav2vec-style self-supervised context prediction task. The algorithm uses either a gumbel softmax or online k-means clustering to quantize the dense representations. Discretization enables the direct application of algorithms from the NLP community which require discrete inputs. Experiments show that BERT pre-training achieves a new state of the art on TIMIT phoneme classification and WSJ speech recognition.
https://openalex.org/W2794908468,Semi-supervised learning: a brief review,"{'Most': [0], 'of': [1, 59, 99, 103], 'the': [2, 34, 97], 'application': [3], 'domain': [4, 28], 'suffers': [5], 'from': [6], 'not': [7], 'having': [8], 'sufficient': [9], 'labeled': [10, 20], 'data': [11, 14, 36], 'whereas': [12], 'unlabeled': [13, 35], 'is': [15, 23, 73], 'available': [16], 'cheaply.': [17], 'To': [18], 'get': [19], 'instances,': [21], 'it': [22], 'very': [24], 'difficult': [25], 'because': [26], 'experienced': [27], 'experts': [29], 'are': [30], 'required': [31], 'to': [32, 76], 'label': [33], 'patterns.': [37], 'Semi-supervised': [38, 60, 77, 80, 104], 'learning': [39, 61, 91], 'addresses': [40, 56, 96], 'this': [41], 'problem': [42], 'and': [43, 51, 79, 89, 101], 'act': [44], 'as': [45, 64], 'a': [46], 'half': [47], 'way': [48], 'between': [49], 'supervised': [50, 88], 'unsupervised': [52, 90], 'learning.': [53, 105], 'This': [54], 'paper': [55, 94], 'few': [57], 'techniques': [58], '(SSL)': [62], 'such': [63], 'self-training,': [65], 'co-training,': [66], 'multi-view': [67], 'learning,': [68], 'TSVMs': [69], 'methods.': [70], 'Traditionally': [71], 'SSL': [72], 'classified': [74], 'in': [75], 'Classification': [78], 'Clustering': [81], 'which': [82], 'achieves': [83], 'better': [84], 'accuracy': [85], 'than': [86], 'traditional': [87], 'techniques.': [92], 'The': [93], 'also': [95], 'issue': [98], 'scalability': [100], 'applications': [102]}",2018,"['Semi-supervised learning', 'Computer science', 'Unsupervised learning', 'Machine learning', 'Artificial intelligence', 'Supervised learning', 'Labeled data', 'Cluster analysis', 'Scalability', 'Domain (mathematical analysis)', 'Co-training', 'Pattern recognition (psychology)', 'Artificial neural network', 'Mathematics', 'Database', 'Mathematical analysis']","Most of the application domain suffers from not having sufficient labeled data whereas unlabeled data is available cheaply. To get labeled instances, it is very difficult because experienced domain experts are required to label the unlabeled data patterns. Semi-supervised learning addresses this problem and act as a half way between supervised and unsupervised learning. This paper addresses few techniques of Semi-supervised learning (SSL) such as self-training, co-training, multi-view learning, TSVMs methods. Traditionally SSL is classified in to Semi-supervised Classification and Semi-supervised Clustering which achieves better accuracy than traditional supervised and unsupervised learning techniques. The paper also addresses the issue of scalability and applications of Semi-supervised learning."
https://openalex.org/W3041561163,TERA: Self-Supervised Learning of Transformer Encoder Representation for Speech,"{'We': [0, 88, 103, 144], 'introduce': [1], 'a': [2, 21, 45, 65, 105], 'self-supervised': [3, 109], 'speech': [4, 81, 101], 'pre-training': [5, 136, 141], 'method': [6, 175], 'called': [7], 'TERA,': [8], 'which\\nstands': [9], 'for': [10, 80, 165], 'Transformer': [11], 'Encoder': [12], 'Representations': [13], 'from': [14, 59], 'Alteration.': [15], 'Recent\\napproaches': [16], 'often': [17], 'learn': [18], 'by': [19, 117], 'using': [20], 'single': [22], 'auxiliary': [23], 'task': [24], 'like': [25], 'contrastive\\nprediction,': [26], 'autoregressive': [27], 'prediction,': [28], 'or': [29, 83], 'masked': [30], 'reconstruction.': [31], 'Unlike\\nprevious': [32], 'methods,': [33], 'we': [34, 63, 128, 172], 'use': [35, 64], 'alteration': [36], 'along': [37, 70], 'three': [38], 'orthogonal': [39], 'axes': [40], 'to': [41, 68, 178], 'pre-train\\nTransformer': [42], 'Encoders': [43], 'on': [44, 91, 137, 142], 'large': [46], 'amount': [47], 'of': [48, 56, 132], 'unlabeled': [49], 'speech.': [50], 'The': [51], 'model': [52, 147], 'learns\\nthrough': [53], 'the': [54, 130], 'reconstruction': [55], 'acoustic': [57], 'frames': [58], 'their': [60], 'altered': [61], 'counterpart,\\nwhere': [62], 'stochastic': [66], 'policy': [67], 'alter': [69], 'various': [71], 'dimensions:': [72], 'time,\\nfrequency,': [73], 'and': [74, 100, 122, 140, 149], 'magnitude.': [75], 'TERA': [76, 90, 111], 'can': [77], 'be': [78], 'used': [79, 182], 'representations\\nextraction': [82], 'fine-tuning': [84, 167], 'with': [85], 'downstream': [86, 166, 179], 'models.': [87, 110, 170], 'evaluate': [89], 'several\\ndownstream': [92], 'tasks,': [93], 'including': [94], 'phoneme': [95], 'classification,': [96], 'keyword': [97], 'spotting,': [98], 'speaker\\nrecognition,': [99], 'recognition.': [102], 'present': [104], 'large-scale': [106], 'comparison': [107], 'of\\nvarious': [108], 'achieves': [112], 'strong': [113], 'performance': [114], 'in': [115], 'the\\ncomparison': [116], 'improving': [118], 'upon': [119], 'surface': [120], 'features': [121], 'outperforming': [123], 'previous\\nmodels.': [124], 'In': [125], 'our': [126], 'experiments,': [127], 'study': [129], 'effect': [131], 'applying': [133], 'different\\nalteration': [134], 'techniques,': [135], 'more': [138], 'data,': [139], 'various\\nfeatures.': [143], 'analyze': [145], 'different': [146], 'sizes': [148], 'find': [150], 'that': [151], 'smaller': [152, 169], 'models': [153, 162], 'are\\nstrong': [154], 'representation': [155], 'learners': [156], 'than': [157, 168], 'larger': [158, 161], 'models,': [159], 'while': [160], 'are': [163], 'more\\neffective': [164], 'Furthermore,': [171], 'show\\nthe': [173], 'proposed': [174], 'is': [176], 'transferable': [177], 'datasets': [180], 'not': [181], 'in\\npre-training.\\n': [183]}",2021,"['Tera-', 'Computer science', 'Transformer', 'Encoder', 'Autoregressive model', 'Speech recognition', 'Keyword spotting', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Machine learning', 'Mathematics', 'Engineering', 'Voltage', 'Operating system', 'Electrical engineering', 'Econometrics']","We introduce a self-supervised speech pre-training method called TERA, which\nstands for Transformer Encoder Representations from Alteration. Recent\napproaches often learn by using a single auxiliary task like contrastive\nprediction, autoregressive prediction, or masked reconstruction. Unlike\nprevious methods, we use alteration along three orthogonal axes to pre-train\nTransformer Encoders on a large amount of unlabeled speech. The model learns\nthrough the reconstruction of acoustic frames from their altered counterpart,\nwhere we use a stochastic policy to alter along various dimensions: time,\nfrequency, and magnitude. TERA can be used for speech representations\nextraction or fine-tuning with downstream models. We evaluate TERA on several\ndownstream tasks, including phoneme classification, keyword spotting, speaker\nrecognition, and speech recognition. We present a large-scale comparison of\nvarious self-supervised models. TERA achieves strong performance in the\ncomparison by improving upon surface features and outperforming previous\nmodels. In our experiments, we study the effect of applying different\nalteration techniques, pre-training on more data, and pre-training on various\nfeatures. We analyze different model sizes and find that smaller models are\nstrong representation learners than larger models, while larger models are more\neffective for downstream fine-tuning than smaller models. Furthermore, we show\nthe proposed method is transferable to downstream datasets not used in\npre-training.\n"
https://openalex.org/W4288020585,ReMixMatch: Semi-Supervised Learning with Distribution Alignment and\n Augmentation Anchoring,"{'We': [0, 135], 'improve': [1], 'the': [2, 19, 30, 45, 54, 61, 74, 78, 102], 'recently-proposed': [3], '""MixMatch""': [4], 'semi-supervised': [5], 'learning\\nalgorithm': [6], 'by': [7], 'introducing': [8], 'two': [9], 'new': [10], 'techniques:': [11], 'distribution': [12], 'alignment': [13, 17], 'and\\naugmentation': [14], 'anchoring.': [15], 'Distribution': [16], 'encourages': [18, 48], 'marginal\\ndistribution': [20, 31], 'of': [21, 32, 41, 60, 71, 119, 127], 'predictions': [22], 'on': [23, 106], 'unlabeled': [24], 'data': [25, 99, 139], 'to': [26, 29, 50, 53, 100, 116], 'be': [27, 51], 'close': [28, 52], 'ground-truth': [33], 'labels.': [34], 'Augmentation': [35], 'anchoring': [36], 'feeds': [37], 'multiple\\nstrongly': [38], 'augmented': [39], 'versions': [40], 'an': [42], 'input': [43], 'into': [44], 'model': [46, 79], 'and': [47, 96, 138], 'each\\noutput': [49], 'prediction': [55], 'for': [56], 'a': [57, 69, 124], 'weakly-augmented': [58], 'version': [59], 'same\\ninput.': [62], 'To': [63], 'produce': [64], 'strong': [65], 'augmentations,': [66], 'we': [67, 112], 'propose': [68], 'variant': [70], 'AutoAugment\\nwhich': [72], 'learns': [73], 'augmentation': [75], 'policy': [76], 'while': [77], 'is': [80, 87], 'being': [81], 'trained.': [82], 'Our': [83], 'new\\nalgorithm,': [84], 'dubbed': [85], 'ReMixMatch,': [86], 'significantly': [88], 'more': [89], 'data-efficient': [90], 'than': [91], 'prior\\nwork,': [92], 'requiring': [93], 'between': [94], '$5\\\\times$': [95], '$16\\\\times$': [97], 'less': [98], 'reach': [101, 113], 'same\\naccuracy.': [103], 'For': [104], 'example,': [105], 'CIFAR-10': [107], 'with': [108, 121, 129], '250': [109], 'labeled': [110], 'examples': [111], '$93.73\\\\%$\\naccuracy': [114], '(compared': [115], ""MixMatch's"": [117], 'accuracy': [118, 126], '$93.58\\\\%$': [120], '$4{,}000$': [122], 'examples)\\nand': [123], 'median': [125], '$84.92\\\\%$': [128], 'just': [130], 'four': [131], 'labels': [132], 'per': [133], 'class.': [134], 'make': [136], 'our\\ncode': [137], 'open-source': [140], 'at': [141], 'https://github.com/google-research/remixmatch.\\n': [142]}",2019,"['Anchoring', 'Computer science', 'Code (set theory)', 'Ground truth', 'Class (philosophy)', 'Artificial intelligence', 'Labeled data', 'Distribution (mathematics)', 'Pattern recognition (psychology)', 'Machine learning', 'Mathematics', 'Set (abstract data type)', 'Psychology', 'Social psychology', 'Programming language', 'Mathematical analysis']","We improve the recently-proposed ""MixMatch"" semi-supervised learning\nalgorithm by introducing two new techniques: distribution alignment and\naugmentation anchoring. Distribution alignment encourages the marginal\ndistribution of predictions on unlabeled data to be close to the marginal\ndistribution of ground-truth labels. Augmentation anchoring feeds multiple\nstrongly augmented versions of an input into the model and encourages each\noutput to be close to the prediction for a weakly-augmented version of the same\ninput. To produce strong augmentations, we propose a variant of AutoAugment\nwhich learns the augmentation policy while the model is being trained. Our new\nalgorithm, dubbed ReMixMatch, is significantly more data-efficient than prior\nwork, requiring between $5\\times$ and $16\\times$ less data to reach the same\naccuracy. For example, on CIFAR-10 with 250 labeled examples we reach $93.73\\%$\naccuracy (compared to MixMatch's accuracy of $93.58\\%$ with $4{,}000$ examples)\nand a median accuracy of $84.92\\%$ with just four labels per class. We make our\ncode and data open-source at https://github.com/google-research/remixmatch.\n"
https://openalex.org/W4286695273,VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning,"{'Recent': [0], 'self-supervised': [1], 'methods': [2, 129], 'for': [3], 'image': [4], 'representation': [5], 'learning': [6, 45], 'are': [7], 'based': [8, 95], 'on': [9, 76, 96, 105, 113], 'maximizing': [10], 'the': [11, 20, 29, 44, 68, 77, 80, 88, 108, 111, 132], 'agreement': [12], 'between': [13], 'embedding': [14], 'vectors': [15], 'from': [16], 'different': [17], 'views': [18], 'of': [19, 79, 110], 'same': [21], 'image.': [22], 'A': [23], 'trivial': [24], 'solution': [25], 'is': [26, 37], 'obtained': [27], 'when': [28], 'encoder': [30], 'outputs': [31], 'constant': [32], 'vectors.': [33], 'This': [34], 'collapse': [35, 69], 'problem': [36, 70], 'often': [38, 48], 'avoided': [39], 'through': [40], 'implicit': [41], 'biases': [42], 'in': [43], 'architecture,': [46], 'that': [47, 65, 121], 'lack': [49], 'a': [50, 63, 72, 92], 'clear': [51], 'justification': [52], 'or': [53], 'interpretation.': [54], 'In': [55, 117], 'this': [56], 'paper,': [57], 'we': [58, 119], 'introduce': [59], 'VICReg': [60, 86], '(Variance-Invariance-Covariance': [61], 'Regularization),': [62], 'method': [64], 'explicitly': [66], 'avoids': [67], 'with': [71, 91, 107], 'simple': [73], 'regularization': [74], 'term': [75, 90, 126], 'variance': [78, 89, 125], 'embeddings': [81], 'along': [82], 'each': [83], 'dimension': [84], 'individually.': [85], 'combines': [87], 'decorrelation': [93], 'mechanism': [94], 'redundancy': [97], 'reduction': [98], 'and': [99, 102, 134], 'covariance': [100], 'regularization,': [101], 'achieves': [103], 'results': [104], 'par': [106], 'state': [109], 'art': [112], 'several': [114], 'downstream': [115], 'tasks.': [116], 'addition,': [118], 'show': [120], 'incorporating': [122], 'our': [123], 'new': [124], 'into': [127], 'other': [128], 'helps': [130], 'stabilize': [131], 'training': [133], 'leads': [135], 'to': [136], 'performance': [137], 'improvements.': [138]}",2021,"['Regularization (linguistics)', 'Decorrelation', 'Covariance', 'Embedding', 'Computer science', 'Algorithm', 'Artificial intelligence', 'Mathematics', 'Statistics']","Recent self-supervised methods for image representation learning are based on maximizing the agreement between embedding vectors from different views of the same image. A trivial solution is obtained when the encoder outputs constant vectors. This collapse problem is often avoided through implicit biases in the learning architecture, that often lack a clear justification or interpretation. In this paper, we introduce VICReg (Variance-Invariance-Covariance Regularization), a method that explicitly avoids the collapse problem with a simple regularization term on the variance of the embeddings along each dimension individually. VICReg combines the variance term with a decorrelation mechanism based on redundancy reduction and covariance regularization, and achieves results on par with the state of the art on several downstream tasks. In addition, we show that incorporating our new variance term into other methods helps stabilize the training and leads to performance improvements."
https://openalex.org/W3040739508,ProtTrans: Towards Cracking the Language of Life’s Code Through Self-Supervised Learning,"{'Abstract': [0], 'Computational': [1], 'biology': [2], 'and': [3, 38, 50, 70, 135], 'bioinformatics': [4], 'provide': [5], 'vast': [6], 'data': [7, 47, 87], 'gold-mines': [8], 'from': [9, 17, 48, 85], 'protein': [10, 82, 93, 117, 129, 176], 'sequences,': [11], 'ideal': [12], 'for': [13, 22, 106, 154], 'Language': [14], 'Models': [15], 'taken': [16], 'NLP.': [18], 'These': [19], 'LMs': [20, 60, 177], 'reach': [21], 'new': [23], 'prediction': [24, 115], 'frontiers': [25], 'at': [26, 197], 'low': [27], 'inference': [28], 'costs.': [29], 'Here,': [30], 'we': [31, 193], 'trained': [32, 62], 'two': [33], 'auto-regressive': [34], 'models': [35, 41, 196], '(Transformer-XL,': [36], 'XLNet)': [37], 'four': [39], 'auto-encoder': [40], '(BERT,': [42], 'Albert,': [43], 'Electra,': [44], 'T5)': [45], 'on': [46, 63], 'UniRef': [49], 'BFD': [51], 'containing': [52], 'up': [53], 'to': [54], '393': [55], 'billion': [56], 'amino': [57], 'acids.': [58], 'The': [59, 110], 'were': [61, 125], 'the': [64, 80, 97, 101, 123, 143, 146, 149, 155, 159, 172, 181, 184], 'Summit': [65], 'supercomputer': [66], 'using': [67, 100, 162], '5616': [68], 'GPUs': [69], 'TPU': [71], 'Pod': [72], 'up-to': [73], '1024': [74], 'cores.': [75], 'Dimensionality': [76], 'reduction': [77], 'revealed': [78], 'that': [79, 175], 'raw': [81], 'LM-': [83], 'embeddings': [84, 102, 152], 'unlabeled': [86], 'captured': [88], 'some': [89, 179], 'biophysical': [90], 'features': [91], 'of': [92, 99, 116, 128, 148, 180, 183, 186], 'sequences.': [94], 'We': [95], 'validated': [96], 'advantage': [98], 'as': [103], 'exclusive': [104], 'input': [105], 'several': [107], 'subsequent': [108], 'tasks.': [109], 'first': [111, 156], 'was': [112], 'a': [113], 'per-residue': [114, 144], 'secondary': [118], 'structure': [119], '(3-state': [120], 'accuracy': [121, 140], 'Q3=81%-87%);': [122], 'second': [124], 'per-protein': [126], 'predictions': [127, 145], 'sub-cellular': [130], 'localization': [131], '(ten-state': [132], 'accuracy:': [133], 'Q10=81%)': [134], 'membrane': [136], 'vs.': [137], 'water-soluble': [138], '(2-state': [139], 'Q2=91%).': [141], 'For': [142], 'transfer': [147], 'most': [150], 'informative': [151], '(ProtT5)': [153], 'time': [157], 'outperformed': [158], 'state-of-the-art': [160], 'without': [161], 'evolutionary': [163], 'information': [164], 'thereby': [165], 'bypassing': [166], 'expensive': [167], 'database': [168], 'searches.': [169], 'Taken': [170], 'together,': [171], 'results': [173], 'implied': [174], 'learned': [178], 'grammar': [182], 'language': [185], 'life': [187], '.': [188, 199], 'To': [189], 'facilitate': [190], 'future': [191], 'work,': [192], 'released': [194], 'our': [195], 'https://github.com/agemagician/ProtTrans': [198]}",2020,[],"Abstract Computational biology and bioinformatics provide vast data gold-mines from protein sequences, ideal for Language Models taken from NLP. These LMs reach for new prediction frontiers at low inference costs. Here, we trained two auto-regressive models (Transformer-XL, XLNet) and four auto-encoder models (BERT, Albert, Electra, T5) on data from UniRef and BFD containing up to 393 billion amino acids. The LMs were trained on the Summit supercomputer using 5616 GPUs and TPU Pod up-to 1024 cores. Dimensionality reduction revealed that the raw protein LM- embeddings from unlabeled data captured some biophysical features of protein sequences. We validated the advantage of using the embeddings as exclusive input for several subsequent tasks. The first was a per-residue prediction of protein secondary structure (3-state accuracy Q3=81%-87%); the second were per-protein predictions of protein sub-cellular localization (ten-state accuracy: Q10=81%) and membrane vs. water-soluble (2-state accuracy Q2=91%). For the per-residue predictions the transfer of the most informative embeddings (ProtT5) for the first time outperformed the state-of-the-art without using evolutionary information thereby bypassing expensive database searches. Taken together, the results implied that protein LMs learned some of the grammar of the language of life . To facilitate future work, we released our models at https://github.com/agemagician/ProtTrans ."
https://openalex.org/W1516529420,Supervised learning in the brain,"{'Experience': [0], 'shapes': [1, 24], 'the': [2, 6, 14, 25, 49, 58, 74, 104, 109, 132, 136, 155, 160, 166, 175, 182, 186, 189, 199, 208, 214, 218, 225, 229, 232, 237, 254, 257, 266, 282, 319], 'functional': [3], 'organization': [4], 'of': [5, 40, 51, 85, 113, 116, 157, 168, 174, 181, 201, 210, 217, 231, 269, 284, 306, 322], 'brain,': [7], 'optimizing': [8], 'and': [9, 16, 88, 111, 192, 295], 'customizing': [10], 'its': [11], 'properties': [12], 'for': [13], 'individual': [15], 'his': [17], 'or': [18, 70], 'her': [19], 'environment.One': [20], 'way': [21], 'that': [22, 66, 92, 122, 143, 184, 264, 276, 286], 'experience': [23], 'constituent': [26], 'networks': [27, 121, 285], 'ofthe': [28], 'brain': [29, 117], 'is': [30, 77, 162, 274], 'through': [31], 'supervised': [32, 34, 81, 277, 311], 'learning.In': [33], 'learning,': [35], 'information': [36, 64, 171, 202], 'from': [37, 224, 236, 256], 'one': [38], 'network': [39, 60], 'neurons': [41, 212], 'acts': [42], 'as': [43, 292, 301, 313], 'an': [44, 261], 'instructive': [45, 75, 152, 262, 323], 'signal': [46, 76, 263], 'to': [47, 62, 96, 108, 164, 281], 'influence': [48], 'pattern': [50, 293], 'connectivity': [52, 86], 'in': [53, 103, 203, 207, 213, 252, 318], 'another': [54], 'network.As': [55], 'a': [56, 67, 90, 114, 140, 150], 'result,': [57], 'instructed': [59], 'learns': [61], 'process': [63], 'so': [65, 79], 'particular': [68], 'goal': [69], 'transformation': [71, 167], 'specified': [72], 'by': [73, 128], 'achieved.In': [78], 'doing,': [80], 'learning': [82, 106, 195, 278, 312], 'establishes': [83], 'patterns': [84], 'efficiently': [87], 'with': [89, 134], 'precision': [91], 'does': [93], 'not': [94], 'need': [95], 'be': [97, 101, 145, 250, 316], 'and,': [98], 'often,': [99], 'cannot': [100], 'encoded': [102], 'genome.Supervised': [105], 'contributes': [107, 280], 'development': [110, 209], 'maintenance': [112], 'variety': [115], 'functions.For': [118], 'example,': [119, 206, 246], 'sensorimotor': [120], 'control': [123, 198], 'goal-directed': [124], 'movements': [125, 137, 180], 'are': [126, 138], 'calibrated': [127], 'sensory': [129, 170, 204], 'feedback': [130], 'indicating': [131, 154], 'accuracy': [133], 'which': [135, 247], 'made.In': [139], 'specific': [141], 'example': [142], 'will': [144, 249], 'discussed': [146, 251], 'at': [147], 'some': [148], 'length,': [149], 'visual': [151, 233], 'signal,': [153], 'slip': [156], 'images': [158, 187], 'across': [159], 'retinae,': [161], 'used': [163], 'calibrate': [165], 'vestibular': [169], '(indicating': [172], 'rotation': [173], 'head)': [176], 'into': [177], 'precise,': [178], 'compensatory': [179], 'eyes': [183], 'stabilize': [185], 'on': [188], 'retinae': [190], '(Miles': [191], 'Eighmy,': [193], '1980).Supervised': [194], 'can': [196], 'also': [197, 248, 279], 'representation': [200], 'networks.For': [205], 'binocular': [211], 'optic': [215], 'tectum': [216], 'frog': [219], 'Xenopus,': [220], 'visually': [221], 'driven': [222], 'activity': [223, 255], 'contralateral': [226, 258], 'eye': [227, 239, 259], 'specifies': [228], 'topography': [230], 'map': [234], 'originating': [235], 'ipsilateral': [238], '(Gaze': [240], 'et': [241], 'al.,': [242], '1970;Udin,': [243], '1985).In': [244], 'this': [245, 307], 'detail,': [253], 'provides': [260], 'assures': [265], 'mutual': [267], 'alignment': [268], 'left-and': [270], 'right-eye': [271], 'receptive': [272], 'fields.It': [273], 'likely': [275], 'establishment': [283], 'support': [287], 'certain': [288], 'cognitive': [289], 'skills,': [290], 'such': [291], 'recognition': [294], 'language': [296], 'acquisition,': [297], 'although': [298], 'there': [299], 'is,': [300], 'yet,': [302], 'no': [303], 'experimental': [304], 'confirmation': [305], 'proposition.This': [308], 'article': [309], 'discusses': [310], 'it': [314], 'might': [315], 'implemented': [317], 'brain.Different': [320], 'kinds': [321], 'signals,': [324]}",1994,"['Psychology', 'Neuroscience', 'Cognitive science', 'Cognitive psychology']","Experience shapes the functional organization of the brain, optimizing and customizing its properties for the individual and his or her environment.One way that experience shapes the constituent networks ofthe brain is through supervised learning.In supervised learning, information from one network of neurons acts as an instructive signal to influence the pattern of connectivity in another network.As a result, the instructed network learns to process information so that a particular goal or transformation specified by the instructive signal is achieved.In so doing, supervised learning establishes patterns of connectivity efficiently and with a precision that does not need to be and, often, cannot be encoded in the genome.Supervised learning contributes to the development and maintenance of a variety of brain functions.For example, sensorimotor networks that control goal-directed movements are calibrated by sensory feedback indicating the accuracy with which the movements are made.In a specific example that will be discussed at some length, a visual instructive signal, indicating the slip of images across the retinae, is used to calibrate the transformation of vestibular sensory information (indicating rotation of the head) into precise, compensatory movements of the eyes that stabilize the images on the retinae (Miles and Eighmy, 1980).Supervised learning can also control the representation of information in sensory networks.For example, in the development of binocular neurons in the optic tectum of the frog Xenopus, visually driven activity from the contralateral eye specifies the topography of the visual map originating from the ipsilateral eye (Gaze et al., 1970;Udin, 1985).In this example, which also will be discussed in detail, the activity from the contralateral eye provides an instructive signal that assures the mutual alignment of left-and right-eye receptive fields.It is likely that supervised learning also contributes to the establishment of networks that support certain cognitive skills, such as pattern recognition and language acquisition, although there is, as yet, no experimental confirmation of this proposition.This article discusses supervised learning as it might be implemented in the brain.Different kinds of instructive signals,"
https://openalex.org/W2946856970,S4L: Self-Supervised Semi-Supervised Learning,"{'This': [0], 'work': [1], 'tackles': [2], 'the': [3, 16, 24, 39, 58], 'problem': [4], 'of': [5, 8, 18, 28, 41, 60, 99], 'semi-supervised': [6, 19, 43, 52, 72, 83, 95], 'learning': [7, 20, 44, 73], 'image': [9, 53], 'classifiers.': [10], 'Our': [11], 'main': [12], 'insight': [13], 'is': [14], 'that': [15, 78], 'field': [17, 27], 'can': [21, 85], 'benefit': [22], 'from': [23], 'quickly': [25], 'advancing': [26], 'self-supervised': [29, 42], 'visual': [30], 'representation': [31], 'learning.': [32], 'Unifying': [33], 'these': [34, 61], 'two': [35, 50], 'approaches,': [36], 'we': [37], 'propose': [38], 'framework': [40], 'and': [45, 70, 81], 'use': [46], 'it': [47], 'to': [48, 65], 'derive': [49], 'novel': [51], 'classification': [54], 'methods.': [55, 74], 'We': [56, 75], 'demonstrate': [57], 'effectiveness': [59], 'methods': [62, 84], 'in': [63], 'comparison': [64], 'both': [66], 'carefully': [67], 'tuned': [68], 'baselines,': [69], 'existing': [71, 82], 'then': [76], 'show': [77], 'our': [79], 'approach': [80], 'be': [86], 'jointly': [87], 'trained,': [88], 'yielding': [89], 'a': [90], 'new': [91], 'state-of-the-art': [92], 'result': [93], 'on': [94], 'ILSVRC-2012': [96], 'with': [97], '10%': [98], 'labels.': [100]}",2019,"['Semi-supervised learning', 'Supervised learning', 'Computer science', 'Machine learning', 'Artificial intelligence', 'Field (mathematics)', 'Representation (politics)', 'Unsupervised learning', 'Pattern recognition (psychology)', 'Mathematics', 'Artificial neural network', 'Pure mathematics', 'Law', 'Politics', 'Political science']","This work tackles the problem of semi-supervised learning of image classifiers. Our main insight is that the field of semi-supervised learning can benefit from the quickly advancing field of self-supervised visual representation learning. Unifying these two approaches, we propose the framework of self-supervised semi-supervised learning and use it to derive two novel semi-supervised image classification methods. We demonstrate the effectiveness of these methods in comparison to both carefully tuned baselines, and existing semi-supervised learning methods. We then show that our approach and existing semi-supervised methods can be jointly trained, yielding a new state-of-the-art result on semi-supervised ILSVRC-2012 with 10% of labels."
https://openalex.org/W2738853914,"WILDCAT: Weakly Supervised Learning of Deep ConvNets for Image Classification, Pointwise Localization and Segmentation","{'International': [0], 'audience': [1]}",2017,"['Artificial intelligence', 'Computer science', 'Convolutional neural network', 'Pattern recognition (psychology)', 'Pointwise', 'Contextual image classification', 'Image (mathematics)', 'Image segmentation', 'Deep learning', 'Segmentation', 'Class (philosophy)', 'Supervised learning', 'Artificial neural network', 'Computer vision', 'Machine learning', 'Mathematics', 'Mathematical analysis']",International audience
https://openalex.org/W2586937979,Supervised Learning of Semantics-Preserving Hash via Deep Convolutional Neural Networks,"{'This': [0], 'paper': [1], 'presents': [2], 'a': [3, 63, 67, 96, 106, 123, 141], 'simple': [4, 135], 'yet': [5, 151], 'effective': [6, 154], 'supervised': [7, 54], 'deep': [8, 56, 68, 147], 'hash': [9, 14, 60, 88, 118], 'approach': [10], 'that': [11, 25, 99], 'constructs': [12, 59], 'binary': [13, 72], 'codes': [15, 73, 89], 'from': [16], 'labeled': [17], 'data': [18], 'for': [19, 149], 'large-scale': [20, 131], 'image': [21, 116], 'search.': [22], 'We': [23], 'assume': [24], 'the': [26, 71, 176], 'semantic': [27], 'labels': [28], 'are': [29, 74, 103], 'governed': [30], 'by': [31, 76, 140], 'several': [32, 161], 'latent': [33, 64], 'attributes': [34], 'with': [35, 167], 'each': [36], 'attribute': [37], 'on': [38, 44, 48, 160], 'or': [39], 'off,': [40], 'and': [41, 70, 85, 101, 120, 126, 136, 155, 163], 'classification': [42, 83, 100, 121, 177], 'relies': [43], 'these': [45], 'attributes.': [46], 'Based': [47], 'this': [49, 92], 'assumption,': [50], 'our': [51], 'approach,': [52], 'dubbed': [53], 'semantics-preserving': [55], 'hashing': [57, 158], '(SSDH),': [58], 'functions': [61], 'as': [62], 'layer': [65], 'in': [66, 105, 122], 'network': [69], 'learned': [75], 'minimizing': [77], 'an': [78, 145], 'objective': [79], 'function': [80], 'defined': [81], 'over': [82], 'error': [84], 'other': [86, 157], 'desirable': [87], 'properties.': [90], 'With': [91], 'design,': [93], 'SSDH': [94, 111, 133, 170], 'has': [95], 'nice': [97], 'characteristic': [98], 'retrieval': [102, 173], 'unified': [104], 'single': [107], 'learning': [108, 114], 'model.': [109], 'Moreover,': [110], 'performs': [112], 'joint': [113], 'of': [115, 144], 'representations,': [117], 'codes,': [119], 'point-wised': [124], 'manner,': [125], 'thus': [127], 'is': [128, 134, 153, 179], 'scalable': [129], 'to': [130], 'datasets.': [132, 165], 'can': [137], 'be': [138], 'realized': [139], 'slight': [142], 'enhancement': [143], 'existing': [146], 'architecture': [148], 'classification;': [150], 'it': [152], 'outperforms': [156], 'approaches': [159], 'benchmarks': [162], 'large': [164], 'Compared': [166], 'state-of-the-art': [168], 'approaches,': [169], 'achieves': [171], 'higher': [172], 'accuracy,': [174], 'while': [175], 'performance': [178], 'not': [180], 'sacrificed.': [181]}",2017,"['Hash function', 'Computer science', 'Convolutional neural network', 'Scalability', 'Artificial intelligence', 'Deep learning', 'Feature hashing', 'Hash table', 'Semantics (computer science)', 'Pattern recognition (psychology)', 'Machine learning', 'Double hashing', 'Database', 'Computer security', 'Programming language']","This paper presents a simple yet effective supervised deep hash approach that constructs binary hash codes from labeled data for large-scale image search. We assume that the semantic labels are governed by several latent attributes with each attribute on or off, and classification relies on these attributes. Based on this assumption, our approach, dubbed supervised semantics-preserving deep hashing (SSDH), constructs hash functions as a latent layer in a deep network and the binary codes are learned by minimizing an objective function defined over classification error and other desirable hash codes properties. With this design, SSDH has a nice characteristic that classification and retrieval are unified in a single learning model. Moreover, SSDH performs joint learning of image representations, hash codes, and classification in a point-wised manner, and thus is scalable to large-scale datasets. SSDH is simple and can be realized by a slight enhancement of an existing deep architecture for classification; yet it is effective and outperforms other hashing approaches on several benchmarks and large datasets. Compared with state-of-the-art approaches, SSDH achieves higher retrieval accuracy, while the classification performance is not sacrificed."
https://openalex.org/W2619371851,Good Semi-supervised Learning that Requires a Bad GAN,"{'Semi-supervised': [0], 'learning': [1, 57], 'methods': [2], 'based': [3, 77], 'on': [4, 78, 91], 'generative': [5], 'adversarial': [6], 'networks': [7], '(GANs)': [8], 'obtained': [9, 42], 'strong': [10], 'empirical': [11], 'results,': [12], 'but': [13], 'it': [14], 'is': [15], 'not': [16], 'clear': [17], '1)': [18], 'how': [19], 'the': [20, 44, 52, 65], 'discriminator': [21, 53], 'benefits': [22], 'from': [23], 'joint': [24], 'training': [25], 'with': [26], 'a': [27, 37, 60, 68, 74], 'generator,': [28, 62], 'and': [29, 36, 63], '2)': [30], 'why': [31], 'good': [32, 38, 55], 'semi-supervised': [33], 'classification': [34], 'performance': [35], 'generator': [39], 'cannot': [40], 'be': [41], 'at': [43], 'same': [45], 'time.': [46], 'Theoretically,': [47], 'we': [48, 72], 'show': [49], 'that': [50, 81], 'given': [51], 'objective,': [54], 'semisupervised': [56], 'indeed': [58], 'requires': [59], 'bad': [61], 'propose': [64], 'definition': [66], 'of': [67], 'preferred': [69], 'generator.': [70], 'Empirically,': [71], 'derive': [73], 'novel': [75], 'formulation': [76], 'our': [79], 'analysis': [80], 'substantially': [82], 'improves': [83], 'over': [84], 'feature': [85], 'matching': [86], 'GANs,': [87], 'obtaining': [88], 'state-of-the-art': [89], 'results': [90], 'multiple': [92], 'benchmark': [93], 'datasets.': [94]}",2017,"['Discriminator', 'Generator (circuit theory)', 'Benchmark (surveying)', 'Computer science', 'Artificial intelligence', 'Machine learning', 'Generative grammar', 'Feature matching', 'Matching (statistics)', 'Feature (linguistics)', 'Supervised learning', 'Pattern recognition (psychology)', 'Artificial neural network', 'Feature extraction', 'Power (physics)', 'Mathematics', 'Statistics', 'Philosophy', 'Quantum mechanics', 'Detector', 'Geography', 'Linguistics', 'Geodesy', 'Telecommunications', 'Physics']","Semi-supervised learning methods based on generative adversarial networks (GANs) obtained strong empirical results, but it is not clear 1) how the discriminator benefits from joint training with a generator, and 2) why good semi-supervised classification performance and a good generator cannot be obtained at the same time. Theoretically, we show that given the discriminator objective, good semisupervised learning indeed requires a bad generator, and propose the definition of a preferred generator. Empirically, we derive a novel formulation based on our analysis that substantially improves over feature matching GANs, obtaining state-of-the-art results on multiple benchmark datasets."
https://openalex.org/W3154596443,"VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text","{'We': [0, 40, 84], 'present': [1], 'a': [2, 35, 73, 168], 'framework': [3], 'for': [4], 'learning': [5], 'multimodal': [6, 27, 47], 'representations': [7, 28], 'from': [8, 44, 147], 'unlabeled': [9], 'data': [10], 'using': [11, 46], 'convolution-free': [12, 88], 'Transformer': [13, 18, 76, 101, 146, 165], 'architectures.': [14], 'Specifically,': [15], 'our': [16, 153], 'Video-Audio-Text': [17], '(VATT)': [19], 'takes': [20], 'raw': [21], 'signals': [22], 'as': [23], 'inputs': [24], 'and': [25, 50, 67, 116, 161], 'extracts': [26], 'that': [29, 86], 'are': [30], 'rich': [31], 'enough': [32], 'to': [33, 129, 133, 140], 'benefit': [34], 'variety': [36], 'of': [37, 58, 106, 152, 180], 'downstream': [38, 56, 96], 'tasks.': [39, 97], 'train': [41], 'VATT': [42, 89], 'end-to-end': [43], 'scratch': [45], 'contrastive': [48], 'losses': [49], 'evaluate': [51], 'its': [52], 'performance': [53], 'by': [54, 77, 142, 176], 'the': [55, 81, 87, 95, 103, 144, 150, 156, 178], 'tasks': [57], 'video': [59], 'action': [60], 'recognition,': [61], 'audio': [62, 164, 173], 'event': [63, 174], 'classification,': [64, 66], 'image': [65, 130], 'text-to-video': [68], 'retrieval.': [69], 'Furthermore,': [70], 'we': [71], 'study': [72], 'modality-agnostic,': [74], 'single-backbone': [75], 'sharing': [78], 'weights': [79], 'among': [80], 'three': [82], 'modalities.': [83], 'show': [85], 'outperforms': [90], 'state-of-the-art': [91], 'ConvNet-based': [92], 'architectures': [93], 'in': [94, 120], 'Especially,': [98], ""VATT's"": [99, 163, 188], 'vision': [100], 'achieves': [102], 'top-1': [104, 135], 'accuracy': [105, 136], '82.1%': [107], 'on': [108, 111, 114, 118, 137, 171, 182], 'Kinetics-400,': [109], '83.6%': [110], 'Kinetics-600,': [112], '72.7%': [113], 'Kinetics-700,': [115], '41.1%': [117], 'Moments': [119], 'Time,': [121], 'new': [122, 169], 'records': [123], 'while': [124], 'avoiding': [125], 'supervised': [126, 186], 'pre-training.': [127, 187], 'Transferring': [128], 'classification': [131], 'leads': [132], '78.7%': [134], 'ImageNet': [138], 'compared': [139], '64.7%': [141], 'training': [143], 'same': [145], 'scratch,': [148], 'showing': [149], 'generalizability': [151], 'model': [154], 'despite': [155], 'domain': [157], 'gap': [158], 'between': [159], 'videos': [160], 'images.': [162], 'also': [166], 'sets': [167], 'record': [170], 'waveform-based': [172], 'recognition': [175], 'achieving': [177], 'mAP': [179], '39.4%': [181], 'AudioSet': [183], 'without': [184], 'any': [185], 'source': [189], 'code': [190], 'is': [191], 'publicly': [192], 'available.': [193]}",2021,"['Computer science', 'Transformer', 'Generalizability theory', 'Artificial intelligence', 'Action recognition', 'Speech recognition', 'Pattern recognition (psychology)', 'Voltage', 'Quantum mechanics', 'Mathematics', 'Physics', 'Statistics', 'Class (philosophy)']","We present a framework for learning multimodal representations from unlabeled data using convolution-free Transformer architectures. Specifically, our Video-Audio-Text Transformer (VATT) takes raw signals as inputs and extracts multimodal representations that are rich enough to benefit a variety of downstream tasks. We train VATT end-to-end from scratch using multimodal contrastive losses and evaluate its performance by the downstream tasks of video action recognition, audio event classification, image classification, and text-to-video retrieval. Furthermore, we study a modality-agnostic, single-backbone Transformer by sharing weights among the three modalities. We show that the convolution-free VATT outperforms state-of-the-art ConvNet-based architectures in the downstream tasks. Especially, VATT's vision Transformer achieves the top-1 accuracy of 82.1% on Kinetics-400, 83.6% on Kinetics-600, 72.7% on Kinetics-700, and 41.1% on Moments in Time, new records while avoiding supervised pre-training. Transferring to image classification leads to 78.7% top-1 accuracy on ImageNet compared to 64.7% by training the same Transformer from scratch, showing the generalizability of our model despite the domain gap between videos and images. VATT's audio Transformer also sets a new record on waveform-based audio event recognition by achieving the mAP of 39.4% on AudioSet without any supervised pre-training. VATT's source code is publicly available."
https://openalex.org/W2129947832,Weakly Supervised Learning of Interactions between Humans and Objects,"{'We': [0, 21, 141], 'introduce': [1], 'a': [2, 24, 51, 66, 83, 89, 100, 124, 163], 'weakly': [3], 'supervised': [4], 'approach': [5, 18, 63, 108], 'for': [6, 35], 'learning': [7], 'human': [8, 25, 67, 137], 'actions': [9], 'modeled': [10], 'as': [11], 'interactions': [12], 'between': [13, 135], 'humans': [14, 97], 'and': [15, 29, 38, 113, 138, 162], 'objects.': [16], 'Our': [17, 62], 'is': [19, 47, 123], 'human-centric:': [20], 'first': [22], 'localize': [23], 'in': [26, 99], 'the': [27, 32, 36, 43, 59, 71, 105, 110, 118, 128, 132, 136, 139, 148, 155], 'image': [28], 'then': [30], 'determine': [31], 'object': [33, 112], 'relevant': [34], 'action': [37, 60, 111, 150], 'its': [39, 114], 'spatial': [40, 115, 133], 'relation': [41, 116, 134], 'with': [42, 58], 'human.': [44, 119], 'The': [45], 'model': [46, 72, 126], 'learned': [48], 'automatically': [49], 'from': [50, 96, 153], 'set': [52, 90, 101, 152, 160], 'of': [53, 79, 91, 102, 127], 'still': [54], 'images': [55, 103], 'annotated': [56], 'only': [57], 'label.': [61], 'relies': [64], 'on': [65, 147], 'detector': [68, 84], 'to': [69, 76, 87, 117], 'initialize': [70], 'learning.': [73], 'For': [74], 'robustness': [75], 'various': [77], 'degrees': [78], 'visibility,': [80], 'we': [81], 'build': [82], 'that': [85], 'learns': [86], 'combine': [88], 'existing': [92], 'part': [93], 'detectors.': [94], 'Starting': [95], 'detected': [98], 'depicting': [104], 'action,': [106], 'our': [107], 'determines': [109], 'Its': [120], 'final': [121], 'output': [122], 'probabilistic': [125], 'human-object': [129, 165], 'interaction,': [130], 'i.e.,': [131], 'object.': [140], 'present': [142], 'an': [143], 'extensive': [144], 'experimental': [145], 'evaluation': [146], 'sports': [149], 'data': [151, 159, 167], '[1],': [154], 'PASCAL': [156], 'Action': [157], '2010': [158], '[2],': [161], 'new': [164], 'interaction': [166], 'set.': [168]}",2011,"['Artificial intelligence', 'Computer science', 'Pascal (unit)', 'Relation (database)', 'Object (grammar)', 'Robustness (evolution)', 'Pattern recognition (psychology)', 'Set (abstract data type)', 'Probabilistic logic', 'Computer vision', 'Machine learning', 'Object detection', 'Data mining', 'Programming language', 'Gene', 'Biochemistry', 'Chemistry']","We introduce a weakly supervised approach for learning human actions modeled as interactions between humans and objects. Our approach is human-centric: We first localize a human in the image and then determine the object relevant for the action and its spatial relation with the human. The model is learned automatically from a set of still images annotated only with the action label. Our approach relies on a human detector to initialize the model learning. For robustness to various degrees of visibility, we build a detector that learns to combine a set of existing part detectors. Starting from humans detected in a set of images depicting the action, our approach determines the action object and its spatial relation to the human. Its final output is a probabilistic model of the human-object interaction, i.e., the spatial relation between the human and the object. We present an extensive experimental evaluation on the sports action data set from [1], the PASCAL Action 2010 data set [2], and a new human-object interaction data set."
https://openalex.org/W4367000428,A Cookbook of Self-Supervised Learning,"{'Self-supervised': [0], 'learning,': [1], 'dubbed': [2], 'the': [3, 50, 61, 70, 77, 86, 91, 96, 99, 104], 'dark': [4], 'matter': [5], 'of': [6, 47, 79, 93, 98], 'intelligence,': [7], 'is': [8, 23, 58], 'a': [9, 24, 28, 40, 44, 80], 'promising': [10], 'path': [11], 'to': [12, 31, 53, 59, 63, 84, 89, 107], 'advance': [13], 'machine': [14], 'learning.': [15], 'Yet,': [16], 'much': [17], 'like': [18], 'cooking,': [19], 'training': [20, 39, 54], 'SSL': [21, 41, 66, 74, 111], 'methods': [22], 'delicate': [25], 'art': [26], 'with': [27], 'high': [29], 'barrier': [30, 62], 'entry.': [32], 'While': [33], 'many': [34], 'components': [35], 'are': [36], 'familiar,': [37], 'successfully': [38], 'method': [42], 'involves': [43], 'dizzying': [45], 'set': [46], 'choices': [48], 'from': [49], 'pretext': [51], 'tasks': [52], 'hyper-parameters.': [55], 'Our': [56], 'goal': [57], 'lower': [60], 'entry': [64], 'into': [65], 'research': [67], 'by': [68], 'laying': [69], 'foundations': [71], 'and': [72, 102], 'latest': [73], 'recipes': [75], 'in': [76], 'style': [78], 'cookbook.': [81], 'We': [82], 'hope': [83], 'empower': [85], 'curious': [87], 'researcher': [88], 'navigate': [90], 'terrain': [92], 'methods,': [94], 'understand': [95], 'role': [97], 'various': [100], 'knobs,': [101], 'gain': [103], 'know-how': [105], 'required': [106], 'explore': [108], 'how': [109], 'delicious': [110], 'can': [112], 'be.': [113]}",2023,"['Pretext', 'Computer science', 'Set (abstract data type)', 'Artificial intelligence', 'Style (visual arts)', 'Human–computer interaction', 'Visual arts', 'Art', 'Politics', 'Law', 'Programming language', 'Political science']","Self-supervised learning, dubbed the dark matter of intelligence, is a promising path to advance machine learning. Yet, much like cooking, training SSL methods is a delicate art with a high barrier to entry. While many components are familiar, successfully training a SSL method involves a dizzying set of choices from the pretext tasks to training hyper-parameters. Our goal is to lower the barrier to entry into SSL research by laying the foundations and latest SSL recipes in the style of a cookbook. We hope to empower the curious researcher to navigate the terrain of methods, understand the role of the various knobs, and gain the know-how required to explore how delicious SSL can be."
https://openalex.org/W2103715332,Contextual Bandit Algorithms with Supervised Learning Guarantees,"{'We': [0, 29], 'address': [1], 'the': [2, 12, 50, 141], 'problem': [3], 'of': [4, 55, 97, 99, 119], 'learning': [5, 137], 'in': [6, 52, 77, 124], 'an': [7], 'online,': [8], 'bandit': [9, 143], 'setting': [10], 'where': [11], 'learner': [13], 'must': [14], 'repeatedly': [15], 'select': [16], 'among': [17], '$K$': [18], 'actions,': [19], 'but': [20], 'only': [21], 'receives': [22], 'partial': [23], 'feedback': [24], 'based': [25], 'on': [26, 117], 'its': [27], 'choices.': [28], 'establish': [30], 'two': [31], 'new': [32, 37, 72, 86], 'facts:': [33], 'First,': [34], 'using': [35], 'a': [36, 53, 78, 85, 93, 125], 'algorithm': [38, 73, 87], 'called': [39, 88], 'Exp4.P,': [40], 'we': [41, 83], 'show': [42], 'that': [43, 90], 'it': [44], 'is': [45, 74], 'possible': [46], 'to': [47, 134], 'compete': [48], 'with': [49, 58, 92, 111], 'best': [51], 'set': [54, 96], '$N$': [56], 'experts': [57], 'probability': [59, 112], '$1-δ$': [60], 'while': [61, 102], 'incurring': [62, 103], 'regret': [63, 104], 'at': [64, 105], 'most': [65, 106], '$O(\\sqrt{KT\\ln(N/δ)})$': [66], 'over': [67], '$T$': [68], 'time': [69], 'steps.': [70], 'The': [71], 'tested': [75], 'empirically': [76], 'large-scale,': [79], 'real-world': [80], 'dataset.': [81], 'Second,': [82], 'give': [84], 'VE': [89], 'competes': [91], 'possibly': [94], 'infinite': [95], 'policies': [98], 'VC-dimension': [100], '$d$': [101], '$O(\\sqrt{T(d\\ln(T)': [107], '+': [108], '\\ln': [109], '(1/δ))})$': [110], '$1-δ$.': [113], 'These': [114], 'guarantees': [115, 139], 'improve': [116], 'those': [118], 'all': [120], 'previous': [121], 'algorithms,': [122], 'whether': [123], 'stochastic': [126], 'or': [127], 'adversarial': [128], 'environment,': [129], 'and': [130], 'bring': [131], 'us': [132], 'closer': [133], 'providing': [135], 'supervised': [136], 'type': [138], 'for': [140], 'contextual': [142], 'setting.': [144]}",2010,"['Regret', 'Dimension (graph theory)', 'Set (abstract data type)', 'Computer science', 'Artificial intelligence', 'Algorithm', 'Scale (ratio)', 'Adversarial system', 'Online learning', 'Machine learning', 'Mathematics', 'Combinatorics', 'Programming language', 'Quantum mechanics', 'World Wide Web', 'Physics']","We address the problem of learning in an online, bandit setting where the learner must repeatedly select among $K$ actions, but only receives partial feedback based on its choices. We establish two new facts: First, using a new algorithm called Exp4.P, we show that it is possible to compete with the best in a set of $N$ experts with probability $1-δ$ while incurring regret at most $O(\sqrt{KT\ln(N/δ)})$ over $T$ time steps. The new algorithm is tested empirically in a large-scale, real-world dataset. Second, we give a new algorithm called VE that competes with a possibly infinite set of policies of VC-dimension $d$ while incurring regret at most $O(\sqrt{T(d\ln(T) + \ln (1/δ))})$ with probability $1-δ$. These guarantees improve on those of all previous algorithms, whether in a stochastic or adversarial environment, and bring us closer to providing supervised learning type guarantees for the contextual bandit setting."
https://openalex.org/W2740962769,Weakly-Supervised Learning of Visual Relations,"{'This': [0], 'paper': [1, 92], 'introduces': [2], 'a': [3, 16, 28, 35, 41, 128], 'novel': [4], 'approach': [5], 'for': [6, 78, 108], 'modeling': [7], 'visual': [8, 100, 144, 158], 'relations': [9, 48, 121, 133], 'between\\npairs': [10], 'of': [11, 18, 43, 90, 110, 143], 'objects.': [12, 111], 'We': [13, 147], 'call': [14], 'relation': [15, 62, 145], 'triplet': [17], 'the': [19, 24, 52, 61, 71, 104, 157], 'form': [20], '(subject,': [21, 45], 'predicate,\\nobject)': [22], 'where': [23], 'predicate': [25], 'is': [26, 49], 'typically': [27], 'preposition': [29], '(eg.': [30], ""'under',"": [31], ""'in"": [32], ""front\\nof')"": [33], 'or': [34], 'verb': [36], ""('hold',"": [37], ""'ride')"": [38], 'that': [39, 102, 140], 'links': [40], 'pair': [42], 'objects': [44, 53], 'object).\\nLearning': [46], 'such': [47], 'challenging': [50, 130], 'as': [51], 'have': [54], 'different': [55], 'spatial\\nconfigurations': [56], 'and': [57, 168], 'appearances': [58], 'depending': [59], 'on': [60, 156, 163, 172], 'in': [63, 153], 'which': [64, 82], 'they': [65], 'occur.\\nAnother': [66], 'major': [67], 'challenge': [68], 'comes': [69], 'from': [70], 'difficulty': [72], 'to': [73, 119], 'get': [74], 'annotations,\\nespecially': [75], 'at': [76], 'box-level,': [77], 'all': [79], 'possible': [80], 'triplets,': [81], 'makes': [83], 'both': [84], 'learning\\nand': [85], 'evaluation': [86, 142], 'difficult.': [87], 'The': [88], 'contributions': [89], 'this': [91, 170], 'are': [93], 'threefold.': [94], 'First,\\nwe': [95], 'design': [96], 'strong': [97], 'yet': [98], 'flexible': [99], 'features': [101], 'encode': [103], 'appearance': [105], 'and\\nspatial': [106], 'configuration': [107], 'pairs': [109], 'Second,': [112], 'we': [113, 126], 'propose': [114], 'a\\nweakly-supervised': [115], 'discriminative': [116], 'clustering': [117], 'model': [118, 151], 'learn': [120], 'from\\nimage-level': [122], 'labels': [123], 'only.': [124], 'Third': [125], 'introduce': [127], 'new': [129], 'dataset': [131], 'of\\nunusual': [132], '(UnRel)': [134], 'together': [135], 'with': [136], 'an': [137], 'exhaustive': [138], 'annotation,': [139], 'enables\\naccurate': [141], 'retrieval.': [146], 'show': [148], 'experimentally': [149], 'that\\nour': [150], 'results': [152, 155], 'state-of-the-art': [154], 'relationship\\ndataset': [159], 'significantly': [160], 'improving': [161], 'performance': [162], 'previously': [164], 'unseen': [165], 'relations\\n(zero-shot': [166], 'learning),': [167], 'confirm': [169], 'observation': [171], 'our': [173], 'newly': [174], 'introduced\\nUnRel': [175], 'dataset.\\n': [176]}",2017,"['Computer science', 'Discriminative model', 'Spatial relation', 'Artificial intelligence', 'Predicate (mathematical logic)', 'Object (grammar)', 'Relation (database)', 'Cluster analysis', 'Visualization', 'Natural language processing', 'Pattern recognition (psychology)', 'Machine learning', 'Data mining', 'Programming language']","This paper introduces a novel approach for modeling visual relations between\npairs of objects. We call relation a triplet of the form (subject, predicate,\nobject) where the predicate is typically a preposition (eg. 'under', 'in front\nof') or a verb ('hold', 'ride') that links a pair of objects (subject, object).\nLearning such relations is challenging as the objects have different spatial\nconfigurations and appearances depending on the relation in which they occur.\nAnother major challenge comes from the difficulty to get annotations,\nespecially at box-level, for all possible triplets, which makes both learning\nand evaluation difficult. The contributions of this paper are threefold. First,\nwe design strong yet flexible visual features that encode the appearance and\nspatial configuration for pairs of objects. Second, we propose a\nweakly-supervised discriminative clustering model to learn relations from\nimage-level labels only. Third we introduce a new challenging dataset of\nunusual relations (UnRel) together with an exhaustive annotation, that enables\naccurate evaluation of visual relation retrieval. We show experimentally that\nour model results in state-of-the-art results on the visual relationship\ndataset significantly improving performance on previously unseen relations\n(zero-shot learning), and confirm this observation on our newly introduced\nUnRel dataset.\n"
https://openalex.org/W2990408345,Self-Supervised Learning by Cross-Modal Audio-Video Clustering,"{'Visual': [0], 'and': [1, 47, 96, 111, 125, 148, 155], 'audio': [2, 48, 126], 'modalities': [3], 'are': [4], 'highly': [5], 'correlated,': [6], 'yet': [7], 'they': [8], 'contain': [9], 'different': [10], 'information.': [11], 'Their': [12, 30], 'strong': [13], 'correlation': [14, 95], 'makes': [15], 'it': [16], 'possible': [17], 'to': [18, 51], 'predict': [19], 'the': [20, 25, 82, 93, 97, 100, 140, 158, 165, 179], 'semantics': [21], 'of': [22, 45, 160], 'one': [23, 73], 'from': [24], 'other': [26, 83, 112], 'with': [27, 144], 'good': [28], 'accuracy.': [29], 'intrinsic': [31], 'differences': [32, 98], 'make': [33], 'cross-modal': [34, 88], 'prediction': [35], 'a': [36, 64, 78], 'potentially': [37], 'more': [38], 'rewarding': [39], 'pretext': [40], 'task': [41], 'for': [42, 81, 150, 175], 'self-supervised': [43, 66, 120, 167], 'learning': [44, 168], 'video': [46, 124, 131], 'representations': [49], 'compared': [50], 'within-modality': [52], 'learning.': [53], 'Based': [54], 'on': [55, 122, 134, 146, 153, 178], 'this': [56], 'intuition,': [57], 'we': [58], 'propose': [59], 'Cross-Modal': [60], 'Deep': [61], 'Clustering': [62], '(XDC),': [63], 'novel': [65], 'method': [67, 169], 'that': [68, 106, 170], 'leverages': [69], 'unsupervised': [70], 'clustering': [71, 110], 'in': [72], 'modality': [74, 84], '(e.g.,': [75, 85], 'audio)': [76], 'as': [77], 'supervisory': [79], 'signal': [80], 'video).': [86], 'This': [87], 'supervision': [89], 'helps': [90], 'XDC': [91, 107, 115, 163], 'utilize': [92], 'semantic': [94], 'between': [99], 'two': [101], 'modalities.': [102], 'Our': [103], 'experiments': [104], 'show': [105], 'outperforms': [108, 139, 171], 'single-modality': [109], 'multi-modal': [113], 'variants.': [114], 'achieves': [116], 'state-of-the-art': [117], 'accuracy': [118], 'among': [119], 'methods': [121], 'multiple': [123], 'benchmarks.': [127], 'Most': [128], 'importantly,': [129], 'our': [130, 161], 'model': [132, 142], 'pretrained': [133, 143], 'large-scale': [135, 172], 'unlabeled': [136], 'data': [137], 'significantly': [138], 'same': [141, 180], 'full-supervision': [145], 'ImageNet': [147], 'Kinetics': [149], 'action': [151, 176], 'recognition': [152, 177], 'HMDB51': [154], 'UCF101.': [156], 'To': [157], 'best': [159], 'knowledge,': [162], 'is': [164], 'first': [166], 'fully-supervised': [173], 'pretraining': [174], 'architecture.': [181]}",2019,"['Cluster analysis', 'Computer science', 'Modal', 'Artificial intelligence', 'Speech recognition', 'Chemistry', 'Polymer chemistry']","Visual and audio modalities are highly correlated, yet they contain different information. Their strong correlation makes it possible to predict the semantics of one from the other with good accuracy. Their intrinsic differences make cross-modal prediction a potentially more rewarding pretext task for self-supervised learning of video and audio representations compared to within-modality learning. Based on this intuition, we propose Cross-Modal Deep Clustering (XDC), a novel self-supervised method that leverages unsupervised clustering in one modality (e.g., audio) as a supervisory signal for the other modality (e.g., video). This cross-modal supervision helps XDC utilize the semantic correlation and the differences between the two modalities. Our experiments show that XDC outperforms single-modality clustering and other multi-modal variants. XDC achieves state-of-the-art accuracy among self-supervised methods on multiple video and audio benchmarks. Most importantly, our video model pretrained on large-scale unlabeled data significantly outperforms the same model pretrained with full-supervision on ImageNet and Kinetics for action recognition on HMDB51 and UCF101. To the best of our knowledge, XDC is the first self-supervised learning method that outperforms large-scale fully-supervised pretraining for action recognition on the same architecture."
https://openalex.org/W2787740662,Attention-based Graph Neural Network for Semi-supervised Learning,"{'Recently': [0], 'popularized': [1], 'graph': [2, 112], 'neural': [3, 113], 'networks': [4, 166], 'achieve': [5, 64, 154], 'the': [6, 34, 38, 56, 69, 75, 118, 124, 132, 135, 151, 178], 'state-of-the-art': [7, 70], 'accuracy': [8], 'on': [9, 105, 163, 192], 'a': [10, 29, 42, 50, 65, 96, 110, 144, 159], 'number': [11, 76, 86, 160], 'of': [12, 37, 77, 87, 134, 150, 161], 'standard': [13], 'benchmark': [14, 164], 'datasets': [15], 'for': [16, 82, 98], 'graph-based': [17], 'semi-supervised': [18, 83], 'learning,': [19], 'improving': [20], 'significantly': [21, 73], 'over': [22], 'existing': [23], 'approaches.': [24], 'These': [25], 'architectures': [26], 'alternate': [27], 'between': [28], 'propagation': [30, 102, 125], 'layer': [31], 'that': [32, 49, 53, 115, 130, 170, 185], 'aggregates': [33], 'hidden': [35], 'states': [36], 'local': [39, 148], 'neighborhood': [40, 152], 'and': [41, 122, 146], 'fully-connected': [43, 58, 120], 'layer.': [44], 'Perhaps': [45], 'surprisingly,': [46], 'we': [47, 108, 168, 183], 'show': [48, 184], 'linear': [51], 'model,': [52], 'removes': [54, 116], 'all': [55, 117], 'intermediate': [57, 119], 'layers,': [59, 121], 'is': [60, 80], 'still': [61], 'able': [62], 'to': [63, 68, 142, 153], 'performance': [66], 'comparable': [67], 'models.': [71], 'This': [72, 92], 'reduces': [74], 'parameters,': [78], 'which': [79], 'critical': [81], 'learning': [84], 'where': [85], 'labeled': [88], 'examples': [89], 'are': [90], 'small.': [91], 'in': [93], 'turn': [94], 'allows': [95, 140], 'room': [97], 'designing': [99], 'more': [100, 155], 'innovative': [101], 'layers.': [103], 'Based': [104], 'this': [106], 'insight,': [107], 'propose': [109], 'novel': [111], 'network': [114], 'replaces': [123], 'layers': [126], 'with': [127], 'attention': [128, 138, 179], 'mechanisms': [129], 'respect': [131], 'structure': [133], 'graph.': [136], 'The': [137], 'mechanism': [139], 'us': [141], 'learn': [143], 'dynamic': [145], 'adaptive': [147], 'summary': [149], 'accurate': [156], 'predictions.': [157], 'In': [158], 'experiments': [162], 'citation': [165], 'datasets,': [167], 'demonstrate': [169], 'our': [171, 186], 'approach': [172], 'outperforms': [173], 'competing': [174], 'methods.': [175], 'By': [176], 'examining': [177], 'weights': [180], 'among': [181], 'neighbors,': [182], 'model': [187], 'provides': [188], 'some': [189], 'interesting': [190], 'insights': [191], 'how': [193], 'neighbors': [194], 'influence': [195], 'each': [196], 'other.': [197]}",2018,"['Computer science', 'Benchmark (surveying)', 'Graph', 'Artificial neural network', 'Artificial intelligence', 'Machine learning', 'Theoretical computer science', 'Geography', 'Geodesy']","Recently popularized graph neural networks achieve the state-of-the-art accuracy on a number of standard benchmark datasets for graph-based semi-supervised learning, improving significantly over existing approaches. These architectures alternate between a propagation layer that aggregates the hidden states of the local neighborhood and a fully-connected layer. Perhaps surprisingly, we show that a linear model, that removes all the intermediate fully-connected layers, is still able to achieve a performance comparable to the state-of-the-art models. This significantly reduces the number of parameters, which is critical for semi-supervised learning where number of labeled examples are small. This in turn allows a room for designing more innovative propagation layers. Based on this insight, we propose a novel graph neural network that removes all the intermediate fully-connected layers, and replaces the propagation layers with attention mechanisms that respect the structure of the graph. The attention mechanism allows us to learn a dynamic and adaptive local summary of the neighborhood to achieve more accurate predictions. In a number of experiments on benchmark citation networks datasets, we demonstrate that our approach outperforms competing methods. By examining the attention weights among neighbors, we show that our model provides some interesting insights on how neighbors influence each other."
https://openalex.org/W4367055910,Self-supervised learning for medical image classification: a systematic review and implementation guidelines,"{'Abstract': [0], 'Advancements': [1], 'in': [2, 152], 'deep': [3, 27], 'learning': [4, 28, 49, 88, 110, 155], 'and': [5, 18, 41, 90, 100, 105, 123, 130, 144], 'computer': [6], 'vision': [7], 'provide': [8, 82, 145], 'promising': [9], 'solutions': [10], 'for': [11, 45, 127, 148], 'medical': [12, 46, 62, 74, 112, 160], 'image': [13], 'analysis,': [14], 'potentially': [15], 'improving': [16], 'healthcare': [17], 'patient': [19], 'outcomes.': [20], 'However,': [21], 'the': [22, 51, 58, 138], 'prevailing': [23], 'paradigm': [24], 'of': [25, 33, 60, 85, 95, 119, 141, 159], 'training': [26, 35], 'models': [29, 64], 'requires': [30], 'large': [31], 'quantities': [32], 'labeled': [34], 'data,': [36], 'which': [37], 'is': [38], 'both': [39], 'time-consuming': [40], 'cost-prohibitive': [42], 'to': [43, 53, 57, 68, 111, 156], 'curate': [44], 'images.': [47], 'Self-supervised': [48], 'has': [50], 'potential': [52], 'make': [54], 'significant': [55], 'contributions': [56], 'development': [59, 158], 'robust': [61], 'imaging': [63, 113, 161], 'through': [65], 'its': [66], 'ability': [67], 'learn': [69], 'useful': [70], 'insights': [71], 'from': [72], 'copious': [73], 'datasets': [75], 'without': [76], 'labels.': [77], 'In': [78], 'this': [79, 133], 'review,': [80], 'we': [81, 136], 'consistent': [83], 'descriptions': [84], 'different': [86], 'self-supervised': [87, 109, 154], 'strategies': [89], 'compose': [91], 'a': [92, 117], 'systematic': [93], 'review': [94], 'papers': [96, 126], 'published': [97], 'between': [98], '2012': [99], '2022': [101], 'on': [102], 'PubMed,': [103], 'Scopus,': [104], 'ArXiv': [106], 'that': [107], 'applied': [108], 'classification.': [114], 'We': [115], 'screened': [116], 'total': [118], '412': [120], 'relevant': [121], 'studies': [122], 'included': [124], '79': [125], 'data': [128], 'extraction': [129], 'analysis.': [131], 'With': [132], 'comprehensive': [134], 'effort,': [135], 'synthesize': [137], 'collective': [139], 'knowledge': [140], 'prior': [142], 'work': [143], 'implementation': [146], 'guidelines': [147], 'future': [149], 'researchers': [150], 'interested': [151], 'applying': [153], 'their': [157], 'classification': [162], 'models.': [163]}",2023,"['Artificial intelligence', 'Computer science', 'Machine learning', 'Deep learning', 'Supervised learning', 'Medical imaging', 'Scopus', 'Data science', 'MEDLINE', 'Artificial neural network', 'Law', 'Political science']","Abstract Advancements in deep learning and computer vision provide promising solutions for medical image analysis, potentially improving healthcare and patient outcomes. However, the prevailing paradigm of training deep learning models requires large quantities of labeled training data, which is both time-consuming and cost-prohibitive to curate for medical images. Self-supervised learning has the potential to make significant contributions to the development of robust medical imaging models through its ability to learn useful insights from copious medical datasets without labels. In this review, we provide consistent descriptions of different self-supervised learning strategies and compose a systematic review of papers published between 2012 and 2022 on PubMed, Scopus, and ArXiv that applied self-supervised learning to medical imaging classification. We screened a total of 412 relevant studies and included 79 papers for data extraction and analysis. With this comprehensive effort, we synthesize the collective knowledge of prior work and provide implementation guidelines for future researchers interested in applying self-supervised learning to their development of medical imaging classification models."
https://openalex.org/W2473876819,NLLSS: Predicting Synergistic Drug Combinations Based on Semi-supervised Learning,"{'Fungal': [0], 'infection': [1], 'has': [2], 'become': [3], 'one': [4], 'of': [5, 9, 54, 70, 116, 149, 169], 'the': [6], 'leading': [7], 'causes': [8], 'hospital-acquired': [10], 'infections': [11], 'with': [12, 79], 'high': [13], 'mortality': [14], 'rates.': [15], 'Furthermore,': [16, 89], 'drug': [17, 25, 34, 38, 46, 56, 71, 102, 110, 122, 127, 137, 174], 'resistance': [18], 'is': [19], 'common': [20], 'for': [21, 58, 160], 'fungus-causing': [22, 59], 'diseases.': [23], 'Synergistic': [24, 101], 'combinations': [26, 39, 57, 111, 138], 'could': [27], 'provide': [28], 'an': [29, 178], 'effective': [30], 'strategy': [31, 180], 'to': [32, 48, 106, 133, 165, 181], 'overcome': [33], 'resistance.': [35], 'Meanwhile,': [36], 'synergistic': [37, 55, 77, 109, 121, 136, 173, 184], 'can': [40], 'increase': [41], 'treatment': [42], 'efficacy': [43], 'and': [44, 86, 126, 139, 152], 'decrease': [45], 'dosage': [47], 'avoid': [49], 'toxicity.': [50], 'Therefore,': [51], 'computational': [52], 'prediction': [53, 104], 'diseases': [60], 'becomes': [61], 'attractive.': [62], 'In': [63], 'this': [64], 'study,': [65], 'we': [66, 90, 156], 'proposed': [67], 'similar': [68, 80, 85], 'nature': [69], 'combinations:': [72], 'principal': [73], 'drugs': [74, 82], 'which': [75], 'obtain': [76], 'effect': [78], 'adjuvant': [81], 'are': [83], 'often': [84], 'vice': [87], 'versa.': [88], 'developed': [91], 'a': [92], 'novel': [93], 'algorithm': [94], 'termed': [95], 'Network-based': [96], 'Laplacian': [97], 'regularized': [98], 'Least': [99], 'Square': [100], 'combination': [103], '(NLLSS)': [105], 'predict': [107, 134], 'potential': [108, 183], 'by': [112], 'integrating': [113], 'different': [114], 'kinds': [115], 'information': [117], 'such': [118], 'as': [119], 'known': [120], 'combinations,': [123], 'drug-target': [124], 'interactions,': [125], 'chemical': [128], 'structures.': [129], 'We': [130], 'applied': [131], 'NLLSS': [132, 176], 'antifungal': [135, 172, 185], 'showed': [140], 'that': [141], 'it': [142], 'achieved': [143], 'excellent': [144], 'performance': [145], 'both': [146], 'in': [147], 'terms': [148], 'cross': [150], 'validation': [151], 'independent': [153], 'prediction.': [154], 'Finally,': [155], 'performed': [157], 'biological': [158], 'experiments': [159], 'fungal': [161], 'pathogen': [162], 'Candida': [163], 'albicans': [164], 'confirm': [166], '7': [167], 'out': [168], '13': [170], 'predicted': [171], 'combinations.': [175, 186], 'provides': [177], 'efficient': [179], 'identify': [182]}",2016,"['Drug', 'Antifungal drug', 'Drug resistance', 'Candida albicans', 'Antifungal', 'Antifungal drugs', 'Computational biology', 'Pharmacology', 'Biology', 'Microbiology']","Fungal infection has become one of the leading causes of hospital-acquired infections with high mortality rates. Furthermore, drug resistance is common for fungus-causing diseases. Synergistic drug combinations could provide an effective strategy to overcome drug resistance. Meanwhile, synergistic drug combinations can increase treatment efficacy and decrease drug dosage to avoid toxicity. Therefore, computational prediction of synergistic drug combinations for fungus-causing diseases becomes attractive. In this study, we proposed similar nature of drug combinations: principal drugs which obtain synergistic effect with similar adjuvant drugs are often similar and vice versa. Furthermore, we developed a novel algorithm termed Network-based Laplacian regularized Least Square Synergistic drug combination prediction (NLLSS) to predict potential synergistic drug combinations by integrating different kinds of information such as known synergistic drug combinations, drug-target interactions, and drug chemical structures. We applied NLLSS to predict antifungal synergistic drug combinations and showed that it achieved excellent performance both in terms of cross validation and independent prediction. Finally, we performed biological experiments for fungal pathogen Candida albicans to confirm 7 out of 13 predicted antifungal synergistic drug combinations. NLLSS provides an efficient strategy to identify potential synergistic antifungal combinations."
https://openalex.org/W2564414379,Visualizing the Effects of Predictor Variables in Black Box Supervised Learning Models,"{'When': [0], 'fitting': [1], 'black': [2], 'box': [3], 'supervised': [4], 'learning': [5], 'models': [6], '(e.g.,': [7], 'complex': [8], 'trees,': [9, 13], 'neural': [10], 'networks,': [11], 'boosted': [12], 'random': [14], 'forests,': [15], 'nearest': [16], 'neighbors,': [17], 'local': [18, 145], 'kernel-weighted': [19], 'methods,': [20], 'etc.),': [21], 'visualizing': [22], 'the': [23, 27, 45, 60, 82, 91, 95, 101, 123, 129, 151, 182], 'main': [24], 'effects': [25, 35, 146], 'of': [26, 81, 94, 154], 'individual': [28], 'predictor': [29, 61, 85], 'variables': [30, 62], 'and': [31, 39, 119, 156, 173], 'their': [32, 161], 'low-order': [33], 'interaction': [34], 'is': [36, 68], 'often': [37], 'important,': [38], 'partial': [40], 'dependence': [41], '(PD)': [42], 'plots': [43, 54, 78, 103, 107, 168, 188], 'are': [44, 63, 88, 125, 178, 189], 'most': [46], 'popular': [47], 'approach': [48, 140], 'for': [49], 'accomplishing': [50], 'this.': [51], 'However,': [52], 'PD': [53, 77, 102, 155, 175, 195], 'involve': [55], 'a': [56, 137], 'serious': [57], 'pitfall': [58], 'if': [59], 'far': [64, 89, 190], 'from': [65], 'independent,': [66], 'which': [67, 98, 149], 'quite': [69], 'common': [70], 'with': [71], 'large': [72], 'observational': [73], 'data': [74], 'sets.': [75], 'Namely,': [76], 'require': [79, 112, 171], 'extrapolation': [80], 'response': [83], 'at': [84], 'values': [86], 'that': [87, 141], 'outside': [90], 'multivariate': [92], 'envelope': [93], 'training': [96], 'data,': [97], 'can': [99], 'render': [100], 'unreliable.': [104], 'Although': [105], 'marginal': [106], '(M': [108], 'plots)': [109], 'do': [110, 169], 'not': [111, 170, 179], 'such': [113], 'extrapolation,': [114], 'they': [115, 177], 'produce': [116], 'substantially': [117], 'biased': [118, 180], 'misleading': [120], 'results': [121], 'when': [122], 'predictors': [124], 'dependent,': [126], 'analogous': [127], 'to': [128], 'omitted': [130, 183], 'variable': [131, 184], 'bias': [132], 'in': [133], 'regression.': [134], 'We': [135], 'present': [136], 'new': [138], 'visualization': [139], 'we': [142], 'term': [143], 'accumulated': [144], '(ALE)': [147], 'plots,': [148, 158, 166, 176], 'inherits': [150], 'desirable': [152], 'characteristics': [153], 'M': [157, 165], 'without': [159], 'inheriting': [160], 'preceding': [162], 'shortcomings.': [163], 'Like': [164], 'ALE': [167, 187], 'extrapolation;': [172], 'like': [174], 'by': [181], 'phenomenon.': [185], 'Moreover,': [186], 'less': [191], 'computationally': [192], 'expensive': [193], 'than': [194], 'plots.': [196]}",2016,"['Extrapolation', 'Random forest', 'Regression', 'Variable (mathematics)', 'Multivariate statistics', 'Regression analysis', 'Scatter plot', 'Artificial neural network', 'Variables', 'Omitted-variable bias', 'Statistics', 'Computer science', 'Term (time)', 'Machine learning', 'Mathematics', 'Artificial intelligence', 'Econometrics', 'Physics', 'Quantum mechanics', 'Mathematical analysis']","When fitting black box supervised learning models (e.g., complex trees, neural networks, boosted trees, random forests, nearest neighbors, local kernel-weighted methods, etc.), visualizing the main effects of the individual predictor variables and their low-order interaction effects is often important, and partial dependence (PD) plots are the most popular approach for accomplishing this. However, PD plots involve a serious pitfall if the predictor variables are far from independent, which is quite common with large observational data sets. Namely, PD plots require extrapolation of the response at predictor values that are far outside the multivariate envelope of the training data, which can render the PD plots unreliable. Although marginal plots (M plots) do not require such extrapolation, they produce substantially biased and misleading results when the predictors are dependent, analogous to the omitted variable bias in regression. We present a new visualization approach that we term accumulated local effects (ALE) plots, which inherits the desirable characteristics of PD and M plots, without inheriting their preceding shortcomings. Like M plots, ALE plots do not require extrapolation; and like PD plots, they are not biased by the omitted variable phenomenon. Moreover, ALE plots are far less computationally expensive than PD plots."
https://openalex.org/W3201675569,Data Analytics for the Identification of Fake Reviews Using Supervised Learning,"{'Fake': [0], 'reviews,': [1], 'also': [2], 'known': [3], 'as': [4, 30, 178], 'deceptive': [5], 'opinions,': [6], 'are': [7], 'used': [8, 134, 253], 'to': [9, 21, 40, 101, 175], 'mislead': [10], 'people': [11], 'and': [12, 32, 43, 91, 120, 143, 147, 158, 163, 194, 197, 226, 234, 241, 257], 'have': [13], 'gained': [14], 'more': [15], 'importance': [16], 'recently.': [17], 'This': [18], 'is': [19, 74], 'due': [20], 'the': [22, 46, 57, 63, 71, 93, 117, 125, 172, 183, 204, 254, 258, 262], 'rapid': [23], 'increase': [24], 'in': [25, 131, 265], 'online': [26], 'marketing': [27], 'transactions,': [28], 'such': [29], 'selling': [31], 'purchasing.': [33], 'E-commerce': [34], 'provides': [35], 'a': [36, 67, 135, 148, 200], 'facility': [37], 'for': [38, 141, 155], 'customers': [39, 53], 'post': [41], 'reviews': [42, 59, 81, 110], 'comment': [44], 'about': [45], 'product': [47], 'or': [48, 60, 180], 'service': [49], 'when': [50], 'purchased.': [51], 'New': [52], 'usually': [54], 'go': [55], 'through': [56], 'posted': [58], 'comments': [61], 'on': [62, 111, 199, 238], 'website': [64], 'before': [65], 'making': [66], 'purchase': [68], 'decision.': [69], 'However,': [70, 182], 'current': [72], 'challenge': [73], 'how': [75], 'new': [76], 'individuals': [77], 'can': [78, 107], 'distinguish': [79], 'truthful': [80], 'from': [82, 203], 'fake': [83, 109, 137, 179], 'ones,': [84], 'which': [85], 'later': [86], 'deceives': [87], 'customers,': [88], 'inflicts': [89], 'losses,': [90], 'tarnishes': [92], 'reputation': [94], 'of': [95, 116, 166, 211, 267], 'companies.': [96], 'The': [97, 127, 208, 244], 'present': [98], 'paper': [99], 'attempts': [100], 'develop': [102], 'an': [103], 'intelligent': [104], 'system': [105], 'that': [106, 215, 252], 'detect': [108], 'e-commerce': [112], 'platforms': [113], 'using': [114, 188], 'n-grams': [115, 165], 'review': [118, 139, 167], 'text': [119], 'sentiment': [121], 'scores': [122], 'given': [123], 'by': [124], 'reviewer.': [126], 'proposed': [128, 259], 'methodology': [129], 'adopted': [130], 'this': [132], 'study': [133], 'standard': [136], 'hotel': [138], 'dataset': [140, 201], 'experimenting': [142], 'data': [144], 'preprocessing': [145], 'methods': [146, 260, 264], 'term': [149], 'frequency-Inverse': [150], 'document': [151], 'frequency': [152], '(TF-IDF)': [153], 'approach': [154], 'extracting': [156], 'features': [157], 'their': [159], 'representation.': [160], 'For': [161], 'detection': [162], 'classification,': [164], 'texts': [168], 'were': [169, 185, 195, 247], 'inputted': [170], 'into': [171], 'constructed': [173], 'models': [174], 'be': [176], 'classified': [177], 'truthful.': [181], 'experiments': [184, 213], 'carried': [186], 'out': [187], 'four': [189], 'different': [190], 'supervised': [191], 'machine-learning': [192], 'techniques': [193], 'trained': [196], 'tested': [198], 'collected': [202], 'Trip': [205], 'Advisor': [206], 'website.': [207], 'classification': [209], 'results': [210, 246], 'these': [212], 'showed': [214], 'naïve': [216], 'Bayes': [217], '(NB),': [218], 'support': [219], 'vector': [220], 'machine': [221], '(SVM),': [222], 'adaptive': [223], 'boosting': [224], '(AB),': [225], 'random': [227], 'forest': [228], '(RF)': [229], 'received': [230], '88%,': [231], '93%,': [232], '94%,': [233], '95%,': [235], 'respectively,': [236], 'based': [237], 'testing': [239], 'accuracy': [240], 'tje': [242], 'F1-score.': [243], 'obtained': [245], 'compared': [248], 'with': [249], 'existing': [250], 'works': [251], 'same': [255], 'dataset,': [256], 'outperformed': [261], 'comparable': [263], 'terms': [266], 'accuracy.': [268]}",2021,"['Naive Bayes classifier', 'Computer science', 'Support vector machine', 'Machine learning', 'Artificial intelligence', 'Purchasing', 'Reputation', 'Random forest', 'Sentiment analysis', 'Identification (biology)', 'Preprocessor', 'Product (mathematics)', 'Misinformation', 'Marketing', 'Computer security', 'Social science', 'Mathematics', 'Business', 'Sociology', 'Geometry', 'Botany', 'Biology']","Fake reviews, also known as deceptive opinions, are used to mislead people and have gained more importance recently. This is due to the rapid increase in online marketing transactions, such as selling and purchasing. E-commerce provides a facility for customers to post reviews and comment about the product or service when purchased. New customers usually go through the posted reviews or comments on the website before making a purchase decision. However, the current challenge is how new individuals can distinguish truthful reviews from fake ones, which later deceives customers, inflicts losses, and tarnishes the reputation of companies. The present paper attempts to develop an intelligent system that can detect fake reviews on e-commerce platforms using n-grams of the review text and sentiment scores given by the reviewer. The proposed methodology adopted in this study used a standard fake hotel review dataset for experimenting and data preprocessing methods and a term frequency-Inverse document frequency (TF-IDF) approach for extracting features and their representation. For detection and classification, n-grams of review texts were inputted into the constructed models to be classified as fake or truthful. However, the experiments were carried out using four different supervised machine-learning techniques and were trained and tested on a dataset collected from the Trip Advisor website. The classification results of these experiments showed that naïve Bayes (NB), support vector machine (SVM), adaptive boosting (AB), and random forest (RF) received 88%, 93%, 94%, and 95%, respectively, based on testing accuracy and tje F1-score. The obtained results were compared with existing works that used the same dataset, and the proposed methods outperformed the comparable methods in terms of accuracy."
https://openalex.org/W3208338073,Self-supervised Learning for Large-scale Item Recommendations,"{'Large': [0], 'scale': [1], 'recommender': [2, 34], 'models': [3], 'find': [4], 'most': [5], 'relevant': [6], 'items': [7, 48, 59, 86], 'from': [8, 49], 'huge': [9], 'catalogs,': [10], 'and': [11, 20, 47], 'they': [12], 'play': [13], 'a': [14, 32, 37, 69, 76], 'critical': [15], 'role': [16], 'in': [17, 60], 'modern': [18], 'search': [19], 'recommendation': [21], 'systems.': [22], 'To': [23], 'model': [24, 35], 'the': [25, 61, 81], 'input': [26], 'space': [27, 40], 'with': [28, 54], 'large-vocab': [29], 'categorical': [30], 'features,': [31], 'typical': [33], 'learns': [36], 'joint': [38], 'embedding': [39], 'through': [41], 'neural': [42], 'networks': [43], 'for': [44, 68, 84], 'both': [45], 'queries': [46], 'user': [50], 'feedback': [51, 67, 82], 'data.': [52], 'However,': [53], 'millions': [55], 'to': [56, 65], 'billions': [57], 'of': [58, 73], 'corpus,': [62], 'users': [63], 'tend': [64], 'provide': [66], 'very': [70], 'small': [71], 'set': [72], 'them,': [74], 'causing': [75], 'power-law': [77], 'distribution.': [78], 'This': [79], 'makes': [80], 'data': [83], 'long-tail': [85], 'extremely': [87], 'sparse.': [88]}",2021,"['Recommender system', 'Categorical variable', 'Computer science', 'Space (punctuation)', 'Set (abstract data type)', 'Embedding', 'Scale (ratio)', 'Machine learning', 'Data set', 'Information retrieval', 'Collaborative filtering', 'Artificial intelligence', 'Data mining', 'Quantum mechanics', 'Programming language', 'Physics', 'Operating system']","Large scale recommender models find most relevant items from huge catalogs, and they play a critical role in modern search and recommendation systems. To model the input space with large-vocab categorical features, a typical recommender model learns a joint embedding space through neural networks for both queries and items from user feedback data. However, with millions to billions of items in the corpus, users tend to provide feedback for a very small set of them, causing a power-law distribution. This makes the feedback data for long-tail items extremely sparse."
https://openalex.org/W2606711863,Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning,"{'We': [0], 'propose': [1], 'a': [2, 11, 133], 'new': [3, 12], 'regularization': [4], 'method': [5, 49, 80], 'based': [6, 139], 'on': [7, 128, 140, 154], 'virtual': [8, 81, 100], 'adversarial': [9, 25, 46, 52, 82, 101], 'loss:': [10], 'measure': [13], 'of': [14, 17, 32, 88, 99, 112, 136], 'local': [15, 43], 'smoothness': [16], 'the': [18, 30, 33, 51, 65, 71, 96, 137, 141], 'conditional': [19, 34], 'label': [20, 35, 55], 'distribution': [21, 36], 'given': [22], 'input.': [23], 'Virtual': [24], 'loss': [26, 102], 'is': [27, 58, 90], 'defined': [28], 'as': [29], 'robustness': [31], 'around': [37], 'each': [38], 'input': [39], 'data': [40], 'point': [41], 'against': [42], 'perturbation.': [44], 'Unlike': [45], 'training,': [47], 'our': [48, 79, 117, 145], 'defines': [50], 'direction': [53], 'without': [54], 'information': [56], 'and': [57, 114, 124, 156], 'hence': [59], 'applicable': [60], 'to': [61, 122], 'semi-supervised': [62, 125, 151], 'learning.': [63], 'Because': [64], 'directions': [66], 'in': [67], 'which': [68], 'we': [69, 77, 119], 'smooth': [70], 'model': [72], 'are': [73], 'only': [74], '""virtually""': [75], 'adversarial,': [76], 'call': [78], 'training': [83], '(VAT).': [84], 'The': [85], 'computational': [86], 'cost': [87], 'VAT': [89, 121, 146], 'relatively': [91], 'low.': [92], 'For': [93], 'neural': [94], 'networks,': [95], 'approximated': [97], 'gradient': [98], 'can': [103], 'be': [104], 'computed': [105], 'with': [106], 'no': [107], 'more': [108], 'than': [109], 'two': [110], 'pairs': [111], 'forward-': [113], 'back-propagations.': [115], 'In': [116], 'experiments,': [118], 'applied': [120], 'supervised': [123], 'learning': [126, 152], 'tasks': [127, 153], 'multiple': [129], 'benchmark': [130], 'datasets.': [131], 'With': [132], 'simple': [134], 'enhancement': [135], 'algorithm': [138], 'entropy': [142], 'minimization': [143], 'principle,': [144], 'achieves': [147], 'state-of-the-art': [148], 'performance': [149], 'for': [150], 'SVHN': [155], 'CIFAR-10.': [157]}",2017,"['Adversarial system', 'Computer science', 'Artificial intelligence', 'Machine learning', 'Regularization (linguistics)', 'Cross entropy', 'Entropy (arrow of time)', 'Minification', 'Supervised learning', 'Deep neural networks', 'Mathematical optimization', 'Deep learning', 'Artificial neural network', 'Pattern recognition (psychology)', 'Mathematics', 'Quantum mechanics', 'Programming language', 'Physics']","We propose a new regularization method based on virtual adversarial loss: a new measure of local smoothness of the conditional label distribution given input. Virtual adversarial loss is defined as the robustness of the conditional label distribution around each input data point against local perturbation. Unlike adversarial training, our method defines the adversarial direction without label information and is hence applicable to semi-supervised learning. Because the directions in which we smooth the model are only ""virtually"" adversarial, we call our method virtual adversarial training (VAT). The computational cost of VAT is relatively low. For neural networks, the approximated gradient of virtual adversarial loss can be computed with no more than two pairs of forward- and back-propagations. In our experiments, we applied VAT to supervised and semi-supervised learning tasks on multiple benchmark datasets. With a simple enhancement of the algorithm based on the entropy minimization principle, our VAT achieves state-of-the-art performance for semi-supervised learning tasks on SVHN and CIFAR-10."
https://openalex.org/W2794523151,Realistic Evaluation of Deep Semi-Supervised Learning Algorithms,"{'Semi-supervised': [0], 'learning': [1], '(SSL)': [2], 'provides': [3], 'a': [4, 55, 67], 'powerful': [5], 'framework': [6], 'for': [7], 'leveraging': [8], 'unlabeled': [9, 88, 105, 115], 'data': [10, 89], 'when': [11, 113], 'labels': [12], 'are': [13], 'limited': [14], 'or': [15], 'expensive': [16], 'to': [17, 41, 72, 99], 'obtain.': [18], 'SSL': [19, 61, 94, 123], 'algorithms': [20, 47], 'based': [21], 'on': [22, 30], 'deep': [23], 'neural': [24], 'networks': [25], 'have': [26], 'recently': [27], 'proven': [28], 'successful': [29], 'standard': [31], 'benchmark': [32], 'tasks.': [33], 'However,': [34], 'we': [35, 63, 128], 'argue': [36], 'that': [37, 45, 78, 93, 108], 'these': [38, 46, 74], 'benchmarks': [39], 'fail': [40], 'address': [42, 73], 'many': [43], 'issues': [44], 'would': [48], 'face': [49], 'in': [50, 66, 97], 'real-world': [51, 126], 'applications.': [52], 'After': [53], 'creating': [54], 'unified': [56, 131], 'reimplementation': [57], 'of': [58, 69, 81, 102], 'various': [59], 'widely-used': [60], 'techniques,': [62], 'test': [64], 'them': [65], 'suite': [68], 'experiments': [70], 'designed': [71], 'issues.': [75], 'We': [76], 'find': [77], 'the': [79, 100, 114], 'performance': [80, 109], 'simple': [82], 'baselines': [83], 'which': [84], 'do': [85], 'not': [86], 'use': [87], 'is': [90], 'often': [91], 'underreported,': [92], 'methods': [95], 'differ': [96], 'sensitivity': [98], 'amount': [101], 'labeled': [103], 'and': [104, 107, 133], 'data,': [106], 'can': [110], 'degrade': [111], 'substantially': [112], 'dataset': [116], 'contains': [117], 'out-of-class': [118], 'examples.': [119], 'To': [120], 'help': [121], 'guide': [122], 'research': [124], 'towards': [125], 'applicability,': [127], 'make': [129], 'our': [130], 'reimplemention': [132], 'evaluation': [134], 'platform': [135], 'publicly': [136], 'available.': [137]}",2018,"['Computer science', 'Suite', 'Benchmark (surveying)', 'Machine learning', 'Artificial intelligence', 'Labeled data', 'Test suite', 'Class (philosophy)', 'Simple (philosophy)', 'Deep learning', 'Data mining', 'Test case', 'Geography', 'Geodesy', 'Epistemology', 'History', 'Archaeology', 'Philosophy', 'Regression analysis']","Semi-supervised learning (SSL) provides a powerful framework for leveraging unlabeled data when labels are limited or expensive to obtain. SSL algorithms based on deep neural networks have recently proven successful on standard benchmark tasks. However, we argue that these benchmarks fail to address many issues that these algorithms would face in real-world applications. After creating a unified reimplementation of various widely-used SSL techniques, we test them in a suite of experiments designed to address these issues. We find that the performance of simple baselines which do not use unlabeled data is often underreported, that SSL methods differ in sensitivity to the amount of labeled and unlabeled data, and that performance can degrade substantially when the unlabeled dataset contains out-of-class examples. To help guide SSL research towards real-world applicability, we make our unified reimplemention and evaluation platform publicly available."
https://openalex.org/W2172251087,A high-performance semi-supervised learning method for text chunking,"{'In': [0], 'machine': [1], 'learning,': [2], 'whether': [3], 'one': [4], 'can': [5, 92, 96], 'build': [6], 'a': [7, 22, 42, 48], 'more': [8], 'accurate': [9], 'classifier': [10], 'by': [11, 66, 87], 'using': [12], 'unlabeled': [13, 77], 'data': [14], '(semi-supervised': [15], 'learning)': [16], 'is': [17, 35, 58], 'an': [18], 'important': [19], 'issue.': [20], 'Although': [21], 'number': [23], 'of': [24, 70], 'semi-supervised': [25, 44], 'methods': [26], 'have': [27], 'been': [28], 'proposed,': [29], 'their': [30], 'effectiveness': [31], 'on': [32, 76, 103, 117], 'NLP': [33], 'tasks': [34], 'not': [36], 'always': [37], 'clear.': [38], 'This': [39], 'paper': [40], 'presents': [41], 'novel': [43], 'method': [45, 108], 'that': [46], 'employs': [47], 'learning': [49, 67], 'paradigm': [50], 'which': [51, 95], 'we': [52], 'call': [53], 'structural': [54], 'learning.': [55], 'The': [56, 107], 'idea': [57], 'to': [59, 100], 'find': [60], '""what': [61], 'good': [62], 'classifiers': [63], 'are': [64], 'like""': [65], 'from': [68], 'thousands': [69], 'automatically': [71], 'generated': [72], 'auxiliary': [73], 'classification': [74, 90], 'problems': [75, 91], 'data.': [78], 'By': [79], 'doing': [80], 'so,': [81], 'the': [82, 88, 104, 113], 'common': [83], 'predictive': [84], 'structure': [85], 'shared': [86], 'multiple': [89], 'be': [93, 98], 'discovered,': [94], 'then': [97], 'used': [99], 'improve': [101], 'performance': [102, 110], 'target': [105], 'problem.': [106], 'produces': [109], 'higher': [111], 'than': [112], 'previous': [114], 'best': [115], 'results': [116], ""CoNLL'00"": [118], 'syntactic': [119], 'chunking': [120, 125], 'and': [121, 127], ""CoNLL'03"": [122], 'named': [123], 'entity': [124], '(English': [126], 'German).': [128]}",2005,"['Chunking (psychology)', 'Computer science', 'Artificial intelligence', 'Semi-supervised learning', 'Classifier (UML)', 'Machine learning', 'Labeled data', 'Supervised learning', 'Natural language processing', 'German', 'Artificial neural network', 'History', 'Archaeology']","In machine learning, whether one can build a more accurate classifier by using unlabeled data (semi-supervised learning) is an important issue. Although a number of semi-supervised methods have been proposed, their effectiveness on NLP tasks is not always clear. This paper presents a novel semi-supervised method that employs a learning paradigm which we call structural learning. The idea is to find ""what good classifiers are like"" by learning from thousands of automatically generated auxiliary classification problems on unlabeled data. By doing so, the common predictive structure shared by the multiple classification problems can be discovered, which can then be used to improve performance on the target problem. The method produces performance higher than the previous best results on CoNLL'00 syntactic chunking and CoNLL'03 named entity chunking (English and German)."
https://openalex.org/W3119308075,"VoxPopuli: A Large-Scale Multilingual Speech Corpus for Representation Learning, Semi-Supervised Learning and Interpretation","{'International': [0], 'audience': [1]}",2021,"['Computer science', 'Natural language processing', 'Interpretation (philosophy)', 'Representation (politics)', 'Artificial intelligence', 'Computational linguistics', 'Scale (ratio)', 'Linguistics', 'Joint (building)', 'Corpus linguistics', 'Association (psychology)', 'Volume (thermodynamics)', 'Speech recognition', 'Programming language', 'Engineering', 'Philosophy', 'Geography', 'Epistemology', 'Cartography', 'Politics', 'Architectural engineering', 'Political science', 'Physics', 'Quantum mechanics', 'Law']",International audience
https://openalex.org/W1543911290,Safe Feature Elimination in Sparse Supervised Learning,"{'We': [0, 124], 'investigate': [1], 'fast': [2], 'methods': [3, 43], 'that': [4, 51, 181], 'allow': [5], 'to': [6, 25, 36, 55, 66, 91, 128, 148, 163, 173], 'quickly': [7], 'eliminate': [8, 49], 'variables': [9, 34], '(features)': [10], 'in': [11, 30, 97, 132, 144], 'supervised': [12, 39, 100], 'learning': [13, 40, 61, 101, 151], 'problems': [14], 'involving': [15], 'a': [16, 21, 26, 67, 137], 'convex': [17], 'loss': [18], 'function': [19], 'and': [20, 79, 135], '$l_1$-norm': [22], 'penalty,': [23], 'leading': [24], 'potentially': [27], 'substantial': [28], 'reduction': [29, 139], 'the': [31, 38, 60, 84, 92, 98, 107, 112, 141, 150, 166], 'number': [32, 108, 113], 'of': [33, 70, 83, 109, 114, 140, 168, 179, 184], 'prior': [35], 'running': [37], 'algorithm.': [41], 'The': [42, 81], 'are': [44, 52, 158], 'not': [45], 'heuristic:': [46], 'they': [47], 'only': [48], 'features': [50, 110], '{\\em': [53], 'guaranteed}': [54], 'be': [56], 'absent': [57], 'after': [58], 'solving': [59], 'problem.': [62], 'Our': [63, 160], 'framework': [64], 'applies': [65], 'large': [68], 'class': [69], 'problems,': [71], 'including': [72], 'support': [73], 'vector': [74], 'machine': [75], 'classification,': [76], 'logistic': [77], 'regression': [78], 'least-squares.': [80], 'complexity': [82], 'feature': [85], 'elimination': [86], 'step': [87], 'is': [88, 122], 'negligible': [89], 'compared': [90], 'typical': [93], 'computational': [94, 145], 'effort': [95, 146], 'involved': [96], 'sparse': [99, 156], 'problem:': [102], 'it': [103], 'grows': [104], 'linearly': [105], 'with': [106, 116], 'times': [111], 'examples,': [115], 'much': [117], 'better': [118], 'count': [119], 'if': [120], 'data': [121, 129, 177], 'sparse.': [123], 'apply': [125], 'our': [126], 'method': [127, 161], 'sets': [130, 178], 'arising': [131], 'text': [133], 'classification': [134], 'observe': [136], 'dramatic': [138], 'dimensionality,': [142], 'hence': [143], 'required': [147], 'solve': [149], 'problem,': [152], 'especially': [153], 'when': [154], 'very': [155], 'classifiers': [157], 'sought.': [159], 'allows': [162], 'immediately': [164], 'extend': [165], 'scope': [167], 'existing': [169], 'algorithms,': [170], 'allowing': [171], 'us': [172], 'run': [174], 'them': [175], 'on': [176], 'sizes': [180], 'were': [182], 'out': [183], 'their': [185], 'reach': [186], 'before.': [187]}",2010,"['Computer science', 'Machine learning', 'Artificial intelligence', 'Supervised learning', 'Semi-supervised learning', 'Dimensionality reduction', 'Heuristic', 'Feature vector', 'Curse of dimensionality', 'Support vector machine', 'Feature (linguistics)', 'Pattern recognition (psychology)', 'Artificial neural network', 'Philosophy', 'Linguistics']","We investigate fast methods that allow to quickly eliminate variables (features) in supervised learning problems involving a convex loss function and a $l_1$-norm penalty, leading to a potentially substantial reduction in the number of variables prior to running the supervised learning algorithm. The methods are not heuristic: they only eliminate features that are {\em guaranteed} to be absent after solving the learning problem. Our framework applies to a large class of problems, including support vector machine classification, logistic regression and least-squares. The complexity of the feature elimination step is negligible compared to the typical computational effort involved in the sparse supervised learning problem: it grows linearly with the number of features times the number of examples, with much better count if data is sparse. We apply our method to data sets arising in text classification and observe a dramatic reduction of the dimensionality, hence in computational effort required to solve the learning problem, especially when very sparse classifiers are sought. Our method allows to immediately extend the scope of existing algorithms, allowing us to run them on data sets of sizes that were out of their reach before."
https://openalex.org/W3026732421,CERT: Contrastive Self-supervised Learning for Language Understanding,"{'Pretrained': [0], 'language': [1, 12, 53, 77, 112], 'models': [2, 55], 'such': [3], 'as': [4], 'BERT,': [5], 'GPT': [6], 'have': [7], 'shown': [8], 'great': [9], 'effectiveness': [10], 'in': [11, 18], 'understanding.': [13], 'The': [14], 'auxiliary': [15], 'predictive': [16], 'tasks': [17], 'existing': [19], 'pretraining': [20], 'approaches': [21], 'are': [22], 'mostly': [23], 'defined': [24], 'on': [25, 110], 'tokens,': [26], 'thus': [27], 'may': [28], 'not': [29], 'be': [30, 99], 'able': [31], 'to': [32, 95], 'capture': [33], 'sentence-level': [34], 'semantics': [35], 'very': [36], 'well.': [37], 'To': [38], 'address': [39], 'this': [40], 'issue,': [41], 'we': [42], 'propose': [43], 'CERT:': [44], 'Contrastive': [45], 'self-supervised': [46, 58], 'Encoder': [47], 'Representations': [48], 'from': [49, 88], 'Transformers,': [50], 'which': [51], 'pretrains': [52], 'representation': [54], 'using': [56, 70], 'contrastive': [57], 'learning': [59], 'at': [60], 'the': [61, 89], 'sentence': [62], 'level.': [63], 'CERT': [64, 92, 109, 119], 'creates': [65], 'augmentations': [66], 'of': [67], 'original': [68], 'sentences': [69, 86], 'back-translation.': [71], 'Then': [72], 'it': [73], 'finetunes': [74], 'a': [75], 'pretrained': [76], 'encoder': [78], '(e.g.,': [79], 'BERT)': [80], 'by': [81], 'predicting': [82], 'whether': [83], 'two': [84], 'augmented': [85], 'originate': [87], 'same': [90], 'sentence.': [91], 'is': [93], 'simple': [94], 'use': [96], 'and': [97, 117], 'can': [98], 'flexibly': [100], 'plugged': [101], 'into': [102], 'any': [103], 'pretraining-finetuning': [104], 'NLP': [105], 'pipeline.': [106], 'We': [107], 'evaluate': [108], 'three': [111], 'understanding': [113], 'tasks:': [114], 'CoLA,': [115], 'RTE,': [116], 'QNLI.': [118], 'outperforms': [120], 'BERT': [121], 'significantly.&lt;br&gt;': [122]}",2020,"['Computer science', 'Sentence', 'Natural language processing', 'Artificial intelligence', 'Encoder', 'Transformer', 'Pipeline (software)', 'Programming language', 'Operating system', 'Physics', 'Quantum mechanics', 'Voltage']","Pretrained language models such as BERT, GPT have shown great effectiveness in language understanding. The auxiliary predictive tasks in existing pretraining approaches are mostly defined on tokens, thus may not be able to capture sentence-level semantics very well. To address this issue, we propose CERT: Contrastive self-supervised Encoder Representations from Transformers, which pretrains language representation models using contrastive self-supervised learning at the sentence level. CERT creates augmentations of original sentences using back-translation. Then it finetunes a pretrained language encoder (e.g., BERT) by predicting whether two augmented sentences originate from the same sentence. CERT is simple to use and can be flexibly plugged into any pretraining-finetuning NLP pipeline. We evaluate CERT on three language understanding tasks: CoLA, RTE, and QNLI. CERT outperforms BERT significantly.&lt;br&gt;"
https://openalex.org/W4389265550,"A comparison review of transfer learning and self-supervised learning: Definitions, applications, advantages and limitations","{'Deep': [0], 'learning': [1, 13, 34, 53, 65, 70, 114, 123, 172, 222, 236, 312], 'has': [2], 'emerged': [3], 'as': [4, 81, 200], 'a': [5, 77, 87, 293], 'powerful': [6], 'tool': [7], 'in': [8, 112, 176, 197, 258], 'various': [9, 177, 259], 'domains,': [10, 233], 'revolutionising': [11], 'machine': [12], 'research.': [14, 290], 'However,': [15, 208], 'one': [16], 'persistent': [17], 'challenge': [18], 'is': [19], 'the': [20, 28, 101, 119, 160, 229, 251, 262, 269, 277, 306, 316], 'scarcity': [21, 48, 318], 'of': [22, 32, 146, 240, 254, 273, 279, 296], 'labelled': [23, 92, 164], 'training': [24, 126], 'data,': [25], 'which': [26], 'hampers': [27], 'performance': [29, 115, 278], 'and': [30, 49, 66, 83, 104, 116, 170, 185, 205, 231, 271, 284], 'generalisation': [31], 'deep': [33, 51, 311], 'models.': [35], 'To': [36], 'address': [37, 315], 'this': [38, 300], 'limitation,': [39], 'researchers': [40], 'have': [41, 59, 173, 191, 217], 'developed': [42], 'innovative': [43], 'methods': [44, 211, 257], 'to': [45, 86, 98, 108, 139, 243, 314], 'overcome': [46], 'data': [47, 317], 'enhance': [50], 'model': [52], 'capabilities.': [54], 'Two': [55], 'prevalent': [56], 'techniques': [57], 'that': [58, 131], 'gained': [60], 'significant': [61], 'attention': [62], 'are': [63], 'transfer': [64, 106, 169, 221], 'self-supervised': [67, 122, 171, 235], 'learning.': [68], 'Transfer': [69], 'leverages': [71], 'knowledge': [72, 107], 'learned': [73, 102, 150], 'from': [74, 100, 143], 'pre-training': [75, 230, 256, 298], 'on': [76, 125], 'large-scale': [78], 'dataset,': [79], 'such': [80, 199], 'ImageNet,': [82], 'applies': [84], 'it': [85], 'target': [88, 232], 'task': [89], 'with': [90], 'limited': [91], 'data.': [93, 148, 165], 'This': [94, 247], 'approach': [95], 'allows': [96], 'models': [97, 127, 280], 'benefit': [99], 'representations': [103, 142, 151], 'effectively': [105], 'new': [109], 'tasks,': [110, 158], 'resulting': [111], 'improved': [113], 'generalisation.': [117], 'On': [118], 'other': [120], 'hand,': [121], 'focuses': [124], 'using': [128], 'pretext': [129, 241], 'tasks': [130, 242], 'do': [132], 'not': [133], 'require': [134], 'manual': [135], 'annotation,': [136], 'allowing': [137], 'them': [138], 'learn': [140], 'valuable': [141], 'large': [144], 'amounts': [145], 'unlabelled': [147], 'These': [149, 189], 'can': [152], 'then': [153], 'be': [154], 'fine-tuned': [155], 'for': [156, 162, 288, 304, 309], 'downstream': [157], 'mitigating': [159], 'need': [161], 'extensive': [163], 'In': [166], 'recent': [167, 252], 'years,': [168], 'found': [174], 'applications': [175, 253, 313], 'fields,': [178], 'including': [179], 'medical': [180], 'image': [181], 'processing,': [182], 'video': [183], 'recognition,': [184, 204], 'natural': [186], 'language': [187, 206], 'processing.': [188], 'approaches': [190], 'demonstrated': [192], 'remarkable': [193], 'achievements,': [194], 'enabling': [195], 'breakthroughs': [196], 'areas': [198], 'disease': [201], 'diagnosis,': [202], 'object': [203], 'understanding.': [207], 'while': [209, 234], 'these': [210, 255, 282], 'offer': [212], 'numerous': [213], 'advantages,': [214], 'they': [215], 'also': [216], 'limitations.': [218], 'For': [219], 'example,': [220], 'may': [223], 'face': [224], 'domain': [225], 'mismatch': [226], 'issues': [227], 'between': [228], 'requires': [237], 'careful': [238], 'design': [239], 'ensure': [244], 'meaningful': [245], 'representations.': [246], 'review': [248, 295], 'paper': [249], 'explores': [250], 'fields': [260], 'within': [261], 'past': [263], 'three': [264], 'years.': [265], 'It': [266], 'delves': [267], 'into': [268], 'advantages': [270], 'limitations': [272], 'each': [274], 'approach,': [275], 'assesses': [276], 'employing': [281], 'techniques,': [283], 'identifies': [285], 'potential': [286], 'directions': [287], 'future': [289], 'By': [291], 'providing': [292], 'comprehensive': [294], 'current': [297], 'methods,': [299], 'article': [301], 'offers': [302], 'guidance': [303], 'selecting': [305], 'best': [307], 'technique': [308], 'specific': [310], 'issue.': [319]}",2023,"['Computer science', 'Transfer of learning', 'Artificial intelligence', 'Machine learning', 'Deep learning', 'Task (project management)', 'Multi-task learning', 'Supervised learning', 'Artificial neural network', 'Management', 'Economics']","Deep learning has emerged as a powerful tool in various domains, revolutionising machine learning research. However, one persistent challenge is the scarcity of labelled training data, which hampers the performance and generalisation of deep learning models. To address this limitation, researchers have developed innovative methods to overcome data scarcity and enhance deep model learning capabilities. Two prevalent techniques that have gained significant attention are transfer learning and self-supervised learning. Transfer learning leverages knowledge learned from pre-training on a large-scale dataset, such as ImageNet, and applies it to a target task with limited labelled data. This approach allows models to benefit from the learned representations and effectively transfer knowledge to new tasks, resulting in improved learning performance and generalisation. On the other hand, self-supervised learning focuses on training models using pretext tasks that do not require manual annotation, allowing them to learn valuable representations from large amounts of unlabelled data. These learned representations can then be fine-tuned for downstream tasks, mitigating the need for extensive labelled data. In recent years, transfer and self-supervised learning have found applications in various fields, including medical image processing, video recognition, and natural language processing. These approaches have demonstrated remarkable achievements, enabling breakthroughs in areas such as disease diagnosis, object recognition, and language understanding. However, while these methods offer numerous advantages, they also have limitations. For example, transfer learning may face domain mismatch issues between the pre-training and target domains, while self-supervised learning requires careful design of pretext tasks to ensure meaningful representations. This review paper explores the recent applications of these pre-training methods in various fields within the past three years. It delves into the advantages and limitations of each approach, assesses the performance of models employing these techniques, and identifies potential directions for future research. By providing a comprehensive review of current pre-training methods, this article offers guidance for selecting the best technique for specific deep learning applications to address the data scarcity issue."
https://openalex.org/W4221145109,"data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language","{'While': [0], 'the': [1, 11, 43, 63, 73, 113, 118, 135], 'general': [2, 33], 'idea': [3, 56], 'of': [4, 62, 72, 85, 96, 121, 134], 'self-supervised': [5, 34], 'learning': [6, 45], 'is': [7, 57], 'identical': [8], 'across': [9], 'modalities,': [10], 'actual': [12], 'algorithms': [13], 'and': [14, 126], 'objectives': [15], 'differ': [16], 'widely': [17], 'because': [18], 'they': [19], 'were': [20], 'developed': [21], 'with': [22], 'a': [23, 39, 69, 76, 80, 131], 'single': [24], 'modality': [25], 'in': [26, 75, 102], 'mind.': [27], 'To': [28], 'get': [29], 'us': [30], 'closer': [31], 'to': [32, 58, 140], 'learning,': [35], 'we': [36], 'present': [37], 'data2vec,': [38], 'framework': [40], 'that': [41, 109], 'uses': [42], 'same': [44], 'method': [46], 'for': [47], 'either': [48], 'speech,': [49], 'NLP': [50], 'or': [51, 94, 137], 'computer': [52], 'vision.': [53], 'The': [54], 'core': [55], 'predict': [59], 'latent': [60, 107], 'representations': [61, 108], 'full': [64], 'input': [65, 74], 'data': [66], 'based': [67], 'on': [68, 117], 'masked': [70], 'view': [71], 'self-distillation': [77], 'setup': [78], 'using': [79], 'standard': [81], 'Transformer': [82], 'architecture.': [83], 'Instead': [84], 'predicting': [86], 'modality-specific': [87], 'targets': [88], 'such': [89], 'as': [90], 'words,': [91], 'visual': [92], 'tokens': [93], 'units': [95], 'human': [97], 'speech': [98, 122], 'which': [99], 'are': [100], 'local': [101], 'nature,': [103], 'data2vec': [104], 'predicts': [105], 'contextualized': [106], 'contain': [110], 'information': [111], 'from': [112], 'entire': [114], 'input.': [115], 'Experiments': [116], 'major': [119], 'benchmarks': [120], 'recognition,': [123], 'image': [124], 'classification,': [125], 'natural': [127], 'language': [128], 'understanding': [129], 'demonstrate': [130], 'new': [132], 'state': [133], 'art': [136], 'competitive': [138], 'performance': [139], 'predominant': [141], 'approaches.': [142]}",2022,"['Computer science', 'Transformer', 'Artificial intelligence', 'Modalities', 'Natural language processing', 'Modality (human–computer interaction)', 'Natural language', 'Speech recognition', 'Machine learning', 'Multimodal learning', 'Supervised learning', 'Language understanding', 'Artificial neural network', 'Physics', 'Sociology', 'Voltage', 'Quantum mechanics', 'Social science']","While the general idea of self-supervised learning is identical across modalities, the actual algorithms and objectives differ widely because they were developed with a single modality in mind. To get us closer to general self-supervised learning, we present data2vec, a framework that uses the same learning method for either speech, NLP or computer vision. The core idea is to predict latent representations of the full input data based on a masked view of the input in a self-distillation setup using a standard Transformer architecture. Instead of predicting modality-specific targets such as words, visual tokens or units of human speech which are local in nature, data2vec predicts contextualized latent representations that contain information from the entire input. Experiments on the major benchmarks of speech recognition, image classification, and natural language understanding demonstrate a new state of the art or competitive performance to predominant approaches."
https://openalex.org/W2921948732,Retinal Image Synthesis and Semi-Supervised Learning for Glaucoma Assessment,"{'[EN]': [0], 'Recent': [1], 'works': [2], 'show': [3], 'that': [4, 72, 86], 'Generative': [5, 127], 'Adversarial': [6, 128], 'Networks': [7, 129], '(GANs)': [8], 'can': [9, 74], 'be': [10, 75, 246], 'successfully': [11], 'applied': [12], 'to': [13, 33, 107, 134, 162, 167, 198, 212, 225, 249], 'image': [14, 45, 112, 208, 239], 'synthesis': [15], 'and': [16, 25, 47, 64, 82, 114, 133, 185, 230, 241], 'semi-supervised': [17, 49, 116], 'learning,': [18], 'where,': [19], 'given': [20], 'a': [21, 26, 35, 43, 48, 61, 109, 115], 'small': [22, 62], 'labelled': [23], 'database': [24], 'large': [27, 65], 'unlabelled': [28, 66], 'database,': [29], 'the': [30, 79, 88, 98, 124, 135, 138, 183, 193, 199, 203, 220, 242], 'goal': [31], 'is': [32, 106, 143, 158, 210, 223], 'train': [34], 'powerful': [36], 'classifier.': [37], 'In': [38, 131], 'this': [39, 92, 104, 141], 'paper,': [40], 'we': [41], 'trained': [42, 144], 'retinal': [44, 111, 216, 238, 256], 'synthesizer': [46, 113, 209, 240], 'learning': [50, 117], 'method': [51, 118], 'for': [52, 85, 119], 'automatic': [53], 'glaucoma': [54, 73, 120, 221, 243, 259], 'assessment': [55, 121], 'using': [56, 176], 'an': [57, 146, 251], 'adversarial': [58], 'model': [59], 'on': [60, 123, 145], 'glaucoma-labelled': [63], 'database.': [67], 'Various': [68], 'studies': [69], 'have': [70], 'shown': [71], 'monitored': [76], 'by': [77, 191], 'analyzing': [78], 'optic': [80, 99, 204], 'disc': [81], 'its': [83], 'surroundings,': [84], 'reason': [87], 'images': [89, 152, 164, 172, 184, 217, 257], 'used': [90, 247], 'in': [91], 'work': [93, 105], 'were': [94, 173, 189], 'automatically': [95], 'cropped': [96, 255], 'around': [97, 202], 'disc.': [100, 205], 'The': [101, 206, 236], 'novelty': [102], 'of': [103, 137, 149, 179, 195, 254], 'propose': [108], 'new': [110], 'based': [122], 'Deep': [125], 'Convolutional': [126], '(DCGAN).': [130], 'addition,': [132], 'best': [136], ""authors'"": [139], 'knowledge,': [140], 'system': [142], 'unprecedented': [147], 'number': [148, 253], 'publicly': [150], 'available': [151], '(86926': [153], 'images).': [154], 'This': [155], 'system,': [156], 'hence,': [157], 'not': [159], 'only': [160], 'able': [161, 211, 224], 'generate': [163, 213, 250], 'synthetically': [165], 'but': [166], 'provide': [168], 'labels': [169], 'automatically.': [170], 'Synthetic': [171], 'qualitatively': [174], 'evaluated': [175], 't-SNE': [177], 'plots': [178], 'features': [180], 'associated': [181], 'with': [182, 232, 258], 'their': [186], 'anatomical': [187, 200], 'consistency': [188], 'estimated': [190], 'measuring': [192], 'proportion': [194], 'pixels': [196], 'corresponding': [197], 'structures': [201], 'resulting': [207], 'realistic': [214], '(cropped)': [215], 'and,': [218], 'subsequently,': [219], 'classifier': [222, 244], 'classify': [226], 'them': [227], 'into': [228], 'glaucomatous': [229], 'normal': [231], 'high': [233], 'accuracy': [234], '(AUC=0.9017).': [235], 'obtained': [237], 'could': [245], 'then': [248], 'unlimited': [252], 'labels.': [260]}",2019,"['Artificial intelligence', 'Computer science', 'Glaucoma', 'Optic disc', 'Classifier (UML)', 'Pattern recognition (psychology)', 'Computer vision', 'Ophthalmology', 'Medicine']","[EN] Recent works show that Generative Adversarial Networks (GANs) can be successfully applied to image synthesis and semi-supervised learning, where, given a small labelled database and a large unlabelled database, the goal is to train a powerful classifier. In this paper, we trained a retinal image synthesizer and a semi-supervised learning method for automatic glaucoma assessment using an adversarial model on a small glaucoma-labelled and large unlabelled database. Various studies have shown that glaucoma can be monitored by analyzing the optic disc and its surroundings, for that reason the images used in this work were automatically cropped around the optic disc. The novelty of this work is to propose a new retinal image synthesizer and a semi-supervised learning method for glaucoma assessment based on the Deep Convolutional Generative Adversarial Networks (DCGAN). In addition, and to the best of the authors' knowledge, this system is trained on an unprecedented number of publicly available images (86926 images). This system, hence, is not only able to generate images synthetically but to provide labels automatically. Synthetic images were qualitatively evaluated using t-SNE plots of features associated with the images and their anatomical consistency were estimated by measuring the proportion of pixels corresponding to the anatomical structures around the optic disc. The resulting image synthesizer is able to generate realistic (cropped) retinal images and, subsequently, the glaucoma classifier is able to classify them into glaucomatous and normal with high accuracy (AUC=0.9017). The obtained retinal image synthesizer and the glaucoma classifier could be used then to generate an unlimited number of cropped retinal images with glaucoma labels."
https://openalex.org/W4382240004,Spatio-Temporal Self-Supervised Learning for Traffic Flow Prediction,"{'Robust': [0], 'prediction': [1, 101, 188], 'of': [2, 112, 172], 'citywide': [3], 'traffic': [4, 56, 71, 100, 106, 161, 175, 187], 'flows': [5, 44], 'at': [6, 165, 232], 'different': [7, 51], 'time': [8, 86], 'periods': [9], 'plays': [10], 'a': [11, 80, 94], 'crucial': [12], 'role': [13], 'in': [14, 214], 'intelligent': [15], 'transportation': [16], 'systems.': [17], 'While': [18], 'previous': [19], 'work': [20], 'has': [21], 'made': [22], 'great': [23], 'efforts': [24], 'to': [25, 63, 109, 183], 'model': [26, 76], 'spatio-temporal': [27, 149, 210], 'correlations,': [28], 'existing': [29], 'methods': [30], 'still': [31], 'suffer': [32], 'from': [33], 'two': [34, 177], 'key': [35], 'limitations:': [36], 'i)': [37], 'Most': [38], 'models': [39, 61], 'collectively': [40], 'predict': [41], 'all': [42, 85], ""regions'"": [43], 'without': [45], 'accounting': [46], 'for': [47, 84, 137], 'spatial': [48, 114, 135, 191], 'heterogeneity,': [49, 117], 'i.e.,': [50], 'regions': [52], 'may': [53, 220], 'have': [54], 'skewed': [55], 'flow': [57, 162], 'distributions.': [58], 'ii)': [59], 'These': [60], 'fail': [62], 'capture': [64], 'the': [65, 105, 139, 147, 156, 160, 173, 185, 217], 'temporal': [66, 77, 116, 133, 193], 'heterogeneity': [67, 211], 'induced': [68], 'by': [69], 'time-varying': [70], 'patterns,': [72], 'as': [73], 'they': [74], 'typically': [75], 'correlations': [78], 'with': [79, 118, 132, 190], 'shared': [81], 'parameterized': [82], 'space': [83, 142], 'periods.': [87], 'To': [88, 145], 'tackle': [89], 'these': [90], 'challenges,': [91], 'we': [92], 'propose': [93], 'novel': [95], 'Spatio-Temporal': [96], 'Self-Supervised': [97], 'Learning': [98], '(ST-SSL)': [99], 'framework': [102, 219], 'which': [103], 'enhances': [104], 'pattern': [107], 'representations': [108], 'be': [110], 'reflective': [111], 'both': [113, 166], 'and': [115, 134, 143, 168, 192], 'auxiliary': [119, 179], 'self-supervised': [120, 150], 'learning': [121], 'paradigms.': [122], 'Specifically,': [123], 'our': [124, 152], 'ST-SSL': [125, 153, 203], 'is': [126, 230], 'built': [127], 'over': [128, 159], 'an': [129], 'integrated': [130], 'module': [131], 'convolutions': [136], 'encoding': [138], 'information': [140], 'across': [141], 'time.': [144], 'achieve': [146], 'adaptive': [148, 157], 'learning,': [151], 'first': [154], 'performs': [155], 'augmentation': [158], 'graph': [163], 'data': [164], 'attribute-': [167], 'structure-levels.': [169], 'On': [170], 'top': [171], 'augmented': [174], 'graph,': [176], 'SSL': [178], 'tasks': [180], 'are': [181], 'constructed': [182], 'supplement': [184], 'main': [186], 'task': [189], 'heterogeneity-aware': [194], 'augmentation.': [195], 'Experiments': [196], 'on': [197, 224], 'four': [198], 'benchmark': [199], 'datasets': [200], 'demonstrate': [201], 'that': [202], 'consistently': [204], 'outperforms': [205], 'various': [206], 'state-of-the-art': [207], 'baselines.': [208], 'Since': [209], 'widely': [212], 'exists': [213], 'practical': [215], 'datasets,': [216], 'proposed': [218], 'also': [221], 'cast': [222], 'light': [223], 'other': [225], 'spatial-temporal': [226], 'applications.': [227], 'Model': [228], 'implementation': [229], 'available': [231], 'https://github.com/Echo-Ji/ST-SSL.': [233]}",2023,"['Computer science', 'Benchmark (surveying)', 'Temporal database', 'Graph', 'Artificial intelligence', 'Data mining', 'Machine learning', 'Parameterized complexity', 'Deep learning', 'Key (lock)', 'Theoretical computer science', 'Geography', 'Computer security', 'Geodesy', 'Algorithm']","Robust prediction of citywide traffic flows at different time periods plays a crucial role in intelligent transportation systems. While previous work has made great efforts to model spatio-temporal correlations, existing methods still suffer from two key limitations: i) Most models collectively predict all regions' flows without accounting for spatial heterogeneity, i.e., different regions may have skewed traffic flow distributions. ii) These models fail to capture the temporal heterogeneity induced by time-varying traffic patterns, as they typically model temporal correlations with a shared parameterized space for all time periods. To tackle these challenges, we propose a novel Spatio-Temporal Self-Supervised Learning (ST-SSL) traffic prediction framework which enhances the traffic pattern representations to be reflective of both spatial and temporal heterogeneity, with auxiliary self-supervised learning paradigms. Specifically, our ST-SSL is built over an integrated module with temporal and spatial convolutions for encoding the information across space and time. To achieve the adaptive spatio-temporal self-supervised learning, our ST-SSL first performs the adaptive augmentation over the traffic flow graph data at both attribute- and structure-levels. On top of the augmented traffic graph, two SSL auxiliary tasks are constructed to supplement the main traffic prediction task with spatial and temporal heterogeneity-aware augmentation. Experiments on four benchmark datasets demonstrate that ST-SSL consistently outperforms various state-of-the-art baselines. Since spatio-temporal heterogeneity widely exists in practical datasets, the proposed framework may also cast light on other spatial-temporal applications. Model implementation is available at https://github.com/Echo-Ji/ST-SSL."
https://openalex.org/W4321593910,Multi-Modal Self-Supervised Learning for Recommendation,"{'The': [0, 171], 'online': [1], 'emergence': [2], 'of': [3, 60, 74, 158], 'multi-modal': [4, 30, 106], 'sharing': [5], 'platforms': [6], '(eg,': [7], 'TikTok,': [8], 'Youtube)\\nis': [9], 'powering': [10], 'personalized': [11], 'recommender': [12], 'systems': [13], 'to': [14, 123, 142], 'incorporate': [15], 'various': [16, 168], 'modalities\\n(eg,': [17], 'visual,': [18], 'textual': [19], 'and': [20, 48, 78, 148], 'acoustic)': [21], 'into': [22], 'the': [23, 57, 98, 101, 125, 145, 156], 'latent': [24], 'user': [25, 53, 76, 149], 'representations.': [26], 'While\\nexisting': [27], 'works': [28], 'on': [29, 51, 153], 'recommendation': [31], 'exploit': [32], 'multimedia': [33], 'content\\nfeatures': [34], 'in': [35, 161], 'enhancing': [36], 'item': [37], 'embeddings,': [38], 'their': [39], 'model': [40], 'representation': [41], 'capability': [42], 'is\\nlimited': [43], 'by': [44, 56], 'heavy': [45], 'label': [46, 64], 'reliance': [47], 'weak': [49], 'robustness': [50], 'sparse': [52], 'behavior\\ndata.': [54], 'Inspired': [55], 'recent': [58], 'progress': [59], 'self-supervised': [61], 'learning': [62, 73, 114], 'in\\nalleviating': [63], 'scarcity': [65], 'issue,': [66], 'we': [67, 83, 109], 'explore': [68], 'deriving': [69], 'self-supervision': [70], 'signals\\nwith': [71], 'effectively': [72], 'modality-aware': [75, 112], 'preference': [77, 150], 'cross-modal\\ndependencies.': [79], 'To': [80], 'this': [81], 'end,': [82], 'propose': [84], 'a': [85, 111, 136], 'new': [86], 'Multi-Modal': [87], 'Self-Supervised\\nLearning': [88], '(MMSSL)': [89], 'method': [90, 160], 'which': [91], 'tackles': [92], 'two': [93], 'key': [94], 'challenges.': [95], 'Specifically,': [96], 'to\\ncharacterize': [97], 'inter-dependency': [99], 'between': [100], 'user-item': [102], 'collaborative': [103], 'view': [104], 'and\\nitem': [105], 'semantic': [107], 'view,': [108], 'design': [110], 'interactive\\nstructure': [113], 'paradigm': [115], 'via': [116], 'adversarial': [117], 'perturbations': [118], 'for': [119, 165], 'data\\naugmentation.': [120], 'In': [121], 'addition,': [122], 'capture': [124], 'effects': [126], 'that': [127], ""user's"": [128], 'modality-aware\\ninteraction': [129], 'pattern': [130], 'would': [131], 'interweave': [132], 'with': [133], 'each': [134], 'other,': [135], 'cross-modal': [137], 'contrastive\\nlearning': [138], 'approach': [139], 'is': [140], 'introduced': [141], 'jointly': [143], 'preserve': [144], 'inter-modal': [146], 'semantic\\ncommonality': [147], 'diversity.': [151], 'Experiments': [152], 'real-world': [154], 'datasets\\nverify': [155], 'superiority': [157], 'our': [159], 'offering': [162], 'great': [163], 'potential': [164], 'multimedia\\nrecommendation': [166], 'over': [167], 'state-of-the-art': [169], 'baselines.': [170], 'implementation': [172], 'is\\nreleased': [173], 'at:': [174], 'https://github.com/HKUDS/MMSSL.\\n': [175]}",2023,"['Computer science', 'Modal', 'Artificial intelligence', 'Recommender system', 'Machine learning', 'Polymer chemistry', 'Chemistry']","The online emergence of multi-modal sharing platforms (eg, TikTok, Youtube)\nis powering personalized recommender systems to incorporate various modalities\n(eg, visual, textual and acoustic) into the latent user representations. While\nexisting works on multi-modal recommendation exploit multimedia content\nfeatures in enhancing item embeddings, their model representation capability is\nlimited by heavy label reliance and weak robustness on sparse user behavior\ndata. Inspired by the recent progress of self-supervised learning in\nalleviating label scarcity issue, we explore deriving self-supervision signals\nwith effectively learning of modality-aware user preference and cross-modal\ndependencies. To this end, we propose a new Multi-Modal Self-Supervised\nLearning (MMSSL) method which tackles two key challenges. Specifically, to\ncharacterize the inter-dependency between the user-item collaborative view and\nitem multi-modal semantic view, we design a modality-aware interactive\nstructure learning paradigm via adversarial perturbations for data\naugmentation. In addition, to capture the effects that user's modality-aware\ninteraction pattern would interweave with each other, a cross-modal contrastive\nlearning approach is introduced to jointly preserve the inter-modal semantic\ncommonality and user preference diversity. Experiments on real-world datasets\nverify the superiority of our method in offering great potential for multimedia\nrecommendation over various state-of-the-art baselines. The implementation is\nreleased at: https://github.com/HKUDS/MMSSL.\n"
https://openalex.org/W3093579165,Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition,"{'We': [0], 'employ': [1], 'a': [2], 'combination': [3], 'of': [4, 24], 'recent': [5], 'developments': [6], 'in': [7], 'semi-supervised': [8], 'learning': [9], 'for': [10], 'automatic': [11], 'speech': [12], 'recognition': [13], 'to': [14, 53], 'obtain': [15], 'state-of-the-art': [16, 66], 'results': [17], 'on': [18, 58], 'LibriSpeech': [19, 60], 'utilizing': [20], 'the': [21, 25, 59, 64], 'unlabeled': [22], 'audio': [23], 'Libri-Light': [26], 'dataset.': [27], 'More': [28], 'precisely,': [29], 'we': [30, 50], 'carry': [31], 'out': [32], 'noisy': [33], 'student': [34], 'training': [35], 'with': [36], 'SpecAugment': [37], 'using': [38, 43], 'giant': [39], 'Conformer': [40], 'models': [41], 'pre-trained': [42], 'wav2vec': [44], '2.0': [45], 'pre-training.': [46], 'By': [47], 'doing': [48], 'so,': [49], 'are': [51], 'able': [52], 'achieve': [54], 'word-error-rates': [55], '(WERs)': [56], '1.4%/2.6%': [57], 'test/test-other': [61], 'sets': [62], 'against': [63], 'current': [65], 'WERs': [67], '1.7%/3.3%.': [68]}",2020,"['State (computer science)', 'Speech recognition', 'Test (biology)', 'Computer science', 'Word (group theory)', 'Word error rate', 'Artificial intelligence', 'Mathematics', 'Algorithm', 'Biology', 'Paleontology', 'Geometry']","We employ a combination of recent developments in semi-supervised learning for automatic speech recognition to obtain state-of-the-art results on LibriSpeech utilizing the unlabeled audio of the Libri-Light dataset. More precisely, we carry out noisy student training with SpecAugment using giant Conformer models pre-trained using wav2vec 2.0 pre-training. By doing so, we are able to achieve word-error-rates (WERs) 1.4%/2.6% on the LibriSpeech test/test-other sets against the current state-of-the-art WERs 1.7%/3.3%."
https://openalex.org/W2054113233,Supervised Learning in Multilayer Spiking Neural Networks,"{'We': [0], 'introduce': [1], 'a': [2, 14], 'supervised': [3], 'learning': [4, 18], 'algorithm': [5, 12, 58, 88], 'for': [6, 112], 'multilayer': [7], 'spiking': [8], 'neural': [9, 31], 'networks.': [10], 'The': [11, 57, 87], 'overcomes': [13], 'limitation': [15], 'of': [16, 53, 96], 'existing': [17, 110], 'algorithms:': [19], 'it': [20], 'can': [21, 37], 'be': [22, 41], 'applied': [23, 60], 'to': [24, 62, 80], 'neurons': [25], 'firing': [26], 'multiple': [27], 'spikes': [28], 'in': [29, 39, 93, 106], 'artificial': [30], 'networks': [32, 100], 'with': [33, 43], 'hidden': [34], 'layers.': [35], 'It': [36], 'also,': [38], 'principle,': [40], 'used': [42], 'any': [44], 'linearizable': [45], 'neuron': [46], 'model': [47], 'and': [48, 72, 84, 104], 'allows': [49], 'different': [50], 'coding': [51], 'schemes': [52], 'spike': [54], 'train': [55], 'patterns.': [56], 'is': [59], 'successfully': [61, 91], 'classic': [63], 'linearly': [64], 'nonseparable': [65], 'benchmarks': [66], 'such': [67, 115], 'as': [68, 77, 79, 116], 'the': [69, 73, 94], 'XOR': [70], 'problem': [71], 'Iris': [74], 'data': [75], 'set,': [76], 'well': [78], 'more': [81], 'complex': [82], 'classification': [83], 'mapping': [85], 'problems.': [86], 'has': [89], 'been': [90], 'tested': [92], 'presence': [95], 'noise,': [97], 'requires': [98], 'smaller': [99], 'than': [101, 109], 'reservoir': [102], 'computing,': [103], 'results': [105], 'faster': [107], 'convergence': [108], 'algorithms': [111], 'similar': [113], 'tasks': [114], 'SpikeProp.': [117]}",2012,"['Artificial neural network', 'Computer science', 'Artificial intelligence', 'Spiking neural network', 'Coding (social sciences)', 'Algorithm', 'Convergence (economics)', 'Set (abstract data type)', 'Supervised learning', 'Spike (software development)', 'Neural coding', 'Noise (video)', 'Pattern recognition (psychology)', 'Mathematics', 'Economic growth', 'Software engineering', 'Image (mathematics)', 'Economics', 'Statistics', 'Programming language']","We introduce a supervised learning algorithm for multilayer spiking neural networks. The algorithm overcomes a limitation of existing learning algorithms: it can be applied to neurons firing multiple spikes in artificial neural networks with hidden layers. It can also, in principle, be used with any linearizable neuron model and allows different coding schemes of spike train patterns. The algorithm is applied successfully to classic linearly nonseparable benchmarks such as the XOR problem and the Iris data set, as well as to more complex classification and mapping problems. The algorithm has been successfully tested in the presence of noise, requires smaller networks than reservoir computing, and results in faster convergence than existing algorithms for similar tasks such as SpikeProp."
https://openalex.org/W3201190151,Self-supervised learning methods and applications in medical imaging analysis: a survey,"{'The': [0, 88], 'scarcity': [1, 56], 'of': [2, 21, 57, 84, 93, 128, 137], 'high-quality': [3], 'annotated': [4, 58], 'medical': [5, 22, 59, 85, 111, 141], 'imaging': [6, 23, 86, 112, 142], 'datasets': [7], 'is': [8, 31], 'a': [9, 32, 76, 91], 'major': [10], 'problem': [11], 'that': [12, 36], 'collides': [13], 'with': [14, 75, 160], 'machine': [15], 'learning': [16, 30, 38, 70, 98, 139], 'applications': [17, 80], 'in': [18, 68, 81, 134, 140, 153, 165], 'the': [19, 42, 55, 64, 82, 94, 101, 110, 124, 129, 135, 147, 150, 154, 157, 166], 'field': [20, 83, 104, 136], 'analysis': [24, 113, 143], 'and': [25, 114, 120], 'impedes': [26], 'its': [27], 'advancement.': [28], 'Self-supervised': [29], 'recent': [33, 96, 131, 151], 'training': [34], 'paradigm': [35], 'enables': [37], 'robust': [39], 'representations': [40], 'without': [41], 'need': [43], 'for': [44, 54, 72], 'human': [45], 'annotation': [46], 'which': [47], 'can': [48], 'be': [49], 'considered': [50], 'an': [51], 'effective': [52], 'solution': [53], 'data.': [60], 'This': [61], 'article': [62, 89, 125, 158], 'reviews': [63], 'state-of-the-art': [65], 'research': [66, 132, 163], 'directions': [67, 164], 'self-supervised': [69, 97, 138], 'approaches': [71], 'image': [73], 'data': [74], 'concentration': [77], 'on': [78, 149], 'their': [79], 'analysis.': [87], 'covers': [90, 126], 'set': [92], 'most': [95, 130], 'methods': [99], 'from': [100], 'computer': [102], 'vision': [103], 'as': [105, 117], 'they': [106], 'are': [107], 'applicable': [108], 'to': [109], 'categorize': [115], 'them': [116], 'predictive,': [118], 'generative,': [119], 'contrastive': [121], 'approaches.': [122], 'Moreover,': [123], '40': [127], 'papers': [133], 'aiming': [144], 'at': [145], 'shedding': [146], 'light': [148], 'innovation': [152], 'field.': [155, 167], 'Finally,': [156], 'concludes': [159], 'possible': [161], 'future': [162]}",2022,"['Field (mathematics)', 'Computer science', 'Artificial intelligence', 'Medical imaging', 'Categorization', 'Data science', 'Machine learning', 'Supervised learning', 'Scarcity', 'Medical research', 'Artificial neural network', 'Medicine', 'Mathematics', 'Economics', 'Pathology', 'Microeconomics', 'Pure mathematics']","The scarcity of high-quality annotated medical imaging datasets is a major problem that collides with machine learning applications in the field of medical imaging analysis and impedes its advancement. Self-supervised learning is a recent training paradigm that enables learning robust representations without the need for human annotation which can be considered an effective solution for the scarcity of annotated medical data. This article reviews the state-of-the-art research directions in self-supervised learning approaches for image data with a concentration on their applications in the field of medical imaging analysis. The article covers a set of the most recent self-supervised learning methods from the computer vision field as they are applicable to the medical imaging analysis and categorize them as predictive, generative, and contrastive approaches. Moreover, the article covers 40 of the most recent research papers in the field of self-supervised learning in medical imaging analysis aiming at shedding the light on the recent innovation in the field. Finally, the article concludes with possible future research directions in the field."
https://openalex.org/W2890787190,Supervised Learning for Suicidal Ideation Detection in Online User Content,"{'Early': [0], 'detection': [1, 59, 165], 'and': [2, 15, 67, 93, 100, 109, 129, 132, 142, 153, 158, 173], 'treatment': [3], 'are': [4, 29], 'regarded': [5], 'as': [6, 77], 'the': [7, 55, 151, 156, 162, 167], 'most': [8], 'effective': [9], 'ways': [10], 'to': [11, 36, 46], 'prevent': [12], 'suicidal': [13, 39, 48, 84, 114, 163], 'ideation': [14, 49, 164], 'potential': [16], 'suicide': [17], 'attempts—two': [18], 'critical': [19], 'risk': [20], 'factors': [21], 'resulting': [22], 'in': [23], 'successful': [24], 'suicides.': [25], 'Online': [26], 'communication': [27], 'channels': [28], 'becoming': [30], 'a': [31], 'new': [32], 'way': [33], 'for': [34, 82, 161], 'people': [35], 'express': [37, 88], 'their': [38], 'tendencies.': [40, 85], 'This': [41], 'paper': [42], 'presents': [43], 'an': [44, 78], 'approach': [45, 157], 'understand': [47], 'through': [50], 'online': [51, 169], 'user‐generated': [52], 'content': [53], 'with': [54], 'goal': [56], 'of': [57, 121, 155], 'early': [58, 79], 'via': [60], 'supervised': [61, 140], 'learning.': [62], 'Analysing': [63], 'users’': [64], 'language': [65], 'preferences': [66], 'topic': [68, 130], 'descriptions': [69], 'reveals': [70], 'rich': [71], 'knowledge': [72], 'that': [73], 'can': [74], 'be': [75], 'used': [76], 'warning': [80], 'system': [81], 'detecting': [83], 'Suicidal': [86, 95], 'individuals': [87], 'strong': [89], 'negative': [90], 'feelings,': [91], 'anxiety,': [92], 'hopelessness.': [94], 'thoughts': [96], 'may': [97], 'involve': [98], 'family': [99], 'friends.': [101], 'And': [102], 'topics': [103], 'they': [104], 'discuss': [105], 'cover': [106], 'both': [107], 'personal': [108], 'social': [110], 'issues.': [111], 'To': [112], 'detect': [113], 'ideation,': [115], 'we': [116, 133], 'extract': [117], 'several': [118], 'informative': [119], 'sets': [120], 'features,': [122, 131], 'including': [123, 137], 'statistical,': [124], 'syntactic,': [125], 'linguistic,': [126], 'word': [127], 'embedding,': [128], 'compare': [134], 'six': [135], 'classifiers,': [136], 'four': [138], 'traditional': [139], 'classifiers': [141], 'two': [143], 'neural': [144], 'network': [145], 'models.': [146], 'An': [147], 'experimental': [148], 'study': [149], 'demonstrates': [150], 'feasibility': [152], 'practicability': [154], 'provides': [159], 'benchmarks': [160], 'on': [166], 'active': [168], 'platforms:': [170], 'Reddit': [171], 'SuicideWatch': [172], 'Twitter.': [174]}",2018,"['Suicidal ideation', 'Ideation', 'Feeling', 'Psychology', 'Computer science', 'Anxiety', 'Social media', 'Word embedding', 'Artificial intelligence', 'Machine learning', 'Suicide prevention', 'Poison control', 'Social psychology', 'World Wide Web', 'Embedding', 'Medicine', 'Psychiatry', 'Cognitive science', 'Environmental health']","Early detection and treatment are regarded as the most effective ways to prevent suicidal ideation and potential suicide attempts—two critical risk factors resulting in successful suicides. Online communication channels are becoming a new way for people to express their suicidal tendencies. This paper presents an approach to understand suicidal ideation through online user‐generated content with the goal of early detection via supervised learning. Analysing users’ language preferences and topic descriptions reveals rich knowledge that can be used as an early warning system for detecting suicidal tendencies. Suicidal individuals express strong negative feelings, anxiety, and hopelessness. Suicidal thoughts may involve family and friends. And topics they discuss cover both personal and social issues. To detect suicidal ideation, we extract several informative sets of features, including statistical, syntactic, linguistic, word embedding, and topic features, and we compare six classifiers, including four traditional supervised classifiers and two neural network models. An experimental study demonstrates the feasibility and practicability of the approach and provides benchmarks for the suicidal ideation detection on the active online platforms: Reddit SuicideWatch and Twitter."
https://openalex.org/W2914913933,Exploiting Unlabeled Data in CNNs by Self-Supervised Learning to Rank,"{'For': [0, 104], 'many': [1], 'applications': [2], 'the': [3, 39, 80, 85, 127, 162], 'collection': [4], 'of': [5, 12, 23, 170, 172], 'labeled': [6, 132], 'data': [7, 14, 44, 133, 141], 'is': [8, 17, 45, 166], 'expensive': [9], 'laborious.': [10], 'Exploitation': [11], 'unlabeled': [13, 116, 140, 173], 'during': [15], 'training': [16], 'thus': [18], 'a': [19, 59, 167], 'long': [20], 'pursued': [21], 'objective': [22], 'machine': [24], 'learning.': [25], 'Self-supervised': [26], 'learning': [27, 185], 'addresses': [28], 'this': [29, 49, 190], 'by': [30, 84, 194], 'positing': [31], 'an': [32, 71, 181], 'auxiliary': [33], 'task': [34, 61, 165], '(different,': [35], 'but': [36], 'related': [37], 'to': [38, 93, 109, 124, 126, 135, 138, 179, 196], 'supervised': [40], 'task)': [41], 'for': [42, 62, 75, 131, 147, 183], 'which': [43, 78], 'abundantly': [46], 'available.': [47], 'In': [48, 153], 'paper,': [50], 'we': [51, 69, 106, 155, 187], 'show': [52, 107, 120, 156, 188], 'how': [53, 108], 'ranking': [54], 'can': [55, 176], 'be': [56, 177], 'used': [57, 178], 'as': [58], 'proxy': [60, 164], 'some': [63], 'regression': [64, 95], 'problems.': [65], 'As': [66], 'another': [67], 'contribution,': [68], 'propose': [70], 'efficient': [72], 'backpropagation': [73], 'technique': [74], 'Siamese': [76], 'networks': [77, 122], 'prevents': [79], 'redundant': [81], 'computation': [82], 'introduced': [83], 'multi-branch': [86], 'network': [87, 159], 'architecture.': [88], 'We': [89], 'apply': [90], 'our': [91], 'framework': [92], 'two': [94], 'problems:': [96], 'Image': [97], 'Quality': [98], 'Assessment': [99], '(IQA)': [100], 'and': [101, 134, 150, 186], 'Crowd': [102], 'Counting.': [103], 'both': [105, 148], 'automatically': [110], 'generate': [111], 'ranked': [112], 'image': [113], 'sets': [114], 'from': [115], 'data.': [117, 174], 'Our': [118], 'results': [119, 146], 'that': [121, 157, 189], 'trained': [123], 'regress': [125], 'ground': [128], 'truth': [129], 'targets': [130], 'simultaneously': [136], 'learn': [137], 'rank': [139], 'obtain': [142], 'significantly': [143], 'better,': [144], 'state-of-the-art': [145], 'IQA': [149], 'crowd': [151], 'counting.': [152], 'addition,': [154], 'measuring': [158], 'uncertainty': [160], 'on': [161], 'self-supervised': [163], 'good': [168], 'measure': [169], 'informativeness': [171], 'This': [175], 'drive': [180], 'algorithm': [182], 'active': [184], 'reduces': [191], 'labeling': [192], 'effort': [193], 'up': [195], '50': [197], 'percent.': [198]}",2019,"['Artificial intelligence', 'Computer science', 'Machine learning', 'Labeled data', 'Ranking (information retrieval)', 'Task (project management)', 'Supervised learning', 'Regression', 'Learning to rank', 'Ground truth', 'Pattern recognition (psychology)', 'Semi-supervised learning', 'Rank (graph theory)', 'Data mining', 'Artificial neural network', 'Mathematics', 'Statistics', 'Economics', 'Management', 'Combinatorics']","For many applications the collection of labeled data is expensive laborious. Exploitation of unlabeled data during training is thus a long pursued objective of machine learning. Self-supervised learning addresses this by positing an auxiliary task (different, but related to the supervised task) for which data is abundantly available. In this paper, we show how ranking can be used as a proxy task for some regression problems. As another contribution, we propose an efficient backpropagation technique for Siamese networks which prevents the redundant computation introduced by the multi-branch network architecture. We apply our framework to two regression problems: Image Quality Assessment (IQA) and Crowd Counting. For both we show how to automatically generate ranked image sets from unlabeled data. Our results show that networks trained to regress to the ground truth targets for labeled data and to simultaneously learn to rank unlabeled data obtain significantly better, state-of-the-art results for both IQA and crowd counting. In addition, we show that measuring network uncertainty on the self-supervised proxy task is a good measure of informativeness of unlabeled data. This can be used to drive an algorithm for active learning and we show that this reduces labeling effort by up to 50 percent."
https://openalex.org/W2950562763,Semi-supervised learning of the electronic health record for phenotype stratification,"{'Patient': [0], 'interactions': [1], 'with': [2, 43, 108], 'health': [3, 11], 'care': [4], 'providers': [5], 'result': [6], 'in': [7, 68, 123, 132, 148], 'entries': [8], 'to': [9, 35, 46, 81, 174], 'electronic': [10, 37], 'records': [12, 32, 70], '(EHRs).': [13], 'EHRs': [14], 'were': [15], 'built': [16], 'for': [17, 94, 101, 160], 'clinical': [18, 125], 'and': [19, 62, 74, 88, 119, 158, 178], 'billing': [20], 'purposes': [21], 'but': [22], 'contain': [23], 'many': [24, 66], 'data': [25, 45], 'points': [26], 'about': [27], 'an': [28], 'individual.': [29], 'Mining': [30], 'these': [31], 'provides': [33], 'opportunities': [34], 'extract': [36], 'phenotypes,': [38, 144], 'which': [39], 'can': [40], 'be': [41], 'paired': [42], 'genetic': [44], 'identify': [47], 'genes': [48], 'underlying': [49], 'common': [50, 146], 'human': [51], 'diseases.': [52], 'This': [53, 128, 168], 'task': [54], 'remains': [55], 'challenging:': [56], 'high': [57, 142], 'quality': [58, 143], 'phenotyping': [59], 'is': [60, 129], 'costly': [61], 'requires': [63], 'physician': [64], 'review;': [65], 'fields': [67], 'the': [69, 161], 'are': [71, 79], 'sparsely': [72], 'filled;': [73], 'our': [75], 'definitions': [76], 'of': [77, 139, 163, 166], 'diseases': [78], 'continuing': [80], 'improve': [82, 179], 'over': [83], 'time.': [84], 'Here': [85], 'we': [86, 111], 'develop': [87], 'evaluate': [89], 'a': [90, 136, 145, 171], 'semi-supervised': [91], 'learning': [92], 'method': [93, 169], 'EHR': [95], 'phenotype': [96, 102], 'extraction': [97], 'using': [98], 'denoising': [99, 106], 'autoencoders': [100, 107, 152], 'stratification.': [103], 'By': [104], 'combining': [105], 'random': [109], 'forests': [110], 'find': [112], 'classification': [113], 'improvements': [114], 'across': [115], 'multiple': [116], 'simulation': [117], 'models': [118], 'improved': [120], 'survival': [121], 'prediction': [122], 'ALS': [124], 'trial': [126], 'data.': [127], 'particularly': [130], 'evident': [131], 'cases': [133], 'where': [134], 'only': [135], 'small': [137], 'number': [138], 'patients': [140], 'have': [141], 'scenario': [147], 'EHR-based': [149], 'research.': [150], 'Denoising': [151], 'perform': [153], 'dimensionality': [154], 'reduction': [155], 'enabling': [156], 'visualization': [157], 'clustering': [159], 'discovery': [162], 'new': [164], 'subtypes': [165, 177], 'disease.': [167], 'represents': [170], 'promising': [172], 'approach': [173], 'clarify': [175], 'disease': [176], 'genotype-phenotype': [180], 'association': [181], 'studies': [182], 'that': [183], 'leverage': [184], 'EHRs.': [185]}",2016,"['Computer science', 'Machine learning', 'Leverage (statistics)', 'Random forest', 'Health records', 'Artificial intelligence', 'Data mining', 'Cluster analysis', 'Dimensionality reduction', 'Supervised learning', 'Artificial neural network', 'Health care', 'Economics', 'Economic growth']","Patient interactions with health care providers result in entries to electronic health records (EHRs). EHRs were built for clinical and billing purposes but contain many data points about an individual. Mining these records provides opportunities to extract electronic phenotypes, which can be paired with genetic data to identify genes underlying common human diseases. This task remains challenging: high quality phenotyping is costly and requires physician review; many fields in the records are sparsely filled; and our definitions of diseases are continuing to improve over time. Here we develop and evaluate a semi-supervised learning method for EHR phenotype extraction using denoising autoencoders for phenotype stratification. By combining denoising autoencoders with random forests we find classification improvements across multiple simulation models and improved survival prediction in ALS clinical trial data. This is particularly evident in cases where only a small number of patients have high quality phenotypes, a common scenario in EHR-based research. Denoising autoencoders perform dimensionality reduction enabling visualization and clustering for the discovery of new subtypes of disease. This method represents a promising approach to clarify disease subtypes and improve genotype-phenotype association studies that leverage EHRs."
https://openalex.org/W2024152195,Optimal Spike-Timing-Dependent Plasticity for Precise Action Potential Firing in Supervised Learning,"{'In': [0, 123], 'timing-based': [1], 'neural': [2], 'codes,': [3], 'neurons': [4], 'have': [5], 'to': [6, 21, 167], 'emit': [7], 'action': [8], 'potentials': [9], 'at': [10, 37], 'precise': [11], 'moments': [12], 'in': [13, 144], 'time.': [14], 'We': [15, 44], 'use': [16], 'a': [17, 23], 'supervised': [18], 'learning': [19, 82, 172], 'paradigm': [20], 'derive': [22], 'synaptic': [24, 54, 117, 132], 'update': [25], 'rule': [26, 83], 'that': [27, 46, 85], 'optimizes': [28], 'by': [29], 'gradient': [30], 'ascent': [31], 'the': [32, 47, 58, 70, 75, 86, 94, 101, 125, 145], 'likelihood': [33], 'of': [34, 50, 93, 104, 129, 131, 152, 157, 164], 'postsynaptic': [35, 67, 77, 107, 153], 'firing': [36, 42], 'one': [38], 'or': [39], 'several': [40], 'desired': [41, 66, 76], 'times.': [43], 'find': [45], 'optimal': [48, 81], 'strategy': [49], 'up-': [51], 'and': [52, 65, 127, 155, 170], 'downregulating': [53], 'efficacies': [55, 133], 'depends': [56], 'on': [57, 96, 139], 'relative': [59], 'timing': [60, 98, 137], 'between': [61], 'presynaptic': [62, 71], 'spike': [63, 72, 78, 97, 121, 136], 'arrival': [64], 'firing.': [68], 'If': [69], 'arrives': [73], 'before': [74], 'timing,': [79], 'our': [80, 110, 165], 'predicts': [84], 'synapse': [87], 'should': [88], 'become': [89], 'potentiated.': [90], 'The': [91, 162], 'dependence': [92], 'potentiation': [95], 'directly': [99], 'reflects': [100], 'time': [102], 'course': [103], 'an': [105], 'excitatory': [106], 'potential.': [108], 'However,': [109], 'approach': [111], 'gives': [112], 'no': [113], 'unique': [114], 'reason': [115], 'for': [116, 134], 'depression': [118, 130], 'under': [119], 'reversed': [120, 135], 'timing.': [122], 'fact,': [124], 'presence': [126], 'amplitude': [128], 'depend': [138], 'how': [140], 'constraints': [141], 'are': [142, 160], 'implemented': [143], 'optimization': [146], 'problem.': [147], 'Two': [148], 'different': [149], 'constraints,': [150], 'control': [151, 156], 'rates': [154], 'temporal': [158], 'locality,': [159], 'studied.': [161], 'relation': [163], 'results': [166], 'spike-timing-dependent': [168], 'plasticity': [169], 'reinforcement': [171], 'is': [173], 'discussed.': [174]}",2006,"['Spike-timing-dependent plasticity', 'Postsynaptic potential', 'Spike (software development)', 'Excitatory postsynaptic potential', 'Neuroscience', 'Post-tetanic potentiation', 'Inhibitory postsynaptic potential', 'Computer science', 'Long-term potentiation', 'Synaptic weight', 'Reinforcement learning', 'Synapse', 'Synaptic plasticity', 'Learning rule', 'Artificial neural network', 'Artificial intelligence', 'Biology', 'Receptor', 'Biochemistry', 'Software engineering']","In timing-based neural codes, neurons have to emit action potentials at precise moments in time. We use a supervised learning paradigm to derive a synaptic update rule that optimizes by gradient ascent the likelihood of postsynaptic firing at one or several desired firing times. We find that the optimal strategy of up- and downregulating synaptic efficacies depends on the relative timing between presynaptic spike arrival and desired postsynaptic firing. If the presynaptic spike arrives before the desired postsynaptic spike timing, our optimal learning rule predicts that the synapse should become potentiated. The dependence of the potentiation on spike timing directly reflects the time course of an excitatory postsynaptic potential. However, our approach gives no unique reason for synaptic depression under reversed spike timing. In fact, the presence and amplitude of depression of synaptic efficacies for reversed spike timing depend on how constraints are implemented in the optimization problem. Two different constraints, control of postsynaptic rates and control of temporal locality, are studied. The relation of our results to spike-timing-dependent plasticity and reinforcement learning is discussed."
https://openalex.org/W2750606766,Self-supervised Learning of Motion Capture,"{'Current': [0], 'state-of-the-art': [1], 'solutions': [2, 225], 'for': [3, 82], 'motion': [4, 79], 'capture': [5, 59, 80], 'from': [6, 122, 127], 'a': [7, 18, 76, 108, 117, 208], 'single': [8, 83], 'camera': [9, 84], 'are': [10, 41], 'optimization': [11, 228], 'driven:': [12], 'they': [13], 'optimize': [14], 'the': [15, 29, 49, 153, 167, 171, 196, 199, 215], 'parameters': [16, 92, 169], 'of': [17, 87, 119, 130, 155, 158, 195], '3D': [19, 102, 136], 'human': [20], 'model': [21, 81, 95, 113, 151, 168, 197, 217], 'so': [22], 'that': [23, 51, 100, 214], 'its': [24], 're-projection': [25], 'matches': [26], 'measurements': [27], 'in': [28, 143, 170], 'video': [30], '(e.g.': [31], 'person': [32], 'segmentation,': [33, 142], 'optical': [34], 'flow,': [35], 'keypoint': [36], 'detections': [37], 'etc.).': [38], 'Optimization': [39], 'models': [40], 'susceptible': [42], 'to': [43, 65, 198, 223], 'local': [44], 'minima.': [45], 'This': [46], 'has': [47], 'been': [48], 'bottleneck': [50], 'forced': [52], 'using': [53, 116], 'clean': [54], 'green-screen': [55], 'like': [56], 'backgrounds': [57], 'at': [58, 180], 'time,': [60, 182], 'manual': [61, 184], 'initialization,': [62], 'or': [63], 'switching': [64], 'multiple': [66], 'cameras': [67], 'as': [68], 'input': [69], 'resource.': [70], 'In': [71], 'this': [72], 'work,': [73], 'we': [74, 148], 'propose': [75], 'learning': [77, 160, 165], 'based': [78], 'input.': [85], 'Instead': [86], 'optimizing': [88], 'mesh': [89, 137], 'and': [90, 104, 125, 139, 161, 177, 202, 221], 'skeleton': [91, 105], 'directly,': [93], 'our': [94, 150], 'optimizes': [96], 'neural': [97], 'network': [98], 'weights': [99], 'predict': [101], 'shape': [103], 'configurations': [106], 'given': [107], 'monocular': [109], 'RGB': [110], 'video.': [111], 'Our': [112], 'is': [114], 'trained': [115], 'combination': [118], 'strong': [120], 'supervision': [121], 'synthetic': [123], 'data,': [124, 201], 'self-supervision': [126], 'differentiable': [128, 190], 'rendering': [129, 191], '(a)': [131], 'skeletal': [132], 'keypoints,': [133], '(b)': [134], 'dense': [135], 'motion,': [138], '(c)': [140], 'human-background': [141], 'an': [144], 'end-to-end': [145], 'framework.': [146], 'Empirically': [147], 'show': [149, 213], 'combines': [152], 'best': [154], 'both': [156], 'worlds': [157], 'supervised': [159, 164], 'test-time': [162], 'optimization:': [163], 'initializes': [166], 'right': [172], 'regime,': [173], 'ensuring': [174], 'good': [175], 'pose': [176], 'surface': [178], 'initialization': [179], 'test': [181, 200], 'without': [183], 'effort.': [185], 'Self-supervision': [186], 'by': [187], 'back-propagating': [188], 'through': [189], 'allows': [192], '(unsupervised)': [193], 'adaptation': [194], 'offers': [203], 'much': [204], 'tighter': [205], 'fit': [206], 'than': [207], 'pretrained': [209], 'fixed': [210], 'model.': [211], 'We': [212], 'proposed': [216], 'improves': [218], 'with': [219], 'experience': [220], 'converges': [222], 'low-error': [224], 'where': [226], 'previous': [227], 'methods': [229], 'fail.': [230]}",2017,"['Motion (physics)', 'Motion capture', 'Computer science', 'Artificial intelligence', 'Machine learning']","Current state-of-the-art solutions for motion capture from a single camera are optimization driven: they optimize the parameters of a 3D human model so that its re-projection matches measurements in the video (e.g. person segmentation, optical flow, keypoint detections etc.). Optimization models are susceptible to local minima. This has been the bottleneck that forced using clean green-screen like backgrounds at capture time, manual initialization, or switching to multiple cameras as input resource. In this work, we propose a learning based motion capture model for single camera input. Instead of optimizing mesh and skeleton parameters directly, our model optimizes neural network weights that predict 3D shape and skeleton configurations given a monocular RGB video. Our model is trained using a combination of strong supervision from synthetic data, and self-supervision from differentiable rendering of (a) skeletal keypoints, (b) dense 3D mesh motion, and (c) human-background segmentation, in an end-to-end framework. Empirically we show our model combines the best of both worlds of supervised learning and test-time optimization: supervised learning initializes the model parameters in the right regime, ensuring good pose and surface initialization at test time, without manual effort. Self-supervision by back-propagating through differentiable rendering allows (unsupervised) adaptation of the model to the test data, and offers much tighter fit than a pretrained fixed model. We show that the proposed model improves with experience and converges to low-error solutions where previous optimization methods fail."
https://openalex.org/W2118670840,Nonparametric Transforms of Graph Kernels for Semi-Supervised Learning,"{'We': [0, 91], 'present': [1], 'an': [2], 'algorithm': [3], 'based': [4], 'on': [5, 77, 95], 'convex': [6], 'optimization': [7], 'for': [8, 11, 88], 'constructing': [9], 'kernels': [10, 41, 63, 94], 'semi-supervised': [12], 'learning.': [13], 'The': [14], 'kernel': [15, 49], 'matrices': [16], 'are': [17], 'derived': [18], 'from': [19], 'the': [20, 66, 93], 'spectral': [21], 'decomposition': [22], 'of': [23], 'graph': [24], 'Laplacians,': [25], 'and': [26, 29, 42, 64, 84], 'combine': [27], 'labeled': [28], 'unlabeled': [30], 'data': [31], 'in': [32, 61], 'a': [33, 47, 78], 'systematic': [34], 'fashion.': [35], 'Unlike': [36], 'previous': [37], 'work': [38], 'using': [39, 98], 'diffusion': [40], 'Gaussian': [43], 'random': [44], 'field': [45], 'kernels,': [46], 'nonparametric': [48], 'approach': [50, 75], 'is': [51, 85], 'presented': [52], 'that': [53], 'incorporates': [54], 'order': [55], 'constraints': [56], 'during': [57], 'optimization.': [58], 'This': [59], 'results': [60], 'flexible': [62], 'avoids': [65], 'need': [67], 'to': [68], 'choose': [69], 'among': [70], 'different': [71], 'parametric': [72], 'forms.': [73], 'Our': [74], 'relies': [76], 'quadratically': [79], 'constrained': [80], 'quadratic': [81], 'program': [82], '(QCQP),': [83], 'computationally': [86], 'feasible': [87], 'large': [89], 'datasets.': [90], 'evaluate': [92], 'real': [96], 'datasets': [97], 'support': [99], 'vector': [100], 'machines,': [101], 'with': [102], 'encouraging': [103], 'results.': [104]}",2018,"['Kernel (algebra)', 'Quadratic growth', 'Computer science', 'Nonparametric statistics', 'Graph', 'Quadratic programming', 'Support vector machine', 'Kernel method', 'Parametric statistics', 'Artificial intelligence', 'Graph kernel', 'Multiple kernel learning', 'Gaussian process', 'Quadratic equation', 'Polynomial kernel', 'Machine learning', 'Mathematics', 'Mathematical optimization', 'Gaussian', 'Algorithm', 'Theoretical computer science', 'Geometry', 'Statistics', 'Physics', 'Combinatorics', 'Quantum mechanics']","We present an algorithm based on convex optimization for constructing kernels for semi-supervised learning. The kernel matrices are derived from the spectral decomposition of graph Laplacians, and combine labeled and unlabeled data in a systematic fashion. Unlike previous work using diffusion kernels and Gaussian random field kernels, a nonparametric kernel approach is presented that incorporates order constraints during optimization. This results in flexible kernels and avoids the need to choose among different parametric forms. Our approach relies on a quadratically constrained quadratic program (QCQP), and is computationally feasible for large datasets. We evaluate the kernels on real datasets using support vector machines, with encouraging results."
https://openalex.org/W3039236647,Self‐supervised learning of physics‐guided reconstruction neural networks without fully sampled reference data,"{'Purpose': [0], 'To': [1], 'develop': [2], 'a': [3, 7, 14, 173], 'strategy': [4], 'for': [5, 28, 64, 105], 'training': [6, 68, 78, 114, 239], 'physics‐guided': [8, 29, 100, 241], 'MRI': [9, 244, 258], 'reconstruction': [10, 32, 206, 220, 245], 'neural': [11, 101], 'network': [12, 54, 102], 'without': [13, 69, 246], 'database': [15], 'of': [16, 41, 146, 195, 240], 'fully': [17, 70, 76, 247, 261], 'sampled': [18, 71, 248, 262], 'data': [19, 25, 47, 72, 124, 183], 'sets.': [20], 'Methods': [21], 'Self‐supervised': [22], 'learning': [23, 31, 188, 243, 257], 'via': [24], 'undersampling': [26], '(SSDU)': [27], 'deep': [30, 242, 256], 'partitions': [33], 'available': [34, 94], 'measurements': [35], 'into': [36], 'two': [37], 'disjoint': [38], 'sets,': [39, 184], 'one': [40], 'which': [42, 186], 'is': [43, 58, 73, 103, 115], 'used': [44, 59, 104, 191], 'in': [45, 51, 185], 'the': [46, 52, 56, 62, 92, 150, 200, 223], 'consistency': [48], '(DC)': [49], 'units': [50], 'unrolled': [53], 'and': [55, 87, 109, 130, 164, 172, 213], 'other': [57], 'to': [60, 118, 193], 'define': [61], 'loss': [63], 'training.': [65, 111], 'The': [66, 98, 112, 177, 234], 'proposed': [67, 107, 151, 201, 224, 235], 'compared': [74, 131, 226], 'with': [75, 79, 132, 156, 222, 227, 254], 'supervised': [77, 110, 157, 187, 255], 'ground‐truth': [80, 196], 'data,': [81, 249], 'as': [82, 84, 167], 'well': [83], 'conventional': [85, 162], 'compressed‐sensing': [86, 163], 'parallel': [88, 133, 165, 228], 'imaging': [89, 229], 'methods': [90], 'using': [91], 'publicly': [93], 'fastMRI': [95], 'knee': [96, 140], 'database.': [97], 'same': [99], 'both': [106], 'SSDU': [108, 113, 236], 'also': [116], 'applied': [117], 'prospectively': [119, 180], 'two‐fold': [120], 'accelerated': [121], 'high‐resolution': [122], 'brain': [123, 182], 'sets': [125], 'at': [126, 142, 207, 230], 'different': [127, 139], 'acceleration': [128, 144, 209], 'rates,': [129], 'imaging.': [134], 'Results': [135, 136], 'on': [137, 179, 260], 'five': [138], 'sequences': [141], 'an': [143], 'rate': [145], '4': [147], 'shows': [148], 'that': [149, 199], 'self‐supervised': [152, 202], 'approach': [153, 203, 225, 237], 'performs': [154, 205], 'closely': [155], 'learning,': [158], 'while': [159, 250], 'significantly': [160], 'outperforming': [161], 'imaging,': [166], 'characterized': [168], 'by': [169], 'quantitative': [170], 'metrics': [171], 'clinical': [174], 'reader': [175], 'study.': [176], 'results': [178, 253], 'subsampled': [181], 'cannot': [189], 'be': [190], 'due': [192], 'lack': [194], 'reference,': [197], 'show': [198], 'successfully': [204], 'high': [208], 'rates': [210], '(4,': [211], '6,': [212], '8).': [214], 'Image': [215], 'readings': [216], 'indicate': [217], 'improved': [218], 'visual': [219], 'quality': [221], 'acquisition': [231], 'acceleration.': [232], 'Conclusion': [233], 'allows': [238], 'achieving': [251], 'comparable': [252], 'trained': [259], 'data.': [263]}",2020,"['Undersampling', 'Compressed sensing', 'Computer science', 'Artificial intelligence', 'Data consistency', 'Ground truth', 'Artificial neural network', 'Acceleration', 'Consistency (knowledge bases)', 'Pattern recognition (psychology)', 'Disjoint sets', 'Supervised learning', 'Deep learning', 'Machine learning', 'Mathematics', 'Classical mechanics', 'Operating system', 'Combinatorics', 'Physics']","Purpose To develop a strategy for training a physics‐guided MRI reconstruction neural network without a database of fully sampled data sets. Methods Self‐supervised learning via data undersampling (SSDU) for physics‐guided deep learning reconstruction partitions available measurements into two disjoint sets, one of which is used in the data consistency (DC) units in the unrolled network and the other is used to define the loss for training. The proposed training without fully sampled data is compared with fully supervised training with ground‐truth data, as well as conventional compressed‐sensing and parallel imaging methods using the publicly available fastMRI knee database. The same physics‐guided neural network is used for both proposed SSDU and supervised training. The SSDU training is also applied to prospectively two‐fold accelerated high‐resolution brain data sets at different acceleration rates, and compared with parallel imaging. Results Results on five different knee sequences at an acceleration rate of 4 shows that the proposed self‐supervised approach performs closely with supervised learning, while significantly outperforming conventional compressed‐sensing and parallel imaging, as characterized by quantitative metrics and a clinical reader study. The results on prospectively subsampled brain data sets, in which supervised learning cannot be used due to lack of ground‐truth reference, show that the proposed self‐supervised approach successfully performs reconstruction at high acceleration rates (4, 6, and 8). Image readings indicate improved visual reconstruction quality with the proposed approach compared with parallel imaging at acquisition acceleration. Conclusion The proposed SSDU approach allows training of physics‐guided deep learning MRI reconstruction without fully sampled data, while achieving comparable results with supervised deep learning MRI trained on fully sampled data."
https://openalex.org/W2109405055,Efficient Non-Parametric Function Induction in Semi-Supervised Learning,"{'There': [0], 'has': [1], 'been': [2, 140, 147], 'an': [3, 38, 65], 'increase': [4], 'of': [5, 12, 19, 59, 74, 81, 103, 108, 129, 177], 'interest': [6], 'for': [7, 42, 91], 'semi-supervised': [8], 'learning': [9], 'recently,': [10], 'because': [11], 'the': [13, 43, 57, 72, 82, 89, 122, 127, 135, 143, 150, 169, 188], 'many': [14], 'datasets': [15], 'with': [16, 181], 'large': [17, 166], 'amounts': [18], 'unlabeled': [20, 45, 109, 151], 'examples': [21], 'and': [22, 68, 110, 186], 'only': [23, 174], 'a': [24, 60, 75, 92, 100, 131, 178], 'few': [25], 'labeled': [26, 111], 'ones.': [27], 'This': [28, 153], 'paper': [29], 'follows': [30], 'up': [31], 'on': [32], 'proposed': [33], 'non-parametric': [34], 'algorithms': [35, 53], 'which': [36, 114], 'provide': [37], 'estimated': [39], 'continuous': [40], 'label': [41, 90, 132], 'given': [44], 'examples.': [46], 'It': [47], 'extends': [48], 'them': [49], 'to': [50, 56, 64, 70, 97, 134, 167, 191], 'function': [51, 156], 'induction': [52, 157], 'that': [54, 85, 121, 137], 'correspond': [55], 'minimization': [58], 'regularization': [61], 'criterion': [62], 'applied': [63], 'out-of-sample': [66], 'example,': [67], 'happens': [69], 'have': [71, 139], 'form': [73], 'Parzen': [76], 'windows': [77], 'regressor.': [78], 'The': [79], 'advantage': [80], 'extension': [83, 123], 'is': [84, 165], 'it': [86, 173], 'allows': [87], 'predicting': [88, 130], 'new': [93], 'example': [94, 145], 'without': [95], 'having': [96], 'solve': [98], 'again': [99], 'linear': [101, 189], 'system': [102, 190], 'dimension': [104], 'n': [105, 164, 184], '(the': [106], 'number': [107], 'training': [112], 'examples),': [113], 'can': [115, 159], 'cost': [116], 'O(n': [117], '3).': [118], 'Experiments': [119], 'show': [120], 'works': [124], 'well,': [125], 'in': [126, 149, 175, 194], 'sense': [128], 'close': [133], 'one': [136], 'would': [138], 'obtained': [141], 'if': [142], 'test': [144], 'had': [146], 'included': [148], 'set.': [152], 'relatively': [154], 'efficient': [155], 'procedure': [158], 'also': [160], 'be': [161], 'used': [162], 'when': [163], 'approximate': [168], 'solution': [170], 'by': [171], 'writing': [172], 'terms': [176], 'kernel': [179], 'expansion': [180], 'm': [182, 192, 195], '≪': [183], 'terms,': [185], 'reducing': [187], 'equations': [193], 'unknowns.': [196], '1': [197]}",2004,"['Regularization (linguistics)', 'Dimension (graph theory)', 'Extension (predicate logic)', 'Kernel (algebra)', 'Mathematics', 'Semi-supervised learning', 'Parametric statistics', 'Computer science', 'Function (biology)', 'Minification', 'Algorithm', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Mathematical optimization', 'Discrete mathematics', 'Combinatorics', 'Statistics', 'Biology', 'Programming language', 'Evolutionary biology']","There has been an increase of interest for semi-supervised learning recently, because of the many datasets with large amounts of unlabeled examples and only a few labeled ones. This paper follows up on proposed non-parametric algorithms which provide an estimated continuous label for the given unlabeled examples. It extends them to function induction algorithms that correspond to the minimization of a regularization criterion applied to an out-of-sample example, and happens to have the form of a Parzen windows regressor. The advantage of the extension is that it allows predicting the label for a new example without having to solve again a linear system of dimension n (the number of unlabeled and labeled training examples), which can cost O(n 3). Experiments show that the extension works well, in the sense of predicting a label close to the one that would have been obtained if the test example had been included in the unlabeled set. This relatively efficient function induction procedure can also be used when n is large to approximate the solution by writing it only in terms of a kernel expansion with m ≪ n terms, and reducing the linear system to m equations in m unknowns. 1"
https://openalex.org/W2069735839,A discriminative model for semi-supervised learning,"{'Supervised': [0], 'learning—that': [1], 'is,': [2, 356], 'learning': [3, 136, 141, 147, 161, 335], 'from': [4, 302], 'labeled': [5, 83, 101, 111], 'examples—is': [6], 'an': [7, 168, 232, 408], 'area': [8], 'of': [9, 71, 110, 134, 171, 187, 234, 256, 270, 291, 298, 306, 329, 359, 362, 391], 'Machine': [10, 198], 'Learning': [11, 45, 199], 'that': [12, 106, 179, 258, 355, 380], 'has': [13, 18, 89], 'reached': [14], 'substantial': [15, 92], 'maturity.': [16], 'It': [17], 'generated': [19], 'general-purpose': [20], 'and': [21, 25, 32, 42, 79, 154, 210, 223, 293, 374, 399, 402], 'practically': [22], 'successful': [23], 'algorithms': [24, 336], 'the': [26, 39, 43, 69, 108, 139, 151, 155, 172, 188, 193, 197, 235, 261, 267, 289, 296, 299, 303, 323, 330, 345, 376, 388, 417, 422], 'foundations': [27], 'are': [28, 317, 379], 'quite': [29], 'well': [30], 'understood': [31], 'captured': [33], 'by': [34], 'theoretical': [35], 'frameworks': [36, 142], 'such': [37, 54], 'as': [38, 55, 231], 'PAC-learning': [40], 'model': [41, 174, 202, 227, 238], 'Statistical': [44], 'theory': [46], 'framework.': [47, 342], 'However,': [48], 'for': [49, 124, 143, 176, 207, 396, 411], 'many': [50, 186, 328], 'contemporary': [51], 'practical': [52], 'problems': [53], 'classifying': [56], 'web': [57], 'pages': [58], 'or': [59], 'detecting': [60], 'spam,': [61], 'there': [62, 88], 'is': [63, 75, 274], 'often': [64, 76], 'additional': [65], 'information': [66, 105], 'available': [67], 'in': [68, 94, 196, 216, 240, 278, 340, 352, 369], 'form': [70], 'unlabeled': [72, 97, 212], 'data,': [73], 'which': [74, 217], 'much': [77, 358], 'cheaper': [78], 'more': [80], 'plentiful': [81], 'than': [82], 'data.': [84, 271], 'As': [85, 325], 'a': [86, 116, 132, 204, 243, 251, 254], 'consequence,': [87], 'recently': [90], 'been': [91, 122], 'interest': [93], 'semi-supervised': [95, 177, 334], 'learning—using': [96], 'data': [98, 112, 213, 273, 363], 'together': [99], 'with': [100, 128, 266, 320, 413], 'data—since': [102], 'any': [103], 'useful': [104], 'reduces': [107], 'amount': [109], 'needed': [113], 'can': [114, 180, 214, 219, 228, 337], 'be': [115, 181, 229, 338], 'significant': [117], 'benefit.': [118], 'Several': [119], 'techniques': [120], 'have': [121, 265], 'developed': [123], 'doing': [125], 'this,': [126], 'along': [127], 'experimental': [129], 'results': [130, 406], 'on': [131], 'variety': [133], 'different': [135, 189], 'problems.': [137], 'Unfortunately,': [138], 'standard': [140, 236], 'reasoning': [144], 'about': [145, 185], 'supervised': [146], 'do': [148], 'not': [149], 'capture': [150], 'key': [152, 377], 'aspects': [153], 'assumptions': [156, 331], 'underlying': [157, 268, 332], 'these': [158, 381], 'semi': [159], '-supervised': [160], 'methods.': [162], 'In': [163], 'this': [164, 279, 341, 353], 'article,': [165], 'we': [166, 326, 347], 'describe': [167], 'augmented': [169], 'version': [170], 'PAC': [173, 237], 'designed': [175], 'learning,': [178], 'used': [182], 'to': [183, 242, 285, 294, 310, 314, 322, 367, 371, 393], 'reason': [184], 'approaches': [190], 'taken': [191], 'over': [192, 288], 'past': [194], 'decade': [195], 'community.': [200], 'This': [201], 'provides': [203], 'unified': [205], 'framework': [206], 'analyzing': [208], 'when': [209, 416], 'why': [211], 'help,': [215], 'one': [218, 248, 259, 284, 364], 'analyze': [220, 349], 'both': [221], 'sample-complexity': [222, 350], 'algorithmic': [224, 389, 405], 'issues.': [225], 'The': [226], 'viewed': [230], 'extension': [233], 'where,': [239], 'addition': [241], 'concept': [244, 263], 'class': [245], 'C': [246, 308], ',': [247], 'also': [249, 386], 'proposes': [250], 'compatibility': [252, 257, 287, 400], 'notion:': [253], 'type': [255, 361], 'believes': [260], 'target': [262], 'should': [264, 365], 'distribution': [269, 418], 'Unlabeled': [272], 'then': [275, 348], 'potentially': [276], 'helpful': [277], 'setting': [280], 'because': [281], 'it': [282], 'allows': [283], 'estimate': [286], 'space': [290, 301], 'hypotheses,': [292], 'reduce': [295], 'size': [297], 'search': [300], 'whole': [304], 'set': [305], 'hypotheses': [307], 'down': [309], 'those': [311], 'that,': [312], 'according': [313], ""one's"": [315], 'assumptions,': [316], 'a-priori': [318], 'reasonable': [319], 'respect': [321], 'distribution.': [324], 'show,': [327], 'existing': [333], 'formulated': [339], 'After': [343], 'proposing': [344], 'model,': [346], 'issues': [351], 'setting:': [354], 'how': [357, 392], 'each': [360], 'expect': [366], 'need': [368], 'order': [370], 'learn': [372], 'well,': [373], 'what': [375], 'quantities': [378], 'numbers': [382], 'depend': [383], 'on.': [384], 'We': [385], 'consider': [387], 'question': [390], 'efficiently': [394], 'optimize': [395], 'natural': [397], 'classes': [398], 'notions,': [401], 'provide': [403], 'several': [404], 'including': [407], 'improved': [409], 'bound': [410], 'Co-Training': [412], 'linear': [414], 'separators': [415], 'satisfies': [419], 'independence': [420], 'given': [421], 'label.': [423]}",2010,"['Machine learning', 'Computer science', 'Artificial intelligence', 'Semi-supervised learning', 'Algorithmic learning theory', 'Instance-based learning', 'Unsupervised learning', 'Supervised learning', 'Discriminative model', 'Online machine learning', 'Variety (cybernetics)', 'Computational learning theory', 'Class (philosophy)', 'Artificial neural network']","Supervised learning—that is, learning from labeled examples—is an area of Machine Learning that has reached substantial maturity. It has generated general-purpose and practically successful algorithms and the foundations are quite well understood and captured by theoretical frameworks such as the PAC-learning model and the Statistical Learning theory framework. However, for many contemporary practical problems such as classifying web pages or detecting spam, there is often additional information available in the form of unlabeled data, which is often much cheaper and more plentiful than labeled data. As a consequence, there has recently been substantial interest in semi-supervised learning—using unlabeled data together with labeled data—since any useful information that reduces the amount of labeled data needed can be a significant benefit. Several techniques have been developed for doing this, along with experimental results on a variety of different learning problems. Unfortunately, the standard learning frameworks for reasoning about supervised learning do not capture the key aspects and the assumptions underlying these semi -supervised learning methods. In this article, we describe an augmented version of the PAC model designed for semi-supervised learning, that can be used to reason about many of the different approaches taken over the past decade in the Machine Learning community. This model provides a unified framework for analyzing when and why unlabeled data can help, in which one can analyze both sample-complexity and algorithmic issues. The model can be viewed as an extension of the standard PAC model where, in addition to a concept class C , one also proposes a compatibility notion: a type of compatibility that one believes the target concept should have with the underlying distribution of data. Unlabeled data is then potentially helpful in this setting because it allows one to estimate compatibility over the space of hypotheses, and to reduce the size of the search space from the whole set of hypotheses C down to those that, according to one's assumptions, are a-priori reasonable with respect to the distribution. As we show, many of the assumptions underlying existing semi-supervised learning algorithms can be formulated in this framework. After proposing the model, we then analyze sample-complexity issues in this setting: that is, how much of each type of data one should expect to need in order to learn well, and what the key quantities are that these numbers depend on. We also consider the algorithmic question of how to efficiently optimize for natural classes and compatibility notions, and provide several algorithmic results including an improved bound for Co-Training with linear separators when the distribution satisfies independence given the label."
https://openalex.org/W2921087533,Interpolation Consistency Training for Semi-supervised Learning,"{'We': [0], 'introduce': [1], 'Interpolation': [2], 'Consistency': [3], 'Training': [4], '(ICT),': [5], 'a': [6], 'simple': [7], 'and': [8, 77], 'computation': [9], 'efficient': [10], 'algorithm': [11], 'for': [12], 'training': [13], 'Deep': [14], 'Neural': [15], 'Networks': [16], 'in': [17], 'the': [18, 24, 36, 39, 49, 56, 75], 'semi-supervised': [19], 'learning': [20], 'paradigm.': [21], 'ICT': [22, 47, 63], 'encourages': [23], 'prediction': [25], 'at': [26, 41], 'an': [27], 'interpolation': [28, 37], 'of': [29, 38, 55], 'unlabeled': [30], 'points': [31], 'to': [32, 52, 69], 'be': [33], 'consistent': [34], 'with': [35], 'predictions': [40], 'those': [42], 'points.': [43], 'In': [44], 'classification': [45], 'problems,': [46], 'moves': [48], 'decision': [50], 'boundary': [51], 'low-density': [53], 'regions': [54], 'data': [57], 'distribution.': [58], 'Our': [59], 'experiments': [60], 'show': [61], 'that': [62], 'achieves': [64], 'state-of-the-art': [65], 'performance': [66], 'when': [67], 'applied': [68], 'standard': [70], 'neural': [71], 'network': [72], 'architectures': [73], 'on': [74], 'CIFAR-10': [76], 'SVHN': [78], 'benchmark': [79], 'dataset.': [80]}",2019,"['Overfitting', 'Computer science', 'Interpolation (computer graphics)', 'Regularization (linguistics)', 'Benchmark (surveying)', 'Machine learning', 'Artificial intelligence', 'Artificial neural network', 'Consistency (knowledge bases)', 'Extrapolation', 'Mathematics', 'Statistics', 'Motion (physics)', 'Geodesy', 'Geography']","We introduce Interpolation Consistency Training (ICT), a simple and computation efficient algorithm for training Deep Neural Networks in the semi-supervised learning paradigm. ICT encourages the prediction at an interpolation of unlabeled points to be consistent with the interpolation of the predictions at those points. In classification problems, ICT moves the decision boundary to low-density regions of the data distribution. Our experiments show that ICT achieves state-of-the-art performance when applied to standard neural network architectures on the CIFAR-10 and SVHN benchmark dataset."
https://openalex.org/W2996383576,vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations,"{'We': [0], 'propose': [1], 'vq-wav2vec': [2], 'to': [3, 28], 'learn': [4], 'discrete': [5, 46], 'representations': [6], 'of': [7, 38, 57], 'audio': [8], 'segments': [9], 'through': [10], 'a': [11, 21, 54], 'wav2vec-style': [12], 'self-supervised': [13], 'context': [14], 'prediction': [15], 'task.': [16], 'The': [17], 'algorithm': [18], 'uses': [19], 'either': [20], 'gumbel': [22], 'softmax': [23], 'or': [24], 'online': [25], 'k-means': [26], 'clustering': [27], 'quantize': [29], 'the': [30, 35, 41, 58], 'dense': [31], 'representations.': [32], 'Discretization': [33], 'enables': [34], 'direct': [36], 'application': [37], 'algorithms': [39], 'from': [40], 'NLP': [42], 'community': [43], 'which': [44], 'require': [45], 'inputs.': [47], 'Experiments': [48], 'show': [49], 'that': [50], 'BERT': [51], 'pre-training': [52], 'achieves': [53], 'new': [55], 'state': [56], 'art': [59], 'on': [60], 'TIMIT': [61], 'phoneme': [62], 'classification': [63], 'and': [64], 'WSJ': [65], 'speech': [66], 'recognition.': [67]}",2020,"['TIMIT', 'Computer science', 'Softmax function', 'Speech recognition', 'Artificial intelligence', 'Cluster analysis', 'Context (archaeology)', 'Task (project management)', 'Pattern recognition (psychology)', 'Discretization', 'Hidden Markov model', 'Natural language processing', 'Artificial neural network', 'Mathematics', 'Mathematical analysis', 'Economics', 'Management', 'Biology', 'Paleontology']",We propose vq-wav2vec to learn discrete representations of audio segments through a wav2vec-style self-supervised context prediction task. The algorithm uses either a gumbel softmax or online k-means clustering to quantize the dense representations. Discretization enables the direct application of algorithms from the NLP community which require discrete inputs. Experiments show that BERT pre-training achieves a new state of the art on TIMIT phoneme classification and WSJ speech recognition.
https://openalex.org/W2016707451,SybilBelief: A Semi-Supervised Learning Approach for Structure-Based Sybil Detection,"{'Sybil': [0, 25, 46, 60, 87, 128, 158, 183, 194, 202], 'attacks': [1], 'are': [2], 'a': [3, 16, 81, 91, 100, 109], 'fundamental': [4], 'threat': [5], 'to': [6, 23, 49, 71, 85, 130, 155, 173], 'the': [7, 28, 95, 98, 120, 124, 131, 135], 'security': [8], 'of': [9, 94, 103, 112, 189], 'distributed': [10], 'systems.': [11], 'Recently,': [12], 'there': [13], 'has': [14], 'been': [15], 'growing': [17], 'interest': [18], 'in': [19, 52, 97, 134, 175], 'leveraging': [20], 'social': [21, 92, 146], 'networks': [22], 'mitigate': [24], 'attacks.': [26], 'However,': [27], 'existing': [29, 193, 201], 'approaches': [30], 'suffer': [31], 'from': [32, 39, 123], 'one': [33], 'or': [34, 44, 59], 'more': [35], 'drawbacks,': [36], 'including': [37], 'bootstrapping': [38], 'either': [40], 'only': [41], 'known': [42, 45, 57, 104, 113, 125, 180], 'benign': [43, 58, 105, 126, 181], 'nodes,': [47, 61, 106], 'failing': [48], 'tolerate': [50], 'noise': [51, 174], 'their': [53], 'prior': [54, 177], 'knowledge': [55, 178], 'about': [56, 179], 'and': [62, 143, 165, 182, 197], 'being': [63], 'not': [64], 'scalable.': [65], 'In': [66], 'this': [67, 76], 'work,': [68], 'we': [69, 78], 'aim': [70], 'overcome': [72], 'these': [73], 'drawbacks.': [74], 'Towards': [75], 'goal,': [77], 'introduce': [79], 'SybilBelief,': [80], 'semi-supervised': [82], 'learning': [83], 'framework,': [84], 'detect': [86], 'nodes.': [88, 184], 'SybilBelief': [89, 118, 139, 152, 170, 186], 'takes': [90], 'network': [93, 147], 'nodes': [96, 129, 133, 159], 'system,': [99], 'small': [101, 110], 'set': [102, 111], 'and,': [107], 'optionally,': [108], 'Sybils': [114], 'as': [115], 'input.': [116], 'Then': [117], 'propagates': [119], 'label': [121], 'information': [122], 'and/or': [127], 'remaining': [132], 'system.': [136], 'We': [137, 149], 'evaluate': [138], 'using': [140], 'both': [141], 'synthetic': [142], 'real': [144], 'world': [145], 'topologies.': [148], 'show': [150], 'that': [151], 'is': [153, 171], 'able': [154], 'accurately': [156], 'identify': [157], 'with': [160], 'low': [161, 166], 'false': [162, 167], 'positive': [163], 'rates': [164], 'negative': [168], 'rates.': [169], 'resilient': [172], 'our': [176], 'Moreover,': [185], 'performs': [187], 'orders': [188], 'magnitudes': [190], 'better': [191, 199], 'than': [192, 200], 'classification': [195], 'mechanisms': [196], 'significantly': [198], 'ranking': [203], 'mechanisms.': [204]}",2014,"['Computer science', 'Sybil attack', 'Artificial intelligence', 'Machine learning', 'Computer network', 'Wireless sensor network']","Sybil attacks are a fundamental threat to the security of distributed systems. Recently, there has been a growing interest in leveraging social networks to mitigate Sybil attacks. However, the existing approaches suffer from one or more drawbacks, including bootstrapping from either only known benign or known Sybil nodes, failing to tolerate noise in their prior knowledge about known benign or Sybil nodes, and being not scalable. In this work, we aim to overcome these drawbacks. Towards this goal, we introduce SybilBelief, a semi-supervised learning framework, to detect Sybil nodes. SybilBelief takes a social network of the nodes in the system, a small set of known benign nodes, and, optionally, a small set of known Sybils as input. Then SybilBelief propagates the label information from the known benign and/or Sybil nodes to the remaining nodes in the system. We evaluate SybilBelief using both synthetic and real world social network topologies. We show that SybilBelief is able to accurately identify Sybil nodes with low false positive rates and low false negative rates. SybilBelief is resilient to noise in our prior knowledge about known benign and Sybil nodes. Moreover, SybilBelief performs orders of magnitudes better than existing Sybil classification mechanisms and significantly better than existing Sybil ranking mechanisms."
https://openalex.org/W2786541991,Multimodal Generative Models for Scalable Weakly-Supervised Learning,"{'Multiple': [0], 'modalities': [1, 14], 'often': [2], 'co-occur': [3], 'when': [4], 'describing': [5], 'natural': [6], 'phenomena.': [7], 'Learning': [8], 'a': [9, 32, 46, 53, 58, 130], 'joint': [10, 33], 'representation': [11], 'of': [12, 79, 123, 132, 137, 150], 'these': [13], 'should': [15], 'yield': [16], 'deeper': [17], 'and': [18, 57, 89, 110], 'more': [19], 'useful': [20], 'representations.': [21], 'Previous': [22], 'generative': [23], 'approaches': [24], 'to': [25, 39, 62, 73, 107, 113], 'multi-modal': [26, 65], 'input': [27], 'either': [28], 'do': [29], 'not': [30], 'learn': [31, 75], 'distribution': [34], 'or': [35], 'require': [36], 'additional': [37], 'computation': [38], 'handle': [40], 'missing': [41, 80], 'data.': [42], 'Here,': [43], 'we': [44, 99], 'introduce': [45], 'multimodal': [47], 'variational': [48], 'autoencoder': [49], '(MVAE)': [50], 'that': [51, 101], 'uses': [52], 'product-of-experts': [54], 'inference': [55, 66], 'network': [56], 'sub-sampled': [59], 'training': [60], 'paradigm': [61], 'solve': [63], 'the': [64, 84, 102], 'problem.': [67], 'Notably,': [68], 'our': [69], 'model': [70], 'shares': [71], 'parameters': [72], 'efficiently': [74], 'under': [76], 'any': [77], 'combination': [78], 'modalities.': [81], 'We': [82, 116, 143], 'apply': [83], 'MVAE': [85, 103], 'on': [86], 'four': [87], 'datasets': [88], 'match': [90], 'state-of-the-art': [91], 'performance': [92], 'using': [93], 'many': [94], 'fewer': [95], 'parameters.': [96], 'In': [97], 'addition,': [98], 'show': [100], 'is': [104, 111], 'directly': [105], 'applicable': [106], 'weakly-supervised': [108], 'learning,': [109], 'robust': [112], 'incomplete': [114], 'supervision.': [115], 'then': [117], 'consider': [118], 'two': [119, 141], 'case': [120], 'studies,': [121], 'one': [122, 136], 'learning': [124], 'image': [125], 'transformations---edge': [126], 'detection,': [127], 'colorization,': [128], 'segmentation---as': [129], 'set': [131], 'modalities,': [133], 'followed': [134], 'by': [135], 'machine': [138], 'translation': [139], 'between': [140], 'languages.': [142], 'find': [144], 'appealing': [145], 'results': [146], 'across': [147], 'this': [148], 'range': [149], 'tasks.': [151]}",2018,"['Computer science', 'Modalities', 'Artificial intelligence', 'Autoencoder', 'Machine learning', 'Multimodal learning', 'Inference', 'Generative grammar', 'Representation (politics)', 'Generative model', 'Modal', 'Scalability', 'Deep learning', 'Political science', 'Database', 'Chemistry', 'Polymer chemistry', 'Politics', 'Sociology', 'Law', 'Social science']","Multiple modalities often co-occur when describing natural phenomena. Learning a joint representation of these modalities should yield deeper and more useful representations. Previous generative approaches to multi-modal input either do not learn a joint distribution or require additional computation to handle missing data. Here, we introduce a multimodal variational autoencoder (MVAE) that uses a product-of-experts inference network and a sub-sampled training paradigm to solve the multi-modal inference problem. Notably, our model shares parameters to efficiently learn under any combination of missing modalities. We apply the MVAE on four datasets and match state-of-the-art performance using many fewer parameters. In addition, we show that the MVAE is directly applicable to weakly-supervised learning, and is robust to incomplete supervision. We then consider two case studies, one of learning image transformations---edge detection, colorization, segmentation---as a set of modalities, followed by one of machine translation between two languages. We find appealing results across this range of tasks."
https://openalex.org/W2769857323,Improvements to Context Based Self-Supervised Learning,"{'We': [0, 15, 51, 101, 119], 'develop': [1], 'a': [2, 18], 'set': [3], 'of': [4, 11, 20, 69, 108], 'methods': [5, 30, 71], 'to': [6, 111, 127], 'improve': [7], 'on': [8, 56, 75, 83, 88, 94, 115, 123], 'the': [9, 95], 'results': [10, 68, 122], 'self-supervised\\nlearning': [12], 'using': [13, 62], 'context.': [14], 'start': [16], 'with': [17, 54], 'baseline': [19, 106], 'patch': [21], 'based': [22], 'arrangement\\ncontext': [23], 'learning': [24], 'and': [25, 47, 92, 97, 136], 'go': [26], 'from': [27], 'there.': [28], 'Our': [29], 'address': [31], 'some': [32], 'overt': [33], 'problems\\nsuch': [34], 'as': [35, 38, 40, 130, 132], 'chromatic': [36], 'aberration': [37], 'well': [39, 131], 'other': [41], 'potential': [42], 'problems': [43, 53], 'such': [44], 'as\\nspatial': [45], 'skew': [46], 'mid-level': [48], 'feature': [49], 'neglect.': [50], 'prevent': [52], 'testing\\ngeneralization': [55], 'common': [57], 'self-supervised': [58, 78], 'benchmark': [59], 'tests': [60], 'by': [61], 'different\\ndatasets': [63], 'during': [64], 'our': [65, 70], 'development.': [66], 'The': [67], 'combined': [72], 'yield': [73], 'top\\nscores': [74], 'all': [76], 'standard': [77], 'benchmarks,': [79], 'including': [80], 'classification': [81, 117], 'and\\ndetection': [82], 'PASCAL': [84, 89], 'VOC': [85, 90], '2007,': [86], 'segmentation': [87], '2012,': [91], '""linear\\ntests""': [93], 'ImageNet': [96], 'CSAIL': [98], 'Places': [99], 'datasets.': [100], 'obtain': [102], 'an': [103], 'improvement': [104], 'over\\nour': [105], 'method': [107], 'between': [109], '4.0': [110], '7.1': [112], 'percentage': [113], 'points': [114], 'transfer\\nlearning': [116], 'tests.': [118], 'also': [120], 'show': [121], 'different': [124], 'standard\\nnetwork': [125], 'architectures': [126], 'demonstrate': [128], 'generalization': [129], 'portability.': [133], 'All\\ndata,': [134], 'models': [135], 'programs': [137], 'are': [138], 'available': [139], 'at:\\nhttps://gdo-datasci.llnl.gov/selfsupervised/.\\n': [140]}",2018,"['Pascal (unit)', 'Computer science', 'Machine learning', 'Artificial intelligence', 'Software portability', 'Skew', 'Discriminative model', 'Generalization', 'Context (archaeology)', 'Pattern recognition (psychology)', 'Mathematics', 'Telecommunications', 'Paleontology', 'Mathematical analysis', 'Programming language', 'Biology']","We develop a set of methods to improve on the results of self-supervised\nlearning using context. We start with a baseline of patch based arrangement\ncontext learning and go from there. Our methods address some overt problems\nsuch as chromatic aberration as well as other potential problems such as\nspatial skew and mid-level feature neglect. We prevent problems with testing\ngeneralization on common self-supervised benchmark tests by using different\ndatasets during our development. The results of our methods combined yield top\nscores on all standard self-supervised benchmarks, including classification and\ndetection on PASCAL VOC 2007, segmentation on PASCAL VOC 2012, and ""linear\ntests"" on the ImageNet and CSAIL Places datasets. We obtain an improvement over\nour baseline method of between 4.0 to 7.1 percentage points on transfer\nlearning classification tests. We also show results on different standard\nnetwork architectures to demonstrate generalization as well as portability. All\ndata, models and programs are available at:\nhttps://gdo-datasci.llnl.gov/selfsupervised/.\n"
https://openalex.org/W2989700832,ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentation Anchoring,"{'We': [0, 148], 'improve': [1], 'the': [2, 21, 33, 50, 60, 67, 82, 86, 112], 'recently-proposed': [3], '""MixMatch""': [4], 'semi-supervised': [5], 'learning': [6], 'algorithm': [7], 'by': [8], 'introducing': [9], 'two': [10], 'new': [11, 92], 'techniques:': [12], 'distribution': [13, 23, 35], 'alignment': [14, 19], 'and': [15, 52, 106, 136, 152], 'augmentation': [16, 83], 'anchoring.': [17], 'Distribution': [18], 'encourages': [20, 53], 'marginal': [22, 34], 'of': [24, 36, 46, 66, 78, 131, 140], 'predictions': [25], 'on': [26, 117], 'unlabeled': [27], 'data': [28, 109, 153], 'to': [29, 32, 56, 59, 110, 128], 'be': [30, 57], 'close': [31, 58], 'ground-truth': [37], 'labels.': [38], 'Augmentation': [39], 'anchoring': [40], 'feeds': [41], 'multiple': [42], 'strongly': [43], 'augmented': [44], 'versions': [45], 'an': [47], 'input': [48], 'into': [49], 'model': [51, 87], 'each': [54], 'output': [55], 'prediction': [61], 'for': [62], 'a': [63, 76, 137], 'weakly-augmented': [64], 'version': [65], 'same': [68, 113], 'input.': [69], 'To': [70], 'produce': [71], 'strong': [72], 'augmentations,': [73], 'we': [74, 123], 'propose': [75], 'variant': [77], 'AutoAugment': [79], 'which': [80], 'learns': [81], 'policy': [84], 'while': [85], 'is': [88, 96], 'being': [89], 'trained.': [90], 'Our': [91], 'algorithm,': [93], 'dubbed': [94], 'ReMixMatch,': [95], 'significantly': [97], 'more': [98], 'data-efficient': [99], 'than': [100], 'prior': [101], 'work,': [102], 'requiring': [103], 'between': [104], '$5\\times$': [105], '$16\\times$': [107], 'less': [108], 'reach': [111, 124], 'accuracy.': [114], 'For': [115], 'example,': [116], 'CIFAR-10': [118], 'with': [119, 133, 142], '250': [120], 'labeled': [121], 'examples': [122], '$93.73\\%$': [125], 'accuracy': [126, 130, 139], '(compared': [127], ""MixMatch's"": [129], '$93.58\\%$': [132], '$4{,}000$': [134], 'examples)': [135], 'median': [138], '$84.92\\%$': [141], 'just': [143], 'four': [144], 'labels': [145], 'per': [146], 'class.': [147], 'make': [149], 'our': [150], 'code': [151], 'open-source': [154], 'at': [155], 'https://github.com/google-research/remixmatch.': [156]}",2019,"['Anchoring', 'Computer science', 'Code (set theory)', 'Ground truth', 'Artificial intelligence', 'Class (philosophy)', 'Distribution (mathematics)', 'Labeled data', 'Pattern recognition (psychology)', 'Algorithm', 'Machine learning', 'Mathematics', 'Set (abstract data type)', 'Psychology', 'Mathematical analysis', 'Social psychology', 'Programming language']","We improve the recently-proposed ""MixMatch"" semi-supervised learning algorithm by introducing two new techniques: distribution alignment and augmentation anchoring. Distribution alignment encourages the marginal distribution of predictions on unlabeled data to be close to the marginal distribution of ground-truth labels. Augmentation anchoring feeds multiple strongly augmented versions of an input into the model and encourages each output to be close to the prediction for a weakly-augmented version of the same input. To produce strong augmentations, we propose a variant of AutoAugment which learns the augmentation policy while the model is being trained. Our new algorithm, dubbed ReMixMatch, is significantly more data-efficient than prior work, requiring between $5\times$ and $16\times$ less data to reach the same accuracy. For example, on CIFAR-10 with 250 labeled examples we reach $93.73\%$ accuracy (compared to MixMatch's accuracy of $93.58\%$ with $4{,}000$ examples) and a median accuracy of $84.92\%$ with just four labels per class. We make our code and data open-source at https://github.com/google-research/remixmatch."
https://openalex.org/W2911135784,Qoala-T: A supervised-learning tool for quality control of FreeSurfer segmented MRI data,"{'Performing': [0], 'quality': [1, 32, 49, 66, 77, 113, 123, 149, 170, 197, 227, 250, 258], 'control': [2, 50, 67, 114], 'to': [3, 73, 101, 105, 146, 167, 193, 219, 232, 244, 248], 'detect': [4], 'image': [5], 'artifacts': [6], 'and': [7, 44, 70, 79, 99, 109, 175], 'data-processing': [8], 'errors': [9], 'is': [10, 51, 68, 96, 165], 'crucial': [11], 'in': [12, 18, 111, 132, 136], 'structural': [13], 'magnetic': [14], 'resonance': [15], 'imaging,': [16], 'especially': [17], 'developmental': [19], 'studies.': [20, 260], 'Currently,': [21], 'many': [22], 'studies': [23], 'rely': [24], 'on': [25], 'visual': [26], 'inspection': [27], 'by': [28], 'trained': [29], 'raters': [30], 'for': [31], 'control.': [33], 'The': [34], 'subjectivity': [35], 'of': [36, 64, 75, 81, 83, 124, 198, 209, 256], 'these': [37], 'manual': [38, 65, 112, 148, 249], 'procedures': [39, 115], 'lessens': [40], 'comparability': [41, 255], 'between': [42, 259], 'studies,': [43], 'with': [45, 171], 'growing': [46], 'study': [47, 89], 'sizes': [48], 'increasingly': [52], 'time': [53], 'consuming.': [54], 'In': [55, 86, 185], 'addition,': [56, 186], 'both': [57, 172], 'inter-rater': [58], 'as': [59, 61], 'well': [60], 'intra-rater': [62], 'variability': [63, 246], 'high': [69, 173], 'may': [71], 'lead': [72], 'inclusion': [74], 'poor': [76], 'scans': [78, 82, 130], 'exclusion': [80], 'usable': [84], 'quality.': [85], 'the': [87, 92, 159, 180, 187, 196, 254], 'current': [88], 'we': [90, 120], 'present': [91], 'Qoala-T': [93, 160, 188], 'tool,': [94], 'which': [95], 'an': [97], 'easy': [98], 'free': [100], 'use': [102], 'supervised-learning': [103, 141], 'model': [104], 'reduce': [106, 245], 'rater': [107], 'bias': [108], 'misclassification': [110], 'using': [116, 151, 162], 'FreeSurfer-processed': [117, 128], 'scans.': [118], 'First,': [119], 'manually': [121], 'rated': [122], 'N': [125, 204], '=': [126, 183, 205], '784': [127], 'T1-weighted': [129], 'acquired': [131], 'three': [133], 'different': [134], 'waves': [135], 'a': [137], 'longitudinal': [138], 'study.': [139], 'Different': [140], 'models': [142], 'were': [143, 216], 'then': [144], 'compared': [145], 'predict': [147, 168, 195], 'ratings': [150], 'FreeSurfer': [152], 'segmented': [153], 'output': [154], 'data.': [155], 'Results': [156], 'show': [157], 'that': [158, 213, 225, 238], 'tool': [161, 189], 'random': [163], 'forests': [164], 'able': [166, 192], 'scan': [169, 222, 226], 'sensitivity': [174], 'specificity': [176], '(mean': [177], 'area': [178], 'under': [179], 'curve': [181], '(AUC)': [182], '0.98).': [184], 'was': [190], 'also': [191], 'adequately': [194], 'two': [199], 'novel': [200], 'unseen': [201], 'datasets': [202], '(total': [203], '872).': [206], 'Finally,': [207], 'analyses': [208], 'age': [210, 233], 'effects': [211], 'showed': [212], 'younger': [214], 'participants': [215], 'more': [217], 'likely': [218], 'have': [220], 'lower': [221], 'quality,': [223], 'underlining': [224], 'might': [228], 'confound': [229], 'findings': [230], 'attributed': [231], 'effects.': [234], 'These': [235], 'outcomes': [236], 'indicate': [237], 'this': [239], 'procedure': [240], 'could': [241], 'further': [242], 'help': [243], 'related': [247], 'control,': [251], 'thereby': [252], 'benefiting': [253], 'data': [257]}",2019,"['Artificial intelligence', 'Quality (philosophy)', 'Computer science', 'Machine learning', 'Random forest', 'Quality Score', 'Comparability', 'Image quality', 'Data quality', 'Control (management)', 'Pattern recognition (psychology)', 'Mathematics', 'Engineering', 'Image (mathematics)', 'Philosophy', 'Epistemology', 'Combinatorics', 'Operations management', 'Metric (unit)']","Performing quality control to detect image artifacts and data-processing errors is crucial in structural magnetic resonance imaging, especially in developmental studies. Currently, many studies rely on visual inspection by trained raters for quality control. The subjectivity of these manual procedures lessens comparability between studies, and with growing study sizes quality control is increasingly time consuming. In addition, both inter-rater as well as intra-rater variability of manual quality control is high and may lead to inclusion of poor quality scans and exclusion of scans of usable quality. In the current study we present the Qoala-T tool, which is an easy and free to use supervised-learning model to reduce rater bias and misclassification in manual quality control procedures using FreeSurfer-processed scans. First, we manually rated quality of N = 784 FreeSurfer-processed T1-weighted scans acquired in three different waves in a longitudinal study. Different supervised-learning models were then compared to predict manual quality ratings using FreeSurfer segmented output data. Results show that the Qoala-T tool using random forests is able to predict scan quality with both high sensitivity and specificity (mean area under the curve (AUC) = 0.98). In addition, the Qoala-T tool was also able to adequately predict the quality of two novel unseen datasets (total N = 872). Finally, analyses of age effects showed that younger participants were more likely to have lower scan quality, underlining that scan quality might confound findings attributed to age effects. These outcomes indicate that this procedure could further help to reduce variability related to manual quality control, thereby benefiting the comparability of data quality between studies."
https://openalex.org/W2997212544,Self-Supervised Learning for Generalizable Out-of-Distribution Detection,"{'The': [0], 'real-world': [1], 'deployment': [2], 'of': [3, 20, 24, 70, 118], 'Deep': [4], 'Neural': [5], 'Networks': [6], '(DNNs)': [7], 'in': [8, 35], 'safety-critical': [9], 'applications': [10], 'such': [11], 'as': [12], 'autonomous': [13], 'vehicles': [14], 'needs': [15], 'to': [16, 66, 80, 93], 'address': [17], 'a': [18, 41], 'variety': [19], ""DNNs'"": [21], 'vulnerabilities,': [22], 'one': [23], 'which': [25], 'being': [26], 'detecting': [27], 'and': [28, 53, 74, 89], 'rejecting': [29, 54, 113], 'out-of-distribution': [30, 49], 'outliers': [31], 'that': [32, 104], 'might': [33], 'result': [34], 'unpredictable': [36], 'fatal': [37], 'errors.': [38], 'We': [39, 83], 'propose': [40], 'new': [42], 'technique': [43, 62, 92], 'relying': [44], 'on': [45], 'self-supervision': [46], 'for': [47], 'generalizable': [48], '(OOD)': [50], 'feature': [51], 'learning': [52], 'those': [55], 'samples': [56, 73, 114], 'at': [57], 'the': [58, 68, 116, 119], 'inference': [59], 'time.': [60], 'Our': [61], 'does': [63], 'not': [64], 'need': [65], 'pre-know': [67], 'distribution': [69], 'targeted': [71], 'OOD': [72, 98], 'incur': [75], 'no': [76], 'extra': [77], 'overheads': [78], 'compared': [79], 'other': [81], 'methods.': [82, 100], 'perform': [84, 94], 'multiple': [85], 'image': [86], 'classification': [87, 110], 'experiments': [88], 'observe': [90], 'our': [91, 105], 'favorably': [95], 'against': [96], 'state-of-the-art': [97], 'detection': [99], 'Interestingly,': [101], 'we': [102], 'witness': [103], 'method': [106], 'also': [107], 'reduces': [108], 'in-distribution': [109], 'risk': [111], 'via': [112], 'near': [115], 'boundaries': [117], 'training': [120], 'set': [121], 'distribution.': [122]}",2020,"['Computer science', 'Artificial intelligence', 'Software deployment', 'Inference', 'Outlier', 'Machine learning', 'Variety (cybernetics)', 'Feature (linguistics)', 'Anomaly detection', 'Deep learning', 'Set (abstract data type)', 'Witness', 'Pattern recognition (psychology)', 'Philosophy', 'Operating system', 'Linguistics', 'Programming language']","The real-world deployment of Deep Neural Networks (DNNs) in safety-critical applications such as autonomous vehicles needs to address a variety of DNNs' vulnerabilities, one of which being detecting and rejecting out-of-distribution outliers that might result in unpredictable fatal errors. We propose a new technique relying on self-supervision for generalizable out-of-distribution (OOD) feature learning and rejecting those samples at the inference time. Our technique does not need to pre-know the distribution of targeted OOD samples and incur no extra overheads compared to other methods. We perform multiple image classification experiments and observe our technique to perform favorably against state-of-the-art OOD detection methods. Interestingly, we witness that our method also reduces in-distribution classification risk via rejecting samples near the boundaries of the training set distribution."
https://openalex.org/W1506622324,Multi-Manifold Semi-Supervised Learning,"{'We': [0, 12, 31], 'study': [1], 'semi-supervised': [2, 35, 72], 'learning': [3, 36, 48, 73], 'when': [4], 'the': [5, 20, 67], 'data': [6, 26], 'consists': [7], 'of': [8, 23, 58, 69], 'multiple': [9], 'intersecting': [10], 'manifolds.': [11], 'give': [13], 'a': [14, 34, 55], 'finite': [15], 'sample': [16], 'analysis': [17], 'to': [18], 'quantify': [19], 'potential': [21], 'gain': [22], 'using': [24], 'unlabeled': [25], 'in': [27], 'this': [28], 'multi-manifold': [29, 71], 'setting.': [30], 'then': [32], 'propose': [33], 'algorithm': [37, 53], 'that': [38], 'separates': [39], 'different': [40], 'manifolds': [41], 'into': [42], 'decision': [43], 'sets,': [44], 'and': [45, 61], 'performs': [46], 'supervised': [47], 'within': [49], 'each': [50], 'set.': [51], 'Our': [52], 'involves': [54], 'novel': [56], 'application': [57], 'Hellinger': [59], 'distance': [60], 'size-constrained': [62], 'spectral': [63], 'clustering.': [64], 'Experiments': [65], 'demonstrate': [66], 'benefit': [68], 'our': [70], 'approach': [74]}",2009,"['Semi-supervised learning', 'Artificial intelligence', 'Supervised learning', 'Cluster analysis', 'Nonlinear dimensionality reduction', 'Hellinger distance', 'Computer science', 'Unsupervised learning', 'Pattern recognition (psychology)', 'Machine learning', 'Manifold alignment', 'Set (abstract data type)', 'Manifold (fluid mechanics)', 'Mathematics', 'Artificial neural network', 'Dimensionality reduction', 'Applied mathematics', 'Programming language', 'Mechanical engineering', 'Engineering']","We study semi-supervised learning when the data consists of multiple intersecting manifolds. We give a finite sample analysis to quantify the potential gain of using unlabeled data in this multi-manifold setting. We then propose a semi-supervised learning algorithm that separates different manifolds into decision sets, and performs supervised learning within each set. Our algorithm involves a novel application of Hellinger distance and size-constrained spectral clustering. Experiments demonstrate the benefit of our multi-manifold semi-supervised learning approach"
https://openalex.org/W2962866211,Supervised Speech Separation Based on Deep Learning: An Overview,"{'Speech': [0], 'separation': [1, 14, 28, 55, 72, 79, 96, 109, 138, 151], 'is': [2, 15, 136, 171], 'the': [3, 35, 50, 63, 88, 98, 105, 111, 134, 196], 'task': [4], 'of': [5, 38, 66, 87, 107, 113, 122, 133, 165, 190], 'separating': [6], 'target': [7, 197], 'speech': [8, 13, 27, 71, 95, 108, 146, 155], 'from': [9, 46], 'background': [10, 42, 106], 'interference.': [11], 'Traditionally,': [12], 'studied': [16], 'as': [17, 29, 157, 159], 'a': [18, 30, 84, 176, 188], 'signal': [19], 'processing': [20], 'problem.': [21], 'A': [22], 'more': [23], 'recent': [24, 64], 'approach': [25], 'formulates': [26], 'supervised': [31, 54, 70, 94, 114, 123, 169], 'learning': [32, 68, 92, 125], 'problem,': [33], 'where': [34, 140], 'discriminative': [36], 'patterns': [37], 'speech,': [39], 'speakers,': [40], 'and': [41, 77, 110, 129, 154], 'noise': [43], 'are': [44, 182], 'learned': [45], 'training': [47, 127], 'data.': [48], 'Over': [49], 'past': [51], 'decade,': [52], 'many': [53], 'algorithms': [56, 139], 'have': [57], 'been': [58], 'put': [59], 'forward.': [60], 'In': [61, 184], 'particular,': [62], 'introduction': [65], 'deep': [67, 91], 'to': [69, 168], 'has': [73], 'dramatically': [74], 'accelerated': [75], 'progress': [76], 'boosted': [78], 'performance.': [80], 'This': [81, 173], 'paper': [82], 'provides': [83, 175], 'comprehensive': [85], 'overview': [86, 135, 174], 'research': [89], 'on': [90, 137, 179], 'based': [93], 'in': [97], 'last': [99], 'several': [100], 'years.': [101], 'We': [102], 'first': [103], 'introduce': [104], 'formulation': [112], 'separation.': [115], 'Then,': [116], 'we': [117, 141, 186], 'discuss': [118, 187], 'three': [119], 'main': [120], 'components': [121], 'separation:': [124], 'machines,': [126], 'targets,': [128], 'acoustic': [130], 'features.': [131], 'Much': [132], 'review': [142], 'monaural': [143], 'methods,': [144], 'including': [145, 193], 'enhancement': [147], '(speech-nonspeech': [148], 'separation),': [149, 153], 'speaker': [150], '(multitalker': [152], 'dereverberation,': [156], 'well': [158], 'multimicrophone': [160], 'techniques.': [161], 'The': [162], 'important': [163], 'issue': [164], 'generalization,': [166], 'unique': [167], 'learning,': [170], 'discussed.': [172], 'historical': [177], 'perspective': [178], 'how': [180], 'advances': [181], 'made.': [183], 'addition,': [185], 'number': [189], 'conceptual': [191], 'issues,': [192], 'what': [194], 'constitutes': [195], 'source.': [198]}",2018,"['Separation (statistics)', 'Computer science', 'Source separation', 'Supervised learning', 'Artificial intelligence', 'Deep learning', 'Speech recognition', 'Discriminative model', 'Generalization', 'Speech processing', 'Monaural', 'Machine learning', 'Artificial neural network', 'Mathematics', 'Mathematical analysis']","Speech separation is the task of separating target speech from background interference. Traditionally, speech separation is studied as a signal processing problem. A more recent approach formulates speech separation as a supervised learning problem, where the discriminative patterns of speech, speakers, and background noise are learned from training data. Over the past decade, many supervised separation algorithms have been put forward. In particular, the recent introduction of deep learning to supervised speech separation has dramatically accelerated progress and boosted separation performance. This paper provides a comprehensive overview of the research on deep learning based supervised speech separation in the last several years. We first introduce the background of speech separation and the formulation of supervised separation. Then, we discuss three main components of supervised separation: learning machines, training targets, and acoustic features. Much of the overview is on separation algorithms where we review monaural methods, including speech enhancement (speech-nonspeech separation), speaker separation (multitalker separation), and speech dereverberation, as well as multimicrophone techniques. The important issue of generalization, unique to supervised learning, is discussed. This overview provides a historical perspective on how advances are made. In addition, we discuss a number of conceptual issues, including what constitutes the target source."
https://openalex.org/W2998269939,Multi-Stage Self-Supervised Learning for Graph Convolutional Networks on Graphs with Few Labeled Nodes,"{'Graph': [0, 35], 'Convolutional': [1, 36], 'Networks': [2], '(GCNs)': [3], 'play': [4], 'a': [5, 22, 30, 64, 82], 'crucial': [6], 'role': [7], 'in': [8, 104], 'graph': [9, 14], 'learning': [10, 13, 47], 'tasks,': [11], 'however,': [12], 'embedding': [15, 95], 'with': [16, 45, 59, 121, 130], 'few': [17, 60, 122], 'supervised': [18], 'signals': [19], 'is': [20, 68], 'still': [21], 'difficult': [23], 'problem.': [24], 'In': [25], 'this': [26], 'paper,': [27], 'we': [28, 78], 'propose': [29], 'novel': [31], 'training': [32, 75], 'algorithm': [33, 118], 'for': [34], 'Network,': [37], 'called': [38], 'Multi-Stage': [39, 65, 100], 'Self-Supervised': [40], '(M3S)': [41], 'Training': [42, 66, 101, 106], 'Algorithm,': [43], 'combined': [44], 'self-supervised': [46, 86], 'approach,': [48], 'focusing': [49], 'on': [50, 57, 93, 119], 'improving': [51], 'the': [52, 71, 94, 99, 113], 'generalization': [53], 'performance': [54, 115], 'of': [55, 73, 85, 116], 'GCNs': [56], 'graphs': [58, 120], 'labeled': [61, 123], 'nodes.': [62], 'Firstly,': [63], 'Framework': [67], 'provided': [69], 'as': [70], 'basis': [72], 'M3S': [74, 105], 'method.': [76], 'Then': [77], 'leverage': [79], 'DeepCluster': [80], 'technique,': [81], 'popular': [83], 'form': [84], 'learning,': [87], 'and': [88], 'design': [89], 'corresponding': [90], 'aligning': [91], 'mechanism': [92], 'space': [96], 'to': [97], 'refine': [98], 'Framework,': [102], 'resulting': [103], 'Algorithm.': [107], 'Finally,': [108], 'extensive': [109], 'experimental': [110], 'results': [111], 'verify': [112], 'superior': [114], 'our': [117], 'nodes': [124], 'under': [125], 'different': [126], 'label': [127], 'rates': [128], 'compared': [129], 'other': [131], 'state-of-the-art': [132], 'approaches.': [133]}",2020,"['Computer science', 'Embedding', 'Leverage (statistics)', 'Artificial intelligence', 'Semi-supervised learning', 'Graph', 'Machine learning', 'Generalization', 'Theoretical computer science', 'Pattern recognition (psychology)', 'Mathematics', 'Mathematical analysis']","Graph Convolutional Networks (GCNs) play a crucial role in graph learning tasks, however, learning graph embedding with few supervised signals is still a difficult problem. In this paper, we propose a novel training algorithm for Graph Convolutional Network, called Multi-Stage Self-Supervised (M3S) Training Algorithm, combined with self-supervised learning approach, focusing on improving the generalization performance of GCNs on graphs with few labeled nodes. Firstly, a Multi-Stage Training Framework is provided as the basis of M3S training method. Then we leverage DeepCluster technique, a popular form of self-supervised learning, and design corresponding aligning mechanism on the embedding space to refine the Multi-Stage Training Framework, resulting in M3S Training Algorithm. Finally, extensive experimental results verify the superior performance of our algorithm on graphs with few labeled nodes under different label rates compared with other state-of-the-art approaches."
https://openalex.org/W2251652123,Semi-supervised learning of morphological paradigms and lexicons,"{'We': [0], 'present': [1], 'a': [2, 127, 141, 153, 158], 'semi-supervised': [3], 'approach': [4], 'to': [5, 31, 35, 99, 118, 170], 'the': [6, 21, 50, 57, 78, 111, 124, 138, 147], 'problem': [7], 'of': [8, 39, 53, 130, 140, 144, 155], 'paradigm': [9], 'induction': [10], 'from': [11, 17, 95, 114, 152, 164], 'inflection': [12, 18, 61, 145, 161], 'tables.Our': [13], 'system': [14, 58, 125, 148], 'extracts': [15], 'generalizations': [16, 38], 'tables,': [19, 146], 'representing': [20], 'resulting': [22], 'paradigms': [23], 'in': [24, 91, 126], 'an': [25, 60], 'abstract': [26], 'form.The': [27], 'process': [28], 'is': [29], 'intended': [30], 'be': [32, 45], 'language-independent,': [33], 'and': [34, 71, 134], 'provide': [36, 43], 'human-readable': [37], 'paradigms.The': [40], 'tools': [41], 'we': [42], 'can': [44, 149], 'used': [46], 'by': [47], 'linguists': [48], 'for': [49, 68, 109], 'rapid': [51], 'creation': [52], 'lexical': [54], 'resources.We': [55], 'evaluate': [56, 123], 'through': [59], 'table': [62], 'reconstruction': [63], 'task': [64, 129], 'using': [65], 'Wiktionary': [66], 'data': [67], 'German,': [69], 'Spanish,': [70], 'Finnish.With': [72], 'no': [73], 'additional': [74, 104], 'corpus': [75], 'information': [76, 162], 'available,': [77], 'evaluation': [79], 'yields': [80], 'per': [81], 'word': [82], 'form': [83], 'accuracy': [84], 'scores': [85, 112], 'on': [86, 137], 'inflecting': [87], 'unseen': [88], 'base': [89], 'forms': [90, 157], 'different': [92], 'languages': [93], 'ranging': [94, 163], '87.81%': [96], '(German': [97, 116], 'nouns)': [98, 117], '99.52%': [100], '(Spanish': [101, 120], 'verbs);': [102], 'with': [103, 160], 'unlabeled': [105], 'text': [106], 'corpora': [107], 'available': [108], 'training': [110], 'range': [113], '91.81%': [115], '99.58%': [119], 'verbs).We': [121], 'separately': [122], 'simulated': [128], 'Swedish': [131], 'lexicon': [132, 159], 'creation,': [133], 'show': [135], 'that': [136], 'basis': [139], 'small': [142], 'number': [143], 'accurately': [150], 'collect': [151], 'list': [154], 'noun': [156], '100.0%': [165], 'correct': [166, 172], '(collect': [167, 173], '100': [168], 'words),': [169], '96.4%': [171], '1000': [174], 'words).': [175]}",2014,"['Inflection', 'Computer science', 'Natural language processing', 'Noun', 'Artificial intelligence', 'Lexicon', 'German', 'Task (project management)', 'Table (database)', 'Process (computing)', 'Linguistics', 'Database', 'Economics', 'Management', 'Philosophy', 'Operating system']","We present a semi-supervised approach to the problem of paradigm induction from inflection tables.Our system extracts generalizations from inflection tables, representing the resulting paradigms in an abstract form.The process is intended to be language-independent, and to provide human-readable generalizations of paradigms.The tools we provide can be used by linguists for the rapid creation of lexical resources.We evaluate the system through an inflection table reconstruction task using Wiktionary data for German, Spanish, and Finnish.With no additional corpus information available, the evaluation yields per word form accuracy scores on inflecting unseen base forms in different languages ranging from 87.81% (German nouns) to 99.52% (Spanish verbs); with additional unlabeled text corpora available for training the scores range from 91.81% (German nouns) to 99.58% (Spanish verbs).We separately evaluate the system in a simulated task of Swedish lexicon creation, and show that on the basis of a small number of inflection tables, the system can accurately collect from a list of noun forms a lexicon with inflection information ranging from 100.0% correct (collect 100 words), to 96.4% correct (collect 1000 words)."
https://openalex.org/W4280625391,Deciphering the language of antibodies using self-supervised learning,"{'An': [0], ""individual's"": [1], 'B': [2], 'cell': [3], 'receptor': [4], '(BCR)': [5], 'repertoire': [6], 'encodes': [7], 'information': [8, 21], 'about': [9], 'past': [10], 'immune': [11], 'responses': [12], 'and': [13, 33, 39, 145], 'potential': [14], 'for': [15, 141], 'future': [16], 'disease': [17, 32], 'protection.': [18], 'Deciphering': [19], 'the': [20, 50, 126, 151], 'stored': [22], 'in': [23], 'BCR': [24, 46, 53, 81], 'sequence': [25, 47, 59], 'datasets': [26], 'will': [27], 'transform': [28], 'our': [29, 122, 148], 'understanding': [30, 149], 'of': [31, 36, 45, 52, 80, 98, 135, 150, 153], 'enable': [34], 'discovery': [35], 'novel': [37], 'diagnostics': [38], 'antibody': [40, 113], 'therapeutics.': [41], 'A': [42], 'key': [43], 'challenge': [44], 'analysis': [48], 'is': [49, 125], 'prediction': [51], 'properties': [54], 'from': [55, 72, 111], 'their': [56], 'amino': [57], 'acid': [58], 'alone.': [60], 'Here,': [61], 'we': [62, 85, 104], 'present': [63], 'an': [64, 112], 'antibody-specific': [65], 'language': [66, 129, 152], 'model,': [67, 130], 'Antibody-specific': [68], 'Bidirectional': [69], 'Encoder': [70], 'Representation': [71], 'Transformers': [73], '(AntiBERTa),': [74], 'which': [75], 'provides': [76], 'a': [77, 96, 101, 132], 'contextualized': [78], 'representation': [79, 134], 'sequences.': [82], 'Following': [83], 'pre-training,': [84], 'show': [86], 'that': [87], 'AntiBERTa': [88, 106, 124, 137], 'embeddings': [89, 138], 'capture': [90], 'biologically': [91], 'relevant': [92], 'information,': [93], 'generalizable': [94], 'to': [95, 107], 'range': [97], 'applications.': [99], 'As': [100], 'case': [102], 'study,': [103], 'fine-tune': [105], 'predict': [108], 'paratope': [109], 'positions': [110], 'sequence,': [114], 'outperforming': [115], 'public': [116], 'tools': [117], 'across': [118], 'multiple': [119, 142], 'metrics.': [120], 'To': [121], 'knowledge,': [123], 'deepest': [127], 'protein-family-specific': [128], 'providing': [131], 'rich': [133], 'BCRs.': [136], 'are': [139], 'primed': [140], 'downstream': [143], 'tasks': [144], 'can': [146], 'improve': [147], 'antibodies.': [154]}",2022,"['Paratope', 'Computer science', 'Repertoire', 'breakpoint cluster region', 'Representation (politics)', 'Sequence (biology)', 'Computational biology', 'Antibody', 'Artificial intelligence', 'Biology', 'Receptor', 'Immunology', 'Genetics', 'Epitope', 'Politics', 'Political science', 'Law', 'Acoustics', 'Physics']","An individual's B cell receptor (BCR) repertoire encodes information about past immune responses and potential for future disease protection. Deciphering the information stored in BCR sequence datasets will transform our understanding of disease and enable discovery of novel diagnostics and antibody therapeutics. A key challenge of BCR sequence analysis is the prediction of BCR properties from their amino acid sequence alone. Here, we present an antibody-specific language model, Antibody-specific Bidirectional Encoder Representation from Transformers (AntiBERTa), which provides a contextualized representation of BCR sequences. Following pre-training, we show that AntiBERTa embeddings capture biologically relevant information, generalizable to a range of applications. As a case study, we fine-tune AntiBERTa to predict paratope positions from an antibody sequence, outperforming public tools across multiple metrics. To our knowledge, AntiBERTa is the deepest protein-family-specific language model, providing a rich representation of BCRs. AntiBERTa embeddings are primed for multiple downstream tasks and can improve our understanding of the language of antibodies."
https://openalex.org/W3094605801,Self-supervised Graph Learning for Recommendation,"{'Representation': [0], 'learning': [1, 82, 115, 166], 'on': [2, 48, 83, 174, 207], 'user-item': [3, 84], 'graph': [4, 24, 158], 'for': [5, 95], 'recommendation': [6, 106, 204], 'has': [7], 'evolved\\nfrom': [8], 'using': [9], 'single': [10], 'ID': [11], 'or': [12], 'interaction': [13, 213], 'history': [14], 'to': [15, 20, 63, 143], 'exploiting': [16], 'higher-order\\nneighbors.': [17], 'This': [18], 'leads': [19], 'the': [21, 49, 53, 66, 89, 101, 125, 131, 145, 157, 185, 198, 211], 'success': [22], 'of': [23, 73, 93, 105, 122, 130, 136, 187, 200], 'convolution': [25], 'networks': [26], '(GCNs)': [27], 'for\\nrecommendation': [28], 'such': [29], 'as': [30, 65], 'PinSage': [31], 'and': [32, 58, 91, 151, 210], 'LightGCN.': [33, 177], 'Despite': [34], 'effectiveness,': [35], 'we': [36, 79, 118, 181], 'argue\\nthat': [37], 'they': [38], 'suffer': [39], 'from': [40], 'two': [41], 'limitations:': [42], '(1)': [43], 'high-degree': [44], 'nodes': [45], 'exert': [46], 'larger\\nimpact': [47], 'representation': [50, 114], 'learning,': [51], 'deteriorating': [52], 'recommendations': [54], 'of\\nlow-degree': [55], '(long-tail)': [56], 'items;': [57], '(2)': [59], 'representations': [60], 'are': [61, 217], 'vulnerable': [62], 'noisy\\ninteractions,': [64], 'neighborhood': [67], 'aggregation': [68], 'scheme': [69], 'further': [70], 'enlarges': [71], 'the\\nimpact': [72], 'observed': [74], 'edges.\\n': [75], 'In': [76], 'this': [77, 164], 'work,': [78], 'explore': [80], 'self-supervised': [81], 'graph,': [85], 'so': [86], 'as\\nto': [87], 'improve': [88], 'accuracy': [90], 'robustness': [92], 'GCNs': [94], 'recommendation.': [96], 'The': [97], 'idea': [98], 'is\\nto': [99], 'supplement': [100], 'classical': [102], 'supervised': [103], 'task': [104], 'with': [107], 'an': [108], 'auxiliary\\nself-supervised': [109], 'task,': [110], 'which': [111, 202], 'reinforces': [112], 'node': [113, 133], 'via\\nself-discrimination.': [116], 'Specifically,': [117], 'generate': [119, 144], 'multiple': [120], 'views': [121, 129, 146], 'a': [123], 'node,\\nmaximizing': [124], 'agreement': [126], 'between': [127], 'different': [128], 'same': [132], 'compared': [134], 'to\\nthat': [135], 'other': [137], 'nodes.': [138], 'We': [139, 162], 'devise': [140], 'three': [141], 'operators': [142], '--': [147, 154], 'node\\ndropout,': [148], 'edge': [149], 'dropout,': [150], 'random': [152], 'walk': [153], 'that': [155, 183], 'change': [156], 'structure': [159], 'in\\ndifferent': [160], 'manners.': [161], 'term': [163], 'new': [165], 'paradigm': [167], 'as\\n\\\\textit{Self-supervised': [168], 'Graph': [169], 'Learning}': [170], '(SGL),': [171], 'implementing': [172], 'it': [173], 'the\\nstate-of-the-art': [175], 'model': [176], 'Through': [178], 'theoretical': [179], 'analyses,': [180], 'find': [182], 'SGL\\nhas': [184], 'ability': [186], 'automatically': [188], 'mining': [189], 'hard': [190], 'negatives.': [191], 'Empirical': [192], 'studies': [193], 'on\\nthree': [194], 'benchmark': [195], 'datasets': [196], 'demonstrate': [197], 'effectiveness': [199], 'SGL,': [201], 'improves\\nthe': [203], 'accuracy,': [205], 'especially': [206], 'long-tail': [208], 'items,': [209], 'robustness\\nagainst': [212], 'noises.': [214], 'Our': [215], 'implementations': [216], 'available': [218], 'at\\n\\\\url{https://github.com/wujcan/SGL}.\\n': [219]}",2021,[],"Representation learning on user-item graph for recommendation has evolved\nfrom using single ID or interaction history to exploiting higher-order\nneighbors. This leads to the success of graph convolution networks (GCNs) for\nrecommendation such as PinSage and LightGCN. Despite effectiveness, we argue\nthat they suffer from two limitations: (1) high-degree nodes exert larger\nimpact on the representation learning, deteriorating the recommendations of\nlow-degree (long-tail) items; and (2) representations are vulnerable to noisy\ninteractions, as the neighborhood aggregation scheme further enlarges the\nimpact of observed edges.\n In this work, we explore self-supervised learning on user-item graph, so as\nto improve the accuracy and robustness of GCNs for recommendation. The idea is\nto supplement the classical supervised task of recommendation with an auxiliary\nself-supervised task, which reinforces node representation learning via\nself-discrimination. Specifically, we generate multiple views of a node,\nmaximizing the agreement between different views of the same node compared to\nthat of other nodes. We devise three operators to generate the views -- node\ndropout, edge dropout, and random walk -- that change the graph structure in\ndifferent manners. We term this new learning paradigm as\n\\textit{Self-supervised Graph Learning} (SGL), implementing it on the\nstate-of-the-art model LightGCN. Through theoretical analyses, we find that SGL\nhas the ability of automatically mining hard negatives. Empirical studies on\nthree benchmark datasets demonstrate the effectiveness of SGL, which improves\nthe recommendation accuracy, especially on long-tail items, and the robustness\nagainst interaction noises. Our implementations are available at\n\\url{https://github.com/wujcan/SGL}.\n"
https://openalex.org/W2991213871,End-to-end ASR: from Supervised to Semi-Supervised Learning with Modern Architectures,"{'We': [0, 24, 41], 'study': [1, 108], 'pseudo-labeling': [2], 'for': [3, 14, 82], 'the': [4, 28, 52, 69, 93, 109, 123], 'semi-supervised': [5, 104], 'training': [6], 'of': [7, 68, 111, 115, 121, 125], 'ResNet,': [8], 'Time-Depth': [9], 'Separable': [10], 'ConvNets,': [11], 'and': [12, 32, 62, 65, 98, 132], 'Transformers': [13], 'speech': [15], 'recognition,': [16], 'with': [17, 51, 87, 103, 138], 'either': [18], 'CTC': [19], 'or': [20], 'Seq2Seq': [21], 'loss': [22, 63], 'functions.': [23], 'perform': [25], 'experiments': [26], 'on': [27, 143], 'standard': [29, 94], 'LibriSpeech': [30], 'dataset,': [31], 'leverage': [33], 'additional': [34], 'unlabeled': [35, 116, 126], 'data': [36], 'from': [37], 'LibriVox': [38], 'through': [39], 'pseudo-labeling.': [40], 'show': [42, 133], 'that': [43, 134], 'while': [44], 'Transformer-based': [45], 'acoustic': [46, 84, 130, 135], 'models': [47, 59, 85, 136], 'have': [48], 'superior': [49], 'performance': [50, 70], 'supervised': [53, 95], 'dataset': [54], 'alone,': [55], 'semi-supervision': [56], 'improves': [57], 'all': [58], 'across': [60], 'architectures': [61], 'functions': [64], 'bridges': [66], 'much': [67], 'gaps': [71], 'between': [72], 'them.': [73], 'In': [74], 'doing': [75], 'so,': [76], 'we': [77, 107], 'reach': [78], 'a': [79, 99], 'new': [80, 100], 'state-of-the-art': [81, 102], 'end-to-end': [83], 'decoded': [86], 'an': [88], 'external': [89, 144], 'language': [90, 145], 'model': [91], 'in': [92], 'learning': [96], 'setting,': [97], 'absolute': [101], 'training.': [105], 'Finally,': [106], 'effect': [110], 'leveraging': [112], 'different': [113], 'amounts': [114], 'audio,': [117], 'propose': [118], 'several': [119], 'ways': [120], 'evaluating': [122], 'characteristics': [124], 'audio': [127, 140], 'which': [128], 'improve': [129], 'modeling,': [131], 'trained': [137], 'more': [139], 'rely': [141], 'less': [142], 'models.': [146]}",2019,"['Computer science', 'Artificial intelligence', 'Semi-supervised learning', 'Supervised learning', 'Machine learning', 'Artificial neural network']","We study pseudo-labeling for the semi-supervised training of ResNet, Time-Depth Separable ConvNets, and Transformers for speech recognition, with either CTC or Seq2Seq loss functions. We perform experiments on the standard LibriSpeech dataset, and leverage additional unlabeled data from LibriVox through pseudo-labeling. We show that while Transformer-based acoustic models have superior performance with the supervised dataset alone, semi-supervision improves all models across architectures and loss functions and bridges much of the performance gaps between them. In doing so, we reach a new state-of-the-art for end-to-end acoustic models decoded with an external language model in the standard supervised learning setting, and a new absolute state-of-the-art with semi-supervised training. Finally, we study the effect of leveraging different amounts of unlabeled audio, propose several ways of evaluating the characteristics of unlabeled audio which improve acoustic modeling, and show that acoustic models trained with more audio rely less on external language models."
https://openalex.org/W3160566314,Self-Supervised Learning with Swin Transformers,"{'We': [0, 147], 'are': [1, 168], 'witnessing': [2], 'a': [3, 18, 122], 'modeling': [4], 'shift': [5], 'from': [6, 41], 'CNN': [7], 'to': [8, 48, 103, 121, 138], 'Transformers': [9, 26], 'in': [10, 119], 'computer': [11], 'vision.': [12], 'In': [13], 'this': [14], 'work,': [15], 'we': [16], 'present': [17], 'self-supervised': [19, 157], 'learning': [20, 158], 'approach': [21, 32], 'called': [22], 'MoBY,': [23], 'with': [24, 90], 'Vision': [25], 'as': [27, 86, 113], 'its': [28], 'backbone': [29, 100], 'architecture.': [30], 'The': [31, 70], 'basically': [33], 'has': [34], 'no': [35], 'new': [36], 'inventions,': [37], 'which': [38, 83, 129, 172], 'is': [39, 72], 'combined': [40], 'MoCo': [42, 79], 'v2': [43], 'and': [44, 46, 58, 64, 81, 116, 166], 'BYOL': [45], 'tuned': [47], 'achieve': [49], 'reasonably': [50], 'high': [51], 'accuracy': [52, 61], 'on': [53, 109, 127, 135], 'ImageNet-1K': [54, 136], 'linear': [55, 132], 'evaluation:': [56], '72.8%': [57], '75.0%': [59], 'top-1': [60], 'using': [62], 'DeiT-S': [63], 'Swin-T,': [65], 'respectively,': [66], 'by': [67], '300-epoch': [68], 'training.': [69], 'performance': [71], 'slightly': [73], 'better': [74], 'than': [75], 'recent': [76, 124], 'works': [77], 'of': [78, 156], 'v3': [80], 'DINO': [82], 'adopt': [84], 'DeiT': [85], 'the': [87, 96, 106], 'backbone,': [88], 'but': [89], 'much': [91], 'lighter': [92], 'tricks.': [93], 'More': [94], 'importantly,': [95], 'general-purpose': [97], 'Swin': [98], 'Transformer': [99, 162], 'enables': [101], 'us': [102], 'also': [104], 'evaluate': [105], 'learnt': [107], 'representations': [108], 'downstream': [110], 'tasks': [111], 'such': [112], 'object': [114], 'detection': [115], 'semantic': [117], 'segmentation,': [118], 'contrast': [120], 'few': [123], 'approaches': [125], 'built': [126], 'ViT/DeiT': [128, 139], 'only': [130], 'report': [131], 'evaluation': [133, 155], 'results': [134, 150], 'due': [137], 'not': [140], 'tamed': [141], 'for': [142, 161], 'these': [143], 'dense': [144], 'prediction': [145], 'tasks.': [146], 'hope': [148], 'our': [149], 'can': [151], 'facilitate': [152], 'more': [153], 'comprehensive': [154], 'methods': [159], 'designed': [160], 'architectures.': [163], 'Our': [164], 'code': [165], 'models': [167], 'available': [169], 'at': [170], 'https://github.com/SwinTransformer/Transformer-SSL,': [171], 'will': [173], 'be': [174], 'continually': [175], 'enriched.': [176]}",2021,"['Transformer', 'Computer science', 'Artificial intelligence', 'Psychology', 'Business', 'Engineering', 'Electrical engineering', 'Voltage']","We are witnessing a modeling shift from CNN to Transformers in computer vision. In this work, we present a self-supervised learning approach called MoBY, with Vision Transformers as its backbone architecture. The approach basically has no new inventions, which is combined from MoCo v2 and BYOL and tuned to achieve reasonably high accuracy on ImageNet-1K linear evaluation: 72.8% and 75.0% top-1 accuracy using DeiT-S and Swin-T, respectively, by 300-epoch training. The performance is slightly better than recent works of MoCo v3 and DINO which adopt DeiT as the backbone, but with much lighter tricks. More importantly, the general-purpose Swin Transformer backbone enables us to also evaluate the learnt representations on downstream tasks such as object detection and semantic segmentation, in contrast to a few recent approaches built on ViT/DeiT which only report linear evaluation results on ImageNet-1K due to ViT/DeiT not tamed for these dense prediction tasks. We hope our results can facilitate more comprehensive evaluation of self-supervised learning methods designed for Transformer architectures. Our code and models are available at https://github.com/SwinTransformer/Transformer-SSL, which will be continually enriched."
https://openalex.org/W3086452730,Contrastive Self-supervised Learning for Graph Classification,"{'Graph': [0], 'classification': [1, 23, 94, 165], 'is': [2, 25, 129, 143, 176], 'a': [3, 85, 108, 134], 'widely': [4], 'studied': [5], 'problem': [6], 'and': [7, 90, 96], 'has': [8], 'broad': [9], 'applications.': [10], 'In': [11, 51, 79], 'many': [12], 'real-world': [13], 'problems,': [14], 'the': [15, 52, 73, 80, 92, 97, 123, 157, 168], 'number': [16], 'of': [17, 110, 122, 136, 170], 'labeled': [18, 77], 'graphs': [19, 65, 120, 154], 'available': [20, 177], 'for': [21], 'training': [22], 'models': [24, 30], 'limited,': [26], 'which': [27], 'renders': [28], 'these': [29], 'prone': [31], 'to': [32, 48, 58, 117, 145], 'overfitting.': [33, 50], 'To': [34, 102], 'address': [35], 'this': [36], 'problem,': [37], 'we': [38, 55, 83, 113], 'propose': [39], 'two': [40, 152], 'approaches': [41], 'based': [42, 87], 'on': [43, 62, 68, 76, 88, 105, 162], 'contrastive': [44, 141], 'self-supervised': [45], 'learning': [46], '(CSSL)': [47], 'alleviate': [49], 'first': [53], 'approach,': [54, 82], 'use': [56], 'CSSL': [57, 99, 104], 'pretrain': [59], 'graph': [60, 128, 137, 147, 164], 'encoders': [61, 75, 148], 'widely-available': [63], 'unlabeled': [64], 'without': [66], 'relying': [67], 'human-provided': [69], 'labels,': [70], 'then': [71], 'finetune': [72], 'pretrained': [74], 'graphs.': [78, 125], 'second': [81], 'develop': [84], 'regularizer': [86], 'CSSL,': [89], 'solve': [91], 'supervised': [93], 'task': [95, 100], 'unsupervised': [98], 'simultaneously.': [101], 'perform': [103, 114], 'graphs,': [106, 112], 'given': [107], 'collection': [109], 'original': [111, 124, 159], 'data': [115], 'augmentation': [116], 'create': [118], 'augmented': [119, 127, 153], 'out': [121], 'An': [126], 'created': [130], 'by': [131, 149], 'consecutively': [132], 'applying': [133], 'sequence': [135], 'alteration': [138], 'operations.': [139], 'A': [140], 'loss': [142], 'defined': [144], 'learn': [146], 'judging': [150], 'whether': [151], 'are': [155], 'from': [156], 'same': [158], 'graph.': [160], 'Experiments': [161], 'various': [163], 'datasets': [166], 'demonstrate': [167], 'effectiveness': [169], 'our': [171], 'proposed': [172], 'methods.': [173], 'The': [174], 'code': [175], 'at': [178], 'https://github.com/UCSD-AI4H/GraphSSL.': [179]}",2021,"['Overfitting', 'Computer science', 'Graph', 'Encoder', 'Artificial intelligence', 'Machine learning', 'Pattern recognition (psychology)', 'Theoretical computer science', 'Artificial neural network', 'Operating system']","Graph classification is a widely studied problem and has broad applications. In many real-world problems, the number of labeled graphs available for training classification models is limited, which renders these models prone to overfitting. To address this problem, we propose two approaches based on contrastive self-supervised learning (CSSL) to alleviate overfitting. In the first approach, we use CSSL to pretrain graph encoders on widely-available unlabeled graphs without relying on human-provided labels, then finetune the pretrained encoders on labeled graphs. In the second approach, we develop a regularizer based on CSSL, and solve the supervised classification task and the unsupervised CSSL task simultaneously. To perform CSSL on graphs, given a collection of original graphs, we perform data augmentation to create augmented graphs out of the original graphs. An augmented graph is created by consecutively applying a sequence of graph alteration operations. A contrastive loss is defined to learn graph encoders by judging whether two augmented graphs are from the same original graph. Experiments on various graph classification datasets demonstrate the effectiveness of our proposed methods. The code is available at https://github.com/UCSD-AI4H/GraphSSL."
https://openalex.org/W2751625733,Self-Supervised Learning for Stereo Matching with Self-Improving Ability,"{'Exiting': [0], 'deep-learning': [1, 113], 'based': [2], 'dense': [3, 44], 'stereo': [4, 50, 105, 149, 159], 'matching': [5, 160], 'methods': [6, 161], 'often': [7], 'rely': [8], 'on': [9, 145], 'ground-truth': [10, 63], 'disparity': [11, 45, 64], 'maps': [12, 46], 'as': [13, 78, 137, 139], 'the': [14, 49, 60, 79, 84, 94, 167], 'training': [15], 'signals,': [16], 'which': [17], 'are': [18], 'however': [19], 'not': [20], 'always': [21], 'available': [22], 'in': [23, 55, 104, 111, 122], 'many': [24, 115, 157], 'situations.': [25], 'In': [26], 'this': [27, 98, 123], 'paper,': [28], 'we': [29, 125], 'design': [30], 'a': [31, 90, 100, 112, 163], 'simple': [32, 101], 'convolutional': [33], 'neural': [34], 'network': [35, 130], 'architecture': [36], 'that': [37, 92, 153], 'is': [38, 53, 68, 99, 131], 'able': [39], 'to': [40, 42, 69, 82, 88, 107, 133, 140], 'learn': [41], 'compute': [43], 'directly': [47], 'from': [48], 'inputs.': [51], 'Training': [52], 'performed': [54], 'an': [56], 'end-to-end': [57], 'fashion': [58], 'without': [59], 'need': [61], 'of': [62, 75], 'maps.': [65], 'The': [66], 'idea': [67], 'use': [70], 'image': [71], 'warping': [72, 95], 'error': [73], '(instead': [74], 'disparity-map': [76], 'residuals)': [77], 'loss': [80], 'function': [81], 'drive': [83], 'learning': [85], 'process,': [86], 'aiming': [87], 'find': [89], 'depth-map': [91], 'minimizes': [93], 'error.': [96], 'While': [97], 'concept': [102], 'well-known': [103], 'matching,': [106], 'make': [108], 'it': [109], 'work': [110, 124], 'framework,': [114], 'non-trivial': [116], 'challenges': [117], 'must': [118], 'be': [119], 'overcome,': [120], 'and': [121, 147, 165], 'provide': [126], 'effective': [127], 'solutions.': [128], 'Our': [129], 'self-adaptive': [132], 'different': [134, 141], 'unseen': [135], 'imageries': [136], 'well': [138], 'camera': [142], 'settings.': [143], 'Experiments': [144], 'KITTI': [146], 'Middlebury': [148], 'benchmark': [150], 'datasets': [151], 'show': [152], 'our': [154], 'method': [155], 'outperforms': [156], 'state-of-the-art': [158], 'with': [162], 'margin,': [164], 'at': [166], 'same': [168], 'time': [169], 'significantly': [170], 'faster.': [171]}",2017,"['Artificial intelligence', 'Image warping', 'Computer science', 'Benchmark (surveying)', 'Ground truth', 'Margin (machine learning)', 'Convolutional neural network', 'Matching (statistics)', 'Computer vision', 'Deep learning', 'Process (computing)', 'Stereopsis', 'Pattern recognition (psychology)', 'Machine learning', 'Mathematics', 'Geography', 'Geodesy', 'Statistics', 'Operating system']","Exiting deep-learning based dense stereo matching methods often rely on ground-truth disparity maps as the training signals, which are however not always available in many situations. In this paper, we design a simple convolutional neural network architecture that is able to learn to compute dense disparity maps directly from the stereo inputs. Training is performed in an end-to-end fashion without the need of ground-truth disparity maps. The idea is to use image warping error (instead of disparity-map residuals) as the loss function to drive the learning process, aiming to find a depth-map that minimizes the warping error. While this is a simple concept well-known in stereo matching, to make it work in a deep-learning framework, many non-trivial challenges must be overcome, and in this work we provide effective solutions. Our network is self-adaptive to different unseen imageries as well as to different camera settings. Experiments on KITTI and Middlebury stereo benchmark datasets show that our method outperforms many state-of-the-art stereo matching methods with a margin, and at the same time significantly faster."
https://openalex.org/W4280634279,FreeMatch: Self-adaptive Thresholding for Semi-supervised Learning,"{'Semi-supervised': [0], 'Learning': [1], '(SSL)': [2], 'has': [3], 'witnessed': [4], 'great': [5], 'success': [6], 'owing': [7], 'to': [8, 31, 66, 88, 98, 112], 'the': [9, 33, 70, 73, 82, 90, 99, 114, 120, 127, 133, 149, 180], 'impressive': [10], 'performances': [11], 'brought': [12], 'by': [13], 'various': [14], 'methods': [15, 28], 'based': [16], 'on': [17, 69, 81, 154], 'pseudo': [18], 'labeling': [19], 'and': [20, 57, 76, 143, 167], 'consistency': [21], 'regularization.': [22], 'However,': [23], 'we': [24, 84], 'argue': [25], 'that': [26], 'existing': [27], 'might': [29], 'fail': [30], 'utilize': [32], 'unlabeled': [34], 'data': [35, 135], 'more': [36], 'effectively': [37], 'since': [38], 'they': [39], 'either': [40], 'use': [41], 'a': [42, 63, 94, 106], 'pre-defined': [43], '/': [44], 'fixed': [45], 'threshold': [46, 50, 75, 92], 'or': [47], 'an': [48], 'ad-hoc': [49], 'adjusting': [51], 'scheme,': [52], 'resulting': [53], 'in': [54, 93], 'inferior': [55], 'performance': [56, 181], 'slow': [58], 'convergence.': [59], 'We': [60, 103], 'first': [61], 'analyze': [62], 'motivating': [64], 'example': [65], 'obtain': [67], 'intuitions': [68], 'relationship': [71], 'between': [72], 'desirable': [74], ""model's"": [77, 100], 'learning': [78, 101], 'status.': [79, 102], 'Based': [80], 'analysis,': [83], 'hence': [85], 'propose': [86], 'FreeMatch': [87, 130, 139, 176], 'adjust': [89], 'confidence': [91], 'self-adaptive': [95, 107], 'manner': [96], 'according': [97], 'further': [104], 'introduce': [105], 'class': [108], 'fairness': [109], 'regularization': [110], 'penalty': [111], 'encourage': [113], 'model': [115], 'for': [116], 'diverse': [117], 'predictions': [118], 'during': [119], 'early': [121], 'training': [122], 'stage.': [123], 'Extensive': [124], 'experiments': [125], 'indicate': [126], 'superiority': [128], 'of': [129, 182], 'especially': [131], 'when': [132], 'labeled': [134], 'are': [136], 'extremely': [137], 'rare.': [138], 'achieves': [140], '5.78%,': [141], '13.59%,': [142], '1.28%': [144], 'error': [145], 'rate': [146], 'reduction': [147], 'over': [148], 'latest': [150], 'state-of-the-art': [151], 'method': [152], 'FlexMatch': [153], 'CIFAR-10': [155], 'with': [156, 162, 169], '1': [157], 'label': [158], 'per': [159, 165, 172], 'class,': [160, 166, 173], 'STL-10': [161], '4': [163], 'labels': [164, 171], 'ImageNet': [168], '100': [170], 'respectively.': [174], 'Moreover,': [175], 'can': [177, 187], 'also': [178], 'boost': [179], 'imbalanced': [183], 'SSL.': [184], 'The': [185], 'codes': [186], 'be': [188], 'found': [189], 'at': [190], 'https://github.com/microsoft/Semi-supervised-learning.': [191]}",2022,"['Computer science', 'Regularization (linguistics)', 'Thresholding', 'Class (philosophy)', 'Consistency (knowledge bases)', 'Artificial intelligence', 'Machine learning', 'Semi-supervised learning', 'Word error rate', 'Labeled data', 'Image (mathematics)']","Semi-supervised Learning (SSL) has witnessed great success owing to the impressive performances brought by various methods based on pseudo labeling and consistency regularization. However, we argue that existing methods might fail to utilize the unlabeled data more effectively since they either use a pre-defined / fixed threshold or an ad-hoc threshold adjusting scheme, resulting in inferior performance and slow convergence. We first analyze a motivating example to obtain intuitions on the relationship between the desirable threshold and model's learning status. Based on the analysis, we hence propose FreeMatch to adjust the confidence threshold in a self-adaptive manner according to the model's learning status. We further introduce a self-adaptive class fairness regularization penalty to encourage the model for diverse predictions during the early training stage. Extensive experiments indicate the superiority of FreeMatch especially when the labeled data are extremely rare. FreeMatch achieves 5.78%, 13.59%, and 1.28% error rate reduction over the latest state-of-the-art method FlexMatch on CIFAR-10 with 1 label per class, STL-10 with 4 labels per class, and ImageNet with 100 labels per class, respectively. Moreover, FreeMatch can also boost the performance of imbalanced SSL. The codes can be found at https://github.com/microsoft/Semi-supervised-learning."
https://openalex.org/W4287388854,In Defense of Pseudo-Labeling: An Uncertainty-Aware Pseudo-label\n Selection Framework for Semi-Supervised Learning,"{'The': [0], 'recent': [1, 134], 'research': [2], 'in': [3], 'semi-supervised': [4], 'learning': [5], '(SSL)': [6], 'is': [7, 36], 'mostly': [8], 'dominated': [9], 'by\\nconsistency': [10], 'regularization': [11], 'based': [12], 'methods': [13, 136], 'which': [14, 25, 84], 'achieve': [15, 129], 'strong': [16], 'performance.\\nHowever,': [17], 'they': [18], 'heavily': [19], 'rely': [20], 'on': [21, 137, 150], 'domain-specific': [22], 'data': [23, 32], 'augmentations,': [24], 'are': [26], 'not\\neasy': [27], 'to': [28, 59, 74, 123, 133], 'generate': [29], 'for': [30, 105, 116], 'all': [31], 'modalities.': [33], 'Pseudo-labeling': [34], '(PL)': [35], 'a': [37], 'general': [38], 'SSL\\napproach': [39], 'that': [40, 55], 'does': [41], 'not': [42], 'have': [43], 'this': [44], 'constraint': [45], 'but': [46], 'performs': [47], 'relatively': [48], 'poorly': [49, 65], 'in\\nits': [50], 'original': [51], 'formulation.': [52], 'We': [53, 77, 128], 'argue': [54], 'PL': [56], 'underperforms': [57], 'due': [58], 'the': [60, 91, 102, 106, 125, 138, 145, 151, 155], 'erroneous\\nhigh': [61], 'confidence': [62], 'predictions': [63], 'from': [64], 'calibrated': [66], 'models;': [67], 'these': [68, 111], 'predictions\\ngenerate': [69], 'many': [70], 'incorrect': [71], 'pseudo-labels,': [72], 'leading': [73], 'noisy': [75], 'training.': [76], 'propose': [78], 'an\\nuncertainty-aware': [79], 'pseudo-label': [80], 'selection': [81], '(UPS)': [82], 'framework': [83], 'improves': [85], 'pseudo\\nlabeling': [86], 'accuracy': [87], 'by': [88], 'drastically': [89], 'reducing': [90], 'amount': [92], 'of': [93, 108, 147], 'noise': [94], 'encountered': [95], 'in\\nthe': [96], 'training': [97], 'process.': [98], 'Furthermore,': [99], 'UPS': [100], 'generalizes': [101], 'pseudo-labeling': [103], 'process,\\nallowing': [104], 'creation': [107], 'negative': [109], 'pseudo-labels;': [110], 'negative\\npseudo-labels': [112], 'can': [113], 'be': [114], 'used': [115], 'multi-label': [117, 156], 'classification': [118], 'as': [119, 121], 'well': [120], 'negative\\nlearning': [122], 'improve': [124], 'single-label': [126], 'classification.': [127], 'strong\\nperformance': [130], 'when': [131], 'compared': [132], 'SSL': [135], 'CIFAR-10': [139], 'and': [140, 154], 'CIFAR-100\\ndatasets.': [141], 'Also,': [142], 'we': [143], 'demonstrate': [144], 'versatility': [146], 'our': [148], 'method': [149], 'video\\ndataset': [152], 'UCF-101': [153], 'dataset': [157], 'Pascal': [158], 'VOC.\\n': [159]}",2021,"['Computer science', 'Pascal (unit)', 'Artificial intelligence', 'Machine learning', 'Consistency (knowledge bases)', 'Labeled data', 'Regularization (linguistics)', 'Process (computing)', 'Selection (genetic algorithm)', 'Pattern recognition (psychology)', 'Operating system', 'Programming language']","The recent research in semi-supervised learning (SSL) is mostly dominated by\nconsistency regularization based methods which achieve strong performance.\nHowever, they heavily rely on domain-specific data augmentations, which are not\neasy to generate for all data modalities. Pseudo-labeling (PL) is a general SSL\napproach that does not have this constraint but performs relatively poorly in\nits original formulation. We argue that PL underperforms due to the erroneous\nhigh confidence predictions from poorly calibrated models; these predictions\ngenerate many incorrect pseudo-labels, leading to noisy training. We propose an\nuncertainty-aware pseudo-label selection (UPS) framework which improves pseudo\nlabeling accuracy by drastically reducing the amount of noise encountered in\nthe training process. Furthermore, UPS generalizes the pseudo-labeling process,\nallowing for the creation of negative pseudo-labels; these negative\npseudo-labels can be used for multi-label classification as well as negative\nlearning to improve the single-label classification. We achieve strong\nperformance when compared to recent SSL methods on the CIFAR-10 and CIFAR-100\ndatasets. Also, we demonstrate the versatility of our method on the video\ndataset UCF-101 and the multi-label dataset Pascal VOC.\n"
https://openalex.org/W2995098893,Comparing different supervised machine learning algorithms for disease prediction,"{'Abstract': [0], 'Background': [1], 'Supervised': [2], 'machine': [3, 44, 75, 109, 201, 226], 'learning': [4, 45, 76, 110, 202, 227], 'algorithms': [5, 111, 203], 'have': [6], 'been': [7], 'a': [8, 24, 189], 'dominant': [9], 'method': [10], 'in': [11, 101, 164, 177, 219], 'the': [12, 36, 104, 119, 134, 142, 152, 161, 180, 193, 220], 'data': [13, 20], 'mining': [14], 'field.': [15], 'Disease': [16], 'prediction': [17], 'using': [18], 'health': [19], 'has': [21], 'recently': [22], 'shown': [23], 'potential': [25], 'application': [26], 'area': [27], 'for': [28, 52, 90, 103, 112, 204, 229], 'these': [29], 'methods.': [30], 'This': [31, 170, 186, 207], 'study': [32, 187], 'aims': [33], 'to': [34, 65, 216], 'identify': [35, 66], 'key': [37], 'trends': [38], 'among': [39, 106], 'different': [40, 91, 197], 'types': [41, 92], 'of': [42, 93, 166, 179, 192, 196, 199, 210, 222], 'supervised': [43, 74, 108, 200, 225], 'algorithms,': [46], 'and': [47, 50, 86], 'their': [48, 230], 'performance': [49, 195, 212], 'usage': [51], 'disease': [53, 80, 113, 205], 'risk': [54], 'prediction.': [55, 81, 114, 206], 'Methods': [56], 'In': [57], 'this': [58], 'study,': [59], 'extensive': [60], 'research': [61], 'efforts': [62], 'were': [63, 88], 'made': [64], 'those': [67], 'studies': [68, 154, 181], 'that': [69, 118], 'applied': [70, 126], 'more': [71], 'than': [72], 'one': [73], 'algorithm': [77, 124, 137, 146, 228], 'on': [78], 'single': [79], 'Two': [82], 'databases': [83], '(i.e.,': [84], 'Scopus': [85], 'PubMed)': [87], 'searched': [89], 'search': [94], 'items.': [95], 'Thus,': [96], 'we': [97], 'selected': [98], '48': [99], 'articles': [100], 'total': [102], 'comparison': [105], 'variants': [107, 198], 'Results': [115], 'We': [116], 'found': [117], 'Support': [120], 'Vector': [121], 'Machine': [122], '(SVM)': [123], 'is': [125], 'most': [127], 'frequently': [128], '(in': [129, 138], '29': [130], 'studies)': [131], 'followed': [132, 172], 'by': [133, 173], 'Naïve': [135], 'Bayes': [136], '23': [139], 'studies).': [140], 'However,': [141], 'Random': [143], 'Forest': [144], '(RF)': [145], 'showed': [147, 160], 'superior': [148], 'accuracy': [149, 163], 'comparatively.': [150], 'Of': [151], '17': [153], 'where': [155], 'it': [156, 182], 'was': [157, 171, 183], 'applied,': [158], 'RF': [159], 'highest': [162], '9': [165], 'them,': [167], 'i.e.,': [168], '53%.': [169], 'SVM': [174], 'which': [175], 'topped': [176], '41%': [178], 'considered.': [184], 'Conclusion': [185], 'provides': [188], 'wide': [190], 'overview': [191], 'relative': [194, 211], 'important': [208], 'information': [209], 'can': [213], 'be': [214], 'used': [215], 'aid': [217], 'researchers': [218], 'selection': [221], 'an': [223], 'appropriate': [224], 'studies.': [231]}",2019,"['Health informatics', 'Computer science', 'Machine learning', 'Artificial intelligence', 'Algorithm', 'Public health', 'Medicine', 'Nursing']","Abstract Background Supervised machine learning algorithms have been a dominant method in the data mining field. Disease prediction using health data has recently shown a potential application area for these methods. This study aims to identify the key trends among different types of supervised machine learning algorithms, and their performance and usage for disease risk prediction. Methods In this study, extensive research efforts were made to identify those studies that applied more than one supervised machine learning algorithm on single disease prediction. Two databases (i.e., Scopus and PubMed) were searched for different types of search items. Thus, we selected 48 articles in total for the comparison among variants supervised machine learning algorithms for disease prediction. Results We found that the Support Vector Machine (SVM) algorithm is applied most frequently (in 29 studies) followed by the Naïve Bayes algorithm (in 23 studies). However, the Random Forest (RF) algorithm showed superior accuracy comparatively. Of the 17 studies where it was applied, RF showed the highest accuracy in 9 of them, i.e., 53%. This was followed by SVM which topped in 41% of the studies it was considered. Conclusion This study provides a wide overview of the relative performance of different variants of supervised machine learning algorithms for disease prediction. This important information of relative performance can be used to aid researchers in the selection of an appropriate supervised machine learning algorithm for their studies."
https://openalex.org/W2898403737,Pulmonary CT Registration Through Supervised Learning With Convolutional Neural Networks,"{'Deformable': [0], 'image': [1, 137], 'registration': [2, 23, 147, 199], 'can': [3, 117, 156], 'be': [4, 118, 157], 'time': [5, 208], 'consuming': [6], 'and': [7, 186, 195], 'often': [8], 'needs': [9], 'extensive': [10], 'parameterization': [11, 205], 'to': [12, 62, 107, 159, 167], 'perform': [13], 'well': [14], 'on': [15, 26, 55, 83, 129], 'a': [16, 21, 27, 34, 39, 63, 96, 152, 168, 177, 183, 202], 'specific': [17], 'application.': [18, 72], 'We': [19, 149], 'present': [20], 'deformable': [22, 198], 'method': [24], 'based': [25], '3-D': [28, 49], 'convolutional': [29], 'neural': [30], 'network,': [31, 162], 'together': [32], 'with': [33, 114, 141], 'framework': [35, 87], 'for': [36, 69, 88, 93, 143, 204, 213], 'training': [37, 94, 154], 'such': [38], 'network.': [40], 'The': [41, 51, 86, 125], 'network': [42, 52], 'directly': [43], 'learns': [44], 'transformations': [45, 58, 92, 100, 113], 'between': [46], 'pairs': [47, 138], 'of': [48, 66, 91, 98, 133, 145], 'images.': [50, 124], 'is': [53, 127], 'trained': [54], 'synthetic': [56], 'random': [57], 'which': [59, 139], 'are': [60, 105], 'applied': [61, 106], 'small': [64, 153], 'set': [65, 155, 173], 'representative': [67], 'images': [68], 'the': [70, 84, 89, 108, 146, 161], 'desired': [71], 'Training,': [73], 'therefore,': [74], 'does': [75], 'not': [76], 'require': [77], 'manually': [78, 210], 'annotated': [79, 211], 'ground': [80], 'truth': [81], 'information': [82], 'deformation.': [85], 'generation': [90], 'uses': [95], 'sequence': [97], 'multiple': [99], 'at': [101, 206], 'different': [102, 178, 184], 'scales': [103], 'that': [104, 151], 'image.': [109], 'This': [110, 189], 'way,': [111], 'complex': [112], 'large': [115], 'displacements': [116], 'modeled': [119], 'without': [120, 201], 'folding': [121], 'or': [122, 209], 'tearing': [123], 'methodology': [126], 'demonstrated': [128], 'public': [130], 'data': [131, 172, 175, 212], 'sets': [132], 'inhale-exhale': [134], 'lung': [135], 'CT': [136, 171], 'come': [140], 'landmarks': [142], 'evaluation': [144], 'quality.': [148], 'show': [150], 'used': [158], 'train': [160], 'while': [163], 'still': [164], 'allowing': [165], 'generalization': [166], 'separate': [169], 'pulmonary': [170], 'containing': [174], 'from': [176], 'patient': [179], 'group,': [180], 'acquired': [181], 'using': [182], 'scanner': [185], 'scan': [187], 'protocol.': [188], 'approach': [190], 'results': [191], 'in': [192], 'an': [193], 'accurate': [194], 'very': [196], 'fast': [197], 'method,': [200], 'requirement': [203], 'test': [207], 'training.': [214]}",2018,"['Computer science', 'Artificial intelligence', 'Image registration', 'Convolutional neural network', 'Ground truth', 'Generalization', 'Set (abstract data type)', 'Pattern recognition (psychology)', 'Data set', 'Computer vision', 'Image (mathematics)', 'Artificial neural network', 'Test set', 'Mathematics', 'Programming language', 'Mathematical analysis']","Deformable image registration can be time consuming and often needs extensive parameterization to perform well on a specific application. We present a deformable registration method based on a 3-D convolutional neural network, together with a framework for training such a network. The network directly learns transformations between pairs of 3-D images. The network is trained on synthetic random transformations which are applied to a small set of representative images for the desired application. Training, therefore, does not require manually annotated ground truth information on the deformation. The framework for the generation of transformations for training uses a sequence of multiple transformations at different scales that are applied to the image. This way, complex transformations with large displacements can be modeled without folding or tearing images. The methodology is demonstrated on public data sets of inhale-exhale lung CT image pairs which come with landmarks for evaluation of the registration quality. We show that a small training set can be used to train the network, while still allowing generalization to a separate pulmonary CT data set containing data from a different patient group, acquired using a different scanner and scan protocol. This approach results in an accurate and very fast deformable registration method, without a requirement for parameterization at test time or manually annotated data for training."
https://openalex.org/W1979828500,Distributed ARTMAP: a neural network for fast distributed supervised learning,"{'Distributed': [0, 72], 'coding': [1, 130, 140], 'at': [2, 128], 'the': [3, 12, 78, 109, 129], 'hidden': [4], 'layer': [5], 'of': [6, 81, 101, 108], 'a': [7, 68, 87, 119], 'multi-layer': [8], 'perceptron': [9], '(MLP)': [10], 'endows': [11], 'network': [13, 90], 'with': [14, 51], 'memory': [15, 121, 154], 'compression': [16], 'and': [17, 83], 'noise': [18], 'tolerance': [19], 'capabilities.': [20], 'However,': [21, 55], 'an': [22, 34], 'MLP': [23, 82], 'typically': [24, 58], 'requires': [25, 59], 'slow': [26], 'off-line': [27], 'learning': [28], 'to': [29, 46, 76, 136], 'avoid': [30], 'catastrophic': [31], 'forgetting': [32], 'in': [33, 67, 86], 'open': [35], 'input': [36, 70], 'environment.': [37, 71], 'An': [38, 94], 'adaptive': [39], 'resonance': [40], 'theory': [41], '(ART)': [42], 'model': [43], 'is': [44, 141], 'designed': [45], 'guarantee': [47], 'stable': [48], 'memories': [49], 'even': [50], 'fast': [52], 'on-line': [53], 'learning.': [54, 93], 'ART': [56, 84], 'stability': [57], 'winner-take-all': [60], 'coding,': [61], 'which': [62], 'may': [63], 'cause': [64], 'category': [65], 'proliferation': [66], 'noisy': [69], 'ARTMAP': [73, 138, 149], '(dARTMAP)': [74], 'seeks': [75], 'combine': [77], 'computational': [79], 'advantages': [80], 'systems': [85], 'real-time': [88], 'neural': [89], 'for': [91, 124], 'supervised': [92], 'implementation': [95], 'algorithm': [96], 'here': [97], 'describes': [98], 'one': [99], 'class': [100], 'dARTMAP': [102, 133, 146], 'networks.': [103], 'This': [104], 'system': [105, 134], 'incorporates': [106], 'elements': [107], 'unsupervised': [110], 'dART': [111], 'model,': [112], 'as': [113, 115], 'well': [114], 'new': [116], 'features,': [117], 'including': [118], 'content-addressable': [120], '(CAM)': [122], 'rule': [123], 'improved': [125], 'contrast': [126], 'control': [127], 'field.': [131], 'A': [132], 'reduces': [135], 'fuzzy': [137, 148], 'when': [139], 'winner-take-all.': [142], 'Simulations': [143], 'show': [144], 'that': [145], 'retains': [147], 'accuracy': [150], 'while': [151], 'significantly': [152], 'improving': [153], 'compression.': [155]}",1998,"['Computer science', 'Adaptive resonance theory', 'Artificial intelligence', 'Artificial neural network', 'Perceptron', 'Coding (social sciences)', 'Supervised learning', 'Forgetting', 'Neural coding', 'Learning rule', 'Multilayer perceptron', 'Machine learning', 'Pattern recognition (psychology)', 'Linguistics', 'Statistics', 'Philosophy', 'Mathematics']","Distributed coding at the hidden layer of a multi-layer perceptron (MLP) endows the network with memory compression and noise tolerance capabilities. However, an MLP typically requires slow off-line learning to avoid catastrophic forgetting in an open input environment. An adaptive resonance theory (ART) model is designed to guarantee stable memories even with fast on-line learning. However, ART stability typically requires winner-take-all coding, which may cause category proliferation in a noisy input environment. Distributed ARTMAP (dARTMAP) seeks to combine the computational advantages of MLP and ART systems in a real-time neural network for supervised learning. An implementation algorithm here describes one class of dARTMAP networks. This system incorporates elements of the unsupervised dART model, as well as new features, including a content-addressable memory (CAM) rule for improved contrast control at the coding field. A dARTMAP system reduces to fuzzy ARTMAP when coding is winner-take-all. Simulations show that dARTMAP retains fuzzy ARTMAP accuracy while significantly improving memory compression."
https://openalex.org/W3174697924,Generative Semi-supervised Learning for Multivariate Time Series Imputation,"{'The': [0, 70], 'missing': [1, 49, 87, 139], 'values,': [2], 'widely': [3], 'existed': [4], 'in': [5, 29, 52, 169], 'multivariate': [6, 53], 'time': [7, 16, 31, 54, 75], 'series': [8, 17, 32, 55, 76], 'data,': [9, 77], 'hinder': [10], 'the': [11, 26, 82, 86, 99, 110, 114, 118, 128, 133, 143, 148, 173], 'effective': [12], 'data': [13, 96, 145], 'analysis.': [14], 'Existing': [15], 'imputation': [18, 51], 'methods': [19], 'do': [20], 'not': [21], 'make': [22], 'full': [23], 'use': [24], 'of': [25, 59, 74], 'label': [27], 'information': [28], 'real-life': [30], 'data.': [33, 56], 'In': [34], 'this': [35], 'paper,': [36], 'we': [37, 122], 'propose': [38], 'a': [39, 63, 65, 68, 104, 164], 'novel': [40], 'semi-supervised': [41], 'generative': [42], 'adversarial': [43], 'network': [44], 'model,': [45], 'named': [46], 'SSGAN,': [47], 'for': [48], 'value': [50], 'It': [57], 'consists': [58], 'three': [60, 156], 'players,': [61], 'i.e.,': [62], 'generator,': [64], 'discriminator,': [66], 'and': [67, 78, 95, 132], 'classifier.': [69], 'classifier': [71, 134], 'predicts': [72], 'labels': [73, 97], 'thus': [79], 'it': [80], 'drives': [81], 'generator': [83], 'to': [84, 108, 137, 142], 'estimate': [85, 138], 'values': [88, 140], '(or': [89], 'components),': [90], 'conditioned': [91], 'on': [92, 155], 'observed': [93, 115], 'components': [94, 116], 'at': [98], 'same': [100], 'time.': [101], 'We': [102], 'introduce': [103], 'temporal': [105, 129], 'reminder': [106, 130], 'matrix': [107, 131], 'help': [109], 'discriminator': [111], 'better': [112], 'distinguish': [113], 'from': [117], 'imputed': [119], 'ones.': [120], 'Moreover,': [121], 'theoretically': [123], 'prove': [124], 'that,': [125, 161], 'SSGAN': [126, 162], 'using': [127], 'does': [135], 'learn': [136], 'converging': [141], 'true': [144], 'distribution': [146], 'when': [147], 'Nash': [149], 'equilibrium': [150], 'is': [151], 'achieved.': [152], 'Extensive': [153], 'experiments': [154], 'public': [157], 'real-world': [158], 'datasets': [159], 'demonstrate': [160], 'yields': [163], 'more': [165], 'than': [166], '15%': [167], 'gain': [168], 'performance,': [170], 'compared': [171], 'with': [172], 'state-of-the-art': [174], 'methods.': [175]}",2021,"['Discriminator', 'Missing data', 'Imputation (statistics)', 'Classifier (UML)', 'Computer science', 'Multivariate statistics', 'Time series', 'Artificial intelligence', 'Generative model', 'Pattern recognition (psychology)', 'Machine learning', 'Generative grammar', 'Data mining', 'Detector', 'Telecommunications']","The missing values, widely existed in multivariate time series data, hinder the effective data analysis. Existing time series imputation methods do not make full use of the label information in real-life time series data. In this paper, we propose a novel semi-supervised generative adversarial network model, named SSGAN, for missing value imputation in multivariate time series data. It consists of three players, i.e., a generator, a discriminator, and a classifier. The classifier predicts labels of time series data, and thus it drives the generator to estimate the missing values (or components), conditioned on observed components and data labels at the same time. We introduce a temporal reminder matrix to help the discriminator better distinguish the observed components from the imputed ones. Moreover, we theoretically prove that, SSGAN using the temporal reminder matrix and the classifier does learn to estimate missing values converging to the true data distribution when the Nash equilibrium is achieved. Extensive experiments on three public real-world datasets demonstrate that, SSGAN yields a more than 15% gain in performance, compared with the state-of-the-art methods."
https://openalex.org/W4249573750,CERT: Contrastive Self-supervised Learning for Language Understanding,"{'Pretrained': [0], 'language': [1, 12, 53, 77, 112], 'models': [2, 55], 'such': [3], 'as': [4], 'BERT,': [5], 'GPT': [6], 'have': [7], 'shown': [8], 'great': [9], 'effectiveness': [10], 'in': [11, 18], 'understanding.': [13], 'The': [14], 'auxiliary': [15], 'predictive': [16], 'tasks': [17], 'existing': [19], 'pretraining': [20], 'approaches': [21], 'are': [22], 'mostly': [23], 'defined': [24], 'on': [25, 110], 'tokens,': [26], 'thus': [27], 'may': [28], 'not': [29], 'be': [30, 99], 'able': [31], 'to': [32, 95], 'capture': [33], 'sentence-level': [34], 'semantics': [35], 'very': [36], 'well.': [37], 'To': [38], 'address': [39], 'this': [40], 'issue,': [41], 'we': [42], 'propose': [43], 'CERT:': [44], 'Contrastive': [45], 'self-supervised': [46, 58], 'Encoder': [47], 'Representations': [48], 'from': [49, 88], 'Transformers,': [50], 'which': [51], 'pretrains': [52], 'representation': [54], 'using': [56, 70], 'contrastive': [57], 'learning': [59], 'at': [60], 'the': [61, 89], 'sentence': [62], 'level.': [63], 'CERT': [64, 92, 109, 119], 'creates': [65], 'augmentations': [66], 'of': [67], 'original': [68], 'sentences': [69, 86], 'back-translation.': [71], 'Then': [72], 'it': [73], 'finetunes': [74], 'a': [75], 'pretrained': [76], 'encoder': [78], '(e.g.,': [79], 'BERT)': [80], 'by': [81], 'predicting': [82], 'whether': [83], 'two': [84], 'augmented': [85], 'originate': [87], 'same': [90], 'sentence.': [91], 'is': [93], 'simple': [94], 'use': [96], 'and': [97, 117], 'can': [98], 'flexibly': [100], 'plugged': [101], 'into': [102], 'any': [103], 'pretraining-finetuning': [104], 'NLP': [105], 'pipeline.': [106], 'We': [107], 'evaluate': [108], 'three': [111], 'understanding': [113], 'tasks:': [114], 'CoLA,': [115], 'RTE,': [116], 'QNLI.': [118], 'outperforms': [120], 'BERT': [121], 'significantly.&lt;br&gt;': [122]}",2020,"['Computer science', 'Sentence', 'Natural language processing', 'Artificial intelligence', 'Encoder', 'Transformer', 'Pipeline (software)', 'Programming language', 'Voltage', 'Quantum mechanics', 'Physics', 'Operating system']","Pretrained language models such as BERT, GPT have shown great effectiveness in language understanding. The auxiliary predictive tasks in existing pretraining approaches are mostly defined on tokens, thus may not be able to capture sentence-level semantics very well. To address this issue, we propose CERT: Contrastive self-supervised Encoder Representations from Transformers, which pretrains language representation models using contrastive self-supervised learning at the sentence level. CERT creates augmentations of original sentences using back-translation. Then it finetunes a pretrained language encoder (e.g., BERT) by predicting whether two augmented sentences originate from the same sentence. CERT is simple to use and can be flexibly plugged into any pretraining-finetuning NLP pipeline. We evaluate CERT on three language understanding tasks: CoLA, RTE, and QNLI. CERT outperforms BERT significantly.&lt;br&gt;"
https://openalex.org/W2994536315,Self-Supervised Learning of Pretext-Invariant Representations,"{'The': [0], 'goal': [1], 'of': [2, 30, 98, 141, 144], 'self-supervised': [3, 110, 119, 142], 'learning': [4, 111, 129, 143], 'from': [5, 112], 'images': [6, 113], 'is': [7], 'to': [8, 36, 51], 'construct': [9], 'image': [10, 42, 101, 130, 145], 'representations': [11, 37, 49, 70, 131, 146], 'that': [12, 19, 38, 67, 84, 91], 'are': [13, 39], 'semantically': [14], 'meaningful': [15], 'via': [16], 'pretext': [17, 33, 73, 82], 'tasks': [18, 34], 'do': [20], 'not': [21], 'require': [22], 'semantic': [23, 48, 96], 'annotations': [24], 'for': [25, 118, 132], 'a': [26, 79, 106], 'large': [27], 'training': [28], 'set': [29], 'images.': [31], 'Many': [32], 'lead': [35], 'covariant': [40], 'with': [41, 78, 147], 'transformations.': [43, 56], 'We': [44, 75, 89], 'argue': [45], 'that,': [46], 'instead,': [47], 'ought': [50], 'be': [52], 'invariant': [53, 69], 'under': [54], 'such': [55], 'Specifically,': [57], 'we': [58], 'develop': [59], 'Pretext-Invariant': [60], 'Representation': [61], 'Learning': [62], '(PIRL,': [63], 'pronounced': [64], 'as': [65], '""pearl"")': [66], 'learns': [68], 'based': [71], 'on': [72, 114], 'tasks.': [74], 'use': [76], 'PIRL': [77, 92, 124], 'commonly': [80], 'used': [81], 'task': [83], 'involves': [85], 'solving': [86], 'jigsaw': [87], 'puzzles.': [88], 'find': [90], 'substantially': [93], 'improves': [94], 'the': [95, 99, 139], 'quality': [97], 'learned': [100], 'representations.': [102], 'Our': [103], 'approach': [104], 'sets': [105], 'new': [107], 'state-of-the-art': [108], 'in': [109, 128], 'several': [115], 'popular': [116], 'benchmarks': [117], 'learning.': [120], 'Despite': [121], 'being': [122], 'unsupervised,': [123], 'outperforms': [125], 'supervised': [126], 'pre-training': [127], 'object': [133], 'detection.': [134], 'Altogether,': [135], 'our': [136], 'results': [137], 'demonstrate': [138], 'potential': [140], 'good': [148], 'invariance': [149], 'properties.': [150]}",2020,"['Pretext', 'Invariant (physics)', 'Artificial intelligence', 'Computer science', 'Pattern recognition (psychology)', 'Supervised learning', 'Machine learning', 'Mathematics', 'Artificial neural network', 'Politics', 'Mathematical physics', 'Law', 'Political science']","The goal of self-supervised learning from images is to construct image representations that are semantically meaningful via pretext tasks that do not require semantic annotations for a large training set of images. Many pretext tasks lead to representations that are covariant with image transformations. We argue that, instead, semantic representations ought to be invariant under such transformations. Specifically, we develop Pretext-Invariant Representation Learning (PIRL, pronounced as ""pearl"") that learns invariant representations based on pretext tasks. We use PIRL with a commonly used pretext task that involves solving jigsaw puzzles. We find that PIRL substantially improves the semantic quality of the learned image representations. Our approach sets a new state-of-the-art in self-supervised learning from images on several popular benchmarks for self-supervised learning. Despite being unsupervised, PIRL outperforms supervised pre-training in learning image representations for object detection. Altogether, our results demonstrate the potential of self-supervised learning of image representations with good invariance properties."
https://openalex.org/W2127621215,A Fast Stochastic Error-Descent Algorithm for Supervised Learning and Optimization,"{'A': [0, 40, 59], 'parallel': [1], 'stochastic': [2], 'algorithm': [3, 70], 'is': [4, 24, 28, 45, 64], 'investigated': [5], 'for': [6, 92], 'error-descent': [7], 'learning': [8, 34, 62, 72, 95], 'and': [9, 38, 82, 88, 101], 'optimization': [10, 106], 'in': [11, 57, 75, 96], 'deterministic': [12], 'networks': [13], 'of': [14, 36, 85, 113, 133], 'arbitrary': [15], 'topology.': [16], 'No': [17], 'explicit': [18], 'information': [19], 'about': [20], 'internal': [21], 'network': [22], 'structure': [23], 'needed.': [25], 'The': [26], 'method': [27], 'based': [29], 'on': [30], 'the': [31, 68, 80, 86, 129], 'model-free': [32], 'distributed': [33], 'mechanism': [35], 'Dembo': [37], 'Kailath.': [39], 'modified': [41, 69], 'parameter': [42, 51, 115], 'update': [43], 'rule': [44], 'proposed': [46], 'by': [47], 'which': [48], 'each': [49], 'individual': [50], 'vector': [52], 'perturbation': [53], 'contributes': [54], 'a': [55, 111, 121], 'decrease': [56], 'error.': [58], 'substantially': [60], 'faster': [61], 'speed': [63], 'hence': [65], 'allowed.': [66], 'Furthermore,': [67], 'supports': [71], 'time-varying': [73], 'features': [74], 'dynamical': [76], 'networks.': [77, 98], 'We': [78, 103], 'analyze': [79], 'convergence': [81], 'scaling': [83], 'properties': [84], 'algorithm,': [87], 'present': [89], 'simulation': [90], 'results': [91], 'dynamic': [93], 'trajectory': [94], 'recurrent': [97], '1': [99], 'Background': [100], 'Motivation': [102], 'address': [104], 'general': [105], 'tasks': [107], 'that': [108, 119], 'require': [109], 'finding': [110], 'set': [112], 'constant': [114], 'values': [116], 'p': [117], 'i': [118], 'minimize': [120], 'given': [122], 'error': [123, 130], 'functional': [124, 131], 'E(p).': [125], 'For': [126], 'supervised': [127], 'learning,': [128], 'consists': [132], 'some': [134], 'quantitativ...': [135]}",1992,"['Computer science', 'Convergence (economics)', 'Online machine learning', 'Stochastic gradient descent', 'Algorithm', 'Trajectory', 'Scaling', 'Wake-sleep algorithm', 'Gradient descent', 'Perturbation (astronomy)', 'Artificial intelligence', 'Mathematical optimization', 'Generalization error', 'Artificial neural network', 'Mathematics', 'Economics', 'Astronomy', 'Quantum mechanics', 'Economic growth', 'Geometry', 'Physics']","A parallel stochastic algorithm is investigated for error-descent learning and optimization in deterministic networks of arbitrary topology. No explicit information about internal network structure is needed. The method is based on the model-free distributed learning mechanism of Dembo and Kailath. A modified parameter update rule is proposed by which each individual parameter vector perturbation contributes a decrease in error. A substantially faster learning speed is hence allowed. Furthermore, the modified algorithm supports learning time-varying features in dynamical networks. We analyze the convergence and scaling properties of the algorithm, and present simulation results for dynamic trajectory learning in recurrent networks. 1 Background and Motivation We address general optimization tasks that require finding a set of constant parameter values p i that minimize a given error functional E(p). For supervised learning, the error functional consists of some quantitativ..."
https://openalex.org/W1516171683,RTextTools: A Supervised Learning Package for Text Classification,"{'Social': [0], 'scientists': [1, 20], 'have': [2, 21], 'long': [3], 'hand-labeled': [4], 'texts': [5], 'to': [6, 16, 23, 32, 53, 77, 80, 111], 'create': [7], 'datasets': [8], 'useful': [9], 'for': [10, 70, 95, 115], 'studying': [11], 'topics': [12], 'from': [13], 'congressional': [14], 'policymaking': [15], 'media': [17], 'reporting.Many': [18], 'social': [19], 'begun': [22], 'incorporate': [24], 'machine': [25, 34], 'learning': [26, 35], 'into': [27], 'their': [28, 82, 105, 109], 'toolkits.RTextTools': [29], 'was': [30], 'designed': [31], 'make': [33], 'accessible': [36], 'by': [37], 'providing': [38], 'a': [39, 55, 59, 112], 'start-to-finish': [40], 'product': [41], 'in': [42], 'less': [43], 'than': [44], '10': [45], 'steps.After': [46], 'installing': [47], 'RTextTools,': [48], 'the': [49, 67, 84, 88], 'initial': [50], 'step': [51], 'is': [52, 62, 90, 100], 'generate': [54], 'document': [56], 'term': [57], 'matrix.Second,': [58], 'container': [60], 'object': [61], 'created,': [63], 'which': [64], 'holds': [65], 'all': [66], 'objects': [68], 'needed': [69], 'further': [71, 116], 'analysis.Third,': [72], 'users': [73, 102, 107], 'can': [74, 103], 'use': [75], 'up': [76], 'nine': [78], 'algorithms': [79], 'train': [81], 'data.Fourth,': [83], 'data': [85, 110], 'are': [86, 93], 'classified.Fifth,': [87], 'classification': [89], 'summarized.Sixth,': [91], 'functions': [92], 'available': [94], 'performance': [96], 'evaluation.Seventh,': [97], 'ensemble': [98], 'agreement': [99], 'conducted.Eighth,': [101], 'cross-validate': [104], 'data.Finally,': [106], 'write': [108], 'spreadsheet,': [113], 'allowing': [114], 'manual': [117], 'coding': [118], 'if': [119], 'required.': [120]}",2013,"['Computer science', 'Coding (social sciences)', 'Artificial intelligence', 'Machine learning', 'Information retrieval', 'Supervised learning', 'Object (grammar)', 'Ensemble learning', 'Product (mathematics)', 'Social media', 'World Wide Web', 'Geometry', 'Mathematics', 'Artificial neural network', 'Statistics']","Social scientists have long hand-labeled texts to create datasets useful for studying topics from congressional policymaking to media reporting.Many social scientists have begun to incorporate machine learning into their toolkits.RTextTools was designed to make machine learning accessible by providing a start-to-finish product in less than 10 steps.After installing RTextTools, the initial step is to generate a document term matrix.Second, a container object is created, which holds all the objects needed for further analysis.Third, users can use up to nine algorithms to train their data.Fourth, the data are classified.Fifth, the classification is summarized.Sixth, functions are available for performance evaluation.Seventh, ensemble agreement is conducted.Eighth, users can cross-validate their data.Finally, users write their data to a spreadsheet, allowing for further manual coding if required."
https://openalex.org/W2036759514,Efficient supervised learning in networks with binary synapses,"{'Recent': [0], 'experimental': [1], 'studies': [2], 'indicate': [3], 'that': [4, 44, 52, 73, 99, 114, 132, 143, 167, 207, 233], 'synaptic': [5, 165, 182, 195], 'changes': [6, 183], 'induced': [7], 'by': [8, 243], 'neuronal': [9], 'activity': [10], 'are': [11, 184], 'discrete': [12, 25], 'jumps': [13], 'between': [14], 'a': [15, 31, 38, 58, 65, 77, 82, 88, 120, 137, 171, 208, 225], 'small': [16, 146], 'number': [17, 67, 89, 122, 139], 'of': [18, 68, 90, 123, 140], 'stable': [19], 'states.': [20, 230], 'Learning': [21], 'in': [22, 57, 97, 102, 188, 193, 200, 247], 'systems': [23, 245], 'with': [24, 61, 160, 210, 227], 'synapses': [26], 'is': [27, 84, 100, 106, 115, 134, 152, 175, 218, 236], 'known': [28], 'to': [29, 75, 86, 93, 107, 117, 154, 222, 239], 'be': [30, 240], 'computationally': [32], 'hard': [33], 'problem.': [34], 'Here,': [35], 'we': [36, 130, 205], 'study': [37], 'neurobiologically': [39], 'plausible': [40], 'on-line': [41, 112], 'learning': [42, 158], 'algorithm': [43, 113, 151], 'derives': [45], 'from': [46], 'belief': [47], 'propagation': [48], 'algorithms.': [49], 'We': [50, 231], 'show': [51, 131, 206], 'it': [53], 'performs': [54], 'remarkably': [55], 'well': [56], 'model': [59], 'neuron': [60], 'binary': [62, 127], 'synapses,': [63], 'and': [64, 191, 214], 'finite': [66, 121, 138], '“hidden”': [69], 'states': [70, 142, 190, 213, 217], 'per': [71, 126], 'synapse,': [72], 'has': [74], 'learn': [76, 87], 'random': [78], 'classification': [79], 'task.': [80], 'Such': [81], 'system': [83, 103, 209, 226], 'able': [85, 116], 'associations': [91], 'close': [92], 'the': [94, 110, 155, 181, 198], 'theoretical': [95], 'limit': [96], 'time': [98], 'sublinear': [101], 'size.': [104], 'This': [105], 'our': [108], 'knowledge': [109], 'first': [111], 'achieve': [118], 'efficiently': [119], 'patterns': [124], 'learned': [125], 'synapse.': [128], 'Furthermore,': [129], 'performance': [133], 'optimal': [135], 'for': [136, 147, 164], 'hidden': [141, 189, 216], 'becomes': [144], 'very': [145], 'sparse': [148], 'coding.': [149], 'The': [150], 'similar': [153], 'standard': [156], '“perceptron”': [157], 'algorithm,': [159], 'an': [161], 'additional': [162], 'rule': [163, 235], 'transitions': [166], 'occur': [168], 'only': [169, 186], 'if': [170], 'currently': [172], 'presented': [173], 'pattern': [174], '“barely': [176], 'correct.”': [177], 'In': [178], 'this': [179, 234], 'case,': [180], 'metaplastic': [185], '(change': [187], 'not': [192], 'actual': [194], 'state),': [196], 'stabilizing': [197], 'synapse': [199], 'its': [201], 'current': [202], 'state.': [203], 'Finally,': [204], 'two': [211], 'visible': [212, 229], 'K': [215, 228], 'much': [219], 'more': [220], 'robust': [221], 'noise': [223], 'than': [224], 'suggest': [232], 'sufficiently': [237], 'simple': [238], 'easily': [241], 'implemented': [242], 'neurobiological': [244], 'or': [246], 'hardware.': [248]}",2007,"['Computer science', 'Artificial intelligence', 'Binary number', 'Machine learning', 'Mathematics', 'Arithmetic']","Recent experimental studies indicate that synaptic changes induced by neuronal activity are discrete jumps between a small number of stable states. Learning in systems with discrete synapses is known to be a computationally hard problem. Here, we study a neurobiologically plausible on-line learning algorithm that derives from belief propagation algorithms. We show that it performs remarkably well in a model neuron with binary synapses, and a finite number of “hidden” states per synapse, that has to learn a random classification task. Such a system is able to learn a number of associations close to the theoretical limit in time that is sublinear in system size. This is to our knowledge the first on-line algorithm that is able to achieve efficiently a finite number of patterns learned per binary synapse. Furthermore, we show that performance is optimal for a finite number of hidden states that becomes very small for sparse coding. The algorithm is similar to the standard “perceptron” learning algorithm, with an additional rule for synaptic transitions that occur only if a currently presented pattern is “barely correct.” In this case, the synaptic changes are metaplastic only (change in hidden states and not in actual synaptic state), stabilizing the synapse in its current state. Finally, we show that a system with two visible states and K hidden states is much more robust to noise than a system with K visible states. We suggest that this rule is sufficiently simple to be easily implemented by neurobiological systems or in hardware."
https://openalex.org/W101596157,Zero-day malware detection based on supervised learning algorithms of API call signatures,"{'\\n\\t\\t\\t\\t\\tZero-day': [0], 'or': [1], 'unknown': [2], 'malware': [3, 40, 69, 166], 'are': [4, 146, 321], 'created': [5], 'using': [6, 117], 'code': [7, 15], 'obfuscation': [8], 'techniques': [9, 30, 63], 'that': [10, 293, 320], 'can': [11], 'modify': [12], 'the': [13, 22, 35, 42, 79, 88, 92, 100, 104, 108, 115, 128, 135, 152, 160, 179, 243, 287, 323], 'parent': [14], 'to': [16, 64, 98, 126, 148], 'produce': [17], 'offspring': [18], 'copies': [19], 'which': [20, 273], 'have': [21, 51, 191, 238], 'same': [23], 'functionality': [24], 'but': [25], 'with': [26, 41, 70, 209], 'different': [27, 316], 'signatures.': [28], 'Current': [29], 'reported': [31], 'in': [32, 123, 173, 187, 278, 302, 314], 'literature': [33, 279], 'lack': [34], 'capability': [36], 'of': [37, 58, 73, 81, 94, 107, 138, 154, 181, 259, 269, 318], 'detecting': [38, 164, 303], 'zero-day': [39, 68, 165, 304], 'required': [43, 288], 'accuracy': [44, 74], 'and': [45, 53, 66, 75, 102, 132, 150, 184, 223, 233, 237, 263], 'efficiency.': [46], 'In': [47], 'this': [48, 124, 174, 250], 'paper,': [49], 'we': [50, 145], 'proposed': [52], 'evaluated': [54, 239], 'a': [55, 118, 298], 'novel': [56, 295], 'method': [57], 'employing': [59], 'several': [60], 'data': [61, 96, 110, 156, 169, 245], 'mining': [62, 111, 157, 170, 246], 'detect': [65], 'classify': [67], 'high': [71, 254], 'levels': [72], 'efficiency': [76], 'based': [77], 'on': [78], 'frequency': [80], 'Windows': [82], 'API': [83], 'calls.': [84], 'This': [85, 282, 306], 'paper': [86, 307], 'describes': [87], 'methodology': [89], 'employed': [90, 172, 192], 'for': [91, 114, 162, 249, 312], 'collection': [93], 'large': [95, 188], 'sets': [97], 'train': [99], 'classifiers,': [101, 194], 'analyses': [103], 'performance': [105, 136], 'results': [106, 137], 'various': [109, 129], 'algorithms': [112, 140], 'adopted': [113], 'study': [116, 251], 'fully': [119], 'automated': [120, 244], 'tool': [121], 'developed': [122], 'research': [125, 175], 'conduct': [127], 'experimental': [130, 143], 'investigations': [131], 'evaluation.': [133], 'Through': [134], 'these': [139], 'from': [141], 'our': [142, 294], 'analysis,': [144], 'able': [147], 'evaluate': [149], 'discuss': [151], 'advantages': [153], 'one': [155], 'algorithm': [158], 'over': [159], 'other': [161], 'accurately': [163], 'successfully.': [167], 'The': [168], 'framework': [171], 'learns': [176], 'through': [177], 'analysing': [178], 'behavior': [180], 'existing': [182], 'malicious': [183], 'benign': [185], 'codes': [186], 'datasets.': [189], 'We': [190], 'robust': [193], 'namely': [195], 'Na&amp;iuml;ve': [196], 'Bayes': [197], '(NB)': [198], 'Algorithm,': [199, 203, 232], 'k&amp;minus;Nearest': [200], 'Neighbor': [201], '(kNN)': [202], 'Sequential': [204], 'Minimal': [205], 'Optimization': [206], '(SMO)': [207], 'Algorithm': [208], '4': [210], 'differents': [211], 'kernels': [212], '(SMO': [213], '-': [214], 'Normalized': [215], 'PolyKernel,': [216, 219], 'SMO': [217, 220], '&amp;ndash;': [218, 221], 'Puk,': [222], 'SMO-': [224], 'Radial': [225], 'Basis': [226], 'Function': [227], '(RBF)),': [228], 'Backpropagation': [229], 'Neural': [230], 'Networks': [231], 'J48': [234], 'decision': [235], 'tree': [236], 'their': [240], 'performance.': [241], 'Overall,': [242], 'system': [247], 'implemented': [248], 'has': [252, 274], 'achieved': [253, 277], 'true': [255], 'positive': [256, 266], '(TP)': [257], 'rate': [258, 268], 'more': [260], 'than': [261, 271, 286], '98.5%,': [262], 'low': [264], 'false': [265], '(FP)': [267], 'less': [270], '0.025,': [272], 'not': [275], 'been': [276], 'so': [280], 'far.': [281], 'is': [283, 297], 'much': [284], 'higher': [285], 'commercial': [289], 'acceptance': [290], 'level': [291], 'indicating': [292], 'technique': [296], 'major': [299], 'leap': [300], 'forward': [301], 'malware.': [305], 'also': [308], 'offers': [309], 'future': [310], 'directions': [311], 'researchers': [313], 'exploring': [315], 'aspects': [317], 'obfuscations': [319], 'affecting': [322], 'IT': [324], 'world': [325], 'today.\\n\\t\\t\\t\\t': [326]}",2011,"['Computer science', 'Malware', 'C4.5 algorithm', 'Algorithm', 'Data mining', 'Machine learning', 'Naive Bayes classifier', 'Decision tree', 'Artificial neural network', 'Statistical classification', 'Artificial intelligence', 'Support vector machine', 'Operating system']","\n\t\t\t\t\tZero-day or unknown malware are created using code obfuscation techniques that can modify the parent code to produce offspring copies which have the same functionality but with different signatures. Current techniques reported in literature lack the capability of detecting zero-day malware with the required accuracy and efficiency. In this paper, we have proposed and evaluated a novel method of employing several data mining techniques to detect and classify zero-day malware with high levels of accuracy and efficiency based on the frequency of Windows API calls. This paper describes the methodology employed for the collection of large data sets to train the classifiers, and analyses the performance results of the various data mining algorithms adopted for the study using a fully automated tool developed in this research to conduct the various experimental investigations and evaluation. Through the performance results of these algorithms from our experimental analysis, we are able to evaluate and discuss the advantages of one data mining algorithm over the other for accurately detecting zero-day malware successfully. The data mining framework employed in this research learns through analysing the behavior of existing malicious and benign codes in large datasets. We have employed robust classifiers, namely Na&amp;iuml;ve Bayes (NB) Algorithm, k&amp;minus;Nearest Neighbor (kNN) Algorithm, Sequential Minimal Optimization (SMO) Algorithm with 4 differents kernels (SMO - Normalized PolyKernel, SMO &amp;ndash; PolyKernel, SMO &amp;ndash; Puk, and SMO- Radial Basis Function (RBF)), Backpropagation Neural Networks Algorithm, and J48 decision tree and have evaluated their performance. Overall, the automated data mining system implemented for this study has achieved high true positive (TP) rate of more than 98.5%, and low false positive (FP) rate of less than 0.025, which has not been achieved in literature so far. This is much higher than the required commercial acceptance level indicating that our novel technique is a major leap forward in detecting zero-day malware. This paper also offers future directions for researchers in exploring different aspects of obfuscations that are affecting the IT world today.\n\t\t\t\t"
https://openalex.org/W2761781479,Generative Adversarial Networks-Based Semi-Supervised Learning for Hyperspectral Image Classification,"{'Classification': [0], 'of': [1, 42, 78, 92, 184, 200, 210], 'hyperspectral': [2], 'image': [3], '(HSI)': [4], 'is': [5, 28, 71, 104, 123, 132, 169], 'an': [6, 30], 'important': [7], 'research': [8], 'topic': [9], 'in': [10, 161], 'the': [11, 35, 57, 63, 66, 79, 86, 93, 99, 108, 114, 126, 135, 144, 175, 178, 182, 185, 198, 201], 'remote': [12], 'sensing': [13], 'community.': [14], 'Significant': [15], 'efforts': [16], '(e.g.,': [17], 'deep': [18], 'learning)': [19], 'have': [20, 196], 'been': [21], 'concentrated': [22], 'on': [23, 143, 191], 'this': [24, 46], 'task.': [25], 'However,': [26], 'it': [27], 'still': [29], 'open': [31], 'issue': [32], 'to': [33, 106, 134, 163, 177], 'classify': [34], 'high-dimensional': [36], 'HSI': [37, 52, 68, 115, 194], 'with': [38, 206], 'a': [39, 50, 117, 207], 'limited': [40, 80, 208], 'number': [41, 209], 'training': [43], 'samples.': [44, 89, 212], 'In': [45], 'paper,': [47], 'we': [48], 'propose': [49], 'semi-supervised': [51, 148, 167], 'classification': [53, 69, 137], 'method': [54, 70, 95, 203], 'inspired': [55], 'by': [56, 111, 129, 171], 'generative': [58], 'adversarial': [59], 'networks': [60, 155], '(GANs).': [61], 'Unlike': [62], 'supervised': [64], 'methods,': [65], 'proposed': [67, 94, 202], 'semi-supervised,': [72], 'which': [73, 131], 'can': [74], 'make': [75], 'full': [76], 'use': [77], 'labeled': [81, 211], 'samples': [82, 173], 'as': [83, 85, 116], 'well': [84], 'sufficient': [87], 'unlabeled': [88], 'Core': [90], 'ideas': [91], 'are': [96, 141], 'twofold.': [97], 'First,': [98], 'three-dimensional': [100], 'bilateral': [101], 'filter': [102], '(3DBF)': [103], 'adopted': [105], 'extract': [107], 'spectral-spatial': [109, 145], 'features': [110, 128, 146, 179], 'naturally': [112], 'treating': [113], 'volumetric': [118], 'dataset.': [119], 'The': [120, 166], 'spatial': [121], 'information': [122], 'integrated': [124], 'into': [125], 'extracted': [127], '3DBF,': [130], 'propitious': [133], 'subsequent': [136], 'step.': [138], 'Second,': [139], 'GANs': [140], 'trained': [142, 160], 'for': [147], 'learning.': [149], 'A': [150], 'GAN': [151], 'contains': [152], 'two': [153], 'neural': [154], '(i.e.,': [156], 'generator': [157, 176], 'and': [158, 180], 'discriminator)': [159], 'opposition': [162], 'one': [164], 'another.': [165], 'learning': [168], 'achieved': [170], 'adding': [172], 'from': [174], 'increasing': [181], 'dimension': [183], 'classifier': [186], 'output.': [187], 'Experimental': [188], 'results': [189], 'obtained': [190], 'three': [192], 'benchmark': [193], 'datasets': [195], 'confirmed': [197], 'effectiveness': [199], ',': [204], 'especially': [205]}",2017,"['Artificial intelligence', 'Computer science', 'Discriminator', 'Hyperspectral imaging', 'Pattern recognition (psychology)', 'Classifier (UML)', 'Supervised learning', 'Artificial neural network', 'Machine learning', 'Telecommunications', 'Detector']","Classification of hyperspectral image (HSI) is an important research topic in the remote sensing community. Significant efforts (e.g., deep learning) have been concentrated on this task. However, it is still an open issue to classify the high-dimensional HSI with a limited number of training samples. In this paper, we propose a semi-supervised HSI classification method inspired by the generative adversarial networks (GANs). Unlike the supervised methods, the proposed HSI classification method is semi-supervised, which can make full use of the limited labeled samples as well as the sufficient unlabeled samples. Core ideas of the proposed method are twofold. First, the three-dimensional bilateral filter (3DBF) is adopted to extract the spectral-spatial features by naturally treating the HSI as a volumetric dataset. The spatial information is integrated into the extracted features by 3DBF, which is propitious to the subsequent classification step. Second, GANs are trained on the spectral-spatial features for semi-supervised learning. A GAN contains two neural networks (i.e., generator and discriminator) trained in opposition to one another. The semi-supervised learning is achieved by adding samples from the generator to the features and increasing the dimension of the classifier output. Experimental results obtained on three benchmark HSI datasets have confirmed the effectiveness of the proposed method , especially with a limited number of labeled samples."
https://openalex.org/W2980927909,Self-Supervised Learning for ECG-Based Emotion Recognition,"{'We': [0, 83], 'present': [1], 'an': [2, 26], 'electrocardiogram': [3], '(ECG)': [4], '-based': [5], 'emotion': [6, 27, 66, 99, 120], 'recognition': [7, 23, 28, 67, 121], 'system': [8], 'using': [9], 'self-supervised': [10, 49, 87, 137], 'learning.': [11], 'Our': [12, 112], 'proposed': [13, 113], 'architecture': [14], 'consists': [15], 'of': [16, 55, 59, 109, 135], 'two': [17, 70, 123], 'main': [18], 'networks,': [19], 'a': [20], 'signal': [21, 45], 'transformation': [22], 'network': [24, 40, 61], 'and': [25, 69, 80, 128], 'network.': [29], 'First,': [30], 'unlabelled': [31], 'data': [32, 143], 'are': [33, 62, 73], 'used': [34], 'to': [35, 41, 64, 77, 144], 'successfully': [36], 'train': [37], 'the': [38, 48, 53, 56, 65, 90, 93, 106, 110, 116, 133], 'former': [39], 'detect': [42], 'specific': [43], 'pre-determined': [44], 'transformations': [46], 'in': [47, 75, 118, 139], 'learning': [50], 'step.': [51], 'Next,': [52], 'weights': [54], 'convolutional': [57], 'layers': [58, 72], 'this': [60], 'transferred': [63], 'network,': [68], 'dense': [71], 'trained': [74], 'order': [76], 'classify': [78], 'arousal': [79], 'valence': [81], 'scores.': [82], 'show': [84], 'that': [85], 'our': [86, 136], 'approach': [88, 138], 'helps': [89], 'model': [91], 'learn': [92], 'ECG': [94], 'feature': [95], 'manifold': [96], 'required': [97], 'for': [98], 'recognition,': [100], 'performing': [101], 'equal': [102], 'or': [103], 'better': [104], 'than': [105], 'fully-supervised': [107], 'version': [108], 'model.': [111], 'method': [114], 'outperforms': [115], 'state-of-the-art': [117], 'ECG-based': [119], 'with': [122], 'publicly': [124], 'available': [125], 'datasets,': [126], 'SWELL': [127], 'AMIGOS.': [129], 'Further': [130], 'analysis': [131], 'highlights': [132], 'advantage': [134], 'requiring': [140], 'significantly': [141], 'less': [142], 'achieve': [145], 'acceptable': [146], 'results.': [147]}",2020,"['Computer science', 'Artificial intelligence', 'Emotion recognition', 'Pattern recognition (psychology)', 'Supervised learning', 'Feature extraction', 'Emotion classification', 'Machine learning', 'Feature (linguistics)', 'Speech recognition', 'Artificial neural network', 'Philosophy', 'Linguistics']","We present an electrocardiogram (ECG) -based emotion recognition system using self-supervised learning. Our proposed architecture consists of two main networks, a signal transformation recognition network and an emotion recognition network. First, unlabelled data are used to successfully train the former network to detect specific pre-determined signal transformations in the self-supervised learning step. Next, the weights of the convolutional layers of this network are transferred to the emotion recognition network, and two dense layers are trained in order to classify arousal and valence scores. We show that our self-supervised approach helps the model learn the ECG feature manifold required for emotion recognition, performing equal or better than the fully-supervised version of the model. Our proposed method outperforms the state-of-the-art in ECG-based emotion recognition with two publicly available datasets, SWELL and AMIGOS. Further analysis highlights the advantage of our self-supervised approach in requiring significantly less data to achieve acceptable results."
https://openalex.org/W2997131443,Semi-Supervised Learning under Class Distribution Mismatch,"{'Semi-supervised': [0], 'learning': [1, 97], '(SSL)': [2], 'aims': [3], 'to': [4, 60], 'avoid': [5, 91], 'the': [6, 36, 50], 'need': [7], 'for': [8], 'collecting': [9], 'prohibitively': [10], 'expensive': [11], 'labelled': [12, 27], 'training': [13], 'data.': [14], 'Whilst': [15], 'demonstrating': [16], 'impressive': [17], 'performance': [18, 57], 'boost,': [19], 'existing': [20], 'SSL': [21, 75, 133], 'methods': [22, 129], 'artificially': [23], 'assume': [24], 'that': [25, 90], 'small': [26], 'data': [28, 32, 102], 'and': [29, 73, 95, 113, 122, 146], 'large': [30], 'unlabelled': [31, 66, 101], 'are': [33], 'drawn': [34], 'from': [35, 99], 'same': [37], 'class': [38, 46, 135], 'distribution.': [39], 'In': [40], 'a': [41, 78, 117], 'more': [42, 131], 'realistic': [43, 74, 132], 'scenario': [44], 'with': [45, 103], 'distribution': [47, 136], 'mismatch': [48, 137], 'between': [49], 'two': [51], 'sets,': [52], 'they': [53], 'often': [54], 'suffer': [55], 'severe': [56], 'degradation': [58], 'due': [59], 'error': [61, 93], 'propagation': [62], 'introduced': [63], 'by': [64, 77], 'irrelevant': [65], 'samples.': [67, 106], 'Our': [68], 'work': [69], 'addresses': [70], 'this': [71], 'under-studied': [72], 'problem': [76], 'novel': [79], 'algorithm': [80], 'named': [81], 'Uncertainty-Aware': [82], 'Self-Distillation': [83, 112], '(UASD).': [84], 'Specifically,': [85], 'UASD': [86, 124], 'produces': [87], 'soft': [88], 'targets': [89], 'catastrophic': [92], 'propagation,': [94], 'empower': [96], 'effectively': [98], 'unconstrained': [100], 'out-of-distribution': [104], '(OOD)': [105], 'This': [107], 'is': [108], 'based': [109], 'on': [110, 138], 'joint': [111], 'OOD': [114], 'filtering': [115], 'in': [116, 130], 'unified': [118], 'formulation.': [119], 'Without': [120], 'bells': [121], 'whistles,': [123], 'significantly': [125], 'outperforms': [126], 'six': [127], 'state-of-the-art': [128], 'under': [134], 'three': [139], 'popular': [140], 'image': [141], 'classification': [142], 'datasets:': [143], 'CIFAR10,': [144], 'CIFAR100,': [145], 'TinyImageNet.': [147]}",2020,"['Computer science', 'Class (philosophy)', 'Distillation', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Machine learning', 'Training set', 'Distribution (mathematics)', 'Data mining', 'Mathematics', 'Organic chemistry', 'Chemistry', 'Mathematical analysis']","Semi-supervised learning (SSL) aims to avoid the need for collecting prohibitively expensive labelled training data. Whilst demonstrating impressive performance boost, existing SSL methods artificially assume that small labelled data and large unlabelled data are drawn from the same class distribution. In a more realistic scenario with class distribution mismatch between the two sets, they often suffer severe performance degradation due to error propagation introduced by irrelevant unlabelled samples. Our work addresses this under-studied and realistic SSL problem by a novel algorithm named Uncertainty-Aware Self-Distillation (UASD). Specifically, UASD produces soft targets that avoid catastrophic error propagation, and empower learning effectively from unconstrained unlabelled data with out-of-distribution (OOD) samples. This is based on joint Self-Distillation and OOD filtering in a unified formulation. Without bells and whistles, UASD significantly outperforms six state-of-the-art methods in more realistic SSL under class distribution mismatch on three popular image classification datasets: CIFAR10, CIFAR100, and TinyImageNet."
https://openalex.org/W4327525152,Automated Self-Supervised Learning for Recommendation,"{'Graph': [0], 'neural': [1], 'networks': [2], '(GNNs)': [3], 'have': [4], 'emerged': [5], 'as': [6], 'the': [7, 15, 95, 127, 150, 159], 'state-of-the-art': [8], 'paradigm\\nfor': [9], 'collaborative': [10], 'filtering': [11], '(CF).': [12], 'To': [13, 72, 112], 'improve': [14], 'representation': [16], 'quality': [17], 'over\\nlimited': [18], 'labeled': [19], 'data,': [20], 'contrastive': [21, 37, 44], 'learning': [22], 'has': [23], 'attracted': [24], 'attention': [25], 'in\\nrecommendation': [26], 'and': [27, 56, 68, 135, 147], 'benefited': [28], 'graph-based': [29], 'CF': [30], 'model': [31, 160], 'recently.': [32], 'However,': [33], 'the\\nsuccess': [34], 'of': [35, 108, 152], 'most': [36], 'methods': [38], 'heavily': [39], 'relies': [40], 'on': [41, 94], 'manually': [42], 'generating\\neffective': [43], 'views': [45], 'for': [46, 65, 143], 'heuristic-based': [47], 'data': [48, 66, 88], 'augmentation.': [49], 'This': [50], 'does\\nnot': [51], 'generalize': [52], 'across': [53], 'different': [54], 'datasets': [55, 142], 'downstream': [57], 'recommendation': [58], 'tasks,\\nwhich': [59], 'is': [60, 121], 'difficult': [61], 'to': [62, 70, 85], 'be': [63], 'adaptive': [64], 'augmentation': [67, 89, 102, 128], 'robust': [69], 'noise\\nperturbation.': [71], 'fill': [73], 'this': [74, 77], 'crucial': [75], 'gap,': [76], 'work': [78], 'proposes': [79], 'a': [80, 100], 'unified': [81], 'Automated\\nCollaborative': [82], 'Filtering': [83], '(AutoCF)': [84], 'automatically': [86], 'perform': [87], 'for\\nrecommendation.': [90], 'Specifically,': [91], 'we': [92], 'focus': [93], 'generative': [96], 'self-supervised\\nlearning': [97], 'framework': [98], 'with': [99], 'learnable': [101], 'paradigm': [103], 'that': [104], 'benefits': [105], 'the\\nautomated': [106], 'distillation': [107], 'important': [109], 'self-supervised': [110], 'signals.': [111], 'enhance': [113], 'the\\nrepresentation': [114], 'discrimination': [115], 'ability,': [116], 'our': [117], 'masked': [118], 'graph': [119], 'autoencoder': [120], 'designed\\nto': [122], 'aggregate': [123], 'global': [124], 'information': [125], 'during': [126], 'via': [129], 'reconstructing': [130], 'the\\nmasked': [131], 'subgraph': [132], 'structures.': [133], 'Experiments': [134], 'ablation': [136], 'studies': [137], 'are': [138], 'performed': [139], 'on\\nseveral': [140], 'public': [141], 'recommending': [144], 'products,': [145], 'venues,': [146], 'locations.\\nResults': [148], 'demonstrate': [149], 'superiority': [151], 'AutoCF': [153], 'against': [154], 'various': [155], 'baseline': [156], 'methods.\\nWe': [157], 'release': [158], 'implementation': [161], 'at': [162], 'https://github.com/HKUDS/AutoCF.\\n': [163]}",2023,"['Computer science', 'Machine learning', 'Artificial intelligence', 'Autoencoder', 'Collaborative filtering', 'Graph', 'Recommender system', 'Feature learning', 'Deep learning', 'Theoretical computer science']","Graph neural networks (GNNs) have emerged as the state-of-the-art paradigm\nfor collaborative filtering (CF). To improve the representation quality over\nlimited labeled data, contrastive learning has attracted attention in\nrecommendation and benefited graph-based CF model recently. However, the\nsuccess of most contrastive methods heavily relies on manually generating\neffective contrastive views for heuristic-based data augmentation. This does\nnot generalize across different datasets and downstream recommendation tasks,\nwhich is difficult to be adaptive for data augmentation and robust to noise\nperturbation. To fill this crucial gap, this work proposes a unified Automated\nCollaborative Filtering (AutoCF) to automatically perform data augmentation for\nrecommendation. Specifically, we focus on the generative self-supervised\nlearning framework with a learnable augmentation paradigm that benefits the\nautomated distillation of important self-supervised signals. To enhance the\nrepresentation discrimination ability, our masked graph autoencoder is designed\nto aggregate global information during the augmentation via reconstructing the\nmasked subgraph structures. Experiments and ablation studies are performed on\nseveral public datasets for recommending products, venues, and locations.\nResults demonstrate the superiority of AutoCF against various baseline methods.\nWe release the model implementation at https://github.com/HKUDS/AutoCF.\n"
https://openalex.org/W2953139536,Supervised Dictionary Learning,"{'It': [0], 'is': [1, 64], 'now': [2], 'well': [3, 10], 'established': [4], 'that': [5], 'sparse': [6, 23], 'signal': [7], 'models': [8, 24], 'are': [9], 'suited': [11], 'to': [12], 'restoration': [13], 'tasksandcaneffectivelybelearnedfromaudio,image,': [14], 'andvideodata.': [15], 'Recentresearch': [16], 'has': [17], 'been': [18], 'aimed': [19], 'at': [20], 'learning': [21, 56], 'discriminative': [22], 'instead': [25], 'of': [26, 50, 60], 'purely': [27], 'reconstructiveones.': [28], 'Thispaperproposesanewstepinthatdirection,withanovel': [29], 'sparserepresentationforsignalsbelongingtodifferent': [30], 'classesintermsofashared': [31], 'dictionaryandmultiplediscriminativeclassmodels.': [32], 'Thelinearvariantoftheproposed': [33], 'model': [34, 63], 'admits': [35, 45], 'a': [36], 'simple': [37], 'probabilistic': [38], 'interpretation,': [39], 'while': [40], 'its': [41], 'most': [42], 'general': [43], 'variant': [44], 'an': [46], 'interpretation': [47], 'in': [48], 'terms': [49], 'kernels.': [51], 'An': [52], 'optimization': [53], 'framework': [54], 'for': [55], 'all': [57], 'the': [58, 61], 'components': [59], 'proposed': [62], 'presented,': [65], 'along': [66], 'with': [67], 'experimentalresultsonstandardhandwrittendigitand': [68], 'textureclassificationtasks.': [69]}",2008,"['Discriminative model', 'Computer science', 'Artificial intelligence', 'Probabilistic logic', 'Interpretation (philosophy)', 'Class (philosophy)', 'Pattern recognition (psychology)', 'Sparse approximation', 'Representation (politics)', 'Machine learning', 'Simple (philosophy)', 'Politics', 'Philosophy', 'Political science', 'Epistemology', 'Programming language', 'Law']","It is now well established that sparse signal models are well suited to restoration tasksandcaneffectivelybelearnedfromaudio,image, andvideodata. Recentresearch has been aimed at learning discriminative sparse models instead of purely reconstructiveones. Thispaperproposesanewstepinthatdirection,withanovel sparserepresentationforsignalsbelongingtodifferent classesintermsofashared dictionaryandmultiplediscriminativeclassmodels. Thelinearvariantoftheproposed model admits a simple probabilistic interpretation, while its most general variant admits an interpretation in terms of kernels. An optimization framework for learning all the components of the proposed model is presented, along with experimentalresultsonstandardhandwrittendigitand textureclassificationtasks."
https://openalex.org/W2989184872,Dense Depth Estimation in Monocular Endoscopy With Self-Supervised Learning Methods,"{'We': [0], 'present': [1], 'a': [2, 19, 34, 46, 69, 86, 116], 'self-supervised': [3, 91], 'approach': [4, 110], 'to': [5, 42, 89], 'training': [6, 64], 'convolutional': [7], 'neural': [8], 'networks': [9], 'for': [10, 96, 122], 'dense': [11], 'depth': [12, 92], 'estimation': [13, 93], 'from': [14, 40], 'monocular': [15, 30], 'endoscopy': [16, 103], 'data': [17], 'without': [18], 'priori': [20], 'modeling': [21], 'of': [22], 'anatomy': [23], 'or': [24], 'shading.': [25], 'Our': [26], 'method': [27, 51, 79], 'only': [28], 'requires': [29, 52], 'endoscopic': [31], 'videos': [32], 'and': [33, 65], 'multi-view': [35], 'stereo': [36], 'method,': [37], 'e.g.,': [38], 'structure': [39], 'motion,': [41], 'supervise': [43], 'learning': [44], 'in': [45, 62, 100], 'sparse': [47], 'manner.': [48], 'Consequently,': [49], 'our': [50], 'neither': [53], 'manual': [54], 'labeling': [55], 'nor': [56], 'patient': [57], 'computed': [58], 'tomography': [59], '(CT)': [60], 'scan': [61], 'the': [63, 77, 108, 112], 'application': [66], 'phases.': [67], 'In': [68, 85], 'cross-patient': [70], 'experiment': [71], 'using': [72], 'CT': [73], 'scans': [74], 'as': [75], 'groundtruth,': [76], 'proposed': [78, 109], 'achieved': [80], 'submillimeter': [81], 'mean': [82], 'residual': [83], 'error.': [84], 'comparison': [87], 'study': [88], 'recent': [90], 'methods': [94, 114], 'designed': [95], 'natural': [97], 'video': [98], 'on': [99], 'vivo': [101], 'sinus': [102], 'data,': [104], 'we': [105], 'demonstrate': [106], 'that': [107], 'outperforms': [111], 'previous': [113], 'by': [115], 'large': [117], 'margin.': [118], 'The': [119], 'source': [120], 'code': [121], 'this': [123], 'work': [124], 'is': [125], 'publicly': [126], 'available': [127], 'online': [128], 'at': [129], 'https://github.com/lppllppl920/EndoscopyDepthEstimation-Pytorch.': [130]}",2019,"['Artificial intelligence', 'Computer science', 'Monocular', 'Margin (machine learning)', 'Computer vision', 'Convolutional neural network', 'Residual', 'A priori and a posteriori', 'Supervised learning', 'Code (set theory)', 'Pattern recognition (psychology)', 'Artificial neural network', 'Machine learning', 'Algorithm', 'Set (abstract data type)', 'Epistemology', 'Programming language', 'Philosophy']","We present a self-supervised approach to training convolutional neural networks for dense depth estimation from monocular endoscopy data without a priori modeling of anatomy or shading. Our method only requires monocular endoscopic videos and a multi-view stereo method, e.g., structure from motion, to supervise learning in a sparse manner. Consequently, our method requires neither manual labeling nor patient computed tomography (CT) scan in the training and application phases. In a cross-patient experiment using CT scans as groundtruth, the proposed method achieved submillimeter mean residual error. In a comparison study to recent self-supervised depth estimation methods designed for natural video on in vivo sinus endoscopy data, we demonstrate that the proposed approach outperforms the previous methods by a large margin. The source code for this work is publicly available online at https://github.com/lppllppl920/EndoscopyDepthEstimation-Pytorch."
https://openalex.org/W2002287862,Combining supervised learning with color correlograms for content-based image retrieval,"{'Article': [0], 'Free': [1], 'Access': [2], 'Share': [3], 'on': [4, 89, 138], 'Combining': [5], 'supervised': [6], 'learning': [7], 'with': [8], 'color': [9], 'correlograms': [10], 'for': [11], 'content-based': [12], 'image': [13], 'retrieval': [14], 'Authors:': [15], 'Jing': [16], 'Huang': [17], 'Department': [18, 26, 39, 47, 59, 67], 'of': [19, 27, 40, 48, 60, 68, 83], 'Computer': [20, 28, 41, 49, 61, 69], 'Science,': [21, 29, 42, 50, 62, 70], 'Cornell': [22, 30, 43, 51, 63, 71], 'University,': [23, 31, 44, 52, 64, 72], 'Ithaca,': [24, 32, 45, 53, 65, 73], 'NY': [25, 46, 66], 'NYView': [33, 54, 74], 'Profile': [34, 55, 75], ',': [35, 56], 'S.': [36], 'Ravi': [37], 'Kumar': [38], 'Mandar': [57], 'Mitra': [58], 'Authors': [76], 'Info': [77], '&': [78], 'Claims': [79], 'MULTIMEDIA': [80], ""'97:"": [81], 'Proceedings': [82], 'the': [84, 139], 'fifth': [85], 'ACM': [86], 'international': [87], 'conference': [88], 'MultimediaNovember': [90], '1997': [91], 'Pages': [92], '325–334https://doi.org/10.1145/266180.266383Published:01': [93], 'November': [94], '1997Publication': [95], 'History': [96], '94citation876DownloadsMetricsTotal': [97], 'Citations94Total': [98], 'Downloads876Last': [99], '12': [100], 'Months28Last': [101], '6': [102], 'weeks9': [103], 'Get': [104], 'Citation': [105, 107, 145], 'AlertsNew': [106], 'Alert': [108], 'added!This': [109], 'alert': [110, 135], 'has': [111, 130], 'been': [112, 131], 'successfully': [113], 'added': [114], 'and': [115], 'will': [116, 120], 'be': [117, 121], 'sent': [118], 'to:You': [119], 'notified': [122], 'whenever': [123], 'a': [124, 157], 'record': [125], 'that': [126], 'you': [127], 'have': [128], 'chosen': [129], 'cited.To': [132], 'manage': [133], 'your': [134, 150], 'preferences,': [136], 'click': [137], 'button': [140], 'below.Manage': [141], 'my': [142], 'Alerts': [143], 'New': [144, 158], 'Alert!Please': [146], 'log': [147], 'in': [148], 'to': [149, 153, 155], 'account': [151], 'Save': [152], 'BinderSave': [154], 'BinderCreate': [156], 'BinderNameCancelCreateExport': [159], 'CitationPublisher': [160], 'SiteeReaderPDF': [161]}",1997,"['Citation', 'Computer science', 'Library science', 'Information retrieval', 'World Wide Web']","Article Free Access Share on Combining supervised learning with color correlograms for content-based image retrieval Authors: Jing Huang Department of Computer Science, Cornell University, Ithaca, NY Department of Computer Science, Cornell University, Ithaca, NYView Profile , S. Ravi Kumar Department of Computer Science, Cornell University, Ithaca, NY Department of Computer Science, Cornell University, Ithaca, NYView Profile , Mandar Mitra Department of Computer Science, Cornell University, Ithaca, NY Department of Computer Science, Cornell University, Ithaca, NYView Profile Authors Info & Claims MULTIMEDIA '97: Proceedings of the fifth ACM international conference on MultimediaNovember 1997 Pages 325–334https://doi.org/10.1145/266180.266383Published:01 November 1997Publication History 94citation876DownloadsMetricsTotal Citations94Total Downloads876Last 12 Months28Last 6 weeks9 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF"
https://openalex.org/W2167975231,AcceleRater: a web application for supervised learning of behavioral modes from acceleration measurements,"{'AcceleRater': [0], 'provides': [1], 'the': [2], 'means': [3], 'to': [4], 'identify': [5], 'animal': [6], 'behavior,': [7], 'offering': [8], 'a': [9], 'user-friendly': [10], 'tool': [11], 'for': [12], 'ACC-based': [13], 'behavioral': [14], 'annotation,': [15], 'which': [16], 'will': [17], 'be': [18], 'dynamically': [19], 'upgraded': [20], 'and': [21], 'maintained.': [22]}",2014,"['Animal ecology', 'Acceleration', 'Behavioural sciences', 'Computer science', 'Psychology', 'Ecology', 'Biology', 'Physics', 'Psychotherapist', 'Classical mechanics']","AcceleRater provides the means to identify animal behavior, offering a user-friendly tool for ACC-based behavioral annotation, which will be dynamically upgraded and maintained."
https://openalex.org/W2733239165,Dual Supervised Learning,"{'Many': [0], 'supervised': [1, 101, 107], 'learning': [2, 108], 'tasks': [3, 29, 61, 76], 'are': [4], 'emerged': [5], 'in': [6], 'dual': [7, 28, 60, 75, 106], 'forms,': [8], 'e.g.,': [9], 'English-to-French': [10], 'translation': [11], 'vs.': [12, 17, 24], 'French-to-English': [13], 'translation,': [14, 122], 'speech': [15], 'recognition': [16], 'text': [18], 'to': [19, 37, 86], 'speech,': [20], 'and': [21, 63, 78, 125], 'image': [22, 25, 123], 'classification': [23], 'generation.': [26], 'Two': [27], 'have': [30], 'intrinsic': [31], 'connections': [32], 'with': [33], 'each': [34], 'other': [35], 'due': [36], 'the': [38, 56, 71, 81, 88, 97, 111], 'probabilistic': [39, 82], 'correlation': [40, 83], 'between': [41, 84], 'their': [42], 'models.': [43], 'This': [44], 'connection': [45], 'is,': [46], 'however,': [47], 'not': [48], 'effectively': [49], 'utilized': [50], 'today,': [51], 'since': [52], 'people': [53], 'usually': [54], 'train': [55], 'models': [57, 72], 'of': [58, 73, 93, 114], 'two': [59, 74], 'separately': [62], 'independently.': [64], 'In': [65], 'this': [66], 'work,': [67], 'we': [68, 95], 'propose': [69], 'training': [70, 89], 'simultaneously,': [77], 'explicitly': [79], 'exploiting': [80], 'them': [85], 'regularize': [87], 'process.': [90], 'For': [91], 'ease': [92], 'reference,': [94], 'call': [96], 'proposed': [98], 'approach': [99], '\\emph{dual': [100], 'learning}.': [102], 'We': [103], 'demonstrate': [104], 'that': [105], 'can': [109], 'improve': [110], 'practical': [112], 'performances': [113], 'both': [115], 'tasks,': [116], 'for': [117], 'various': [118], 'applications': [119], 'including': [120], 'machine': [121], 'processing,': [124], 'sentiment': [126], 'analysis.': [127]}",2017,"['Dual (grammatical number)', 'Computer science', 'Probabilistic logic', 'Artificial intelligence', 'Machine learning', 'Translation (biology)', 'Natural language processing', 'Process (computing)', 'Speech recognition', 'Supervised learning', 'Machine translation', 'Image (mathematics)', 'Correlation', 'Pattern recognition (psychology)', 'Mathematics', 'Art', 'Gene', 'Biochemistry', 'Literature', 'Artificial neural network', 'Geometry', 'Chemistry', 'Operating system', 'Messenger RNA']","Many supervised learning tasks are emerged in dual forms, e.g., English-to-French translation vs. French-to-English translation, speech recognition vs. text to speech, and image classification vs. image generation. Two dual tasks have intrinsic connections with each other due to the probabilistic correlation between their models. This connection is, however, not effectively utilized today, since people usually train the models of two dual tasks separately and independently. In this work, we propose training the models of two dual tasks simultaneously, and explicitly exploiting the probabilistic correlation between them to regularize the training process. For ease of reference, we call the proposed approach \emph{dual supervised learning}. We demonstrate that dual supervised learning can improve the practical performances of both tasks, for various applications including machine translation, image processing, and sentiment analysis."
https://openalex.org/W2966859223,Graph Convolutional Networks using Heat Kernel for Semi-supervised Learning,"{'Graph': [0], 'convolutional': [1], 'networks': [2], 'gain': [3], 'remarkable': [4], 'success': [5], 'in': [6, 85, 104, 141], 'semi-supervised': [7, 67, 146], 'learning': [8, 17], 'on': [9, 108], 'graph-structured': [10], 'data.': [11], 'The': [12], 'key': [13], 'to': [14, 40, 57, 61, 74, 97, 122], 'graph-based': [15, 66, 145], 'semisupervised': [16], 'is': [18, 72], 'capturing': [19], 'the': [20, 59, 63, 105, 109, 113, 129, 142], 'smoothness': [21, 60, 83, 103], 'of': [22, 65, 82, 116, 131, 144], 'labels': [23], 'or': [24], 'features': [25], 'over': [26, 48], 'nodes': [27, 126], 'exerted': [28], 'by': [29, 134], 'graph': [30, 42, 54, 86], 'structure.': [31, 87], 'Previous': [32], 'methods,': [33, 38], 'spectral': [34], 'methods': [35], 'and': [36, 51, 101, 154], 'spatial': [37], 'devote': [39], 'defining': [41], 'convolution': [43, 55], 'as': [44], 'a': [45], 'weighted': [46], 'average': [47], 'neighboring': [49, 125], 'nodes,': [50], 'then': [52], 'learn': [53], 'kernels': [56], 'leverage': [58], 'improve': [62], 'performance': [64], 'learning.': [68], 'One': [69], 'open': [70], 'challenge': [71], 'how': [73], 'determine': [75, 123], 'appropriate': [76], 'neighborhood': [77], 'that': [78], 'reflects': [79], 'relevant': [80], 'information': [81], 'manifested': [84], 'In': [88], 'this': [89], 'paper,': [90], 'we': [91], 'propose': [92], 'GraphHeat,': [93], 'leveraging': [94], 'heat': [95, 120], 'kernel': [96], 'enhance': [98], 'low-frequency': [99], 'filters': [100], 'enforce': [102], 'signal': [106], 'variation': [107], 'graph.': [110], 'GraphHeat': [111, 137], 'leverages': [112], 'local': [114], 'structure': [115], 'target': [117], 'node': [118], 'under': [119], 'diffusion': [121], 'its': [124], 'flexibly,': [127], 'without': [128], 'constraint': [130], 'order': [132], 'suffered': [133], 'previous': [135], 'methods.': [136], 'achieves': [138], 'state-of-the-art': [139], 'results': [140], 'task': [143], 'classification': [147], 'across': [148], 'three': [149], 'benchmark': [150], 'datasets:': [151], 'Cora,': [152], 'Citeseer': [153], 'Pubmed.': [155]}",2019,"['Computer science', 'Graph', 'Semi-supervised learning', 'Leverage (statistics)', 'Kernel (algebra)', 'Heat kernel', 'Artificial intelligence', 'Graph kernel', 'Theoretical computer science', 'Pattern recognition (psychology)', 'Machine learning', 'Polynomial kernel', 'Mathematics', 'Kernel method', 'Support vector machine', 'Discrete mathematics', 'Mathematical analysis']","Graph convolutional networks gain remarkable success in semi-supervised learning on graph-structured data. The key to graph-based semisupervised learning is capturing the smoothness of labels or features over nodes exerted by graph structure. Previous methods, spectral methods and spatial methods, devote to defining graph convolution as a weighted average over neighboring nodes, and then learn graph convolution kernels to leverage the smoothness to improve the performance of graph-based semi-supervised learning. One open challenge is how to determine appropriate neighborhood that reflects relevant information of smoothness manifested in graph structure. In this paper, we propose GraphHeat, leveraging heat kernel to enhance low-frequency filters and enforce smoothness in the signal variation on the graph. GraphHeat leverages the local structure of target node under heat diffusion to determine its neighboring nodes flexibly, without the constraint of order suffered by previous methods. GraphHeat achieves state-of-the-art results in the task of graph-based semi-supervised classification across three benchmark datasets: Cora, Citeseer and Pubmed."
https://openalex.org/W2106296294,Feature Subset Selection Problem using Wrapper Approach in Supervised Learning,"{'Feature': [0], 'subset': [1, 73, 93, 129], 'selection': [2, 52, 59, 130], 'is': [3, 53], 'of': [4, 10, 15, 21, 30, 57], 'immense': [5], 'importance': [6], 'in': [7], 'the': [8, 27, 40, 114], 'field': [9], 'data': [11, 16], 'mining.The': [12], 'increased': [13], 'dimensionality': [14], 'makes': [17], 'testing': [18], 'and': [19, 35, 88, 110], 'training': [20], 'general': [22], 'classification': [23, 137], 'method': [24], 'difficult.Mining': [25], 'on': [26, 96], 'reduced': [28], 'set': [29], 'attributes': [31, 116], 'reduces': [32], 'computation': [33], 'time': [34], 'also': [36], 'helps': [37], 'to': [38, 43], 'make': [39], 'patterns': [41], 'easier': [42], 'understand.In': [44], 'this': [45], 'paper': [46], 'a': [47, 55], 'wrapper': [48, 63, 120, 133], 'approach': [49, 64, 134], 'for': [50, 72], 'feature': [51, 58, 128], 'proposed.As': [54], 'part': [56], 'step': [60], 'we': [61], 'used': [62], 'with': [65, 76], 'Genetic': [66], 'algorithm': [67, 80], 'as': [68, 92], 'random': [69], 'search': [70], 'technique': [71], 'generation': [74], ',wrapped': [75], 'different': [77], 'classifiers/': [78], 'induction': [79], 'namely': [81, 100], 'decision': [82], 'tree': [83], 'C4.5,': [84], 'NaïveBayes,': [85], 'Bayes': [86], 'networks': [87], 'Radial': [89], 'basis': [90], 'function': [91], 'evaluating': [94], 'mechanism': [95], 'four': [97], 'standard': [98], 'datasets': [99], 'Pima': [101], 'Indians': [102], 'Diabetes': [103], 'Dataset,': [104], 'Breast': [105, 112], 'Cancer,': [106], 'Heart': [107], 'Stat': [108], 'log': [109], 'Wisconsin': [111], 'Cancer.Further': [113], 'relevant': [115], 'identified': [117], 'by': [118], 'proposed': [119, 132], 'are': [121], 'validated': [122], 'using': [123, 131], 'classifiers.Experimental': [124], 'results': [125], 'illustrate,': [126], 'employing': [127], 'has': [135], 'enhanced': [136], 'accuracy.': [138]}",2010,"['Computer science', 'Feature selection', 'Selection (genetic algorithm)', 'Machine learning', 'Artificial intelligence', 'Feature (linguistics)', 'Supervised learning', 'Data mining', 'Artificial neural network', 'Linguistics', 'Philosophy']","Feature subset selection is of immense importance in the field of data mining.The increased dimensionality of data makes testing and training of general classification method difficult.Mining on the reduced set of attributes reduces computation time and also helps to make the patterns easier to understand.In this paper a wrapper approach for feature selection is proposed.As a part of feature selection step we used wrapper approach with Genetic algorithm as random search technique for subset generation ,wrapped with different classifiers/ induction algorithm namely decision tree C4.5, NaïveBayes, Bayes networks and Radial basis function as subset evaluating mechanism on four standard datasets namely Pima Indians Diabetes Dataset, Breast Cancer, Heart Stat log and Wisconsin Breast Cancer.Further the relevant attributes identified by proposed wrapper are validated using classifiers.Experimental results illustrate, employing feature subset selection using proposed wrapper approach has enhanced classification accuracy."
https://openalex.org/W2128638419,Supervised Dictionary Learning,"{'It': [0], 'is': [1, 107], 'now': [2], 'well': [3, 10], 'established': [4], 'that': [5, 48], 'sparse': [6, 34, 53], 'signal': [7], 'models': [8, 35], 'are': [9], 'suited': [11], 'to': [12, 58], 'restoration': [13], 'tasks': [14], 'and': [15, 23, 67, 117], 'can': [16], 'effectively': [17], 'be': [18], 'learned': [19], 'from': [20], 'audio,': [21], 'image,': [22], 'video': [24], 'data.': [25], 'Recent': [26], 'research': [27], 'has': [28], 'been': [29], 'aimed': [30], 'at': [31], 'learning': [32, 99], 'discriminative': [33], 'instead': [36], 'of': [37, 63, 74, 93, 103], 'purely': [38], 'reconstructive': [39], 'ones.': [40], 'This': [41], 'paper': [42], 'proposes': [43], 'a': [44, 51, 64, 79], 'new': [45], 'step': [46], 'in': [47, 61, 91], 'direction,': [49], 'with': [50, 110], 'novel': [52], 'representation': [54], 'for': [55, 98], 'signals': [56], 'belonging': [57], 'different': [59], 'classes': [60], 'terms': [62, 92], 'shared': [65], 'dictionary': [66], 'multiple': [68], 'class-decision': [69], 'functions.': [70], 'The': [71], 'linear': [72], 'variant': [73, 87], 'the': [75, 101, 104], 'proposed': [76, 105], 'model': [77, 106], 'admits': [78, 88], 'simple': [80], 'probabilistic': [81], 'interpretation,': [82], 'while': [83], 'its': [84], 'most': [85], 'general': [86], 'an': [89], 'interpretation': [90], 'kernels.': [94], 'An': [95], 'optimization': [96], 'framework': [97], 'all': [100], 'components': [102], 'presented,': [108], 'along': [109], 'experimental': [111], 'results': [112], 'on': [113], 'standard': [114], 'handwritten': [115], 'digit': [116], 'texture': [118], 'classification': [119], 'tasks.': [120]}",2008,"['Computer science', 'Artificial intelligence', 'Dictionary learning', 'Natural language processing', 'Sparse approximation']","It is now well established that sparse signal models are well suited to restoration tasks and can effectively be learned from audio, image, and video data. Recent research has been aimed at learning discriminative sparse models instead of purely reconstructive ones. This paper proposes a new step in that direction, with a novel sparse representation for signals belonging to different classes in terms of a shared dictionary and multiple class-decision functions. The linear variant of the proposed model admits a simple probabilistic interpretation, while its most general variant admits an interpretation in terms of kernels. An optimization framework for learning all the components of the proposed model is presented, along with experimental results on standard handwritten digit and texture classification tasks."
https://openalex.org/W2157807817,Revisiting Embedding Features for Simple Semi-supervised Learning,"{'Recent': [0], 'work': [1], 'has': [2], 'shown': [3], 'success': [4], 'in': [5, 82], 'us-ing': [6], 'continuous': [7, 128], 'word': [8, 37, 103], 'embeddings': [9], 'learned': [10], 'from': [11], 'unlabeled': [12], 'data': [13], 'as': [14, 24], 'features': [15, 39, 130], 'to': [16], 'improve': [17], 'supervised': [18], 'NLP': [19], 'systems,': [20], 'which': [21, 107], 'is': [22], 're-garded': [23], 'a': [25, 58], 'simple': [26], 'semi-supervised': [27], 'learn-ing': [28], 'mechanism.': [29], 'However,': [30], 'fundamen-tal': [31], 'problems': [32], 'on': [33, 85], 'effectively': [34], 'incorporating': [35], 'the': [36, 41, 66, 78, 86, 96, 102, 108, 113, 116, 119, 125], 'embedding': [38, 67, 104, 129], 'within': [40], 'framework': [42], 'of': [43, 77, 88, 95, 118, 135], 'linear': [44, 80], 'models': [45, 81], 'remain.': [46], 'In': [47], 'this': [48], 'study,': [49], 'we': [50], 'investigate': [51], 'and': [52, 127], 'analyze': [53], 'three': [54], 'different': [55], 'approaches,': [56], 'including': [57], 'new': [59], 'pro-posed': [60], 'distributional': [61, 109], 'prototype': [62, 110], 'approach,': [63], 'for': [64], 'utilizing': [65], 'features.': [68], 'The': [69], 'presented': [70], 'approaches': [71, 98, 120], 'can': [72, 99], 'be': [73], 'integrated': [74], 'into': [75], 'most': [76], 'classical': [79], 'NLP.': [83], 'Experiments': [84], 'task': [87], 'named': [89], 'entity': [90], 'recognition': [91], 'show': [92], 'that': [93], 'each': [94], 'proposed': [97], 'better': [100], 'utilize': [101], 'features,': [105], 'among': [106], 'approach': [111], 'per-forms': [112], 'best.': [114], 'Moreover,': [115], 'combination': [117], 'provides': [121], 'additive': [122], 'im-provements,': [123], 'outperforming': [124], 'dense': [126], 'by': [131], 'nearly': [132], '2': [133], 'points': [134], 'F1': [136], 'score.': [137], '1': [138]}",2014,"['Embedding', 'Word embedding', 'Computer science', 'Word (group theory)', 'Artificial intelligence', 'Simple (philosophy)', 'Task (project management)', 'Machine learning', 'Supervised learning', 'Pattern recognition (psychology)', 'Natural language processing', 'Mathematics', 'Artificial neural network', 'Management', 'Philosophy', 'Epistemology', 'Geometry', 'Economics']","Recent work has shown success in us-ing continuous word embeddings learned from unlabeled data as features to improve supervised NLP systems, which is re-garded as a simple semi-supervised learn-ing mechanism. However, fundamen-tal problems on effectively incorporating the word embedding features within the framework of linear models remain. In this study, we investigate and analyze three different approaches, including a new pro-posed distributional prototype approach, for utilizing the embedding features. The presented approaches can be integrated into most of the classical linear models in NLP. Experiments on the task of named entity recognition show that each of the proposed approaches can better utilize the word embedding features, among which the distributional prototype approach per-forms the best. Moreover, the combination of the approaches provides additive im-provements, outperforming the dense and continuous embedding features by nearly 2 points of F1 score. 1"
https://openalex.org/W2554050192,Detection of false data attacks in smart grid with supervised learning,"{'The': [0, 78], 'threat': [1], 'of': [2, 17, 30, 48, 104, 107, 144], 'false': [3, 83, 90], 'data': [4, 85, 92], 'injection': [5], '(FDI)': [6], 'attacks': [7, 40, 138], 'have': [8, 117], 'raised': [9], 'wide': [10], 'interest': [11], 'in': [12, 41], 'the': [13, 28, 42, 49, 105, 120, 135], 'research': [14], 'and': [15, 37, 61, 89, 99, 110, 129], 'development': [16], 'smart': [18, 43], 'grid': [19], 'security.': [20], 'This': [21], 'paper': [22], 'presents': [23], 'a': [24], 'comparative': [25], 'study': [26], 'on': [27, 96, 113], 'utilization': [29], 'supervised': [31, 66], 'learning': [32, 67], 'classifiers': [33, 54, 70], 'to': [34, 73], 'detect': [35, 126], 'direct': [36, 128], 'stealth': [38, 130], 'FDI': [39, 76, 87, 94, 108, 131], 'grid.': [44], 'A': [45], 'detailed': [46], 'formulation': [47], 'problem': [50], 'for': [51, 134], 'detection': [52], 'with': [53, 58, 102, 139], 'is': [55], 'first': [56], 'described': [57], 'proper': [59], 'assumptions': [60], 'justifications.': [62], 'Three': [63], 'widely': [64], 'used': [65], '(SL)': [68], 'based': [69, 122], 'are': [71, 80], 'chosen': [72], 'design': [74], 'corresponding': [75], 'detectors.': [77], 'performance': [79], 'tested': [81], 'against': [82], 'measurement': [84], '(direct': [86], 'attack)': [88, 95], 'state': [91], '(stealth': [93], 'both': [97, 127], 'balanced': [98], 'imbalanced': [100], 'cases,': [101], 'consideration': [103], 'influence': [106], 'resources': [109], 'magnitudes.': [111], 'Simulations': [112], 'IEEE': [114], '30-bus': [115], 'system': [116], 'shown': [118], 'that': [119], 'SL': [121], 'detectors': [123], 'can': [124], 'effectively': [125], 'attacks,': [132], 'especially': [133], 'more': [136], 'severe': [137], 'large': [140], 'amount': [141], 'or': [142], 'magnitude': [143], 'compromised': [145], 'measurements.': [146]}",2016,"['Computer science', 'Smart grid', 'Foreign direct investment', 'Detector', 'Grid', 'Artificial intelligence', 'Machine learning', 'Data mining', 'Pattern recognition (psychology)', 'Engineering', 'Mathematics', 'Telecommunications', 'Electrical engineering', 'Geometry', 'Law', 'Political science']","The threat of false data injection (FDI) attacks have raised wide interest in the research and development of smart grid security. This paper presents a comparative study on the utilization of supervised learning classifiers to detect direct and stealth FDI attacks in the smart grid. A detailed formulation of the problem for detection with classifiers is first described with proper assumptions and justifications. Three widely used supervised learning (SL) based classifiers are chosen to design corresponding FDI detectors. The performance are tested against false measurement data (direct FDI attack) and false state data (stealth FDI attack) on both balanced and imbalanced cases, with consideration of the influence of FDI resources and magnitudes. Simulations on IEEE 30-bus system have shown that the SL based detectors can effectively detect both direct and stealth FDI attacks, especially for the more severe attacks with large amount or magnitude of compromised measurements."
https://openalex.org/W4294982764,Explainable Intelligent Fault Diagnosis for Nonlinear Dynamic Systems: From Unsupervised to Supervised Learning,"{'The': [0], 'increased': [1], 'complexity': [2], 'and': [3, 51, 71, 95, 127, 143, 172, 186], 'intelligence': [4], 'of': [5, 11, 22, 64, 85, 111, 121], 'automation': [6], 'systems': [7, 42], 'require': [8], 'the': [9, 20, 52, 83, 100, 105, 109, 122, 134, 139, 145, 157, 174], 'development': [10], 'intelligent': [12, 179], 'fault': [13, 54], 'diagnosis': [14], '(IFD)': [15], 'methodologies.': [16], 'By': [17], 'relying': [18], 'on': [19], 'concept': [21], 'a': [23, 44, 61, 77, 86, 89, 118, 164], 'suspected': [24], 'space,': [25], 'this': [26, 112], 'study': [27], 'develops': [28], 'explainable': [29, 178], 'data-driven': [30, 187], 'IFD': [31, 102, 146, 188], 'approaches': [32, 103], 'for': [33, 48, 177, 190], 'nonlinear': [34, 41, 191], 'dynamic': [35, 192], 'systems.': [36, 193], 'More': [37, 74], 'specifically,': [38], 'we': [39, 81], 'parameterize': [40], 'through': [43, 76], 'generalized': [45, 140], 'kernel': [46, 65, 141], 'representation': [47], 'system': [49, 184], 'modeling': [50, 185], 'associated': [53], 'diagnosis.': [55], 'An': [56], 'important': [57], 'result': [58], 'obtained': [59], 'is': [60, 152, 163], 'unified': [62], 'form': [63], 'representations,': [66], 'applicable': [67], 'to': [68, 116, 137, 155, 183], 'both': [69, 125], 'unsupervised': [70, 96, 126], 'supervised': [72, 94, 128], 'learning.': [73], 'importantly,': [75], 'rigorous': [78], 'theoretical': [79], 'analysis,': [80], 'discover': [82], 'existence': [84], 'bridge': [87, 158], '(i.e.,': [88], 'bijective': [90], 'mapping)': [91], 'between': [92, 159], 'some': [93], 'learning-based': [97], 'entities.': [98], 'Notably,': [99], 'designed': [101], 'achieve': [104], 'same': [106], 'performance': [107], 'with': [108], 'use': [110], 'bridge.': [113], 'In': [114], 'order': [115], 'have': [117], 'better': [119], 'understanding': [120], 'results': [123], 'obtained,': [124], 'neural': [129, 150], 'networks': [130], 'are': [131], 'chosen': [132], 'as': [133], 'learning': [135, 180], 'tools': [136], 'identify': [138], 'representations': [142], 'design': [144], 'schemes;': [147], 'an': [148], 'invertible': [149], 'network': [151], 'then': [153], 'employed': [154], 'build': [156], 'them.': [160], 'This': [161], 'article': [162], 'perspective': [165], 'article,': [166], 'whose': [167], 'contribution': [168], 'lies': [169], 'in': [170], 'proposing': [171], 'formalizing': [173], 'fundamental': [175], 'concepts': [176], 'methods,': [181], 'contributing': [182], 'designs': [189]}",2022,"['Computer science', 'Artificial intelligence', 'Unsupervised learning', 'Machine learning', 'Artificial neural network', 'Bridge (graph theory)', 'Supervised learning', 'Kernel (algebra)', 'Nonlinear system', 'Fault detection and isolation', 'Representation (politics)', 'Mathematics', 'Physics', 'Medicine', 'Quantum mechanics', 'Actuator', 'Politics', 'Internal medicine', 'Political science', 'Law', 'Combinatorics']","The increased complexity and intelligence of automation systems require the development of intelligent fault diagnosis (IFD) methodologies. By relying on the concept of a suspected space, this study develops explainable data-driven IFD approaches for nonlinear dynamic systems. More specifically, we parameterize nonlinear systems through a generalized kernel representation for system modeling and the associated fault diagnosis. An important result obtained is a unified form of kernel representations, applicable to both unsupervised and supervised learning. More importantly, through a rigorous theoretical analysis, we discover the existence of a bridge (i.e., a bijective mapping) between some supervised and unsupervised learning-based entities. Notably, the designed IFD approaches achieve the same performance with the use of this bridge. In order to have a better understanding of the results obtained, both unsupervised and supervised neural networks are chosen as the learning tools to identify the generalized kernel representations and design the IFD schemes; an invertible neural network is then employed to build the bridge between them. This article is a perspective article, whose contribution lies in proposing and formalizing the fundamental concepts for explainable intelligent learning methods, contributing to system modeling and data-driven IFD designs for nonlinear dynamic systems."
https://openalex.org/W2953070460,Mean teachers are better role models: Weight-averaged consistency\n targets improve semi-supervised deep learning results,"{'The': [0], 'recently': [1], 'proposed': [2], 'Temporal': [3, 41, 79, 98], 'Ensembling': [4, 42, 99], 'has': [5], 'achieved': [6], 'state-of-the-art\\nresults': [7], 'in': [8], 'several': [9], 'semi-supervised': [10], 'learning': [11, 45], 'benchmarks.': [12], 'It': [13], 'maintains': [14], 'an\\nexponential': [15], 'moving': [16], 'average': [17], 'of': [18, 62, 91, 124, 141], 'label': [19, 63], 'predictions': [20, 26], 'on': [21, 93, 127, 136], 'each': [22], 'training': [23], 'example,': [24], 'and\\npenalizes': [25], 'that': [27, 57, 106], 'are': [28], 'inconsistent': [29], 'with': [30, 95, 101, 139], 'this': [31, 50], 'target.': [32], 'However,': [33], 'because\\nthe': [34], 'targets': [35], 'change': [36], 'only': [37], 'once': [38], 'per': [39], 'epoch,': [40], 'becomes': [43], 'unwieldy\\nwhen': [44], 'large': [46], 'datasets.': [47], 'To': [48], 'overcome': [49], 'problem,': [51], 'we': [52, 120], 'propose': [53], 'Mean\\nTeacher,': [54], 'a': [55, 107], 'method': [56], 'averages': [58], 'model': [59], 'weights': [60], 'instead': [61], 'predictions.': [64], 'As\\nan': [65], 'additional': [66], 'benefit,': [67], 'Mean': [68, 85], 'Teacher': [69, 86], 'improves': [70], 'test': [71], 'accuracy': [72], 'and': [73, 117, 135], 'enables': [74], 'training\\nwith': [75], 'fewer': [76], 'labels': [77, 130], 'than': [78], 'Ensembling.': [80], 'Without': [81], 'changing': [82], 'the': [83, 122, 125, 142], 'network\\narchitecture,': [84], 'achieves': [87], 'an': [88], 'error': [89], 'rate': [90], '4.35%': [92], 'SVHN': [94], '250\\nlabels,': [96], 'outperforming': [97], 'trained': [100], '1000': [102], 'labels.': [103], 'We': [104], 'also\\nshow': [105], 'good': [108], 'network': [109], 'architecture': [110], 'is': [111], 'crucial': [112], 'to': [113, 133, 145], 'performance.': [114], 'Combining': [115], 'Mean\\nTeacher': [116], 'Residual': [118], 'Networks,': [119], 'improve': [121], 'state': [123], 'art': [126], 'CIFAR-10': [128], 'with\\n4000': [129], 'from': [131], '10.55%': [132], '6.28%,': [134], 'ImageNet': [137], '2012': [138], '10%': [140], 'labels\\nfrom': [143], '35.24%': [144], '9.11%.\\n': [146]}",2017,"['Consistency (knowledge bases)', 'Computer science', 'Artificial intelligence', 'Residual', 'Machine learning', 'Algorithm']","The recently proposed Temporal Ensembling has achieved state-of-the-art\nresults in several semi-supervised learning benchmarks. It maintains an\nexponential moving average of label predictions on each training example, and\npenalizes predictions that are inconsistent with this target. However, because\nthe targets change only once per epoch, Temporal Ensembling becomes unwieldy\nwhen learning large datasets. To overcome this problem, we propose Mean\nTeacher, a method that averages model weights instead of label predictions. As\nan additional benefit, Mean Teacher improves test accuracy and enables training\nwith fewer labels than Temporal Ensembling. Without changing the network\narchitecture, Mean Teacher achieves an error rate of 4.35% on SVHN with 250\nlabels, outperforming Temporal Ensembling trained with 1000 labels. We also\nshow that a good network architecture is crucial to performance. Combining Mean\nTeacher and Residual Networks, we improve the state of the art on CIFAR-10 with\n4000 labels from 10.55% to 6.28%, and on ImageNet 2012 with 10% of the labels\nfrom 35.24% to 9.11%.\n"
https://openalex.org/W3041895828,A supervised learning framework for chromatin loop detection in genome-wide contact maps,"{'Abstract': [0], 'Accurately': [1], 'predicting': [2], 'chromatin': [3, 68, 81, 129], 'loops': [4, 82, 130], 'from': [5, 83], 'genome-wide': [6, 36, 84], 'interaction': [7], 'matrices': [8], 'such': [9, 46], 'as': [10, 47], 'Hi-C': [11, 133], 'data': [12, 44], 'is': [13], 'critical': [14], 'to': [15, 127], 'deepening': [16], 'our': [17, 108], 'understanding': [18], 'of': [19, 42, 63, 67, 102], 'proper': [20], 'gene': [21], 'regulation.': [22], 'Current': [23], 'approaches': [24], 'are': [25], 'mainly': [26], 'focused': [27], 'on': [28, 34], 'searching': [29], 'for': [30], 'statistically': [31], 'enriched': [32], 'dots': [33], 'a': [35, 55, 64, 74, 99], 'map.': [37], 'However,': [38], 'given': [39], 'the': [40, 61, 137, 140], 'availability': [41], 'orthogonal': [43], 'types': [45], 'ChIA-PET,': [48], 'HiChIP,': [49], 'Capture': [50], 'Hi-C,': [51], 'and': [52, 94, 119, 135], 'high-throughput': [53], 'imaging,': [54], 'supervised': [56], 'learning': [57], 'approach': [58], 'could': [59], 'facilitate': [60], 'discovery': [62], 'comprehensive': [65], 'set': [66, 101], 'interactions.': [69, 104], 'Here,': [70], 'we': [71], 'present': [72], 'Peakachu,': [73], 'Random': [75], 'Forest': [76], 'classification': [77], 'framework': [78, 126], 'that': [79, 96, 107], 'predicts': [80], 'contact': [85], 'maps.': [86], 'We': [87, 105, 123], 'compare': [88], 'Peakachu': [89, 97], 'with': [90], 'current': [91], 'enrichment-based': [92], 'approaches,': [93], 'find': [95], 'identifies': [98], 'unique': [100], 'short-range': [103], 'show': [106], 'models': [109], 'perform': [110], 'well': [111], 'in': [112, 131], 'different': [113, 116, 121], 'platforms,': [114], 'across': [115, 120], 'sequencing': [117], 'depths,': [118], 'species.': [122], 'apply': [124], 'this': [125], 'predict': [128], '56': [132], 'datasets,': [134], 'release': [136], 'results': [138], 'at': [139], '3D': [141], 'Genome': [142], 'Browser.': [143]}",2020,"['Chromatin', 'Computer science', 'Genome', 'Loop (graph theory)', 'Computational biology', 'Artificial intelligence', 'Biology', 'Genetics', 'DNA', 'Gene', 'Mathematics', 'Combinatorics']","Abstract Accurately predicting chromatin loops from genome-wide interaction matrices such as Hi-C data is critical to deepening our understanding of proper gene regulation. Current approaches are mainly focused on searching for statistically enriched dots on a genome-wide map. However, given the availability of orthogonal data types such as ChIA-PET, HiChIP, Capture Hi-C, and high-throughput imaging, a supervised learning approach could facilitate the discovery of a comprehensive set of chromatin interactions. Here, we present Peakachu, a Random Forest classification framework that predicts chromatin loops from genome-wide contact maps. We compare Peakachu with current enrichment-based approaches, and find that Peakachu identifies a unique set of short-range interactions. We show that our models perform well in different platforms, across different sequencing depths, and across different species. We apply this framework to predict chromatin loops in 56 Hi-C datasets, and release the results at the 3D Genome Browser."
https://openalex.org/W2396770278,Supervised Learning with Quantum-Inspired Tensor Networks,"{'Tensor': [0], 'networks': [1, 25], 'are': [2], 'efficient': [3], 'representations': [4], 'of': [5], 'high-dimensional': [6], 'tensors': [7], 'which': [8], 'have': [9], 'been': [10], 'very': [11], 'successful': [12], 'for': [13, 22, 43], 'physics': [14], 'and': [15, 74], 'mathematics': [16], 'applications.': [17], 'We': [18, 60], 'demonstrate': [19], 'how': [20, 62], 'algorithms': [21], 'optimizing': [23], 'such': [24], 'can': [26], 'be': [27], 'adapted': [28], 'to': [29, 40, 70], 'supervised': [30], 'learning': [31], 'tasks': [32], 'by': [33], 'using': [34], 'matrix': [35], 'product': [36], 'states': [37], '(tensor': [38], 'trains)': [39], 'parameterize': [41], 'models': [42], 'classifying': [44], 'images.': [45], 'For': [46], 'the': [47, 63, 71], 'MNIST': [48], 'data': [49], 'set': [50, 57], 'we': [51], 'obtain': [52], 'less': [53], 'than': [54], '1%': [55], 'test': [56], 'classification': [58], 'error.': [59], 'discuss': [61], 'tensor': [64], 'network': [65], 'form': [66], 'imparts': [67], 'additional': [68], 'structure': [69], 'learned': [72], 'model': [73], 'suggest': [75], 'a': [76], 'possible': [77], 'generative': [78], 'interpretation.': [79]}",2016,"['MNIST database', 'Tensor (intrinsic definition)', 'Artificial intelligence', 'Set (abstract data type)', 'Tensor product', 'Interpretation (philosophy)', 'Computer science', 'Machine learning', 'Matrix (chemical analysis)', 'Matrix multiplication', 'Generative model', 'Generative grammar', 'Theoretical computer science', 'Mathematics', 'Pattern recognition (psychology)', 'Quantum', 'Deep learning', 'Pure mathematics', 'Physics', 'Quantum mechanics', 'Composite material', 'Programming language', 'Materials science']",Tensor networks are efficient representations of high-dimensional tensors which have been very successful for physics and mathematics applications. We demonstrate how algorithms for optimizing such networks can be adapted to supervised learning tasks by using matrix product states (tensor trains) to parameterize models for classifying images. For the MNIST data set we obtain less than 1% test set classification error. We discuss how the tensor network form imparts additional structure to the learned model and suggest a possible generative interpretation.
https://openalex.org/W2911789160,Bayesian semi-supervised learning for uncertainty-calibrated prediction of molecular properties and active learning,"{'We': [0, 18], 'report': [1], 'a': [2], 'statistically': [3], 'principled': [4], 'method': [5], 'to': [6, 27], 'quantify': [7], 'the': [8], 'uncertainty': [9, 22], 'of': [10], 'machine': [11], 'learning': [12], 'models': [13], 'for': [14], 'molecular': [15], 'properties': [16], 'prediction.': [17], 'show': [19], 'that': [20], 'this': [21], 'estimate': [23], 'can': [24], 'be': [25], 'used': [26], 'judiciously': [28], 'design': [29], 'experiments.': [30]}",2019,"['Machine learning', 'Artificial intelligence', 'Active learning (machine learning)', 'Bayesian probability', 'Computer science', 'Uncertainty quantification', 'Bayesian inference']",We report a statistically principled method to quantify the uncertainty of machine learning models for molecular properties prediction. We show that this uncertainty estimate can be used to judiciously design experiments.
https://openalex.org/W2971088236,PRNet: Self-Supervised Learning for Partial-to-Partial Registration,"{'We': [0, 87], 'present': [1], 'a': [2, 73], 'simple,': [3], 'flexible,': [4], 'and': [5, 35, 58, 84, 92, 97], 'general': [6], 'framework': [7], 'titled': [8], 'Partial': [9], 'Registration': [10], 'Network': [11], '(PRNet),': [12], 'for': [13, 23, 52], 'partial-to-partial': [14, 53], 'point': [15], 'cloud': [16], 'registration.': [17], 'Inspired': [18], 'by': [19], 'recently-proposed': [20], 'learning-based': [21, 41], 'methods': [22, 42, 60], 'registration,': [24, 54], 'we': [25], 'use': [26], 'deep': [27], 'networks': [28], 'to': [29, 105], 'tackle': [30], 'non-convexity': [31], 'of': [32], 'the': [33, 44, 100], 'alignment': [34], 'partial': [36, 82], 'correspondence': [37], 'problems.': [38], 'While': [39], 'previous': [40], 'assume': [43], 'entire': [45], 'shape': [46], 'is': [47, 50, 65, 103], 'visible,': [48], 'PRNet': [49, 64, 89], 'suitable': [51], 'outperforming': [55], 'PointNetLK,': [56], 'DCP,': [57], 'non-learning': [59], 'on': [61], 'synthetic': [62], 'data.': [63], 'self-supervised,': [66], 'jointly': [67], 'learning': [68], 'an': [69], 'appropriate': [70], 'geometric': [71], 'representation,': [72], 'keypoint': [74], 'detector': [75], 'that': [76], 'finds': [77], 'points': [78], 'in': [79], 'common': [80], 'between': [81], 'views,': [83], 'keypoint-to-keypoint': [85], 'correspondences.': [86], 'show': [88], 'predicts': [90], 'keypoints': [91], 'correspondences': [93], 'consistently': [94], 'across': [95], 'views': [96], 'objects.': [98], 'Furthermore,': [99], 'learned': [101], 'representation': [102], 'transferable': [104], 'classification.': [106]}",2019,"['Artificial intelligence', 'Computer science', 'Point cloud', 'Representation (politics)', 'Pattern recognition (psychology)', 'Convexity', 'Image registration', 'Computer vision', 'Image (mathematics)', 'Financial economics', 'Politics', 'Economics', 'Political science', 'Law']","We present a simple, flexible, and general framework titled Partial Registration Network (PRNet), for partial-to-partial point cloud registration. Inspired by recently-proposed learning-based methods for registration, we use deep networks to tackle non-convexity of the alignment and partial correspondence problems. While previous learning-based methods assume the entire shape is visible, PRNet is suitable for partial-to-partial registration, outperforming PointNetLK, DCP, and non-learning methods on synthetic data. PRNet is self-supervised, jointly learning an appropriate geometric representation, a keypoint detector that finds points in common between partial views, and keypoint-to-keypoint correspondences. We show PRNet predicts keypoints and correspondences consistently across views and objects. Furthermore, the learned representation is transferable to classification."
https://openalex.org/W2128150566,Towards reconstruction of gene networks from expression data by supervised learning,"{'All': [0], 'the': [1, 4, 10, 14, 19, 27], 'relations': [2], 'between': [3], 'considered': [5], 'genes': [6], 'are': [7], 'consistent': [8], 'with': [9], 'facts': [11], 'reported': [12], 'in': [13], 'literature.': [15], 'This': [16], 'indicates': [17], 'that': [18, 26], 'approach': [20], 'presented': [21], 'here': [22], 'is': [23], 'valid': [24], 'and': [25, 37], 'resulting': [28], 'rules': [29], 'can': [30], 'be': [31], 'used': [32], 'as': [33], 'elements': [34], 'for': [35], 'building': [36], 'explaining': [38], 'gene': [39], 'networks.': [40]}",2003,"['Biology', 'Human genetics', 'Genome Biology', 'Computational biology', 'Gene expression', 'Gene', 'Gene regulatory network', 'Evolutionary biology', 'Genetics', 'Genomics', 'Artificial intelligence', 'Genome', 'Computer science']",All the relations between the considered genes are consistent with the facts reported in the literature. This indicates that the approach presented here is valid and that the resulting rules can be used as elements for building and explaining gene networks.
https://openalex.org/W2055034152,CellClassifier: supervised learning of cellular phenotypes,"{'Abstract': [0], 'Summary:CellClassifier': [1], 'is': [2], 'a': [3], 'tool': [4], 'for': [5, 19, 36], 'classifying': [6], 'single-cell': [7], 'phenotypes': [8], 'in': [9, 45], 'microscope': [10], 'images.': [11], 'It': [12], 'includes': [13], 'several': [14], 'unique': [15], 'and': [16, 31], 'user-friendly': [17], 'features': [18], 'classification': [20], 'using': [21], 'multiclass': [22], 'support': [23], 'vector': [24], 'machines': [25], 'Availability:': [26], 'Source': [27], 'code,': [28], 'user': [29], 'manual': [30], 'SaveObjectSegmentation': [32], 'CellProfiler': [33], 'module': [34], 'available': [35, 54], 'download': [37], 'at': [38, 55], 'www.cellclassifier.ethz.ch': [39], 'under': [40], 'the': [41], 'GPL': [42], 'license': [43], '(implemented': [44], 'Matlab).': [46], 'Contact:': [47], 'pelkmans@imsb.biol.ethz.ch': [48], 'Supplementary': [49, 51], 'information:': [50], 'data': [52], 'are': [53], 'Bioinformatics': [56], 'online.': [57]}",2009,"['Computer science', 'License', 'MIT License', 'Artificial intelligence', 'MATLAB', 'Phenotype', 'Code (set theory)', 'Download', 'Source code', 'Pattern recognition (psychology)', 'Machine learning', 'Set (abstract data type)', 'Biology', 'Programming language', 'Operating system', 'Gene', 'Biochemistry']","Abstract Summary:CellClassifier is a tool for classifying single-cell phenotypes in microscope images. It includes several unique and user-friendly features for classification using multiclass support vector machines Availability: Source code, user manual and SaveObjectSegmentation CellProfiler module available for download at www.cellclassifier.ethz.ch under the GPL license (implemented in Matlab). Contact: pelkmans@imsb.biol.ethz.ch Supplementary information: Supplementary data are available at Bioinformatics online."
https://openalex.org/W2575359483,Revisiting Semi-Supervised Learning for Online Deceptive Review Detection,"{'With': [0], 'more': [1], 'consumers': [2], 'using': [3, 84], 'online': [4, 36], 'opinion': [5, 13, 37, 54], 'reviews': [6, 14, 38, 55], 'to': [7, 32, 42, 75, 80], 'inform': [8], 'their': [9], 'service': [10], 'decision': [11], 'making,': [12], 'have': [15, 30], 'an': [16], 'economical': [17], 'impact': [18], 'on': [19], 'the': [20], 'bottom': [21], 'line': [22], 'of': [23, 59, 88], 'businesses.': [24], 'Unsurprisingly,': [25], 'opportunistic': [26], 'individuals': [27], 'or': [28, 34], 'groups': [29], 'attempted': [31], 'abuse': [33], 'manipulate': [35], '(e.g.,': [39], 'spam': [40, 77], 'reviews)': [41], 'make': [43], 'profits': [44], 'and': [45, 48, 52], 'so': [46], 'on,': [47], 'that': [49], 'detecting': [50], 'deceptive': [51], 'fake': [53], 'is': [56], 'a': [57, 85], 'topic': [58], 'ongoing': [60], 'research': [61], 'interest.': [62], 'In': [63], 'this': [64], 'paper,': [65], 'we': [66], 'explain': [67], 'how': [68], 'semi-supervised': [69], 'learning': [70], 'methods': [71], 'can': [72], 'be': [73], 'used': [74], 'detect': [76], 'reviews,': [78], 'prior': [79], 'demonstrating': [81], 'its': [82], 'utility': [83], 'data': [86], 'set': [87], 'hotel': [89], 'reviews.': [90]}",2017,"['Computer science', 'Sentiment analysis', 'Set (abstract data type)', 'Data science', 'Supervised learning', 'Service (business)', 'Internet privacy', 'Artificial intelligence', 'Marketing', 'Business', 'Artificial neural network', 'Programming language']","With more consumers using online opinion reviews to inform their service decision making, opinion reviews have an economical impact on the bottom line of businesses. Unsurprisingly, opportunistic individuals or groups have attempted to abuse or manipulate online opinion reviews (e.g., spam reviews) to make profits and so on, and that detecting deceptive and fake opinion reviews is a topic of ongoing research interest. In this paper, we explain how semi-supervised learning methods can be used to detect spam reviews, prior to demonstrating its utility using a data set of hotel reviews."
https://openalex.org/W4321227311,Hierarchical Molecular Graph Self-Supervised Learning for property prediction,"{'Abstract': [0], 'Molecular': [1, 95, 117], 'graph': [2, 85], 'representation': [3, 36, 76, 108], 'learning': [4, 29], 'has': [5, 30], 'shown': [6], 'considerable': [7], 'strength': [8], 'in': [9, 34, 54, 69, 139, 176], 'molecular': [10, 21, 35, 70, 130, 157], 'analysis': [11], 'and': [12, 66, 72, 86, 126, 144, 164, 193], 'drug': [13], 'discovery.': [14], 'Due': [15], 'to': [16, 48, 105], 'the': [17, 46, 74, 78, 82, 168, 173, 177, 182], 'difficulty': [18], 'of': [19, 52, 84, 152, 170], 'obtaining': [20, 73], 'property': [22, 110, 158], 'labels,': [23], 'pre-training': [24, 103], 'models': [25], 'based': [26], 'on': [27, 161], 'self-supervised': [28, 150], 'become': [31], 'increasingly': [32], 'popular': [33], 'learning.': [37], 'Notably,': [38], 'Graph': [39, 96, 118], 'Neural': [40, 119], 'Networks': [41], '(GNN)': [42], 'are': [43, 147], 'employed': [44], 'as': [45, 149], 'backbones': [47], 'encode': [49], 'implicit': [50], 'representations': [51, 184], 'molecules': [53], 'most': [55], 'existing': [56], 'works.': [57], 'However,': [58], 'vanilla': [59], 'GNN': [60], 'encoders': [61], 'ignore': [62], 'chemical': [63, 190], 'structural': [64], 'information': [65, 192], 'functions': [67], 'implied': [68], 'motifs,': [71], 'graph-level': [75], 'via': [77], 'READOUT': [79], 'function': [80], 'hinders': [81], 'interaction': [83], 'node': [87], 'representations.': [88, 131], 'In': [89], 'this': [90], 'paper,': [91], 'we': [92, 113, 133], 'propose': [93], 'Hierarchical': [94, 116], 'Self-supervised': [97, 136], 'Learning': [98], '(HiMol),': [99], 'which': [100, 122, 140], 'introduces': [101], 'a': [102, 115], 'framework': [104], 'learn': [106], 'molecule': [107, 183], 'for': [109], 'prediction.': [111], 'First,': [112], 'present': [114], 'Network': [120], '(HMGNN),': [121], 'encodes': [123], 'motif': [124], 'structure': [125], 'extracts': [127], 'node-motif-graph': [128], 'hierarchical': [129], 'Then,': [132], 'introduce': [134], 'Multi-level': [135], 'Pre-training': [137], '(MSP),': [138], 'corresponding': [141], 'multi-level': [142], 'generative': [143], 'predictive': [145], 'tasks': [146, 166], 'designed': [148], 'signals': [151], 'HiMol': [153, 187], 'model.': [154], 'Finally,': [155], 'superior': [156], 'prediction': [159], 'results': [160], 'both': [162], 'classification': [163], 'regression': [165], 'demonstrate': [167], 'effectiveness': [169], 'HiMol.': [171], 'Moreover,': [172], 'visualization': [174], 'performance': [175], 'downstream': [178], 'dataset': [179], 'shows': [180], 'that': [181], 'learned': [185], 'by': [186], 'can': [188], 'capture': [189], 'semantic': [191], 'properties.': [194]}",2023,"['Property (philosophy)', 'Graph', 'Computer science', 'Artificial intelligence', 'Machine learning', 'Theoretical computer science', 'Philosophy', 'Epistemology']","Abstract Molecular graph representation learning has shown considerable strength in molecular analysis and drug discovery. Due to the difficulty of obtaining molecular property labels, pre-training models based on self-supervised learning has become increasingly popular in molecular representation learning. Notably, Graph Neural Networks (GNN) are employed as the backbones to encode implicit representations of molecules in most existing works. However, vanilla GNN encoders ignore chemical structural information and functions implied in molecular motifs, and obtaining the graph-level representation via the READOUT function hinders the interaction of graph and node representations. In this paper, we propose Hierarchical Molecular Graph Self-supervised Learning (HiMol), which introduces a pre-training framework to learn molecule representation for property prediction. First, we present a Hierarchical Molecular Graph Neural Network (HMGNN), which encodes motif structure and extracts node-motif-graph hierarchical molecular representations. Then, we introduce Multi-level Self-supervised Pre-training (MSP), in which corresponding multi-level generative and predictive tasks are designed as self-supervised signals of HiMol model. Finally, superior molecular property prediction results on both classification and regression tasks demonstrate the effectiveness of HiMol. Moreover, the visualization performance in the downstream dataset shows that the molecule representations learned by HiMol can capture chemical semantic information and properties."
https://openalex.org/W3101981467,A Survey on the Explainability of Supervised Machine Learning,"{'Predictions': [0], 'obtained': [1], 'by,': [2], 'e.g.,': [3], 'artificial': [4], 'neural': [5], 'networks': [6], 'have': [7], 'a': [8, 87], 'high': [9], 'accuracy': [10], 'but': [11], 'humans': [12], 'often': [13], 'perceive': [14], 'the': [15, 22, 32, 51, 74, 103], 'models': [16], 'as': [17, 40], 'black': [18, 52], 'boxes.': [19], 'Insights': [20], 'about': [21], 'decision': [23, 33], 'making': [24, 34], 'are': [25], 'mostly': [26], 'opaque': [27], 'for': [28, 63], 'humans.': [29, 64], 'Particularly': [30], 'understanding': [31], 'in': [35], 'highly': [36], 'sensitive': [37], 'areas': [38], 'such': [39], 'healthcare': [41], 'or': [42], 'finance,': [43], 'is': [44], 'of': [45, 73, 79, 112], 'paramount': [46], 'importance.': [47], 'The': [48], 'decision-making': [49], 'behind': [50], 'boxes': [53], 'requires': [54], 'it': [55], 'to': [56, 102], 'be': [57], 'more': [58], 'transparent,': [59], 'accountable,': [60], 'and': [61, 77, 93, 98, 117], 'understandable': [62], 'This': [65], 'survey': [66, 89], 'paper': [67], 'provides': [68], 'essential': [69], 'definitions,': [70], 'an': [71, 113], 'overview': [72], 'different': [75], 'principles': [76, 109], 'methodologies': [78], 'explainable': [80, 95], 'Supervised': [81], 'Machine': [82], 'Learning': [83], '(SML).': [84], 'We': [85], 'conduct': [86], 'state-of-the-art': [88], 'that': [90], 'reviews': [91], 'past': [92], 'recent': [94], 'SML': [96], 'approaches': [97], 'classifies': [99], 'them': [100], 'according': [101], 'introduced': [104], 'definitions.': [105], 'Finally,': [106], 'we': [107], 'illustrate': [108], 'by': [110], 'means': [111], 'explanatory': [114], 'case': [115], 'study': [116], 'discuss': [118], 'important': [119], 'future': [120], 'directions.': [121]}",2021,"['Computer science', 'Machine learning', 'Artificial intelligence', 'Supervised learning', 'Artificial neural network']","Predictions obtained by, e.g., artificial neural networks have a high accuracy but humans often perceive the models as black boxes. Insights about the decision making are mostly opaque for humans. Particularly understanding the decision making in highly sensitive areas such as healthcare or finance, is of paramount importance. The decision-making behind the black boxes requires it to be more transparent, accountable, and understandable for humans. This survey paper provides essential definitions, an overview of the different principles and methodologies of explainable Supervised Machine Learning (SML). We conduct a state-of-the-art survey that reviews past and recent explainable SML approaches and classifies them according to the introduced definitions. Finally, we illustrate principles by means of an explanatory case study and discuss important future directions."
https://openalex.org/W1653444175,Semi-supervised learning : from Gaussian fields to Gaussian processes,"{'Abstract:': [0], '""We': [1], 'show': [2], 'that': [3], 'the': [4, 30, 50], 'Gaussian': [5, 23], 'random': [6], 'fields': [7], 'and': [8, 40], 'harmonic': [9], 'energy': [10], 'minimizing': [11], 'function': [12], 'framework': [13], 'for': [14], 'semi-supervised': [15], 'learning': [16, 36], 'can': [17], 'be': [18], 'viewed': [19], 'in': [20], 'terms': [21], 'of': [22, 45], 'processes,': [24], 'with': [25, 37], 'covariance': [26], 'matrices': [27], 'derived': [28], 'from': [29], 'graph': [31, 51], 'Laplacian.': [32], 'We': [33], 'derive': [34], 'hyperparameter': [35], 'evidence': [38], 'maximization,': [39], 'give': [41], 'an': [42], 'empirical': [43], 'study': [44], 'various': [46], 'ways': [47], 'to': [48], 'parameterize': [49], 'weights.""': [52]}",1965,"['Gaussian', 'Gaussian random field', 'Gaussian process', 'Covariance', 'Hyperparameter', 'Mathematics', 'Graph', 'Gaussian function', 'Machine learning', 'Maximization', 'Artificial intelligence', 'Computer science', 'Applied mathematics', 'Statistical physics', 'Mathematical optimization', 'Combinatorics', 'Statistics', 'Physics', 'Quantum mechanics']","Abstract: ""We show that the Gaussian random fields and harmonic energy minimizing function framework for semi-supervised learning can be viewed in terms of Gaussian processes, with covariance matrices derived from the graph Laplacian. We derive hyperparameter learning with evidence maximization, and give an empirical study of various ways to parameterize the graph weights."""
https://openalex.org/W1618978521,Safe Feature Elimination for the LASSO and Sparse Supervised Learning Problems,"{'We': [0, 120], 'describe': [1], 'a': [2, 23], 'fast': [3], 'method': [4, 39, 80, 102, 124], 'to': [5, 22, 50, 64, 84, 110, 128], 'eliminate': [6], 'features': [7, 20, 46], '(variables)': [8], 'in': [9, 27], 'l1': [10, 130], '-penalized': [11, 131], 'least-square': [12], 'regression': [13], '(or': [14], 'LASSO)': [15], 'problems.': [16, 147], 'The': [17, 58], 'elimination': [18, 60, 72], 'of': [19, 34, 78, 86, 106, 117], 'leads': [21], 'potentially': [24], 'substantial': [25], 'reduction': [26], 'running': [28], 'time,': [29], 'specially': [30], 'for': [31, 71, 138], 'large': [32], 'values': [33], 'the': [35, 55, 75, 88, 95, 104, 139], 'penalty': [36], 'parameter.': [37], 'Our': [38, 101], 'is': [40, 62, 81, 94], 'not': [41], 'heuristic:': [42], 'it': [43, 93], 'only': [44], 'eliminates': [45], 'that': [47, 85], 'are': [48], 'guaranteed': [49], 'be': [51, 126], 'absent': [52], 'after': [53], 'solving': [54, 87], 'LASSO': [56, 89, 108], 'problem.': [57], 'feature': [59, 70], 'step': [61], 'easy': [63], 'parallelize': [65], 'and': [66, 134, 144], 'can': [67, 125], 'test': [68], 'each': [69], 'independently.': [73], 'Moreover,': [74], 'computational': [76], 'effort': [77], 'our': [79, 123], 'negligible': [82], 'compared': [83], 'problem': [90], '-': [91], 'roughly': [92], 'same': [96], 'as': [97], 'single': [98], 'gradient': [99], 'step.': [100], 'extends': [103], 'scope': [105], 'existing': [107], 'algorithms': [109], 'treat': [111], 'larger': [112], 'data': [113], 'sets,': [114], 'previously': [115], 'out': [116], 'their': [118], 'reach.': [119], 'show': [121], 'how': [122], 'extended': [127], 'general': [129], 'convex': [132], 'problems': [133], 'present': [135], 'preliminary': [136], 'results': [137], 'Sparse': [140], 'Support': [141], 'Vector': [142], 'Machine': [143], 'Logistic': [145], 'Regression': [146]}",2010,"['Lasso (programming language)', 'Elastic net regularization', 'Feature (linguistics)', 'Heuristic', 'Computer science', 'Support vector machine', 'Artificial intelligence', 'Logistic regression', 'Feature selection', 'Regression', 'Machine learning', 'Algorithm', 'Pattern recognition (psychology)', 'Mathematical optimization', 'Mathematics', 'Statistics', 'World Wide Web', 'Philosophy', 'Linguistics']","We describe a fast method to eliminate features (variables) in l1 -penalized least-square regression (or LASSO) problems. The elimination of features leads to a potentially substantial reduction in running time, specially for large values of the penalty parameter. Our method is not heuristic: it only eliminates features that are guaranteed to be absent after solving the LASSO problem. The feature elimination step is easy to parallelize and can test each feature for elimination independently. Moreover, the computational effort of our method is negligible compared to that of solving the LASSO problem - roughly it is the same as single gradient step. Our method extends the scope of existing LASSO algorithms to treat larger data sets, previously out of their reach. We show how our method can be extended to general l1 -penalized convex problems and present preliminary results for the Sparse Support Vector Machine and Logistic Regression problems."
https://openalex.org/W3046208551,"Demystifying Contrastive Self-Supervised Learning: Invariances, Augmentations and Dataset Biases","{'Self-supervised': [0], 'representation': [1], 'learning': [2, 9], 'approaches': [3, 61, 91], 'have': [4], 'recently': [5], 'surpassed': [6], 'their': [7], 'supervised': [8], 'counterparts': [10], 'on': [11, 132, 144], 'downstream': [12, 145], 'tasks': [13], 'like': [14, 62, 103], 'object': [15, 84], 'detection': [16], 'and': [17, 36, 64, 75, 141, 148], 'image': [18, 35, 146], 'classification.': [19], 'Somewhat': [20], 'mysteriously': [21], 'the': [22, 126, 133, 142], 'recent': [23], 'gains': [24, 94], 'in': [25, 136], 'performance': [26, 143], 'come': [27], 'from': [28, 95], 'training': [29, 101], 'instance': [30, 77], 'classification': [31, 147], 'models,': [32], 'treating': [33], 'each': [34], ""it's"": [37], 'augmented': [38], 'versions': [39], 'as': [40], 'samples': [41], 'of': [42, 138], 'a': [43, 98], 'single': [44], 'class.': [45], 'In': [46], 'this': [47], 'work,': [48], 'we': [49, 87, 106], 'first': [50], 'present': [51], 'quantitative': [52], 'experiments': [53], 'to': [54, 72, 97, 110, 114], 'demystify': [55], 'these': [56, 90], 'gains.': [57], 'We': [58], 'demonstrate': [59, 88], 'that': [60, 89, 117, 125], 'MOCO': [63], 'PIRL': [65], 'learn': [66, 115], 'occlusion-invariant': [67], 'representations.': [68], 'However,': [69], 'they': [70], 'fail': [71], 'capture': [73], 'viewpoint': [74, 120], 'category': [76], 'invariance': [78], 'which': [79], 'are': [80], 'crucial': [81], 'components': [82], 'for': [83], 'recognition.': [85], 'Second,': [86], 'obtain': [92], 'further': [93], 'access': [96], 'clean': [99], 'object-centric': [100], 'dataset': [102], 'Imagenet.': [104], 'Finally,': [105], 'propose': [107], 'an': [108], 'approach': [109], 'leverage': [111], 'unstructured': [112], 'videos': [113], 'representations': [116, 128], 'possess': [118], 'higher': [119], 'invariance.': [121], 'Our': [122], 'results': [123], 'show': [124], 'learned': [127], 'outperform': [129], 'MOCOv2': [130], 'trained': [131], 'same': [134], 'data': [135], 'terms': [137], 'invariances': [139], 'encoded': [140], 'semantic': [149], 'segmentation': [150], 'tasks.': [151]}",2020,"['Computer science', 'Artificial intelligence', 'Natural language processing', 'Machine learning', 'Psychology']","Self-supervised representation learning approaches have recently surpassed their supervised learning counterparts on downstream tasks like object detection and image classification. Somewhat mysteriously the recent gains in performance come from training instance classification models, treating each image and it's augmented versions as samples of a single class. In this work, we first present quantitative experiments to demystify these gains. We demonstrate that approaches like MOCO and PIRL learn occlusion-invariant representations. However, they fail to capture viewpoint and category instance invariance which are crucial components for object recognition. Second, we demonstrate that these approaches obtain further gains from access to a clean object-centric training dataset like Imagenet. Finally, we propose an approach to leverage unstructured videos to learn representations that possess higher viewpoint invariance. Our results show that the learned representations outperform MOCOv2 trained on the same data in terms of invariances encoded and the performance on downstream image classification and semantic segmentation tasks."
https://openalex.org/W3173292968,Contrastive and Generative Graph Convolutional Networks for Graph-based Semi-Supervised Learning,"{'Graph-based': [0], 'Semi-Supervised': [1], 'Learning': [2], '(SSL)': [3], 'aims': [4, 95], 'to': [5, 15, 96, 199], 'transfer': [6], 'the': [7, 16, 27, 33, 46, 56, 64, 70, 98, 116, 125, 131, 135, 138, 142, 147, 167, 172, 177, 213], 'labels': [8], 'of': [9, 12, 26, 49, 67, 72, 130, 208, 215], 'a': [10, 22, 89, 112, 194, 206], 'handful': [11], 'labeled': [13, 151], 'data': [14, 20, 104, 133, 136, 145, 152, 182], 'remaining': [17], 'massive': [18], 'unlabeled': [19, 144], 'via': [21, 123, 192], 'graph.': [23], 'As': [24], 'one': [25], 'most': [28], 'popular': [29], 'graph-based': [30, 58], 'SSL': [31, 92, 191], 'approaches,': [32], 'recently': [34], 'proposed': [35], 'Graph': [36], 'Convolutional': [37], 'Networks': [38], '(GCNs)': [39], 'have': [40], 'gained': [41], 'remarkable': [42], 'progress': [43], 'by': [44, 101, 110], 'combining': [45], 'sound': [47], 'expressiveness': [48], 'neural': [50], 'networks': [51], 'with': [52, 220], 'graph': [53, 107, 179, 195], 'structure.': [54, 108], 'Nevertheless,': [55], 'existing': [57], 'methods': [59], 'do': [60], 'not': [61], 'directly': [62], 'address': [63], 'core': [65], 'problem': [66], 'SSL,': [68], '\\emph{i.e.},': [69], 'shortage': [71], 'supervision,': [73], 'and': [74, 106, 146, 181], 'thus': [75], 'their': [76], 'performances': [77], 'are': [78], 'still': [79], 'very': [80], 'limited.': [81], 'To': [82], 'accommodate': [83], 'this': [84, 86], 'issue,': [85], 'paper': [87], 'presents': [88], 'novel': [90], 'GCN-based': [91], 'algorithm': [93, 217], 'which': [94, 164], 'enrich': [97], 'supervision': [99, 157, 188], 'signals': [100, 189], 'utilizing': [102], 'both': [103], 'similarities': [105], 'Firstly,': [109], 'designing': [111], 'semi-supervised': [113], 'contrastive': [114], 'loss,': [115], 'improved': [117], 'node': [118, 162], 'representations': [119], 'can': [120, 153], 'be': [121], 'generated': [122], 'maximizing': [124], 'agreement': [126], 'between': [127, 176], 'different': [128], 'views': [129], 'same': [132, 139], 'or': [134], 'from': [137], 'class.': [140], 'Therefore,': [141], 'rich': [143], 'scarce': [148], 'yet': [149], 'valuable': [150], 'jointly': [154], 'provide': [155], 'abundant': [156], 'information': [158], 'for': [159, 190], 'learning': [160], 'discriminative': [161], 'representations,': [163], 'helps': [165], 'improve': [166], 'subsequent': [168], 'classification': [169], 'result.': [170], 'Secondly,': [171], 'underlying': [173], 'determinative': [174], 'relationship': [175], 'input': [178, 200], 'topology': [180], 'features': [183], 'is': [184], 'extracted': [185], 'as': [186], 'supplementary': [187], 'using': [193], 'generative': [196], 'loss': [197], 'related': [198], 'features.': [201], 'Intensive': [202], 'experimental': [203], 'results': [204], 'on': [205], 'variety': [207], 'real-world': [209], 'datasets': [210], 'firmly': [211], 'verify': [212], 'effectiveness': [214], 'our': [216], 'when': [218], 'compared': [219], 'other': [221], 'state-of-the-art': [222], 'methods.': [223]}",2021,"['Computer science', 'Graph', 'Discriminative model', 'Theoretical computer science', 'Labeled data', 'Artificial intelligence', 'Machine learning', 'Semi-supervised learning', 'Convolutional neural network', 'Data mining', 'Pattern recognition (psychology)']","Graph-based Semi-Supervised Learning (SSL) aims to transfer the labels of a handful of labeled data to the remaining massive unlabeled data via a graph. As one of the most popular graph-based SSL approaches, the recently proposed Graph Convolutional Networks (GCNs) have gained remarkable progress by combining the sound expressiveness of neural networks with graph structure. Nevertheless, the existing graph-based methods do not directly address the core problem of SSL, \emph{i.e.}, the shortage of supervision, and thus their performances are still very limited. To accommodate this issue, this paper presents a novel GCN-based SSL algorithm which aims to enrich the supervision signals by utilizing both data similarities and graph structure. Firstly, by designing a semi-supervised contrastive loss, the improved node representations can be generated via maximizing the agreement between different views of the same data or the data from the same class. Therefore, the rich unlabeled data and the scarce yet valuable labeled data can jointly provide abundant supervision information for learning discriminative node representations, which helps improve the subsequent classification result. Secondly, the underlying determinative relationship between the input graph topology and data features is extracted as supplementary supervision signals for SSL via using a graph generative loss related to input features. Intensive experimental results on a variety of real-world datasets firmly verify the effectiveness of our algorithm when compared with other state-of-the-art methods."
https://openalex.org/W2134134392,Generalized Expectation Criteria for Semi-Supervised Learning of Conditional Random Fields,"{'This': [0, 22], 'paper': [1], 'presents': [2], 'a': [3, 32, 46, 80], 'semi-supervised': [4, 103], 'training': [5, 100], 'method': [6], 'for': [7, 34, 79], 'linear-chain': [8], 'conditional': [9, 52], 'random': [10], 'fields': [11], 'that': [12], 'makes': [13], 'use': [14, 73], 'of': [15, 55, 74], 'labeled': [16, 20], 'features': [17, 58], 'rather': [18], 'than': [19], 'instances.': [21], 'is': [23, 109], 'accomplished': [24], 'by': [25, 86], 'using': [26], 'generalized': [27, 75], 'expectation': [28, 76], 'criteria': [29, 77], 'to': [30, 91], 'express': [31], 'preference': [33], 'parameter': [35], 'settings': [36], 'in': [37, 64, 83], 'which': [38], 'the': [39, 94], 'model’s': [40], 'distribution': [41], 'on': [42], 'unlabeled': [43], 'data': [44], 'matches': [45], 'target': [47, 51], 'distribution.': [48], 'We': [49], 'induce': [50], 'probability': [53], 'distributions': [54], 'labels': [56], 'given': [57], 'from': [59, 88], 'both': [60], 'annotated': [61], 'feature': [62, 68], 'occurrences': [63], 'context': [65], 'and': [66, 93, 101], 'adhoc': [67], 'majority': [69], 'label': [70], 'assignment.': [71], 'The': [72], 'allows': [78], 'dramatic': [81], 'reduction': [82], 'annotation': [84], 'time': [85], 'shifting': [87], 'traditional': [89, 98], 'instance-labeling': [90], 'feature-labeling,': [92], 'methods': [95, 104], 'presented': [96], 'outperform': [97], 'CRF': [99], 'other': [102], 'when': [105], 'limited': [106], 'human': [107], 'effort': [108], 'available.': [110], '1': [111]}",2008,"['Conditional random field', 'Feature (linguistics)', 'Artificial intelligence', 'Computer science', 'Machine learning', 'Context (archaeology)', 'Conditional probability distribution', 'Pattern recognition (psychology)', 'Annotation', 'Probability distribution', 'Reduction (mathematics)', 'Mathematics', 'Statistics', 'Philosophy', 'Linguistics', 'Biology', 'Geometry', 'Paleontology']","This paper presents a semi-supervised training method for linear-chain conditional random fields that makes use of labeled features rather than labeled instances. This is accomplished by using generalized expectation criteria to express a preference for parameter settings in which the model’s distribution on unlabeled data matches a target distribution. We induce target conditional probability distributions of labels given features from both annotated feature occurrences in context and adhoc feature majority label assignment. The use of generalized expectation criteria allows for a dramatic reduction in annotation time by shifting from traditional instance-labeling to feature-labeling, and the methods presented outperform traditional CRF training and other semi-supervised methods when limited human effort is available. 1"
https://openalex.org/W2808701867,Prediction of Slope Stability Using Four Supervised Learning Methods,"{'The': [0, 70, 129, 142], 'analysis': [1, 41], 'and': [2, 40, 59, 81, 98, 106, 111, 140, 147, 156, 163, 196], 'prediction': [3, 130], 'of': [4, 25, 37, 42, 115, 125, 132, 144], 'slope': [5, 11, 31, 38, 47, 55, 57, 100], 'stability': [6, 32], 'are': [7, 186], 'very': [8], 'important,': [9], 'because': [10], 'failure': [12], 'can': [13, 159, 167], 'lead': [14], 'to': [15, 64, 87, 104, 188], 'large': [16], 'disasters.': [17], 'This': [18], 'paper': [19], 'focused': [20], 'on': [21, 35, 194], 'a': [22], 'performance': [23], 'comparison': [24], 'four': [26, 109, 117, 134], 'supervised': [27, 135], 'learning': [28, 136, 178], 'methods': [29, 137], 'for': [30], 'prediction.': [33], 'Based': [34], 'characteristics': [36], 'instability': [39], 'data': [43, 91], 'availability,': [44], 'six': [45], 'typical': [46], 'parameters-the': [48], 'unit': [49], 'weight,': [50], 'cohesion,': [51], 'internal': [52], 'friction': [53], 'angle,': [54], 'inclination,': [56], 'height,': [58], 'pore': [60], 'water': [61], 'ratio-were': [62], 'chosen': [63], 'establish': [65, 88], 'the': [66, 108, 116, 123, 133, 164, 169, 175, 190], 'evaluation': [67], 'index': [68], 'system.': [69], 'gravitational': [71], 'search': [72], 'algorithm': [73], '(GSA),': [74], 'random': [75], 'forest': [76], '(RF),': [77], 'support': [78], 'vector': [79], 'machine,': [80], 'naive': [82], 'Bayesian': [83], '(Bayes)': [84], 'were': [85, 119, 138], 'proposed': [86], 'classifiers.': [89], 'A': [90], 'set': [92], 'from': [93], 'more': [94], 'than': [95], '10': [96], 'domestic': [97], 'abroad': [99], 'projects': [101], 'was': [102], 'established': [103], 'train': [105], 'test': [107], 'classifiers,': [110], 'then,': [112], 'key': [113], 'parameters': [114], 'models': [118, 158, 182], 'optimized': [120], 'by': [121], 'using': [122], 'method': [124], '10-fold': [126], 'cross': [127], 'validation.': [128], 'performances': [131], 'compared': [139, 173], 'analyzed.': [141], 'results': [143, 171], 'accuracy,': [145], 'Kappa,': [146], 'receiver': [148], 'operating': [149], 'characteristic': [150], 'curves': [151], 'reveal': [152], 'that': [153], 'both': [154], 'GSA': [155, 165, 197], 'RF': [157, 195], 'achieve': [160], 'satisfactory': [161], 'results,': [162], 'model': [166], 'obtain': [168, 189], 'best': [170], 'when': [172], 'with': [174, 183], 'other': [176], 'three': [177], 'methods.': [179], 'Finally,': [180], 'seven': [181], 'varying': [184], 'indicators': [185], 'investigated': [187], 'parameter': [191], 'sensitivity': [192], 'based': [193], 'models.': [198]}",2018,"['Random forest', 'Cohesion (chemistry)', 'Naive Bayes classifier', 'Slope stability', 'Artificial intelligence', 'Stability (learning theory)', 'Support vector machine', 'Computer science', 'Machine learning', 'Slope stability analysis', 'Sensitivity (control systems)', 'Receiver operating characteristic', 'Mathematics', 'Engineering', 'Geotechnical engineering', 'Organic chemistry', 'Chemistry', 'Electronic engineering']","The analysis and prediction of slope stability are very important, because slope failure can lead to large disasters. This paper focused on a performance comparison of four supervised learning methods for slope stability prediction. Based on characteristics of slope instability and analysis of data availability, six typical slope parameters-the unit weight, cohesion, internal friction angle, slope inclination, slope height, and pore water ratio-were chosen to establish the evaluation index system. The gravitational search algorithm (GSA), random forest (RF), support vector machine, and naive Bayesian (Bayes) were proposed to establish classifiers. A data set from more than 10 domestic and abroad slope projects was established to train and test the four classifiers, and then, key parameters of the four models were optimized by using the method of 10-fold cross validation. The prediction performances of the four supervised learning methods were compared and analyzed. The results of accuracy, Kappa, and receiver operating characteristic curves reveal that both GSA and RF models can achieve satisfactory results, and the GSA model can obtain the best results when compared with the other three learning methods. Finally, seven models with varying indicators are investigated to obtain the parameter sensitivity based on RF and GSA models."
https://openalex.org/W2148950352,Comparison of supervised learning methods for spike time coding in spiking neural networks,"{'In': [0, 69], 'this': [1, 73, 108], 'review': [2, 109], 'we': [3, 75, 97], 'focus': [4], 'our': [5], 'attention': [6], 'on': [7], 'supervised': [8], 'learning': [9, 81, 88], 'methods': [10], 'for': [11, 44], 'spike': [12], 'time': [13], 'coding': [14, 29, 61], 'in': [15, 30, 47], 'Spiking': [16], 'Neural': [17], 'Networks(SNNs).': [18], 'This': [19], 'study': [20], 'is': [21], 'motivated': [22], 'by': [23], 'recent': [24], 'experimental': [25], 'results': [26, 93], 'regarding': [27], 'information': [28], 'biological': [31], 'neural': [32, 59], 'systems,which': [33], 'suggest': [34], 'that': [35], 'precise': [36], 'timing': [37], 'of': [38, 58, 94, 103, 114], 'individual': [39], 'spikes': [40], 'may': [41], 'be': [42, 63], 'essential': [43], 'efficient': [45], 'computation': [46], 'the': [48, 53, 66, 80, 86, 92, 99, 117], 'brain.': [49], 'We': [50, 106], 'areconcerned': [51], 'with': [52, 65, 110], 'fundamental': [54], 'question:': [55], 'What': [56], 'paradigms': [57], 'temporal': [60], 'can': [62], 'implemented': [64], 'recentlearning': [67], 'methods?': [68], 'order': [70], 'to': [71, 79, 116], 'answer': [72], 'question,': [74], 'discuss': [76, 98], 'various': [77], 'approaches': [78], 'task': [82], 'considered.': [83], 'Weshortly': [84], 'describe': [85], 'particular': [87], 'algorithms': [89], 'and': [90, 101], 'report': [91], 'experiments.': [95], 'Finally,': [96], 'properties,assumptions': [100], 'limitations': [102], 'each': [104], 'method.': [105], 'complete': [107], 'a': [111], 'comprehensive': [112], 'list': [113], 'pointers': [115], 'literature.': [118]}",2006,"['Computer science', 'Spiking neural network', 'Artificial intelligence', 'Coding (social sciences)', 'Neural coding', 'Machine learning', 'Artificial neural network', 'Spike (software development)', 'Supervised learning', 'Focus (optics)', 'Optics', 'Mathematics', 'Statistics', 'Software engineering', 'Physics']","In this review we focus our attention on supervised learning methods for spike time coding in Spiking Neural Networks(SNNs). This study is motivated by recent experimental results regarding information coding in biological neural systems,which suggest that precise timing of individual spikes may be essential for efficient computation in the brain. We areconcerned with the fundamental question: What paradigms of neural temporal coding can be implemented with the recentlearning methods? In order to answer this question, we discuss various approaches to the learning task considered. Weshortly describe the particular learning algorithms and report the results of experiments. Finally, we discuss the properties,assumptions and limitations of each method. We complete this review with a comprehensive list of pointers to the literature."
https://openalex.org/W3082435965,Real-World Anomaly Detection by Using Digital Twin Systems and Weakly Supervised Learning,"{'The': [0, 19, 68, 135], 'continuously': [1], 'growing': [2], 'amount': [3], 'of': [4, 21, 29, 72, 86, 94, 137, 165, 171], 'monitored': [5], 'data': [6, 133], 'in': [7, 44], 'the': [8, 42, 83, 87, 99, 119, 138, 169, 185], 'Industry': [9], '4.0': [10], 'context': [11], 'requires': [12], 'strong': [13], 'and': [14, 113, 177], 'reliable': [15], 'anomaly': [16, 45, 63, 146, 192], 'detection': [17, 46, 64, 147, 193], 'techniques.': [18], 'advancement': [20], 'Digital': [22, 74], 'Twin': [23, 75], 'technologies': [24], 'allows': [25], 'for': [26, 41, 65, 126, 197], 'realistic': [27], 'simulations': [28], 'complex': [30], 'machinery,': [31, 88], 'therefore,': [32], 'it': [33], 'is': [34, 141, 180], 'ideally': [35], 'suited': [36], 'to': [37, 50, 62, 76, 152, 174], 'generate': [38, 77], 'synthetic': [39], 'datasets': [40], 'use': [43, 71], 'approaches': [47, 61, 69, 194], 'when': [48], 'compared': [49, 142], 'actual': [51], 'measurement': [52, 97], 'data.': [53], 'In': [54, 102], 'this': [55], 'paper,': [56], 'we': [57, 104], 'present': [58], 'novel': [59], 'weakly-supervised': [60, 127], 'industrial': [66], 'settings.': [67], 'make': [70], 'a': [73, 78, 91, 106, 114, 153, 157, 163], 'training': [79], 'dataset': [80, 155], 'which': [81, 123], 'simulates': [82], 'normal': [84], 'operation': [85], 'along': [89], 'with': [90, 129], 'small': [92], 'set': [93], 'labeled': [95, 132], 'anomalous': [96], 'from': [98, 156], 'real': [100], 'machinery.': [101], 'particular,': [103], 'introduce': [105], 'clustering-based': [107], 'approach,': [108], 'called': [109], 'Cluster': [110], 'Centers': [111], '(CC),': [112], 'neural': [115], 'architecture': [116, 179], 'based': [117, 188], 'on': [118, 149, 202], 'Siamese': [120], 'Autoencoders': [121], '(SAE),': [122], 'are': [124], 'tailored': [125], 'settings': [128, 201], 'very': [130, 195], 'few': [131], 'samples.': [134], 'performance': [136, 166, 204], 'proposed': [139, 186], 'methods': [140], 'against': [143], 'various': [144], 'state-of-the-art': [145, 191], 'algorithms': [148], 'an': [150], 'application': [151], 'real-world': [154], 'facility': [158], 'monitoring': [159], 'system,': [160], 'by': [161], 'using': [162], 'multitude': [164], 'measures.': [167, 205], 'Also,': [168], 'influence': [170], 'hyper-parameters': [172], 'related': [173], 'feature': [175], 'extraction': [176], 'network': [178], 'investigated.': [181], 'We': [182], 'find': [183], 'that': [184], 'SAE': [187], 'solutions': [189], 'outperform': [190], 'robustly': [196], 'many': [198], 'different': [199], 'hyper-parameter': [200], 'all': [203]}",2020,"['Anomaly detection', 'Computer science', 'Artificial intelligence', 'Supervised learning', 'Machine learning', 'Pattern recognition (psychology)', 'Artificial neural network']","The continuously growing amount of monitored data in the Industry 4.0 context requires strong and reliable anomaly detection techniques. The advancement of Digital Twin technologies allows for realistic simulations of complex machinery, therefore, it is ideally suited to generate synthetic datasets for the use in anomaly detection approaches when compared to actual measurement data. In this paper, we present novel weakly-supervised approaches to anomaly detection for industrial settings. The approaches make use of a Digital Twin to generate a training dataset which simulates the normal operation of the machinery, along with a small set of labeled anomalous measurement from the real machinery. In particular, we introduce a clustering-based approach, called Cluster Centers (CC), and a neural architecture based on the Siamese Autoencoders (SAE), which are tailored for weakly-supervised settings with very few labeled data samples. The performance of the proposed methods is compared against various state-of-the-art anomaly detection algorithms on an application to a real-world dataset from a facility monitoring system, by using a multitude of performance measures. Also, the influence of hyper-parameters related to feature extraction and network architecture is investigated. We find that the proposed SAE based solutions outperform state-of-the-art anomaly detection approaches very robustly for many different hyper-parameter settings on all performance measures."
https://openalex.org/W4210642697,Global and Local Contrastive Self-Supervised Learning for Semantic Segmentation of HR Remote Sensing Images,"{'Supervised': [0], 'learning': [1, 22, 70, 99, 113, 139, 195], 'for': [2, 84, 102, 151, 237], 'semantic': [3, 85, 152], 'segmentation': [4, 86], 'requires': [5], 'a': [6, 32, 36, 46, 56, 93], 'large': [7, 37], 'number': [8, 38], 'of\\nlabeled': [9], 'samples,': [10], 'which': [11, 81, 148, 222], 'is': [12, 55, 141, 149, 223, 245], 'difficult': [13], 'to': [14, 27, 76, 116, 143, 187], 'obtain': [15, 77], 'in': [16, 226], 'the': [17, 109, 130, 165, 183, 188, 227], 'field': [18], 'of': [19, 39, 59, 204, 217, 234], 'remote': [20, 103, 228], 'sensing.\\nSelf-supervised': [21], '(SSL),': [23], 'can': [24, 62, 127], 'be': [25, 233], 'used': [26], 'solve': [28], 'such': [29], 'problems': [30], 'by\\npre-training': [31], 'general': [33, 64], 'model': [34], 'with': [35, 49, 170], 'unlabeled': [40, 220], 'images': [41], 'and': [42, 96, 207], 'then\\nfine-tuning': [43], 'it': [44], 'on': [45, 182], 'downstream': [47, 208], 'task': [48], 'very': [50], 'few': [51], 'labeled': [52], 'samples.': [53], 'Contrastive\\nlearning': [54], 'typical': [57], 'method': [58, 159, 193], 'SSL': [60, 211], 'that': [61, 125, 157], 'learn': [63, 118, 144], 'invariant': [65], 'features.\\nHowever,': [66], 'most': [67], 'existing': [68, 189], 'contrastive': [69, 112, 138], 'methods': [71, 196], 'are': [72, 199], 'designed': [73, 142], 'for\\nclassification': [74], 'tasks': [75, 87, 206], 'an': [78, 119], 'image-level': [79, 120], 'representation,': [80, 121], 'may': [82, 232], 'be\\nsuboptimal': [83], 'requiring': [88], 'pixel-level\\ndiscrimination.': [89], 'Therefore,': [90], 'we': [91, 123], 'propose': [92], 'global': [94, 110, 240], 'style': [95, 111], 'local': [97, 136], 'matching\\ncontrastive': [98], 'network': [100], '(GLCNet)': [101], 'sensing': [104, 229], 'image': [105, 132], 'semantic\\nsegmentation.': [106], 'Specifically,': [107, 169], '1)': [108], 'module': [114, 140], 'is\\nused': [115], 'better': [117, 128], 'as': [122, 239], 'consider': [124], 'style\\nfeatures': [126], 'represent': [129], 'overall': [131], 'features.': [133], '2)': [134], 'The': [135, 154, 242], 'features\\nmatching': [137], 'representations': [145], 'of\\nlocal': [146], 'regions,': [147], 'beneficial': [150], 'segmentation.': [153], 'experimental\\nresults': [155], 'show': [156], 'our': [158, 176, 192], 'mostly': [160], 'outperforms': [161], 'SOTA': [162], 'self-supervised': [163], 'methods\\nand': [164], 'ImageNet': [166], 'pre-training': [167], 'method.': [168], '1\\\\%': [171], 'annotation': [172], 'from\\nthe': [173], 'original': [174], 'dataset,': [175], 'approach': [177], 'improves': [178], 'Kappa': [179], 'by': [180], '6\\\\%': [181], 'ISPRS': [184], 'Potsdam\\ndataset': [185], 'relative': [186], 'baseline.': [190], 'Moreover,': [191], 'outperforms\\nsupervised': [194], 'when': [197], 'there': [198], 'some': [200], 'differences': [201], 'between': [202], 'the\\ndatasets': [203], 'upstream': [205], 'tasks.': [209], 'Since': [210], 'could': [212], 'directly': [213], 'learn\\nthe': [214], 'essential': [215], 'characteristics': [216], 'data': [218], 'from': [219], 'data,': [221], 'easy': [224], 'to\\nobtain': [225], 'field,': [230], 'this': [231], 'great': [235], 'significance': [236], 'tasks\\nsuch': [238], 'mapping.': [241], 'source': [243], 'code': [244], 'available': [246], 'at\\nhttps://github.com/GeoX-Lab/G-RSIM.\\n': [247]}",2022,"['Computer science', 'Artificial intelligence', 'Segmentation', 'Pattern recognition (psychology)', 'Matching (statistics)', 'Supervised learning', 'Feature learning', 'Image segmentation', 'Machine learning', 'Artificial neural network', 'Mathematics', 'Statistics']","Supervised learning for semantic segmentation requires a large number of\nlabeled samples, which is difficult to obtain in the field of remote sensing.\nSelf-supervised learning (SSL), can be used to solve such problems by\npre-training a general model with a large number of unlabeled images and then\nfine-tuning it on a downstream task with very few labeled samples. Contrastive\nlearning is a typical method of SSL that can learn general invariant features.\nHowever, most existing contrastive learning methods are designed for\nclassification tasks to obtain an image-level representation, which may be\nsuboptimal for semantic segmentation tasks requiring pixel-level\ndiscrimination. Therefore, we propose a global style and local matching\ncontrastive learning network (GLCNet) for remote sensing image semantic\nsegmentation. Specifically, 1) the global style contrastive learning module is\nused to better learn an image-level representation, as we consider that style\nfeatures can better represent the overall image features. 2) The local features\nmatching contrastive learning module is designed to learn representations of\nlocal regions, which is beneficial for semantic segmentation. The experimental\nresults show that our method mostly outperforms SOTA self-supervised methods\nand the ImageNet pre-training method. Specifically, with 1\\% annotation from\nthe original dataset, our approach improves Kappa by 6\\% on the ISPRS Potsdam\ndataset relative to the existing baseline. Moreover, our method outperforms\nsupervised learning methods when there are some differences between the\ndatasets of upstream tasks and downstream tasks. Since SSL could directly learn\nthe essential characteristics of data from unlabeled data, which is easy to\nobtain in the remote sensing field, this may be of great significance for tasks\nsuch as global mapping. The source code is available at\nhttps://github.com/GeoX-Lab/G-RSIM.\n"
https://openalex.org/W2963357083,Semi-Supervised Learning for Neural Machine Translation,"{'While': [0], 'end-to-end': [1], 'neural': [2], 'machine': [3], 'translation': [4, 85], '(NMT)': [5], 'has': [6], 'made': [7], 'remarkable': [8], 'progress': [9], 'recently,': [10], 'NMT': [11, 53, 129], 'systems': [12], 'only': [13, 98], 'rely': [14], 'on': [15, 55, 114], 'parallel': [16, 22], 'corpora': [17, 23, 42, 75, 102], 'for': [18, 33, 51], 'parameter': [19], 'estimation.': [20], 'Since': [21], 'are': [24], 'usually': [25], 'limited': [26], 'in': [27, 79], 'quantity,': [28], 'quality,': [29], 'and': [30, 62, 83, 91, 128], 'coverage,': [31], 'especially': [32], 'low-resource': [34], 'languages,': [35], 'it': [36], 'is': [37, 70], 'appealing': [38], 'to': [39, 43, 71], 'exploit': [40, 99], 'monolingual': [41, 74, 101], 'improve': [44], 'NMT.': [45], 'We': [46], 'propose': [47], 'a': [48], 'semi-supervised': [49], 'approach': [50, 95, 121], 'training': [52], 'models': [54, 86], 'the': [56, 73, 81, 89, 100, 104, 110, 115], 'concatenation': [57], 'of': [58, 103, 109], 'labeled': [59], '(parallel': [60], 'corpora)': [61, 65], 'unlabeled': [63], '(monolingual': [64], 'data.': [66], 'The': [67], 'central': [68], 'idea': [69], 'reconstruct': [72], 'using': [76], 'an': [77], 'autoencoder,': [78], 'which': [80], 'source-to-target': [82], 'target-to-source': [84], 'serve': [87], 'as': [88], 'encoder': [90], 'decoder,': [92], 'respectively.': [93], 'Our': [94], 'can': [96], 'not': [97], 'target': [105], 'language,': [106], 'but': [107], 'also': [108], 'source': [111], 'language.': [112], 'Experiments': [113], 'Chinese-English': [116], 'dataset': [117], 'show': [118], 'that': [119], 'our': [120], 'achieves': [122], 'significant': [123], 'improvements': [124], 'over': [125], 'state-of-the-art': [126], 'SMT': [127], 'systems.': [130]}",2016,"['Computer science', 'Machine translation', 'Exploit', 'Concatenation (mathematics)', 'Artificial intelligence', 'Autoencoder', 'Natural language processing', 'Parallel corpora', 'Encoder', 'Translation (biology)', 'Deep learning', 'Computer security', 'Biochemistry', 'Combinatorics', 'Messenger RNA', 'Operating system', 'Gene', 'Mathematics', 'Chemistry']","While end-to-end neural machine translation (NMT) has made remarkable progress recently, NMT systems only rely on parallel corpora for parameter estimation. Since parallel corpora are usually limited in quantity, quality, and coverage, especially for low-resource languages, it is appealing to exploit monolingual corpora to improve NMT. We propose a semi-supervised approach for training NMT models on the concatenation of labeled (parallel corpora) and unlabeled (monolingual corpora) data. The central idea is to reconstruct the monolingual corpora using an autoencoder, in which the source-to-target and target-to-source translation models serve as the encoder and decoder, respectively. Our approach can not only exploit the monolingual corpora of the target language, but also of the source language. Experiments on the Chinese-English dataset show that our approach achieves significant improvements over state-of-the-art SMT and NMT systems."
https://openalex.org/W3045661671,Network intrusion detection system using supervised learning paradigm,"{'Internet': [0, 20], 'has': [1, 30], 'positively': [2], 'changed': [3], 'social,': [4], 'political': [5], 'and': [6, 9, 38, 107, 124, 139], 'economic': [7], 'structures': [8], 'in': [10, 32, 56, 69, 133], 'many': [11], 'ways': [12], 'obviating': [13], 'geographical': [14], 'boundaries.': [15], 'The': [16], 'enormous': [17, 65], 'contributions': [18], 'of': [19, 28, 35, 51, 73], 'to': [21, 44, 58, 77, 87, 92, 105], 'business': [22], 'transactions': [23], 'coupled': [24], 'with': [25, 48, 79, 95], 'its': [26], 'ease': [27], 'use': [29], 'resulted': [31], 'increased': [33], 'number': [34], 'internet': [36], 'users': [37], 'consequently,': [39], 'intruders.': [40], 'It': [41], 'is': [42, 159, 169], 'crucial': [43], 'safeguard': [45], 'computer': [46], 'resources': [47], 'the': [49, 80, 150, 165], 'aid': [50], 'Intrusion': [52, 59], 'Detection': [53], 'Systems': [54], '(IDS)': [55], 'addition': [57], 'Prevention': [60], 'Systems.': [61], 'In': [62], 'recent': [63], 'times,': [64], 'network': [66], 'traffic': [67, 141], 'generated': [68], 'terabytes': [70], 'within': [71], 'couples': [72], 'seconds': [74], 'are': [75], 'difficult': [76], 'analyze': [78], 'traditional': [81], 'rule-based': [82], 'approach;': [83], 'hence,': [84], 'researchers': [85], 'have': [86], 'subject': [88], 'data': [89], 'mining': [90], 'techniques': [91], 'intrusion': [93, 98, 152, 174], 'detection': [94, 99, 110, 153], 'emphasis': [96], 'on': [97, 121, 155], 'accuracy;': [100], 'relevant': [101, 135], 'feature': [102], 'selection': [103], 'leads': [104], 'faster': [106], 'enhanced': [108], 'accurate': [109], 'rate.': [111], 'Therefore,': [112], 'this': [113], 'paper': [114], 'presents': [115], 'a': [116, 160], 'light': [117, 166], 'weight': [118, 167], 'IDS': [119, 168], 'based': [120], 'information': [122], 'gain': [123], 'Multi-layer': [125], 'perceptron': [126], 'Neural': [127, 145], 'Network.': [128, 146], 'Gain': [129], 'ratio': [130], 'was': [131], 'used': [132], 'selecting': [134], 'features': [136], 'for': [137, 171], 'attack': [138], 'normal': [140], 'prior': [142], 'classification': [143], 'using': [144], 'Empirical': [147], 'results': [148], 'from': [149], 'UNSW-NB15': [151], 'dataset': [154], 'thirty': [156], 'selected': [157], 'attributes': [158], 'highly': [161], 'ranked': [162], 'decision,': [163], 'thus,': [164], 'suitable': [170], 'real': [172], 'time': [173], 'detection.': [175]}",2020,"['Intrusion detection system', 'Computer science', 'The Internet', 'Anomaly-based intrusion detection system', 'Terabyte', 'Artificial intelligence', 'Artificial neural network', 'Data mining', 'Feature selection', 'Perceptron', 'Machine learning', 'World Wide Web', 'Operating system']","Internet has positively changed social, political and economic structures and in many ways obviating geographical boundaries. The enormous contributions of Internet to business transactions coupled with its ease of use has resulted in increased number of internet users and consequently, intruders. It is crucial to safeguard computer resources with the aid of Intrusion Detection Systems (IDS) in addition to Intrusion Prevention Systems. In recent times, enormous network traffic generated in terabytes within couples of seconds are difficult to analyze with the traditional rule-based approach; hence, researchers have to subject data mining techniques to intrusion detection with emphasis on intrusion detection accuracy; relevant feature selection leads to faster and enhanced accurate detection rate. Therefore, this paper presents a light weight IDS based on information gain and Multi-layer perceptron Neural Network. Gain ratio was used in selecting relevant features for attack and normal traffic prior classification using Neural Network. Empirical results from the UNSW-NB15 intrusion detection dataset on thirty selected attributes is a highly ranked decision, thus, the light weight IDS is suitable for real time intrusion detection."
https://openalex.org/W2962970583,Student Academic Performance Prediction using Supervised Learning Techniques,"{'Automatic': [0], 'Student': [1], 'performance': [2, 138, 158], 'prediction': [3, 139], 'is': [4, 20, 35, 153, 165, 206], 'a': [5, 136], 'crucial': [6], 'job': [7, 19], 'due': [8], 'to': [9, 155, 167, 186, 200], 'the': [10, 80, 90, 93, 117, 120, 157, 160, 177, 188], 'large': [11], 'volume': [12], 'of': [13, 82, 92, 114, 119, 159, 179, 203], 'data': [14, 25, 33, 98, 103, 180, 189], 'in': [15, 129, 196, 223], 'educational': [16, 24, 38, 52], 'databases.': [17], 'This': [18, 174], 'being': [21], 'addressed': [22], 'by': [23], 'mining': [26, 99], '(EDM).': [27], 'EDM': [28], 'develop': [29], 'methods': [30, 41, 163], 'for': [31, 44, 64, 85, 226], 'discovering': [32], 'that': [34, 57, 74, 232], 'derived': [36], 'from': [37, 208], 'environment.': [39, 50], 'These': [40], 'are': [42, 54, 127, 221], 'used': [43, 195], 'understanding': [45], 'student': [46, 137], 'and': [47, 88, 108, 182, 219], 'their': [48], 'learning': [49, 144, 215], 'The': [51, 192, 229], 'institutions': [53], 'often': [55], 'curious': [56], 'how': [58], 'many': [59, 75], 'students': [60], 'will': [61], 'be': [62], 'pass/fail': [63], 'necessary': [65], 'arrangements.': [66], 'In': [67, 148], 'previous': [68], 'studies,': [69], 'it': [70], 'has': [71], 'been': [72], 'observed': [73], 'researchers': [76], 'have': [77], 'intension': [78], 'on': [79, 142], 'selection': [81], 'appropriate': [83], 'algorithm': [84], 'just': [86], 'classification': [87, 109, 125], 'ignores': [89], 'solutions': [91], 'problems': [94, 115], 'which': [95, 205], 'comes': [96], 'during': [97], 'phases': [100], 'such': [101], 'as': [102], 'high': [104], 'dimensionality': [105], ',class': [106], 'imbalance': [107], 'error': [110], 'etc.': [111], 'Such': [112], 'types': [113], 'reduced': [116], 'accuracy': [118, 236], 'model.&#x0D;': [121], '&#x0D;': [122, 172, 173], 'Several': [123], 'well-known': [124], 'algorithms': [126, 183, 216], 'applied': [128, 154], 'this': [130, 133, 197, 224], 'domain': [131], 'but': [132], 'paper': [134], 'proposed': [135], 'model': [140], 'based': [141], 'supervised': [143, 214], 'decision': [145], 'tree': [146], 'classifier.': [147, 161], 'addition,': [149], 'an': [150], 'ensemble': [151], 'method': [152], 'improve': [156], 'Ensemble': [162], 'approach': [164], 'designed': [166], 'solve': [168], 'classification,': [169], 'predictions': [170], 'problems.': [171], 'study': [175, 225], 'proves': [176], 'importance': [178], 'preprocessing': [181], 'fine-tuning': [184], 'tasks': [185], 'resolve': [187], 'quality': [190], 'issues.': [191], 'experimental': [193, 227], 'dataset': [194], 'work': [198], 'belongs': [199], 'Alentejo': [201], 'region': [202], 'Portugal': [204], 'obtained': [207], 'UCI': [209], 'Machine': [210], 'Learning': [211], 'Repository.': [212], 'Three': [213], '(J48,': [217], 'NNge': [218], 'MLP)': [220], 'employed': [222], 'purposes.': [228], 'results': [230], 'showed': [231], 'J48': [233], 'achieved': [234], 'highest': [235], '95.78%': [237], 'among': [238], 'others.': [239]}",2019,"['C4.5 algorithm', 'Computer science', 'Machine learning', 'Artificial intelligence', 'Educational data mining', 'Decision tree', 'Data pre-processing', 'Classifier (UML)', 'Curse of dimensionality', 'Data mining', 'Ensemble learning', 'Preprocessor', 'Supervised learning', 'Support vector machine', 'Artificial neural network', 'Naive Bayes classifier']","Automatic Student performance prediction is a crucial job due to the large volume of data in educational databases. This job is being addressed by educational data mining (EDM). EDM develop methods for discovering data that is derived from educational environment. These methods are used for understanding student and their learning environment. The educational institutions are often curious that how many students will be pass/fail for necessary arrangements. In previous studies, it has been observed that many researchers have intension on the selection of appropriate algorithm for just classification and ignores the solutions of the problems which comes during data mining phases such as data high dimensionality ,class imbalance and classification error etc. Such types of problems reduced the accuracy of the model.&#x0D; &#x0D; Several well-known classification algorithms are applied in this domain but this paper proposed a student performance prediction model based on supervised learning decision tree classifier. In addition, an ensemble method is applied to improve the performance of the classifier. Ensemble methods approach is designed to solve classification, predictions problems. &#x0D; &#x0D; This study proves the importance of data preprocessing and algorithms fine-tuning tasks to resolve the data quality issues. The experimental dataset used in this work belongs to Alentejo region of Portugal which is obtained from UCI Machine Learning Repository. Three supervised learning algorithms (J48, NNge and MLP) are employed in this study for experimental purposes. The results showed that J48 achieved highest accuracy 95.78% among others."
https://openalex.org/W4306916468,Demystifying Supervised Learning in Healthcare 4.0: A New Reality of Transforming Diagnostic Medicine,"{'The': [0, 23, 72, 233], 'global': [1], 'healthcare': [2, 27, 67, 105, 116, 162, 182, 195, 262], 'sector': [3], 'continues': [4], 'to': [5, 121, 220, 246, 255], 'grow': [6], 'rapidly': [7], 'and': [8, 33, 37, 69, 74, 98, 150, 157, 165, 185, 194, 205, 217, 223, 229, 244, 248, 263], 'is': [9, 142, 183, 188], 'reflected': [10], 'as': [11, 181], 'one': [12], 'of': [13, 25, 55, 78, 126, 132, 140, 177, 227], 'the': [14, 18, 26, 43, 46, 52, 57, 108, 123, 155, 159, 168, 214, 224, 250, 261], 'fastest-growing': [15], 'sectors': [16], 'in': [17, 65, 100, 104, 115, 167, 192, 236, 242, 260], 'fourth': [19], 'industrial': [20], 'revolution': [21], '(4.0).': [22], 'majority': [24], 'industry': [28, 245], 'still': [29], 'uses': [30], 'labor-intensive,': [31], 'time-consuming,': [32], 'error-prone': [34], 'traditional,': [35], 'manual,': [36], 'manpower-based': [38], 'methods.': [39], 'This': [40, 144], 'review': [41], 'addresses': [42], 'current': [44], 'paradigm,': [45], 'potential': [47, 58, 75, 124], 'for': [48, 59, 76, 110, 161, 202], 'new': [49, 148], 'scientific': [50], 'discoveries,': [51], 'technological': [53], 'state': [54], 'preparation,': [56], 'supervised': [60], 'machine': [61], 'learning': [62], '(SML)': [63], 'prospects': [64], 'various': [66, 101], 'sectors,': [68], 'ethical': [70], 'issues.': [71], 'effectiveness': [73], 'innovation': [77], 'disease': [79], 'diagnosis,': [80], 'personalized': [81], 'medicine,': [82], 'clinical': [83], 'trials,': [84], 'non-invasive': [85, 127], 'image': [86], 'analysis,': [87], 'drug': [88], 'discovery,': [89], 'patient': [90, 94], 'care': [91], 'services,': [92], 'remote': [93], 'monitoring,': [95], 'hospital': [96], 'data,': [97], 'nanotechnology': [99], 'learning-based': [102], 'automation': [103], 'along': [106], 'with': [107], 'requirement': [109], 'explainable': [111], 'artificial': [112], 'intelligence': [113], '(AI)': [114], 'are': [117], 'evaluated.': [118], 'In': [119], 'order': [120], 'understand': [122, 247], 'architecture': [125], 'treatment,': [128], 'a': [129, 137, 175, 206, 212], 'thorough': [130], 'study': [131, 145], 'medical': [133], 'imaging': [134], 'analysis': [135], 'from': [136], 'technical': [138], 'point': [139], 'view': [141], 'presented.': [143], 'also': [146], 'represents': [147], 'thinking': [149], 'developments': [151, 196], 'that': [152, 253], 'will': [153, 239], 'push': [154], 'boundaries': [156], 'increase': [158], 'opportunity': [160], 'through': [163], 'AI': [164, 228], 'SML': [166, 191, 230, 259], 'near': [169], 'future.': [170], 'Nowadays,': [171, 190], 'SML-based': [172], 'applications': [173], 'require': [174], 'lot': [176], 'data': [178, 200], 'quality': [179, 199], 'awareness': [180], 'data-heavy,': [184], 'knowledge': [186], 'management': [187, 209], 'paramount.': [189], 'biomedical': [193, 264], 'needs': [197, 254], 'skills,': [198], 'consciousness': [201], 'data-intensive': [203], 'study,': [204], 'knowledge-centric': [207], 'health': [208], 'system.': [210], 'As': [211], 'result,': [213], 'merits,': [215], 'demerits,': [216], 'precautions': [218], 'need': [219], 'take': [221], 'ethics': [222], 'other': [225], 'effects': [226], 'into': [231], 'consideration.': [232], 'overall': [234], 'insight': [235], 'this': [237], 'paper': [238], 'help': [240], 'researchers': [241], 'academia': [243], 'address': [249], 'future': [251], 'research': [252], 'be': [256], 'discussed': [257], 'on': [258], 'sectors.': [265]}",2022,"['Health care', 'Quality (philosophy)', 'Knowledge management', 'Computer science', 'Data science', 'Artificial intelligence', 'Political science', 'Law', 'Philosophy', 'Epistemology']","The global healthcare sector continues to grow rapidly and is reflected as one of the fastest-growing sectors in the fourth industrial revolution (4.0). The majority of the healthcare industry still uses labor-intensive, time-consuming, and error-prone traditional, manual, and manpower-based methods. This review addresses the current paradigm, the potential for new scientific discoveries, the technological state of preparation, the potential for supervised machine learning (SML) prospects in various healthcare sectors, and ethical issues. The effectiveness and potential for innovation of disease diagnosis, personalized medicine, clinical trials, non-invasive image analysis, drug discovery, patient care services, remote patient monitoring, hospital data, and nanotechnology in various learning-based automation in healthcare along with the requirement for explainable artificial intelligence (AI) in healthcare are evaluated. In order to understand the potential architecture of non-invasive treatment, a thorough study of medical imaging analysis from a technical point of view is presented. This study also represents new thinking and developments that will push the boundaries and increase the opportunity for healthcare through AI and SML in the near future. Nowadays, SML-based applications require a lot of data quality awareness as healthcare is data-heavy, and knowledge management is paramount. Nowadays, SML in biomedical and healthcare developments needs skills, quality data consciousness for data-intensive study, and a knowledge-centric health management system. As a result, the merits, demerits, and precautions need to take ethics and the other effects of AI and SML into consideration. The overall insight in this paper will help researchers in academia and industry to understand and address the future research that needs to be discussed on SML in the healthcare and biomedical sectors."
https://openalex.org/W3204696009,BigSSL: Exploring the Frontier of Large-Scale Semi-Supervised Learning for Automatic Speech Recognition,"{'We': [0, 27, 95], 'summarize': [1], 'the': [2, 30, 84, 91, 142], 'results': [3, 150], 'of': [4, 7, 25, 49, 51, 64, 83, 112, 120, 126, 128, 144], 'a': [5, 22, 109, 117], 'host': [6], 'efforts': [8], 'using': [9, 16, 103], 'giant': [10], 'automatic': [11], 'speech\\nrecognition': [12], '(ASR)': [13], 'models': [14], 'pre-trained': [15, 72, 105, 145], 'large,': [17], 'diverse': [18], 'unlabeled': [19], 'datasets\\ncontaining': [20], 'approximately': [21], 'million': [23], 'hours': [24, 52, 63], 'audio.': [26], 'find': [28], 'that': [29, 115], 'combination\\nof': [31], 'pre-training,': [32], 'self-training': [33], 'and': [34, 106], 'scaling': [35], 'up': [36], 'model': [37, 74], 'size': [38], 'greatly': [39], 'increases': [40], 'data\\nefficiency,': [41], 'even': [42], 'for': [43], 'extremely': [44], 'large': [45, 110], 'tasks': [46, 114], 'with': [47, 61, 80, 90], 'tens': [48], 'thousands': [50], 'of\\nlabeled': [53], 'data.': [54], 'In': [55, 138], 'particular,': [56], 'on': [57, 98, 134, 151], 'an': [58, 68], 'ASR': [59], 'task': [60], '34k': [62], 'labeled': [65], 'data,': [66], 'by\\nfine-tuning': [67], '8': [69], 'billion': [70], 'parameter': [71], 'Conformer': [73], 'we': [75, 140], 'can': [76], 'match\\nstate-of-the-art': [77], '(SoTA)': [78], 'performance': [79, 133], 'only': [81], '3%': [82], 'training': [85, 93], 'data': [86], 'and\\nsignificantly': [87], 'improve': [88], 'SoTA': [89, 149], 'full': [92], 'set.': [94], 'also': [96], 'report': [97], 'the\\nuniversal': [99], 'benefits': [100], 'gained': [101], 'from': [102], 'big': [104], 'self-trained': [107], 'models\\nfor': [108], 'set': [111], 'downstream': [113], 'cover': [116], 'wide': [118], 'range': [119], 'speech': [121], 'domains\\nand': [122], 'span': [123], 'multiple': [124], 'orders': [125], 'magnitudes': [127], 'dataset': [129], 'sizes,': [130], 'including': [131], 'obtaining\\nSoTA': [132], 'many': [135], 'public': [136], 'benchmarks.': [137], 'addition,': [139], 'utilize': [141], 'learned\\nrepresentation': [143], 'networks': [146], 'to': [147], 'achieve': [148], 'non-ASR\\ntasks.\\n': [152]}",2022,"['Computer science', 'Training set', 'Set (abstract data type)', 'Artificial intelligence', 'Task (project management)', 'Speech recognition', 'Range (aeronautics)', 'Machine learning', 'Pattern recognition (psychology)', 'Economics', 'Programming language', 'Management', 'Materials science', 'Composite material']","We summarize the results of a host of efforts using giant automatic speech\nrecognition (ASR) models pre-trained using large, diverse unlabeled datasets\ncontaining approximately a million hours of audio. We find that the combination\nof pre-training, self-training and scaling up model size greatly increases data\nefficiency, even for extremely large tasks with tens of thousands of hours of\nlabeled data. In particular, on an ASR task with 34k hours of labeled data, by\nfine-tuning an 8 billion parameter pre-trained Conformer model we can match\nstate-of-the-art (SoTA) performance with only 3% of the training data and\nsignificantly improve SoTA with the full training set. We also report on the\nuniversal benefits gained from using big pre-trained and self-trained models\nfor a large set of downstream tasks that cover a wide range of speech domains\nand span multiple orders of magnitudes of dataset sizes, including obtaining\nSoTA performance on many public benchmarks. In addition, we utilize the learned\nrepresentation of pre-trained networks to achieve SoTA results on non-ASR\ntasks.\n"
https://openalex.org/W3092206109,GraphMix: Improved Training of GNNs for Semi-Supervised Learning,"{'We': [0, 69], 'present': [1], 'GraphMix,': [2], 'a': [3, 19, 37], 'regularization': [4], 'method': [5], 'for': [6], 'Graph': [7, 82, 85, 111], 'Neural': [8], 'Network': [9], 'based': [10], 'semi-supervised': [11], 'object': [12], 'classification,': [13], 'whereby': [14], 'we': [15, 35, 93], 'propose': [16], 'to': [17, 77], 'train': [18], 'fully-connected': [20], 'network': [21, 27, 124], 'jointly': [22], 'with': [23], 'the': [24, 44, 48, 58, 62, 65], 'graph': [25, 50, 66, 117], 'neural': [26, 51, 67], 'via': [28], 'parameter': [29], 'sharing': [30], 'and': [31, 88, 121, 135], 'interpolation-based': [32], 'regularization.': [33], 'Further,': [34], 'provide': [36], 'theoretical': [38], 'analysis': [39, 73], 'of': [40, 47, 64], 'how': [41], 'GraphMix': [42, 76, 96], 'improves': [43], 'generalization': [45], 'bounds': [46], 'underlying': [49], 'network,': [52], 'without': [53], 'making': [54], 'any': [55], 'assumptions': [56], 'about': [57], '""aggregation""': [59], 'layer': [60], 'or': [61, 100], 'depth': [63], 'networks.': [68], 'experimentally': [70], 'validate': [71], 'this': [72], 'by': [74], 'applying': [75], 'various': [78], 'architectures': [79, 108], 'such': [80, 109], 'as': [81, 110, 126, 128], 'Convolutional': [83, 112], 'Networks,': [84, 113], 'Attention': [86], 'Networks': [87], 'Graph-U-Net.': [89], 'Despite': [90], 'its': [91], 'simplicity,': [92], 'demonstrate': [94], 'that': [95], 'can': [97], 'consistently': [98], 'improve': [99], 'closely': [101], 'match': [102], 'state-of-the-art': [103], 'performance': [104], 'using': [105], 'even': [106], 'simpler': [107], 'across': [114], 'three': [115, 129], 'established': [116], 'benchmarks:': [118], 'Cora,': [119], 'Citeseer': [120], 'Pubmed': [122], 'citation': [123], 'datasets,': [125], 'well': [127], 'newly': [130], 'proposed': [131], 'datasets:': [132], 'Cora-Full,': [133], 'Co-author-CS': [134], 'Co-author-Physics.': [136]}",2021,"['Computer science', 'Graph', 'Convolutional neural network', 'Theoretical computer science', 'Artificial intelligence', 'Machine learning', 'Regularization (linguistics)', 'Artificial neural network']","We present GraphMix, a regularization method for Graph Neural Network based semi-supervised object classification, whereby we propose to train a fully-connected network jointly with the graph neural network via parameter sharing and interpolation-based regularization. Further, we provide a theoretical analysis of how GraphMix improves the generalization bounds of the underlying graph neural network, without making any assumptions about the ""aggregation"" layer or the depth of the graph neural networks. We experimentally validate this analysis by applying GraphMix to various architectures such as Graph Convolutional Networks, Graph Attention Networks and Graph-U-Net. Despite its simplicity, we demonstrate that GraphMix can consistently improve or closely match state-of-the-art performance using even simpler architectures such as Graph Convolutional Networks, across three established graph benchmarks: Cora, Citeseer and Pubmed citation network datasets, as well as three newly proposed datasets: Cora-Full, Co-author-CS and Co-author-Physics."
https://openalex.org/W3005731330,DivideMix: Learning with Noisy Labels as Semi-supervised Learning,"{'Deep': [0], 'neural': [1], 'networks': [2, 113], 'are': [3], 'known': [4], 'to': [5, 13, 69], 'be': [6], 'annotation-hungry.': [7], 'Numerous': [8], 'efforts': [9], 'have': [10], 'been': [11], 'devoted': [12], 'reducing': [14], 'the': [15, 61, 72, 91, 95, 118, 122, 126, 132], 'annotation': [16], 'cost': [17], 'when': [18], 'learning': [19, 27, 33, 48, 55], 'with': [20, 28, 49, 65, 79, 86], 'deep': [21], 'networks.': [22], 'Two': [23], 'prominent': [24], 'directions': [25], 'include': [26], 'noisy': [29, 50, 87], 'labels': [30, 51], 'and': [31, 82, 89, 97, 139, 144], 'semi-supervised': [32, 54, 102, 127], 'by': [34, 52, 135], 'exploiting': [35], 'unlabeled': [36, 84, 98, 145], 'data.': [37], 'In': [38, 57], 'this': [39, 163], 'work,': [40], 'we': [41, 108, 130], 'propose': [42], 'DivideMix,': [43], 'a': [44, 66, 76, 101], 'novel': [45], 'framework': [46], 'for': [47], 'leveraging': [53], 'techniques.': [56], 'particular,': [58], 'DivideMix': [59], 'models': [60], 'per-sample': [62], 'loss': [63], 'distribution': [64], 'mixture': [67], 'model': [68, 92], 'dynamically': [70], 'divide': [71], 'training': [73, 128], 'data': [74, 99], 'into': [75], 'labeled': [77, 96, 143], 'set': [78, 85], 'clean': [80], 'samples': [81], 'an': [83], 'samples,': [88, 146], 'trains': [90], 'on': [93, 142, 149], 'both': [94], 'in': [100], 'manner.': [103], 'To': [104], 'avoid': [105], 'confirmation': [106], 'bias,': [107], 'simultaneously': [109], 'train': [110], 'two': [111], 'diverged': [112], 'where': [114], 'each': [115], 'network': [116], 'uses': [117], 'dataset': [119], 'division': [120], 'from': [121], 'other': [123], 'network.': [124], 'During': [125], 'phase,': [129], 'improve': [131], 'MixMatch': [133], 'strategy': [134], 'performing': [136], 'label': [137, 140], 'co-refinement': [138], 'co-guessing': [141], 'respectively.': [147], 'Experiments': [148], 'multiple': [150], 'benchmark': [151], 'datasets': [152], 'demonstrate': [153], 'substantial': [154], 'improvements': [155], 'over': [156], 'state-of-the-art': [157], 'methods.': [158], 'Code': [159], 'is': [160], 'available': [161], 'at': [162], 'https': [164], 'URL': [165], '.': [166]}",2020,"['Computer science', 'Artificial intelligence', 'Benchmark (surveying)', 'Annotation', 'Machine learning', 'Semi-supervised learning', 'Supervised learning', 'Labeled data', 'Deep learning', 'Artificial neural network', 'Set (abstract data type)', 'Sample (material)', 'Code (set theory)', 'Chromatography', 'Geodesy', 'Geography', 'Programming language', 'Chemistry']","Deep neural networks are known to be annotation-hungry. Numerous efforts have been devoted to reducing the annotation cost when learning with deep networks. Two prominent directions include learning with noisy labels and semi-supervised learning by exploiting unlabeled data. In this work, we propose DivideMix, a novel framework for learning with noisy labels by leveraging semi-supervised learning techniques. In particular, DivideMix models the per-sample loss distribution with a mixture model to dynamically divide the training data into a labeled set with clean samples and an unlabeled set with noisy samples, and trains the model on both the labeled and unlabeled data in a semi-supervised manner. To avoid confirmation bias, we simultaneously train two diverged networks where each network uses the dataset division from the other network. During the semi-supervised training phase, we improve the MixMatch strategy by performing label co-refinement and label co-guessing on labeled and unlabeled samples, respectively. Experiments on multiple benchmark datasets demonstrate substantial improvements over state-of-the-art methods. Code is available at this https URL ."
https://openalex.org/W3036974265,Self-supervised Learning on Graphs: Deep Insights and New Direction,"{'The': [0, 239], 'success': [1], 'of': [2, 9, 19, 54, 77, 177, 194], 'deep': [3, 45, 211], 'learning': [4, 21, 46], 'notoriously': [5], 'requires': [6], 'larger': [7], 'amounts': [8], 'costly': [10], 'annotated': [11], 'data.': [12, 37, 93], 'This': [13], 'has': [14], 'led': [15], 'to': [16, 25, 47, 73, 83, 88, 144, 153, 171, 223, 231, 243], 'the': [17, 48, 52, 66, 91, 99, 135, 148, 161, 214], 'development': [18], 'self-supervised': [20], '(SSL)': [22], 'that': [23, 70, 140, 168, 228], 'aims': [24], 'alleviate': [26], 'this': [27, 181], 'limitation': [28], 'by': [29, 199, 210], 'creating': [30], 'domain': [31, 50], 'specific': [32, 240], 'pretext': [33, 205, 226], 'tasks': [34, 206, 227], 'on': [35, 132, 188, 207, 235], 'unlabeled': [36, 63, 78, 92], 'Simultaneously,': [38], 'there': [39], 'are': [40, 113, 158, 229], 'increasing': [41], 'interests': [42], 'in': [43, 51, 98, 105, 180, 250], 'generalizing': [44], 'graph': [49, 55], 'form': [53], 'neural': [56], 'networks': [57], '(GNNs).': [58], 'GNNs': [59, 87, 198], 'can': [60, 247], 'naturally': [61], 'utilize': [62], 'nodes': [64, 104], 'through': [65], 'simple': [67], 'neighborhood': [68], 'aggregation': [69], 'is': [71, 126, 142], 'unable': [72], 'thoroughly': [74], 'make': [75], 'use': [76], 'nodes.': [79], 'Thus,': [80, 179], 'we': [81, 183, 217], 'seek': [82], 'harness': [84], 'SSL': [85, 131, 173, 195, 204], 'for': [86, 130], 'fully': [89], 'exploit': [90], 'Different': [94], 'from': [95, 147, 174, 213], 'data': [96], 'instances': [97], 'image': [100, 149], 'and': [101, 111, 119, 150, 155, 191], 'text': [102, 151], 'domains,': [103], 'graphs': [106, 154], 'present': [107], 'unique': [108], 'structure': [109], 'information': [110, 167], 'they': [112], 'inherently': [114], 'linked': [115], 'indicating': [116], 'not': [117], 'independent': [118], 'identically': [120], 'distributed': [121], '(or': [122], 'i.i.d.).': [123], 'Such': [124], 'complexity': [125], 'a': [127, 175, 219], 'double-edged': [128], 'sword': [129], 'graphs.': [133, 208], 'On': [134, 160], 'one': [136], 'hand,': [137, 163], 'it': [138, 141, 164], 'determines': [139], 'challenging': [143], 'adopt': [145], 'solutions': [146], 'domains': [152], 'dedicated': [156], 'efforts': [157], 'desired.': [159], 'other': [162], 'provides': [165], 'rich': [166], 'enables': [169], 'us': [170], 'build': [172, 224], 'variety': [176], 'perspectives.': [178], 'paper,': [182], 'first': [184], 'deepen': [185], 'our': [186, 245], 'understandings': [187], 'when,': [189], 'why,': [190], 'which': [192], 'strategies': [193], 'work': [196], 'with': [197], 'empirically': [200], 'studying': [201], 'numerous': [202], 'basic': [203], 'Inspired': [209], 'insights': [212], 'empirical': [215], 'studies,': [216], 'propose': [218], 'new': [220], 'direction': [221], 'SelfTask': [222], 'advanced': [225], 'able': [230], 'achieve': [232], 'state-of-the-art': [233], 'performance': [234], 'various': [236], 'real-world': [237], 'datasets.': [238], 'experimental': [241], 'settings': [242], 'reproduce': [244], 'results': [246], 'be': [248], 'found': [249], '\\url{https://github.com/ChandlerBang/SelfTask-GNN}.': [251]}",2020,"['Computer science', 'Exploit', 'Artificial intelligence', 'Deep learning', 'Pretext', 'Graph', 'Theoretical computer science', 'Machine learning', 'Domain (mathematical analysis)', 'Feature learning', 'Computer security', 'Political science', 'Politics', 'Mathematics', 'Law', 'Mathematical analysis']","The success of deep learning notoriously requires larger amounts of costly annotated data. This has led to the development of self-supervised learning (SSL) that aims to alleviate this limitation by creating domain specific pretext tasks on unlabeled data. Simultaneously, there are increasing interests in generalizing deep learning to the graph domain in the form of graph neural networks (GNNs). GNNs can naturally utilize unlabeled nodes through the simple neighborhood aggregation that is unable to thoroughly make use of unlabeled nodes. Thus, we seek to harness SSL for GNNs to fully exploit the unlabeled data. Different from data instances in the image and text domains, nodes in graphs present unique structure information and they are inherently linked indicating not independent and identically distributed (or i.i.d.). Such complexity is a double-edged sword for SSL on graphs. On the one hand, it determines that it is challenging to adopt solutions from the image and text domains to graphs and dedicated efforts are desired. On the other hand, it provides rich information that enables us to build SSL from a variety of perspectives. Thus, in this paper, we first deepen our understandings on when, why, and which strategies of SSL work with GNNs by empirically studying numerous basic SSL pretext tasks on graphs. Inspired by deep insights from the empirical studies, we propose a new direction SelfTask to build advanced pretext tasks that are able to achieve state-of-the-art performance on various real-world datasets. The specific experimental settings to reproduce our results can be found in \url{https://github.com/ChandlerBang/SelfTask-GNN}."
https://openalex.org/W1981920455,A semi-supervised learning approach for robust indoor-outdoor detection with smartphones,"{'The': [0], 'environmental': [1], 'context': [2], 'of': [3, 28, 81, 120, 170], 'a': [4, 31, 42, 56, 61, 89], 'mobile': [5], 'device': [6, 15, 32, 149], 'determines': [7], 'how': [8, 13], 'it': [9, 135], 'is': [10, 33, 71, 75, 114, 129, 153], 'used': [11], 'and': [12, 22, 49, 84, 86, 101, 142, 173], 'the': [14, 26, 52, 112, 121, 148], 'can': [16, 99, 136], 'optimize': [17], 'operations': [18], 'for': [19, 116], 'greater': [20], 'efficiency': [21], 'usability.': [23], 'We': [24, 58], 'consider': [25], 'problem': [27], 'detecting': [29], 'if': [30], 'indoor': [34], 'or': [35, 166], 'outdoor.': [36], 'Towards': [37], 'this': [38], 'end,': [39], 'we': [40], 'present': [41], 'general': [43], 'method': [44, 65, 113, 128], 'employing': [45], 'semi-supervised': [46, 63], 'machine': [47], 'learning': [48, 64], 'using': [50], 'only': [51], 'lightweight': [53, 130], 'sensors': [54], 'on': [55, 126, 163], 'smartphone.': [57], 'find': [59], 'that': [60, 161], 'particular': [62], 'called': [66], 'co-training,': [67], 'when': [68, 138], 'suitably': [69], 'engineered,': [70], 'most': [72], 'effective.': [73], 'It': [74, 98, 152], 'able': [76], 'to': [77, 146, 155], 'automatically': [78], 'learn': [79, 100], 'characteristics': [80], 'new': [82], 'environments': [83], 'devices,': [85], 'thereby': [87], 'provides': [88], 'detection': [90, 123, 159], 'accuracy': [91, 172], 'exceeding': [92], '90%': [93], 'even': [94], 'in': [95, 104, 131, 140, 168], 'unfamiliar': [96], 'circumstances.': [97], 'adapt': [102], 'online,': [103], 'real': [105], 'time,': [106], 'at': [107], 'modest': [108], 'computational': [109], 'costs.': [110], 'Thus': [111], 'suitable': [115], 'on-device': [117], 'learning.': [118], 'Implementation': [119], 'indoor-outdoor': [122, 158], 'service': [124], 'based': [125], 'our': [127], 'energy': [132], 'use': [133, 141], '--': [134], 'sleep': [137], 'not': [139, 144], 'does': [143], 'need': [145], 'track': [147], 'state': [150], 'continuously.': [151], 'shown': [154], 'outperform': [156], 'existing': [157], 'techniques': [160], 'rely': [162], 'static': [164], 'algorithms': [165], 'GPS,': [167], 'terms': [169], 'both': [171], 'energy-efficiency.': [174]}",2014,"['Computer science', 'Usability', 'Global Positioning System', 'Mobile device', 'Context (archaeology)', 'Real-time computing', 'Machine learning', 'Artificial intelligence', 'Efficient energy use', 'Supervised learning', 'Energy (signal processing)', 'Human–computer interaction', 'Artificial neural network', 'Engineering', 'Mathematics', 'Operating system', 'Telecommunications', 'Paleontology', 'Biology', 'Electrical engineering', 'Statistics']","The environmental context of a mobile device determines how it is used and how the device can optimize operations for greater efficiency and usability. We consider the problem of detecting if a device is indoor or outdoor. Towards this end, we present a general method employing semi-supervised machine learning and using only the lightweight sensors on a smartphone. We find that a particular semi-supervised learning method called co-training, when suitably engineered, is most effective. It is able to automatically learn characteristics of new environments and devices, and thereby provides a detection accuracy exceeding 90% even in unfamiliar circumstances. It can learn and adapt online, in real time, at modest computational costs. Thus the method is suitable for on-device learning. Implementation of the indoor-outdoor detection service based on our method is lightweight in energy use -- it can sleep when not in use and does not need to track the device state continuously. It is shown to outperform existing indoor-outdoor detection techniques that rely on static algorithms or GPS, in terms of both accuracy and energy-efficiency."
https://openalex.org/W2913921102,Where Should I Walk? Predicting Terrain Properties From Images Via Self-Supervised Learning,{'ISSN:2377-3766': [0]},2019,"['Terrain', 'Traverse', 'Artificial intelligence', 'Robot', 'Computer science', 'Computer vision', 'Trajectory', 'Convolutional neural network', 'Quadcopter', 'Segmentation', 'Legged robot', 'Engineering', 'Geography', 'Cartography', 'Astronomy', 'Aerospace engineering', 'Geodesy', 'Physics']",ISSN:2377-3766
https://openalex.org/W4366208220,DINOv2: Learning Robust Visual Features without Supervision,"{'The': [0], 'recent': [1], 'breakthroughs': [2], 'in': [3, 23, 35, 89, 135], 'natural': [4], 'language': [5], 'processing': [6], 'for': [7, 19], 'model': [8, 94, 147], 'pretraining': [9, 59, 88], 'on': [10, 70, 176], 'large': [11], 'quantities': [12], 'of': [13, 33, 91, 97, 112, 129, 141, 161, 178], 'data': [14, 73, 92], 'have': [15], 'opened': [16], 'the': [17, 31, 98, 106, 136, 166, 179], 'way': [18], 'similar': [20], 'foundation': [21], 'models': [22, 27, 163], 'computer': [24], 'vision.': [25], 'These': [26], 'could': [28], 'greatly': [29], 'simplify': [30], 'use': [32], 'images': [34], 'any': [36], 'system': [37], 'by': [38], 'producing': [39], 'all-purpose': [40, 169], 'visual': [41], 'features,': [42, 170], 'i.e.,': [43], 'features': [44, 67], 'that': [45, 57, 164], 'work': [46, 55], 'across': [47], 'image': [48, 126, 182], 'distributions': [49], 'and': [50, 81, 93, 104, 124, 155, 183], 'tasks': [51], 'without': [52], 'finetuning.': [53], 'This': [54], 'shows': [56], 'existing': [58, 79], 'methods,': [60, 63], 'especially': [61], 'self-supervised': [62, 137], 'can': [64], 'produce': [65], 'such': [66], 'if': [68], 'trained': [69], 'enough': [71], 'curated': [72, 125], 'from': [74], 'diverse': [75], 'sources.': [76], 'We': [77], 'revisit': [78], 'approaches': [80], 'combine': [82], 'different': [83], 'techniques': [84], 'to': [85, 119], 'scale': [86], 'our': [87], 'terms': [90, 111, 140], 'size.': [95], 'Most': [96], 'technical': [99], 'contributions': [100], 'aim': [101], 'at': [102, 108, 181], 'accelerating': [103], 'stabilizing': [105], 'training': [107], 'scale.': [109], 'In': [110, 139], 'data,': [113, 131], 'we': [114, 143], 'propose': [115], 'an': [116], 'automatic': [117], 'pipeline': [118], 'build': [120], 'a': [121, 145, 159], 'dedicated,': [122], 'diverse,': [123], 'dataset': [127], 'instead': [128], 'uncurated': [130], 'as': [132], 'typically': [133], 'done': [134], 'literature.': [138], 'models,': [142], 'train': [144], 'ViT': [146], '(Dosovitskiy': [148], 'et': [149, 173], 'al.,': [150, 174], '2020)': [151], 'with': [152], '1B': [153], 'parameters': [154], 'distill': [156], 'it': [157], 'into': [158], 'series': [160], 'smaller': [162], 'surpass': [165], 'best': [167], 'available': [168], 'OpenCLIP': [171], '(Ilharco': [172], '2021)': [175], 'most': [177], 'benchmarks': [180], 'pixel': [184], 'levels.': [185]}",2023,"['Computer science', 'Pipeline (software)', 'Artificial intelligence', 'Machine learning', 'Scale (ratio)', 'Training set', 'Image (mathematics)', 'Quantum mechanics', 'Programming language', 'Physics']","The recent breakthroughs in natural language processing for model pretraining on large quantities of data have opened the way for similar foundation models in computer vision. These models could greatly simplify the use of images in any system by producing all-purpose visual features, i.e., features that work across image distributions and tasks without finetuning. This work shows that existing pretraining methods, especially self-supervised methods, can produce such features if trained on enough curated data from diverse sources. We revisit existing approaches and combine different techniques to scale our pretraining in terms of data and model size. Most of the technical contributions aim at accelerating and stabilizing the training at scale. In terms of data, we propose an automatic pipeline to build a dedicated, diverse, and curated image dataset instead of uncurated data, as typically done in the self-supervised literature. In terms of models, we train a ViT model (Dosovitskiy et al., 2020) with 1B parameters and distill it into a series of smaller models that surpass the best available all-purpose features, OpenCLIP (Ilharco et al., 2021) on most of the benchmarks at image and pixel levels."
https://openalex.org/W2963275829,Semi-Supervised Learning for Neural Keyphrase Generation,"{'We': [0], 'study': [1], 'the': [2, 9, 115, 118], 'problem': [3], 'of': [4, 38, 117], 'generating': [5], 'keyphrases': [6, 80, 111], 'that': [7, 123], 'summarize': [8], 'key': [10], 'points': [11], 'for': [12, 66, 97], 'a': [13, 88, 102, 129], 'given': [14], 'document.': [15], 'While': [16], 'sequence-to-sequence': [17], '(seq2seq)': [18], 'models': [19], 'have': [20], 'achieved': [21], 'remarkable': [22], 'performance': [23], 'on': [24, 35], 'this': [25, 49], 'task': [26], '(Meng': [27], 'et': [28], 'al.,': [29], '2017),': [30], 'model': [31, 131], 'training': [32], 'often': [33], 'relies': [34], 'large': [36], 'amounts': [37], 'labeled': [39, 60, 95, 134], 'data,': [40], 'which': [41], 'is': [42], 'only': [43], 'applicable': [44], 'to': [45, 106, 109], 'resource-rich': [46], 'domains.': [47], 'In': [48], 'paper,': [50], 'we': [51, 100], 'propose': [52], 'semi-supervised': [53, 125], 'keyphrase': [54, 84], 'generation': [55], 'methods': [56, 86, 127], 'by': [57], 'leveraging': [58], 'both': [59], 'data': [61, 135], 'and': [62, 91], 'large-scale': [63], 'unlabeled': [64, 73], 'samples': [65, 96], 'learning.': [67], 'Two': [68], 'strategies': [69], 'are': [70, 75], 'proposed.': [71], 'First,': [72], 'documents': [74], 'first': [76], 'tagged': [77], 'with': [78, 94, 133], 'synthetic': [79], 'obtained': [81], 'from': [82], 'unsupervised': [83], 'extraction': [85], 'or': [87], 'self-learning': [89], 'algorithm,': [90], 'then': [92], 'combined': [93], 'training.': [98], 'Furthermore,': [99], 'investigate': [101], 'multi-task': [103], 'learning': [104], 'framework': [105], 'jointly': [107], 'learn': [108], 'generate': [110], 'as': [112, 114], 'well': [113], 'titles': [116], 'articles.': [119], 'Experimental': [120], 'results': [121], 'show': [122], 'our': [124], 'learning-based': [126], 'outperform': [128], 'state-of-the-art': [130], 'trained': [132], 'only.': [136]}",2018,"['Computer science', 'Artificial intelligence', 'Task (project management)', 'Labeled data', 'Machine learning', 'Sequence (biology)', 'Key (lock)', 'Training set', 'Natural language processing', 'Semi-supervised learning', 'Supervised learning', 'Artificial neural network', 'Economics', 'Biology', 'Management', 'Computer security', 'Genetics']","We study the problem of generating keyphrases that summarize the key points for a given document. While sequence-to-sequence (seq2seq) models have achieved remarkable performance on this task (Meng et al., 2017), model training often relies on large amounts of labeled data, which is only applicable to resource-rich domains. In this paper, we propose semi-supervised keyphrase generation methods by leveraging both labeled data and large-scale unlabeled samples for learning. Two strategies are proposed. First, unlabeled documents are first tagged with synthetic keyphrases obtained from unsupervised keyphrase extraction methods or a self-learning algorithm, and then combined with labeled samples for training. Furthermore, we investigate a multi-task learning framework to jointly learn to generate keyphrases as well as the titles of the articles. Experimental results show that our semi-supervised learning-based methods outperform a state-of-the-art model trained with labeled data only."
https://openalex.org/W2788557041,Does Distributionally Robust Supervised Learning Give Robust Classifiers?,"{'Distributionally': [0], 'Robust': [1], 'Supervised': [2], 'Learning': [3], '(DRSL)': [4], 'is': [5, 16, 70, 114, 145], 'necessary': [6], 'for': [7, 73], 'building': [8], 'reliable': [9], 'machine': [10, 14], 'learning': [11, 15], 'systems.': [12], 'When': [13], 'deployed': [17], 'in': [18, 127], 'the': [19, 44, 50, 64, 68, 98, 109, 123, 130, 133, 139], 'real': [20], 'world,': [21], 'its': [22, 163], 'performance': [23], 'can': [24, 88], 'be': [25, 143], 'significantly': [26], 'degraded': [27], 'because': [28], 'test': [29], 'data': [30], 'may': [31], 'follow': [32], 'a': [33, 74, 84, 104], 'different': [34], 'distribution': [35, 46, 75], 'from': [36, 120], 'training': [37, 53, 111], 'data.': [38], 'DRSL': [39, 69, 99, 140, 155], 'with': [40], 'f-divergences': [41], 'explicitly': [42, 71], 'considers': [43], 'worst-case': [45], 'shift': [47, 76], 'by': [48, 149], 'minimizing': [49], 'adversarially': [51], 'reweighted': [52], 'loss.': [54], 'In': [55], 'this': [56, 60, 158], 'paper,': [57], 'we': [58, 78, 95, 152], 'analyze': [59], 'DRSL,': [61], 'focusing': [62], 'on': [63], 'classification': [65, 128], 'scenario.': [66], 'Since': [67], 'formulated': [72], 'scenario,': [77], 'naturally': [79], 'expect': [80], 'it': [81], 'to': [82, 137, 142], 'give': [83], 'robust': [85, 144], 'classifier': [86, 105], 'that': [87, 97, 106, 132, 156], 'aggressively': [89], 'handle': [90], 'shifted': [91], 'distributions.': [92], 'However,': [93], 'surprisingly,': [94], 'prove': [96], 'just': [100], 'ends': [101], 'up': [102], 'giving': [103], 'exactly': [107], 'fits': [108], 'given': [110], 'distribution,': [112], 'which': [113, 138], 'too': [115, 146], 'pessimistic.': [116], 'This': [117], 'pessimism': [118, 159], 'comes': [119], 'two': [121], 'sources:': [122], 'particular': [124], 'losses': [125], 'used': [126], 'and': [129, 160], 'fact': [131], 'variety': [134], 'of': [135], 'distributions': [136], 'tries': [141], 'wide.': [147], 'Motivated': [148], 'our': [150], 'analysis,': [151], 'propose': [153], 'simple': [154], 'overcomes': [157], 'empirically': [161], 'demonstrate': [162], 'effectiveness.': [164]}",2016,"['Pessimism', 'Classifier (UML)', 'Machine learning', 'Computer science', 'Artificial intelligence', 'Training set', 'Robustness (evolution)', 'Binary classification', 'Mathematical optimization', 'Mathematics', 'Support vector machine', 'Chemistry', 'Epistemology', 'Biochemistry', 'Gene', 'Philosophy']","Distributionally Robust Supervised Learning (DRSL) is necessary for building reliable machine learning systems. When machine learning is deployed in the real world, its performance can be significantly degraded because test data may follow a different distribution from training data. DRSL with f-divergences explicitly considers the worst-case distribution shift by minimizing the adversarially reweighted training loss. In this paper, we analyze this DRSL, focusing on the classification scenario. Since the DRSL is explicitly formulated for a distribution shift scenario, we naturally expect it to give a robust classifier that can aggressively handle shifted distributions. However, surprisingly, we prove that the DRSL just ends up giving a classifier that exactly fits the given training distribution, which is too pessimistic. This pessimism comes from two sources: the particular losses used in classification and the fact that the variety of distributions to which the DRSL tries to be robust is too wide. Motivated by our analysis, we propose simple DRSL that overcomes this pessimism and empirically demonstrate its effectiveness."
https://openalex.org/W1988412055,Improving activity classification for health applications on mobile devices using active and semi-supervised learning,"{'Mobile': [0], ""phones'"": [1], 'increasing': [2], 'ubiquity': [3], 'has': [4], 'created': [5], 'many': [6], 'opportunities': [7], 'for': [8, 28], 'personal': [9], 'context': [10], 'sensing.': [11], 'Personal': [12], 'activity': [13, 38], 'is': [14, 26], 'an': [15], 'important': [16], 'part': [17], 'of': [18, 37], 'a': [19, 35], ""user's"": [20], 'context,': [21], 'and': [22, 30], 'automatically': [23], 'recognizing': [24], 'it': [25], 'vital': [27], 'health': [29], 'fitness': [31], 'monitoring': [32, 41], 'applications.': [33], 'Recording': [34], 'stream': [36], 'data': [39], 'enables': [40]}",2010,"['Computer science', 'Context (archaeology)', 'Activity recognition', 'Mobile device', 'Human–computer interaction', 'Mobile computing', 'Activity detection', 'Multimedia', 'Data science', 'World Wide Web', 'Machine learning', 'Artificial intelligence', 'Telecommunications', 'Biology', 'Paleontology']","Mobile phones' increasing ubiquity has created many opportunities for personal context sensing. Personal activity is an important part of a user's context, and automatically recognizing it is vital for health and fitness monitoring applications. Recording a stream of activity data enables monitoring"
https://openalex.org/W2612953412,Supervised Learning of Universal Sentence Representations from Natural Language Inference Data,"{'Many': [0], 'modern': [1], 'NLP': [2, 126], 'systems': [3], 'rely': [4], 'on': [5, 14, 85], 'word': [6], 'embeddings,': [7], 'previously': [8], 'trained': [9, 65], 'in': [10], 'an': [11], 'unsupervised': [12, 42, 80], 'manner': [13], 'large': [15], 'corpora,': [16], 'as': [17, 30], 'base': [18], 'features.': [19], 'Efforts': [20], 'to': [21, 52, 99, 107, 113, 124], 'obtain': [22, 100], 'embeddings': [23], 'for': [24, 121], 'larger': [25], 'chunks': [26], 'of': [27, 44, 70, 89, 117], 'text,': [28], 'such': [29], 'sentences,': [31], 'have': [32, 46], 'however': [33], 'not': [34, 47], 'been': [35], 'so': [36], 'successful.': [37], 'Several': [38], 'attempts': [39], 'at': [40], 'learning': [41, 123], 'representations': [43, 64], 'sentences': [45], 'reached': [48], 'satisfactory': [49], 'enough': [50], 'performance': [51], 'be': [53, 105], 'widely': [54], 'adopted.': [55], 'In': [56], 'this': [57], 'paper,': [58], 'we': [59], 'show': [60], 'how': [61, 94], 'universal': [62], 'sentence': [63], 'using': [66], 'the': [67, 71, 115], 'supervised': [68], 'data': [69], 'Stanford': [72], 'Natural': [73], 'Language': [74], 'Inference': [75], 'datasets': [76], 'can': [77, 103], 'consistently': [78], 'outperform': [79], 'methods': [81], 'like': [82, 93], 'SkipThought': [83], 'vectors': [84], 'a': [86], 'wide': [87], 'range': [88], 'transfer': [90, 122], 'tasks.': [91, 127], 'Much': [92], 'computer': [95], 'vision': [96], 'uses': [97], 'ImageNet': [98], 'features,': [101], 'which': [102], 'then': [104], 'transferred': [106], 'other': [108, 125], 'tasks,': [109], 'our': [110], 'work': [111], 'tends': [112], 'indicate': [114], 'suitability': [116], 'natural': [118], 'language': [119], 'inference': [120], 'Our': [128], 'encoder': [129], 'is': [130], 'publicly': [131], 'available.': [132]}",2017,"['Computer science', 'Artificial intelligence', 'Natural language processing', 'Inference', 'Sentence', 'Transfer of learning', 'Unsupervised learning', 'Word (group theory)', 'Natural language', 'Encoder', 'Machine learning', 'Linguistics', 'Philosophy', 'Operating system']","Many modern NLP systems rely on word embeddings, previously trained in an unsupervised manner on large corpora, as base features. Efforts to obtain embeddings for larger chunks of text, such as sentences, have however not been so successful. Several attempts at learning unsupervised representations of sentences have not reached satisfactory enough performance to be widely adopted. In this paper, we show how universal sentence representations trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors on a wide range of transfer tasks. Much like how computer vision uses ImageNet to obtain features, which can then be transferred to other tasks, our work tends to indicate the suitability of natural language inference for transfer learning to other NLP tasks. Our encoder is publicly available."
https://openalex.org/W4385285835,Scaling Self-Supervised Learning for Histopathology with Masked Image Modeling,"{'Computational': [0], 'pathology': [1, 7, 55], 'is': [2, 71, 117], 'revolutionizing': [3], 'the': [4, 51, 132, 158, 167, 213, 264, 268, 271], 'field': [5], 'of': [6, 47, 53, 102, 134, 148, 169, 224, 273], 'by': [8, 30], 'integrating': [9], 'advanced': [10], 'computer': [11], 'vision': [12], 'and': [13, 37, 45, 74, 98, 116, 160, 189, 282], 'machine': [14], 'learning': [15, 124, 197], 'technologies': [16], 'into': [17], 'diagnostic': [18], 'workflows.': [19], 'It': [20], 'offers': [21], 'unprecedented': [22], 'opportunities': [23], 'for': [24, 172, 270, 277], 'improved': [25], 'efficiency': [26], 'in': [27, 39, 56, 64, 251, 263], 'treatment': [28], 'decisions': [29], 'allowing': [31], 'pathologists': [32], 'to': [33, 76, 92, 120, 136, 215, 258], 'achieve': [34], 'higher': [35], 'precision': [36], 'objectivity': [38], 'disease': [40], 'classification,': [41], 'tumor': [42], 'microenvironment': [43], 'description': [44], 'identification': [46], 'new': [48], 'biomarkers.': [49], 'However,': [50], 'potential': [52], 'computational': [54], 'personalized': [57], 'medicine': [58], 'comes': [59], 'with': [60, 183, 193], 'significant': [61], 'challenges,': [62, 82], 'particularly': [63], 'annotating': [65], 'whole': [66], 'slide': [67, 159], 'images': [68, 242], '(WSI),': [69], 'which': [70], 'time-consuming,': [72], 'costly': [73], 'subject': [75], 'inter-observer': [77], 'variability.': [78], 'To': [79], 'address': [80], 'these': [81], 'Self-Supervised': [83], 'Learning': [84], '(SSL)': [85], 'has': [86, 114], 'emerged': [87, 115], 'as': [88, 110], 'a': [89, 111, 140, 145, 190, 194, 221, 274], 'promising': [90], 'solution': [91], 'learn': [93, 216], 'representations': [94, 218], 'from': [95, 243], 'histology': [96, 137, 173, 241], 'patches': [97], 'leverage': [99], 'large': [100, 170, 222], 'volumes': [101], 'unlabelled': [103], 'WSI.': [104], 'Recently,': [105], 'Masked': [106], 'Image': [107], 'Modeling': [108], '(MIM)': [109], 'SSL': [112, 260], 'framework': [113], 'now': [118], 'considered': [119], 'outperform': [121], 'purely': [122, 195], 'contrastive': [123, 196], 'paradigms.': [125], 'In': [126], 'this': [127], 'work,': [128], 'we': [129, 163, 178, 202], 'therefore': [130], 'explore': [131], 'application': [133], 'MIM': [135], 'using': [138, 175], 'iBOT,': [139], 'self-supervised': [141], 'transformer-based': [142], 'framework.': [143], 'Through': [144], 'wide': [146], 'range': [147], '17': [149], 'downstream': [150, 225], 'tasks': [151, 256], 'over': [152], 'seven': [153], 'cancer': [154, 246], 'indications,': [155], 'both': [156, 186], 'at': [157, 287], 'patch': [161], 'levels,': [162], 'provide': [164], 'recommendations': [165], 'on': [166, 236], 'pre-training': [168, 182, 188], 'models': [171, 281], 'data': [174], 'MIM.': [176], 'First,': [177], 'demonstrate': [179], 'that': [180, 204, 219], 'in-domain': [181], 'iBOT': [184, 229], 'outperforms': [185], 'ImageNet': [187], 'model': [191, 231, 276], 'pre-trained': [192, 235], 'objective,': [198], 'MoCo': [199], 'v2.': [200], 'Second,': [201], 'show': [203], 'Vision': [205], 'Transformers': [206], '(ViT)': [207], 'models,': [208], 'when': [209], 'scaled': [210], 'appropriately,': [211], 'have': [212], 'capability': [214], 'pan-cancer': [217], 'benefit': [220], 'variety': [223], 'tasks.': [226], 'Finally,': [227], 'our': [228], 'ViT-Base': [230], '(80': [232], 'million': [233, 240], 'parameters),': [234], 'more': [237], 'than': [238], '40': [239], '16': [244], 'different': [245], 'types,': [247], 'achieves': [248], 'state-of-the-art': [249], 'performance': [250], 'most': [252], 'weakly-supervised': [253], 'WSI': [254], 'classification': [255], 'compared': [257], 'other': [259], 'frameworks': [261], 'available': [262, 286], 'literature.': [265], 'This': [266], 'paves': [267], 'way': [269], 'development': [272], 'foundation': [275], 'histopathology.': [278], 'Our': [279], 'code,': [280], 'features': [283], 'are': [284], 'publicly': [285], 'https://github.com/owkin/HistoSSLscaling': [288], '.': [289]}",2023,"['Computer science', 'Artificial intelligence', 'Machine learning', 'Leverage (statistics)', 'Digital pathology', 'Workflow', 'Pattern recognition (psychology)', 'Database']","Computational pathology is revolutionizing the field of pathology by integrating advanced computer vision and machine learning technologies into diagnostic workflows. It offers unprecedented opportunities for improved efficiency in treatment decisions by allowing pathologists to achieve higher precision and objectivity in disease classification, tumor microenvironment description and identification of new biomarkers. However, the potential of computational pathology in personalized medicine comes with significant challenges, particularly in annotating whole slide images (WSI), which is time-consuming, costly and subject to inter-observer variability. To address these challenges, Self-Supervised Learning (SSL) has emerged as a promising solution to learn representations from histology patches and leverage large volumes of unlabelled WSI. Recently, Masked Image Modeling (MIM) as a SSL framework has emerged and is now considered to outperform purely contrastive learning paradigms. In this work, we therefore explore the application of MIM to histology using iBOT, a self-supervised transformer-based framework. Through a wide range of 17 downstream tasks over seven cancer indications, both at the slide and patch levels, we provide recommendations on the pre-training of large models for histology data using MIM. First, we demonstrate that in-domain pre-training with iBOT outperforms both ImageNet pre-training and a model pre-trained with a purely contrastive learning objective, MoCo v2. Second, we show that Vision Transformers (ViT) models, when scaled appropriately, have the capability to learn pan-cancer representations that benefit a large variety of downstream tasks. Finally, our iBOT ViT-Base model (80 million parameters), pre-trained on more than 40 million histology images from 16 different cancer types, achieves state-of-the-art performance in most weakly-supervised WSI classification tasks compared to other SSL frameworks available in the literature. This paves the way for the development of a foundation model for histopathology. Our code, models and features are publicly available at https://github.com/owkin/HistoSSLscaling ."
https://openalex.org/W4223948957,Survey on Self-Supervised Learning: Auxiliary Pretext Tasks and Contrastive Learning Methods in Imaging,"{'Although': [0], 'deep': [1], 'learning': [2, 21, 106, 112, 150], 'algorithms': [3], 'have': [4], 'achieved': [5], 'significant': [6], 'progress': [7], 'in': [8, 55, 111, 129], 'a': [9, 86, 136, 159], 'variety': [10], 'of': [11, 77, 140, 162, 166, 173], 'domains,': [12], 'they': [13], 'require': [14], 'costly': [15], 'annotations': [16], 'on': [17, 81, 100], 'huge': [18], 'datasets.': [19], 'Self-supervised': [20], '(SSL)': [22], 'using': [23, 43, 91, 145], 'unlabeled': [24], 'data': [25], 'has': [26, 107], 'emerged': [27], 'as': [28, 31, 69, 85], 'an': [29, 171], 'alternative,': [30], 'it': [32, 118], 'eliminates': [33], 'manual': [34, 49], 'annotation.': [35], 'To': [36, 116], 'do': [37], 'this,': [38], 'SSL': [39, 78, 143], 'constructs': [40], 'feature': [41], 'representations': [42, 62, 90, 113], 'pretext': [44, 83, 147, 174], 'tasks': [45, 57, 67, 84, 175], 'that': [46, 63, 95], 'operate': [47], 'without': [48], 'annotation,': [50], 'which': [51], 'allows': [52], 'models': [53], 'trained': [54], 'these': [56], 'to': [58, 88, 186], 'extract': [59], 'useful': [60], 'latent': [61, 131], 'later': [64], 'improve': [65], 'downstream': [66], 'such': [68], 'object': [70], 'classification': [71], 'and': [72, 124, 148, 169, 176, 189, 195], 'detection.': [73], 'The': [74], 'early': [75], 'methods': [76, 144, 184], 'are': [79], 'based': [80, 99], 'auxiliary': [82, 146], 'way': [87], 'learn': [89], 'pseudo-labels,': [92], 'or': [93], 'labels': [94], 'were': [96], 'created': [97], 'automatically': [98], 'the': [101, 130, 141, 154, 164, 167], 'dataset’s': [102], 'attributes.': [103], 'Furthermore,': [104], 'contrastive': [105, 149], 'also': [108, 180], 'performed': [109], 'well': [110], 'via': [114], 'SSL.': [115, 200], 'succeed,': [117], 'pushes': [119], 'positive': [120], 'samples': [121], 'closer': [122], 'together,': [123], 'negative': [125], 'ones': [126], 'further': [127, 193], 'apart,': [128], 'space.': [132], 'This': [133], 'paper': [134], 'provides': [135, 170], 'comprehensive': [137], 'literature': [138], 'review': [139], 'top-performing': [142], 'techniques.': [151], 'It': [152, 179], 'details': [153], 'motivation': [155], 'for': [156], 'this': [157], 'research,': [158], 'general': [160], 'pipeline': [161], 'SSL,': [163], 'terminologies': [165], 'field,': [168], 'examination': [172], 'self-supervised': [177, 183], 'methods.': [178], 'examines': [181], 'how': [182], 'compare': [185], 'supervised': [187], 'ones,': [188], 'then': [190], 'discusses': [191], 'both': [192], 'considerations': [194], 'ongoing': [196], 'challenges': [197], 'faced': [198], 'by': [199]}",2022,"['Pretext', 'Computer science', 'Artificial intelligence', 'Annotation', 'Machine learning', 'Pipeline (software)', 'Natural language processing', 'Object (grammar)', 'Supervised learning', 'Artificial neural network', 'Politics', 'Programming language', 'Political science', 'Law']","Although deep learning algorithms have achieved significant progress in a variety of domains, they require costly annotations on huge datasets. Self-supervised learning (SSL) using unlabeled data has emerged as an alternative, as it eliminates manual annotation. To do this, SSL constructs feature representations using pretext tasks that operate without manual annotation, which allows models trained in these tasks to extract useful latent representations that later improve downstream tasks such as object classification and detection. The early methods of SSL are based on auxiliary pretext tasks as a way to learn representations using pseudo-labels, or labels that were created automatically based on the dataset’s attributes. Furthermore, contrastive learning has also performed well in learning representations via SSL. To succeed, it pushes positive samples closer together, and negative ones further apart, in the latent space. This paper provides a comprehensive literature review of the top-performing SSL methods using auxiliary pretext and contrastive learning techniques. It details the motivation for this research, a general pipeline of SSL, the terminologies of the field, and provides an examination of pretext tasks and self-supervised methods. It also examines how self-supervised methods compare to supervised ones, and then discusses both further considerations and ongoing challenges faced by SSL."
https://openalex.org/W3036224891,Unsupervised Learning of Visual Features by Contrasting Cluster Assignments,"{'Unsupervised': [0], 'image': [1], 'representations': [2], 'have': [3], 'significantly': [4], 'reduced': [5], 'the': [6, 13, 67, 82, 105, 112, 188, 215], 'gap': [7], 'with': [8, 12, 122, 177, 205], 'supervised': [9, 211], 'pretraining,': [10], 'notably': [11], 'recent': [14], 'achievements': [15], 'of': [16, 32, 53, 81, 86, 108, 114, 133, 175, 182], 'contrastive': [17, 21, 54, 92, 138], 'learning': [18], 'methods.': [19], 'These': [20], 'methods': [22, 55], 'typically': [23], 'work': [24], 'online': [25, 47], 'and': [26, 124, 127], 'rely': [27], 'on': [28, 203, 213], 'a': [29, 98, 109, 151, 156, 165, 173], 'large': [30, 123, 152], 'number': [31], 'explicit': [33], 'pairwise': [34, 60], 'feature': [35], 'comparisons,': [36], 'which': [37], 'is': [38, 142], 'computationally': [39], 'challenging.': [40], 'In': [41, 160], 'this': [42], 'paper,': [43], 'we': [44, 96, 103, 162], 'propose': [45, 164], 'an': [46], 'algorithm,': [48], 'SwAV,': [49], 'that': [50, 171], 'takes': [51], 'advantage': [52], 'without': [56, 186], 'requiring': [57], 'to': [58, 130, 136], 'compute': [59, 191], 'comparisons.': [61], 'Specifically,': [62], 'our': [63, 140, 196], 'method': [64, 118, 141], 'simultaneously': [65], 'clusters': [66], 'data': [68, 167], 'while': [69], 'enforcing': [70], 'consistency': [71], 'between': [72], 'cluster': [73, 106], 'assignments': [74], 'produced': [75], 'for': [76], 'different': [77, 178], 'augmentations': [78], '(or': [79], 'views)': [80], 'same': [83], 'image,': [84], 'instead': [85], 'comparing': [87], 'features': [88], 'directly': [89], 'as': [90, 207, 209], 'in': [91, 180], 'learning.': [93], 'Simply': [94], 'put,': [95], 'use': [97], 'swapped': [99], 'prediction': [100], 'mechanism': [101], 'where': [102], 'predict': [104], 'assignment': [107], 'view': [110], 'from': [111], 'representation': [113], 'another': [115], 'view.': [116], 'Our': [117], 'can': [119, 128], 'be': [120], 'trained': [121], 'small': [125], 'batches': [126], 'scale': [129], 'unlimited': [131], 'amounts': [132], 'data.': [134], 'Compared': [135], 'previous': [137], 'methods,': [139], 'more': [143], 'memory': [144, 153, 189], 'efficient': [145], 'since': [146], 'it': [147], 'does': [148], 'not': [149], 'require': [150], 'bank': [154], 'or': [155, 190], 'special': [157], 'momentum': [158], 'network.': [159], 'addition,': [161], 'also': [163], 'new': [166], 'augmentation': [168], 'strategy,': [169], 'multi-crop,': [170], 'uses': [172], 'mix': [174], 'views': [176], 'resolutions': [179], 'place': [181], 'two': [183], 'full-resolution': [184], 'views,': [185], 'increasing': [187], 'requirements': [192], 'much.': [193], 'We': [194], 'validate': [195], 'findings': [197], 'by': [198], 'achieving': [199], '75.3%': [200], 'top-1': [201], 'accuracy': [202], 'ImageNet': [204], 'ResNet-50,': [206], 'well': [208], 'surpassing': [210], 'pretraining': [212], 'all': [214], 'considered': [216], 'transfer': [217], 'tasks.': [218]}",2020,"['Computer science', 'Pairwise comparison', 'Artificial intelligence', 'Consistency (knowledge bases)', 'Representation (politics)', 'Feature (linguistics)', 'Machine learning', 'Pattern recognition (psychology)', 'Politics', 'Philosophy', 'Political science', 'Linguistics', 'Law']","Unsupervised image representations have significantly reduced the gap with supervised pretraining, notably with the recent achievements of contrastive learning methods. These contrastive methods typically work online and rely on a large number of explicit pairwise feature comparisons, which is computationally challenging. In this paper, we propose an online algorithm, SwAV, that takes advantage of contrastive methods without requiring to compute pairwise comparisons. Specifically, our method simultaneously clusters the data while enforcing consistency between cluster assignments produced for different augmentations (or views) of the same image, instead of comparing features directly as in contrastive learning. Simply put, we use a swapped prediction mechanism where we predict the cluster assignment of a view from the representation of another view. Our method can be trained with large and small batches and can scale to unlimited amounts of data. Compared to previous contrastive methods, our method is more memory efficient since it does not require a large memory bank or a special momentum network. In addition, we also propose a new data augmentation strategy, multi-crop, that uses a mix of views with different resolutions in place of two full-resolution views, without increasing the memory or compute requirements much. We validate our findings by achieving 75.3% top-1 accuracy on ImageNet with ResNet-50, as well as surpassing supervised pretraining on all the considered transfer tasks."
https://openalex.org/W2116435618,Unsupervised Learning of Video Representations using LSTMs,"{'We': [0, 56, 82, 99, 126, 135, 151, 174], 'use': [1], 'multilayer': [2], 'Long': [3], 'Short': [4], 'Term': [5], 'Memory': [6], '(LSTM)': [7], 'networks': [8], 'to': [9, 21, 41, 107, 128], 'learn': [10], 'representations': [11, 71, 155, 178], 'of': [12, 61, 66, 73, 103, 200], 'video': [13, 74, 117], 'sequences.': [14], 'Our': [15], 'model': [16, 105, 112, 139], 'uses': [17], 'an': [18, 23], 'encoder': [19], 'LSTM': [20], 'map': [22], 'input': [24, 49, 62], 'sequence': [25], 'into': [26, 119, 123], 'a': [27, 78, 160, 188], 'fixed': [28], 'length': [29], 'representation.': [30], 'This': [31], 'representation': [32, 118], 'is': [33], 'decoded': [34], 'using': [35, 77], 'single': [36], 'or': [37, 51], 'multiple': [38], 'decoder': [39, 91], 'LSTMs': [40, 92], 'perform': [42], 'different': [43, 84], 'tasks,': [44], 'such': [45, 87], 'as': [46, 88], 'reconstructing': [47], 'the': [48, 53, 90, 96, 101, 104, 111, 115, 120, 124, 132, 138, 154, 169, 177], 'sequence,': [50], 'predicting': [52], 'future': [54, 121], 'sequence.': [55], 'experiment': [57], 'with': [58], 'two': [59], 'kinds': [60], 'sequences': [63], '-': [64, 164], 'patches': [65], 'image': [67], 'pixels': [68], 'and': [69, 122, 130, 147, 171], 'high-level': [70], '(""percepts"")': [72], 'frames': [75], 'extracted': [76], 'pretrained': [79, 194], 'convolutional': [80], 'net.': [81], 'explore': [83], 'design': [85], 'choices': [86], 'whether': [89], 'should': [93], 'condition': [94], 'on': [95, 143, 148, 168, 195], 'generated': [97], 'output.': [98], 'analyze': [100], 'outputs': [102], 'qualitatively': [106], 'see': [108], 'how': [109], 'well': [110], 'can': [113, 203], 'extrapolate': [114], 'learned': [116, 133], 'past.': [125], 'try': [127], 'visualize': [129], 'interpret': [131], 'features.': [134], 'stress': [136], 'test': [137], 'by': [140, 156], 'running': [141], 'it': [142], 'longer': [144], 'time': [145], 'scales': [146], 'out-of-domain': [149], 'data.': [150], 'further': [152], 'evaluate': [153], 'finetuning': [157], 'them': [158], 'for': [159], 'supervised': [161], 'learning': [162], 'problem': [163], 'human': [165], 'action': [166, 205], 'recognition': [167, 206], 'UCF-101': [170], 'HMDB-51': [172], 'datasets.': [173], 'show': [175], 'that': [176], 'help': [179, 204], 'improve': [180], 'classification': [181], 'accuracy,': [182], 'especially': [183], 'when': [184], 'there': [185], 'are': [186], 'only': [187], 'few': [189], 'training': [190], 'examples.': [191], 'Even': [192], 'models': [193], 'unrelated': [196], 'datasets': [197], '(300': [198], 'hours': [199], 'YouTube': [201], 'videos)': [202], 'performance.': [207]}",2015,"['Computer science', 'Encoder', 'Artificial intelligence', 'Representation (politics)', 'Sequence (biology)', 'Pattern recognition (psychology)', 'Feature learning', 'Convolutional neural network', 'Deep learning', 'Sequence labeling', 'Machine learning', 'Task (project management)', 'Economics', 'Operating system', 'Political science', 'Law', 'Genetics', 'Politics', 'Management', 'Biology']","We use multilayer Long Short Term Memory (LSTM) networks to learn representations of video sequences. Our model uses an encoder LSTM to map an input sequence into a fixed length representation. This representation is decoded using single or multiple decoder LSTMs to perform different tasks, such as reconstructing the input sequence, or predicting the future sequence. We experiment with two kinds of input sequences - patches of image pixels and high-level representations (""percepts"") of video frames extracted using a pretrained convolutional net. We explore different design choices such as whether the decoder LSTMs should condition on the generated output. We analyze the outputs of the model qualitatively to see how well the model can extrapolate the learned video representation into the future and into the past. We try to visualize and interpret the learned features. We stress test the model by running it on longer time scales and on out-of-domain data. We further evaluate the representations by finetuning them for a supervised learning problem - human action recognition on the UCF-101 and HMDB-51 datasets. We show that the representations help improve classification accuracy, especially when there are only a few training examples. Even models pretrained on unrelated datasets (300 hours of YouTube videos) can help action recognition performance."
https://openalex.org/W3146944767,Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences,"{'Significance': [0], 'Learning': [1], 'biological': [2, 59], 'properties': [3, 50], 'from': [4], 'sequence': [5], 'data': [6], 'is': [7], 'a': [8, 23], 'logical': [9], 'step': [10], 'toward': [11], 'generative': [12], 'and': [13, 58, 81, 94, 97], 'predictive': [14], 'artificial': [15], 'intelligence': [16], 'for': [17, 70, 101], 'biology.': [18], 'Here,': [19], 'we': [20], 'propose': [21], 'scaling': [22], 'deep': [24], 'contextual': [25], 'language': [26], 'model': [27], 'with': [28], 'unsupervised': [29], 'learning': [30, 86], 'to': [31], 'sequences': [32], 'spanning': [33], 'evolutionary': [34], 'diversity.': [35], 'We': [36, 61], 'find': [37], 'that': [38], 'without': [39], 'prior': [40], 'knowledge,': [41], 'information': [42], 'emerges': [43], 'in': [44], 'the': [45, 63], 'learned': [46, 64], 'representations': [47, 65], 'on': [48], 'fundamental': [49], 'of': [51, 75, 91], 'proteins': [52], 'such': [53], 'as': [54], 'secondary': [55, 76, 95], 'structure,': [56, 77], 'contacts,': [57, 80], 'activity.': [60], 'show': [62], 'are': [66], 'useful': [67], 'across': [68], 'benchmarks': [69], 'remote': [71], 'homology': [72], 'detection,': [73], 'prediction': [74, 90], 'long-range': [78, 102], 'residue–residue': [79], 'mutational': [82, 92], 'effect.': [83], 'Unsupervised': [84], 'representation': [85], 'enables': [87], 'state-of-the-art': [88, 99], 'supervised': [89], 'effect': [93], 'structure': [96], 'improves': [98], 'features': [100], 'contact': [103], 'prediction.': [104]}",2021,"['Artificial intelligence', 'Generative grammar', 'Generative model', 'Unsupervised learning', 'Computer science', 'Machine learning', 'Protein secondary structure', 'Biology', 'Biochemistry']","Significance Learning biological properties from sequence data is a logical step toward generative and predictive artificial intelligence for biology. Here, we propose scaling a deep contextual language model with unsupervised learning to sequences spanning evolutionary diversity. We find that without prior knowledge, information emerges in the learned representations on fundamental properties of proteins such as secondary structure, contacts, and biological activity. We show the learned representations are useful across benchmarks for remote homology detection, prediction of secondary structure, long-range residue–residue contacts, and mutational effect. Unsupervised representation learning enables state-of-the-art supervised prediction of mutational effect and secondary structure and improves state-of-the-art features for long-range contact prediction."
https://openalex.org/W2129069237,Deep Unsupervised Learning using Nonequilibrium Thermodynamics,"{'A': [0], 'central': [1], 'problem': [2], 'in': [3, 17, 57, 77, 102], 'machine': [4], 'learning': [5], 'involves': [6], 'modeling': [7], 'complex': [8], 'data-sets': [9], 'using': [10], 'highly': [11, 81], 'flexible': [12, 82], 'families': [13], 'of': [14, 87, 108, 134], 'probability': [15], 'distributions': [16], 'which': [18], 'learning,': [19], 'sampling,': [20], 'inference,': [21], 'and': [22, 40, 53, 83, 99, 119], 'evaluation': [23], 'are': [24], 'still': [25], 'analytically': [26], 'or': [27, 110], 'computationally': [28], 'tractable.': [29], 'Here,': [30], 'we': [31], 'develop': [32], 'an': [33, 62, 129], 'approach': [34, 91], 'that': [35, 74], 'simultaneously': [36], 'achieves': [37], 'both': [38], 'flexibility': [39], 'tractability.': [41], 'The': [42], 'essential': [43], 'idea,': [44], 'inspired': [45], 'by': [46], 'non-equilibrium': [47], 'statistical': [48], 'physics,': [49], 'is': [50], 'to': [51, 94, 116], 'systematically': [52], 'slowly': [54], 'destroy': [55], 'structure': [56, 76], 'a': [58, 70, 80], 'data': [59], 'distribution': [60], 'through': [61], 'iterative': [63], 'forward': [64], 'diffusion': [65, 72], 'process.': [66], 'We': [67, 126], 'then': [68], 'learn': [69], 'reverse': [71], 'process': [73], 'restores': [75], 'data,': [78], 'yielding': [79], 'tractable': [84], 'generative': [85, 104], 'model': [86], 'the': [88, 123, 135], 'data.': [89], 'This': [90], 'allows': [92], 'us': [93], 'rapidly': [95], 'learn,': [96], 'sample': [97], 'from,': [98], 'evaluate': [100], 'probabilities': [101, 121], 'deep': [103], 'models': [105], 'with': [106], 'thousands': [107], 'layers': [109], 'time': [111], 'steps,': [112], 'as': [113, 115], 'well': [114], 'compute': [117], 'conditional': [118], 'posterior': [120], 'under': [122], 'learned': [124], 'model.': [125], 'additionally': [127], 'release': [128], 'open': [130], 'source': [131], 'reference': [132], 'implementation': [133], 'algorithm.': [136]}",2015,"['Non-equilibrium thermodynamics', 'Thermodynamics', 'Statistical physics', 'Economics', 'Artificial intelligence', 'Physics', 'Computer science']","A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm."
https://openalex.org/W1570411240,Unsupervised learning of digit recognition using spike-timing-dependent plasticity,"{'In': [0], 'order': [1], 'to': [2, 17, 33, 44, 66, 81, 109, 165], 'understand': [3], 'how': [4, 39, 58], 'the': [5, 23, 166, 179, 201, 209, 217, 234], 'mammalian': [6], 'neocortex': [7], 'is': [8, 53, 120, 183], 'performing': [9], 'computations,': [10], 'two': [11], 'things': [12], 'are': [13, 42], 'necessary;': [14], 'we': [15, 31, 151, 194], 'need': [16, 32], 'have': [18], 'a': [19, 35, 78, 103, 110, 114, 155], 'good': [20], 'understanding': [21, 37], 'of': [22, 38, 131, 204, 211, 219, 233, 237], 'available': [24], 'neuronal': [25], 'processing': [26], 'units': [27], 'and': [28, 30, 106, 142, 158, 222], 'mechanisms,': [29, 238], 'gain': [34], 'better': [36, 184], 'those': [40], 'mechanisms': [41, 88, 123], 'combined': [43], 'build': [45], 'functioning': [46], 'systems.': [47], 'Therefore,': [48], 'in': [49, 57, 102, 242], 'recent': [50], 'years': [51], 'there': [52], 'an': [54, 143], 'increasing': [55], 'interest': [56], 'spiking': [59, 145], 'neural': [60, 245], 'networks': [61], '(SNN)': [62], 'can': [63], 'be': [64], 'used': [65, 195, 221], 'perform': [67], 'complex': [68], 'computations': [69], 'or': [70], 'solve': [71], 'pattern': [72], 'recognition': [73, 118], 'tasks.': [74], 'However,': [75], 'it': [76], 'remains': [77], 'challenging': [79], 'task': [80], 'design': [82], 'SNNs': [83], 'which': [84, 119, 182, 239], 'use': [85, 154], 'biologically': [86], 'plausible': [87], '(especially': [89], 'for': [90, 116, 226], 'learning': [91, 171, 229], 'new': [92], 'patterns),': [93], 'since': [94], 'most': [95, 148], 'such': [96], 'SNN': [97, 115, 187], 'architectures': [98], 'rely': [99], 'on': [100, 122, 178], 'training': [101], 'rate-based': [104], 'network': [105, 206, 213], 'subsequent': [107], 'conversion': [108], 'SNN.': [111], 'We': [112], 'present': [113, 161], 'digit': [117], 'based': [121], 'with': [124, 136, 216], 'increased': [125], 'biological': [126, 244], 'plausibility,': [127], 'i.e.,': [128], 'conductance-based': [129], 'instead': [130], 'current-based': [132], 'synapses,': [133], 'spike-timing-dependent': [134], 'plasticity': [135], 'time-dependent': [137], 'weight': [138], 'change,': [139], 'lateral': [140], 'inhibition,': [141], 'adaptive': [144], 'threshold.': [146], 'Unlike': [147], 'other': [149], 'systems,': [150], 'do': [152, 159], 'not': [153, 160], 'teaching': [156], 'signal': [157], 'any': [162], 'class': [163], 'labels': [164], 'network.': [167], 'Using': [168], 'this': [169], 'unsupervised': [170], 'scheme,': [172], 'our': [173, 205, 212], 'architecture': [174], 'achieves': [175], '95%': [176], 'accuracy': [177], 'MNIST': [180], 'benchmark,': [181], 'than': [185], 'previous': [186], 'implementations': [188], 'without': [189], 'supervision.': [190], 'The': [191], 'fact': [192], 'that': [193], 'no': [196], 'domain-specific': [197], 'knowledge': [198], 'points': [199], 'toward': [200], 'general': [202], 'applicability': [203, 241], 'design.': [207], 'Also,': [208], 'performance': [210, 225], 'scales': [214], 'well': [215], 'number': [218], 'neurons': [220], 'shows': [223], 'similar': [224], 'four': [227], 'different': [228], 'rules,': [230], 'indicating': [231], 'robustness': [232], 'full': [235], 'combination': [236], 'suggests': [240], 'heterogeneous': [243], 'networks.': [246]}",2015,"['Spiking neural network', 'Computer science', 'Spike-timing-dependent plasticity', 'MNIST database', 'Artificial intelligence', 'Machine learning', 'Robustness (evolution)', 'Artificial neural network', 'Benchmark (surveying)', 'Pattern recognition (psychology)', 'Synaptic plasticity', 'Receptor', 'Gene', 'Biochemistry', 'Geodesy', 'Chemistry', 'Geography']","In order to understand how the mammalian neocortex is performing computations, two things are necessary; we need to have a good understanding of the available neuronal processing units and mechanisms, and we need to gain a better understanding of how those mechanisms are combined to build functioning systems. Therefore, in recent years there is an increasing interest in how spiking neural networks (SNN) can be used to perform complex computations or solve pattern recognition tasks. However, it remains a challenging task to design SNNs which use biologically plausible mechanisms (especially for learning new patterns), since most such SNN architectures rely on training in a rate-based network and subsequent conversion to a SNN. We present a SNN for digit recognition which is based on mechanisms with increased biological plausibility, i.e., conductance-based instead of current-based synapses, spike-timing-dependent plasticity with time-dependent weight change, lateral inhibition, and an adaptive spiking threshold. Unlike most other systems, we do not use a teaching signal and do not present any class labels to the network. Using this unsupervised learning scheme, our architecture achieves 95% accuracy on the MNIST benchmark, which is better than previous SNN implementations without supervision. The fact that we used no domain-specific knowledge points toward the general applicability of our network design. Also, the performance of our network scales well with the number of neurons used and shows similar performance for four different learning rules, indicating robustness of the full combination of mechanisms, which suggests applicability in heterogeneous biological neural networks."
https://openalex.org/W2101711363,Unsupervised Learning of the Morphology of a Natural Language,"{'This': [0], 'study': [1], 'reports': [2], 'the': [3, 17, 57, 61, 73, 84, 89, 99], 'results': [4], 'of': [5, 16, 20, 38, 91, 94, 101], 'using': [6, 23], 'minimum': [7], 'description': [8], 'length': [9], '(MDL)': [10], 'analysis': [11, 74, 97], 'to': [12, 31, 54, 98], 'model': [13], 'unsupervised': [14], 'learning': [15], 'morphological': [18, 45], 'segmentation': [19], 'European': [21], 'languages,': [22], 'corpora': [24], 'ranging': [25], 'in': [26, 104], 'size': [27], 'from': [28], '5,000': [29], 'words': [30], '500,000': [32], 'words.': [33], 'We': [34], 'develop': [35, 42], 'a': [36, 43, 80], 'set': [37], 'heuristics': [39, 62], 'that': [40, 75], 'rapidly': [41], 'probabilistic': [44], 'grammar,': [46], 'and': [47], 'use': [48], 'MDL': [49, 95], 'as': [50], 'our': [51], 'primary': [52], 'tool': [53], 'determine': [55], 'whether': [56], 'modifications': [58], 'proposed': [59], 'by': [60, 79], 'will': [63], 'be': [64, 77], 'adopted': [65], 'or': [66], 'not.': [67], 'The': [68], 'resulting': [69], 'grammar': [70], 'matches': [71], 'well': [72], 'would': [76], 'developed': [78], 'human': [81], 'morphologist.': [82], 'In': [83], 'final': [85], 'section,': [86], 'we': [87], 'discuss': [88], 'relationship': [90], 'this': [92], 'style': [93], 'grammatical': [96], 'notion': [100], 'evaluation': [102], 'metric': [103], 'early': [105], 'generative': [106], 'grammar.': [107]}",2001,"['Computer science', 'Generative grammar', 'Heuristics', 'Natural language processing', 'Artificial intelligence', 'Minimum description length', 'Grammar', 'Metric (unit)', 'Segmentation', 'Set (abstract data type)', 'Natural language', 'Generative model', 'Probabilistic logic', 'Linguistics', 'Programming language', 'Philosophy', 'Economics', 'Operating system', 'Operations management']","This study reports the results of using minimum description length (MDL) analysis to model unsupervised learning of the morphological segmentation of European languages, using corpora ranging in size from 5,000 words to 500,000 words. We develop a set of heuristics that rapidly develop a probabilistic morphological grammar, and use MDL as our primary tool to determine whether the modifications proposed by the heuristics will be adopted or not. The resulting grammar matches well the analysis that would be developed by a human morphologist. In the final section, we discuss the relationship of this style of MDL grammatical analysis to the notion of evaluation metric in early generative grammar."
https://openalex.org/W2414456771,Discovering phase transitions with unsupervised learning,"{'Unsupervised': [0], 'learning': [1, 7], 'is': [2], 'a': [3, 50], 'discipline': [4], 'of': [5, 49, 92, 100], 'machine': [6], 'which': [8], 'aims': [9], 'at\\ndiscovering': [10], 'patterns': [11], 'in': [12, 73], 'big': [13], 'data': [14, 19, 65], 'sets': [15], 'or': [16], 'classifying': [17], 'the': [18, 63, 74, 93], 'into': [20], 'several\\ncategories': [21], 'without': [22], 'being': [23], 'trained': [24], 'explicitly.': [25], 'We': [26, 96], 'show': [27], 'that': [28], 'unsupervised': [29, 108], 'learning\\ntechniques': [30], 'can': [31], 'be': [32], 'readily': [33], 'used': [34], 'to': [35, 58, 90], 'identify': [36], 'phases': [37, 39, 72, 103], 'and': [38, 66, 87, 104], 'transitions': [40, 106], 'of\\nmany': [41], 'body': [42], 'systems.': [43], 'Starting': [44], 'with': [45], 'raw': [46], 'spin': [47], 'configurations': [48], 'prototypical\\nIsing': [51], 'model,': [52], 'we': [53], 'use': [54, 67], 'principal': [55], 'component': [56], 'analysis': [57, 69], 'extract': [59], 'relevant': [60], 'low\\ndimensional': [61], 'representations': [62], 'original': [64], 'clustering': [68], 'to\\nidentify': [70], 'distinct': [71], 'feature': [75], 'space.': [76], 'This': [77], 'approach': [78], 'successfully': [79], 'finds\\nout': [80], 'physical': [81], 'concepts': [82], 'such': [83], 'as': [84], 'order': [85], 'parameter': [86], 'structure': [88], 'factor': [89], 'be\\nindicators': [91], 'phase': [94, 105], 'transition.': [95], 'discuss': [97], 'future': [98], 'prospects': [99], 'discovering\\nmore': [101], 'complex': [102], 'using': [107], 'learning\\ntechniques.\\n': [109]}",2016,"['Phase (matter)', 'Unsupervised learning', 'Computer science', 'Artificial intelligence', 'Physics', 'Quantum mechanics']","Unsupervised learning is a discipline of machine learning which aims at\ndiscovering patterns in big data sets or classifying the data into several\ncategories without being trained explicitly. We show that unsupervised learning\ntechniques can be readily used to identify phases and phases transitions of\nmany body systems. Starting with raw spin configurations of a prototypical\nIsing model, we use principal component analysis to extract relevant low\ndimensional representations the original data and use clustering analysis to\nidentify distinct phases in the feature space. This approach successfully finds\nout physical concepts such as order parameter and structure factor to be\nindicators of the phase transition. We discuss future prospects of discovering\nmore complex phases and phase transitions using unsupervised learning\ntechniques.\n"
https://openalex.org/W2173520492,Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks,"{'In': [0, 26], 'recent': [1], 'years,': [2], 'supervised': [3, 42], 'learning': [4, 19, 43], 'with': [5, 20], 'convolutional': [6, 55, 88], 'networks': [7, 58], '(CNNs)': [8], 'has': [9, 22], 'seen': [10], 'huge': [11], 'adoption': [12], 'in': [13, 101], 'computer': [14], 'vision': [15], 'applications.': [16], 'Comparatively,': [17], 'unsupervised': [18, 45, 74], 'CNNs': [21, 40, 52], 'received': [23], 'less': [24], 'attention.': [25], 'this': [27], 'work': [28], 'we': [29, 81, 108], 'hope': [30], 'to': [31, 99], 'help': [32], 'bridge': [33], 'the': [34, 37, 103, 110], 'gap': [35], 'between': [36], 'success': [38], 'of': [39, 51, 94], 'for': [41, 73, 113], 'and': [44, 65, 105], 'learning.': [46, 75], 'We': [47], 'introduce': [48], 'a': [49, 70, 92], 'class': [50], 'called': [53], 'deep': [54, 87], 'generative': [56], 'adversarial': [57, 89], '(DCGANs),': [59], 'that': [60, 67, 85], 'have': [61], 'certain': [62], 'architectural': [63], 'constraints,': [64], 'demonstrate': [66], 'they': [68], 'are': [69], 'strong': [71], 'candidate': [72], 'Training': [76], 'on': [77], 'various': [78], 'image': [79, 122], 'datasets,': [80], 'show': [82], 'convincing': [83], 'evidence': [84], 'our': [86], 'pair': [90], 'learns': [91], 'hierarchy': [93], 'representations': [95], 'from': [96], 'object': [97], 'parts': [98], 'scenes': [100], 'both': [102], 'generator': [104], 'discriminator.': [106], 'Additionally,': [107], 'use': [109], 'learned': [111], 'features': [112], 'novel': [114], 'tasks': [115], '-': [116], 'demonstrating': [117], 'their': [118], 'applicability': [119], 'as': [120], 'general': [121], 'representations.': [123]}",2015,"['Artificial intelligence', 'Computer science', 'Convolutional neural network', 'Unsupervised learning', 'Deep learning', 'Discriminator', 'Feature learning', 'Adversarial system', 'Representation (politics)', 'Generative grammar', 'Machine learning', 'Generator (circuit theory)', 'Class (philosophy)', 'Hierarchy', 'Pattern recognition (psychology)', 'Telecommunications', 'Power (physics)', 'Law', 'Political science', 'Physics', 'Quantum mechanics', 'Economics', 'Politics', 'Market economy', 'Detector']","In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations."
https://openalex.org/W2963684088,Unsupervised Representation Learning with Deep Convolutional Generative\n Adversarial Networks,"{'In': [0, 24], 'recent': [1], 'years,': [2], 'supervised': [3, 39], 'learning': [4, 40], 'with': [5, 18], 'convolutional': [6, 80], 'networks': [7, 53], '(CNNs)': [8], 'has\\nseen': [9], 'huge': [10], 'adoption': [11], 'in': [12, 92], 'computer': [13], 'vision': [14], 'applications.': [15], 'Comparatively,': [16], 'unsupervised\\nlearning': [17], 'CNNs': [19, 37, 48], 'has': [20], 'received': [21], 'less': [22], 'attention.': [23], 'this': [25], 'work': [26], 'we': [27, 74, 98], 'hope': [28], 'to': [29, 90], 'help\\nbridge': [30], 'the': [31, 34, 94, 100], 'gap': [32], 'between': [33], 'success': [35], 'of': [36, 47, 86], 'for': [38, 67, 103], 'and\\nunsupervised': [41], 'learning.': [42], 'We': [43], 'introduce': [44], 'a': [45, 64, 84], 'class': [46], 'called': [49], 'deep': [50, 79], 'convolutional\\ngenerative': [51], 'adversarial': [52, 81], '(DCGANs),': [54], 'that': [55, 61], 'have': [56], 'certain': [57], 'architectural\\nconstraints,': [58], 'and': [59, 96], 'demonstrate': [60], 'they': [62], 'are': [63], 'strong': [65], 'candidate': [66], 'unsupervised\\nlearning.': [68], 'Training': [69], 'on': [70], 'various': [71], 'image': [72, 111], 'datasets,': [73], 'show': [75], 'convincing': [76], 'evidence': [77], 'that\\nour': [78], 'pair': [82], 'learns': [83], 'hierarchy': [85], 'representations\\nfrom': [87], 'object': [88], 'parts': [89], 'scenes': [91], 'both': [93], 'generator': [95], 'discriminator.\\nAdditionally,': [97], 'use': [99], 'learned': [101], 'features': [102], 'novel': [104], 'tasks': [105], '-': [106], 'demonstrating': [107], 'their\\napplicability': [108], 'as': [109], 'general': [110], 'representations.\\n': [112]}",2015,"['Artificial intelligence', 'Computer science', 'Convolutional neural network', 'Unsupervised learning', 'Deep learning', 'Discriminator', 'Feature learning', 'Representation (politics)', 'Adversarial system', 'Generative grammar', 'Machine learning', 'Generator (circuit theory)', 'Class (philosophy)', 'Hierarchy', 'Pattern recognition (psychology)', 'Political science', 'Law', 'Economics', 'Physics', 'Telecommunications', 'Quantum mechanics', 'Detector', 'Politics', 'Market economy', 'Power (physics)']","In recent years, supervised learning with convolutional networks (CNNs) has\nseen huge adoption in computer vision applications. Comparatively, unsupervised\nlearning with CNNs has received less attention. In this work we hope to help\nbridge the gap between the success of CNNs for supervised learning and\nunsupervised learning. We introduce a class of CNNs called deep convolutional\ngenerative adversarial networks (DCGANs), that have certain architectural\nconstraints, and demonstrate that they are a strong candidate for unsupervised\nlearning. Training on various image datasets, we show convincing evidence that\nour deep convolutional adversarial pair learns a hierarchy of representations\nfrom object parts to scenes in both the generator and discriminator.\nAdditionally, we use the learned features for novel tasks - demonstrating their\napplicability as general image representations.\n"
https://openalex.org/W2903538854,Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations,"{'The': [0], 'key': [1], 'idea': [2], 'behind': [3], 'the': [4, 43, 55, 69, 72, 103, 111, 153, 168], 'unsupervised': [5, 28, 56], 'learning': [6, 29, 57, 136, 148], 'of': [7, 21, 58, 135, 155, 164, 167], 'disentangled': [8, 59], 'representations': [9, 60], 'is': [10, 14, 61], 'that': [11, 54, 101, 143], 'real-world': [12], 'data': [13, 97, 179], 'generated': [15], 'by': [16, 27, 110], 'a': [17, 36, 89, 131, 173], 'few': [18], 'explanatory': [19], 'factors': [20], 'variation': [22], 'which': [23], 'can': [24], 'be': [25, 118, 150], 'recovered': [26], 'algorithms.': [30], 'In': [31], 'this': [32], 'paper,': [33], 'we': [34, 75], 'provide': [35], 'sober': [37], 'look': [38], 'at': [39], 'recent': [40], 'progress': [41], 'in': [42, 88], 'field': [44], 'and': [45, 71, 85, 158, 171], 'challenge': [46], 'some': [47], 'common': [48], 'assumptions.': [49], 'We': [50, 99], 'first': [51], 'theoretically': [52], 'show': [53], 'fundamentally': [62], 'impossible': [63], 'without': [64, 120], 'inductive': [65, 156], 'biases': [66, 157], 'on': [67, 94, 146], 'both': [68], 'models': [70, 80, 115], 'data.': [73], 'Then,': [74], 'train': [76], 'more': [77], 'than': [78], '12000': [79], 'covering': [81, 177], 'most': [82], 'prominent': [83], 'methods': [84, 105], 'evaluation': [86], 'metrics': [87], 'reproducible': [90, 174], 'large-scale': [91], 'experimental': [92, 175], 'study': [93], 'seven': [95], 'different': [96, 104], 'sets.': [98, 180], 'observe': [100], 'while': [102], 'successfully': [106], 'enforce': [107], 'properties': [108], ""``encouraged''"": [109], 'corresponding': [112], 'losses,': [113], 'well-disentangled': [114], 'seemingly': [116], 'cannot': [117], 'identified': [119], 'supervision.': [121], 'Furthermore,': [122], 'increased': [123], 'disentanglement': [124, 147, 166], 'does': [125], 'not': [126], 'seem': [127], 'to': [128, 130], 'lead': [129], 'decreased': [132], 'sample': [133], 'complexity': [134], 'for': [137], 'downstream': [138], 'tasks.': [139], 'Our': [140], 'results': [141], 'suggest': [142], 'future': [144], 'work': [145], 'should': [149], 'explicit': [151], 'about': [152], 'role': [154], '(implicit)': [159], 'supervision,': [160], 'investigate': [161], 'concrete': [162], 'benefits': [163], 'enforcing': [165], 'learned': [169], 'representations,': [170], 'consider': [172], 'setup': [176], 'several': [178]}",2018,"['Computer science', 'Artificial intelligence', 'Unsupervised learning', 'Natural language processing', 'Machine learning']","The key idea behind the unsupervised learning of disentangled representations is that real-world data is generated by a few explanatory factors of variation which can be recovered by unsupervised learning algorithms. In this paper, we provide a sober look at recent progress in the field and challenge some common assumptions. We first theoretically show that the unsupervised learning of disentangled representations is fundamentally impossible without inductive biases on both the models and the data. Then, we train more than 12000 models covering most prominent methods and evaluation metrics in a reproducible large-scale experimental study on seven different data sets. We observe that while the different methods successfully enforce properties ``encouraged'' by the corresponding losses, well-disentangled models seemingly cannot be identified without supervision. Furthermore, increased disentanglement does not seem to lead to a decreased sample complexity of learning for downstream tasks. Our results suggest that future work on disentanglement learning should be explicit about the role of inductive biases and (implicit) supervision, investigate concrete benefits of enforcing disentanglement of the learned representations, and consider a reproducible experimental setup covering several data sets."
https://openalex.org/W2605035112,Unsupervised Learning of Sentence Embeddings Using Compositional n-Gram Features,"{'The': [0], 'recent': [1], 'tremendous': [2], 'success': [3], 'of': [4, 11, 29, 46, 62], 'unsupervised': [5, 40, 53], 'word': [6, 30], 'embeddings': [7, 25], 'in': [8], 'a': [9, 36], 'multitude': [10], 'applications': [12], 'raises': [13], 'the': [14, 51, 60, 63], 'obvious': [15], 'question': [16], 'if': [17], 'similar': [18], 'methods': [19], 'could': [20], 'be': [21], 'derived': [22], 'to': [23, 42], 'improve': [24], '(i.e.': [26], 'semantic': [27], 'representations)': [28], 'sequences': [31], 'as': [32], 'well.': [33], 'We': [34], 'present': [35], 'simple': [37], 'but': [38], 'efficient': [39], 'objective': [41], 'train': [43], 'distributed': [44], 'representations': [45], 'sentences.': [47], 'Our': [48], 'method': [49], 'outperforms': [50], 'state-of-the-art': [52], 'models': [54], 'on': [55], 'most': [56], 'benchmark': [57], 'tasks,': [58], 'highlighting': [59], 'robustness': [61], 'produced': [64], 'general-purpose': [65], 'sentence': [66], 'embeddings.': [67]}",2018,"['Computer science', 'Unsupervised learning', 'Robustness (evolution)', 'Artificial intelligence', 'Sentence', 'Natural language processing', 'n-gram', 'Benchmark (surveying)', 'Word (group theory)', 'Simple (philosophy)', 'Machine learning', 'Language model', 'Mathematics', 'Geography', 'Biochemistry', 'Geodesy', 'Gene', 'Geometry', 'Epistemology', 'Philosophy', 'Chemistry']","The recent tremendous success of unsupervised word embeddings in a multitude of applications raises the obvious question if similar methods could be derived to improve embeddings (i.e. semantic representations) of word sequences as well. We present a simple but efficient unsupervised objective to train distributed representations of sentences. Our method outperforms the state-of-the-art unsupervised models on most benchmark tasks, highlighting the robustness of the produced general-purpose sentence embeddings."
https://openalex.org/W2787740020,An Unsupervised Learning Model for Deformable Medical Image Registration,"{'We': [0, 33, 76, 123], 'present': [1], 'a': [2, 37, 45, 50, 55, 64, 81, 88], 'fast': [3], 'learning-based': [4, 159], 'algorithm': [5], 'for': [6, 21, 30], 'deformable,': [7], 'pairwise': [8], '3D': [9, 130], 'medical': [10, 148], 'image': [11, 95, 131, 149], 'registration.': [12], 'Current': [13], 'registration': [14, 35, 65, 104, 118, 125, 160], 'methods': [15], 'optimize': [16, 41], 'an': [17], 'objective': [18], 'function': [19, 71, 79], 'independently': [20], 'each': [22], 'pair': [23, 57], 'of': [24, 47, 52, 58, 136], 'images,': [25], 'which': [26], 'can': [27, 61], 'be': [28], 'time-consuming': [29], 'large': [31], 'data.': [32], 'define': [34], 'as': [36, 115], 'parametric': [38], 'function,': [39], 'and': [40, 86, 151, 161], 'its': [42, 162], 'parameters': [43], 'given': [44], 'set': [46], 'images': [48], 'from': [49, 96], 'collection': [51], 'interest.': [53], 'Given': [54], 'new': [56], 'scans,': [59], 'we': [60], 'quickly': [62], 'compute': [63], 'field': [66], 'by': [67], 'directly': [68], 'evaluating': [69], 'the': [70, 73, 103], 'using': [72, 80], 'learned': [74], 'parameters.': [75], 'model': [77], 'this': [78], 'convolutional': [82], 'neural': [83], 'network': [84], '(CNN),': [85], 'use': [87], 'spatial': [89], 'transform': [90], 'layer': [91], 'to': [92, 128, 144], 'reconstruct': [93], 'one': [94], 'another': [97], 'while': [98, 133, 154], 'imposing': [99], 'smoothness': [100], 'constraints': [101], 'on': [102], 'field.': [105], 'The': [106], 'proposed': [107], 'method': [108, 142], 'does': [109], 'not': [110], 'require': [111], 'supervised': [112], 'information': [113], 'such': [114], 'ground': [116], 'truth': [117], 'fields': [119], 'or': [120], 'anatomical': [121], 'landmarks.': [122], 'demonstrate': [124], 'accuracy': [126], 'comparable': [127], 'state-of-the-art': [129], 'registration,': [132], 'operating': [134], 'orders': [135], 'magnitude': [137], 'faster': [138], 'in': [139, 158], 'practice.': [140], 'Our': [141, 164], 'promises': [143], 'significantly': [145], 'speed': [146], 'up': [147], 'analysis': [150], 'processing': [152], 'pipelines,': [153], 'facilitating': [155], 'novel': [156], 'directions': [157], 'applications.': [163], 'code': [165], 'is': [166], 'available': [167], 'at': [168], 'https://github.com/balakg/voxelmorph': [169], '.': [170]}",2018,[],"We present a fast learning-based algorithm for deformable, pairwise 3D medical image registration. Current registration methods optimize an objective function independently for each pair of images, which can be time-consuming for large data. We define registration as a parametric function, and optimize its parameters given a set of images from a collection of interest. Given a new pair of scans, we can quickly compute a registration field by directly evaluating the function using the learned parameters. We model this function using a convolutional neural network (CNN), and use a spatial transform layer to reconstruct one image from another while imposing smoothness constraints on the registration field. The proposed method does not require supervised information such as ground truth registration fields or anatomical landmarks. We demonstrate registration accuracy comparable to state-of-the-art 3D image registration, while operating orders of magnitude faster in practice. Our method promises to significantly speed up medical image analysis and processing pipelines, while facilitating novel directions in learning-based registration and its applications. Our code is available at https://github.com/balakg/voxelmorph ."
https://openalex.org/W2950180292,Deep Clustering for Unsupervised Learning of Visual Features,"{'Clustering': [0], 'is': [1], 'a': [2, 43, 52, 69, 117], 'class': [3], 'of': [4, 30, 51, 59, 85, 95, 113], 'unsupervised': [5, 93], 'learning': [6], 'methods': [7], 'that': [8, 46], 'has': [9, 20], 'been': [10, 21], 'extensively': [11], 'applied': [12], 'and': [13, 55, 74, 104], 'studied': [14], 'in': [15], 'computer': [16], 'vision.': [17], 'Little': [18], 'work': [19], 'done': [22], 'to': [23, 26, 81, 91], 'adapt': [24], 'it': [25], 'the': [27, 49, 56, 60, 66, 76, 83, 86, 92, 110, 114, 122], 'end-to-end': [28], 'training': [29, 94], 'visual': [31], 'features': [32, 67], 'on': [33, 99, 120], 'large': [34, 100], 'scale': [35], 'datasets.': [36], 'In': [37], 'this': [38], 'work,': [39], 'we': [40], 'present': [41], 'DeepCluster,': [42], 'clustering': [44, 71], 'method': [45], 'jointly': [47], 'learns': [48], 'parameters': [50], 'neural': [53, 97], 'network': [54], 'cluster': [57], 'assignments': [58, 78], 'resulting': [61, 107], 'features.': [62], 'DeepCluster': [63, 90], 'iteratively': [64], 'groups': [65], 'with': [68], 'standard': [70, 123], 'algorithm,': [72], 'k-means,': [73], 'uses': [75], 'subsequent': [77], 'as': [79], 'supervision': [80], 'update': [82], 'weights': [84], 'network.': [87], 'We': [88], 'apply': [89], 'convolutional': [96], 'networks': [98], 'datasets': [101], 'like': [102], 'ImageNet': [103], 'YFCC100M.': [105], 'The': [106], 'model': [108], 'outperforms': [109], 'current': [111], 'state': [112], 'art': [115], 'by': [116], 'significant': [118], 'margin': [119], 'all': [121], 'benchmarks.': [124]}",2018,"['Cluster analysis', 'Computer science', 'Margin (machine learning)', 'Artificial intelligence', 'Unsupervised learning', 'Convolutional neural network', 'Pattern recognition (psychology)', 'Machine learning', 'Artificial neural network', 'Class (philosophy)', 'Deep learning']","Clustering is a class of unsupervised learning methods that has been extensively applied and studied in computer vision. Little work has been done to adapt it to the end-to-end training of visual features on large scale datasets. In this work, we present DeepCluster, a clustering method that jointly learns the parameters of a neural network and the cluster assignments of the resulting features. DeepCluster iteratively groups the features with a standard clustering algorithm, k-means, and uses the subsequent assignments as supervision to update the weights of the network. We apply DeepCluster to the unsupervised training of convolutional neural networks on large datasets like ImageNet and YFCC100M. The resulting model outperforms the current state of the art by a significant margin on all the standard benchmarks."
https://openalex.org/W2158794898,Unsupervised learning of narrative schemas and their participants,"{'We': [0], 'describe': [1], 'an': [2], 'unsupervised': [3, 68], 'system': [4, 52], 'for': [5], 'learning': [6, 69, 100], 'narrative': [7, 82], 'schemas,': [8], 'coherent': [9], 'sequences': [10], 'or': [11, 47, 60, 65], 'sets': [12], 'of': [13, 63, 76], 'events': [14, 64], '(arrested(POLICE,': [15], 'SUSPECT),': [16], 'convicted(JUDGE,': [17], 'SUSPECT))': [18], 'whose': [19], 'arguments': [20, 73], 'are': [21], 'filled': [22], 'with': [23], 'participant': [24], 'semantic': [25, 48, 105], 'roles': [26], 'defined': [27], 'over': [28], 'words': [29], '(Judge': [30], '=': [31, 36], '{judge,': [32], 'jury,': [33], 'court},': [34], 'Police': [35], '{police,': [37], 'agent,': [38], 'authorities}).': [39], 'Unlike': [40], 'most': [41], 'previous': [42, 96], 'work': [43], 'in': [44, 74, 98], 'event': [45, 83], 'structure': [46, 84], 'role': [49], 'learning,': [50], 'our': [51], 'does': [53], 'not': [54], 'use': [55], 'supervised': [56], 'techniques,': [57], 'hand-built': [58], 'knowledge,': [59], 'predefined': [61], 'classes': [62], 'roles.': [66, 87, 106], 'Our': [67], 'algorithm': [70], 'uses': [71], 'coreferring': [72], 'chains': [75], 'verbs': [77], 'to': [78], 'learn': [79], 'both': [80, 91], 'rich': [81, 103], 'and': [85, 101], 'argument': [86], 'By': [88], 'jointly': [89], 'addressing': [90], 'tasks,': [92], 'we': [93], 'improve': [94], 'on': [95], 'results': [97], 'narrative/frame': [99], 'induce': [102], 'frame-specific': [104]}",2009,"['Narrative', 'Suspect', 'Computer science', 'Argument (complex analysis)', 'Frame (networking)', 'Jury', 'Event (particle physics)', 'Artificial intelligence', 'Natural language processing', 'Unsupervised learning', 'Psychology', 'Cognitive psychology', 'Linguistics', 'Telecommunications', 'Law', 'Chemistry', 'Philosophy', 'Criminology', 'Quantum mechanics', 'Biochemistry', 'Political science', 'Physics']","We describe an unsupervised system for learning narrative schemas, coherent sequences or sets of events (arrested(POLICE, SUSPECT), convicted(JUDGE, SUSPECT)) whose arguments are filled with participant semantic roles defined over words (Judge = {judge, jury, court}, Police = {police, agent, authorities}). Unlike most previous work in event structure or semantic role learning, our system does not use supervised techniques, hand-built knowledge, or predefined classes of events or roles. Our unsupervised learning algorithm uses coreferring arguments in chains of verbs to learn both rich narrative event structure and argument roles. By jointly addressing both tasks, we improve on previous results in narrative/frame learning and induce rich frame-specific semantic roles."
https://openalex.org/W2143296986,Unsupervised learning of natural languages,"{'We': [0], 'address': [1], 'the': [2], 'problem,': [3], 'fundamental': [4], 'to': [5, 20], 'linguistics,': [6], 'bioinformatics,': [7], 'and': [8, 71, 103, 105, 126], 'certain': [9], 'other': [10, 130], 'disciplines,': [11], 'of': [12, 15, 31, 60, 94, 118], 'using': [13], 'corpora': [14], 'raw': [16, 138], 'symbolic': [17], 'sequential': [18], 'data': [19, 108], 'infer': [21], 'underlying': [22], 'rules': [23], 'that': [24, 77, 132], 'govern': [25], 'their': [26], 'production.': [27], 'Given': [28], 'a': [29, 65], 'corpus': [30], 'strings': [32], '(such': [33], 'as': [34, 99, 101, 141], 'text,': [35], 'transcribed': [36], 'speech,': [37], 'chromosome': [38], 'or': [39], 'protein': [40, 107], 'sequence': [41, 110], 'data,': [42, 139], 'sheet': [43], 'music,': [44], 'etc.),': [45], 'our': [46], 'unsupervised': [47, 114], 'algorithm': [48, 62, 115], 'recursively': [49], 'distills': [50], 'from': [51, 137], 'it': [52], 'hierarchically': [53], 'structured': [54, 73], 'patterns.': [55], 'The': [56], 'adios': [57], '(automatic': [58], 'distillation': [59], 'structure)': [61], 'relies': [63], 'on': [64, 72, 88, 96, 106], 'statistical': [66], 'method': [67], 'for': [68, 134], 'pattern': [69], 'extraction': [70], 'generalization,': [74], 'two': [75], 'processes': [76], 'have': [78], 'been': [79, 86], 'implicated': [80], 'in': [81, 129], 'language': [82], 'acquisition.': [83], 'It': [84], 'has': [85], 'evaluated': [87], 'artificial': [89], 'context-free': [90], 'grammars': [91], 'with': [92, 111], 'thousands': [93], 'rules,': [95], 'natural': [97], 'languages': [98], 'diverse': [100], 'English': [102], 'Chinese,': [104], 'correlating': [109], 'function.': [112], 'This': [113], 'is': [116], 'capable': [117], 'learning': [119], 'complex': [120], 'syntax,': [121], 'generating': [122], 'grammatical': [123], 'novel': [124], 'sentences,': [125], 'proving': [127], 'useful': [128], 'fields': [131], 'call': [133], 'structure': [135], 'discovery': [136], 'such': [140], 'bioinformatics.': [142]}",2005,"['Computer science', 'Grammar induction', 'Natural language processing', 'Artificial intelligence', 'Syntax', 'Rule-based machine translation', 'Natural language', 'Generalization', 'Stochastic context-free grammar', 'Context (archaeology)', 'Context-free grammar', 'Unsupervised learning', 'Information extraction', 'Tree-adjoining grammar', 'Biology', 'Mathematics', 'Mathematical analysis', 'Paleontology']","We address the problem, fundamental to linguistics, bioinformatics, and certain other disciplines, of using corpora of raw symbolic sequential data to infer underlying rules that govern their production. Given a corpus of strings (such as text, transcribed speech, chromosome or protein sequence data, sheet music, etc.), our unsupervised algorithm recursively distills from it hierarchically structured patterns. The adios (automatic distillation of structure) algorithm relies on a statistical method for pattern extraction and on structured generalization, two processes that have been implicated in language acquisition. It has been evaluated on artificial context-free grammars with thousands of rules, on natural languages as diverse as English and Chinese, and on protein data correlating sequence with function. This unsupervised algorithm is capable of learning complex syntax, generating grammatical novel sentences, and proving useful in other fields that call for structure discovery from raw data, such as bioinformatics."
https://openalex.org/W2335728318,Reading digits in natural images with unsupervised feature learning,"{'Detecting': [0], 'and': [1, 35, 39, 154], 'reading': [2, 47, 96], 'text': [3], 'from': [4, 99, 121], 'natural': [5], 'images': [6], 'is': [7, 14, 60, 137], 'a': [8, 17, 88, 108], 'hard': [9], 'computer': [10, 33], 'vision': [11, 34], 'task': [12], 'that': [13, 156], 'central': [15], 'to': [16], 'variety': [18], 'of': [19, 84, 130, 146], 'emerging': [20], 'applications.': [21], 'Related': [22], 'problems': [23], 'like': [24, 46, 57], 'document': [25], 'character': [26], 'recognition': [27], 'have': [28], 'been': [29], 'widely': [30], 'studied': [31], 'by': [32], 'machine': [36], 'learning': [37, 94, 152], 'researchers': [38], 'are': [40, 158], 'virtually': [41], 'solved': [42], 'for': [43, 112], 'practical': [44], 'applications': [45], 'handwritten': [48], 'digits.': [49], 'Reliably': [50], 'recognizing': [51, 85, 131], 'characters': [52], 'in': [53, 87], 'more': [54, 62], 'complex': [55], 'scenes': [56], 'photographs,': [58], 'however,': [59], 'far': [61], 'difficult:': [63], 'the': [64, 74, 82, 128, 135], 'best': [65], 'existing': [66], 'methods': [67, 153], 'lag': [68], 'well': [69], 'behind': [70], 'human': [71], 'performance': [72], 'on': [73, 161], 'same': [75], 'tasks.': [76], 'In': [77], 'this': [78, 104], 'paper': [79], 'we': [80, 106, 143], 'attack': [81], 'problem': [83, 136], 'digits': [86, 119, 133], 'real': [89], 'application': [90], 'using': [91], 'unsupervised': [92, 150], 'feature': [93, 151], 'methods:': [95], 'house': [97], 'numbers': [98], 'street': [100], 'level': [101], 'photos.': [102], 'To': [103], 'end,': [105], 'introduce': [107], 'new': [109], 'benchmark': [110], 'dataset': [111], 'research': [113], 'use': [114], 'containing': [115], 'over': [116], '600,000': [117], 'labeled': [118], 'cropped': [120], 'Street': [122], 'View': [123], 'images.': [124], 'We': [125], 'then': [126], 'demonstrate': [127], 'difficulty': [129], 'these': [132], 'when': [134], 'approached': [138], 'with': [139], 'hand-designed': [140], 'features.': [141], 'Finally,': [142], 'employ': [144], 'variants': [145], 'two': [147], 'recently': [148], 'proposed': [149], 'find': [155], 'they': [157], 'convincingly': [159], 'superior': [160], 'our': [162], 'benchmarks.': [163], '1': [164]}",2024,"['Computer science', 'Artificial intelligence', 'Feature (linguistics)', 'Benchmark (surveying)', 'Reading (process)', 'Task (project management)', 'Unsupervised learning', 'Feature learning', 'Pattern recognition (psychology)', 'Variety (cybernetics)', 'Feature extraction', 'Machine learning', 'Deep learning', 'Natural language processing', 'Speech recognition', 'Geodesy', 'Management', 'Law', 'Philosophy', 'Political science', 'Economics', 'Linguistics', 'Geography']","Detecting and reading text from natural images is a hard computer vision task that is central to a variety of emerging applications. Related problems like document character recognition have been widely studied by computer vision and machine learning researchers and are virtually solved for practical applications like reading handwritten digits. Reliably recognizing characters in more complex scenes like photographs, however, is far more difficult: the best existing methods lag well behind human performance on the same tasks. In this paper we attack the problem of recognizing digits in a real application using unsupervised feature learning methods: reading house numbers from street level photos. To this end, we introduce a new benchmark dataset for research use containing over 600,000 labeled digits cropped from Street View images. We then demonstrate the difficulty of recognizing these digits when the problem is approached with hand-designed features. Finally, we employ variants of two recently proposed unsupervised feature learning methods and find that they are convincingly superior on our benchmarks. 1"
https://openalex.org/W2119018277,Comparison of Supervised and Unsupervised Learning Algorithms for Pattern Classification,"{'This': [0], 'paper': [1], 'presents': [2], 'a': [3, 26, 58], 'comparative': [4], 'account': [5], 'of': [6, 60, 65], 'unsupervised': [7, 66], 'and': [8, 12, 34, 72], 'supervised': [9, 51], 'learning': [10, 32, 46, 52, 67], 'models': [11], 'their': [13], 'pattern': [14], 'classification': [15, 73], 'evaluations': [16], 'as': [17, 48], 'applied': [18], 'to': [19], 'the': [20, 36, 43, 75], 'higher': [21], 'education': [22], 'scenario.': [23], 'Classification': [24], 'plays': [25], 'vital': [27], 'role': [28], 'in': [29, 35, 74], 'machine': [30], 'based': [31], 'algorithms': [33], 'present': [37, 76], 'study,': [38], 'we': [39], 'found': [40], 'that,': [41], 'though': [42], 'error': [44], 'back-propagation': [45], 'algorithm': [47], 'provided': [49], 'by': [50], 'model': [53], 'is': [54], 'very': [55], 'efficient': [56, 70], 'for': [57], 'number': [59], 'non-linear': [61], 'real-time': [62], 'problems,': [63], 'KSOM': [64], 'model,': [68], 'offers': [69], 'solution': [71], 'study.': [77]}",2013,"['Computer science', 'Unsupervised learning', 'Machine learning', 'Artificial intelligence', 'Semi-supervised learning', 'Wake-sleep algorithm', 'Supervised learning', 'Linear classifier', 'Statistical classification', 'Pattern recognition (psychology)', 'Generalization error', 'Support vector machine', 'Artificial neural network']","This paper presents a comparative account of unsupervised and supervised learning models and their pattern classification evaluations as applied to the higher education scenario. Classification plays a vital role in machine based learning algorithms and in the present study, we found that, though the error back-propagation learning algorithm as provided by supervised learning model is very efficient for a number of non-linear real-time problems, KSOM of unsupervised learning model, offers efficient solution and classification in the present study."
https://openalex.org/W2007815184,Unsupervised Learning of Visual Features through Spike Timing Dependent Plasticity,"{'Spike': [0], 'timing': [1, 19], 'dependent': [2], 'plasticity': [3], '(STDP)': [4], 'is': [5, 28, 35, 82], 'a': [6, 14, 26, 134], 'learning': [7, 61], 'rule': [8, 62], 'that': [9, 48, 70, 78, 100, 129, 148], 'modifies': [10], 'synaptic': [11, 44], 'strength': [12], 'as': [13, 118], 'function': [15], 'of': [16, 20, 41], 'the': [17, 39, 72, 80, 108, 138, 144], 'relative': [18], 'pre-': [21], 'and': [22, 76, 104, 113, 147, 154], 'postsynaptic': [23, 53], 'spikes.': [24], 'When': [25], 'neuron': [27], 'repeatedly': [29], 'presented': [30, 83], 'with': [31, 84], 'similar': [32], 'inputs,': [33], 'STDP': [34, 149], 'known': [36], 'to': [37, 88, 97, 136, 152], 'have': [38], 'effect': [40], 'concentrating': [42], 'high': [43], 'weights': [45], 'on': [46, 120], 'afferents': [47], 'systematically': [49], 'fire': [50], 'early,': [51], 'while': [52], 'spike': [54], 'latencies': [55], 'decrease.': [56], 'Here': [57], 'we': [58], 'use': [59], 'this': [60], 'in': [63, 107], 'an': [64], 'asynchronous': [65], 'feedforward': [66], 'spiking': [67], 'neural': [68], 'network': [69, 81], 'mimics': [71], 'ventral': [73], 'visual': [74, 90, 145], 'pathway': [75], 'shows': [77], 'when': [79], 'natural': [85], 'images,': [86, 109], 'selectivity': [87], 'intermediate-complexity': [89], 'features': [91], 'emerges.': [92], 'Those': [93], 'features,': [94], 'which': [95], 'correspond': [96], 'prototypical': [98], 'patterns': [99], 'are': [101, 110], 'both': [102], 'salient': [103], 'consistently': [105], 'present': [106], 'highly': [111], 'informative': [112], 'enable': [114], 'robust': [115], 'object': [116], 'recognition,': [117], 'demonstrated': [119], 'various': [121], 'classification': [122], 'tasks.': [123], 'Taken': [124], 'together,': [125], 'these': [126], 'results': [127], 'show': [128], 'temporal': [130], 'codes': [131], 'may': [132], 'be': [133], 'key': [135], 'understanding': [137], 'phenomenal': [139], 'processing': [140], 'speed': [141], 'achieved': [142], 'by': [143], 'system': [146], 'can': [150], 'lead': [151], 'fast': [153], 'selective': [155], 'responses.': [156]}",2007,"['Spike-timing-dependent plasticity', 'Computer science', 'Spike (software development)', 'Artificial intelligence', 'Postsynaptic potential', 'Learning rule', 'Feed forward', 'Neuroscience', 'Pattern recognition (psychology)', 'Synaptic plasticity', 'Visual processing', 'Artificial neural network', 'Biology', 'Perception', 'Software engineering', 'Control engineering', 'Receptor', 'Engineering', 'Biochemistry']","Spike timing dependent plasticity (STDP) is a learning rule that modifies synaptic strength as a function of the relative timing of pre- and postsynaptic spikes. When a neuron is repeatedly presented with similar inputs, STDP is known to have the effect of concentrating high synaptic weights on afferents that systematically fire early, while postsynaptic spike latencies decrease. Here we use this learning rule in an asynchronous feedforward spiking neural network that mimics the ventral visual pathway and shows that when the network is presented with natural images, selectivity to intermediate-complexity visual features emerges. Those features, which correspond to prototypical patterns that are both salient and consistently present in the images, are highly informative and enable robust object recognition, as demonstrated on various classification tasks. Taken together, these results show that temporal codes may be a key to understanding the phenomenal processing speed achieved by the visual system and that STDP can lead to fast and selective responses."
https://openalex.org/W3159156584,Unsupervised Learning Methods for Molecular Simulation Data,"{'Unsupervised': [0], 'learning': [1, 43], 'is': [2], 'becoming': [3], 'an': [4], 'essential': [5], 'tool': [6], 'to': [7, 50], 'analyze': [8, 133], 'the': [9, 39, 62, 106, 112, 121], 'increasingly': [10], 'large': [11], 'amounts': [12], 'of': [13, 38, 41, 70, 77, 111], 'data': [14, 53], 'produced': [15], 'by': [16], 'atomistic': [17], 'and': [18, 28, 54, 73, 82, 84, 108, 117, 119], 'molecular': [19, 71, 134], 'simulations,': [20], 'in': [21, 61, 124], 'material': [22], 'science,': [23], 'solid': [24], 'state': [25], 'physics,': [26], 'biophysics,': [27], 'biochemistry.': [29], 'In': [30, 64, 99], 'this': [31], 'Review,': [32], 'we': [33, 66, 102], 'provide': [34], 'a': [35, 96], 'comprehensive': [36], 'overview': [37], 'methods': [40], 'unsupervised': [42], 'that': [44], 'have': [45], 'been': [46, 128], 'most': [47], 'commonly': [48], 'used': [49], 'investigate': [51], 'simulation': [52, 135], 'indicate': [55], 'likely': [56], 'directions': [57], 'for': [58], 'further': [59], 'developments': [60], 'field.': [63], 'particular,': [65], 'discuss': [67], 'feature': [68], 'representation': [69], 'systems': [72], 'present': [74], 'state-of-the-art': [75], 'algorithms': [76], 'dimensionality': [78], 'reduction,': [79], 'density': [80], 'estimation,': [81], 'clustering,': [83], 'kinetic': [85], 'models.': [86], 'We': [87], 'divide': [88], 'our': [89], 'discussion': [90], 'into': [91], 'self-contained': [92], 'sections,': [93], 'each': [94, 100], 'discussing': [95], 'specific': [97, 122], 'method.': [98], 'section,': [101], 'briefly': [103], 'touch': [104], 'upon': [105], 'mathematical': [107], 'algorithmic': [109], 'foundations': [110], 'method,': [113], 'highlight': [114], 'its': [115], 'strengths': [116], 'limitations,': [118], 'describe': [120], 'ways': [123], 'which': [125], 'it': [126], 'has': [127], 'used-or': [129], 'can': [130], 'be': [131], 'used-to': [132], 'data.': [136]}",2021,"['Cluster analysis', 'Dimensionality reduction', 'Unsupervised learning', 'Representation (politics)', 'Field (mathematics)', 'Artificial intelligence', 'Feature (linguistics)', 'Curse of dimensionality', 'Computer science', 'Chemistry', 'Machine learning', 'Pure mathematics', 'Philosophy', 'Political science', 'Linguistics', 'Politics', 'Law', 'Mathematics']","Unsupervised learning is becoming an essential tool to analyze the increasingly large amounts of data produced by atomistic and molecular simulations, in material science, solid state physics, biophysics, and biochemistry. In this Review, we provide a comprehensive overview of the methods of unsupervised learning that have been most commonly used to investigate simulation data and indicate likely directions for further developments in the field. In particular, we discuss feature representation of molecular systems and present state-of-the-art algorithms of dimensionality reduction, density estimation, and clustering, and kinetic models. We divide our discussion into self-contained sections, each discussing a specific method. In each section, we briefly touch upon the mathematical and algorithmic foundations of the method, highlight its strengths and limitations, and describe the specific ways in which it has been used-or can be used-to analyze molecular simulation data."
https://openalex.org/W2401640538,Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning,"{'While': [0], 'great': [1], 'strides': [2], 'have': [3], 'been': [4], 'made': [5], 'in': [6, 46, 92, 99, 136, 190, 198], 'using': [7], 'deep': [8], 'learning': [9, 14, 20, 53, 56, 224], 'algorithms': [10], 'to': [11, 25, 88, 112, 123, 126, 170], 'solve': [12], 'supervised': [13], 'tasks,': [15], 'the': [16, 28, 58, 61, 76, 82, 100, 128, 139, 186, 191, 195, 205], 'problem': [17], 'of': [18, 30, 43, 60, 78, 130, 181, 188, 225], 'unsupervised': [19, 52, 219], '-': [21, 33], 'leveraging': [22], 'unlabeled': [23], 'examples': [24], 'learn': [26, 87, 125, 141], 'about': [27, 57], 'structure': [29, 59], 'a': [31, 35, 47, 66, 93, 215], 'domain': [32], 'remains': [34], 'difficult': [36], 'unsolved': [37], 'challenge.': [38], 'Here,': [39], 'we': [40], 'explore': [41], 'prediction': [42, 213], 'future': [44, 90], 'frames': [45, 91], 'video': [48, 94], 'sequence': [49], 'as': [50], 'an': [51], 'rule': [54], 'for': [55, 147, 203, 218, 222], 'visual': [62, 192], 'world.': [63], 'We': [64, 116, 162], 'describe': [65], 'predictive': [67], 'neural': [68], 'network': [69, 101, 114], '(""PredNet"")': [70], 'architecture': [71], 'that': [72, 118, 135, 144, 154, 165, 212], 'is': [73, 201], 'inspired': [74], 'by': [75], 'concept': [77], '""predictive': [79], 'coding""': [80], 'from': [81, 109], 'neuroscience': [83], 'literature.': [84], 'These': [85], 'networks': [86, 120, 140, 167], 'predict': [89, 127], 'sequence,': [95], 'with': [96, 158], 'each': [97], 'layer': [98], 'making': [102], 'local': [103], 'predictions': [104, 111], 'and': [105, 134, 185, 194, 227], 'only': [106], 'forwarding': [107], 'deviations': [108], 'those': [110], 'subsequent': [113], 'layers.': [115], 'show': [117, 164], 'these': [119, 166, 209], 'are': [121, 145], 'able': [122], 'robustly': [124], 'movement': [129, 184, 187], 'synthetic': [131], '(rendered)': [132], 'objects,': [133], 'doing': [137], 'so,': [138], 'internal': [142], 'representations': [143], 'useful': [146, 202], 'decoding': [148], 'latent': [149], 'object': [150, 156, 226], 'parameters': [151], '(e.g.': [152], 'pose)': [153], 'support': [155], 'recognition': [157], 'fewer': [159], 'training': [160], 'views.': [161], 'also': [163], 'can': [168], 'scale': [169], 'complex': [171], 'natural': [172], 'image': [173], 'streams': [174], '(car-mounted': [175], 'camera': [176], 'videos),': [177], 'capturing': [178], 'key': [179], 'aspects': [180], 'both': [182], 'egocentric': [183], 'objects': [189], 'scene,': [193], 'representation': [196], 'learned': [197], 'this': [199], 'setting': [200], 'estimating': [204], 'steering': [206], 'angle.': [207], 'Altogether,': [208], 'results': [210], 'suggest': [211], 'represents': [214], 'powerful': [216], 'framework': [217], 'learning,': [220], 'allowing': [221], 'implicit': [223], 'scene': [228], 'structure.': [229]}",2016,"['Computer science', 'Artificial intelligence', 'Unsupervised learning', 'Feature learning', 'Deep learning', 'Artificial neural network', 'Coding (social sciences)', 'Machine learning', 'Supervised learning', 'Predictive coding', 'Object (grammar)', 'Mathematics', 'Statistics']","While great strides have been made in using deep learning algorithms to solve supervised learning tasks, the problem of unsupervised learning - leveraging unlabeled examples to learn about the structure of a domain - remains a difficult unsolved challenge. Here, we explore prediction of future frames in a video sequence as an unsupervised learning rule for learning about the structure of the visual world. We describe a predictive neural network (""PredNet"") architecture that is inspired by the concept of ""predictive coding"" from the neuroscience literature. These networks learn to predict future frames in a video sequence, with each layer in the network making local predictions and only forwarding deviations from those predictions to subsequent network layers. We show that these networks are able to robustly learn to predict the movement of synthetic (rendered) objects, and that in doing so, the networks learn internal representations that are useful for decoding latent object parameters (e.g. pose) that support object recognition with fewer training views. We also show that these networks can scale to complex natural image streams (car-mounted camera videos), capturing key aspects of both egocentric movement and the movement of objects in the visual scene, and the representation learned in this setting is useful for estimating the steering angle. Altogether, these results suggest that prediction represents a powerful framework for unsupervised learning, allowing for implicit learning of object and scene structure."
https://openalex.org/W2594041373,Unsupervised learning of phase transitions: From principal component analysis to variational autoencoders,"{'We': [0, 60], 'examine': [1], 'unsupervised': [2], 'machine': [3], 'learning': [4], 'techniques': [5], 'to': [6, 35, 43, 79, 98], 'learn': [7], 'features': [8], 'that': [9, 62, 110], 'best': [10], 'describe': [11], 'configurations': [12, 46], 'of': [13, 87, 104], 'the': [14, 19, 54, 57, 63, 80, 88, 111], 'two-dimensional': [15], 'Ising': [16], 'model': [17], 'and': [18, 32, 47, 71], 'three-dimensional': [20], 'XY': [21], 'model.': [22], 'The': [23, 84], 'methods': [24, 34], 'range': [25], 'from': [26], 'principal': [27, 68], 'component': [28, 69], 'analysis': [29, 70], 'over': [30], 'manifold': [31], 'clustering': [33], 'artificial': [36], 'neural-network-based': [37], 'variational': [38, 72], 'autoencoders.': [39, 73], 'They': [40], 'are': [41, 67, 92], 'applied': [42], 'Monte': [44], 'Carlo-sampled': [45], 'have,': [48], 'a': [49, 119], 'priori,': [50], 'no': [51], 'knowledge': [52, 103], 'about': [53], 'Hamiltonian': [55], 'or': [56], 'order': [58, 82], 'parameter.': [59], 'find': [61, 109], 'most': [64], 'promising': [65], 'algorithms': [66], 'Their': [74], 'predicted': [75], 'latent': [76, 85], 'parameters': [77], 'correspond': [78], 'known': [81], 'parameters.': [83], 'representations': [86], 'models': [89], 'in': [90], 'question': [91], 'clustered,': [93], 'which': [94], 'makes': [95], 'it': [96], 'possible': [97], 'identify': [99], 'phases': [100], 'without': [101], 'prior': [102], 'their': [105], 'existence.': [106], 'Furthermore,': [107], 'we': [108], 'reconstruction': [112], 'loss': [113], 'function': [114], 'can': [115], 'be': [116], 'used': [117], 'as': [118], 'universal': [120], 'identifier': [121], 'for': [122], 'phase': [123], 'transitions.': [124]}",2017,"['Principal component analysis', 'A priori and a posteriori', 'Artificial intelligence', 'Cluster analysis', 'Unsupervised learning', 'Artificial neural network', 'Computer science', 'Ising model', 'Pattern recognition (psychology)', 'Latent variable', 'Monte Carlo method', 'Hamiltonian (control theory)', 'Machine learning', 'Algorithm', 'Mathematics', 'Statistical physics', 'Mathematical optimization', 'Physics', 'Philosophy', 'Epistemology', 'Statistics']","We examine unsupervised machine learning techniques to learn features that best describe configurations of the two-dimensional Ising model and the three-dimensional XY model. The methods range from principal component analysis over manifold and clustering methods to artificial neural-network-based variational autoencoders. They are applied to Monte Carlo-sampled configurations and have, a priori, no knowledge about the Hamiltonian or the order parameter. We find that the most promising algorithms are principal component analysis and variational autoencoders. Their predicted latent parameters correspond to the known order parameters. The latent representations of the models in question are clustered, which makes it possible to identify phases without prior knowledge of their existence. Furthermore, we find that the reconstruction loss function can be used as a universal identifier for phase transitions."
https://openalex.org/W1971014294,Unsupervised learning of hierarchical representations with convolutional deep belief networks,"{'There': [0], 'has': [1], 'been': [2], 'much': [3], 'interest': [4], 'in': [5, 82], 'unsupervised': [6], 'learning': [7], 'of': [8, 79, 105], 'hierarchical': [9, 43, 126], 'generative': [10, 44], 'models': [11, 21], 'such': [12, 20, 98], 'as': [13, 99], 'deep': [14, 38], 'belief': [15, 39], 'networks': [16], '(DBNs);': [17], 'however,': [18], 'scaling': [19], 'to': [22, 48, 65], 'full-sized,': [23], 'high-dimensional': [24], 'images': [25, 104], 'remains': [26], 'a': [27, 42, 72, 83], 'difficult': [28], 'problem.': [29], 'To': [30], 'address': [31], 'this': [32], 'problem,': [33], 'we': [34], 'present': [35], 'the': [36, 77, 91], 'convolutional': [37], 'network': [40], ',': [41, 71], 'model': [45, 53, 123], 'that': [46, 75, 90, 121], 'scales': [47], 'realistic': [49], 'image': [50], 'sizes.': [51], 'This': [52], 'is': [54, 68], 'translation-invariant': [55], 'and': [56, 60, 107, 119, 128], 'supports': [57], 'efficient': [58], 'bottom-up': [59], 'top-down': [61], 'probabilistic': [62, 69], 'inference.': [63], 'Key': [64], 'our': [66, 122], 'approach': [67], 'max-pooling': [70], 'novel': [73], 'technique': [74], 'shrinks': [76], 'representations': [78], 'higher': [80], 'layers': [81], 'probabilistically': [84], 'sound': [85], 'way.': [86], 'Our': [87], 'experiments': [88], 'show': [89, 120], 'algorithm': [92], 'learns': [93], 'useful': [94], 'high-level': [95], 'visual': [96, 116], 'features,': [97], 'object': [100], 'parts,': [101], 'from': [102], 'unlabeled': [103], 'objects': [106], 'natural': [108], 'scenes.': [109], 'We': [110], 'demonstrate': [111], 'excellent': [112], 'performance': [113], 'on': [114], 'several': [115], 'recognition': [117], 'tasks': [118], 'can': [124], 'perform': [125], '(bottom-up': [127], 'top-down)': [129], 'inference': [130], 'over': [131], 'full-sized': [132], 'images.': [133]}",2011,"['Computer science', 'Artificial intelligence', 'Deep belief network', 'Pooling', 'Generative model', 'Inference', 'Deep learning', 'Probabilistic logic', 'Convolutional neural network', 'Pattern recognition (psychology)', 'Unsupervised learning', 'Machine learning', 'Generative grammar']","There has been much interest in unsupervised learning of hierarchical generative models such as deep belief networks (DBNs); however, scaling such models to full-sized, high-dimensional images remains a difficult problem. To address this problem, we present the convolutional deep belief network , a hierarchical generative model that scales to realistic image sizes. This model is translation-invariant and supports efficient bottom-up and top-down probabilistic inference. Key to our approach is probabilistic max-pooling , a novel technique that shrinks the representations of higher layers in a probabilistically sound way. Our experiments show that the algorithm learns useful high-level visual features, such as object parts, from unlabeled images of objects and natural scenes. We demonstrate excellent performance on several visual recognition tasks and show that our model can perform hierarchical (bottom-up and top-down) inference over full-sized images."
https://openalex.org/W1982304603,Unsupervised learning techniques for an intrusion detection system,"{'With': [0], 'the': [1, 5, 60, 64, 72, 87, 97, 119, 124], 'continuous': [2], 'evolution': [3], 'of': [4, 7, 29, 63, 121], 'types': [6], 'attacks': [8], 'against': [9], 'computer': [10], 'networks,': [11], 'traditional': [12, 110], 'intrusion': [13, 45], 'detection': [14, 112], 'systems,': [15], 'based': [16], 'on': [17, 51, 123], 'pattern': [18], 'matching': [19], 'and': [20, 32], 'static': [21], 'signatures,': [22], 'are': [23], 'increasingly': [24], 'limited': [25], 'by': [26, 59, 70, 118], 'their': [27], 'need': [28], 'an': [30, 91], 'up-to-date': [31], 'comprehensive': [33], 'knowledge': [34], 'base.': [35], 'Data': [36], 'mining': [37, 49], 'techniques': [38, 50], 'have': [39], 'been': [40], 'successfully': [41], 'applied': [42], 'in': [43], 'host-based': [44], 'detection.': [46], 'Applying': [47], 'data': [48, 122], 'raw': [52], 'network': [53, 73, 98], 'data,': [54], 'however,': [55], 'is': [56, 67, 90, 108, 116], 'made': [57], 'difficult': [58], 'sheer': [61], 'size': [62], 'input;': [65], 'this': [66, 76, 85], 'usually': [68], 'avoided': [69], 'discarding': [71], 'packet': [74, 125], 'contents.In': [75], 'paper,': [77], 'we': [78], 'introduce': [79], 'a': [80, 102, 109], 'two-tier': [81], 'architecture': [82], 'to': [83, 101], 'overcome': [84], 'problem:': [86], 'first': [88], 'tier': [89, 107], 'unsupervised': [92], 'clustering': [93], 'algorithm': [94], 'which': [95], 'reduces': [96], 'packets': [99], 'payload': [100, 126], 'tractable': [103], 'size.': [104], 'The': [105], 'second': [106], 'anomaly': [111], 'algorithm,': [113], 'whose': [114], 'efficiency': [115], 'improved': [117], 'availability': [120], 'content.': [127]}",2004,"['Computer science', 'Intrusion detection system', 'Payload (computing)', 'Cluster analysis', 'Network packet', 'Data mining', 'Anomaly detection', 'Matching (statistics)', 'Unsupervised learning', 'Raw data', 'Artificial intelligence', 'Machine learning', 'Computer network', 'Programming language', 'Mathematics', 'Statistics']","With the continuous evolution of the types of attacks against computer networks, traditional intrusion detection systems, based on pattern matching and static signatures, are increasingly limited by their need of an up-to-date and comprehensive knowledge base. Data mining techniques have been successfully applied in host-based intrusion detection. Applying data mining techniques on raw network data, however, is made difficult by the sheer size of the input; this is usually avoided by discarding the network packet contents.In this paper, we introduce a two-tier architecture to overcome this problem: the first tier is an unsupervised clustering algorithm which reduces the network packets payload to a tractable size. The second tier is a traditional anomaly detection algorithm, whose efficiency is improved by the availability of data on the packet payload content."
https://openalex.org/W2950662112,Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations,"{'The': [0], 'key': [1], 'idea': [2], 'behind': [3], 'the': [4, 43, 55, 69, 72, 103, 111, 153, 168], 'unsupervised': [5, 28, 56], 'learning': [6, 29, 57, 136, 148], 'of': [7, 21, 58, 135, 155, 164, 167], 'disentangled': [8, 59], 'representations': [9, 60], 'is': [10, 14, 61], 'that': [11, 54, 101, 143], 'real-world': [12], 'data': [13, 97, 179], 'generated': [15], 'by': [16, 27, 110], 'a': [17, 36, 89, 131, 173], 'few': [18], 'explanatory': [19], 'factors': [20], 'variation': [22], 'which': [23], 'can': [24], 'be': [25, 118, 150], 'recovered': [26], 'algorithms.': [30], 'In': [31], 'this': [32], 'paper,': [33], 'we': [34, 75], 'provide': [35], 'sober': [37], 'look': [38], 'at': [39], 'recent': [40], 'progress': [41], 'in': [42, 88], 'field': [44], 'and': [45, 71, 85, 158, 171], 'challenge': [46], 'some': [47], 'common': [48], 'assumptions.': [49], 'We': [50, 99], 'first': [51], 'theoretically': [52], 'show': [53], 'fundamentally': [62], 'impossible': [63], 'without': [64, 120], 'inductive': [65, 156], 'biases': [66, 157], 'on': [67, 94, 146], 'both': [68], 'models': [70, 80, 115], 'data.': [73], 'Then,': [74], 'train': [76], 'more': [77], 'than': [78], '12000': [79], 'covering': [81, 177], 'most': [82], 'prominent': [83], 'methods': [84, 105], 'evaluation': [86], 'metrics': [87], 'reproducible': [90, 174], 'large-scale': [91], 'experimental': [92, 175], 'study': [93], 'seven': [95], 'different': [96, 104], 'sets.': [98, 180], 'observe': [100], 'while': [102], 'successfully': [106], 'enforce': [107], 'properties': [108], ""``encouraged''"": [109], 'corresponding': [112], 'losses,': [113], 'well-disentangled': [114], 'seemingly': [116], 'cannot': [117], 'identified': [119], 'supervision.': [121], 'Furthermore,': [122], 'increased': [123], 'disentanglement': [124, 147, 166], 'does': [125], 'not': [126], 'seem': [127], 'to': [128, 130], 'lead': [129], 'decreased': [132], 'sample': [133], 'complexity': [134], 'for': [137], 'downstream': [138], 'tasks.': [139], 'Our': [140], 'results': [141], 'suggest': [142], 'future': [144], 'work': [145], 'should': [149], 'explicit': [151], 'about': [152], 'role': [154], '(implicit)': [159], 'supervision,': [160], 'investigate': [161], 'concrete': [162], 'benefits': [163], 'enforcing': [165], 'learned': [169], 'representations,': [170], 'consider': [172], 'setup': [176], 'several': [178]}",2018,"['Computer science', 'Unsupervised learning', 'Artificial intelligence', 'Machine learning', 'Inductive bias', 'Variation (astronomy)', 'Sample complexity', 'Field (mathematics)', 'Scale (ratio)', 'Key (lock)', 'Multi-task learning', 'Mathematics', 'Physics', 'Economics', 'Pure mathematics', 'Management', 'Computer security', 'Quantum mechanics', 'Astrophysics', 'Task (project management)']","The key idea behind the unsupervised learning of disentangled representations is that real-world data is generated by a few explanatory factors of variation which can be recovered by unsupervised learning algorithms. In this paper, we provide a sober look at recent progress in the field and challenge some common assumptions. We first theoretically show that the unsupervised learning of disentangled representations is fundamentally impossible without inductive biases on both the models and the data. Then, we train more than 12000 models covering most prominent methods and evaluation metrics in a reproducible large-scale experimental study on seven different data sets. We observe that while the different methods successfully enforce properties ``encouraged'' by the corresponding losses, well-disentangled models seemingly cannot be identified without supervision. Furthermore, increased disentanglement does not seem to lead to a decreased sample complexity of learning for downstream tasks. Our results suggest that future work on disentanglement learning should be explicit about the role of inductive biases and (implicit) supervision, investigate concrete benefits of enforcing disentanglement of the learned representations, and consider a reproducible experimental setup covering several data sets."
https://openalex.org/W2162095731,Unsupervised Learning of Semantic Orientation from a Hundred-Billion-Word Corpus,"{'The': [0, 46, 65, 110, 120], 'evaluative': [1], 'character': [2], 'of': [3, 39, 74, 83, 108, 148], 'a': [4, 21, 33, 52, 71, 134], 'word': [5], 'is': [6, 67, 87, 122, 141], 'called': [7], 'its': [8], 'semantic': [9, 13, 23, 40, 146], 'orientation.': [10], 'A': [11], 'positive': [12, 99], 'orientation': [14, 24, 41, 147], 'implies': [15, 25], 'desirability': [16], '(e.g.,': [17, 27], '""honest"",': [18], '""intrepid"")': [19], 'and': [20, 56, 100, 118, 130], 'negative': [22], 'undesirability': [26], '""disturbing"",': [28], '""superfluous"").': [29], 'This': [30], 'paper': [31], 'introduces': [32], 'simple': [34], 'algorithm': [35, 66, 104, 139], 'for': [36], 'unsupervised': [37], 'learning': [38, 138], 'from': [42], 'extremely': [43], 'large': [44], 'corpora.': [45], 'method': [47], 'involves': [48], 'issuing': [49], 'queries': [50], 'to': [51, 61, 143], 'Web': [53, 85], 'search': [54, 92], 'engine': [55], 'using': [57, 70, 133], 'pointwise': [58], 'mutual': [59], 'information': [60], 'analyse': [62], 'the': [63, 81, 84, 90, 103, 125, 145], 'results.': [64], 'empirically': [68], 'evaluated': [69], 'training': [72], 'corpus': [73], 'approximately': [75], 'one': [76], 'hundred': [77], 'billion': [78], 'words': [79, 97, 113], '--': [80], 'subset': [82], 'that': [86, 140], 'indexed': [88], 'by': [89, 128], 'chosen': [91], 'engine.': [93], 'Tested': [94], 'with': [95, 124], '3,596': [96, 111], '(1,614': [98], '1,982': [101], 'negative),': [102], 'attains': [105], 'an': [106], 'accuracy': [107, 121], '80%.': [109], 'test': [112], 'include': [114], 'adjectives,': [115], 'adverbs,': [116], 'nouns,': [117], 'verbs.': [119], 'comparable': [123], 'results': [126], 'achieved': [127], 'Hatzivassiloglou': [129], 'McKeown': [131], '(1997),': [132], 'complex': [135], 'four-stage': [136], 'supervised': [137], 'restricted': [142], 'determining': [144], 'adjectives.': [149]}",2002,"['Pointwise mutual information', 'Pointwise', 'Natural language processing', 'Artificial intelligence', 'Computer science', 'Orientation (vector space)', 'Word (group theory)', 'Noun', 'Character (mathematics)', 'Simple (philosophy)', 'Information retrieval', 'Mutual information', 'Linguistics', 'Mathematics', 'Epistemology', 'Geometry', 'Mathematical analysis', 'Philosophy']","The evaluative character of a word is called its semantic orientation. A positive semantic orientation implies desirability (e.g., ""honest"", ""intrepid"") and a negative semantic orientation implies undesirability (e.g., ""disturbing"", ""superfluous""). This paper introduces a simple algorithm for unsupervised learning of semantic orientation from extremely large corpora. The method involves issuing queries to a Web search engine and using pointwise mutual information to analyse the results. The algorithm is empirically evaluated using a training corpus of approximately one hundred billion words -- the subset of the Web that is indexed by the chosen search engine. Tested with 3,596 words (1,614 positive and 1,982 negative), the algorithm attains an accuracy of 80%. The 3,596 test words include adjectives, adverbs, nouns, and verbs. The accuracy is comparable with the results achieved by Hatzivassiloglou and McKeown (1997), using a complex four-stage supervised learning algorithm that is restricted to determining the semantic orientation of adjectives."
https://openalex.org/W2152565110,Recursive unsupervised learning of finite mixture models,"{'There': [0], 'are': [1, 9], 'two': [2], 'open': [3], 'problems': [4], 'when': [5], 'finite': [6], 'mixture': [7, 40], 'densities': [8], 'used': [10, 64], 'to': [11, 80, 90], 'model': [12], 'multivariate': [13], 'data:': [14], 'the': [15, 18, 23, 36, 39, 45, 83, 92], 'selection': [16], 'of': [17, 20, 38, 47, 57], 'number': [19, 46, 56], 'components': [21], 'and': [22, 41, 89], 'initialization.': [24], 'In': [25], 'this': [26], 'paper,': [27], 'we': [28], 'propose': [29], 'an': [30], 'online': [31], '(recursive)': [32], 'algorithm': [33, 51, 77], 'that': [34, 42], 'estimates': [35], 'parameters': [37], 'simultaneously': [43], 'selects': [44], 'components.': [48, 60, 94], 'The': [49], 'new': [50], 'starts': [52], 'with': [53], 'a': [54, 66, 85], 'large': [55], 'randomly': [58], 'initialized': [59], 'A': [61, 72], 'prior': [62], 'is': [63, 78], 'as': [65], 'bias': [67], 'for': [68, 82], 'maximally': [69], 'structured': [70], 'models.': [71], 'stochastic': [73], 'approximation': [74], 'recursive': [75], 'learning': [76], 'proposed': [79], 'search': [81], 'maximum': [84], 'posteriori': [86], '(MAP)': [87], 'solution': [88], 'discard': [91], 'irrelevant': [93]}",2004,"['Initialization', 'A priori and a posteriori', 'Computer science', 'Maximum a posteriori estimation', 'Stochastic approximation', 'Artificial intelligence', 'Mixture model', 'Multivariate statistics', 'Unsupervised learning', 'Algorithm', 'Selection (genetic algorithm)', 'Expectation–maximization algorithm', 'Component (thermodynamics)', 'Pattern recognition (psychology)', 'Mathematics', 'Machine learning', 'Maximum likelihood', 'Statistics', 'Thermodynamics', 'Physics', 'Epistemology', 'Programming language', 'Philosophy', 'Computer security', 'Key (lock)']","There are two open problems when finite mixture densities are used to model multivariate data: the selection of the number of components and the initialization. In this paper, we propose an online (recursive) algorithm that estimates the parameters of the mixture and that simultaneously selects the number of components. The new algorithm starts with a large number of randomly initialized components. A prior is used as a bias for maximally structured models. A stochastic approximation recursive learning algorithm is proposed to search for the maximum a posteriori (MAP) solution and to discard the irrelevant components."
https://openalex.org/W2400532028,Unsupervised Learning for Physical Interaction through Video Prediction,"{'A': [0], 'core': [1], 'challenge': [2], 'for': [3, 26, 111], 'an': [4, 66], 'agent': [5], 'learning': [6, 27, 42, 149], 'to': [7, 13, 38, 43, 96, 101, 103, 148, 180], 'interact': [8], 'with': [9, 131], 'the': [10, 28, 143], 'world': [11], 'is': [12, 93], 'predict': [14], 'how': [15], 'its': [16, 21], 'actions': [17, 146], 'affect': [18], 'objects': [19], 'in': [20], 'environment.': [22], 'Many': [23], 'existing': [24], 'methods': [25], 'dynamics': [29], 'of': [30, 46, 120, 139, 153, 160], 'physical': [31, 59], 'interactions': [32, 123], 'require': [33], 'labeled': [34, 51], 'object': [35, 60, 97], 'information.': [36], 'However,': [37], 'scale': [39], 'real-world': [40, 112], 'interaction': [41], 'a': [44, 78, 118, 128, 150], 'variety': [45], 'scenes': [47], 'and': [48, 176], 'objects,': [49], 'acquiring': [50], 'data': [52], 'becomes': [53], 'increasingly': [54], 'impractical.': [55], 'To': [56, 107], 'learn': [57], 'about': [58], 'motion': [61, 82], 'without': [62], 'labels,': [63], 'we': [64, 115], 'develop': [65], 'action-conditioned': [67], 'video': [68, 109, 172], 'prediction': [69, 110, 138], 'model': [70, 88], 'that': [71, 165], 'explicitly': [72, 89], 'models': [73], 'pixel': [74, 81], 'motion,': [75, 91], 'by': [76], 'predicting': [77], 'distribution': [79], 'over': [80], 'from': [83], 'previous': [84], 'frames.': [85], 'Because': [86], 'our': [87, 166], 'predicts': [90], 'it': [92, 100], 'partially': [94], 'invariant': [95], 'appearance,': [98], 'enabling': [99], 'generalize': [102], 'previously': [104], 'unseen': [105], 'objects.': [106, 133], 'explore': [108], 'interactive': [113], 'agents,': [114], 'also': [116], 'introduce': [117], 'dataset': [119], '59,000': [121], 'robot': [122], 'involving': [124], 'pushing': [125], 'motions,': [126], 'including': [127], 'test': [129], 'set': [130], 'novel': [132], 'In': [134], 'this': [135], 'dataset,': [136], 'accurate': [137, 171], 'videos': [140], 'conditioned': [141], 'on': [142, 157], ""robot's"": [144], 'future': [145], 'amounts': [147], '""visual': [151], 'imagination""': [152], 'different': [154, 158], 'futures': [155], 'based': [156], 'courses': [159], 'action.': [161], 'Our': [162], 'experiments': [163], 'show': [164], 'proposed': [167], 'method': [168], 'produces': [169], 'more': [170], 'predictions': [173], 'both': [174], 'quantitatively': [175], 'qualitatively,': [177], 'when': [178], 'compared': [179], 'prior': [181], 'methods.': [182]}",2016,"['Artificial intelligence', 'Computer science', 'Object (grammar)', 'Motion (physics)', 'Action (physics)', 'Robot', 'Computer vision', 'Machine learning', 'Invariant (physics)', 'Set (abstract data type)', 'Mathematics', 'Quantum mechanics', 'Physics', 'Mathematical physics', 'Programming language']","A core challenge for an agent learning to interact with the world is to predict how its actions affect objects in its environment. Many existing methods for learning the dynamics of physical interactions require labeled object information. However, to scale real-world interaction learning to a variety of scenes and objects, acquiring labeled data becomes increasingly impractical. To learn about physical object motion without labels, we develop an action-conditioned video prediction model that explicitly models pixel motion, by predicting a distribution over pixel motion from previous frames. Because our model explicitly predicts motion, it is partially invariant to object appearance, enabling it to generalize to previously unseen objects. To explore video prediction for real-world interactive agents, we also introduce a dataset of 59,000 robot interactions involving pushing motions, including a test set with novel objects. In this dataset, accurate prediction of videos conditioned on the robot's future actions amounts to learning a ""visual imagination"" of different futures based on different courses of action. Our experiments show that our proposed method produces more accurate video predictions both quantitatively and qualitatively, when compared to prior methods."
https://openalex.org/W2031056773,Quantum speed-up for unsupervised learning,"{'International': [0], 'audience': [1]}",2012,"['Computer science', 'Cluster analysis', 'Unsupervised learning', 'Initialization', 'Graph', 'Speedup', 'Quantum', 'Quantum machine learning', 'Theoretical computer science', 'Quantization (signal processing)', 'Algorithm', 'Artificial intelligence', 'Quantum algorithm', 'Quantum mechanics', 'Programming language', 'Physics', 'Operating system']",International audience
https://openalex.org/W2619034550,Unsupervised Learning of Disentangled Representations from Video,"{'We': [0, 69], 'present': [1], 'a': [2, 22, 28, 35, 39, 50, 57, 74], 'new': [3], 'model': [4], 'DrNET': [5], 'that': [6, 30], 'learns': [7], 'disentangled': [8, 44], 'image': [9], 'representations': [10], 'from': [11], 'video.': [12], 'Our': [13], 'approach': [14, 72], 'leverages': [15], 'the': [16, 61, 82, 91], 'temporal': [17], 'coherence': [18], 'of': [19, 52, 66, 76, 88], 'video': [20], 'and': [21, 38, 78], 'novel': [23], 'adversarial': [24], 'loss': [25], 'to': [26, 60, 84], 'learn': [27], 'representation': [29, 45], 'factorizes': [31], 'each': [32], 'frame': [33], 'into': [34, 90], 'stationary': [36], 'part': [37], 'temporally': [40], 'varying': [41], 'component.': [42], 'The': [43], 'can': [46], 'be': [47], 'used': [48], 'for': [49], 'range': [51, 75], 'tasks.': [53], 'For': [54], 'example,': [55], 'applying': [56], 'standard': [58], 'LSTM': [59], 'time-vary': [62], 'components': [63], 'enables': [64], 'prediction': [65], 'future': [67], 'frames.': [68], 'evaluate': [70], 'our': [71], 'on': [73], 'synthetic': [77], 'real': [79], 'videos,': [80], 'demonstrating': [81], 'ability': [83], 'coherently': [85], 'generate': [86], 'hundreds': [87], 'steps': [89], 'future.': [92]}",2017,"['Representation (politics)', 'Computer science', 'Coherence (philosophical gambling strategy)', 'Artificial intelligence', 'Range (aeronautics)', 'Frame (networking)', 'Component (thermodynamics)', 'Feature learning', 'Adversarial system', 'Pattern recognition (psychology)', 'Mathematics', 'Politics', 'Telecommunications', 'Physics', 'Thermodynamics', 'Composite material', 'Statistics', 'Law', 'Materials science', 'Political science']","We present a new model DrNET that learns disentangled image representations from video. Our approach leverages the temporal coherence of video and a novel adversarial loss to learn a representation that factorizes each frame into a stationary part and a temporally varying component. The disentangled representation can be used for a range of tasks. For example, applying a standard LSTM to the time-vary components enables prediction of future frames. We evaluate our approach on a range of synthetic and real videos, demonstrating the ability to coherently generate hundreds of steps into the future."
https://openalex.org/W2153767712,Unsupervised learning of vowel categories from infant-directed speech,"{'Infants': [0], 'rapidly': [1], 'learn': [2], 'the': [3, 32, 42, 61, 87, 100, 117, 121, 143, 164, 174], 'sound': [4], 'categories': [5, 62, 90, 124, 179], 'of': [6, 34, 66, 89, 142], 'their': [7], 'native': [8], 'language,': [9], 'even': [10], 'though': [11], 'they': [12], 'do': [13], 'not': [14], 'receive': [15], 'explicit': [16], 'or': [17, 93, 113], 'focused': [18], 'training.': [19], 'Recent': [20], 'research': [21], 'suggests': [22], 'that': [23, 38, 176, 186], 'this': [24], 'learning': [25, 60, 184, 188], 'is': [26, 56], 'due': [27], 'to': [28, 31, 46, 91, 99, 106, 147, 162], ""infants'"": [29], 'sensitivity': [30], 'distribution': [33], 'speech': [35, 40, 178], 'sounds': [36], 'and': [37, 155, 185], 'infant-directed': [39, 115], 'contains': [41], 'distributional': [43, 183], 'information': [44, 76], 'needed': [45], 'form': [47], 'native-language': [48, 177], 'vowel': [49, 67, 79, 107, 123, 165], 'categories.': [50], 'An': [51], 'algorithm,': [52, 144], 'based': [53, 151], 'on': [54, 152], 'Expectation–Maximization,': [55], 'presented': [57], 'here': [58], 'for': [59, 131, 137], 'from': [63, 110], 'a': [64, 193], 'sequence': [65], 'tokens': [68, 108], 'without': [69], '(': [70, 81, 94], 'i': [71, 126], ')': [72, 83, 96], 'receiving': [73], 'any': [74], 'category': [75], 'with': [77], 'each': [78], 'token,': [80], 'ii': [82], 'knowing': [84], 'in': [85, 192], 'advance': [86], 'number': [88], 'learn,': [92], 'iii': [95], 'having': [97], 'access': [98], 'entire': [101], 'data': [102], 'ensemble.': [103], 'When': [104], 'exposed': [105], 'drawn': [109], 'either': [111], 'English': [112], 'Japanese': [114], 'speech,': [116], 'algorithm': [118], 'successfully': [119], 'discovered': [120], 'language-specific': [122], '(/': [125], ',': [127], 'i,': [128], 'ε,': [129], 'e/': [130], 'English,': [132], '/i,': [133], 'iː,': [134], 'e,': [135], 'eː/': [136], 'Japanese).': [138], 'A': [139], 'nonparametric': [140], 'version': [141], 'closely': [145], 'related': [146], 'neural': [148], 'network': [149], 'models': [150], 'topographic': [153], 'representation': [154], 'competitive': [156], 'Hebbian': [157], 'learning,': [158], 'also': [159], 'was': [160], 'able': [161], 'discover': [163], 'categories,': [166], 'albeit': [167], 'somewhat': [168], 'less': [169], 'reliably.': [170], 'These': [171], 'results': [172], 'reinforce': [173], 'proposal': [175], 'are': [180], 'acquired': [181], 'through': [182], 'such': [187], 'may': [189], 'be': [190], 'instantiated': [191], 'biologically': [194], 'plausible': [195], 'manner.': [196]}",2007,"['Vowel', 'Computer science', 'Language acquisition', 'Artificial intelligence', 'Speech recognition', 'Natural language processing', 'Vowel length', 'Psychology', 'Mathematics education']","Infants rapidly learn the sound categories of their native language, even though they do not receive explicit or focused training. Recent research suggests that this learning is due to infants' sensitivity to the distribution of speech sounds and that infant-directed speech contains the distributional information needed to form native-language vowel categories. An algorithm, based on Expectation–Maximization, is presented here for learning the categories from a sequence of vowel tokens without ( i ) receiving any category information with each vowel token, ( ii ) knowing in advance the number of categories to learn, or ( iii ) having access to the entire data ensemble. When exposed to vowel tokens drawn from either English or Japanese infant-directed speech, the algorithm successfully discovered the language-specific vowel categories (/ i , i, ε, e/ for English, /i, iː, e, eː/ for Japanese). A nonparametric version of the algorithm, closely related to neural network models based on topographic representation and competitive Hebbian learning, also was able to discover the vowel categories, albeit somewhat less reliably. These results reinforce the proposal that native-language speech categories are acquired through distributional learning and that such learning may be instantiated in a biologically plausible manner."
https://openalex.org/W2943495267,Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences,"{'Abstract': [0], 'In': [1, 31], 'the': [2, 32, 35, 51, 124, 146], 'field': [3], 'of': [4, 9, 38, 53, 126, 129, 135, 164, 170], 'artificial': [5, 63], 'intelligence,': [6], 'a': [7, 56, 76, 118, 162], 'combination': [8], 'scale': [10, 52], 'in': [11, 25, 102, 145], 'data': [12, 42, 111], 'and': [13, 28, 61, 140, 148, 173, 176], 'model': [14, 80, 96], 'capacity': [15], 'enabled': [16], 'by': [17, 152], 'un-supervised': [18], 'learning': [19, 27, 73, 156], 'has': [20, 117], 'led': [21], 'to': [22, 74, 132], 'major': [23], 'advances': [24], 'representation': [26, 115], 'statistical': [29], 'generation.': [30], 'life': [33], 'sciences,': [34], 'anticipated': [36], 'growth': [37], 'sequencing': [39], 'promises': [40], 'unprecedented': [41], 'on': [43, 81], 'natural': [44], 'sequence': [45, 110], 'diversity.': [46, 93], 'Protein': [47], 'language': [48, 79], 'modeling': [49], 'at': [50], 'evolution': [54], 'is': [55, 143], 'logical': [57], 'step': [58], 'toward': [59], 'predictive': [60], 'generative': [62], 'intelligence': [64], 'for': [65, 180], 'biology.': [66], 'To': [67], 'this': [68], 'end': [69], 'we': [70], 'use': [71], 'unsupervised': [72], 'train': [75], 'deep': [77], 'contextual': [78], '86': [82], 'billion': [83], 'amino': [84, 130], 'acids': [85, 131], 'across': [86, 161], '250': [87], 'million': [88], 'protein': [89], 'sequences': [90], 'spanning': [91], 'evolutionary': [92], 'The': [94, 105, 113], 'resulting': [95], 'contains': [97], 'information': [98], 'about': [99, 138], 'biological': [100], 'properties': [101, 128], 'its': [103], 'representations.': [104], 'representations': [106, 147], 'are': [107], 'learned': [108, 114], 'from': [109, 123], 'alone.': [112], 'space': [116], 'multi-scale': [119], 'organization': [120], 'reflecting': [121], 'structure': [122, 142], 'level': [125], 'biochemical': [127], 'remote': [133], 'homology': [134], 'proteins.': [136], 'Information': [137], 'secondary': [139, 174], 'tertiary': [141], 'encoded': [144], 'can': [149], 'be': [150], 'identified': [151], 'linear': [153], 'projections.': [154], 'Representation': [155], 'produces': [157], 'features': [158, 179], 'that': [159], 'generalize': [160], 'range': [163], 'applications,': [165], 'enabling': [166], 'state-of-the-art': [167, 178], 'supervised': [168], 'prediction': [169], 'mutational': [171], 'effect': [172], 'structure,': [175], 'improving': [177], 'long-range': [181], 'contact': [182], 'prediction.': [183]}",2019,"['Artificial intelligence', 'Representation (politics)', 'Computer science', 'Unsupervised learning', 'Machine learning', 'Generative model', 'Protein tertiary structure', 'Protein structure prediction', 'Sequence space', 'Sequence (biology)', 'Generative grammar', 'Protein structure', 'Biology', 'Mathematics', 'Law', 'Biochemistry', 'Political science', 'Genetics', 'Pure mathematics', 'Politics', 'Banach space']","Abstract In the field of artificial intelligence, a combination of scale in data and model capacity enabled by un-supervised learning has led to major advances in representation learning and statistical generation. In the life sciences, the anticipated growth of sequencing promises unprecedented data on natural sequence diversity. Protein language modeling at the scale of evolution is a logical step toward predictive and generative artificial intelligence for biology. To this end we use unsupervised learning to train a deep contextual language model on 86 billion amino acids across 250 million protein sequences spanning evolutionary diversity. The resulting model contains information about biological properties in its representations. The representations are learned from sequence data alone. The learned representation space has a multi-scale organization reflecting structure from the level of biochemical properties of amino acids to remote homology of proteins. Information about secondary and tertiary structure is encoded in the representations and can be identified by linear projections. Representation learning produces features that generalize across a range of applications, enabling state-of-the-art supervised prediction of mutational effect and secondary structure, and improving state-of-the-art features for long-range contact prediction."
https://openalex.org/W2556930864,Unsupervised learning of spoken language with visual context,"{'Humans': [0], 'learn': [1], 'to': [2, 92], 'speak': [3], 'before': [4], 'they': [5], 'can': [6], 'read': [7], 'or': [8], 'write,': [9], 'so': [10], 'why': [11], ""can't"": [12], 'computers': [13], 'do': [14], 'the': [15, 43, 52, 65, 97], 'same?': [16], 'In': [17], 'this': [18], 'paper,': [19], 'we': [20], 'present': [21], 'a': [22], 'deep': [23], 'neural': [24], 'network': [25], 'model': [26, 72, 89], 'capable': [27], 'of': [28, 45, 54, 58], 'rudimentary': [29], 'spoken': [30, 61], 'language': [31], 'acquisition': [32], 'using': [33], 'untranscribed': [34], 'audio': [35, 62], 'training': [36], 'data,': [37], 'whose': [38], 'only': [39], 'supervision': [40], 'comes': [41], 'in': [42], 'form': [44], 'contextually': [46], 'relevant': [47], 'visual': [48], 'images.': [49], 'We': [50, 80], 'describe': [51], 'collection': [53], 'our': [55, 71, 88], 'data': [56], 'comprised': [57], 'over': [59], '120,000': [60], 'captions': [63], 'for': [64], 'Places': [66], 'image': [67, 75], 'dataset': [68], 'and': [69, 77], 'evaluate': [70], 'on': [73], 'an': [74], 'search': [76], 'annotation': [78], 'task.': [79], 'also': [81], 'provide': [82], 'some': [83], 'visualizations': [84], 'which': [85], 'suggest': [86], 'that': [87], 'is': [90], 'learning': [91], 'recognize': [93], 'meaningful': [94], 'words': [95], 'within': [96], 'caption': [98], 'spectrograms.': [99]}",2016,"['Computer science', 'Annotation', 'Artificial intelligence', 'Spectrogram', 'Natural language processing', 'Context (archaeology)', 'Spoken language', 'Speech recognition', 'Task (project management)', 'Artificial neural network', 'Deep learning', 'Biology', 'Paleontology', 'Economics', 'Management']","Humans learn to speak before they can read or write, so why can't computers do the same? In this paper, we present a deep neural network model capable of rudimentary spoken language acquisition using untranscribed audio training data, whose only supervision comes in the form of contextually relevant visual images. We describe the collection of our data comprised of over 120,000 spoken audio captions for the Places image dataset and evaluate our model on an image search and annotation task. We also provide some visualizations which suggest that our model is learning to recognize meaningful words within the caption spectrograms."
https://openalex.org/W2953259386,Unsupervised Learning of Visual Representations using Videos,"{'Is': [0], 'strong': [1], 'supervision': [2], 'necessary': [3], 'for': [4, 36], 'learning': [5, 38], 'a': [6, 20, 30, 73, 97, 101, 112, 155], 'good': [7], 'visual': [8, 55, 62, 78], 'representation?': [9], 'Do': [10], 'we': [11, 28, 42, 127], 'really': [12], 'need': [13], 'millions': [14], 'of': [15, 39, 45, 47, 131, 157], 'semantically-labeled': [16], 'images': [17], 'to': [18, 53, 88, 105, 147], 'train': [19, 106, 128], 'Convolutional': [21], 'Neural': [22], 'Network': [23], '(CNN)?': [24], 'In': [25], 'this': [26, 107], 'paper,': [27], 'present': [29], 'simple': [31], 'yet': [32], 'surprisingly': [33], 'powerful': [34], 'approach': [35], 'unsupervised': [37, 132, 164], 'CNN.': [40], 'Specifically,': [41], 'use': [43], 'hundreds': [44], 'thousands': [46], 'unlabeled': [48, 120], 'videos': [49, 121], 'from': [50, 115], 'the': [51, 65, 89, 123], 'web': [52], 'learn': [54], 'representations.': [56], 'Our': [57], 'key': [58], 'idea': [59], 'is': [60], 'that': [61, 134, 162], 'tracking': [63], 'provides': [64], 'supervision.': [66], 'That': [67], 'is,': [68], 'two': [69], 'patches': [70], 'connected': [71], 'by': [72], 'track': [74], 'should': [75], 'have': [76], 'similar': [77], 'representation': [79], 'in': [80, 169], 'deep': [81], 'feature': [82], 'space': [83], 'since': [84], 'they': [85], 'probably': [86], 'belong': [87], 'same': [90], 'object': [91, 93], 'or': [92], 'part.': [94], 'We': [95, 159], 'design': [96], 'Siamese-triplet': [98], 'network': [99, 165], 'with': [100], 'ranking': [102], 'loss': [103], 'function': [104], 'CNN': [108], 'representation.': [109], 'Without': [110], 'using': [111, 118], 'single': [113], 'image': [114], 'ImageNet,': [116], 'just': [117], '100K': [119], 'and': [122], 'VOC': [124], '2012': [125], 'dataset,': [126], 'an': [129, 151], 'ensemble': [130, 152], 'networks': [133], 'achieves': [135, 154], '52%': [136], 'mAP': [137, 156], '(no': [138], 'bounding': [139], 'box': [140], 'regression).': [141], 'This': [142], 'performance': [143], 'comes': [144], 'tantalizingly': [145], 'close': [146], 'its': [148], 'ImageNet-supervised': [149], 'counterpart,': [150], 'which': [153], '54.4%.': [158], 'also': [160], 'show': [161], 'our': [163], 'can': [166], 'perform': [167], 'competitively': [168], 'other': [170], 'tasks': [171], 'such': [172], 'as': [173], 'surface-normal': [174], 'estimation.': [175]}",2015,"['Computer science', 'Artificial intelligence', 'Representation (politics)', 'Convolutional neural network', 'Unsupervised learning', 'Bounding overwatch', 'Feature learning', 'Pattern recognition (psychology)', 'Object (grammar)', 'Ranking (information retrieval)', 'Deep learning', 'Minimum bounding box', 'Machine learning', 'Visualization', 'Feature (linguistics)', 'Image (mathematics)', 'Linguistics', 'Law', 'Philosophy', 'Political science', 'Politics']","Is strong supervision necessary for learning a good visual representation? Do we really need millions of semantically-labeled images to train a Convolutional Neural Network (CNN)? In this paper, we present a simple yet surprisingly powerful approach for unsupervised learning of CNN. Specifically, we use hundreds of thousands of unlabeled videos from the web to learn visual representations. Our key idea is that visual tracking provides the supervision. That is, two patches connected by a track should have similar visual representation in deep feature space since they probably belong to the same object or object part. We design a Siamese-triplet network with a ranking loss function to train this CNN representation. Without using a single image from ImageNet, just using 100K unlabeled videos and the VOC 2012 dataset, we train an ensemble of unsupervised networks that achieves 52% mAP (no bounding box regression). This performance comes tantalizingly close to its ImageNet-supervised counterpart, an ensemble which achieves a mAP of 54.4%. We also show that our unsupervised network can perform competitively in other tasks such as surface-normal estimation."
https://openalex.org/W2951261569,Unsupervised Learning of Depth and Ego-Motion from Video,"{'We': [0, 20], 'present': [1], 'an': [2], 'unsupervised': [3], 'learning': [4], 'framework': [5], 'for': [6, 89], 'the': [7, 33, 39, 48, 65, 69], 'task': [8, 34], 'of': [9, 35, 71], 'monocular': [10, 75], 'depth': [11, 26, 76, 88], 'and': [12, 27, 91], 'camera': [13, 28], 'motion': [14], 'estimation': [15, 30, 94], 'from': [16], 'unstructured': [17], 'video': [18], 'sequences.': [19], 'achieve': [21], 'this': [22], 'by': [23], 'simultaneously': [24], 'training': [25], 'pose': [29, 86, 93], 'networks': [31, 43], 'using': [32], 'view': [36, 49], 'synthesis': [37, 50], 'as': [38], 'supervisory': [40], 'signal.': [41], 'The': [42], 'are': [44], 'thus': [45], 'coupled': [46], 'via': [47], 'objective': [51], 'during': [52], 'training,': [53, 90], 'but': [54], 'can': [55], 'be': [56], 'applied': [57], 'independently': [58], 'at': [59], 'test': [60], 'time.': [61], 'Empirical': [62], 'evaluation': [63], 'on': [64], 'KITTI': [66], 'dataset': [67], 'demonstrates': [68], 'effectiveness': [70], 'our': [72], 'approach:': [73], '1)': [74], 'performing': [77, 95], 'comparably': [78], 'with': [79, 97], 'supervised': [80], 'methods': [81], 'that': [82], 'use': [83], 'either': [84], 'ground-truth': [85], 'or': [87], '2)': [92], 'favorably': [96], 'established': [98], 'SLAM': [99], 'systems': [100], 'under': [101], 'comparable': [102], 'input': [103], 'settings.': [104]}",2017,"['Artificial intelligence', 'Computer science', 'Monocular', 'Task (project management)', 'Computer vision', 'Motion (physics)', 'Ground truth', 'Unsupervised learning', 'Training (meteorology)', 'SIGNAL (programming language)', 'Motion estimation', 'Geography', 'Engineering', 'Systems engineering', 'Programming language', 'Meteorology']","We present an unsupervised learning framework for the task of monocular depth and camera motion estimation from unstructured video sequences. We achieve this by simultaneously training depth and camera pose estimation networks using the task of view synthesis as the supervisory signal. The networks are thus coupled via the view synthesis objective during training, but can be applied independently at test time. Empirical evaluation on the KITTI dataset demonstrates the effectiveness of our approach: 1) monocular depth performing comparably with supervised methods that use either ground-truth pose or depth for training, and 2) pose estimation performing favorably with established SLAM systems under comparable input settings."
https://openalex.org/W3146384714,Extraction of organic chemistry grammar from unsupervised learning of chemical reactions,"{'RXNmapper': [0], 'constructs': [1], 'coherent': [2], 'atom-mapping': [3], 'rules': [4], 'from': [5], 'raw': [6], 'chemical': [7], 'reactions': [8], 'using': [9], 'unsupervised': [10], 'training': [11], 'of': [12], 'neural': [13], 'networks.': [14]}",2021,"['Extraction (chemistry)', 'Computer science', 'Grammar', 'Chemistry', 'Artificial intelligence', 'Organic chemistry', 'Linguistics', 'Philosophy']",RXNmapper constructs coherent atom-mapping rules from raw chemical reactions using unsupervised training of neural networks.
https://openalex.org/W2810701348,Unsupervised learning by competing hidden units,"{'It': [0], 'is': [1, 11, 52, 74, 114, 151], 'widely': [2], 'believed': [3], 'that': [4, 26, 40, 79, 105, 144], 'end-to-end': [5, 161], 'training': [6], 'with': [7, 162], 'the': [8, 32, 36, 44, 47, 56, 82, 92, 95, 110, 145, 148, 154], 'backpropagation': [9, 51, 164], 'algorithm': [10, 104, 165], 'essential': [12], 'for': [13, 31], 'learning': [14, 63, 103, 117], 'good': [15], 'feature': [16, 119, 129], 'detectors': [17, 28, 120, 130], 'in': [18, 109, 121, 138], 'early': [19, 118], 'layers': [20, 38], 'of': [21, 39, 50, 69, 81, 94, 116, 147, 156], 'artificial': [22], 'neural': [23, 41], 'networks,': [24], 'so': [25, 143], 'these': [27], 'are': [29], 'useful': [30], 'task': [33], 'performed': [34], 'by': [35, 76], 'higher': [37], 'network.': [42], 'At': [43], 'same': [45], 'time,': [46], 'traditional': [48], 'form': [49], 'biologically': [53], 'implausible.': [54], 'In': [55], 'present': [57], 'paper': [58], 'we': [59], 'propose': [60], 'an': [61], 'unusual': [62], 'rule,': [64], 'which': [65, 73], 'has': [66], 'a': [67, 102, 122, 139, 163], 'degree': [68], 'biological': [70], 'plausibility': [71], 'and': [72, 97, 113], 'motivated': [75], 'Hebb’s': [77], 'idea': [78], 'change': [80], 'synapse': [83], 'strength': [84], 'should': [85, 88], 'be': [86, 132], 'local—i.e.,': [87], 'depend': [89], 'only': [90], 'on': [91, 166], 'activities': [93], 'pre-': [96], 'postsynaptic': [98], 'neurons.': [99], 'We': [100], 'design': [101], 'utilizes': [106], 'global': [107], 'inhibition': [108], 'hidden': [111], 'layer': [112], 'capable': [115], 'completely': [123], 'unsupervised': [124], 'way.': [125], 'These': [126], 'learned': [127], 'lower-layer': [128], 'can': [131], 'used': [133], 'to': [134, 153], 'train': [135], 'higher-layer': [136], 'weights': [137], 'usual': [140], 'supervised': [141], 'way': [142], 'performance': [146, 155], 'full': [149], 'network': [150], 'comparable': [152], 'standard': [157], 'feedforward': [158], 'networks': [159], 'trained': [160], 'simple': [167], 'tasks.': [168]}",2019,"['Backpropagation', 'Artificial intelligence', 'Computer science', 'Artificial neural network', 'Feature (linguistics)', 'Feed forward', 'Unsupervised learning', 'Learning rule', 'Layer (electronics)', 'Supervised learning', 'Feedforward neural network', 'Task (project management)', 'Pattern recognition (psychology)', 'Competitive learning', 'Machine learning', 'Engineering', 'Philosophy', 'Control engineering', 'Organic chemistry', 'Chemistry', 'Linguistics', 'Systems engineering']","It is widely believed that end-to-end training with the backpropagation algorithm is essential for learning good feature detectors in early layers of artificial neural networks, so that these detectors are useful for the task performed by the higher layers of that neural network. At the same time, the traditional form of backpropagation is biologically implausible. In the present paper we propose an unusual learning rule, which has a degree of biological plausibility and which is motivated by Hebb’s idea that change of the synapse strength should be local—i.e., should depend only on the activities of the pre- and postsynaptic neurons. We design a learning algorithm that utilizes global inhibition in the hidden layer and is capable of learning early feature detectors in a completely unsupervised way. These learned lower-layer feature detectors can be used to train higher-layer weights in a usual supervised way so that the performance of the full network is comparable to the performance of standard feedforward networks trained end-to-end with a backpropagation algorithm on simple tasks."
https://openalex.org/W2169147927,Unsupervised Learning of Morphology,"{'This': [0], 'article': [1], 'surveys': [2], 'work': [3, 61], 'on': [4], 'Unsupervised': [5, 11], 'Learning': [6, 12], 'of': [7, 13, 18, 29, 41, 52, 60], 'Morphology.': [8], 'We': [9, 44, 79], 'define': [10], 'Morphology': [14], 'as': [15], 'the': [16, 48, 53, 69, 74, 81], 'problem': [17], 'inducing': [19], 'a': [20, 42, 65], 'description': [21], '(of': [22], 'some': [23], 'kind,': [24], 'even': [25], 'if': [26], 'only': [27, 37], 'morpheme-segmentation)': [28], 'how': [30], 'orthographic': [31], 'words': [32], 'are': [33, 62, 76], 'built': [34], 'up': [35], 'given': [36], 'raw': [38], 'text': [39], 'data': [40], 'language.': [43], 'briefly': [45], 'go': [46], 'through': [47], 'history': [49], 'and': [50, 68, 85], 'motivation': [51], 'this': [54], 'problem.': [55], 'Next,': [56], 'over': [57], '200': [58], 'items': [59], 'listed': [63], 'with': [64], 'brief': [66], 'characterization,': [67], 'most': [70], 'important': [71], 'ideas': [72], 'in': [73], 'field': [75], 'critically': [77], 'discussed.': [78], 'summarize': [80], 'achievements': [82], 'so': [83], 'far': [84], 'give': [86], 'pointers': [87], 'for': [88], 'future': [89], 'developments.': [90]}",2011,"['Morpheme', 'Computer science', 'Artificial intelligence', 'Unsupervised learning', 'Morphology (biology)', 'Field (mathematics)', 'Natural language processing', 'Segmentation', 'Linguistics', 'Genetics', 'Mathematics', 'Pure mathematics', 'Philosophy', 'Biology']","This article surveys work on Unsupervised Learning of Morphology. We define Unsupervised Learning of Morphology as the problem of inducing a description (of some kind, even if only morpheme-segmentation) of how orthographic words are built up given only raw text data of a language. We briefly go through the history and motivation of the this problem. Next, over 200 items of work are listed with a brief characterization, and the most important ideas in the field are critically discussed. We summarize the achievements so far and give pointers for future developments."
https://openalex.org/W2905885786,Unsupervised Learning-Based Fast Beamforming Design for Downlink MIMO,"{'©': [0], '2018': [1], 'IEEE.': [2], 'Personal': [3], 'use': [4], 'of': [5, 49, 53], 'this': [6, 28, 54], 'material': [7, 29], 'is': [8], 'permitted.': [9], 'Permission': [10], 'from': [11], 'IEEE': [12], 'must': [13], 'be': [14], 'obtained': [15], 'for': [16, 30, 39], 'all': [17], 'other': [18, 57], 'uses,': [19], 'in': [20, 56], 'any': [21, 50], 'current': [22], 'or': [23, 32, 41, 45, 47], 'future': [24], 'media,': [25], 'including': [26], 'reprinting/republishing': [27], 'advertising': [31], 'promotional': [33], 'purposes,': [34], 'creating': [35], 'new': [36], 'collective': [37], 'works,': [38], 'resale': [40], 'redistribution': [42], 'to': [43], 'servers': [44], 'lists,': [46], 'reuse': [48], 'copyrighted': [51], 'component': [52], 'work': [55], 'works.': [58]}",2018,"['Computer science', 'Beamforming', 'Computational complexity theory', 'MIMO', 'Pruning', 'Telecommunications link', 'Artificial neural network', 'Transmitter', 'Minimum mean square error', 'Algorithm', 'Channel (broadcasting)', 'Artificial intelligence', 'Mathematics', 'Telecommunications', 'Estimator', 'Biology', 'Statistics', 'Agronomy']","© 2018 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works."
https://openalex.org/W3042615550,Unsupervised Learning of Image Segmentation Based on Differentiable Feature Clustering,"{'The': [0, 89, 179], 'usage': [1], 'of': [2, 33, 54, 70, 81, 107, 126, 138, 161, 181, 190], 'convolutional': [3], 'neural': [4], 'networks': [5, 169], '(CNNs)': [6], 'for': [7, 112, 141], 'unsupervised': [8], 'image\\nsegmentation': [9], 'was': [10, 185], 'investigated': [11], 'in': [12], 'this': [13], 'study.': [14], 'In': [15], 'the': [16, 39, 48, 52, 64, 68, 85, 124, 162, 182], 'proposed': [17, 65, 163, 183], 'approach,': [18], 'label\\nprediction': [19], 'and': [20, 72, 109], 'network': [21, 101], 'parameter': [22], 'learning': [23], 'are': [24, 93], 'alternately': [25], 'iterated': [26], 'to': [27, 76], 'meet': [28], 'the\\nfollowing': [29], 'criteria:': [30], '(a)': [31], 'pixels': [32, 44], 'similar': [34], 'features': [35], 'should': [36, 45, 57], 'be': [37, 46, 58], 'assigned': [38, 47], 'same\\nlabel,': [40], '(b)': [41], 'spatially': [42], 'continuous': [43], 'same': [49], 'label,': [50], 'and\\n(c)': [51], 'number': [53], 'unique': [55], 'labels': [56], 'large.': [59], 'Although': [60], 'these': [61], 'criteria': [62, 87], 'are\\nincompatible,': [63], 'approach': [66, 184], 'minimizes': [67], 'combination': [69], 'similarity\\nloss': [71], 'spatial': [73], 'continuity': [74], 'loss': [75, 120], 'find': [77], 'a': [78, 98, 118, 172], 'plausible': [79], 'solution': [80], 'label\\nassignment': [82], 'that': [83, 105, 122], 'balances': [84], 'aforementioned': [86], 'well.': [88], 'contributions': [90], 'of\\nthis': [91], 'study': [92], 'four-fold.': [94], 'First,': [95], 'we': [96, 116, 134], 'propose': [97], 'novel': [99], 'end-to-end': [100], 'of\\nunsupervised': [102], 'image': [103, 166, 191], 'segmentation': [104, 142], 'consists': [106], 'normalization': [108], 'an': [110, 136], 'argmax\\nfunction': [111], 'differentiable': [113], 'clustering.': [114], 'Second,': [115], 'introduce': [117], 'spatial\\ncontinuity': [119], 'function': [121], 'mitigates': [123], 'limitations': [125], 'fixed': [127], 'segment\\nboundaries': [128], 'possessed': [129], 'by': [130], 'previous': [131], 'work.': [132], 'Third,': [133], 'present': [135], 'extension': [137, 160], 'the\\nproposed': [139], 'method': [140], 'with': [143, 171], 'scribbles': [144], 'as': [145], 'user': [146], 'input,': [147], 'which': [148], 'showed\\nbetter': [149], 'accuracy': [150], 'than': [151], 'existing': [152], 'methods': [153], 'while': [154], 'maintaining': [155], 'efficiency.': [156], 'Finally,': [157], 'we\\nintroduce': [158], 'another': [159], 'method:': [164], 'unseen': [165], 'segmentation\\nby': [167], 'using': [168], 'pre-trained': [170], 'few': [173], 'reference': [174], 'images': [175], 'without': [176], 're-training\\nthe': [177], 'networks.': [178], 'effectiveness': [180], 'examined': [186], 'on\\nseveral': [187], 'benchmark': [188], 'datasets': [189], 'segmentation.\\n': [192]}",2020,[],"The usage of convolutional neural networks (CNNs) for unsupervised image\nsegmentation was investigated in this study. In the proposed approach, label\nprediction and network parameter learning are alternately iterated to meet the\nfollowing criteria: (a) pixels of similar features should be assigned the same\nlabel, (b) spatially continuous pixels should be assigned the same label, and\n(c) the number of unique labels should be large. Although these criteria are\nincompatible, the proposed approach minimizes the combination of similarity\nloss and spatial continuity loss to find a plausible solution of label\nassignment that balances the aforementioned criteria well. The contributions of\nthis study are four-fold. First, we propose a novel end-to-end network of\nunsupervised image segmentation that consists of normalization and an argmax\nfunction for differentiable clustering. Second, we introduce a spatial\ncontinuity loss function that mitigates the limitations of fixed segment\nboundaries possessed by previous work. Third, we present an extension of the\nproposed method for segmentation with scribbles as user input, which showed\nbetter accuracy than existing methods while maintaining efficiency. Finally, we\nintroduce another extension of the proposed method: unseen image segmentation\nby using networks pre-trained with a few reference images without re-training\nthe networks. The effectiveness of the proposed approach was examined on\nseveral benchmark datasets of image segmentation.\n"
https://openalex.org/W3171229070,"A Survey on Semi-, Self- and Unsupervised Learning for Image Classification","{'While': [0], 'deep': [1], 'learning': [2], 'strategies': [3, 16], 'achieve': [4, 162], 'outstanding': [5], 'results': [6, 58, 164], 'in': [7, 91, 101, 139], 'computer': [8], 'vision': [9], 'tasks,': [10], 'one': [11], 'issue': [12], 'remains:': [13], 'The': [14, 154], 'current': [15], 'rely': [17], 'heavily': [18], 'on': [19, 104], 'a': [20, 64, 114, 183], 'huge': [21], 'amount': [22, 38], 'of': [23, 39, 66, 75, 85, 156, 168, 186, 199], 'labeled': [24, 40], 'data.': [25, 42], 'In': [26, 78, 117], 'many': [27, 205], 'real-world': [28, 137], 'problems,': [29], 'it': [30, 44, 69], 'is': [31, 45, 70, 159, 171], 'not': [32, 151, 203], 'feasible': [33], 'to': [34, 47, 55, 63, 72, 127, 136, 161, 165, 177, 180, 217], 'create': [35], 'such': [36], 'an': [37, 83], 'training': [41, 53], 'Therefore,': [43], 'common': [46, 193], 'incorporate': [48], 'unlabeled': [49], 'data': [50], 'into': [51], 'the': [52, 166], 'process': [54], 'reach': [56], 'equal': [57], 'with': [59, 94, 182], 'fewer': [60, 95], 'labels.': [61, 96], 'Due': [62], 'lot': [65], 'concurrent': [67], 'research,': [68], 'difficult': [71], 'keep': [73], 'track': [74], 'recent': [76], 'developments.': [77], 'this': [79], 'survey,': [80], 'we': [81, 120, 196], 'provide': [82], 'overview': [84], 'often': [86], 'used': [87, 110], 'ideas': [88, 111, 194, 211], 'and': [89, 107, 173], 'methods': [90, 100, 133, 175, 190, 200], 'image': [92], 'classification': [93], 'We': [97, 207], 'compare': [98], '34': [99], 'detail': [102], 'based': [103], 'their': [105, 108], 'performance': [106], 'commonly': [109], 'rather': [112], 'than': [113], 'fine-grained': [115], 'taxonomy.': [116], 'our': [118], 'analysis,': [119], 'identify': [121, 197], 'three': [122], 'major': [123], 'trends': [124], 'that': [125, 201, 209], 'lead': [126, 216], 'future': [128], 'research': [129], 'opportunities.': [130], '1.': [131], 'State-of-the-art': [132], 'are': [134, 150], 'scalable': [135], 'applications': [138], 'theory': [140], 'but': [141, 195], 'issues': [142], 'like': [143], 'class': [144], 'imbalance,': [145], 'robustness,': [146], 'or': [147], 'fuzzy': [148], 'labels': [149, 170], 'considered.': [152], '2.': [153], 'degree': [155], 'supervision': [157], 'which': [158], 'needed': [160], 'comparable': [163], 'usage': [167], 'all': [169], 'decreasing': [172], 'therefore': [174], 'need': [176], 'be': [178], 'extended': [179], 'settings': [181], 'variable': [184], 'number': [185], 'classes.': [187], '3.': [188], 'All': [189], 'share': [191, 204], 'some': [192], 'clusters': [198, 214], 'do': [202], 'ideas.': [206], 'show': [208], 'combining': [210], 'from': [212], 'different': [213], 'can': [215], 'better': [218], 'performance.': [219]}",2021,"['Computer science', 'Robustness (evolution)', 'Artificial intelligence', 'Machine learning', 'Process (computing)', 'Taxonomy (biology)', 'Contextual image classification', 'Class (philosophy)', 'Training set', 'Variable (mathematics)', 'Data science', 'Data mining', 'Image (mathematics)', 'Botany', 'Mathematics', 'Operating system', 'Biology', 'Mathematical analysis', 'Biochemistry', 'Chemistry', 'Gene']","While deep learning strategies achieve outstanding results in computer vision tasks, one issue remains: The current strategies rely heavily on a huge amount of labeled data. In many real-world problems, it is not feasible to create such an amount of labeled training data. Therefore, it is common to incorporate unlabeled data into the training process to reach equal results with fewer labels. Due to a lot of concurrent research, it is difficult to keep track of recent developments. In this survey, we provide an overview of often used ideas and methods in image classification with fewer labels. We compare 34 methods in detail based on their performance and their commonly used ideas rather than a fine-grained taxonomy. In our analysis, we identify three major trends that lead to future research opportunities. 1. State-of-the-art methods are scalable to real-world applications in theory but issues like class imbalance, robustness, or fuzzy labels are not considered. 2. The degree of supervision which is needed to achieve comparable results to the usage of all labels is decreasing and therefore methods need to be extended to settings with a variable number of classes. 3. All methods share some common ideas but we identify clusters of methods that do not share many ideas. We show that combining ideas from different clusters can lead to better performance."
https://openalex.org/W2118681326,Supervised and unsupervised learning for sentence compression,"{'In': [0], 'Statistics-Based': [1], 'Summarization': [2], '-': [3], 'Step': [4], 'One:': [5], 'Sentence': [6], 'Compression,': [7], 'Knight': [8, 35], 'and': [9, 12, 36, 64], 'Marcu': [10, 37], '(Knight': [11], 'Marcu,': [13], '2000)': [14], '(K&M)': [15], 'present': [16], 'a': [17, 39], 'noisy-channel': [18, 59], 'model': [19], 'for': [20, 85], 'sentence': [21], 'compression.': [22], 'The': [23], 'main': [24], 'difficulty': [25], 'in': [26, 52, 79], 'using': [27], 'this': [28, 80], 'method': [29], 'is': [30, 47], 'the': [31, 56, 68, 77], 'lack': [32], 'of': [33, 41, 67], 'data;': [34], 'use': [38], 'corpus': [40], '1035': [42], 'training': [43], 'sentences.': [44], 'More': [45], 'data': [46], 'not': [48], 'easily': [49], 'available,': [50], 'so': [51], 'addition': [53], 'to': [54], 'improving': [55], 'original': [57], 'K&M': [58], 'model,': [60], 'we': [61, 71], 'create': [62], 'unsupervised': [63], 'semi-supervised': [65], 'models': [66], 'task.': [69], 'Finally,': [70], 'point': [72], 'out': [73], 'problems': [74], 'with': [75], 'modeling': [76], 'task': [78], 'way.': [81], 'They': [82], 'suggest': [83], 'areas': [84], 'future': [86], 'research.': [87]}",2005,"['Computer science', 'Automatic summarization', 'Sentence', 'Artificial intelligence', 'Task (project management)', 'Natural language processing', 'Unsupervised learning', 'Compression (physics)', 'Point (geometry)', 'Knight', 'Channel (broadcasting)', 'Speech recognition', 'Machine learning', 'Mathematics', 'Physics', 'Computer network', 'Materials science', 'Astronomy', 'Economics', 'Management', 'Geometry', 'Composite material']","In Statistics-Based Summarization - Step One: Sentence Compression, Knight and Marcu (Knight and Marcu, 2000) (K&M) present a noisy-channel model for sentence compression. The main difficulty in using this method is the lack of data; Knight and Marcu use a corpus of 1035 training sentences. More data is not easily available, so in addition to improving the original K&M noisy-channel model, we create unsupervised and semi-supervised models of the task. Finally, we point out problems with modeling the task in this way. They suggest areas for future research."
https://openalex.org/W2908875379,Lung and Pancreatic Tumor Characterization in the Deep Learning Era: Novel Supervised and Unsupervised Learning Approaches,"{'Risk': [0], 'stratification': [1], '(characterization)': [2], 'of': [3, 39, 92, 130, 173], 'tumors': [4], 'from': [5, 144], 'radiology': [6], 'images': [7], 'can': [8, 24], 'be': [9], 'more': [10], 'accurate': [11], 'and': [12, 31, 49, 84, 185, 196, 201, 206, 211], 'faster': [13], 'with': [14, 72, 198], 'computer-aided': [15], 'diagnosis': [16, 193], '(CAD)': [17], 'tools.': [18], 'Tumor': [19], 'characterization': [20], 'through': [21], 'such': [22], 'tools': [23], 'also': [25, 162], 'enable': [26], 'non-invasive': [27], 'cancer': [28], 'staging,': [29], 'prognosis,': [30], 'foster': [32], 'personalized': [33], 'treatment': [34], 'planning': [35], 'as': [36], 'a': [37, 79, 105, 109, 134], 'part': [38], 'precision': [40], 'medicine.': [41], 'In': [42, 115], 'this': [43], 'papet,': [44], 'we': [45, 68, 95, 119, 151], 'propose': [46, 152], 'both': [47, 215], 'supervised': [48, 64, 184], 'unsupervised': [50, 122, 177, 186], 'machine': [51, 157], 'learning': [52, 65, 74, 113, 123, 143, 187], 'strategies': [53], 'to': [54, 99, 125, 153, 166], 'improve': [55], 'tumor': [56, 178, 192], 'characterization.': [57], 'Our': [58], 'first': [59], 'approach': [60], 'is': [61], 'based': [62], 'on': [63, 189], 'for': [66, 158, 176], 'which': [67], 'demonstrate': [69], 'significant': [70], 'gains': [71], 'deep': [73], 'algorithms,': [75], 'particularly': [76], 'by': [77, 88, 142], 'utilizing': [78], '3D': [80], 'convolutional': [81], 'neural': [82], 'network': [83], 'transfer': [85], 'learning.': [86], 'Motivated': [87], 'the': [89, 93, 116, 127, 164, 167, 171, 208], ""radiologists'"": [90], 'interpretations': [91], 'scans,': [94, 204], 'then': [96], 'show': [97], 'how': [98], 'incorporate': [100], 'task-dependent': [101], 'feature': [102], 'representations': [103], 'into': [104], 'CAD': [106], 'system': [107], 'via': [108], 'graph-regularized': [110], 'sparse': [111], 'multi-task': [112], 'framework.': [114], 'second': [117], 'approach,': [118], 'explore': [120], 'an': [121], 'algorithm': [124], 'address': [126], 'limited': [128], 'availability': [129], 'labeled': [131], 'training': [132], 'data,': [133], 'common': [135], 'problem': [136], 'in': [137, 148, 214], 'medical': [138], 'imaging': [139], 'applications.': [140], 'Inspired': [141], 'label': [145], 'proportion': [146], 'approaches': [147], 'computer': [149], 'vision,': [150], 'use': [154], 'proportion-support': [155], 'vector': [156], 'characterizing': [159], 'tumors.': [160], 'We': [161, 180], 'seek': [163], 'answer': [165], 'fundamental': [168], 'question': [169], 'about': [170], 'goodness': [172], '""deep': [174], 'features""': [175], 'classification.': [179], 'evaluate': [181], 'our': [182], 'proposed': [183], 'algorithms': [188], 'two': [190], 'different': [191], 'challenges:': [194], 'lung': [195], 'pancreas': [197], '1018': [199], 'CT': [200], '171': [202], 'MRI': [203], 'respectively,': [205], 'obtain': [207], 'state-of-the-art': [209], 'sensitivity': [210], 'specificity': [212], 'results': [213], 'problems.': [216]}",2019,"['Artificial intelligence', 'Machine learning', 'Computer science', 'Deep learning', 'Unsupervised learning', 'Convolutional neural network', 'Feature learning', 'Semi-supervised learning', 'Multi-task learning', 'Medical imaging', 'Feature engineering', 'Supervised learning', 'Pattern recognition (psychology)', 'Artificial neural network', 'Task (project management)', 'Economics', 'Management']","Risk stratification (characterization) of tumors from radiology images can be more accurate and faster with computer-aided diagnosis (CAD) tools. Tumor characterization through such tools can also enable non-invasive cancer staging, prognosis, and foster personalized treatment planning as a part of precision medicine. In this papet, we propose both supervised and unsupervised machine learning strategies to improve tumor characterization. Our first approach is based on supervised learning for which we demonstrate significant gains with deep learning algorithms, particularly by utilizing a 3D convolutional neural network and transfer learning. Motivated by the radiologists' interpretations of the scans, we then show how to incorporate task-dependent feature representations into a CAD system via a graph-regularized sparse multi-task learning framework. In the second approach, we explore an unsupervised learning algorithm to address the limited availability of labeled training data, a common problem in medical imaging applications. Inspired by learning from label proportion approaches in computer vision, we propose to use proportion-support vector machine for characterizing tumors. We also seek the answer to the fundamental question about the goodness of ""deep features"" for unsupervised tumor classification. We evaluate our proposed supervised and unsupervised learning algorithms on two different tumor diagnosis challenges: lung and pancreas with 1018 CT and 171 MRI scans, respectively, and obtain the state-of-the-art sensitivity and specificity results in both problems."
https://openalex.org/W2085256060,Automatic text categorization by unsupervised learning,"{'Tile': [0], 'goal': [1], 'of': [2, 13, 27, 97, 120], 'text': [3, 139], 'categorization': [4], 'is': [5, 36, 39, 49, 57, 141], 'to': [6, 41, 51, 61, 78], 'classify': [7], 'documents': [8, 30, 87], 'iuto': [9], 'a': [10, 24, 117], 'certain': [11], 'number': [12, 26], 'predefined': [14], 'categories.': [15], 'The': [16, 82, 113], 'previous': [17], 'works': [18], 'iu': [19], 'this': [20, 70, 130], 'area': [21], 'have': [22], 'used': [23, 134, 147], 'large': [25], 'labeled': [28, 44], 'training': [29, 45], 'IBr': [31], 'supervised': [32, 126], 'learning.': [33], 'One': [34], 'problem': [35], 'that': [37], 'it': [38, 48, 56, 106], 'difficult': [40], 'create': [42], 'the': [43, 53, 86, 108, 124], 'documeuls.': [46], 'While': [47], 'easy': [50, 60], 'collect': [52], 'unlabeled': [54], 'documents,': [55], 'not': [58], 'so': [59], 'mauually': [62], 'categorize': [63], 'them': [64], 'for': [65, 111, 148], 'creating': [66, 149], 'traiuiug': [67], 'documents.': [68, 151], 'In': [69], 'paper,': [71], 'we': [72], 'propose': [73], 'an': [74], 'unsupervised': [75], '!earntug': [76], 'method': [77, 84, 115], 'overcome': [79], 'these': [80], 'difficulties.': [81], 'proposed': [83, 114], 'divides': [85], 'into': [88], 'sentences,': [89], 'aud': [90], 'categorizes': [91], 'each': [92, 98], 'sentence': [93], 'using': [94], 'keyword': [95], 'lists': [96], 'category': [99], 'and': [100], 'scnteuce': [101], 'similarity': [102], 'measure.': [103], 'And': [104], 'lhen,': [105], 'uses': [107], 'categorized': [109], 'senteuces': [110], 'training.': [112], 'shows': [116], 'silnilar': [118], 'degree': [119], 'performance,': [121], 'compared': [122], 'with': [123], 'traditional': [125], 'learuing': [127], 'inethods.': [128], 'Therefore,': [129], 'nethod': [131], 'can': [132, 145], 'be': [133, 146], 'in': [135], 'areas': [136], 'where': [137], 'low-cost': [138], 'catcgorizatiou': [140], 'needed.': [142], 'It': [143], 'also': [144], 'traiuing': [150]}",2000,"['Categorization', 'Computer science', 'Artificial intelligence', 'Unsupervised learning', 'Text categorization', 'Natural language processing', 'Machine learning']","Tile goal of text categorization is to classify documents iuto a certain number of predefined categories. The previous works iu this area have used a large number of labeled training documents IBr supervised learning. One problem is that it is difficult to create the labeled training documeuls. While it is easy to collect the unlabeled documents, it is not so easy to mauually categorize them for creating traiuiug documents. In this paper, we propose an unsupervised !earntug method to overcome these difficulties. The proposed method divides the documents into sentences, aud categorizes each sentence using keyword lists of each category and scnteuce similarity measure. And lhen, it uses the categorized senteuces for training. The proposed method shows a silnilar degree of performance, compared with the traditional supervised learuing inethods. Therefore, this nethod can be used in areas where low-cost text catcgorizatiou is needed. It also can be used for creating traiuing documents."
https://openalex.org/W2578257192,Unsupervised Learning of Long-Term Motion Dynamics for Videos,"{'We': [0, 58, 73, 101], 'present': [1], 'an': [2], 'unsupervised': [3], 'representation': [4, 92], 'learning': [5, 39], 'approach': [6], 'that': [7, 75, 93], 'compactly': [8], 'encodes': [9], 'the': [10, 29, 35, 38, 45, 79, 85, 103], 'motion': [11, 46, 96], 'dependencies': [12, 97], 'in': [13, 76], 'videos.': [14, 140], 'Given': [15], 'a': [16, 21, 48, 60, 89], 'pair': [17], 'of': [18, 37, 50, 71, 105], 'images': [19], 'from': [20], 'video': [22, 91], 'clip,': [23], 'our': [24, 106], 'framework': [25, 66, 128], 'learns': [26], 'to': [27, 43, 67, 81, 131], 'predict': [28, 68], 'long-term': [30, 95], '3D': [31, 52], 'motions.': [32], 'To': [33], 'reduce': [34], 'complexity': [36], 'framework,': [40], 'we': [41], 'propose': [42], 'describe': [44], 'as': [47, 119], 'sequence': [49], 'atomic': [51], 'flows': [53], 'computed': [54], 'with': [55], 'RGB-D': [56, 139], 'modality.': [57], 'use': [59], 'Recurrent': [61], 'Neural': [62], 'Network': [63], 'based': [64], 'Encoder-Decoder': [65], 'these': [69, 83], 'sequences': [70], 'flows.': [72], 'argue': [74], 'order': [77], 'for': [78], 'decoder': [80], 'reconstruct': [82], 'sequences,': [84], 'encoder': [86], 'must': [87], 'learn': [88], 'robust': [90], 'captures': [94], 'and': [98, 116, 122, 138], 'spatial-temporal': [99], 'relations.': [100], 'demonstrate': [102], 'effectiveness': [104], 'learned': [107], 'temporal': [108], 'representations': [109], 'on': [110], 'activity': [111], 'classification': [112], 'across': [113], 'multiple': [114], 'modalities': [115], 'datasets': [117], 'such': [118], 'NTU': [120], 'RGB+D': [121], 'MSR': [123], 'Daily': [124], 'Activity': [125], '3D.': [126], 'Our': [127], 'is': [129], 'generic': [130], 'any': [132], 'input': [133], 'modality,': [134], 'i.e.,': [135], 'RGB,': [136], 'Depth,': [137]}",2017,"['Computer science', 'Artificial intelligence', 'RGB color model', 'Representation (politics)', 'Encoder', 'Modality (human–computer interaction)', 'Motion (physics)', 'Term (time)', 'Computer vision', 'Feature learning', 'Sequence (biology)', 'Artificial neural network', 'Recurrent neural network', 'Modalities', 'Pattern recognition (psychology)', 'Physics', 'Political science', 'Law', 'Politics', 'Operating system', 'Genetics', 'Sociology', 'Biology', 'Quantum mechanics', 'Social science']","We present an unsupervised representation learning approach that compactly encodes the motion dependencies in videos. Given a pair of images from a video clip, our framework learns to predict the long-term 3D motions. To reduce the complexity of the learning framework, we propose to describe the motion as a sequence of atomic 3D flows computed with RGB-D modality. We use a Recurrent Neural Network based Encoder-Decoder framework to predict these sequences of flows. We argue that in order for the decoder to reconstruct these sequences, the encoder must learn a robust video representation that captures long-term motion dependencies and spatial-temporal relations. We demonstrate the effectiveness of our learned temporal representations on activity classification across multiple modalities and datasets such as NTU RGB+D and MSR Daily Activity 3D. Our framework is generic to any input modality, i.e., RGB, Depth, and RGB-D videos."
https://openalex.org/W2607510315,Unsupervised Learning by Predicting Noise,"{'Convolutional': [0], 'neural': [1], 'networks': [2, 18], 'provide': [3], 'visual': [4], 'features': [5, 57], 'that': [6, 103], 'perform': [7, 104], 'remarkably': [8], 'well': [9], 'in': [10], 'many': [11], 'computer': [12], 'vision': [13], 'applications.': [14], 'However,': [15], 'training': [16], 'these': [17], 'requires': [19], 'significant': [20], 'amounts': [21], 'of': [22, 44, 72, 77, 96], 'supervision.': [23, 37], 'This': [24, 62], 'paper': [25], 'introduces': [26], 'a': [27, 42, 81, 87], 'generic': [28], 'framework': [29], 'to': [30, 40, 53, 58, 60, 80, 94], 'train': [31], 'deep': [32, 56], 'networks,': [33], 'end-to-end,': [34], 'with': [35, 107], 'no': [36], 'We': [38], 'propose': [39], 'fix': [41], 'set': [43], 'target': [45], 'representations,': [46], 'called': [47], 'Noise': [48], 'As': [49], 'Targets': [50], '(NAT),': [51], 'and': [52, 75, 86, 113], 'constrain': [54], 'the': [55, 67], 'align': [59], 'them.': [61], 'domain': [63], 'agnostic': [64], 'approach': [65, 100], 'avoids': [66], 'standard': [68], 'unsupervised': [69, 109], 'learning': [70], 'issues': [71], 'trivial': [73], 'solutions': [74], 'collapsing': [76], 'features.': [78], 'Thanks': [79], 'stochastic': [82], 'batch': [83], 'reassignment': [84], 'strategy': [85], 'separable': [88], 'square': [89], 'loss': [90], 'function,': [91], 'it': [92], 'scales': [93], 'millions': [95], 'images.': [97], 'The': [98], 'proposed': [99], 'produces': [101], 'representations': [102], 'on': [105, 111], 'par': [106], 'state-of-the-art': [108], 'methods': [110], 'ImageNet': [112], 'Pascal': [114], 'VOC.': [115]}",2017,"['Pascal (unit)', 'Computer science', 'Artificial intelligence', 'Deep learning', 'Deep neural networks', 'Unsupervised learning', 'Convolutional neural network', 'Noise (video)', 'Set (abstract data type)', 'Machine learning', 'Domain (mathematical analysis)', 'Pattern recognition (psychology)', 'Image (mathematics)', 'Mathematics', 'Mathematical analysis', 'Programming language']","Convolutional neural networks provide visual features that perform remarkably well in many computer vision applications. However, training these networks requires significant amounts of supervision. This paper introduces a generic framework to train deep networks, end-to-end, with no supervision. We propose to fix a set of target representations, called Noise As Targets (NAT), and to constrain the deep features to align to them. This domain agnostic approach avoids the standard unsupervised learning issues of trivial solutions and collapsing of features. Thanks to a stochastic batch reassignment strategy and a separable square loss function, it scales to millions of images. The proposed approach produces representations that perform on par with state-of-the-art unsupervised methods on ImageNet and Pascal VOC."
https://openalex.org/W2895106137,Unsupervised Learning via Meta-Learning,"{'A': [0], 'central': [1], 'goal': [2], 'of': [3, 23, 29, 70, 75, 121, 152], 'unsupervised': [4, 34, 57, 134, 164], 'learning': [5, 22, 35, 139, 165], 'is': [6, 146], 'to': [7, 38, 66, 115, 148], 'acquire': [8], 'representations': [9], 'from': [10, 26, 72, 83], 'unlabeled': [11, 84], 'data': [12, 85, 144], 'or': [13], 'experience': [14], 'that': [15, 60, 132, 145], 'can': [16], 'be': [17], 'used': [18], 'for': [19, 63], 'more': [20], 'effective': [21], 'downstream': [24, 153], 'tasks': [25, 71, 82], 'modest': [27], 'amounts': [28, 74], 'labeled': [30, 143], 'data.': [31, 76], 'Many': [32], 'prior': [33, 163], 'works': [36], 'aim': [37], 'do': [39, 78], 'so': [40], 'by': [41, 161], 'developing': [42], 'proxy': [43], 'objectives': [44], 'based': [45], 'on': [46, 118], 'reconstruction,': [47], 'disentanglement,': [48], 'prediction,': [49], 'and': [50, 90], 'other': [51], 'metrics.': [52], 'Instead,': [53], 'we': [54, 80, 98], 'develop': [55], 'an': [56, 87], 'meta-learning': [58, 92, 135], 'method': [59], 'explicitly': [61], 'optimizes': [62], 'the': [64, 94, 158], 'ability': [65], 'learn': [67], 'a': [68, 119, 138, 149], 'variety': [69, 120], 'small': [73], 'To': [77], 'so,': [79], 'construct': [81], 'in': [86], 'automatic': [88], 'way': [89], 'run': [91], 'over': [93], 'constructed': [95], 'tasks.': [96, 124], 'Surprisingly,': [97], 'find': [99], 'that,': [100], 'when': [101], 'integrated': [102], 'with': [103], 'meta-learning,': [104], 'relatively': [105], 'simple': [106], 'task': [107], 'construction': [108], 'mechanisms,': [109], 'such': [110], 'as': [111], 'clustering': [112], 'embeddings,': [113], 'lead': [114], 'good': [116], 'performance': [117], 'downstream,': [122], 'human-specified': [123], 'Our': [125], 'experiments': [126], 'across': [127], 'four': [128, 162], 'image': [129], 'datasets': [130], 'indicate': [131], 'our': [133], 'approach': [136], 'acquires': [137], 'algorithm': [140], 'without': [141], 'any': [142], 'applicable': [147], 'wide': [150], 'range': [151], 'classification': [154], 'tasks,': [155], 'improving': [156], 'upon': [157], 'embedding': [159], 'learned': [160], 'methods.': [166]}",2018,"['Unsupervised learning', 'Computer science', 'Meta learning (computer science)', 'Machine learning', 'Artificial intelligence', 'Cluster analysis', 'Embedding', 'Construct (python library)', 'Variety (cybernetics)', 'Task (project management)', 'Feature learning', 'Conceptual clustering', 'Competitive learning', 'Fuzzy clustering', 'Management', 'Programming language', 'CURE data clustering algorithm', 'Economics']","A central goal of unsupervised learning is to acquire representations from unlabeled data or experience that can be used for more effective learning of downstream tasks from modest amounts of labeled data. Many prior unsupervised learning works aim to do so by developing proxy objectives based on reconstruction, disentanglement, prediction, and other metrics. Instead, we develop an unsupervised meta-learning method that explicitly optimizes for the ability to learn a variety of tasks from small amounts of data. To do so, we construct tasks from unlabeled data in an automatic way and run meta-learning over the constructed tasks. Surprisingly, we find that, when integrated with meta-learning, relatively simple task construction mechanisms, such as clustering embeddings, lead to good performance on a variety of downstream, human-specified tasks. Our experiments across four image datasets indicate that our unsupervised meta-learning approach acquires a learning algorithm without any labeled data that is applicable to a wide range of downstream classification tasks, improving upon the embedding learned by four prior unsupervised learning methods."
https://openalex.org/W2785325870,Unsupervised Representation Learning by Predicting Image Rotations,"{'Over': [0], 'the': [1, 11, 74, 98, 105, 175, 195, 210], 'last': [2], 'years,': [3], 'deep': [4], 'convolutional': [5], 'neural': [6], 'networks': [7], '(ConvNets)': [8], 'have': [9], 'transformed': [10], 'field': [12], 'of': [13, 41, 66, 77, 150, 201, 244], 'computer': [14], 'vision': [15], 'thanks': [16], 'to': [17, 21, 31, 51, 71, 89, 96, 104], 'their': [18], 'unparalleled': [19], 'capacity': [20], 'learn': [22, 33, 90], 'high': [23], 'level': [24], 'semantic': [25, 55, 131], 'image': [26, 91, 106], 'features.': [27], 'However,': [28], 'in': [29, 69, 139, 148, 167, 183], 'order': [30, 70], 'successfully': [32, 72], 'those': [34, 158], 'features,': [35], 'they': [36], 'usually': [37], 'require': [38], 'massive': [39], 'amounts': [40], 'manually': [42], 'labeled': [43], 'data,': [44], 'which': [45], 'is': [46, 65, 102, 204], 'both': [47, 114], 'expensive': [48], 'and': [49, 116, 145, 171, 237, 242], 'impractical': [50], 'scale.': [52], 'Therefore,': [53], 'unsupervised': [54, 141, 168, 190, 198, 222], 'feature': [56, 132, 142, 179], 'learning,': [57], 'i.e.,': [58], 'learning': [59, 143, 170], 'without': [60], 'requiring': [61], 'manual': [62], 'annotation': [63], 'effort,': [64], 'crucial': [67], 'importance': [68], 'harvest': [73], 'vast': [75], 'amount': [76], 'visual': [78], 'data': [79], 'that': [80, 101, 107, 118, 203], 'are': [81], 'available': [82], 'today.': [83], 'In': [84], 'our': [85, 137, 155, 189, 221, 245], 'work': [86], 'we': [87, 146, 219], 'propose': [88], 'features': [92, 224], 'by': [93], 'training': [94], 'ConvNets': [95], 'recognize': [97], '2d': [99], 'rotation': [100], 'applied': [103], 'it': [108], 'gets': [109], 'as': [110, 230], 'input.': [111], 'We': [112, 134, 213], 'demonstrate': [113, 160], 'qualitatively': [115], 'quantitatively': [117], 'this': [119], 'apparently': [120], 'simple': [121], 'task': [122, 188], 'actually': [123], 'provides': [124], 'a': [125], 'very': [126], 'powerful': [127], 'supervisory': [128], 'signal': [129], 'for': [130], 'learning.': [133, 180], 'exhaustively': [135], 'evaluate': [136], 'method': [138], 'various': [140, 226], 'benchmarks': [144, 159], 'exhibit': [147], 'all': [149], 'them': [151], 'state-of-the-art': [152, 165, 196], 'performance.': [153], 'Specifically,': [154], 'results': [156, 217], 'on': [157, 225], 'dramatic': [161], 'improvements': [162], 'w.r.t.': [163], 'prior': [164], 'approaches': [166], 'representation': [169], 'thus': [172], 'significantly': [173], 'close': [174], 'gap': [176], 'with': [177], 'supervised': [178, 211], 'For': [181], 'instance,': [182], 'PASCAL': [184, 233, 235], 'VOC': [185], '2007': [186], 'detection': [187], 'pre-trained': [191], 'AlexNet': [192], 'model': [193], 'achieves': [194], '(among': [197], 'methods)': [199], 'mAP': [200], '54.4%': [202], 'only': [205], '2.4': [206], 'points': [207], 'lower': [208], 'from': [209], 'case.': [212], 'get': [214], 'similarly': [215], 'striking': [216], 'when': [218], 'transfer': [220], 'learned': [223], 'other': [227], 'tasks,': [228], 'such': [229], 'ImageNet': [231], 'classification,': [232, 234], 'segmentation,': [236], 'CIFAR-10': [238], 'classification.': [239], 'The': [240], 'code': [241], 'models': [243], 'paper': [246], 'will': [247], 'be': [248], 'published': [249], 'on:': [250], 'https://github.com/gidariss/FeatureLearningRotNet': [251], '.': [252]}",2018,"['Pascal (unit)', 'Artificial intelligence', 'Computer science', 'Unsupervised learning', 'Convolutional neural network', 'Feature learning', 'Pattern recognition (psychology)', 'Transfer of learning', 'Deep learning', 'Machine learning', 'Feature extraction', 'Supervised learning', 'Feature (linguistics)', 'Artificial neural network', 'Linguistics', 'Programming language', 'Philosophy']","Over the last years, deep convolutional neural networks (ConvNets) have transformed the field of computer vision thanks to their unparalleled capacity to learn high level semantic image features. However, in order to successfully learn those features, they usually require massive amounts of manually labeled data, which is both expensive and impractical to scale. Therefore, unsupervised semantic feature learning, i.e., learning without requiring manual annotation effort, is of crucial importance in order to successfully harvest the vast amount of visual data that are available today. In our work we propose to learn image features by training ConvNets to recognize the 2d rotation that is applied to the image that it gets as input. We demonstrate both qualitatively and quantitatively that this apparently simple task actually provides a very powerful supervisory signal for semantic feature learning. We exhaustively evaluate our method in various unsupervised feature learning benchmarks and we exhibit in all of them state-of-the-art performance. Specifically, our results on those benchmarks demonstrate dramatic improvements w.r.t. prior state-of-the-art approaches in unsupervised representation learning and thus significantly close the gap with supervised feature learning. For instance, in PASCAL VOC 2007 detection task our unsupervised pre-trained AlexNet model achieves the state-of-the-art (among unsupervised methods) mAP of 54.4% that is only 2.4 points lower from the supervised case. We get similarly striking results when we transfer our unsupervised learned features on various other tasks, such as ImageNet classification, PASCAL classification, PASCAL segmentation, and CIFAR-10 classification. The code and models of our paper will be published on: https://github.com/gidariss/FeatureLearningRotNet ."
https://openalex.org/W2297862270,Unsupervised Learning by Spike Timing Dependent Plasticity in Phase Change Memory (PCM) Synapses,"{'We': [0], 'present': [1], 'a': [2, 47, 101], 'novel': [3], 'one-transistor/one-resistor': [4], '(1T1R)': [5], 'synapse': [6, 18, 73], 'for': [7, 74, 105], 'neuromorphic': [8, 86], 'networks,': [9], 'based': [10], 'on': [11, 30], 'phase': [12], 'change': [13], 'memory': [14], '(PCM)': [15], 'technology.': [16], 'The': [17, 97], 'is': [19, 40], 'capable': [20], 'of': [21, 46, 63, 70, 78, 83], 'spike-timing': [22], 'dependent': [23], 'plasticity': [24], '(STDP),': [25], 'where': [26], 'gradual': [27], 'potentiation': [28], 'relies': [29], 'set': [31], 'transition,': [32], 'namely': [33], 'crystallization,': [34], 'in': [35, 110], 'the': [36, 68, 71], 'PCM,': [37], 'while': [38], 'depression': [39], 'achieved': [41], 'via': [42], 'reset': [43], 'or': [44, 90], 'amorphization': [45], 'chalcogenide': [48], 'active': [49], 'volume.': [50], 'STDP': [51], 'characteristics': [52], 'are': [53], 'demonstrated': [54], 'by': [55, 81], 'experiments': [56], 'under': [57], 'variable': [58], 'initial': [59], 'conditions': [60], 'and': [61, 76], 'number': [62], 'pulses.': [64], 'Finally,': [65], 'we': [66], 'support': [67], 'applicability': [69], '1T1R': [72], 'learning': [75, 109], 'recognition': [77, 95], 'visual': [79], 'patterns': [80], 'simulations': [82], 'fully': [84], 'connected': [85], 'networks': [87], 'with': [88, 93], '2': [89], '3': [91], 'layers': [92], 'high': [94], 'efficiency.': [96], 'proposed': [98], 'scheme': [99], 'provides': [100], 'feasible': [102], 'low-power': [103], 'solution': [104], 'on-line': [106], 'unsupervised': [107], 'machine': [108], 'smart': [111], 'reconfigurable': [112], 'sensors.': [113]}",2016,"['Neuromorphic engineering', 'Spike-timing-dependent plasticity', 'Phase-change memory', 'Computer science', 'Spike (software development)', 'Reset (finance)', 'Synapse', 'Transistor', 'Unsupervised learning', 'Memristor', 'Resistor', 'Spiking neural network', 'Long-term potentiation', 'Artificial intelligence', 'Artificial neural network', 'Neuroscience', 'Electronic engineering', 'Phase change', 'Voltage', 'Physics', 'Electrical engineering', 'Engineering', 'Psychology', 'Chemistry', 'Software engineering', 'Economics', 'Financial economics', 'Engineering physics', 'Biochemistry', 'Receptor']","We present a novel one-transistor/one-resistor (1T1R) synapse for neuromorphic networks, based on phase change memory (PCM) technology. The synapse is capable of spike-timing dependent plasticity (STDP), where gradual potentiation relies on set transition, namely crystallization, in the PCM, while depression is achieved via reset or amorphization of a chalcogenide active volume. STDP characteristics are demonstrated by experiments under variable initial conditions and number of pulses. Finally, we support the applicability of the 1T1R synapse for learning and recognition of visual patterns by simulations of fully connected neuromorphic networks with 2 or 3 layers with high recognition efficiency. The proposed scheme provides a feasible low-power solution for on-line unsupervised machine learning in smart reconfigurable sensors."
https://openalex.org/W2532666972,Analog Memristive Synapse in Spiking Networks Implementing Unsupervised Learning,"{'Emerging': [0], 'brain-inspired': [1], 'architectures': [2], 'call': [3], 'for': [4, 169, 204], 'devices': [5, 28], 'that': [6], 'can': [7], 'emulate': [8], 'the': [9, 44, 47, 50, 59, 66, 129, 133, 137], 'functionality': [10, 61], 'of': [11, 62, 177, 233], 'biological': [12, 73], 'synapses': [13, 171, 175], 'in': [14, 36, 46, 72, 149, 217], 'order': [15], 'to': [16, 23, 43, 57, 83, 114, 212, 229, 235], 'implement': [17], 'new': [18], 'efficient': [19], 'computational': [20], 'schemes': [21], 'able': [22, 56, 82, 113, 211], 'solve': [24], 'ill-posed': [25], 'problems.': [26], 'Various': [27], 'and': [29, 97, 225], 'solutions': [30], 'are': [31, 223], 'still': [32], 'under': [33], 'investigation': [34], 'and,': [35], 'this': [37, 158], 'respect,': [38], 'a': [39, 54, 63, 80, 145, 189, 196, 230], 'challenge': [40], 'is': [41, 53, 139, 144, 210, 227], 'opened': [42], 'researchers': [45], 'field.': [48], 'Indeed,': [49], 'optimal': [51], 'candidate': [52], 'device': [55, 81], 'reproduce': [58], 'complete': [60], 'synapse,': [64], 'i.e.,': [65], 'typical': [67], 'synaptic': [68, 76, 190], 'process': [69], 'underlying': [70], 'learning': [71, 125, 147, 162, 203], 'systems': [74], '(activity-dependent': [75], 'plasticity).': [77], 'This': [78, 142, 181], 'implies': [79], 'change': [84], 'its': [85, 104], 'resistance': [86], '(synaptic': [87, 95], 'strength,': [88], 'or': [89, 220], 'weight)': [90], 'upon': [91], 'proper': [92], 'electrical': [93], 'stimuli': [94], 'activity)': [96], 'showing': [98], 'several': [99, 166], 'stable': [100], 'resistive': [101], 'states': [102], 'throughout': [103], 'dynamic': [105], 'range': [106], '(analog': [107], 'behavior).': [108], 'Moreover,': [109], 'it': [110, 153, 226], 'should': [111], 'be': [112], 'perform': [115], 'spike': [116], 'timing': [117], 'dependent': [118], 'plasticity': [119, 124], '(STDP),': [120], 'an': [121, 184], 'associative': [122], 'homosynaptic': [123], 'rule': [126, 143], 'based': [127], 'on': [128], 'delay': [130], 'time': [131], 'between': [132], 'two': [134], 'firing': [135], 'neurons': [136], 'synapse': [138], 'connected': [140], 'to.': [141], 'fundamental': [146], 'protocol': [148], 'state-of-art': [150], 'networks,': [151], 'because': [152], 'allows': [154], 'unsupervised': [155, 161, 202], 'learning.': [156], 'Notwithstanding': [157], 'fact,': [159], 'STDP-based': [160], 'has': [163], 'been': [164], 'proposed': [165], 'times': [167], 'mainly': [168], 'binary': [170, 179], 'rather': [172], 'than': [173], 'multilevel': [174], 'composed': [176], 'many': [178], 'memristors.': [180], 'paper': [182], 'proposes': [183], 'HfO<sub>2</sub>-based': [185], 'analog': [186], 'memristor': [187], 'as': [188], 'element': [191], 'which': [192], 'performs': [193], 'STDP': [194], 'within': [195], 'small': [197], 'spiking': [198], 'neuromorphic': [199], 'network': [200, 209], 'operating': [201], 'character': [205], 'recognition.': [206], 'The': [207], 'trained': [208], 'recognize': [213], 'five': [214], 'characters': [215], 'even': [216], 'case': [218], 'incomplete': [219], 'noisy': [221], 'images': [222], 'displayed': [224], 'robust': [228], 'device-to-device': [231], 'variability': [232], 'up': [234], '±30%.': [236]}",2016,"['Spiking neural network', 'Synapse', 'Computer science', 'Unsupervised learning', 'Neuroscience', 'Artificial intelligence', 'Artificial neural network', 'Psychology']","Emerging brain-inspired architectures call for devices that can emulate the functionality of biological synapses in order to implement new efficient computational schemes able to solve ill-posed problems. Various devices and solutions are still under investigation and, in this respect, a challenge is opened to the researchers in the field. Indeed, the optimal candidate is a device able to reproduce the complete functionality of a synapse, i.e., the typical synaptic process underlying learning in biological systems (activity-dependent synaptic plasticity). This implies a device able to change its resistance (synaptic strength, or weight) upon proper electrical stimuli (synaptic activity) and showing several stable resistive states throughout its dynamic range (analog behavior). Moreover, it should be able to perform spike timing dependent plasticity (STDP), an associative homosynaptic plasticity learning rule based on the delay time between the two firing neurons the synapse is connected to. This rule is a fundamental learning protocol in state-of-art networks, because it allows unsupervised learning. Notwithstanding this fact, STDP-based unsupervised learning has been proposed several times mainly for binary synapses rather than multilevel synapses composed of many binary memristors. This paper proposes an HfO<sub>2</sub>-based analog memristor as a synaptic element which performs STDP within a small spiking neuromorphic network operating unsupervised learning for character recognition. The trained network is able to recognize five characters even in case incomplete or noisy images are displayed and it is robust to a device-to-device variability of up to ±30%."
https://openalex.org/W3095121901,Unsupervised Learning of Visual Features by Contrasting Cluster Assignments,"{'International': [0], 'audience': [1]}",2020,"['Computer science', 'Unsupervised learning', 'Cluster (spacecraft)', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Operating system']",International audience
https://openalex.org/W2950789693,Building high-level features using large scale unsupervised learning,"{'We': [0, 69, 143], 'consider': [1], 'the': [2, 57, 67, 147, 190], 'problem': [3], 'of': [4, 49, 185], 'building': [5], 'high-level,': [6], 'class-specific': [7], 'feature': [8, 128], 'detectors': [9], 'from': [10, 66, 181], 'only': [11, 25, 133], 'unlabeled': [12, 26], 'data.': [13], 'For': [14], 'example,': [15], 'is': [16, 105, 130, 150], 'it': [17, 104], 'possible': [18, 106], 'to': [19, 91, 94, 107, 114, 134, 138, 152, 172], 'learn': [20], 'a': [21, 33, 46, 80, 96, 109, 119, 183], 'face': [22, 110, 120], 'detector': [23, 111, 129], 'using': [24, 73], 'images?': [27], 'To': [28], 'answer': [29], 'this,': [30], 'we': [31, 168], 'train': [32, 70, 108], '9-layered': [34], 'locally': [35], 'connected': [36], 'sparse': [37], 'autoencoder': [38], 'with': [39, 82, 164], 'pooling': [40], 'and': [41, 76, 140, 160], 'local': [42], 'contrast': [43], 'normalization': [44], 'on': [45, 79], 'large': [47], 'dataset': [48, 58], 'images': [50, 64, 116], '(the': [51], 'model': [52, 74], 'has': [53, 59], '1': [54], 'billion': [55], 'connections,': [56], '10': [60], 'million': [61], '200x200': [62], 'pixel': [63], 'downloaded': [65], 'Internet).': [68], 'this': [71, 127], 'network': [72, 149, 171], 'parallelism': [75], 'asynchronous': [77], 'SGD': [78], 'cluster': [81], '1,000': [83], 'machines': [84], '(16,000': [85], 'cores)': [86], 'for': [87], 'three': [88], 'days.': [89], 'Contrary': [90], 'what': [92], 'appears': [93], 'be': [95], 'widely-held': [97], 'intuition,': [98], 'our': [99, 170], 'experimental': [100], 'results': [101], 'reveal': [102], 'that': [103, 126, 146], 'without': [112], 'having': [113], 'label': [115], 'as': [117, 157], 'containing': [118], 'or': [121], 'not.': [122], 'Control': [123], 'experiments': [124], 'show': [125], 'robust': [131], 'not': [132], 'translation': [135], 'but': [136], 'also': [137, 144], 'scaling': [139], 'out-of-plane': [141], 'rotation.': [142], 'find': [145], 'same': [148], 'sensitive': [151], 'other': [153], 'high-level': [154], 'concepts': [155], 'such': [156], 'cat': [158], 'faces': [159], 'human': [161], 'bodies.': [162], 'Starting': [163], 'these': [165], 'learned': [166], 'features,': [167], 'trained': [169], 'obtain': [173], '15.8%': [174], 'accuracy': [175], 'in': [176], 'recognizing': [177], '20,000': [178], 'object': [179], 'categories': [180], 'ImageNet,': [182], 'leap': [184], '70%': [186], 'relative': [187], 'improvement': [188], 'over': [189], 'previous': [191], 'state-of-the-art.': [192]}",2011,"['Artificial intelligence', 'Computer science', 'Normalization (sociology)', 'Autoencoder', 'Pattern recognition (psychology)', 'Detector', 'Pooling', 'Deep learning', 'Machine learning', 'Computer vision', 'Anthropology', 'Sociology', 'Telecommunications']","We consider the problem of building high-level, class-specific feature detectors from only unlabeled data. For example, is it possible to learn a face detector using only unlabeled images? To answer this, we train a 9-layered locally connected sparse autoencoder with pooling and local contrast normalization on a large dataset of images (the model has 1 billion connections, the dataset has 10 million 200x200 pixel images downloaded from the Internet). We train this network using model parallelism and asynchronous SGD on a cluster with 1,000 machines (16,000 cores) for three days. Contrary to what appears to be a widely-held intuition, our experimental results reveal that it is possible to train a face detector without having to label images as containing a face or not. Control experiments show that this feature detector is robust not only to translation but also to scaling and out-of-plane rotation. We also find that the same network is sensitive to other high-level concepts such as cat faces and human bodies. Starting with these learned features, we trained our network to obtain 15.8% accuracy in recognizing 20,000 object categories from ImageNet, a leap of 70% relative improvement over the previous state-of-the-art."
https://openalex.org/W2337374958,Joint Unsupervised Learning of Deep Representations and Image Clusters,"{'In': [0, 19], 'this': [1, 76], 'paper,': [2], 'we': [3, 114], 'propose': [4], 'a': [5, 25, 33, 43, 101, 105, 141], 'recurrent': [6, 34], 'framework': [7, 77], 'for': [8], 'Joint': [9], 'Unsupervised': [10], 'LEarning': [11], '(JULE)': [12], 'of': [13, 39, 143], 'deep': [14], 'representations': [15, 40, 53, 81, 149], 'and': [16, 52, 87, 110], 'image': [17, 50, 57, 85, 126, 138, 144], 'clusters.': [18, 127], 'our': [20, 132], 'framework,': [21], 'successive': [22], 'operations': [23], 'in': [24, 32, 61, 68], 'clustering': [26, 58, 86, 88, 139], 'algorithm': [27], 'are': [28, 54, 82], 'expressed': [29], 'as': [30], 'steps': [31], 'process,': [35], 'stacked': [36], 'on': [37, 137], 'top': [38], 'output': [41], 'by': [42], 'Convolutional': [44], 'Neural': [45], 'Network': [46], '(CNN).': [47], 'During': [48], 'training,': [49], 'clusters': [51], 'updated': [55], 'jointly:': [56], 'is': [59, 78], 'conducted': [60], 'the': [62, 69, 135, 147], 'forward': [63], 'pass,': [64], 'while': [65], 'representation': [66, 94], 'learning': [67], 'backward': [70], 'pass.': [71], 'Our': [72], 'key': [73], 'idea': [74], 'behind': [75], 'that': [79, 131], 'good': [80], 'beneficial': [83], 'to': [84, 93, 154], 'results': [89], 'provide': [90], 'supervisory': [91], 'signals': [92], 'learning.': [95], 'By': [96], 'integrating': [97], 'two': [98], 'processes': [99], 'into': [100], 'single': [102], 'model': [103], 'with': [104], 'unified': [106], 'weighted': [107], 'triplet': [108], 'loss': [109], 'optimizing': [111], 'it': [112], 'end-to-end,': [113], 'can': [115], 'obtain': [116], 'not': [117], 'only': [118], 'more': [119, 124], 'powerful': [120], 'representations,': [121], 'but': [122], 'also': [123], 'precise': [125], 'Extensive': [128], 'experiments': [129], 'show': [130], 'method': [133], 'outperforms': [134], 'state-of-the-art': [136], 'across': [140], 'variety': [142], 'datasets.': [145], 'Moreover,': [146], 'learned': [148], 'generalize': [150], 'well': [151], 'when': [152], 'transferred': [153], 'other': [155], 'tasks.': [156]}",2016,"['Cluster analysis', 'Computer science', 'Artificial intelligence', 'Image (mathematics)', 'Representation (politics)', 'Feature learning', 'Pattern recognition (psychology)', 'Convolutional neural network', 'Unsupervised learning', 'Deep learning', 'Key (lock)', 'Machine learning', 'Computer security', 'Political science', 'Politics', 'Law']","In this paper, we propose a recurrent framework for Joint Unsupervised LEarning (JULE) of deep representations and image clusters. In our framework, successive operations in a clustering algorithm are expressed as steps in a recurrent process, stacked on top of representations output by a Convolutional Neural Network (CNN). During training, image clusters and representations are updated jointly: image clustering is conducted in the forward pass, while representation learning in the backward pass. Our key idea behind this framework is that good representations are beneficial to image clustering and clustering results provide supervisory signals to representation learning. By integrating two processes into a single model with a unified weighted triplet loss and optimizing it end-to-end, we can obtain not only more powerful representations, but also more precise image clusters. Extensive experiments show that our method outperforms the state-of-the-art on image clustering across a variety of image datasets. Moreover, the learned representations generalize well when transferred to other tasks."
https://openalex.org/W2105000456,Cue Integration With Categories: Weighting Acoustic Cues in Speech Using Unsupervised Learning and Distributional Statistics,"{'Abstract': [0], 'During': [1], 'speech': [2, 53, 136], 'perception,': [3], 'listeners': [4, 29, 36], 'make': [5], 'judgments': [6], 'about': [7], 'the': [8, 49, 74, 106, 120, 135], 'phonological': [9, 22, 99], 'category': [10, 50], 'of': [11, 16, 48, 63, 76, 94, 122], 'sounds': [12], 'by': [13], 'taking': [14], 'advantage': [15], 'multiple': [17], 'acoustic': [18, 40], 'cues': [19, 32, 41, 72, 88], 'for': [20, 51], 'each': [21], 'contrast.': [23], 'Perceptual': [24], 'experiments': [25], 'have': [26], 'shown': [27], 'that': [28, 66, 82, 127], 'weight': [30, 37, 90], 'these': [31, 116], 'differently.': [33], 'How': [34], 'do': [35], 'and': [38, 70], 'combine': [39, 71], 'to': [42, 105], 'arrive': [43], 'at': [44, 97], 'an': [45], 'overall': [46], 'estimate': [47], 'a': [52, 61, 83, 92, 102], 'sound?': [54], 'Here,': [55], 'we': [56], 'present': [57], 'several': [58], 'simulations': [59], 'using': [60], 'mixture': [62], 'Gaussians': [64], 'models': [65], 'learn': [67], 'cue': [68, 128], 'weights': [69, 117, 129], 'on': [73], 'basis': [75], 'their': [77, 95], 'distributional': [78], 'statistics.': [79], 'We': [80], 'show': [81], 'cue‐weighting': [84], 'metric': [85], 'in': [86], 'which': [87], 'receive': [89], 'as': [91], 'function': [93], 'reliability': [96], 'distinguishing': [98], 'categories': [100], 'provides': [101], 'good': [103], 'fit': [104], 'perceptual': [107], 'data': [108], 'obtained': [109], 'from': [110, 134], 'human': [111], 'listeners,': [112], 'but': [113], 'only': [114], 'when': [115], 'emerge': [118], 'through': [119, 138], 'dynamics': [121], 'learning.': [123], 'These': [124], 'results': [125], 'suggest': [126], 'can': [130], 'be': [131], 'readily': [132], 'extracted': [133], 'signal': [137], 'unsupervised': [139], 'learning': [140], 'processes.': [141]}",2010,"['Weighting', 'Perception', 'Speech recognition', 'Contrast (vision)', 'Speech perception', 'Metric (unit)', 'Computer science', 'Psychology', 'Pattern recognition (psychology)', 'Artificial intelligence', 'Operations management', 'Economics', 'Radiology', 'Neuroscience', 'Medicine']","Abstract During speech perception, listeners make judgments about the phonological category of sounds by taking advantage of multiple acoustic cues for each phonological contrast. Perceptual experiments have shown that listeners weight these cues differently. How do listeners weight and combine acoustic cues to arrive at an overall estimate of the category for a speech sound? Here, we present several simulations using a mixture of Gaussians models that learn cue weights and combine cues on the basis of their distributional statistics. We show that a cue‐weighting metric in which cues receive weight as a function of their reliability at distinguishing phonological categories provides a good fit to the perceptual data obtained from human listeners, but only when these weights emerge through the dynamics of learning. These results suggest that cue weights can be readily extracted from the speech signal through unsupervised learning processes."
https://openalex.org/W2134368421,Unsupervised learning of generalized names,"{'We': [0, 78, 88], 'present': [1, 79], 'an': [2], 'algorithm,': [3], 'NOMEN,': [4], 'for': [5], 'learning': [6, 71], 'generalized': [7], 'names': [8, 15, 27, 76], 'in': [9], 'text.': [10], 'Examples': [11], 'of': [12, 16, 39, 48, 53, 57, 65, 72, 75, 81, 94], 'these': [13], 'are': [14], 'diseases': [17], 'and': [18, 24, 56], 'infectious': [19], 'agents,': [20], 'such': [21], 'as': [22], 'bacteria': [23], 'viruses.': [25], 'These': [26], 'exhibit': [28], 'certain': [29], 'properties': [30], 'that': [31, 38], 'make': [32], 'their': [33, 58], 'identification': [34], 'more': [35], 'complex': [36], 'than': [37], 'regular': [40], 'proper': [41], 'names,': [42], 'NOMEN': [43], 'uses': [44], 'a': [45, 85], 'novel': [46], 'form': [47], 'bootstrapping': [49], 'to': [50, 68], 'grow': [51], 'sets': [52], 'textual': [54], 'instances': [55], 'contextual': [59], 'patterns.': [60], 'The': [61], 'algorithm': [62, 83], 'makes': [63], 'use': [64], 'competing': [66], 'evidence': [67], 'boost': [69], 'the': [70, 82, 91], 'several': [73, 95], 'categories': [74], 'simultaneously.': [77], 'results': [80], 'on': [84], 'large': [86], 'corpus.': [87], 'also': [89], 'investigate': [90], 'relative': [92], 'merits': [93], 'evaluation': [96], 'strategies.': [97]}",2002,"['Bootstrapping (finance)', 'Computer science', 'Identification (biology)', 'Artificial intelligence', 'Natural language processing', 'Mathematics', 'Botany', 'Biology', 'Econometrics']","We present an algorithm, NOMEN, for learning generalized names in text. Examples of these are names of diseases and infectious agents, such as bacteria and viruses. These names exhibit certain properties that make their identification more complex than that of regular proper names, NOMEN uses a novel form of bootstrapping to grow sets of textual instances and of their contextual patterns. The algorithm makes use of competing evidence to boost the learning of several categories of names simultaneously. We present results of the algorithm on a large corpus. We also investigate the relative merits of several evaluation strategies."
https://openalex.org/W2758785877,Unsupervised Learning of Disentangled and Interpretable Representations from Sequential Data,"{'We': [0], 'present': [1], 'a': [2, 34], 'factorized': [3, 35], 'hierarchical': [4, 36], 'variational': [5], 'autoencoder,': [6], 'which': [7], 'learns': [8], 'disentangled': [9], 'and': [10, 43, 78, 90], 'interpretable': [11], 'representations': [12], 'from': [13], 'sequential': [14, 27], 'data': [15, 28], 'without': [16], 'supervision.': [17], 'Specifically,': [18], 'we': [19], 'exploit': [20], 'the': [21, 92], 'multi-scale': [22], 'nature': [23], 'of': [24, 49, 75], 'information': [25], 'in': [26, 101], 'by': [29, 71, 96], 'formulating': [30], 'it': [31], 'explicitly': [32], 'within': [33], 'graphical': [37], 'model': [38, 53], 'that': [39], 'imposes': [40], 'sequence-dependent': [41], 'priors': [42, 45], 'sequence-independent': [44], 'to': [46, 60, 65, 82], 'different': [47, 73], 'sets': [48, 74], 'latent': [50, 76], 'variables.': [51], 'The': [52], 'is': [54], 'evaluated': [55], 'on': [56], 'two': [57], 'speech': [58, 107], 'corpora': [59], 'demonstrate,': [61], 'qualitatively,': [62], 'its': [63, 80], 'ability': [64, 81], 'transform': [66], 'speakers': [67], 'or': [68], 'linguistic': [69], 'content': [70], 'manipulating': [72], 'variables;': [77], 'quantitatively,': [79], 'outperform': [83], 'an': [84], 'i-vector': [85], 'baseline': [86], 'for': [87, 105], 'speaker': [88], 'verification': [89], 'reduce': [91], 'word': [93], 'error': [94], 'rate': [95], 'as': [97, 99], 'much': [98], '35%': [100], 'mismatched': [102], 'train/test': [103], 'scenarios': [104], 'automatic': [106], 'recognition': [108], 'tasks.': [109]}",2017,"['Prior probability', 'Computer science', 'Autoencoder', 'Sequence (biology)', 'Artificial intelligence', 'Latent variable', 'Word (group theory)', 'Natural language processing', 'Pattern recognition (psychology)', 'Machine learning', 'Artificial neural network', 'Mathematics', 'Bayesian probability', 'Biology', 'Genetics', 'Geometry']","We present a factorized hierarchical variational autoencoder, which learns disentangled and interpretable representations from sequential data without supervision. Specifically, we exploit the multi-scale nature of information in sequential data by formulating it explicitly within a factorized hierarchical graphical model that imposes sequence-dependent priors and sequence-independent priors to different sets of latent variables. The model is evaluated on two speech corpora to demonstrate, qualitatively, its ability to transform speakers or linguistic content by manipulating different sets of latent variables; and quantitatively, its ability to outperform an i-vector baseline for speaker verification and reduce the word error rate by as much as 35% in mismatched train/test scenarios for automatic speech recognition tasks."
https://openalex.org/W2594132308,Revisiting unsupervised learning for defect prediction,"{'Collecting': [0], 'quality': [1], 'data': [2, 36, 129], 'from': [3, 34], 'software': [4, 98], 'projects': [5], 'can': [6, 52], 'be': [7, 195], 'time-consuming': [8], 'and\\nexpensive.': [9], 'Hence,': [10, 191], 'some': [11, 127, 196], 'researchers': [12, 43], 'explore': [13], '""unsupervised""': [14], 'approaches': [15, 30], 'to': [16, 83, 132, 155, 200, 204, 210], 'quality\\nprediction': [17], 'that': [18, 31, 93], 'does': [19], 'not': [20, 180], 'require': [21], 'labelled': [22, 37], 'data.': [23], 'An': [24], 'alternate': [25], 'technique': [26], 'is': [27, 49, 94, 112, 130], 'to\\nuse': [28], '""supervised""': [29], 'learn': [32], 'models': [33], 'project': [35], 'with,\\nsay,': [38], '""defective""': [39], 'or': [40], '""not-defective"".': [41], 'Most': [42], 'use': [44], 'these': [45, 79], 'supervised\\nmodels': [46], 'since,': [47], 'it': [48], 'argued,': [50], 'they': [51, 192], 'exploit': [53], 'more': [54], 'knowledge': [55], 'of': [56, 86, 117, 165], 'the': [57, 97, 115, 118, 162], 'projects.\\n': [58], 'At': [59], ""FSE'16,"": [60], 'Yang': [61, 119, 166], 'et': [62, 120, 167], 'al.': [63, 121], 'reported': [64], 'startling': [65], 'results': [66, 80, 107], 'where': [67], 'unsupervised': [68, 185], 'defect\\npredictors': [69], 'outperformed': [70], 'supervised': [71, 128, 151, 178, 205], 'predictors': [72, 122, 135, 152], 'for': [73, 187], 'effort-aware': [74], 'just-in-time\\ndefect': [75], 'prediction.': [76, 190], 'If': [77], 'confirmed,': [78], 'would': [81], 'lead': [82], 'a': [84, 87, 148], 'dramatic\\nsimplification': [85], 'seemingly': [88], 'complex': [89], 'task': [90], '(data': [91], 'mining)': [92], 'widely\\nexplored': [95], 'in': [96, 114, 212], 'engineering': [99], 'literature.\\n': [100], 'This': [101], 'paper': [102, 160], 'repeats': [103], 'and': [104], 'refutes': [105], 'those': [106], 'as': [108], 'follows.': [109], '(1)': [110], 'There': [111], 'much\\nvariability': [113], 'efficacy': [116], 'so': [123], 'even': [124], 'with': [125], 'their\\napproach,': [126], 'required': [131], 'prune': [133], 'weaker': [134], 'away.\\n(2)Their': [136], 'findings': [137], 'were': [138], 'grouped': [139], 'across': [140], '$N$': [141], 'projects.': [142], 'When': [143], 'we': [144], 'repeat': [145], 'their\\nanalysis': [146], 'on': [147], 'project-by-project': [149], 'basis,': [150], 'are': [153], 'seen': [154], 'work\\nbetter.\\n': [156], 'Even': [157], 'though': [158], 'this': [159, 213], 'rejects': [161], 'specific': [163], 'conclusions': [164], 'al.,': [168], 'we\\nstill': [169], 'endorse': [170], 'their': [171], 'general': [172], 'goal.': [173], 'In': [174], 'our': [175, 176], 'experiments,': [177], 'predictors\\ndid': [179], 'perform': [181], 'outstandingly': [182], 'better': [183], 'than': [184], 'ones': [186], 'effort-aware\\njust-in-time': [188], 'defect': [189], 'may': [193], 'indeed': [194], 'combination': [197], 'of\\nunsupervised': [198], 'learners': [199], 'achieve': [201], 'comparable': [202], 'performance': [203], 'ones.': [206], 'We\\ntherefore': [207], 'encourage': [208], 'others': [209], 'work': [211], 'promising': [214], 'area.\\n': [215]}",2017,[],"Collecting quality data from software projects can be time-consuming and\nexpensive. Hence, some researchers explore ""unsupervised"" approaches to quality\nprediction that does not require labelled data. An alternate technique is to\nuse ""supervised"" approaches that learn models from project data labelled with,\nsay, ""defective"" or ""not-defective"". Most researchers use these supervised\nmodels since, it is argued, they can exploit more knowledge of the projects.\n At FSE'16, Yang et al. reported startling results where unsupervised defect\npredictors outperformed supervised predictors for effort-aware just-in-time\ndefect prediction. If confirmed, these results would lead to a dramatic\nsimplification of a seemingly complex task (data mining) that is widely\nexplored in the software engineering literature.\n This paper repeats and refutes those results as follows. (1) There is much\nvariability in the efficacy of the Yang et al. predictors so even with their\napproach, some supervised data is required to prune weaker predictors away.\n(2)Their findings were grouped across $N$ projects. When we repeat their\nanalysis on a project-by-project basis, supervised predictors are seen to work\nbetter.\n Even though this paper rejects the specific conclusions of Yang et al., we\nstill endorse their general goal. In our our experiments, supervised predictors\ndid not perform outstandingly better than unsupervised ones for effort-aware\njust-in-time defect prediction. Hence, they may indeed be some combination of\nunsupervised learners to achieve comparable performance to supervised ones. We\ntherefore encourage others to work in this promising area.\n"
https://openalex.org/W2903922555,Almost Unsupervised Learning for Dense Crowd Counting,"{'We': [0], 'present': [1, 156], 'an': [2], 'unsupervised': [3, 142], 'learning': [4], 'method': [5], 'for': [6, 33], 'dense': [7], 'crowd': [8, 40, 82], 'count': [9], 'estimation.': [10], 'Marred': [11], 'by': [12, 64], 'large': [13], 'variability': [14], 'in': [15, 22], 'appearance': [16], 'of': [17, 52, 60, 77, 95, 113, 116, 151, 163], 'people': [18, 25], 'and': [19, 44, 144, 158], 'extreme': [20], 'overlap': [21], 'crowds,': [23], 'enumerating': [24], 'proves': [26], 'to': [27, 73, 107, 140, 148], 'be': [28], 'a': [29, 47, 88, 93], 'difficult': [30], 'task': [31], 'even': [32], 'humans.': [34], 'This': [35], 'implies': [36], 'creating': [37], 'large-scale': [38], 'annotated': [39], 'data': [41, 125], 'is': [42, 105], 'expensive': [43], 'directly': [45], 'takes': [46], 'toll': [48], 'on': [49, 58], 'the': [50, 101, 109, 114, 117, 127, 149, 161], 'performance': [51], 'existing': [53], 'CNN': [54], 'based': [55], 'counting': [56], 'models': [57], 'account': [59], 'small': [61], 'datasets.': [62], 'Motivated': [63], 'these': [65], 'challenges,': [66], 'we': [67, 155], 'develop': [68], 'Grid': [69], 'Winner-Take-All': [70], '(GWTA)': [71], 'autoencoder': [72], 'learn': [74], 'several': [75], 'layers': [76], 'useful': [78], 'filters': [79], 'from': [80], 'unlabeled': [81], 'images.': [83], 'Our': [84], 'GWTA': [85], 'approach': [86], 'divides': [87], 'convolution': [89], 'layer': [90], 'spatially': [91], 'into': [92], 'grid': [94], 'cells.': [96], 'Within': [97], 'each': [98], 'cell,': [99], 'only': [100], 'maximally': [102], 'activated': [103], 'neuron': [104], 'allowed': [106], 'update': [108], 'filter.': [110], 'Almost': [111], '99.9%': [112], 'parameters': [115], 'proposed': [118], 'model': [119, 135], 'are': [120, 130], 'trained': [121], 'without': [122], 'any': [123], 'labeled': [124], 'while': [126], 'rest': [128], '0.1%': [129], 'tuned': [131], 'with': [132], 'supervision.': [133], 'The': [134], 'achieves': [136], 'superior': [137], 'results': [138], 'compared': [139], 'other': [141], 'methods': [143], 'stays': [145], 'reasonably': [146], 'close': [147], 'accuracy': [150], 'supervised': [152], 'baseline.': [153], 'Furthermore,': [154], 'comparisons': [157], 'analyses': [159], 'regarding': [160], 'quality': [162], 'learned': [164], 'features': [165], 'across': [166], 'various': [167], 'models.': [168]}",2019,"['Autoencoder', 'Computer science', 'Crowds', 'Unsupervised learning', 'Artificial intelligence', 'Grid', 'Filter (signal processing)', 'Task (project management)', 'Pattern recognition (psychology)', 'Convolution (computer science)', 'Machine learning', 'Labeled data', 'Deep learning', 'Computer vision', 'Mathematics', 'Artificial neural network', 'Management', 'Geometry', 'Computer security', 'Economics']","We present an unsupervised learning method for dense crowd count estimation. Marred by large variability in appearance of people and extreme overlap in crowds, enumerating people proves to be a difficult task even for humans. This implies creating large-scale annotated crowd data is expensive and directly takes a toll on the performance of existing CNN based counting models on account of small datasets. Motivated by these challenges, we develop Grid Winner-Take-All (GWTA) autoencoder to learn several layers of useful filters from unlabeled crowd images. Our GWTA approach divides a convolution layer spatially into a grid of cells. Within each cell, only the maximally activated neuron is allowed to update the filter. Almost 99.9% of the parameters of the proposed model are trained without any labeled data while the rest 0.1% are tuned with supervision. The model achieves superior results compared to other unsupervised methods and stays reasonably close to the accuracy of supervised baseline. Furthermore, we present comparisons and analyses regarding the quality of learned features across various models."
https://openalex.org/W2946254251,Evaluation Metrics for Unsupervised Learning Algorithms,"{'Determining': [0], 'the': [1, 4, 22, 50, 57, 60, 64], 'quality': [2, 51], 'of': [3, 25, 43, 52, 59], 'results': [5, 54], 'obtained': [6], 'by': [7], 'clustering': [8, 27, 53, 61], 'techniques': [9, 47], 'is': [10], 'a': [11, 39, 41], 'key': [12], 'issue': [13], 'in': [14], 'unsupervised': [15], 'machine': [16], 'learning.': [17], 'Many': [18], 'authors': [19], 'have': [20, 45], 'discussed': [21], 'desirable': [23], 'features': [24], 'good': [26], 'algorithms.': [28], 'However,': [29], 'Jon': [30], 'Kleinberg': [31], 'established': [32], 'an': [33], 'impossibility': [34], 'theorem': [35], 'for': [36], 'clustering.': [37], 'As': [38], 'consequence,': [40], 'wealth': [42], 'studies': [44], 'proposed': [46], 'to': [48, 68], 'evaluate': [49], 'depending': [55], 'on': [56], 'characteristics': [58], 'problem': [62], 'and': [63], 'algorithmic': [65], 'technique': [66], 'employed': [67], 'cluster': [69], 'data.': [70]}",2019,"['Cluster analysis', 'Computer science', 'Conceptual clustering', 'Impossibility', 'Unsupervised learning', 'Artificial intelligence', 'Machine learning', 'Correlation clustering', 'Key (lock)', 'Quality (philosophy)', 'Cluster (spacecraft)', 'Data mining', 'CURE data clustering algorithm', 'Algorithm', 'Computer security', 'Political science', 'Programming language', 'Epistemology', 'Law', 'Philosophy']","Determining the quality of the results obtained by clustering techniques is a key issue in unsupervised machine learning. Many authors have discussed the desirable features of good clustering algorithms. However, Jon Kleinberg established an impossibility theorem for clustering. As a consequence, a wealth of studies have proposed techniques to evaluate the quality of clustering results depending on the characteristics of the clustering problem and the algorithmic technique employed to cluster data."
https://openalex.org/W2461267643,Feuding Families and Former Friends: Unsupervised Learning for Dynamic Fictional Relationships,"{'Mohit': [0], 'Iyyer,': [1], 'Anupam': [2], 'Guha,': [3], 'Snigdha': [4], 'Chaturvedi,': [5], 'Jordan': [6], 'Boyd-Graber,': [7], 'Hal': [8], 'Daumé': [9], 'III.': [10], 'Proceedings': [11], 'of': [12, 16, 21], 'the': [13, 17, 22], '2016': [14], 'Conference': [15], 'North': [18], 'American': [19], 'Chapter': [20], 'Association': [23], 'for': [24], 'Computational': [25], 'Linguistics:': [26], 'Human': [27], 'Language': [28], 'Technologies.': [29], '2016.': [30]}",2016,"['Computer science', 'Natural language processing', 'Linguistics', 'Artificial intelligence', 'Cognitive science', 'Sociology', 'Psychology', 'Philosophy']","Mohit Iyyer, Anupam Guha, Snigdha Chaturvedi, Jordan Boyd-Graber, Hal Daumé III. Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2016."
https://openalex.org/W2047733998,Supervised and unsupervised learning of multidimensional acoustic categories.,"{'Learning': [0, 96], 'to': [1, 40, 102, 148, 165], 'recognize': [2], 'the': [3, 23, 93, 97, 129, 134, 139, 153, 157], 'contrasts': [4], 'of': [5, 25], 'a': [6, 17, 63, 66, 120], 'language-specific': [7], 'phonemic': [8], 'repertoire': [9], 'can': [10], 'be': [11, 103], 'viewed': [12], 'as': [13, 112, 114], 'forming': [14], 'categories': [15, 29, 33, 46, 135], 'in': [16, 88, 156], 'multidimensional': [18, 45, 67, 98, 122], 'psychophysical': [19], 'space.': [20], 'Research': [21], 'on': [22], 'learning': [24, 44, 91, 94], 'distributionally': [26], 'defined': [27, 34, 117], 'visual': [28], 'has': [30], 'shown': [31], 'that': [32, 43, 132, 144], 'over': [35], '1': [36], 'dimension': [37], 'are': [38, 146], 'easy': [39], 'learn': [41], 'and': [42, 83, 107, 152], 'is': [47], 'more': [48, 105], 'difficult': [49, 106], 'but': [50], 'tractable': [51], 'under': [52], 'specific': [53], 'task': [54], 'conditions.': [55], 'In': [56], '2': [57, 167], 'experiments,': [58], 'adult': [59], 'participants': [60], 'learned': [61, 82, 121, 164], 'either': [62], 'unidimensional': [64, 78], 'or': [65, 71], 'category': [68, 90, 99, 123], 'distinction': [69, 100, 124], 'with': [70, 115, 171], 'without': [72], 'supervision': [73, 84, 108], '(feedback)': [74], 'during': [75], 'learning.': [76], 'The': [77], 'distinctions': [79], 'were': [80], 'readily': [81], 'proved': [85, 101], 'beneficial,': [86], 'especially': [87], 'maintaining': [89], 'beyond': [92], 'phase.': [95, 141], 'much': [104], 'was': [109, 125], 'not': [110], 'nearly': [111], 'beneficial': [113], 'unidimensionally': [116], 'categories.': [118], 'Maintaining': [119], 'only': [126], 'possible': [127], 'when': [128], 'distributional': [130, 154], 'information': [131, 155], 'identified': [133], 'remained': [136], 'present': [137], 'throughout': [138], 'testing': [140], 'We': [142], 'conclude': [143], 'listeners': [145, 163], 'sensitive': [147], 'both': [149], 'trial-by-trial': [150], 'feedback': [151], 'stimuli.': [158], 'Even': [159], 'given': [160], 'limited': [161], 'exposure,': [162], 'use': [166], 'relevant': [168], 'dimensions,': [169], 'albeit': [170], 'considerable': [172], 'difficulty.': [173]}",2009,"['Dimension (graph theory)', 'Categorization', 'Cognitive psychology', 'Concept learning', 'Psychology', 'Space (punctuation)', 'Task (project management)', 'Multidimensional analysis', 'Artificial intelligence', 'Computer science', 'Natural language processing', 'Machine learning', 'Mathematics', 'Statistics', 'Pure mathematics', 'Operating system', 'Management', 'Economics']","Learning to recognize the contrasts of a language-specific phonemic repertoire can be viewed as forming categories in a multidimensional psychophysical space. Research on the learning of distributionally defined visual categories has shown that categories defined over 1 dimension are easy to learn and that learning multidimensional categories is more difficult but tractable under specific task conditions. In 2 experiments, adult participants learned either a unidimensional or a multidimensional category distinction with or without supervision (feedback) during learning. The unidimensional distinctions were readily learned and supervision proved beneficial, especially in maintaining category learning beyond the learning phase. Learning the multidimensional category distinction proved to be much more difficult and supervision was not nearly as beneficial as with unidimensionally defined categories. Maintaining a learned multidimensional category distinction was only possible when the distributional information that identified the categories remained present throughout the testing phase. We conclude that listeners are sensitive to both trial-by-trial feedback and the distributional information in the stimuli. Even given limited exposure, listeners learned to use 2 relevant dimensions, albeit with considerable difficulty."
https://openalex.org/W2751471435,A Disentangled Recognition and Nonlinear Dynamics Model for Unsupervised Learning,"{'This': [0], 'paper': [1], 'takes': [2], 'a': [3, 9, 24, 44, 62, 66, 73, 108], 'step': [4], 'towards': [5], 'temporal': [6], 'reasoning': [7], 'in': [8, 14, 23, 35, 118], 'dynamically': [10], 'changing': [11], 'video,': [12], 'not': [13], 'the': [15, 29, 33, 40, 75, 78, 89], 'pixel': [16], 'space': [17, 26], 'that': [18, 27, 52], 'constitutes': [19], 'its': [20, 36, 70], 'frames,': [21], 'but': [22], 'latent': [25, 55, 67], 'describes': [28], 'non-linear': [30], 'dynamics': [31], 'of': [32, 49, 77, 107, 110], 'objects': [34], 'world.': [37], 'We': [38], 'introduce': [39], 'Kalman': [41], 'variational': [42], 'auto-encoder,': [43], 'framework': [45], 'for': [46], 'unsupervised': [47], 'learning': [48], 'sequential': [50], 'data': [51, 85, 122], 'disentangles': [53], 'two': [54], 'representations:': [56], 'an': [57], ""object's"": [58], 'representation,': [59], 'coming': [60], 'from': [61], 'recognition': [63], 'model,': [64], 'and': [65, 83, 114, 120], 'state': [68], 'describing': [69], 'dynamics.': [71], 'As': [72], 'result,': [74], 'evolution': [76], 'world': [79], 'can': [80], 'be': [81], 'imagined': [82], 'missing': [84, 121], 'imputed,': [86], 'both': [87], 'without': [88], 'need': [90], 'to': [91], 'generate': [92], 'high': [93], 'dimensional': [94], 'frames': [95], 'at': [96], 'each': [97], 'time': [98], 'step.': [99], 'The': [100], 'model': [101], 'is': [102], 'trained': [103], 'end-to-end': [104], 'on': [105], 'videos': [106], 'variety': [109], 'simulated': [111], 'physical': [112], 'systems,': [113], 'outperforms': [115], 'competing': [116], 'methods': [117], 'generative': [119], 'imputation': [123], 'tasks.': [124]}",2017,"['Dynamics (music)', 'Nonlinear system', 'Computer science', 'Unsupervised learning', 'Artificial intelligence', 'Psychology', 'Physics', 'Pedagogy', 'Quantum mechanics']","This paper takes a step towards temporal reasoning in a dynamically changing video, not in the pixel space that constitutes its frames, but in a latent space that describes the non-linear dynamics of the objects in its world. We introduce the Kalman variational auto-encoder, a framework for unsupervised learning of sequential data that disentangles two latent representations: an object's representation, coming from a recognition model, and a latent state describing its dynamics. As a result, the evolution of the world can be imagined and missing data imputed, both without the need to generate high dimensional frames at each time step. The model is trained end-to-end on videos of a variety of simulated physical systems, and outperforms competing methods in generative and missing data imputation tasks."
https://openalex.org/W3096925471,The Hidden Pandemic of Family Violence During COVID-19: Unsupervised Learning of Tweets,"{'Background': [0], 'Family': [1], 'violence': [2, 24, 54, 71, 108, 119, 132, 144, 156, 168, 191, 251, 259], '(including': [3], 'intimate': [4], 'partner': [5], 'violence/domestic': [6], 'violence,': [7, 137], 'child': [8, 134], 'abuse,': [9, 135, 159], 'and': [10, 28, 30, 35, 55, 72, 90, 95, 109, 117, 176, 216, 223, 284], 'elder': [11], 'abuse)': [12], 'is': [13, 269], 'a': [14, 46], 'hidden': [15], 'pandemic': [16, 58, 262], 'happening': [17], 'alongside': [18], 'COVID-19.': [19], 'The': [20], 'rates': [21], 'of': [22, 49, 130, 142, 166, 183, 247], 'family': [23, 53, 70, 107, 118, 131, 143, 155, 167, 190, 250, 258], 'are': [25, 32, 252], 'rising': [26, 121], 'fast,': [27], 'women': [29, 182], 'children': [31], 'disproportionately': [33], 'affected': [34], 'vulnerable': [36], 'during': [37, 260], 'this': [38], 'time.': [39], 'Objective': [40], 'This': [41, 234, 268], 'study': [42, 235], 'aims': [43], 'to': [44, 69, 77, 154, 256], 'provide': [45], 'large-scale': [47], 'analysis': [48], 'public': [50], 'discourse': [51], 'on': [52, 59, 106, 244, 249], 'the': [56, 83, 110, 170, 239, 245, 261], 'COVID-19': [57, 73, 111, 116, 248], 'Twitter.': [60], 'Methods': [61], 'We': [62, 81, 99, 254], 'analyzed': [63], 'over': [64], '1': [65], 'million': [66], 'tweets': [67, 105], 'related': [68], 'from': [74, 103], 'April': [75], '12': [76], 'July': [78], '16,': [79], '2020.': [80], 'used': [82], 'machine': [84], 'learning': [85], 'approach': [86], 'Latent': [87], 'Dirichlet': [88], 'Allocation': [89], 'identified': [91], 'salient': [92], 'themes,': [93], 'topics,': [94], 'representative': [96], 'tweets.': [97, 267], 'Results': [98], 'extracted': [100], '9': [101], 'themes': [102], '1,015,874': [104], 'pandemic:': [112], '(1)': [113], 'increased': [114], 'vulnerability:': [115], '(eg,': [120, 133, 145, 157, 169, 192, 204, 218, 228], 'rates,': [122], 'increases': [123], 'in': [124, 238], 'hotline': [125], 'calls,': [126, 206], 'homicide);': [127], '(2)': [128], 'types': [129], 'domestic': [136, 225], 'sexual': [138], 'abuse);': [139], '(3)': [140], 'forms': [141], 'physical': [146], 'aggression,': [147], 'coercive': [148], 'control);': [149], '(4)': [150], 'risk': [151], 'factors': [152], 'linked': [153], 'alcohol': [158], 'financial': [160], 'constraints,': [161], 'guns,': [162], 'quarantine);': [163], '(5)': [164], 'victims': [165, 283], 'LGBTQ': [171], '[lesbian,': [172], 'gay,': [173], 'bisexual,': [174], 'transgender,': [175], 'queer': [177], 'or': [178], 'questioning]': [179], 'community,': [180], 'women,': [181], 'color,': [184], 'children);': [185], '(6)': [186], 'social': [187, 194, 214], 'services': [188], 'for': [189, 271, 282, 289], 'hotlines,': [193], 'workers,': [195], 'confidential': [196], 'services,': [197], 'shelters,': [198], 'funding);': [199], '(7)': [200], 'law': [201], 'enforcement': [202], 'response': [203], '911': [205], 'police': [207], 'arrest,': [208], 'protective': [209], 'orders,': [210], 'abuse': [211], 'reports);': [212], '(8)': [213], 'movements': [215], 'awareness': [217], 'support': [219, 281], 'victims,': [220], 'raise': [221], 'awareness);': [222], '(9)': [224], 'violence–related': [226], 'news': [227], 'Tara': [229], 'Reade,': [230], 'Melissa': [231], 'DeRosa).': [232], 'Conclusions': [233], 'overcomes': [236], 'limitations': [237], 'existing': [240], 'scholarship': [241], 'where': [242], 'data': [243], 'consequences': [246], 'lacking.': [253], 'contribute': [255], 'understanding': [257], 'by': [263], 'providing': [264], 'surveillance': [265], 'via': [266], 'essential': [270], 'identifying': [272], 'potentially': [273], 'useful': [274], 'policy': [275], 'programs': [276], 'that': [277], 'can': [278], 'offer': [279], 'targeted': [280], 'survivors': [285], 'as': [286], 'we': [287], 'prepare': [288], 'future': [290], 'outbreaks.': [291]}",2020,"['Domestic violence', 'Transgender', 'Criminology', 'Poison control', 'Psychiatry', 'Psychology', 'Medicine', 'Suicide prevention', 'Medical emergency', 'Psychoanalysis']","Background Family violence (including intimate partner violence/domestic violence, child abuse, and elder abuse) is a hidden pandemic happening alongside COVID-19. The rates of family violence are rising fast, and women and children are disproportionately affected and vulnerable during this time. Objective This study aims to provide a large-scale analysis of public discourse on family violence and the COVID-19 pandemic on Twitter. Methods We analyzed over 1 million tweets related to family violence and COVID-19 from April 12 to July 16, 2020. We used the machine learning approach Latent Dirichlet Allocation and identified salient themes, topics, and representative tweets. Results We extracted 9 themes from 1,015,874 tweets on family violence and the COVID-19 pandemic: (1) increased vulnerability: COVID-19 and family violence (eg, rising rates, increases in hotline calls, homicide); (2) types of family violence (eg, child abuse, domestic violence, sexual abuse); (3) forms of family violence (eg, physical aggression, coercive control); (4) risk factors linked to family violence (eg, alcohol abuse, financial constraints, guns, quarantine); (5) victims of family violence (eg, the LGBTQ [lesbian, gay, bisexual, transgender, and queer or questioning] community, women, women of color, children); (6) social services for family violence (eg, hotlines, social workers, confidential services, shelters, funding); (7) law enforcement response (eg, 911 calls, police arrest, protective orders, abuse reports); (8) social movements and awareness (eg, support victims, raise awareness); and (9) domestic violence–related news (eg, Tara Reade, Melissa DeRosa). Conclusions This study overcomes limitations in the existing scholarship where data on the consequences of COVID-19 on family violence are lacking. We contribute to understanding family violence during the pandemic by providing surveillance via tweets. This is essential for identifying potentially useful policy programs that can offer targeted support for victims and survivors as we prepare for future outbreaks."
https://openalex.org/W2896377340,Toward an artificial intelligence physicist for unsupervised learning,"{'©': [0], '2019': [1], 'American': [2], 'Physical': [3], 'Society.': [4], 'We': [5, 130], 'investigate': [6], 'opportunities': [7], 'and': [8, 26, 31, 50, 65, 92, 102, 122, 164, 172, 194], 'challenges': [9], 'for': [10, 210], 'improving': [11], 'unsupervised': [12, 150], 'machine': [13], 'learning': [14, 49, 139], 'using': [15, 36], 'four': [16], 'common': [17], 'strategies': [18], 'with': [19, 204], 'a': [20, 44, 77, 93, 114, 142, 178, 183, 211, 217], 'long': [21], 'history': [22], 'in': [23, 68, 87, 113, 216], 'physics:': [24], 'divide': [25], 'conquer,': [27], ""Occam's"": [28], 'razor,': [29], 'unification,': [30], 'lifelong': [32], 'learning.': [33], 'Instead': [34], 'of': [35, 52, 59, 144, 152, 159, 188, 207], 'one': [37], 'model': [38], 'to': [39, 81, 85, 98], 'learn': [40], 'everything,': [41], 'we': [42, 75], 'propose': [43, 76, 124], 'paradigm': [45], 'centered': [46], 'around': [47], 'the': [48, 60, 66, 134], 'manipulation': [51], 'theories,': [53], 'which': [54, 69, 117], 'parsimoniously': [55], 'predict': [56], 'both': [57], 'aspects': [58], 'future': [61], '(from': [62], 'past': [63], 'observations)': [64], 'domain': [67], 'these': [70], 'predictions': [71], 'are': [72, 111], 'accurate.': [73], 'Specifically,': [74], 'generalized': [78], 'mean': [79], 'loss': [80], 'encourage': [82], 'each': [83], 'theory': [84, 196], 'specialize': [86], 'its': [88], 'comparatively': [89], 'advantageous': [90], 'domain,': [91], 'differentiable': [94], 'description': [95], 'length': [96], 'objective': [97], 'downweight': [99], 'bad': [100], 'data': [101], '""snap""': [103], 'learned': [104, 120], 'theories': [105, 121, 125], 'into': [106], 'simple': [107], 'symbolic': [108], 'formulas.': [109], 'Theories': [110], 'stored': [112], '""theory': [115], 'hub,""': [116], 'continuously': [118], 'unifies': [119], 'can': [123], 'when': [126], 'encountering': [127], 'new': [128], 'environments.': [129, 148], 'test': [131], 'our': [132, 167], 'implementation,': [133], 'toy': [135], '""artificial': [136], 'intelligence': [137], 'physicist""': [138], 'agent,': [140], 'on': [141], 'suite': [143], 'increasingly': [145], 'complex': [146], 'physics': [147], 'From': [149], 'observation': [151], 'trajectories': [153], 'through': [154], 'worlds': [155], 'involving': [156], 'random': [157], 'combinations': [158], 'gravity,': [160], 'electromagnetism,': [161], 'harmonic': [162], 'motion,': [163], 'elastic': [165], 'bounces,': [166], 'agent': [168, 200], 'typically': [169, 191], 'learns': [170], 'faster': [171], 'produces': [173], 'mean-squared': [174], 'prediction': [175], 'errors': [176], 'about': [177], 'billion': [179], 'times': [180], 'smaller': [181], 'than': [182], 'standard': [184], 'feedforward': [185], 'neural': [186], 'net': [187], 'comparable': [189], 'complexity,': [190], 'recovering': [192], 'integer': [193], 'rational': [195], 'parameters': [197], 'exactly.': [198], 'Our': [199], 'successfully': [201], 'identifies': [202], 'domains': [203], 'different': [205], 'laws': [206], 'motion': [208], 'also': [209], 'nonlinear': [212], 'chaotic': [213], 'double': [214], 'pendulum': [215], 'piecewise': [218], 'constant': [219], 'force': [220], 'field.': [221]}",2019,"['occam', 'Artificial intelligence', 'Computer science', 'Double pendulum', 'Unsupervised learning', 'Domain (mathematical analysis)', 'Artificial neural network', 'Divide and conquer algorithms', 'Machine learning', 'Mathematics', 'Nonlinear system', 'Algorithm', 'Physics', 'Inverted pendulum', 'Quantum mechanics', 'Programming language', 'Mathematical analysis']","© 2019 American Physical Society. We investigate opportunities and challenges for improving unsupervised machine learning using four common strategies with a long history in physics: divide and conquer, Occam's razor, unification, and lifelong learning. Instead of using one model to learn everything, we propose a paradigm centered around the learning and manipulation of theories, which parsimoniously predict both aspects of the future (from past observations) and the domain in which these predictions are accurate. Specifically, we propose a generalized mean loss to encourage each theory to specialize in its comparatively advantageous domain, and a differentiable description length objective to downweight bad data and ""snap"" learned theories into simple symbolic formulas. Theories are stored in a ""theory hub,"" which continuously unifies learned theories and can propose theories when encountering new environments. We test our implementation, the toy ""artificial intelligence physicist"" learning agent, on a suite of increasingly complex physics environments. From unsupervised observation of trajectories through worlds involving random combinations of gravity, electromagnetism, harmonic motion, and elastic bounces, our agent typically learns faster and produces mean-squared prediction errors about a billion times smaller than a standard feedforward neural net of comparable complexity, typically recovering integer and rational theory parameters exactly. Our agent successfully identifies domains with different laws of motion also for a nonlinear chaotic double pendulum in a piecewise constant force field."
https://openalex.org/W2788857104,Unsupervised Learning of Geometry From Videos With Edge-Aware Depth-Normal Consistency,"{'Learning': [0], 'to': [1, 34, 49, 131, 144, 156], 'reconstruct': [2], 'depths': [3, 46, 89], 'from': [4], 'a': [5, 73, 77, 112], 'single': [6], 'image': [7, 130], 'by': [8, 71], 'watching': [9], 'unlabeled': [10], 'videos': [11], 'via': [12], 'deep': [13], 'convolutional': [14], 'network': [15], '(DCN)': [16], 'is': [17], 'attracting': [18], 'significant': [19], 'attention': [20], 'in': [21], 'recent': [22], 'years,': [23], 'e.g.': [24], '(Zhou': [25], 'et': [26], 'al.': [27], '2017).': [28], 'In': [29], 'this': [30], 'paper,': [31], 'we': [32, 61, 148], 'propose': [33], 'use': [35], 'surface': [36], 'normal': [37, 94, 161], 'representation': [38], 'for': [39], 'unsupervised': [40], 'depth': [41, 114, 159], 'estimation': [42], 'framework.': [43], 'Our': [44], 'estimated': [45, 88, 106], 'are': [47, 122], 'constrained': [48], 'be': [50], 'compatible': [51], 'with': [52, 124], 'predicted': [53], 'normals,': [54, 107], 'yielding': [55], 'more': [56], 'robust': [57], 'geometry': [58], 'results.': [59], 'Specifically,': [60], 'formulate': [62], 'an': [63], 'edge-aware': [64], 'depth-normal': [65], 'consistency': [66], 'term,': [67], 'and': [68, 76, 92, 139, 153, 160, 170, 174], 'solve': [69], 'it': [70], 'constructing': [72], 'depth-to-normal': [74, 85], 'layer': [75, 79, 86, 110], 'normal-to-depth': [78, 109], 'inside': [80, 128], 'of': [81, 126, 136, 186], 'the': [82, 105, 108, 129, 134, 146, 150, 184], 'DCN.': [83], 'The': [84], 'takes': [87], 'as': [90], 'input,': [91], 'computes': [93], 'directions': [95], 'using': [96], 'cross': [97], 'production': [98], 'based': [99], 'on': [100, 166], 'neighboring': [101], 'pixels.': [102], 'Then': [103], 'given': [104], 'outputs': [111], 'regularized': [113], 'map': [115], 'through': [116], 'local': [117], 'planar': [118], 'smoothness.': [119], 'Both': [120], 'layers': [121], 'computed': [123], 'awareness': [125], 'edges': [127], 'help': [132], 'address': [133], 'issue': [135], 'depth/normal': [137], 'discontinuity': [138], 'preserve': [140], 'sharp': [141], 'edges.': [142], 'Finally,': [143], 'train': [145], 'network,': [147], 'apply': [149], 'photometric': [151], 'error': [152], 'gradient': [154], 'smoothness': [155], 'supervise': [157], 'both': [158, 167], 'predictions.': [162], 'We': [163], 'conducted': [164], 'experiments': [165], 'outdoor': [168], '(KITTI)': [169], 'indoor': [171], '(NYUv2)': [172], 'datasets,': [173], 'showed': [175], 'that': [176], 'our': [177, 187], 'algorithm': [178], 'vastly': [179], 'outperforms': [180], 'state-of-the-art,': [181], 'which': [182], 'demonstrates': [183], 'benefits': [185], 'approach.': [188]}",2018,"['Normal', 'Consistency (knowledge bases)', 'Smoothness', 'Artificial intelligence', 'Computer science', 'Discontinuity (linguistics)', 'Enhanced Data Rates for GSM Evolution', 'Image (mathematics)', 'Depth map', 'Pixel', 'Representation (politics)', 'Layer (electronics)', 'Planar', 'Computer vision', 'Geometry', 'Algorithm', 'Mathematics', 'Surface (topology)', 'Mathematical analysis', 'Computer graphics (images)', 'Political science', 'Law', 'Organic chemistry', 'Chemistry', 'Politics']","Learning to reconstruct depths from a single image by watching unlabeled videos via deep convolutional network (DCN) is attracting significant attention in recent years, e.g. (Zhou et al. 2017). In this paper, we propose to use surface normal representation for unsupervised depth estimation framework. Our estimated depths are constrained to be compatible with predicted normals, yielding more robust geometry results. Specifically, we formulate an edge-aware depth-normal consistency term, and solve it by constructing a depth-to-normal layer and a normal-to-depth layer inside of the DCN. The depth-to-normal layer takes estimated depths as input, and computes normal directions using cross production based on neighboring pixels. Then given the estimated normals, the normal-to-depth layer outputs a regularized depth map through local planar smoothness. Both layers are computed with awareness of edges inside the image to help address the issue of depth/normal discontinuity and preserve sharp edges. Finally, to train the network, we apply the photometric error and gradient smoothness to supervise both depth and normal predictions. We conducted experiments on both outdoor (KITTI) and indoor (NYUv2) datasets, and showed that our algorithm vastly outperforms state-of-the-art, which demonstrates the benefits of our approach."
https://openalex.org/W2188492526,Unsupervised Learning Of Sparse Features For Scalable Audio Classification.,"{'[TODO]': [0], 'Add': [1], 'abstract': [2], 'here.': [3]}",2011,"['Computer science', 'Spectrogram', 'Artificial intelligence', 'Classifier (UML)', 'Pattern recognition (psychology)', 'Neural coding', 'Feature extraction', 'Scalability', 'Support vector machine', 'Autoencoder', 'Encoder', 'Feature vector', 'Machine learning', 'Deep learning', 'Database', 'Operating system']",[TODO] Add abstract here.
https://openalex.org/W2117041980,Unsupervised learning of acoustic sub-word units,"{'Accurate': [0], 'unsupervised': [1, 18, 49], 'learning': [2, 19, 50, 109], 'of': [3, 5, 20, 25, 51, 67], 'phonemes': [4], 'a': [6, 26, 55, 82, 92], 'language': [7], 'directly': [8], 'from': [9, 110], 'speech': [10], 'is': [11, 73, 85, 105], 'demonstrated': [12, 106], 'via': [13], 'an': [14, 88], 'algorithm': [15], 'for': [16, 48, 107], 'joint': [17], 'the': [21, 40, 68, 77], 'topology': [22], 'and': [23, 32, 94], 'parameters': [24], 'hidden': [27], 'Markov': [28], 'model': [29], '(HMM);': [30], 'states': [31], 'short': [33], 'state-sequences': [34], 'through': [35], 'this': [36], 'HMM': [37], 'correspond': [38], 'to': [39, 62, 81, 91, 96], 'learnt': [41], 'sub-word': [42], 'units.': [43], 'The': [44], 'algorithm,': [45], 'originally': [46], 'proposed': [47], 'allophonic': [52], 'variations': [53], 'within': [54], 'given': [56], 'phoneme': [57, 102], 'set,': [58], 'has': [59], 'been': [60], 'adapted': [61], 'learn': [63], 'without': [64], 'any': [65], 'knowledge': [66], 'phonemes.': [69], 'An': [70], 'evaluation': [71], 'methodology': [72], 'also': [74], 'proposed,': [75], 'whereby': [76], 'state-sequence': [78], 'that': [79], 'aligns': [80], 'test': [83], 'utterance': [84], 'transduced': [86], 'in': [87], 'automatic': [89], 'manner': [90], 'phoneme-sequence': [93], 'compared': [95], 'its': [97], 'manual': [98], 'transcription.': [99], 'Over': [100], '85%': [101], 'recognition': [103], 'accuracy': [104], 'speaker-dependent': [108], 'fluent,': [111], 'large-vocabulary': [112], 'speech.': [113]}",2008,"['Hidden Markov model', 'Computer science', 'Unsupervised learning', 'Speech recognition', 'Utterance', 'Artificial intelligence', 'Word (group theory)', 'Vocabulary', 'Natural language processing', 'Sequence (biology)', 'Set (abstract data type)', 'Sequence labeling', 'Pattern recognition (psychology)', 'Mathematics', 'Linguistics', 'Biology', 'Geometry', 'Task (project management)', 'Programming language', 'Economics', 'Management', 'Genetics', 'Philosophy']","Accurate unsupervised learning of phonemes of a language directly from speech is demonstrated via an algorithm for joint unsupervised learning of the topology and parameters of a hidden Markov model (HMM); states and short state-sequences through this HMM correspond to the learnt sub-word units. The algorithm, originally proposed for unsupervised learning of allophonic variations within a given phoneme set, has been adapted to learn without any knowledge of the phonemes. An evaluation methodology is also proposed, whereby the state-sequence that aligns to a test utterance is transduced in an automatic manner to a phoneme-sequence and compared to its manual transcription. Over 85% phoneme recognition accuracy is demonstrated for speaker-dependent learning from fluent, large-vocabulary speech."
https://openalex.org/W2987283559,Momentum Contrast for Unsupervised Visual Representation Learning,"{'We': [0], 'present': [1], 'Momentum': [2], 'Contrast': [3], '(MoCo)': [4], 'for': [5], 'unsupervised': [6, 43, 99], 'visual': [7], 'representation': [8, 102], 'learning.': [9, 44], 'From': [10], 'a': [11, 21, 25, 28, 34], 'perspective': [12], 'on': [13, 54, 80], 'contrastive': [14, 42], 'learning': [15, 103], 'as': [16], 'dictionary': [17, 23, 38], 'look-up,': [18], 'we': [19], 'build': [20], 'dynamic': [22], 'with': [24], 'queue': [26], 'and': [27, 36, 84, 100], 'moving-averaged': [29], 'encoder.': [30], 'This': [31, 93], 'enables': [32], 'building': [33], 'large': [35, 91], 'consistent': [37], 'on-the-fly': [39], 'that': [40, 95], 'facilitates': [41], 'MoCo': [45, 63, 69], 'provides': [46], 'competitive': [47], 'results': [48], 'under': [49], 'the': [50, 59, 96], 'common': [51], 'linear': [52], 'protocol': [53], 'ImageNet': [55], 'classification.': [56], 'More': [57], 'importantly,': [58], 'representations': [60], 'learned': [61], 'by': [62, 90], 'transfer': [64], 'well': [65], 'to': [66], 'downstream': [67], 'tasks.': [68, 111], 'can': [70], 'outperform': [71], 'its': [72], 'supervised': [73, 101], 'pre-training': [74], 'counterpart': [75], 'in': [76, 108], '7': [77], 'detection/segmentation': [78], 'tasks': [79], 'PASCAL': [81], 'VOC,': [82], 'COCO,': [83], 'other': [85], 'datasets,': [86], 'sometimes': [87], 'surpassing': [88], 'it': [89], 'margins.': [92], 'suggests': [94], 'gap': [97], 'between': [98], 'has': [104], 'been': [105], 'largely': [106], 'closed': [107], 'many': [109], 'vision': [110]}",2019,"['Pascal (unit)', 'Contrast (vision)', 'Artificial intelligence', 'Computer science', 'Unsupervised learning', 'Segmentation', 'Machine learning', 'Representation (politics)', 'Feature learning', 'Perspective (graphical)', 'Pattern recognition (psychology)', 'Natural language processing', 'Programming language', 'Political science', 'Politics', 'Law']","We present Momentum Contrast (MoCo) for unsupervised visual representation learning. From a perspective on contrastive learning as dictionary look-up, we build a dynamic dictionary with a queue and a moving-averaged encoder. This enables building a large and consistent dictionary on-the-fly that facilitates contrastive unsupervised learning. MoCo provides competitive results under the common linear protocol on ImageNet classification. More importantly, the representations learned by MoCo transfer well to downstream tasks. MoCo can outperform its supervised pre-training counterpart in 7 detection/segmentation tasks on PASCAL VOC, COCO, and other datasets, sometimes surpassing it by large margins. This suggests that the gap between unsupervised and supervised representation learning has been largely closed in many vision tasks."
https://openalex.org/W2469266052,Unsupervised Learning of 3D Structure from Images,"{'A': [0], 'key': [1], 'goal': [2], 'of': [3, 16, 28, 89, 95], 'computer': [4], 'vision': [5], 'is': [6], 'to': [7, 91], 'recover': [8, 32], 'the': [9, 17, 58, 62, 84, 87, 96], 'underlying': [10], '3D': [11, 29, 36, 93], 'structure': [12], 'from': [13, 35, 78], '2D': [14, 38, 79], 'observations': [15], 'world.': [18], 'In': [19], 'this': [20], 'paper': [21], 'we': [22], 'learn': [23], 'strong': [24], 'deep': [25], 'generative': [26], 'models': [27, 69], 'structures,': [30], 'and': [31, 37, 47, 56, 70], 'these': [33, 68], 'structures': [34], 'images': [39], 'via': [40], 'probabilistic': [41], 'inference.': [42], 'We': [43, 64], 'demonstrate': [44], 'high-quality': [45], 'samples': [46], 'report': [48], 'log-likelihoods': [49], 'on': [50], 'several': [51], 'datasets,': [52], 'including': [53], 'ShapeNet': [54], '[2],': [55], 'establish': [57], 'first': [59, 85], 'benchmarks': [60], 'in': [61, 98], 'literature.': [63], 'also': [65], 'show': [66], 'how': [67], 'their': [71], 'inference': [72], 'networks': [73], 'can': [74], 'be': [75], 'trained': [76], 'end-to-end': [77], 'images.': [80], 'This': [81], 'demonstrates': [82], 'for': [83], 'time': [86], 'feasibility': [88], 'learning': [90], 'infer': [92], 'representations': [94], 'world': [97], 'a': [99], 'purely': [100], 'unsupervised': [101], 'manner.': [102]}",2016,"['Inference', 'Computer science', 'Artificial intelligence', 'Generative grammar', 'Probabilistic logic', 'Unsupervised learning', 'Key (lock)', 'Generative model', 'Deep learning', 'Machine learning', 'Pattern recognition (psychology)', '3d model', 'Computer security']","A key goal of computer vision is to recover the underlying 3D structure from 2D observations of the world. In this paper we learn strong deep generative models of 3D structures, and recover these structures from 3D and 2D images via probabilistic inference. We demonstrate high-quality samples and report log-likelihoods on several datasets, including ShapeNet [2], and establish the first benchmarks in the literature. We also show how these models and their inference networks can be trained end-to-end from 2D images. This demonstrates for the first time the feasibility of learning to infer 3D representations of the world in a purely unsupervised manner."
https://openalex.org/W2267038056,Convolutional Clustering for Unsupervised Learning,"{'The': [0], 'task': [1], 'of': [2, 16, 29, 59, 68, 74, 100, 116, 139, 147], 'labeling': [3], 'data': [4, 31], 'for': [5], 'training': [6], 'deep': [7, 51, 102], 'neural': [8, 104], 'networks': [9], 'is': [10], 'daunting': [11], 'and': [12, 77, 143], 'tedious,': [13], 'requiring': [14], 'millions': [15], 'labels': [17], 'to': [18, 48, 109], 'achieve': [19], 'the': [20, 60, 66, 72, 95, 98, 123], 'current': [21], 'state-of-the-art': [22], 'results.': [23], 'Such': [24], 'reliance': [25], 'on': [26, 55, 112, 141, 149], 'large': [27], 'amounts': [28], 'labeled': [30, 117], 'can': [32], 'be': [33, 110], 'relaxed': [34], 'by': [35], 'exploiting': [36], 'hierarchical': [37], 'features': [38], 'via': [39], 'unsupervised': [40], 'learning': [41, 94], 'techniques.': [42], 'In': [43], 'this': [44], 'work,': [45], 'we': [46, 134], 'propose': [47], 'train': [49], 'a': [50, 101, 113, 136, 144], 'convolutional': [52, 87, 103], 'network': [53, 105], 'based': [54], 'an': [56], 'enhanced': [57], 'version': [58], 'k-means': [61, 88], 'clustering': [62], 'algorithm,': [63], 'which': [64], 'reduces': [65], 'number': [67], 'correlated': [69], 'parameters': [70], 'in': [71], 'form': [73], 'similar': [75], 'filters,': [76], 'thus': [78], 'increases': [79], 'test': [80, 137, 145], 'categorization': [81], 'accuracy.': [82], 'We': [83, 90], 'call': [84], 'our': [85], 'algorithm': [86, 125], 'clustering.': [89], 'further': [91], 'show': [92, 121], 'that': [93, 122, 129], 'connection': [96], 'between': [97], 'layers': [99], 'improves': [106], 'its': [107], 'ability': [108], 'trained': [111], 'smaller': [114], 'amount': [115], 'data.': [118], 'Our': [119], 'experiments': [120], 'proposed': [124], 'outperforms': [126], 'other': [127], 'techniques': [128], 'learn': [130], 'filters': [131], 'unsupervised.': [132], 'Specifically,': [133], 'obtained': [135], 'accuracy': [138], '74.1%': [140], 'STL-10': [142], 'error': [146], '0.5%': [148], 'MNIST.': [150]}",2015,"['MNIST database', 'Computer science', 'Artificial intelligence', 'Convolutional neural network', 'Cluster analysis', 'Categorization', 'Unsupervised learning', 'Pattern recognition (psychology)', 'Deep learning', 'Task (project management)', 'Machine learning', 'Test data', 'Programming language', 'Management', 'Economics']","The task of labeling data for training deep neural networks is daunting and tedious, requiring millions of labels to achieve the current state-of-the-art results. Such reliance on large amounts of labeled data can be relaxed by exploiting hierarchical features via unsupervised learning techniques. In this work, we propose to train a deep convolutional network based on an enhanced version of the k-means clustering algorithm, which reduces the number of correlated parameters in the form of similar filters, and thus increases test categorization accuracy. We call our algorithm convolutional k-means clustering. We further show that learning the connection between the layers of a deep convolutional neural network improves its ability to be trained on a smaller amount of labeled data. Our experiments show that the proposed algorithm outperforms other techniques that learn filters unsupervised. Specifically, we obtained a test accuracy of 74.1% on STL-10 and a test error of 0.5% on MNIST."
https://openalex.org/W2739958663,Supervised and Unsupervised Learning Technology in the Study of Rodent Behavior,"{'Quantifying': [0], 'behavior': [1, 15, 89, 95, 111, 133, 173], 'is': [2, 174], 'a': [3, 92, 107, 121], 'challenge': [4], 'for': [5], 'scientists': [6, 36, 60], 'studying': [7], 'neuroscience,': [8], 'ethology,': [9], 'psychology,': [10], 'pathology,': [11], 'etc.': [12], 'Until': [13], 'now,': [14], 'was': [16], 'mostly': [17], 'considered': [18, 139], 'as': [19], 'qualitative': [20], 'descriptions': [21], 'of': [22, 28, 30, 41, 84, 88, 94, 105, 110, 123, 132, 143, 177, 181], 'postures': [23, 40], 'or': [24], 'labor': [25], 'intensive': [26], 'counting': [27], 'bouts': [29], 'individual': [31], 'movements.': [32], 'Many': [33], 'prominent': [34], 'behavioral': [35, 64], 'conducted': [37], 'studies': [38], 'describing': [39], 'mice': [42, 135], 'and': [43, 52, 68, 90, 136, 141, 145, 187], 'rats,': [44], 'depicting': [45], 'step': [46, 48], 'by': [47], 'eating,': [49], 'grooming,': [50], 'courting,': [51], 'other': [53], 'behaviors.': [54], 'Automated': [55], 'video': [56, 130, 159], 'assessment': [57, 131], 'technologies': [58, 124], 'permit': [59], 'to': [61, 112, 115, 170], 'quantify': [62], 'daily': [63], 'patterns/routines,': [65], 'social': [66], 'interactions,': [67], 'postural': [69], 'changes': [70], 'in': [71, 128, 134], 'an': [72], 'unbiased': [73], 'manner.': [74], 'Here,': [75], 'we': [76, 163], 'extensively': [77], 'reviewed': [78], 'published': [79], 'research': [80], 'on': [81, 97, 189], 'the': [82, 85, 98, 103, 150, 166, 175, 179], 'topic': [83], 'structural': [86], 'blocks': [87], 'proposed': [91, 164], 'structure': [93, 109], 'based': [96], 'latest': [99, 151], 'publications.': [100], 'We': [101, 119, 138, 148], 'discuss': [102], 'importance': [104], 'defining': [106], 'clear': [108], 'allow': [113], 'professionals': [114], 'write': [116], 'viable': [117], 'algorithms.': [118], 'presented': [120, 149], 'discussion': [122], 'that': [125, 154, 165], 'are': [126], 'used': [127], 'automated': [129, 158, 167], 'rats.': [137], 'advantages': [140], 'limitations': [142], 'supervised': [144], 'unsupervised': [146], 'learning.': [147], 'scientific': [152], 'discoveries': [153], 'were': [155], 'made': [156], 'using': [157], 'assessment.': [160], 'In': [161], 'conclusion,': [162], 'quantitative': [168], 'approach': [169], 'evaluating': [171], 'animal': [172], 'future': [176], 'understanding': [178], 'effect': [180], 'brain': [182], 'signaling,': [183], 'pathologies,': [184], 'genetic': [185], 'content,': [186], 'environment': [188], 'behavior.': [190]}",2017,"['Ethology', 'Animal behavior', 'Psychology', 'Behavioral neuroscience', 'Artificial intelligence', 'Behavioural sciences', 'Computer science', 'Cognitive psychology', 'Data science', 'Cognitive science', 'Neuroscience', 'Ecology', 'Biology', 'Psychotherapist', 'Zoology']","Quantifying behavior is a challenge for scientists studying neuroscience, ethology, psychology, pathology, etc. Until now, behavior was mostly considered as qualitative descriptions of postures or labor intensive counting of bouts of individual movements. Many prominent behavioral scientists conducted studies describing postures of mice and rats, depicting step by step eating, grooming, courting, and other behaviors. Automated video assessment technologies permit scientists to quantify daily behavioral patterns/routines, social interactions, and postural changes in an unbiased manner. Here, we extensively reviewed published research on the topic of the structural blocks of behavior and proposed a structure of behavior based on the latest publications. We discuss the importance of defining a clear structure of behavior to allow professionals to write viable algorithms. We presented a discussion of technologies that are used in automated video assessment of behavior in mice and rats. We considered advantages and limitations of supervised and unsupervised learning. We presented the latest scientific discoveries that were made using automated video assessment. In conclusion, we proposed that the automated quantitative approach to evaluating animal behavior is the future of understanding the effect of brain signaling, pathologies, genetic content, and environment on behavior."
https://openalex.org/W3093010610,Deep Variational Bayes Filters: Unsupervised Learning of State Space\n Models from Raw Data,"{'We': [0], 'introduce': [1], 'Deep': [2], 'Variational': [3, 25], 'Bayes': [4], 'Filters': [5], '(DVBF),': [6], 'a': [7], 'new': [8], 'method': [9], 'for\\nunsupervised': [10], 'learning': [11], 'and': [12, 63], 'identification': [13], 'of': [14, 68], 'latent': [15], 'Markovian': [16], 'state': [17], 'space\\nmodels.': [18], 'Leveraging': [19], 'recent': [20], 'advances': [21], 'in': [22], 'Stochastic': [23], 'Gradient': [24], 'Bayes,\\nDVBF': [26], 'can': [27, 36], 'overcome': [28], 'intractable': [29], 'inference': [30], 'distributions': [31], 'via': [32], 'variational\\ninference.': [33], 'Thus,': [34], 'it': [35], 'handle': [37], 'highly': [38], 'nonlinear': [39], 'input': [40], 'data': [41], 'with': [42], 'temporal': [43], 'and\\nspatial': [44], 'dependencies': [45], 'such': [46], 'as': [47], 'image': [48], 'sequences': [49], 'without': [50], 'domain': [51], 'knowledge.': [52], 'Our\\nexperiments': [53], 'show': [54], 'that': [55], 'enabling': [56], 'backpropagation': [57], 'through': [58], 'transitions': [59], 'enforces\\nstate': [60], 'space': [61], 'assumptions': [62], 'significantly': [64], 'improves': [65], 'information': [66], 'content': [67], 'the\\nlatent': [69], 'embedding.': [70], 'This': [71], 'also': [72], 'enables': [73], 'realistic': [74], 'long-term': [75], 'prediction.\\n': [76]}",2016,"['Inference', ""Bayes' theorem"", 'Computer science', 'Artificial intelligence', 'Embedding', 'Bayesian inference', 'Backpropagation', 'Machine learning', 'Algorithm', 'Pattern recognition (psychology)', 'Artificial neural network', 'Bayesian probability']","We introduce Deep Variational Bayes Filters (DVBF), a new method for\nunsupervised learning and identification of latent Markovian state space\nmodels. Leveraging recent advances in Stochastic Gradient Variational Bayes,\nDVBF can overcome intractable inference distributions via variational\ninference. Thus, it can handle highly nonlinear input data with temporal and\nspatial dependencies such as image sequences without domain knowledge. Our\nexperiments show that enabling backpropagation through transitions enforces\nstate space assumptions and significantly improves information content of the\nlatent embedding. This also enables realistic long-term prediction.\n"
https://openalex.org/W2794387644,"GeoNet: Unsupervised Learning of Dense Depth, Optical Flow and Camera Pose","{'We': [0], 'propose': [1, 68], 'GeoNet,': [2], 'a': [3], 'jointly': [4, 30], 'unsupervised': [5, 112], 'learning': [6], 'framework': [7, 34], 'for': [8], 'monocular': [9], 'depth,': [10], 'optical': [11], 'flow': [12], 'and': [13, 50, 61, 79, 85, 114], 'ego-motion': [14], 'estimation': [15], 'from': [16], 'videos.': [17], 'The': [18], 'three': [19, 106], 'components': [20], 'are': [21, 42], 'coupled': [22], 'by': [23, 32], 'the': [24, 45, 91, 105], 'nature': [25], 'of': [26, 47, 104], '3D': [27], 'scene': [28, 63], 'geometry,': [29], 'learned': [31], 'our': [33, 97], 'in': [35, 102], 'an': [36, 54, 69], 'end-to-end': [37], 'manner.': [38], 'Specifically,': [39], 'geometric': [40, 71], 'relationships': [41], 'extracted': [43], 'over': [44], 'predictions': [46], 'individual': [48], 'modules': [49], 'then': [51], 'combined': [52], 'as': [53], 'image': [55], 'reconstruction': [56], 'loss,': [57], 'reasoning': [58], 'about': [59], 'static': [60], 'dynamic': [62], 'parts': [64], 'separately.': [65], 'Furthermore,': [66], 'we': [67], 'adaptive': [70], 'consistency': [72], 'loss': [73], 'to': [74], 'increase': [75], 'robustness': [76], 'towards': [77], 'outliers': [78], 'non-Lambertian': [80], 'regions,': [81], 'which': [82], 'resolves': [83], 'occlusions': [84], 'texture': [86], 'ambiguities': [87], 'effectively.': [88], 'Experimentation': [89], 'on': [90], 'KITTI': [92], 'driving': [93], 'dataset': [94], 'reveals': [95], 'that': [96], 'scheme': [98], 'achieves': [99], 'state-of-the-art': [100], 'results': [101], 'all': [103], 'tasks,': [107], 'performing': [108], 'better': [109], 'than': [110], 'previously': [111], 'methods': [113], 'comparably': [115], 'with': [116], 'supervised': [117], 'ones.': [118]}",2018,"['Artificial intelligence', 'Robustness (evolution)', 'Computer science', 'Outlier', 'Optical flow', 'Computer vision', 'Unsupervised learning', 'Monocular', 'Consistency (knowledge bases)', 'View synthesis', 'Pattern recognition (psychology)', 'Image (mathematics)', 'Gene', 'Chemistry', 'Biochemistry', 'Rendering (computer graphics)']","We propose GeoNet, a jointly unsupervised learning framework for monocular depth, optical flow and ego-motion estimation from videos. The three components are coupled by the nature of 3D scene geometry, jointly learned by our framework in an end-to-end manner. Specifically, geometric relationships are extracted over the predictions of individual modules and then combined as an image reconstruction loss, reasoning about static and dynamic scene parts separately. Furthermore, we propose an adaptive geometric consistency loss to increase robustness towards outliers and non-Lambertian regions, which resolves occlusions and texture ambiguities effectively. Experimentation on the KITTI driving dataset reveals that our scheme achieves state-of-the-art results in all of the three tasks, performing better than previously unsupervised methods and comparably with supervised ones."
https://openalex.org/W2528605693,Firms' knowledge profiles: Mapping patent data with unsupervised learning,"{'Patent': [0], 'data': [1, 31], 'has': [2], 'been': [3], 'an': [4, 107], 'obvious': [5], 'choice': [6], 'for': [7, 207, 213], 'analysis': [8, 22, 32, 63], 'leading': [9, 66], 'to': [10, 53, 105, 116, 144, 179], 'strategic': [11, 214], 'technology': [12, 147, 186], 'intelligence,': [13], 'yet,': [14], 'the': [15, 26, 39, 65, 95, 113, 133, 136, 155, 164, 173, 196], 'recent': [16], 'proliferation': [17], 'of': [18, 28, 43, 59, 64, 110, 135, 139, 157, 172, 176, 198], 'machine': [19, 44, 200], 'learning': [20, 45, 61, 97, 201], 'text': [21], 'methods': [23, 33], 'is': [24], 'changing': [25], 'status': [27, 175], 'traditional': [29], 'patent': [30, 50, 180], 'and': [34, 41, 52, 71, 90, 103, 115, 159, 188], 'approaches.': [35, 202], 'This': [36], 'article': [37], 'discusses': [38], 'benefits': [40], 'constraints': [42], 'approaches': [46, 178, 190], 'in': [47, 125, 163, 195, 211, 216], 'industry': [48, 140], 'level': [49], 'analysis,': [51], 'this': [54], 'end': [55], 'offers': [56], 'a': [57, 170], 'demonstration': [58], 'unsupervised': [60, 96], 'based': [62, 73], 'telecommunication': [67, 165], 'firms': [68], 'between': [69], '2001': [70], '2014': [72], 'on': [74, 154, 192], 'about': [75], '160,000': [76], 'USPTO': [77], 'full-text': [78, 84], 'patents.': [79], 'Data': [80], 'were': [81, 99], 'classified': [82], 'using': [83], 'descriptions': [85], 'with': [86], 'Latent': [87], 'Dirichlet': [88], 'Allocation,': [89], 'latent': [91], 'patterns': [92], 'emerging': [93, 158], 'through': [94], 'process': [98], 'modelled': [100], 'by': [101], 'company': [102], 'year': [104], 'create': [106], 'overall': [108], 'view': [109], 'patenting': [111], 'within': [112], 'industry,': [114], 'forecast': [117], 'future': [118], 'trends.': [119], 'Our': [120, 167], 'results': [121, 150, 168], 'demonstrate': [122], 'company-specific': [123], 'differences': [124], 'their': [126], 'knowledge': [127, 137, 161], 'profiles,': [128], 'as': [129, 131, 183], 'well': [130], 'show': [132], 'evolution': [134], 'profiles': [138], 'leaders': [141], 'from': [142], 'hardware': [143], 'software': [145], 'focussed': [146], 'strategies.': [148], 'The': [149], 'cast': [151], 'also': [152], 'light': [153], 'dynamics': [156], 'declining': [160], 'areas': [162], 'industry.': [166], 'prompt': [169], 'consideration': [171], 'current': [174], 'established': [177], 'landscaping,': [181], 'such': [182], 'key-word': [184], 'or': [185], 'classifications': [187], 'other': [189], 'relying': [191], 'semantic': [193], 'labelling,': [194], 'context': [197], 'novel': [199], 'Finally,': [203], 'we': [204], 'discuss': [205], 'implications': [206], 'policy': [208], 'makers,': [209], 'and,': [210], 'particular,': [212], 'management': [215], 'firms.': [217]}",2016,"['Latent Dirichlet allocation', 'Computer science', 'Context (archaeology)', 'Topic model', 'Data science', 'Unsupervised learning', 'Patent analysis', 'Process (computing)', 'Artificial intelligence', 'Knowledge management', 'Hierarchical Dirichlet process', 'Machine learning', 'Strategic management', 'Interpretability', 'Business', 'Marketing', 'Biology', 'Paleontology', 'Operating system']","Patent data has been an obvious choice for analysis leading to strategic technology intelligence, yet, the recent proliferation of machine learning text analysis methods is changing the status of traditional patent data analysis methods and approaches. This article discusses the benefits and constraints of machine learning approaches in industry level patent analysis, and to this end offers a demonstration of unsupervised learning based analysis of the leading telecommunication firms between 2001 and 2014 based on about 160,000 USPTO full-text patents. Data were classified using full-text descriptions with Latent Dirichlet Allocation, and latent patterns emerging through the unsupervised learning process were modelled by company and year to create an overall view of patenting within the industry, and to forecast future trends. Our results demonstrate company-specific differences in their knowledge profiles, as well as show the evolution of the knowledge profiles of industry leaders from hardware to software focussed technology strategies. The results cast also light on the dynamics of emerging and declining knowledge areas in the telecommunication industry. Our results prompt a consideration of the current status of established approaches to patent landscaping, such as key-word or technology classifications and other approaches relying on semantic labelling, in the context of novel machine learning approaches. Finally, we discuss implications for policy makers, and, in particular, for strategic management in firms."
https://openalex.org/W1920845339,Map of science with topic modeling: Comparison of unsupervised learning and human‐assigned subject classification,"{'The': [0], 'delineation': [1], 'of': [2, 9, 16, 30, 44, 70, 84, 116, 131, 157, 169, 178], 'coordinates': [3], 'is': [4, 141], 'fundamental': [5], 'for': [6, 65, 92], 'the': [7, 40, 107, 167, 175], 'cartography': [8], 'science,': [10], 'and': [11, 13, 38, 42, 58, 87, 127, 163], 'accurate': [12], 'credible': [14], 'classification': [15, 68, 98, 103], 'scientific': [17, 71, 85, 161], 'knowledge': [18, 80], 'presents': [19], 'a': [20, 28, 129, 152], 'persistent': [21], 'challenge': [22], 'in': [23, 100, 155], 'this': [24, 45], 'regard.': [25], 'We': [26, 53], 'present': [27], 'map': [29], 'F': [31], 'innish': [32], 'science': [33], 'based': [34], 'on': [35, 174], 'unsupervised‐learning': [36], 'classification,': [37], 'discuss': [39], 'advantages': [41], 'disadvantages': [43], 'approach': [46, 154, 171], 'vis‐à‐vis': [47], 'those': [48], 'generated': [49], 'by': [50], 'human': [51, 66], 'reasoning.': [52], 'conclude': [54], 'that': [55, 139, 166], 'from': [56, 106], 'theoretical': [57], 'practical': [59, 176], 'perspectives': [60], 'there': [61], 'exist': [62], 'several': [63], 'challenges': [64], 'reasoning‐based': [67], 'frameworks': [69], 'knowledge,': [72, 86, 162], 'as': [73], 'they': [74], 'typically': [75], 'try': [76], 'to': [77, 122, 146, 159], 'fit': [78], 'new‐to‐the‐world': [79], 'into': [81], 'historical': [82], 'models': [83, 104], 'cannot': [88], 'easily': [89], 'be': [90], 'deployed': [91], 'new': [93], 'large‐scale': [94, 124], 'data': [95, 125], 'sets.': [96], 'Automated': [97], 'schemes,': [99], 'contrast,': [101], 'generate': [102], 'only': [105], 'available': [108], 'text': [109], 'corpus,': [110], 'thereby': [111], 'identifying': [112], 'credibly': [113], 'novel': [114], 'bodies': [115], 'knowledge.': [117], 'They': [118], 'also': [119, 137], 'lend': [120], 'themselves': [121], 'versatile': [123], 'analysis,': [126], 'enable': [128], 'range': [130], 'Big': [132], 'Data': [133], 'possibilities.': [134], 'However,': [135], 'we': [136, 164], 'argue': [138], 'it': [140], 'neither': [142], 'possible': [143], 'nor': [144], 'fruitful': [145], 'declare': [147], 'one': [148], 'or': [149], 'another': [150], 'method': [151], 'superior': [153], 'terms': [156], 'realism': [158], 'classify': [160], 'believe': [165], 'merits': [168], 'each': [170], 'are': [172], 'dependent': [173], 'objectives': [177], 'analysis.': [179]}",2015,"['Computer science', 'Subject (documents)', 'Data science', 'Artificial intelligence', 'Scale (ratio)', 'Range (aeronautics)', 'Big data', 'Sociology of scientific knowledge', 'Machine learning', 'Data mining', 'Epistemology', 'Library science', 'Philosophy', 'Physics', 'Composite material', 'Materials science', 'Quantum mechanics']","The delineation of coordinates is fundamental for the cartography of science, and accurate and credible classification of scientific knowledge presents a persistent challenge in this regard. We present a map of F innish science based on unsupervised‐learning classification, and discuss the advantages and disadvantages of this approach vis‐à‐vis those generated by human reasoning. We conclude that from theoretical and practical perspectives there exist several challenges for human reasoning‐based classification frameworks of scientific knowledge, as they typically try to fit new‐to‐the‐world knowledge into historical models of scientific knowledge, and cannot easily be deployed for new large‐scale data sets. Automated classification schemes, in contrast, generate classification models only from the available text corpus, thereby identifying credibly novel bodies of knowledge. They also lend themselves to versatile large‐scale data analysis, and enable a range of Big Data possibilities. However, we also argue that it is neither possible nor fruitful to declare one or another method a superior approach in terms of realism to classify scientific knowledge, and we believe that the merits of each approach are dependent on the practical objectives of analysis."
https://openalex.org/W2890967717,Unsupervised Learning of Object Landmarks through Conditional Image Generation,"{'We': [0, 25, 136, 161], 'propose': [1], 'a': [2, 19, 44, 57, 67, 83, 129, 170], 'method': [3, 166], 'for': [4, 8], 'learning': [5], 'landmark': [6, 159], 'detectors': [7], 'visual': [9], 'objects': [10], '(such': [11], 'as': [12, 28, 41, 54], 'the': [13, 16, 29, 36, 39, 49, 52, 62, 87, 125], 'eyes': [14], 'and': [15, 79, 92, 116, 118, 180], 'nose': [17], 'in': [18, 43, 56, 86], 'face)': [20], 'without': [21, 152, 183], 'any': [22, 184], 'manual': [23, 153], 'supervision.': [24], 'cast': [26], 'this': [27], 'problem': [30], 'of': [31, 38, 51, 173], 'generating': [32], 'images': [33], 'that': [34, 90, 127, 138, 164], 'combine': [35], 'appearance': [37, 78, 115], 'object': [40, 53, 72, 143], 'seen': [42, 55], 'first': [45], 'example': [46, 59], 'image': [47, 99, 147], 'with': [48], 'geometry': [50, 117], 'second': [58], 'image,': [60], 'where': [61], 'two': [63], 'examples': [64], 'differ': [65], 'by': [66], 'viewpoint': [68], 'change': [69], 'and/or': [70], 'an': [71], 'deformation.': [73], 'In': [74], 'order': [75], 'to': [76, 97, 124, 169], 'factorize': [77], 'geometry,': [80], 'we': [81], 'introduce': [82], 'tight': [84], 'bottleneck': [85], 'geometry-extraction': [88], 'process': [89], 'selects': [91], 'distils': [93], 'geometry-related': [94], 'features.': [95], 'Compared': [96], 'standard': [98], 'generation': [100, 109], 'problems,': [101], 'which': [102], 'often': [103], 'use': [104], 'generative': [105], 'adversarial': [106], 'networks,': [107], 'our': [108, 139, 165], 'task': [110], 'is': [111, 120, 134, 167], 'conditioned': [112], 'on': [113], 'both': [114], 'thus': [119], 'significantly': [121], 'less': [122], 'ambiguous,': [123], 'point': [126], 'adopting': [128], 'simple': [130], 'perceptual': [131], 'loss': [132], 'formulation': [133], 'sufficient.': [135], 'demonstrate': [137], 'approach': [140], 'can': [141], 'learn': [142], 'landmarks': [144], 'from': [145], 'synthetic': [146], 'deformations': [148], 'or': [149], 'videos,': [150], 'all': [151], 'supervision,': [154], 'while': [155], 'outperforming': [156], 'state-of-the-art': [157], 'unsupervised': [158], 'detectors.': [160], 'further': [162], 'show': [163], 'applicable': [168], 'large': [171], 'variety': [172], 'datasets': [174], '-': [175, 182], 'faces,': [176], 'people,': [177], '3D': [178], 'objects,': [179], 'digits': [181], 'modifications.': [185]}",2018,"['Artificial intelligence', 'Computer science', 'Landmark', 'Computer vision', 'Object (grammar)', 'Face (sociological concept)', 'Object detection', 'Generative model', 'Point cloud', 'Image (mathematics)', 'Pattern recognition (psychology)', 'Generative grammar', 'Social science', 'Sociology']","We propose a method for learning landmark detectors for visual objects (such as the eyes and the nose in a face) without any manual supervision. We cast this as the problem of generating images that combine the appearance of the object as seen in a first example image with the geometry of the object as seen in a second example image, where the two examples differ by a viewpoint change and/or an object deformation. In order to factorize appearance and geometry, we introduce a tight bottleneck in the geometry-extraction process that selects and distils geometry-related features. Compared to standard image generation problems, which often use generative adversarial networks, our generation task is conditioned on both appearance and geometry and thus is significantly less ambiguous, to the point that adopting a simple perceptual loss formulation is sufficient. We demonstrate that our approach can learn object landmarks from synthetic image deformations or videos, all without manual supervision, while outperforming state-of-the-art unsupervised landmark detectors. We further show that our method is applicable to a large variety of datasets - faces, people, 3D objects, and digits - without any modifications."
https://openalex.org/W1616871572,Unsupervised learning of morphology without morphemes,"{'The': [0], 'first': [1], 'morphological': [2], 'learner': [3], 'based': [4], 'upon': [5], 'the': [6], 'theory': [7], 'of': [8], 'Whole': [9], 'Word': [10], 'Morphology': [11], '(Ford': [12], 'et': [13], 'al.,': [14], '1997)': [15], 'is': [16], 'outlined,': [17], 'and': [18], 'preliminary': [19], 'evaluation': [20], 'results': [21], 'are': [22], 'presented.': [23]}",2002,"['Morpheme', 'Lexicon', 'Computer science', 'Natural language processing', 'Artificial intelligence', 'Word (group theory)', 'Morphology (biology)', 'Word formation', 'Linguistics', 'Biology', 'Philosophy', 'Genetics']","The first morphological learner based upon the theory of Whole Word Morphology (Ford et al., 1997) is outlined, and preliminary evaluation results are presented."
https://openalex.org/W2767981409,Unsupervised Learning of Geometry with Edge-aware Depth-Normal Consistency,"{'Learning': [0], 'to': [1, 43, 125, 138], 'reconstruct': [2], 'depths': [3, 40, 83], 'in': [4, 21], 'a': [5, 29, 67, 71, 106], 'single': [6], 'image': [7, 124], 'by': [8, 65], 'watching': [9], 'unlabeled': [10], 'videos': [11], 'via': [12], 'deep': [13], 'convolutional': [14], 'network': [15], '(DCN)': [16], 'is': [17], 'attracting': [18], 'significant': [19], 'attention': [20], 'recent': [22], 'years.': [23], 'In': [24], 'this': [25], 'paper,': [26], 'we': [27, 55, 142], 'introduce': [28], 'surface': [30], 'normal': [31, 88, 154], 'representation': [32], 'for': [33, 150], 'unsupervised': [34], 'depth': [35, 108, 152], 'estimation': [36], 'framework.': [37], 'Our': [38], 'estimated': [39, 82, 100], 'are': [41, 116], 'constrained': [42], 'be': [44], 'compatible': [45], 'with': [46, 118], 'predicted': [47], 'normals,': [48, 101], 'yielding': [49], 'more': [50], 'robust': [51], 'geometry': [52], 'results.': [53], 'Specifically,': [54], 'formulate': [56], 'an': [57], 'edge-aware': [58], 'depth-normal': [59], 'consistency': [60], 'term,': [61], 'and': [62, 70, 86, 133, 147, 153, 163, 167], 'solve': [63], 'it': [64], 'constructing': [66], 'depth-to-normal': [68, 79], 'layer': [69, 73, 80, 104], 'normal-to-depth': [72, 103], 'inside': [74, 122], 'of': [75, 120, 130, 175], 'the': [76, 99, 102, 123, 128, 140, 144, 176, 180], 'DCN.': [77], 'The': [78], 'takes': [81], 'as': [84], 'input,': [85], 'computes': [87], 'directions': [89], 'using': [90], 'cross': [91], 'production': [92], 'based': [93], 'on': [94, 159], 'neighboring': [95], 'pixels.': [96], 'Then': [97], 'given': [98], 'outputs': [105], 'regularized': [107], 'map': [109], 'through': [110], 'local': [111], 'planar': [112], 'smoothness.': [113], 'Both': [114], 'layers': [115], 'computed': [117], 'awareness': [119], 'edges': [121], 'help': [126], 'address': [127], 'issue': [129], 'depth/normal': [131], 'discontinuity': [132], 'preserve': [134], 'sharp': [135], 'edges.': [136], 'Finally,': [137], 'train': [139], 'network,': [141], 'apply': [143], 'photometric': [145], 'error': [146], 'gradient': [148], 'smoothness': [149], 'both': [151, 160], 'predictions.': [155], 'We': [156], 'conducted': [157], 'experiments': [158], 'outdoor': [161], '(KITTI)': [162], 'indoor': [164], '(NYUv2)': [165], 'datasets,': [166], 'show': [168], 'that': [169], 'our': [170, 183], 'algorithm': [171], 'vastly': [172], 'outperforms': [173], 'state': [174], 'art,': [177], 'which': [178], 'demonstrates': [179], 'benefits': [181], 'from': [182], 'approach.': [184]}",2017,"['Normal', 'Consistency (knowledge bases)', 'Smoothness', 'Discontinuity (linguistics)', 'Computer science', 'Enhanced Data Rates for GSM Evolution', 'Artificial intelligence', 'Image (mathematics)', 'Pixel', 'Representation (politics)', 'Layer (electronics)', 'Depth map', 'Geometry', 'Algorithm', 'Surface (topology)', 'Mathematics', 'Computer vision', 'Mathematical analysis', 'Chemistry', 'Organic chemistry', 'Law', 'Political science', 'Politics']","Learning to reconstruct depths in a single image by watching unlabeled videos via deep convolutional network (DCN) is attracting significant attention in recent years. In this paper, we introduce a surface normal representation for unsupervised depth estimation framework. Our estimated depths are constrained to be compatible with predicted normals, yielding more robust geometry results. Specifically, we formulate an edge-aware depth-normal consistency term, and solve it by constructing a depth-to-normal layer and a normal-to-depth layer inside of the DCN. The depth-to-normal layer takes estimated depths as input, and computes normal directions using cross production based on neighboring pixels. Then given the estimated normals, the normal-to-depth layer outputs a regularized depth map through local planar smoothness. Both layers are computed with awareness of edges inside the image to help address the issue of depth/normal discontinuity and preserve sharp edges. Finally, to train the network, we apply the photometric error and gradient smoothness for both depth and normal predictions. We conducted experiments on both outdoor (KITTI) and indoor (NYUv2) datasets, and show that our algorithm vastly outperforms state of the art, which demonstrates the benefits from our approach."
https://openalex.org/W1988951376,Online Adaptation of a c-VEP Brain-Computer Interface(BCI) Based on Error-Related Potentials and Unsupervised Learning,"{'The': [0], 'goal': [1], 'of': [2, 45, 63, 76, 92, 111, 139, 149, 164, 173], 'a': [3, 10, 38, 70, 123, 127, 154, 162], 'Brain-Computer': [4], 'Interface': [5], '(BCI)': [6], 'is': [7, 115, 176], 'to': [8, 29, 48, 105, 134], 'control': [9], 'computer': [11], 'by': [12], 'pure': [13], 'brain': [14], 'activity.': [15], 'Recently,': [16], 'BCIs': [17], 'based': [18, 98, 169], 'on': [19, 99, 170], 'code-modulated': [20], 'visual': [21], 'evoked': [22], 'potentials': [23, 175], '(c-VEPs)': [24], 'have': [25], 'shown': [26], 'great': [27], 'potential': [28], 'establish': [30], 'high-performance': [31], 'communication.': [32], 'In': [33, 126, 157], 'this': [34], 'paper': [35], 'we': [36, 159], 'present': [37], 'c-VEP': [39], 'BCI': [40, 151, 166], 'that': [41, 72, 161], 'uses': [42, 73], 'online': [43, 61, 85], 'adaptation': [44, 62, 97], 'the': [46, 64, 74, 116, 130, 147, 150, 165, 171, 180], 'classifier': [47], 'reduce': [49], 'calibration': [50, 163], 'time': [51], 'and': [52, 69], 'increase': [53], 'performance.': [54], 'We': [55], 'compare': [56], 'two': [57], 'different': [58], 'approaches': [59, 80], 'for': [60, 122], 'system:': [65], 'an': [66, 84, 89, 106, 137], 'unsupervised': [67], 'method': [68, 71], 'detection': [75, 172], 'error-related': [77, 100, 174], 'potentials.': [78, 101], 'Both': [79], 'were': [81, 132], 'tested': [82], 'in': [83, 87, 153], 'study,': [86], 'which': [88, 114, 145], 'average': [90, 107, 138], 'accuracy': [91, 103], '96%': [93], 'was': [94], 'achieved': [95], 'with': [96, 136], 'This': [102], 'corresponds': [104], 'information': [108], 'transfer': [109], 'rate': [110], '144': [112], 'bit/min,': [113], 'highest': [117], 'bitrate': [118], 'reported': [119], 'so': [120], 'far': [121], 'non-invasive': [124], 'BCI.': [125], 'free-spelling': [128], 'mode,': [129], 'subjects': [131], 'able': [133], 'write': [135], '21.3': [140], 'error-free': [141], 'letters': [142], 'per': [143], 'minute,': [144], 'shows': [146], 'feasibility': [148], 'system': [152, 167], 'normal-use': [155], 'scenario.': [156], 'addition': [158], 'show': [160], 'solely': [168], 'possible,': [177], 'without': [178], 'knowing': [179], 'true': [181], 'class': [182], 'labels.': [183]}",2012,"['Brain–computer interface', 'Computer science', 'Interface (matter)', 'Adaptation (eye)', 'Visual evoked potentials', 'Artificial intelligence', 'Error detection and correction', 'Speech recognition', 'Classifier (UML)', 'Pattern recognition (psychology)', 'Electroencephalography', 'Algorithm', 'Neuroscience', 'Psychology', 'Maximum bubble pressure method', 'Bubble', 'Parallel computing']","The goal of a Brain-Computer Interface (BCI) is to control a computer by pure brain activity. Recently, BCIs based on code-modulated visual evoked potentials (c-VEPs) have shown great potential to establish high-performance communication. In this paper we present a c-VEP BCI that uses online adaptation of the classifier to reduce calibration time and increase performance. We compare two different approaches for online adaptation of the system: an unsupervised method and a method that uses the detection of error-related potentials. Both approaches were tested in an online study, in which an average accuracy of 96% was achieved with adaptation based on error-related potentials. This accuracy corresponds to an average information transfer rate of 144 bit/min, which is the highest bitrate reported so far for a non-invasive BCI. In a free-spelling mode, the subjects were able to write with an average of 21.3 error-free letters per minute, which shows the feasibility of the BCI system in a normal-use scenario. In addition we show that a calibration of the BCI system solely based on the detection of error-related potentials is possible, without knowing the true class labels."
https://openalex.org/W2935908327,Local Aggregation for Unsupervised Learning of Visual Embeddings,"{'Unsupervised': [0], 'approaches': [1], 'to': [2, 77, 102, 113, 124, 137], 'learning': [3, 45, 153], 'in': [4, 63, 72, 88, 116, 158, 162, 168], 'neural': [5], 'networks': [6, 23, 51], 'are': [7], 'of': [8, 22, 30, 40, 43, 58, 66, 106, 134], 'substantial': [9], 'interest': [10], 'for': [11, 27], 'furthering': [12], 'artificial': [13], 'intelligence,': [14], 'both': [15], 'because': [16, 34], 'they': [17, 35], 'would': [18, 36], 'enable': [19], 'the': [20, 25, 41, 56, 64, 117], 'training': [21, 73], 'without': [24], 'need': [26], 'large': [28], 'numbers': [29], 'expensive': [31], 'annotations,': [32], 'and': [33, 82, 165], 'be': [37], 'better': [38], 'models': [39], 'kind': [42], 'general-purpose': [44], 'deployed': [46], 'by': [47], 'humans.': [48], 'However,': [49], 'unsupervised': [50, 151], 'have': [52, 85], 'long': [53], 'lagged': [54], 'behind': [55], 'performance': [57, 154], 'their': [59], 'supervised': [60], 'counterparts,': [61], 'especially': [62], 'domain': [65], 'large-scale': [67, 145], 'visual': [68, 146], 'recognition.': [69], 'Recent': [70], 'developments': [71], 'deep': [74], 'convolutional': [75], 'embeddings': [76], 'maximize': [78, 103], 'non-parametric': [79], 'instance': [80], 'separation': [81], 'clustering': [83], 'objectives': [84], 'shown': [86], 'promise': [87], 'closing': [89], 'this': [90], 'gap.': [91], 'Here,': [92], 'we': [93], 'describe': [94], 'a': [95, 104], 'method': [96], 'that': [97], 'trains': [98], 'an': [99], 'embedding': [100, 118], 'function': [101], 'metric': [105, 128], 'local': [107], 'aggregation,': [108], 'causing': [109], 'similar': [110], 'data': [111], 'instances': [112, 123], 'move': [114], 'together': [115], 'space,': [119], 'while': [120], 'allowing': [121, 131], 'dissimilar': [122], 'separate.': [125], 'This': [126], 'aggregation': [127], 'is': [129], 'dynamic,': [130], 'soft': [132], 'clusters': [133], 'different': [135], 'scales': [136], 'emerge.': [138], 'We': [139], 'evaluate': [140], 'our': [141], 'procedure': [142], 'on': [143, 155], 'several': [144], 'recognition': [147, 157, 161], 'datasets,': [148], 'achieving': [149], 'state-of-the-art': [150], 'transfer': [152], 'object': [156, 166], 'ImageNet,': [159], 'scene': [160], 'Places': [163], '205,': [164], 'detection': [167], 'PASCAL': [169], 'VOC.': [170]}",2019,"['Computer science', 'Artificial intelligence', 'Embedding', 'Unsupervised learning', 'Pascal (unit)', 'Cluster analysis', 'Machine learning', 'Convolutional neural network', 'Transfer of learning', 'Competitive learning', 'Pattern recognition (psychology)', 'Metric (unit)', 'Deep learning', 'Programming language', 'Operations management', 'Economics']","Unsupervised approaches to learning in neural networks are of substantial interest for furthering artificial intelligence, both because they would enable the training of networks without the need for large numbers of expensive annotations, and because they would be better models of the kind of general-purpose learning deployed by humans. However, unsupervised networks have long lagged behind the performance of their supervised counterparts, especially in the domain of large-scale visual recognition. Recent developments in training deep convolutional embeddings to maximize non-parametric instance separation and clustering objectives have shown promise in closing this gap. Here, we describe a method that trains an embedding function to maximize a metric of local aggregation, causing similar data instances to move together in the embedding space, while allowing dissimilar instances to separate. This aggregation metric is dynamic, allowing soft clusters of different scales to emerge. We evaluate our procedure on several large-scale visual recognition datasets, achieving state-of-the-art unsupervised transfer learning performance on object recognition in ImageNet, scene recognition in Places 205, and object detection in PASCAL VOC."
https://openalex.org/W2883294120,Unsupervised Learning of a Hierarchical Spiking Neural Network for Optical Flow Estimation: From Events to Global Motion Perception,"{'The': [0, 129], 'combination': [1], 'of': [2, 13, 64, 84, 154], 'spiking': [3, 27, 156], 'neural': [4, 66, 78, 157], 'networks': [5], 'and': [6, 16, 33, 55, 72, 92, 94, 106, 114, 136, 161], 'event-based': [7, 48], 'vision': [8], 'sensors': [9], 'holds': [10], 'the': [11, 24, 42, 62, 77, 81, 146], 'potential': [12], 'highly': [14], 'efficient': [15], 'high-bandwidth': [17], 'optical': [18], 'flow': [19], 'estimation.': [20], 'This': [21], 'paper': [22], 'presents': [23], 'first': [25], 'hierarchical': [26], 'architecture': [28, 79], 'in': [29, 37, 124], 'which': [30], 'motion': [31, 87, 96, 116, 121], '(direction': [32], 'speed)': [34], 'selectivity': [35, 122], 'emerges': [36, 123], 'an': [38, 47], 'unsupervised': [39], 'fashion': [40], 'from': [41], 'raw': [43], 'stimuli': [44], 'generated': [45], 'with': [46, 100, 141], 'camera.': [49], 'A': [50], 'novel': [51], 'adaptive': [52], 'neuron': [53], 'model': [54], 'stable': [56], 'spike-timing-dependent': [57], 'plasticity': [58], 'formulation': [59], 'are': [60, 110, 163], 'at': [61, 165], 'core': [63], 'this': [65, 142], 'network': [67], 'governing': [68], 'its': [69], 'spike-based': [70], 'processing': [71], 'learning,': [73], 'respectively.': [74], 'After': [75], 'convergence,': [76], 'exhibits': [80], 'main': [82], 'properties': [83], 'biological': [85], 'visual': [86], 'systems,': [88], 'namely': [89], 'feature': [90, 113], 'extraction': [91], 'local': [93, 115], 'global': [95, 120], 'perception.': [97], 'Convolutional': [98], 'layers': [99], 'input': [101], 'synapses': [102], 'characterized': [103], 'by': [104], 'single': [105], 'multiple': [107], 'transmission': [108], 'delays': [109], 'employed': [111], 'for': [112], 'perception,': [117], 'respectively;': [118], 'while': [119], 'a': [125, 148], 'final': [126], 'fully-connected': [127], 'layer.': [128], 'proposed': [130], 'solution': [131], 'is': [132], 'validated': [133], 'using': [134], 'synthetic': [135], 'real': [137], 'event': [138], 'sequences.': [139], 'Along': [140], 'paper,': [143], 'we': [144], 'provide': [145], 'cuSNNlibrary,': [147], 'framework': [149], 'that': [150], 'enables': [151], 'GPU-accelerated': [152], 'simulations': [153], 'large-scale': [155], 'networks.': [158], 'Source': [159], 'code': [160], 'samples': [162], 'available': [164], 'https://github.com/tudelft/cuSNN.': [166]}",2019,"['Computer science', 'Artificial intelligence', 'Spiking neural network', 'Optical flow', 'Neuromorphic engineering', 'Motion estimation', 'Convolutional neural network', 'Artificial neural network', 'Feature extraction', 'Feature (linguistics)', 'Spike (software development)', 'Pattern recognition (psychology)', 'Unsupervised learning', 'Computer vision', 'Image (mathematics)', 'Software engineering', 'Linguistics', 'Philosophy']","The combination of spiking neural networks and event-based vision sensors holds the potential of highly efficient and high-bandwidth optical flow estimation. This paper presents the first hierarchical spiking architecture in which motion (direction and speed) selectivity emerges in an unsupervised fashion from the raw stimuli generated with an event-based camera. A novel adaptive neuron model and stable spike-timing-dependent plasticity formulation are at the core of this neural network governing its spike-based processing and learning, respectively. After convergence, the neural architecture exhibits the main properties of biological visual motion systems, namely feature extraction and local and global motion perception. Convolutional layers with input synapses characterized by single and multiple transmission delays are employed for feature and local motion perception, respectively; while global motion selectivity emerges in a final fully-connected layer. The proposed solution is validated using synthetic and real event sequences. Along with this paper, we provide the cuSNNlibrary, a framework that enables GPU-accelerated simulations of large-scale spiking neural networks. Source code and samples are available at https://github.com/tudelft/cuSNN."
https://openalex.org/W2255128034,The use of an unsupervised learning approach for characterizing latent behaviors in accelerometer data,"{'Abstract': [0], 'The': [1, 132], 'recent': [2], 'increase': [3], 'in': [4, 236], 'data': [5, 83, 219], 'accuracy': [6], 'from': [7], 'high': [8], 'resolution': [9], 'accelerometers': [10], 'offers': [11], 'substantial': [12], 'potential': [13], 'for': [14, 26, 53, 210], 'improved': [15], 'understanding': [16], 'and': [17, 90, 101, 123, 129, 153, 174, 189, 195, 248], 'prediction': [18], 'of': [19, 35, 38, 60, 71, 88, 134, 146, 157, 186, 214, 244], 'animal': [20], 'movements.': [21], 'However,': [22], 'current': [23, 242], 'approaches': [24, 252], 'used': [25], 'analysing': [27], 'these': [28], 'multivariable': [29, 217], 'datasets': [30], 'typically': [31], 'require': [32], 'existing': [33, 249], 'knowledge': [34, 59, 243], 'the': [36, 39, 43, 54, 61, 69, 78, 110, 143, 147, 155, 158, 178, 211, 245], 'behaviors': [37, 63, 191, 246], 'animals': [40], 'to': [41, 116, 162], 'inform': [42], 'behavioral': [44, 119, 164], 'classification': [45], 'process.': [46], 'These': [47], 'methods': [48], 'are': [49, 221], 'thus': [50], 'not': [51], 'well‐suited': [52], 'many': [55], 'cases': [56, 237], 'where': [57, 238], 'limited': [58, 241, 255], 'different': [62], 'performed': [64, 247], 'exist.': [65], 'Here,': [66], 'we': [67, 81, 232, 239], 'introduce': [68], 'use': [70], 'an': [72, 184, 207], 'unsupervised': [73, 111, 203], 'learning': [74, 112, 204, 251], 'algorithm.': [75], 'To': [76], 'illustrate': [77], ""method's"": [79], 'capability': [80], 'analyse': [82], 'collected': [84], 'using': [85], 'a': [86], 'combination': [87], 'GPS': [89], 'Accelerometers': [91], 'on': [92], 'two': [93, 148], 'seabird': [94], 'species:': [95], 'razorbills': [96], '(': [97, 104], 'Alca': [98], 'torda': [99], ')': [100], 'common': [102], 'guillemots': [103], 'Uria': [105], 'aalge': [106], ').': [107], 'We': [108, 199], 'applied': [109], 'algorithm': [113], 'Expectation': [114], 'Maximization': [115], 'characterize': [117], 'latent': [118], 'states': [120], 'both': [121, 127, 151], 'above': [122, 152], 'below': [124, 154], 'water': [125, 179], 'at': [126], 'individual': [128], 'group': [130], 'level.': [131], 'application': [133, 235], 'this': [135, 181, 202], 'flexible': [136], 'approach': [137, 182, 205], 'yielded': [138], 'significant': [139], 'new': [140], 'insights': [141], 'into': [142], 'foraging': [144], 'strategies': [145], 'study': [149], 'species,': [150], 'surface': [156], 'water.': [159], 'In': [160, 230], 'addition': [161], 'general': [163], 'modes': [165], 'such': [166, 192, 215], 'as': [167, 170, 172, 193], 'flying,': [168], 'floating,': [169], 'well': [171], 'descending': [173], 'ascending': [175], 'phases': [176], 'within': [177], 'column,': [180], 'allowed': [183], 'exploration': [185], 'previously': [187], 'unstudied': [188], 'important': [190], 'searching': [194], 'prey': [196], 'chasing/capture': [197], 'events.': [198], 'propose': [200], 'that': [201, 220], 'provides': [206], 'ideal': [208], 'tool': [209], 'systematic': [212], 'analysis': [213], 'complex': [216], 'movement': [218], 'increasingly': [222], 'being': [223], 'obtained': [224], 'with': [225], 'accelerometer': [226], 'tags': [227], 'across': [228], 'species.': [229], 'particular,': [231], 'recommend': [233], 'its': [234], 'have': [240, 254], 'supervised': [250], 'may': [253], 'utility.': [256]}",2016,"['Accelerometer', 'Unsupervised learning', 'Computer science', 'Artificial intelligence', 'Machine learning', 'Operating system']","Abstract The recent increase in data accuracy from high resolution accelerometers offers substantial potential for improved understanding and prediction of animal movements. However, current approaches used for analysing these multivariable datasets typically require existing knowledge of the behaviors of the animals to inform the behavioral classification process. These methods are thus not well‐suited for the many cases where limited knowledge of the different behaviors performed exist. Here, we introduce the use of an unsupervised learning algorithm. To illustrate the method's capability we analyse data collected using a combination of GPS and Accelerometers on two seabird species: razorbills ( Alca torda ) and common guillemots ( Uria aalge ). We applied the unsupervised learning algorithm Expectation Maximization to characterize latent behavioral states both above and below water at both individual and group level. The application of this flexible approach yielded significant new insights into the foraging strategies of the two study species, both above and below the surface of the water. In addition to general behavioral modes such as flying, floating, as well as descending and ascending phases within the water column, this approach allowed an exploration of previously unstudied and important behaviors such as searching and prey chasing/capture events. We propose that this unsupervised learning approach provides an ideal tool for the systematic analysis of such complex multivariable movement data that are increasingly being obtained with accelerometer tags across species. In particular, we recommend its application in cases where we have limited current knowledge of the behaviors performed and existing supervised learning approaches may have limited utility."
https://openalex.org/W2955804754,Unsupervised learning for local structure detection in colloidal systems,"{'We': [0, 44, 63], 'introduce': [1], 'a': [2, 18, 29, 47, 73, 101, 130], 'simple,': [3], 'fast,': [4], 'and': [5, 92, 110, 115, 137], 'easy': [6], 'to': [7, 36, 57, 89, 123, 129, 143, 155], 'implement': [8], 'unsupervised': [9], 'learning': [10], 'algorithm': [11], 'for': [12], 'detecting': [13], 'different': [14], 'local': [15, 39, 127], 'environments': [16, 128], 'on': [17, 70], 'single-particle': [19], 'level': [20], 'in': [21, 55, 153, 164], 'colloidal': [22, 77], 'systems.': [23], 'In': [24, 117, 141], 'this': [25], 'algorithm,': [26], 'we': [27, 98, 120, 147], 'use': [28, 46, 149], 'vector': [30], 'of': [31, 41, 67, 72, 76, 103], 'standard': [32], 'bond-orientational': [33], 'order': [34, 56, 139, 154, 162], 'parameters': [35, 163], 'describe': [37], 'the': [38, 65, 68, 125, 150, 157, 165], 'environment': [40], 'each': [42], 'particle.': [43], 'then': [45], 'neural-network-based': [48], 'autoencoder': [49, 152], 'combined': [50], 'with': [51], 'Gaussian': [52], 'mixture': [53], 'models': [54], 'autonomously': [58], 'group': [59], 'together': [60], 'similar': [61, 131], 'environments.': [62], 'test': [64], 'performance': [66], 'method': [69], 'snapshots': [71], 'wide': [74], 'variety': [75, 102], 'systems': [78, 88, 166], 'obtained': [79], 'via': [80], 'computer': [81], 'simulations,': [82], 'ranging': [83], 'from': [84], 'simple': [85], 'isotropically': [86], 'interacting': [87], 'binary': [90], 'mixtures,': [91], 'even': [93], 'anisotropic': [94], 'hard': [95], 'cubes.': [96], 'Additionally,': [97], 'look': [99], 'at': [100], 'common': [104], 'self-assembled': [105], 'situations': [106], 'such': [107, 145], 'as': [108, 133], 'fluid-crystal': [109], 'crystal-crystal': [111], 'coexistences,': [112], 'grain': [113], 'boundaries,': [114], 'nucleation.': [116], 'all': [118], 'cases,': [119], 'are': [121], 'able': [122], 'identify': [124], 'relevant': [126, 159], 'precision': [132], '“standard,”': [134], 'manually': [135], 'tuned,': [136], 'system-specific,': [138], 'parameters.': [140], 'addition': [142], 'classifying': [144], 'environments,': [146], 'also': [148], 'trained': [151], 'determine': [156], 'most': [158], 'bond': [160], 'orientational': [161], 'analyzed.': [167]}",2019,[],"We introduce a simple, fast, and easy to implement unsupervised learning algorithm for detecting different local environments on a single-particle level in colloidal systems. In this algorithm, we use a vector of standard bond-orientational order parameters to describe the local environment of each particle. We then use a neural-network-based autoencoder combined with Gaussian mixture models in order to autonomously group together similar environments. We test the performance of the method on snapshots of a wide variety of colloidal systems obtained via computer simulations, ranging from simple isotropically interacting systems to binary mixtures, and even anisotropic hard cubes. Additionally, we look at a variety of common self-assembled situations such as fluid-crystal and crystal-crystal coexistences, grain boundaries, and nucleation. In all cases, we are able to identify the relevant local environments to a similar precision as “standard,” manually tuned, and system-specific, order parameters. In addition to classifying such environments, we also use the trained autoencoder in order to determine the most relevant bond orientational order parameters in the systems analyzed."
https://openalex.org/W2787109437,Deep Temporal Clustering : Fully Unsupervised Learning of Time-Domain Features,"{'Unsupervised': [0], 'learning': [1, 40], 'of': [2, 125, 134], 'time': [3, 130, 140], 'series': [4, 141], 'data,': [5], 'also': [6], 'known': [7], 'as': [8], 'temporal': [9, 34, 50, 56, 81, 89, 106, 174], 'clustering,': [10, 115], 'is': [11, 137, 168], 'a': [12, 21, 37, 54, 118, 123], 'challenging': [13], 'problem': [14], 'in': [15], 'machine': [16], 'learning.': [17], 'Here': [18], 'we': [19, 116, 156], 'propose': [20], 'novel': [22, 55], 'algorithm,': [23], 'Deep': [24], 'Temporal': [25], 'Clustering': [26], '(DTC),': [27], 'to': [28, 149, 170], 'naturally': [29], 'integrate': [30], 'dimensionality': [31, 51, 71, 175], 'reduction': [32, 52, 72, 176], 'and': [33, 53, 69, 78, 95, 100, 177], 'clustering': [35, 57, 67, 82, 178], 'into': [36, 105], 'single': [38], 'end-to-end': [39], 'framework,': [41], 'fully': [42, 172], 'unsupervised.': [43], 'The': [44, 132, 165], 'algorithm': [45, 136, 161], 'utilizes': [46], 'an': [47], 'autoencoder': [48], 'for': [49, 59, 113, 128], 'layer': [58, 83], 'cluster': [60], 'assignment.': [61], 'Then': [62], 'it': [63], 'jointly': [64], 'optimizes': [65], 'the': [66, 70, 80, 109, 129, 135, 159, 171], 'objective': [68], 'objec': [73], 'tive.': [74], 'Based': [75], 'on': [76], 'requirement': [77], 'application,': [79], 'can': [84], 'be': [85], 'customized': [86], 'with': [87], 'any': [88], 'similarity': [90, 93], 'metric.': [91], 'Several': [92], 'metrics': [94], 'state-of-the-art': [96], 'algorithms': [97], 'are': [98], 'considered': [99], 'compared.': [101], 'To': [102], 'gain': [103], 'insight': [104], 'features': [107], 'that': [108, 121, 158], 'network': [110], 'has': [111], 'learned': [112], 'its': [114], 'apply': [117], 'visualization': [119], 'method': [120], 'generates': [122], 'region': [124], 'interest': [126], 'heatmap': [127], 'series.': [131], 'viability': [133], 'demonstrated': [138], 'using': [139], 'data': [142], 'from': [143, 147], 'diverse': [144], 'domains,': [145], 'ranging': [146], 'earthquakes': [148], 'spacecraft': [150], 'sensor': [151], 'data.': [152], 'In': [153], 'each': [154], 'case,': [155], 'show': [157], 'proposed': [160], 'outperforms': [162], 'traditional': [163], 'methods.': [164], 'superior': [166], 'performance': [167], 'attributed': [169], 'integrated': [173], 'criterion.': [179]}",2018,"['Cluster analysis', 'Autoencoder', 'Dimensionality reduction', 'Computer science', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Correlation clustering', 'Temporal database', 'Data stream clustering', 'Unsupervised learning', 'Deep learning', 'Canopy clustering algorithm', 'Clustering high-dimensional data', 'CURE data clustering algorithm', 'Data mining']","Unsupervised learning of time series data, also known as temporal clustering, is a challenging problem in machine learning. Here we propose a novel algorithm, Deep Temporal Clustering (DTC), to naturally integrate dimensionality reduction and temporal clustering into a single end-to-end learning framework, fully unsupervised. The algorithm utilizes an autoencoder for temporal dimensionality reduction and a novel temporal clustering layer for cluster assignment. Then it jointly optimizes the clustering objective and the dimensionality reduction objec tive. Based on requirement and application, the temporal clustering layer can be customized with any temporal similarity metric. Several similarity metrics and state-of-the-art algorithms are considered and compared. To gain insight into temporal features that the network has learned for its clustering, we apply a visualization method that generates a region of interest heatmap for the time series. The viability of the algorithm is demonstrated using time series data from diverse domains, ranging from earthquakes to spacecraft sensor data. In each case, we show that the proposed algorithm outperforms traditional methods. The superior performance is attributed to the fully integrated temporal dimensionality reduction and clustering criterion."
https://openalex.org/W2963194800,auDeep: Unsupervised Learning of Representations from Audio with Deep\n Recurrent Neural Networks,"{'auDeep': [0], 'is': [1, 13], 'a': [2, 16, 45], 'Python': [3, 46], 'toolkit': [4], 'for': [5, 48], 'deep': [6], 'unsupervised': [7], 'representation': [8], 'learning': [9], 'from\\nacoustic': [10], 'data.': [11], 'It': [12], 'based': [14], 'on': [15], 'recurrent': [17], 'sequence': [18, 20], 'to': [19, 44], 'autoencoder\\napproach': [21], 'which': [22, 54], 'can': [23], 'learn': [24], 'representations': [25], 'of': [26, 53], 'time': [27], 'series': [28], 'data': [29], 'by': [30], 'taking': [31], 'into\\naccount': [32], 'their': [33], 'temporal': [34], 'dynamics.': [35], 'We': [36], 'provide': [37], 'an': [38], 'extensive': [39], 'command': [40], 'line': [41], 'interface\\nin': [42], 'addition': [43], 'API': [47], 'users': [49], 'and': [50, 57], 'developers,': [51], 'both': [52], 'are\\ncomprehensively': [55], 'documented': [56], 'publicly': [58], 'available': [59], 'at\\nhttps://github.com/auDeep/auDeep.': [60], 'Experimental': [61], 'results': [62], 'indicate': [63], 'that': [64], 'auDeep\\nfeatures': [65], 'are': [66], 'competitive': [67], 'with': [68], 'state-of-the': [69], 'art': [70], 'audio': [71], 'classification.\\n': [72]}",2017,"['Python (programming language)', 'Autoencoder', 'Computer science', 'Deep learning', 'Unsupervised learning', 'Artificial intelligence', 'Encoder', 'Feature learning', 'Recurrent neural network', 'Artificial neural network', 'Speech recognition', 'Machine learning', 'Programming language', 'Operating system']","auDeep is a Python toolkit for deep unsupervised representation learning from\nacoustic data. It is based on a recurrent sequence to sequence autoencoder\napproach which can learn representations of time series data by taking into\naccount their temporal dynamics. We provide an extensive command line interface\nin addition to a Python API for users and developers, both of which are\ncomprehensively documented and publicly available at\nhttps://github.com/auDeep/auDeep. Experimental results indicate that auDeep\nfeatures are competitive with state-of-the art audio classification.\n"
https://openalex.org/W2889050299,Microstructure Cluster Analysis with Transfer Learning and Unsupervised Learning,"{'Abstract': [0], 'We': [1, 97], 'apply': [2], 'computer': [3], 'vision': [4], 'and': [5, 85], 'machine': [6], 'learning': [7, 18, 37, 103], 'methods': [8], 'to': [9, 43, 108], 'analyze': [10], 'two': [11, 51], 'datasets': [12], 'of': [13, 25, 48, 73, 89], 'microstructural': [14], 'images.': [15], 'A': [16, 53], 'transfer': [17, 102], 'pipeline': [19], 'utilizes': [20], 'the': [21, 32, 40, 79, 100], 'fully': [22, 109], 'connected': [23], 'layer': [24], 'a': [26, 71, 87], 'pre-trained': [27], 'convolutional': [28], 'neural': [29], 'network': [30], 'as': [31], 'image': [33, 41, 80], 'representation.': [34], 'An': [35], 'unsupervised': [36], 'method': [38, 104], 'uses': [39], 'representations': [42], 'discover': [44], 'visually': [45, 61, 83], 'distinct': [46, 84], 'clusters': [47], 'images': [49, 68], 'within': [50], 'datasets.': [52], 'minimally': [54], 'supervised': [55], 'clustering': [56], 'approach': [57, 65], 'classifies': [58, 67], 'micrographs': [59], 'into': [60], 'similar': [62], 'groups.': [63], 'This': [64], 'successfully': [66], 'both': [69], 'in': [70, 76, 86], 'dataset': [72, 88], 'surface': [74], 'defects': [75], 'steel,': [77], 'where': [78], 'classes': [81], 'are': [82], 'fracture': [90], 'surfaces': [91], 'that': [92, 99], 'humans': [93], 'have': [94], 'difficulty': [95], 'classifying.': [96], 'find': [98], 'unsupervised,': [101], 'gives': [105], 'results': [106], 'comparable': [107], 'supervised,': [110], 'custom-built': [111], 'approaches.': [112]}",2018,"['Artificial intelligence', 'Unsupervised learning', 'Transfer of learning', 'Computer science', 'Convolutional neural network', 'Pattern recognition (psychology)', 'Cluster analysis', 'Pipeline (software)', 'Deep learning', 'Image (mathematics)', 'Representation (politics)', 'Supervised learning', 'Machine learning', 'Artificial neural network', 'Politics', 'Law', 'Programming language', 'Political science']","Abstract We apply computer vision and machine learning methods to analyze two datasets of microstructural images. A transfer learning pipeline utilizes the fully connected layer of a pre-trained convolutional neural network as the image representation. An unsupervised learning method uses the image representations to discover visually distinct clusters of images within two datasets. A minimally supervised clustering approach classifies micrographs into visually similar groups. This approach successfully classifies images both in a dataset of surface defects in steel, where the image classes are visually distinct and in a dataset of fracture surfaces that humans have difficulty classifying. We find that the unsupervised, transfer learning method gives results comparable to fully supervised, custom-built approaches."
https://openalex.org/W2908779501,Low-Complexity Non-Intrusive Load Monitoring Using Unsupervised Learning and Generalized Appliance Models,"{'Awareness': [0], 'of': [1, 35, 65, 77, 134, 141, 174], 'electric': [2, 51], 'energy': [3, 14, 20, 42, 52, 86, 151], 'usage': [4, 53, 59, 143], 'has': [5, 26, 165], 'both': [6], 'societal': [7], 'and': [8, 16, 47, 54, 122, 192], 'economic': [9], 'benefits,': [10], 'which': [11, 44, 98], 'include': [12], 'reduced': [13], 'bills': [15], 'stress': [17], 'on': [18, 58], 'non-renewable': [19], 'sources.': [21], 'In': [22, 88], 'recent': [23, 172], 'years,': [24], 'there': [25], 'been': [27], 'a': [28, 74, 91, 109, 125, 132, 145], 'surge': [29], 'in': [30, 32, 68, 124], 'interest': [31], 'the': [33, 139, 154, 163, 175], 'field': [34], 'load': [36, 127], 'monitoring,': [37], 'also': [38], 'referred': [39], 'to': [40, 61, 130], 'as': [41, 187], 'disaggregation,': [43], 'involves': [45], 'methods': [46], 'techniques': [48], 'for': [49, 85, 138, 167, 178], 'monitoring': [50, 128], 'providing': [55], 'appropriate': [56], 'feedback': [57], 'patterns': [60], 'homeowners.': [62], 'The': [63, 104], 'use': [64], 'unsupervised': [66, 93, 179], 'learning': [67], 'Non-Intrusive': [69], 'Load': [70], 'Monitoring': [71], '(NILM)': [72], 'is': [73, 96, 99, 106], 'key': [75], 'area': [76], 'study,': [78], 'with': [79, 171], 'practical': [80, 102, 126], 'solutions': [81], 'having': [82], 'wide': [83], 'implications': [84], 'monitoring.': [87], 'this': [89], 'paper,': [90], 'low-complexity': [92], 'NILM': [94, 180, 184], 'algorithm': [95, 105, 112, 164], 'presented,': [97], 'designed': [100], 'toward': [101], 'implementation.': [103], 'inspired': [107], 'by': [108], 'fuzzy': [110], 'clustering': [111], 'called': [113], 'Entropy': [114], 'Index': [115], 'Constraints': [116], 'Competitive': [117], 'Agglomeration': [118], '(EICCA),': [119], 'but': [120], 'facilitated': [121], 'improved': [123], 'environment': [129], 'produce': [131], 'set': [133], 'generalized': [135], 'appliance': [136, 142], 'models': [137], 'detection': [140, 169], 'within': [144], 'household.': [146], 'Experimental': [147], 'evaluation': [148], 'conducted': [149], 'using': [150], 'data': [152], 'from': [153], 'Reference': [155], 'Energy': [156, 194], 'Data': [157], 'Disaggregation': [158], 'Dataset': [159], '(REDD)': [160], 'indicates': [161], 'that': [162], 'out-performance': [166], 'event': [168], 'compared': [170], 'state': [173], 'art': [176], 'work': [177], 'when': [181], 'considering': [182], 'common': [183], 'metrics': [185], 'such': [186], 'Accuracy,': [188], 'Precision,': [189], 'Recall,': [190], 'F-measure,': [191], 'Total': [193], 'Correctly': [195], 'Assigned': [196], '(TECA).': [197]}",2019,"['Computer science', 'Unsupervised learning', 'Cluster analysis', 'Data mining', 'Energy (signal processing)', 'Entropy (arrow of time)', 'Machine learning', 'Artificial intelligence', 'Statistics', 'Mathematics', 'Physics', 'Quantum mechanics']","Awareness of electric energy usage has both societal and economic benefits, which include reduced energy bills and stress on non-renewable energy sources. In recent years, there has been a surge in interest in the field of load monitoring, also referred to as energy disaggregation, which involves methods and techniques for monitoring electric energy usage and providing appropriate feedback on usage patterns to homeowners. The use of unsupervised learning in Non-Intrusive Load Monitoring (NILM) is a key area of study, with practical solutions having wide implications for energy monitoring. In this paper, a low-complexity unsupervised NILM algorithm is presented, which is designed toward practical implementation. The algorithm is inspired by a fuzzy clustering algorithm called Entropy Index Constraints Competitive Agglomeration (EICCA), but facilitated and improved in a practical load monitoring environment to produce a set of generalized appliance models for the detection of appliance usage within a household. Experimental evaluation conducted using energy data from the Reference Energy Data Disaggregation Dataset (REDD) indicates that the algorithm has out-performance for event detection compared with recent state of the art work for unsupervised NILM when considering common NILM metrics such as Accuracy, Precision, Recall, F-measure, and Total Energy Correctly Assigned (TECA)."
https://openalex.org/W2120831232,Mining FDA drug labels using an unsupervised learning technique - topic modeling,"{'Abstract': [0], 'Background': [1], 'The': [2, 239, 261, 308], 'Food': [3], 'and': [4, 28, 63, 91, 155, 233, 341], 'Drug': [5], 'Administration': [6], '(FDA)': [7], 'approved': [8], 'drug': [9, 20, 24, 115, 139, 161, 317, 339], 'labels': [10, 140], 'contain': [11], 'a': [12, 49, 61, 98, 118, 205, 324], 'broad': [13], 'array': [14], 'of': [15, 81, 120, 136, 159, 178, 207, 219, 236, 311, 332, 347], 'information,': [16], 'ranging': [17], 'from': [18, 56, 302], 'adverse': [19, 274, 297], 'reactions': [21], '(ADRs)': [22], 'to': [23, 35, 113, 173, 181, 198, 272, 294, 328], 'efficacy,': [25], 'risk-benefit': [26], 'consideration,': [27], 'more.': [29], 'However,': [30], 'the': [31, 57, 78, 82, 114, 147, 166, 175, 182, 187, 213, 217, 220, 230, 250, 315, 345], 'labeling': [32, 58, 116, 149, 318], 'language': [33], 'used': [34, 142], 'describe': [36], 'these': [37], 'information': [38, 55, 228], 'is': [39, 88], 'free': [40, 176], 'text': [41, 59, 84, 100, 177], 'often': [42], 'containing': [43], 'ambiguous': [44], 'semantic': [45], 'descriptions,': [46], 'which': [47, 87], 'poses': [48], 'great': [50], 'challenge': [51], 'in': [52, 60, 106, 143, 336, 344], 'retrieving': [53], 'useful': [54], 'consistent': [62], 'accurate': [64], 'fashion': [65], 'for': [66, 169, 287], 'comparative': [67], 'analysis': [68], 'across': [69], 'drugs.': [70, 237], 'Consequently,': [71], 'this': [72, 96, 144, 337], 'task': [73], 'has': [74], 'largely': [75], 'relied': [76], 'on': [77, 212, 226, 314], 'manual': [79], 'reading': [80], 'full': [83], 'by': [85, 165, 245], 'experts,': [86], 'time': [89], 'consuming': [90], 'labor': [92], 'intensive.': [93], 'Method': [94], 'In': [95], 'study,': [97, 338], 'novel': [99], 'mining': [101], 'method': [102], 'with': [103, 117, 126, 191, 204, 249, 257], 'unsupervised': [104], 'learning': [105], 'nature,': [107], 'called': [108], 'topic': [109, 188, 221, 312], 'modeling,': [110], 'was': [111, 196, 223], 'applied': [112, 197], 'goal': [119], 'discovering': [121], '“topics”': [122], 'that': [123, 242, 267, 299], 'group': [124], 'drugs': [125, 208, 243], 'similar': [127], 'safety': [128, 234, 252, 340], 'concerns': [129, 253], 'and/or': [130, 254], 'therapeutic': [131, 231, 255, 283, 342], 'uses': [132, 232, 256], 'together.': [133], 'A': [134], 'total': [135], '794': [137], 'FDA-approved': [138], 'were': [141, 163, 291], 'study.': [145], 'First,': [146], 'three': [148], 'sections': [150], '(i.e.,': [151], 'Boxed': [152], 'Warning,': [153], 'Warnings': [154], 'Precautions,': [156], 'Adverse': [157], 'Reactions)': [158], 'each': [160, 179, 202], 'label': [162, 180], 'processed': [164], 'Medical': [167], 'Dictionary': [168], 'Regulatory': [170], 'Activities': [171], '(MedDRA)': [172], 'convert': [174], 'standard': [183], 'ADR': [184], 'terms.': [185], 'Next,': [186], 'modeling': [189, 222, 313], 'approach': [190], 'latent': [192], 'Dirichlet': [193], 'allocation': [194], '(LDA)': [195], 'generate': [199], '100': [200], 'topics,': [201], 'associated': [203, 248], 'set': [206], 'grouped': [209, 244], 'together': [210], 'based': [211, 225], 'probability': [214], 'analysis.': [215], 'Lastly,': [216], 'efficacy': [218], 'evaluated': [224], 'known': [227], 'about': [229], 'data': [235], 'Results': [238], 'results': [240], 'demonstrate': [241], 'topics': [246, 263], 'are': [247], 'same': [251], 'statistical': [258], 'significance': [259], '(P&lt;0.05).': [260], 'identified': [262], 'have': [264], 'distinct': [265], 'context': [266], 'can': [268], 'be': [269], 'directly': [270], 'linked': [271], 'specific': [273, 303], 'events': [275, 298], '(e.g.,': [276, 285], 'liver': [277], 'injury': [278], 'or': [279, 282], 'kidney': [280], 'injury)': [281], 'application': [284, 310], 'antiinfectives': [286], 'systemic': [288], 'use).': [289], 'We': [290], 'also': [292], 'able': [293], 'identify': [295], 'potential': [296, 321], 'might': [300], 'arise': [301], 'medications': [304], 'via': [305], 'topics.': [306], 'Conclusions': [307], 'successful': [309], 'FDA': [316], 'demonstrates': [319], 'its': [320], 'utility': [322], 'as': [323], 'hypothesis': [325], 'generation': [326], 'means': [327], 'infer': [329], 'hidden': [330], 'relationships': [331], 'concepts': [333], 'such': [334], 'as,': [335], 'use': [343], 'study': [346], 'biomedical': [348], 'documents.': [349]}",2011,"['Latent Dirichlet allocation', 'Topic model', 'Computer science', 'MedDRA', 'Drug', 'Approved drug', 'Information retrieval', 'Task (project management)', 'Machine learning', 'Natural language processing', 'Pharmacovigilance', 'Artificial intelligence', 'Medicine', 'Pharmacology', 'Management', 'Economics']","Abstract Background The Food and Drug Administration (FDA) approved drug labels contain a broad array of information, ranging from adverse drug reactions (ADRs) to drug efficacy, risk-benefit consideration, and more. However, the labeling language used to describe these information is free text often containing ambiguous semantic descriptions, which poses a great challenge in retrieving useful information from the labeling text in a consistent and accurate fashion for comparative analysis across drugs. Consequently, this task has largely relied on the manual reading of the full text by experts, which is time consuming and labor intensive. Method In this study, a novel text mining method with unsupervised learning in nature, called topic modeling, was applied to the drug labeling with a goal of discovering “topics” that group drugs with similar safety concerns and/or therapeutic uses together. A total of 794 FDA-approved drug labels were used in this study. First, the three labeling sections (i.e., Boxed Warning, Warnings and Precautions, Adverse Reactions) of each drug label were processed by the Medical Dictionary for Regulatory Activities (MedDRA) to convert the free text of each label to the standard ADR terms. Next, the topic modeling approach with latent Dirichlet allocation (LDA) was applied to generate 100 topics, each associated with a set of drugs grouped together based on the probability analysis. Lastly, the efficacy of the topic modeling was evaluated based on known information about the therapeutic uses and safety data of drugs. Results The results demonstrate that drugs grouped by topics are associated with the same safety concerns and/or therapeutic uses with statistical significance (P&lt;0.05). The identified topics have distinct context that can be directly linked to specific adverse events (e.g., liver injury or kidney injury) or therapeutic application (e.g., antiinfectives for systemic use). We were also able to identify potential adverse events that might arise from specific medications via topics. Conclusions The successful application of topic modeling on the FDA drug labeling demonstrates its potential utility as a hypothesis generation means to infer hidden relationships of concepts such as, in this study, drug safety and therapeutic use in the study of biomedical documents."
https://openalex.org/W2955368974,Unsupervised Learning of Object Keypoints for Perception and Control,"{'The': [0, 93], 'study': [1], 'of': [2, 64], 'object': [3, 20, 35, 60, 99], 'representations': [4, 13, 36, 61], 'in': [5, 62, 76, 118], 'computer': [6], 'vision': [7], 'has': [8], 'primarily': [9], 'focused': [10], 'on': [11], 'developing': [12], 'that': [14, 37], 'are': [15, 38], 'useful': [16, 39], 'for': [17, 40, 56], 'image': [18, 84, 129], 'classification,': [19], 'detection,': [21], 'or': [22, 66], 'semantic': [23], 'segmentation': [24], 'as': [25, 131], 'downstream': [26], 'tasks.': [27], 'In': [28], 'this': [29, 47], 'work': [30], 'we': [31, 49], 'aim': [32], 'to': [33, 140, 155], 'learn': [34], 'control': [41, 119], 'and': [42, 98, 127], 'reinforcement': [43, 136], 'learning': [44, 139], '(RL).': [45], 'To': [46], 'end,': [48], 'introduce': [50], 'Transporter,': [51], 'a': [52, 77, 90], 'neural': [53], 'network': [54], 'architecture': [55], 'discovering': [57], 'concise': [58], 'geometric': [59], 'terms': [63], 'keypoints': [65, 95], 'image-space': [67], 'coordinates.': [68], 'Our': [69], 'method': [70], 'learns': [71], 'from': [72], 'raw': [73], 'video': [74, 87], 'frames': [75, 88], 'fully': [78], 'unsupervised': [79], 'manner,': [80], 'by': [81, 142], 'transporting': [82], 'learnt': [83], 'features': [85, 130], 'between': [86], 'using': [89, 123], 'keypoint': [91, 125, 144], 'bottleneck.': [92], 'discovered': [94], 'track': [96], 'objects': [97], 'parts': [100], 'across': [101], 'long': [102], 'time-horizons': [103], 'more': [104], 'accurately': [105], 'than': [106], 'recent': [107], 'similar': [108], 'methods.': [109], 'Furthermore,': [110], 'consistent': [111], 'long-term': [112], 'tracking': [113], 'enables': [114, 133], 'two': [115], 'notable': [116], 'results': [117], 'domains': [120], '--': [121], '(1)': [122], 'the': [124, 148], 'co-ordinates': [126], 'corresponding': [128], 'inputs': [132], 'highly': [134], 'sample-efficient': [135], 'learning;': [137], '(2)': [138], 'explore': [141], 'controlling': [143], 'locations': [145], 'drastically': [146], 'reduces': [147], 'search': [149], 'space,': [150], 'enabling': [151], 'deep': [152], 'exploration': [153], '(leading': [154], 'states': [156], 'unreachable': [157], 'through': [158], 'random': [159], 'action': [160], 'exploration)': [161], 'without': [162], 'any': [163], 'extrinsic': [164], 'rewards.': [165]}",2019,"['Artificial intelligence', 'Computer science', 'Object (grammar)', 'Reinforcement learning', 'Computer vision', 'Bottleneck', 'Unsupervised learning', 'Segmentation', 'Object detection', 'Artificial neural network', 'Pattern recognition (psychology)', 'Image (mathematics)', 'Embedded system']","The study of object representations in computer vision has primarily focused on developing representations that are useful for image classification, object detection, or semantic segmentation as downstream tasks. In this work we aim to learn object representations that are useful for control and reinforcement learning (RL). To this end, we introduce Transporter, a neural network architecture for discovering concise geometric object representations in terms of keypoints or image-space coordinates. Our method learns from raw video frames in a fully unsupervised manner, by transporting learnt image features between video frames using a keypoint bottleneck. The discovered keypoints track objects and object parts across long time-horizons more accurately than recent similar methods. Furthermore, consistent long-term tracking enables two notable results in control domains -- (1) using the keypoint co-ordinates and corresponding image features as inputs enables highly sample-efficient reinforcement learning; (2) learning to explore by controlling keypoint locations drastically reduces the search space, enabling deep exploration (leading to states unreachable through random action exploration) without any extrinsic rewards."
https://openalex.org/W2890119807,Unsupervised Learning of View-invariant Action Representations,"{'The': [0], 'recent': [1], 'success': [2], 'in': [3, 59, 72], 'human': [4], 'action': [5, 125], 'recognition': [6, 126], 'with': [7], 'deep': [8], 'learning': [9, 15, 45, 65, 84, 112], 'methods': [10], 'mostly': [11], 'adopt': [12], 'the': [13, 89, 100, 118, 121], 'supervised': [14], 'paradigm,': [16], 'which': [17, 47, 96], 'requires': [18], 'significant': [19], 'amount': [20], 'of': [21, 113, 120], 'manually': [22], 'labeled': [23], 'data': [24, 50], 'to': [25, 51, 68, 85, 110], 'achieve': [26], 'good': [27], 'performance.': [28], 'However,': [29], 'label': [30], 'collection': [31], 'is': [32, 67, 97], 'an': [33, 43], 'expensive': [34], 'and': [35], 'time-consuming': [36], 'process.': [37], 'In': [38, 102], 'this': [39], 'work,': [40], 'we': [41, 104], 'propose': [42, 105], 'unsupervised': [44, 64], 'framework,': [46], 'exploits': [48], 'unlabeled': [49], 'learn': [52], 'video': [53, 60, 77], 'representations.': [54], 'Different': [55], 'from': [56, 79], 'previous': [57], 'works': [58], 'representation': [61, 78, 90], 'learning,': [62], 'our': [63], 'task': [66], 'predict': [69], '3D': [70], 'motion': [71, 94], 'multiple': [73, 128], 'target': [74], 'views': [75], 'using': [76], 'a': [80, 106], 'source': [81], 'view.': [82], 'By': [83], 'extrapolate': [86], 'cross-view': [87], 'motions,': [88], 'can': [91], 'capture': [92], 'view-invariant': [93, 114], 'dynamics': [95], 'discriminative': [98], 'for': [99, 124], 'action.': [101], 'addition,': [103], 'view-adversarial': [107], 'training': [108], 'method': [109], 'enhance': [111], 'features.': [115], 'We': [116], 'demonstrate': [117], 'effectiveness': [119], 'learned': [122], 'representations': [123], 'on': [127], 'datasets.': [129]}",2018,"['Invariant (physics)', 'Unsupervised learning', 'Action learning', 'Action (physics)', 'Artificial intelligence', 'Computer science', 'Mathematics', 'Mathematics education', 'Cooperative learning', 'Physics', 'Teaching method', 'Mathematical physics', 'Quantum mechanics']","The recent success in human action recognition with deep learning methods mostly adopt the supervised learning paradigm, which requires significant amount of manually labeled data to achieve good performance. However, label collection is an expensive and time-consuming process. In this work, we propose an unsupervised learning framework, which exploits unlabeled data to learn video representations. Different from previous works in video representation learning, our unsupervised learning task is to predict 3D motion in multiple target views using video representation from a source view. By learning to extrapolate cross-view motions, the representation can capture view-invariant motion dynamics which is discriminative for the action. In addition, we propose a view-adversarial training method to enhance learning of view-invariant features. We demonstrate the effectiveness of the learned representations for action recognition on multiple datasets."
https://openalex.org/W15356902,Enhancing Supervised Terrain Classification with Predictive Unsupervised Learning,"{'Abstract': [0], '—': [1], 'This': [2, 92], 'paper': [3], 'describes': [4], 'a': [5, 153, 156, 176], 'method': [6], 'for': [7, 68, 102], 'classifying': [8], 'the': [9, 28, 53, 60, 64, 77, 80, 83, 89, 115, 125, 131, 146, 149, 161], 'traversability': [10, 65, 116], 'of': [11, 17, 27, 66, 82, 114, 148, 178], 'terrain': [12, 110], 'by': [13, 75, 122, 144], 'combining': [14], 'unsupervised': [15], 'learning': [16, 26], 'color': [18, 56, 81, 132], 'models': [19], 'that': [20, 171], 'predict': [21], 'scene': [22, 84], 'geometry': [23, 78], 'with': [24, 136, 152, 155], 'supervised': [25], 'relationship': [29], 'between': [30, 55], 'geometric': [31, 43, 138], 'features': [32, 44], 'and': [33, 57, 85, 97, 109], 'traversability.': [34], 'A': [35], 'neural': [36, 90], 'network': [37], 'is': [38, 71, 95, 118], 'trained': [39], 'offline': [40], 'on': [41], 'hand-labeled': [42], 'computed': [45, 159], 'from': [46, 79, 124, 130, 160, 168], 'stereo': [47, 162], 'data.': [48, 164], 'An': [49], 'online': [50, 93, 121], 'process': [51, 94], 'learns': [52], 'association': [54], 'geometry,': [58], 'enabling': [59], 'robot': [61], 'to': [62, 88, 105], 'assess': [63], 'regions': [67], 'which': [69, 100], 'there': [70], 'little': [72], 'range': [73, 163], 'information': [74], 'estimating': [76], 'passing': [86], 'this': [87], 'network.': [91], 'continuous': [96], 'extremely': [98], 'rapid,': [99], 'allows': [101], 'quick': [103], 'adaptations': [104], 'different': [106], 'lighting': [107], 'conditions': [108], 'changes.': [111], 'The': [112], 'sensitivity': [113], 'judgment': [117], 'further': [119], 'adjusted': [120], 'feedback': [123], 'robot’s': [126], 'bumper.': [127], 'Terrain': [128], 'assessments': [129], 'classifier': [133], 'are': [134], 'merged': [135], 'pure': [137], 'classifications': [139], 'in': [140, 175], 'an': [141], 'occupancy': [142], 'grid': [143], 'computing': [145], 'intersection': [147], 'ray': [150], 'associated': [151], 'pixel': [154], 'ground': [157], 'plane': [158], 'We': [165], 'present': [166], 'results': [167], 'DARPA-conducted': [169], 'tests': [170], 'demonstrate': [172], 'its': [173], 'effectiveness': [174], 'variety': [177], 'outdoor': [179], 'environments.': [180], 'I.': [181]}",2006,"['Artificial intelligence', 'Computer science', 'Terrain', 'Artificial neural network', 'Supervised learning', 'Computer vision', 'Pattern recognition (psychology)', 'Classifier (UML)', 'Intersection (aeronautics)', 'Machine learning', 'Geography', 'Cartography']","Abstract — This paper describes a method for classifying the traversability of terrain by combining unsupervised learning of color models that predict scene geometry with supervised learning of the relationship between geometric features and traversability. A neural network is trained offline on hand-labeled geometric features computed from stereo data. An online process learns the association between color and geometry, enabling the robot to assess the traversability of regions for which there is little range information by estimating the geometry from the color of the scene and passing this to the neural network. This online process is continuous and extremely rapid, which allows for quick adaptations to different lighting conditions and terrain changes. The sensitivity of the traversability judgment is further adjusted online by feedback from the robot’s bumper. Terrain assessments from the color classifier are merged with pure geometric classifications in an occupancy grid by computing the intersection of the ray associated with a pixel with a ground plane computed from the stereo range data. We present results from DARPA-conducted tests that demonstrate its effectiveness in a variety of outdoor environments. I."
https://openalex.org/W2884987480,Unsupervised Learning with Self-Organizing Spiking Neural Networks,"{'We': [0, 42], 'present': [1], 'a': [2, 5], 'system': [3], 'comprising': [4], 'hybridization': [6], 'of': [7, 19, 34, 40, 58, 61, 92], 'self-organized': [8], 'map': [9], '(SOM)\\nproperties': [10], 'with': [11, 51], 'spiking': [12, 99], 'neural': [13, 100], 'networks': [14], '(SNNs)': [15], 'that': [16], 'retain': [17], 'many': [18], 'the': [20, 62, 89], 'features\\nof': [21], 'SOMs.': [22], 'Networks': [23], 'are': [24], 'trained': [25], 'in': [26], 'an': [27], 'unsupervised': [28, 63], 'manner': [29], 'to': [30], 'learn': [31], 'a\\nself-organized': [32], 'lattice': [33], 'filters': [35], 'via': [36], 'excitatory-inhibitory': [37], 'interactions': [38], 'among\\npopulations': [39], 'neurons.': [41], 'develop': [43], 'and': [44, 54, 77], 'test': [45], 'various': [46], 'inhibition': [47], 'strategies,': [48], 'such\\nas': [49], 'growing': [50], 'inter-neuron': [52], 'distance': [53], 'two': [55], 'distinct': [56], 'levels': [57], 'inhibition.\\nThe': [59], 'quality': [60], 'learning': [64], 'algorithm': [65], 'is': [66], 'evaluated': [67], 'using': [68, 84], 'examples\\nwith': [69], 'known': [70], 'labels.': [71], 'Several': [72], 'biologically-inspired': [73], 'classification': [74], 'tools': [75], 'are\\nproposed': [76], 'compared,': [78], 'including': [79], 'population-level': [80], 'confidence': [81], 'rating,': [82], 'and\\nn-grams': [83], 'spike': [85], 'motif': [86], 'algorithm.': [87], 'Using': [88], 'optimal': [90], 'choice': [91], 'parameters,\\nour': [93], 'approach': [94], 'produces': [95], 'improvements': [96], 'over': [97], 'state-of-art': [98], 'networks.\\n': [101]}",2018,"['Computer science', 'Artificial intelligence', 'Unsupervised learning', 'Artificial neural network', 'Spiking neural network', 'Self-organizing map', 'Machine learning', 'Population', 'Pattern recognition (psychology)', 'Demography', 'Sociology']","We present a system comprising a hybridization of self-organized map (SOM)\nproperties with spiking neural networks (SNNs) that retain many of the features\nof SOMs. Networks are trained in an unsupervised manner to learn a\nself-organized lattice of filters via excitatory-inhibitory interactions among\npopulations of neurons. We develop and test various inhibition strategies, such\nas growing with inter-neuron distance and two distinct levels of inhibition.\nThe quality of the unsupervised learning algorithm is evaluated using examples\nwith known labels. Several biologically-inspired classification tools are\nproposed and compared, including population-level confidence rating, and\nn-grams using spike motif algorithm. Using the optimal choice of parameters,\nour approach produces improvements over state-of-art spiking neural networks.\n"
https://openalex.org/W2118778987,Unsupervised learning of field segmentation models for information extraction,"{'The': [0], 'applicability': [1], 'of': [2, 36, 76, 86, 95, 133, 136], 'many': [3], 'current': [4], 'information': [5], 'extraction': [6, 25], 'techniques': [7], 'is': [8], 'severely': [9], 'limited': [10], 'by': [11, 90, 118], 'the': [12, 84, 87, 96], 'need': [13], 'for': [14, 21, 61], 'supervised': [15, 119], 'training': [16], 'data.': [17, 138], 'We': [18], 'demonstrate': [19], 'that': [20, 104, 126], 'certain': [22], 'field': [23, 62], 'structured': [24, 63], 'tasks,': [26], 'such': [27], 'as': [28], 'classified': [29], 'advertisements': [30], 'and': [31, 125], 'bibliographic': [32], 'citations,': [33], 'small': [34, 134], 'amounts': [35, 135], 'prior': [37, 93], 'knowledge': [38, 94], 'can': [39, 81, 107, 129], 'be': [40], 'used': [41], 'to': [42, 70, 115], 'learn': [43, 71], 'effective': [44], 'models': [45, 54], 'in': [46, 74], 'a': [47, 57], 'primarily': [48], 'unsupervised': [49, 66, 105], 'fashion.': [50], 'Although': [51], 'hidden': [52], 'Markov': [53], '(HMMs)': [55], 'provide': [56], 'suitable': [58], 'generative': [59], 'model': [60], 'text,': [64], 'general': [65], 'HMM': [67], 'learning': [68], 'fails': [69], 'useful': [72], 'structure': [73, 89], 'either': [75], 'our': [77], 'domains.': [78], 'However,': [79], 'one': [80], 'dramatically': [82], 'improve': [83], 'quality': [85], 'learned': [88], 'exploiting': [91], 'simple': [92], 'desired': [97], 'solutions.': [98], 'In': [99], 'both': [100], 'domains,': [101], 'we': [102], 'found': [103], 'methods': [106, 120, 128], 'attain': [108], 'accuracies': [109], 'with': [110], '400': [111], 'unlabeled': [112], 'examples': [113], 'comparable': [114], 'those': [116], 'attained': [117], 'on': [121], '50': [122], 'labeled': [123, 137], 'examples,': [124], 'semi-supervised': [127], 'make': [130], 'good': [131], 'use': [132]}",2005,"['Computer science', 'Hidden Markov model', 'Artificial intelligence', 'Unsupervised learning', 'Field (mathematics)', 'Segmentation', 'Machine learning', 'Pattern recognition (psychology)', 'Information extraction', 'Generative grammar', 'Supervised learning', 'Simple (philosophy)', 'Labeled data', 'Artificial neural network', 'Mathematics', 'Epistemology', 'Philosophy', 'Pure mathematics']","The applicability of many current information extraction techniques is severely limited by the need for supervised training data. We demonstrate that for certain field structured extraction tasks, such as classified advertisements and bibliographic citations, small amounts of prior knowledge can be used to learn effective models in a primarily unsupervised fashion. Although hidden Markov models (HMMs) provide a suitable generative model for field structured text, general unsupervised HMM learning fails to learn useful structure in either of our domains. However, one can dramatically improve the quality of the learned structure by exploiting simple prior knowledge of the desired solutions. In both domains, we found that unsupervised methods can attain accuracies with 400 unlabeled examples comparable to those attained by supervised methods on 50 labeled examples, and that semi-supervised methods can make good use of small amounts of labeled data."
https://openalex.org/W1650052828,Unsupervised Learning of Invariant Representations in Hierarchical Architectures,"{'The': [0, 22, 94, 212], 'present': [1], 'phase': [2, 24], 'of': [3, 16, 32, 66, 83, 122, 143, 146, 154, 184, 192, 202, 208, 233, 237, 246], 'Machine': [4], 'Learning': [5], 'is': [6, 25, 97, 240, 250], 'characterized': [7, 73], 'by': [8, 74, 173], 'supervised': [9, 71], 'learning': [10, 33, 65, 217], 'algorithms': [11, 30], 'relying': [12], 'on': [13, 29, 61], 'large': [14], 'sets': [15], 'labeled': [17, 37], 'examples': [18, 38], '($n': [19, 39], '\\to': [20, 40], '\\infty$).': [21], 'next': [23], 'likely': [26], 'to': [27, 46, 52, 91, 110, 241, 252], 'focus': [28], 'capable': [31], 'from': [34], 'very': [35], 'few': [36], '1$),': [41], 'like': [42, 166], 'humans': [43], 'seem': [44], 'able': [45], 'do.': [47], 'We': [48, 79, 124], 'propose': [49], 'an': [50, 127, 267], 'approach': [51], 'this': [53, 185, 260], 'problem': [54], 'and': [55, 113, 129, 151, 164, 169, 175, 195, 210, 222, 255, 272], 'describe': [56], 'the': [57, 62, 81, 88, 98, 119, 147, 167, 199, 203, 229, 234], 'underlying': [58], 'theory,': [59], 'based': [60], 'unsupervised,': [63], 'automatic': [64], 'a': [67, 152, 243], ""``good''"": [68], 'representation': [69, 245, 261], 'for': [70, 136, 220, 257], 'learning,': [72], 'small': [75], 'sample': [76, 120], 'complexity': [77, 121], '($n$).': [78], 'consider': [80], 'case': [82], 'visual': [84, 204, 238, 273], 'object': [85], 'recognition': [86], 'though': [87], 'theory': [89, 213], 'applies': [90], 'other': [92, 114], 'domains.': [93], 'starting': [95], 'point': [96], 'conjecture,': [99], 'proved': [100], 'in': [101, 141, 206, 266], 'specific': [102], 'cases,': [103], 'that': [104, 126, 228, 259], 'image': [105, 138, 221], 'representations': [106], 'which': [107, 249], 'are': [108], 'invariant': [109, 128, 251], 'translations,': [111], 'scaling': [112], 'transformations': [115], 'can': [116, 133, 177], 'considerably': [117], 'reduce': [118], 'learning.': [123, 159], 'prove': [125], 'unique': [130], '(discriminative)': [131], 'signature': [132], 'be': [134, 263], 'computed': [135], 'each': [137], 'patch,': [139], '$I$,': [140], 'terms': [142, 207], 'empirical': [144], 'distributions': [145], 'dot-products': [148], 'between': [149], '$I$': [150], 'set': [153], 'templates': [155], 'stored': [156], 'during': [157, 270], 'unsupervised': [158, 268], 'A': [160], 'module': [161], 'performing': [162], 'filtering': [163], 'pooling,': [165], 'simple': [168], 'complex': [170], 'cells': [171], 'described': [172], 'Hubel': [174], 'Wiesel,': [176], 'compute': [178], 'such': [179], 'estimates.': [180], 'Hierarchical': [181], 'architectures': [182, 219], 'consisting': [183], 'basic': [186], 'Hubel-Wiesel': [187], 'moduli': [188], 'inherit': [189], 'its': [190], 'properties': [191], 'invariance,': [193], 'stability,': [194], 'discriminability': [196], 'while': [197], 'capturing': [198], 'compositional': [200], 'organization': [201], 'world': [205], 'wholes': [209], 'parts.': [211], 'extends': [214], 'existing': [215], 'deep': [216], 'convolutional': [218], 'speech': [223], 'recognition.': [224], 'It': [225], 'also': [226], 'suggests': [227], 'main': [230], 'computational': [231], 'goal': [232], 'ventral': [235], 'stream': [236], 'cortex': [239], 'provide': [242], 'hierarchical': [244], 'new': [247], 'objects/images': [248], 'transformations,': [253], 'stable,': [254], 'discriminative': [256], 'recognition---and': [258], 'may': [262], 'continuously': [264], 'learned': [265], 'way': [269], 'development': [271], 'experience.': [274]}",2013,"['Invariant (physics)', 'Pooling', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Cognitive neuroscience of visual object recognition', 'Computer science', 'Scale invariance', 'Transformation (genetics)', 'Mathematics', 'Object (grammar)', 'Biochemistry', 'Chemistry', 'Gene', 'Mathematical physics', 'Statistics']","The present phase of Machine Learning is characterized by supervised learning algorithms relying on large sets of labeled examples ($n \to \infty$). The next phase is likely to focus on algorithms capable of learning from very few labeled examples ($n \to 1$), like humans seem able to do. We propose an approach to this problem and describe the underlying theory, based on the unsupervised, automatic learning of a ``good'' representation for supervised learning, characterized by small sample complexity ($n$). We consider the case of visual object recognition though the theory applies to other domains. The starting point is the conjecture, proved in specific cases, that image representations which are invariant to translations, scaling and other transformations can considerably reduce the sample complexity of learning. We prove that an invariant and unique (discriminative) signature can be computed for each image patch, $I$, in terms of empirical distributions of the dot-products between $I$ and a set of templates stored during unsupervised learning. A module performing filtering and pooling, like the simple and complex cells described by Hubel and Wiesel, can compute such estimates. Hierarchical architectures consisting of this basic Hubel-Wiesel moduli inherit its properties of invariance, stability, and discriminability while capturing the compositional organization of the visual world in terms of wholes and parts. The theory extends existing deep learning convolutional architectures for image and speech recognition. It also suggests that the main computational goal of the ventral stream of visual cortex is to provide a hierarchical representation of new objects/images which is invariant to transformations, stable, and discriminative for recognition---and that this representation may be continuously learned in an unsupervised way during development and visual experience."
https://openalex.org/W2175711684,Unsupervised Learning of Visual Structure using Predictive Generative Networks,"{'The': [0], 'ability': [1], 'to': [2, 121, 152, 158, 176], 'predict': [3, 122], 'future': [4, 56], 'states': [5], 'of': [6, 13, 24, 30, 113, 133, 137, 164, 196], 'the': [7, 25, 31, 35, 41, 106, 134, 138], 'environment': [8], 'is': [9, 149], 'a': [10, 51, 63, 85, 95, 131, 172, 187], 'central': [11], 'pillar': [12], 'intelligence.': [14], 'At': [15], 'its': [16], 'core,': [17], 'effective': [18], 'prediction': [19, 79, 183], 'requires': [20], 'an': [21, 28], 'internal': [22, 42, 194], 'model': [23], 'world': [26, 36], 'and': [27, 99, 155], 'understanding': [29], 'rules': [32], 'by': [33, 45], 'which': [34], 'changes.': [37], 'Here,': [38], 'we': [39, 144], 'explore': [40], 'models': [43, 168], 'developed': [44], 'deep': [46], 'neural': [47], 'networks': [48], 'trained': [49, 119, 169], 'using': [50, 62], 'loss': [52, 101, 174, 190], 'based': [53], 'on': [54], 'predicting': [55], 'frames': [57], 'in': [58, 76, 84], 'synthetic': [59], 'video': [60], 'sequences,': [61], 'CNN-LSTM-deCNN': [64], 'framework.': [65], 'We': [66, 180], 'first': [67], 'show': [68], 'that': [69, 146, 182], 'this': [70, 147], 'architecture': [71, 108], 'can': [72, 184], 'achieve': [73], 'excellent': [74], 'performance': [75, 83], 'visual': [77], 'sequence': [78], 'tasks,': [80, 160], 'including': [81], 'state-of-the-art': [82], 'standard': [86], ""'bouncing"": [87], ""balls'"": [88], 'dataset': [89], '(Sutskever': [90], 'et': [91, 103], 'al.,': [92, 104], '2009).': [93], 'Using': [94], 'weighted': [96], 'mean-squared': [97], 'error': [98], 'adversarial': [100], '(Goodfellow': [102], '2014),': [105], 'same': [107], 'successfully': [109], 'extrapolates': [110], 'out-of-the-plane': [111], 'rotations': [112], 'computer-generated': [114], 'faces.': [115], 'Furthermore,': [116], 'despite': [117], 'being': [118], 'end-to-end': [120], 'only': [123], 'pixel-level': [124], 'information,': [125], 'our': [126], 'Predictive': [127], 'Generative': [128], 'Networks': [129], 'learn': [130], 'representation': [132, 148], 'latent': [135], 'structure': [136], 'underlying': [139], 'three-dimensional': [140], 'objects': [141], 'themselves.': [142], 'Importantly,': [143], 'find': [145], 'naturally': [150], 'tolerant': [151], 'object': [153, 198], 'transformations,': [154], 'generalizes': [156], 'well': [157], 'new': [159], 'such': [161], 'as': [162, 178, 186], 'classification': [163], 'static': [165], 'images.': [166], 'Similar': [167], 'solely': [170], 'with': [171], 'reconstruction': [173], 'fail': [175], 'generalize': [177], 'effectively.': [179], 'argue': [181], 'serve': [185], 'powerful': [188], 'unsupervised': [189], 'for': [191], 'learning': [192], 'rich': [193], 'representations': [195], 'high-level': [197], 'features.': [199]}",2015,"['Computer science', 'Artificial intelligence', 'Representation (politics)', 'Generative grammar', 'Object (grammar)', 'Machine learning', 'Unsupervised learning', 'Feature learning', 'Artificial neural network', 'Generative model', 'Pattern recognition (psychology)', 'Political science', 'Law', 'Politics']","The ability to predict future states of the environment is a central pillar of intelligence. At its core, effective prediction requires an internal model of the world and an understanding of the rules by which the world changes. Here, we explore the internal models developed by deep neural networks trained using a loss based on predicting future frames in synthetic video sequences, using a CNN-LSTM-deCNN framework. We first show that this architecture can achieve excellent performance in visual sequence prediction tasks, including state-of-the-art performance in a standard 'bouncing balls' dataset (Sutskever et al., 2009). Using a weighted mean-squared error and adversarial loss (Goodfellow et al., 2014), the same architecture successfully extrapolates out-of-the-plane rotations of computer-generated faces. Furthermore, despite being trained end-to-end to predict only pixel-level information, our Predictive Generative Networks learn a representation of the latent structure of the underlying three-dimensional objects themselves. Importantly, we find that this representation is naturally tolerant to object transformations, and generalizes well to new tasks, such as classification of static images. Similar models trained solely with a reconstruction loss fail to generalize as effectively. We argue that prediction can serve as a powerful unsupervised loss for learning rich internal representations of high-level object features."
https://openalex.org/W2921565324,Unsupervised Learning Reveals Geography of Global Ocean Dynamical Regions,"{'Dynamically': [0], 'similar': [1], 'regions': [2, 143], 'of': [3, 19, 26, 57, 119, 129, 154], 'the': [4, 20, 22, 27, 43, 58, 69, 74, 84, 88, 104, 110, 130, 137, 146, 158], 'global': [5], 'ocean': [6, 59], 'are': [7, 66], 'identified': [8], 'using': [9], 'a': [10, 16, 100], 'barotropic': [11], 'vorticity': [12], '(BV)': [13], 'framework': [14], 'from': [15], '20‐year': [17], 'mean': [18], 'Estimating': [21], 'Circulation': [23], 'and': [24, 62, 73, 112, 161], 'Climate': [25], 'Ocean': [28, 160], 'state': [29], 'estimate': [30], 'at': [31], '1°': [32], 'resolution.': [33], 'An': [34], 'unsupervised': [35], 'machine': [36], 'learning': [37], 'algorithm,': [38], 'K': [39], '‐means,': [40], 'objectively': [41], 'clusters': [42], 'standardized': [44], 'BV': [45, 147], 'equation,': [46], 'identifying': [47], 'five': [48], 'unambiguous': [49], 'regimes.': [50], 'Cluster': [51, 77, 92, 120, 132], '1': [52], 'covers': [53, 79, 94], '43': [54], '±': [55, 81, 96, 127], '3.3%': [56], 'area.': [60], 'Surface': [61], 'bottom': [63, 70, 89, 113], 'stress': [64, 114], 'torque': [65, 72], 'balanced': [67, 108], 'by': [68, 99, 109], 'pressure': [71, 90], 'nonlinear': [75], 'torque.': [76, 91], '2': [78], '24.8': [80], '1.2%,': [82], 'where': [83, 103, 145], 'beta': [85, 105], 'effect': [86, 106], 'balances': [87], '3': [93], '14.6': [95], '1.0%,': [97], 'characterized': [98], '“Quasi‐Sverdrupian”': [101], 'regime': [102], 'is': [107, 149], 'wind': [111], 'term.': [115], 'The': [116], 'small': [117], 'region': [118], '4': [121], 'has': [122], 'baroclinic': [123], 'dynamics': [124], 'covering': [125], '6.9': [126], '2.9%': [128], 'ocean.': [131], '5': [133], 'occurs': [134], 'primarily': [135], 'in': [136, 152, 157], 'Southern': [138, 159], 'Ocean.': [139], 'Residual': [140], '“dominantly': [141], 'nonlinear”': [142], 'highlight': [144], 'approach': [148], 'inadequate,': [150], 'found': [151], 'areas': [153], 'rough': [155], 'topography': [156], 'along': [162], 'western': [163], 'boundaries.': [164]}",2019,"['Geography', 'Climatology', 'Geology', 'Oceanography']","Dynamically similar regions of the global ocean are identified using a barotropic vorticity (BV) framework from a 20‐year mean of the Estimating the Circulation and Climate of the Ocean state estimate at 1° resolution. An unsupervised machine learning algorithm, K ‐means, objectively clusters the standardized BV equation, identifying five unambiguous regimes. Cluster 1 covers 43 ± 3.3% of the ocean area. Surface and bottom stress torque are balanced by the bottom pressure torque and the nonlinear torque. Cluster 2 covers 24.8 ± 1.2%, where the beta effect balances the bottom pressure torque. Cluster 3 covers 14.6 ± 1.0%, characterized by a “Quasi‐Sverdrupian” regime where the beta effect is balanced by the wind and bottom stress term. The small region of Cluster 4 has baroclinic dynamics covering 6.9 ± 2.9% of the ocean. Cluster 5 occurs primarily in the Southern Ocean. Residual “dominantly nonlinear” regions highlight where the BV approach is inadequate, found in areas of rough topography in the Southern Ocean and along western boundaries."
https://openalex.org/W2949678110,Unsupervised Learning of Object Landmarks through Conditional Image\n Generation,"{'We': [0, 24, 125, 148], 'propose': [1], 'a': [2, 18, 41, 53, 63, 77, 119, 156], 'method': [3, 152], 'for': [4, 8], 'learning': [5], 'landmark': [6, 146], 'detectors': [7], 'visual': [9], 'objects': [10], '(such\\nas': [11], 'the': [12, 15, 27, 34, 46, 49, 58, 81, 115], 'eyes': [13], 'and': [14, 74, 107, 109, 165], 'nose': [16], 'in': [17, 40, 80], 'face)': [19], 'without': [20, 140, 168], 'any': [21, 169], 'manual': [22, 141], 'supervision.': [23], 'cast\\nthis': [25], 'as': [26, 38, 51], 'problem': [28], 'of': [29, 36, 48, 159], 'generating': [30], 'images': [31], 'that': [32, 84, 117, 127], 'combine': [33], 'appearance': [35, 73, 106], 'the\\nobject': [37], 'seen': [39], 'first': [42], 'example': [43, 55], 'image': [44, 92, 135], 'with': [45], 'geometry': [47, 108], 'object': [50, 67, 132], 'seen\\nin': [52], 'second': [54], 'image,': [56], 'where': [57], 'two': [59], 'examples': [60], 'differ': [61], 'by': [62], 'viewpoint': [64], 'change\\nand/or': [65], 'an': [66], 'deformation.': [68], 'In': [69], 'order': [70], 'to': [71, 90, 114, 155], 'factorize': [72], 'geometry,': [75], 'we\\nintroduce': [76], 'tight': [78], 'bottleneck': [79], 'geometry-extraction': [82], 'process': [83], 'selects\\nand': [85], 'distils': [86], 'geometry-related': [87], 'features.': [88], 'Compared': [89], 'standard': [91], 'generation\\nproblems,': [93], 'which': [94], 'often': [95], 'use': [96], 'generative': [97], 'adversarial': [98], 'networks,': [99], 'our': [100, 128, 151], 'generation': [101], 'task\\nis': [102], 'conditioned': [103], 'on': [104], 'both': [105], 'thus': [110], 'is': [111, 153], 'significantly': [112], 'less\\nambiguous,': [113], 'point': [116], 'adopting': [118], 'simple': [120], 'perceptual': [121], 'loss': [122], 'formulation': [123], 'is\\nsufficient.': [124], 'demonstrate': [126], 'approach': [129], 'can': [130], 'learn': [131], 'landmarks': [133], 'from\\nsynthetic': [134], 'deformations': [136], 'or': [137], 'videos,': [138], 'all': [139], 'supervision,': [142], 'while\\noutperforming': [143], 'state-of-the-art': [144], 'unsupervised': [145], 'detectors.': [147], 'further': [149], 'show\\nthat': [150], 'applicable': [154], 'large': [157], 'variety': [158], 'datasets': [160], '-': [161, 167], 'faces,': [162], 'people,\\n3D': [163], 'objects,': [164], 'digits': [166], 'modifications.\\n': [170]}",2018,"['Artificial intelligence', 'Landmark', 'Computer science', 'Object (grammar)', 'Computer vision', 'Face (sociological concept)', 'Image (mathematics)', 'Point cloud', 'Generative model', 'Object detection', 'Point (geometry)', 'Pattern recognition (psychology)', 'Generative grammar', 'Geometry', 'Mathematics', 'Sociology', 'Social science']","We propose a method for learning landmark detectors for visual objects (such\nas the eyes and the nose in a face) without any manual supervision. We cast\nthis as the problem of generating images that combine the appearance of the\nobject as seen in a first example image with the geometry of the object as seen\nin a second example image, where the two examples differ by a viewpoint change\nand/or an object deformation. In order to factorize appearance and geometry, we\nintroduce a tight bottleneck in the geometry-extraction process that selects\nand distils geometry-related features. Compared to standard image generation\nproblems, which often use generative adversarial networks, our generation task\nis conditioned on both appearance and geometry and thus is significantly less\nambiguous, to the point that adopting a simple perceptual loss formulation is\nsufficient. We demonstrate that our approach can learn object landmarks from\nsynthetic image deformations or videos, all without manual supervision, while\noutperforming state-of-the-art unsupervised landmark detectors. We further show\nthat our method is applicable to a large variety of datasets - faces, people,\n3D objects, and digits - without any modifications.\n"
https://openalex.org/W2187800623,Unsupervised learning by program synthesis,"{'We': [0], 'introduce': [1], 'an': [2], 'unsupervised': [3, 59], 'learning': [4, 22, 27, 60], 'algorithmthat': [5], 'combines': [6], 'probabilistic': [7], 'modeling': [8], 'with': [9], 'solver-based': [10], 'techniques': [11, 17], 'for': [12, 67], 'program': [13, 69], 'synthesis.We': [14], 'apply': [15], 'our': [16, 30], 'to': [18, 58, 72], 'both': [19, 54], 'a': [20, 25, 39, 55, 65], 'visual': [21, 35], 'domain': [23], 'and': [24], 'language': [26], 'problem,showing': [28], 'that': [29, 42], 'algorithm': [31], 'can': [32, 44], 'learn': [33], 'many': [34], 'concepts': [36], 'from': [37], 'only': [38], 'few': [40], 'examplesand': [41], 'it': [43], 'recover': [45], 'some': [46], 'English': [47], 'inflectional': [48], 'morphology.Taken': [49], 'together,': [50], 'these': [51], 'results': [52], 'give': [53], 'new': [56], 'approach': [57], 'of': [61], 'symbolic': [62], 'compositional': [63], 'structures,and': [64], 'technique': [66], 'applying': [68], 'synthesis': [70], 'tools': [71], 'noisy': [73], 'data.': [74]}",2015,"['Computer science', 'Unsupervised learning', 'Artificial intelligence', 'Probabilistic logic', 'Program synthesis', 'Machine learning', 'Domain (mathematical analysis)', 'Theoretical computer science', 'Mathematics', 'Mathematical analysis']","We introduce an unsupervised learning algorithmthat combines probabilistic modeling with solver-based techniques for program synthesis.We apply our techniques to both a visual learning domain and a language learning problem,showing that our algorithm can learn many visual concepts from only a few examplesand that it can recover some English inflectional morphology.Taken together, these results give both a new approach to unsupervised learning of symbolic compositional structures,and a technique for applying program synthesis tools to noisy data."
https://openalex.org/W2774064151,Unsupervised Learning for Cell-Level Visual Representation in Histopathology Images With Generative Adversarial Networks,"{'The': [0], 'visual': [1, 22, 69, 113], 'attributes': [2], 'of': [3, 30, 63, 88, 103, 125, 135], 'cells,': [4], 'such': [5, 39], 'as': [6, 40], 'the': [7, 100, 110, 123, 133], 'nuclear': [8], 'morphology': [9], 'and': [10, 45, 82], 'chromatin': [11], 'openness,': [12], 'are': [13, 33, 137], 'critical': [14], 'for': [15, 36], 'histopathology': [16, 130], 'image': [17, 131], 'analysis.': [18], 'By': [19], 'learning': [20, 71], 'cell-level': [21, 41, 68, 89, 112], 'representation,': [23], 'we': [24, 51, 116], 'can': [25], 'obtain': [26], 'a': [27, 53, 60, 119], 'rich': [28], 'mix': [29], 'features': [31], 'that': [32, 121], 'highly': [34], 'reusable': [35], 'various': [37], 'tasks,': [38], 'classification,': [42, 132], 'nuclei': [43], 'segmentation,': [44], 'cell': [46], 'counting.': [47], 'In': [48], 'this': [49], 'paper,': [50], 'propose': [52], 'unified': [54], 'generative': [55], 'adversarial': [56], 'networks': [57], 'architecture': [58], 'with': [59, 92], 'new': [61], 'formulation': [62], 'loss': [64], 'to': [65, 128], 'perform': [66, 129], 'robust': [67], 'representation': [70, 114], 'in': [72, 99], 'an': [73], 'unsupervised': [74, 90, 101], 'setting.': [75], 'Our': [76], 'model': [77], 'is': [78], 'not': [79], 'only': [80], 'label-free': [81], 'easily': [83], 'trained': [84], 'but': [85], 'also': [86], 'capable': [87], 'classification': [91, 102], 'interpretable': [93], 'visualization,': [94], 'which': [95, 136], 'achieves': [96], 'promising': [97], 'results': [98], 'bone': [104, 140], 'marrow': [105, 141], 'cellular': [106, 126], 'components.': [107], 'Based': [108], 'on': [109, 139], 'proposed': [111], 'learning,': [115], 'further': [117], 'develop': [118], 'pipeline': [120], 'exploits': [122], 'varieties': [124], 'elements': [127], 'advantages': [134], 'demonstrated': [138], 'datasets.': [142]}",2018,"['Artificial intelligence', 'Computer science', 'Representation (politics)', 'Adversarial system', 'Pattern recognition (psychology)', 'Generative grammar', 'Computer vision', 'Politics', 'Political science', 'Law']","The visual attributes of cells, such as the nuclear morphology and chromatin openness, are critical for histopathology image analysis. By learning cell-level visual representation, we can obtain a rich mix of features that are highly reusable for various tasks, such as cell-level classification, nuclei segmentation, and cell counting. In this paper, we propose a unified generative adversarial networks architecture with a new formulation of loss to perform robust cell-level visual representation learning in an unsupervised setting. Our model is not only label-free and easily trained but also capable of cell-level unsupervised classification with interpretable visualization, which achieves promising results in the unsupervised classification of bone marrow cellular components. Based on the proposed cell-level visual representation learning, we further develop a pipeline that exploits the varieties of cellular elements to perform histopathology image classification, the advantages of which are demonstrated on bone marrow datasets."
https://openalex.org/W2962736171,Deep unsupervised learning using nonequilibrium thermodynamics,"{'A': [0], 'central': [1], 'problem': [2], 'in': [3, 17, 57, 77, 102], 'machine': [4], 'learning': [5], 'involves': [6], 'modeling': [7], 'complex': [8], 'data-sets': [9], 'using': [10], 'highly': [11, 81], 'flexi-ble': [12], 'families': [13], 'of': [14, 87, 108, 134], 'probability': [15], 'distributions': [16], 'which': [18], 'learning,': [19], 'sampling,': [20], 'inference,': [21], 'and': [22, 40, 53, 83, 99, 119], 'evaluation': [23], 'are': [24], 'still': [25], 'analytically': [26], 'or': [27, 110], 'computationally': [28], 'tractable.': [29], 'Here,': [30], 'we': [31], 'develop': [32], 'an': [33, 62, 129], 'approach': [34], 'that': [35, 74], 'simultane-ously': [36], 'achieves': [37], 'both': [38], 'flexibility': [39], 'tractability.': [41], 'The': [42], 'essential': [43], 'idea,': [44], 'inspired': [45], 'by': [46], 'non-equilibrium': [47], 'statistical': [48], 'physics,': [49], 'is': [50], 'to': [51, 94, 116], 'systematically': [52], 'slowly': [54], 'destroy': [55], 'structure': [56, 76], 'a': [58, 70, 80], 'data': [59], 'distribution': [60], 'through': [61], 'iterative': [63], 'forward': [64], 'diffusion': [65, 72], 'process.': [66], 'We': [67, 126], 'then': [68], 'learn': [69], 'reverse': [71], 'process': [73], 'restores': [75], 'data,': [78], 'yielding': [79], 'flexible': [82], 'tractable': [84], 'generative': [85, 104], 'model': [86], 'the': [88, 123, 135], 'data.': [89], 'This': [90], 'ap-proach': [91], 'allows': [92], 'us': [93], 'rapidly': [95], 'learn,': [96], 'sample': [97], 'from,': [98], 'evaluate': [100], 'probabilities': [101, 121], 'deep': [103], 'models': [105], 'with': [106], 'thousands': [107], 'layers': [109], 'time': [111], 'steps,': [112], 'as': [113, 115], 'well': [114], 'compute': [117], 'conditional': [118], 'posterior': [120], 'under': [122], 'learned': [124], 'model.': [125], 'addi-tionally': [127], 'release': [128], 'open': [130], 'source': [131], 'reference': [132], 'imple-mentation': [133], 'algorithm.': [136], '1.': [137]}",2024,"['Computer science', 'Generative model', 'Inference', 'Flexibility (engineering)', 'Artificial intelligence', 'Generative grammar', 'Machine learning', 'Unsupervised learning', 'Process (computing)', 'Conditional probability distribution', 'Probability distribution', 'Algorithm', 'Mathematics', 'Operating system', 'Statistics']","A central problem in machine learning involves modeling complex data-sets using highly flexi-ble families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultane-ously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This ap-proach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We addi-tionally release an open source reference imple-mentation of the algorithm. 1."
https://openalex.org/W2804034251,Unsupervised Learning with Stein's Unbiased Risk Estimator,"{'Learning': [0], 'from': [1, 87, 119], 'unlabeled': [2], 'and': [3, 52, 70, 107, 147, 190, 205, 227, 244], 'noisy': [4, 89, 122, 232], 'data': [5, 104, 153], 'is': [6, 81, 105, 135, 154], 'one': [7, 100, 108], 'of': [8, 12, 22, 48, 67, 93, 113, 143, 176, 181, 241], 'the': [9, 46, 94, 120, 131, 136, 141, 169, 182, 199, 242], 'grand': [10], 'challenges': [11], 'machine': [13], 'learning.': [14], 'As': [15], 'such,': [16], 'it': [17], 'has': [18], 'seen': [19], 'a': [20, 34, 65, 88, 221, 230], 'flurry': [21], 'research': [23], 'with': [24, 173, 224], 'new': [25], 'ideas': [26], 'proposed': [27], 'continuously.': [28], 'In': [29, 194], 'this': [30, 161, 179, 248], 'work,': [31], 'we': [32, 110, 184, 196], 'revisit': [33], 'classical': [35], 'idea:': [36], ""Stein's"": [37], 'Unbiased': [38], 'Risk': [39], 'Estimator': [40], '(SURE).': [41], 'We': [42, 96, 157], 'show': [43, 158], 'that,': [44], 'in': [45, 140, 160, 216, 247], 'context': [47, 142], 'image': [49, 68, 85, 233], 'recovery,': [50], 'SURE': [51, 163, 200], 'its': [53], 'generalizations': [54], 'can': [55, 164, 234, 250], 'be': [56, 165, 251], 'used': [57, 166], 'to': [58, 82, 130, 167, 187, 202, 229], 'train': [59, 185], 'convolutional': [60], 'neural': [61], 'networks': [62, 186, 243], '(CNNs)': [63], 'for': [64, 138], 'range': [66], 'denoising': [69, 189], 'recovery': [71], 'problems': [72], 'without': [73], 'any': [74], 'ground': [75, 151], 'truth': [76, 152], 'data.': [77], 'Specifically,': [78], 'our': [79], 'goal': [80], 'reconstruct': [83], 'an': [84, 174, 208], '$x$': [86], 'linear': [90], 'transformation': [91], '(measurement)': [92], 'image.': [95, 238], 'consider': [97], 'two': [98], 'scenarios:': [99], 'where': [101, 109, 149], 'no': [102, 128], 'additional': [103], 'available': [106], 'have': [111, 127], 'measurements': [112], 'other': [114], 'images': [115], 'that': [116, 159, 220, 237], 'are': [117], 'drawn': [118], 'same': [121], 'distribution': [123], 'as': [124], '$x$,': [125], 'but': [126], 'access': [129], 'clean': [132], 'images.': [133], 'Such': [134], 'case,': [137], 'instance,': [139], 'medical': [144], 'imaging,': [145], 'microscopy,': [146], 'astronomy,': [148], 'noise-less': [150], 'rarely': [155], 'available.': [156], 'situation,': [162], 'estimate': [168, 175, 180], 'mean-squared-error': [170], 'loss': [171], 'associated': [172], '$x$.': [177], 'Using': [178], 'loss,': [183], 'perform': [188], 'compressed': [191], 'sensing': [192], 'recovery.': [193], 'addition,': [195], 'also': [197], 'use': [198], 'framework': [201], 'partially': [203], 'explain': [204], 'improve': [206], 'upon': [207], 'intriguing': [209], 'results': [210], 'presented': [211], 'by': [212], 'Ulyanov': [213], 'et': [214], 'al.': [215], '""Deep': [217], 'Image': [218], 'Prior"":': [219], 'network': [222], 'initialized': [223], 'random': [225], 'weights': [226], 'fit': [228], 'single': [231], 'effectively': [235], 'denoise': [236], 'Public': [239], 'implementations': [240], 'methods': [245], 'described': [246], 'paper': [249], 'found': [252], 'at': [253], 'https://github.com/ricedsp/D-AMP_Toolbox.': [254]}",2018,"['Estimator', 'Ground truth', 'Context (archaeology)', 'Convolutional neural network', 'Computer science', 'Image (mathematics)', 'Noise reduction', 'Artificial intelligence', 'Noise (video)', 'Transformation (genetics)', 'Mean squared error', 'Deep learning', 'Range (aeronautics)', 'Supervised learning', 'Pattern recognition (psychology)', 'Algorithm', 'Artificial neural network', 'Machine learning', 'Mathematics', 'Statistics', 'Biology', 'Chemistry', 'Paleontology', 'Biochemistry', 'Materials science', 'Gene', 'Composite material']","Learning from unlabeled and noisy data is one of the grand challenges of machine learning. As such, it has seen a flurry of research with new ideas proposed continuously. In this work, we revisit a classical idea: Stein's Unbiased Risk Estimator (SURE). We show that, in the context of image recovery, SURE and its generalizations can be used to train convolutional neural networks (CNNs) for a range of image denoising and recovery problems without any ground truth data. Specifically, our goal is to reconstruct an image $x$ from a noisy linear transformation (measurement) of the image. We consider two scenarios: one where no additional data is available and one where we have measurements of other images that are drawn from the same noisy distribution as $x$, but have no access to the clean images. Such is the case, for instance, in the context of medical imaging, microscopy, and astronomy, where noise-less ground truth data is rarely available. We show that in this situation, SURE can be used to estimate the mean-squared-error loss associated with an estimate of $x$. Using this estimate of the loss, we train networks to perform denoising and compressed sensing recovery. In addition, we also use the SURE framework to partially explain and improve upon an intriguing results presented by Ulyanov et al. in ""Deep Image Prior"": that a network initialized with random weights and fit to a single noisy image can effectively denoise that image. Public implementations of the networks and methods described in this paper can be found at https://github.com/ricedsp/D-AMP_Toolbox."
https://openalex.org/W2964032613,Unsupervised Learning via Meta-Learning,"{'A': [0], 'central': [1], 'goal': [2], 'of': [3, 23, 29, 70, 75, 121, 152], 'unsupervised': [4, 34, 57, 134, 164], 'learning': [5, 22, 35, 139, 165], 'is': [6, 146], 'to': [7, 38, 66, 115, 148], 'acquire': [8], 'representations': [9], 'from': [10, 26, 72, 83], 'unlabeled': [11, 84], 'data': [12, 85, 144], 'or': [13], 'experience': [14], 'that': [15, 60, 132, 145], 'can': [16], 'be': [17], 'used': [18], 'for': [19, 63], 'more': [20], 'effective': [21], 'downstream': [24, 153], 'tasks': [25, 71, 82], 'modest': [27], 'amounts': [28, 74], 'labeled': [30, 143], 'data.': [31, 76], 'Many': [32], 'prior': [33, 163], 'works': [36], 'aim': [37], 'do': [39, 78], 'so': [40], 'by': [41, 161], 'developing': [42], 'proxy': [43], 'objectives': [44], 'based': [45], 'on': [46, 118], 'reconstruction,': [47], 'disentanglement,': [48], 'prediction,': [49], 'and': [50, 90], 'other': [51], 'metrics.': [52], 'Instead,': [53], 'we': [54, 80, 98], 'develop': [55], 'an': [56, 87], 'meta-learning': [58, 92, 135], 'method': [59], 'explicitly': [61], 'optimizes': [62], 'the': [64, 94, 158], 'ability': [65], 'learn': [67], 'a': [68, 119, 138, 149], 'variety': [69, 120], 'small': [73], 'To': [77], 'so,': [79], 'construct': [81], 'in': [86], 'automatic': [88], 'way': [89], 'run': [91], 'over': [93], 'constructed': [95], 'tasks.': [96, 124], 'Surprisingly,': [97], 'find': [99], 'that,': [100], 'when': [101], 'integrated': [102], 'with': [103], 'meta-learning,': [104], 'relatively': [105], 'simple': [106], 'task': [107], 'construction': [108], 'mechanisms,': [109], 'such': [110], 'as': [111], 'clustering': [112], 'embeddings,': [113], 'lead': [114], 'good': [116], 'performance': [117], 'downstream,': [122], 'human-specified': [123], 'Our': [125], 'experiments': [126], 'across': [127], 'four': [128, 162], 'image': [129], 'datasets': [130], 'indicate': [131], 'our': [133], 'approach': [136], 'acquires': [137], 'algorithm': [140], 'without': [141], 'any': [142], 'applicable': [147], 'wide': [150], 'range': [151], 'classification': [154], 'tasks,': [155], 'improving': [156], 'upon': [157], 'embedding': [159], 'learned': [160], 'methods.': [166]}",2018,"['Unsupervised learning', 'Computer science', 'Machine learning', 'Meta learning (computer science)', 'Artificial intelligence', 'Cluster analysis', 'Embedding', 'Competitive learning', 'Feature learning', 'Task (project management)', 'Conceptual clustering', 'Construct (python library)', 'Semi-supervised learning', 'Variety (cybernetics)', 'Multi-task learning', 'Fuzzy clustering', 'Programming language', 'Management', 'Economics', 'CURE data clustering algorithm']","A central goal of unsupervised learning is to acquire representations from unlabeled data or experience that can be used for more effective learning of downstream tasks from modest amounts of labeled data. Many prior unsupervised learning works aim to do so by developing proxy objectives based on reconstruction, disentanglement, prediction, and other metrics. Instead, we develop an unsupervised meta-learning method that explicitly optimizes for the ability to learn a variety of tasks from small amounts of data. To do so, we construct tasks from unlabeled data in an automatic way and run meta-learning over the constructed tasks. Surprisingly, we find that, when integrated with meta-learning, relatively simple task construction mechanisms, such as clustering embeddings, lead to good performance on a variety of downstream, human-specified tasks. Our experiments across four image datasets indicate that our unsupervised meta-learning approach acquires a learning algorithm without any labeled data that is applicable to a wide range of downstream classification tasks, improving upon the embedding learned by four prior unsupervised learning methods."
https://openalex.org/W2071325675,Multiple Kernel Sparse Representations for Supervised and Unsupervised Learning,"{'In': [0, 75, 111], 'complex': [1], 'visual': [2], 'recognition': [3, 23, 145], 'tasks,': [4], 'it': [5], 'is': [6, 109], 'typical': [7], 'to': [8, 50, 80, 162], 'adopt': [9], 'multiple': [10, 89, 119], 'descriptors,': [11], 'which': [12], 'describe': [13], 'different': [14], 'aspects': [15], 'of': [16, 95, 121], 'the': [17, 51, 58, 88, 93, 96, 126, 130], 'images,': [18], 'for': [19, 68, 143], 'obtaining': [20], 'an': [21], 'improved': [22], 'performance.': [24], 'Descriptors': [25], 'that': [26, 47, 106, 150], 'have': [27], 'diverse': [28], 'forms': [29], 'can': [30, 54, 65], 'be': [31, 55, 66], 'fused': [32], 'into': [33], 'a': [34, 39, 136], 'unified': [35, 59], 'feature': [36], 'space': [37], 'in': [38, 57, 70, 87, 125], 'principled': [40], 'manner': [41], 'using': [42, 118, 135], 'kernel': [43, 60, 90, 98, 127], 'methods.': [44, 165], 'Sparse': [45], 'models': [46], 'generalize': [48], 'well': [49], 'test': [52], 'data': [53], 'learned': [56], 'space,': [61, 91, 128], 'and': [62, 72, 84, 129, 146, 159], 'appropriate': [63], 'constraints': [64], 'incorporated': [67], 'application': [69], 'supervised': [71], 'unsupervised': [73], 'learning.': [74], 'this': [76], 'paper,': [77], 'we': [78], 'propose': [79], 'perform': [81], 'sparse': [82, 131, 155], 'coding': [83, 156], 'dictionary': [85], 'learning': [86], 'where': [92], 'weights': [94], 'ensemble': [97], 'are': [99, 116, 133], 'tuned': [100], 'based': [101, 157], 'on': [102], 'graph-embedding': [103], 'principles': [104], 'such': [105], 'class': [107], 'discrimination': [108], 'maximized.': [110], 'our': [112, 151], 'proposed': [113], 'algorithm,': [114], 'dictionaries': [115], 'inferred': [117], 'levels': [120], '1D': [122], 'subspace': [123], 'clustering': [124, 148], 'codes': [132], 'obtained': [134], 'simple': [137], 'levelwise': [138], 'pursuit': [139], 'scheme.': [140], 'Empirical': [141], 'results': [142], 'object': [144], 'image': [147], 'show': [149], 'algorithm': [152], 'outperforms': [153], 'existing': [154], 'approaches,': [158], 'compares': [160], 'favorably': [161], 'other': [163], 'state-of-the-art': [164]}",2014,[],"In complex visual recognition tasks, it is typical to adopt multiple descriptors, which describe different aspects of the images, for obtaining an improved recognition performance. Descriptors that have diverse forms can be fused into a unified feature space in a principled manner using kernel methods. Sparse models that generalize well to the test data can be learned in the unified kernel space, and appropriate constraints can be incorporated for application in supervised and unsupervised learning. In this paper, we propose to perform sparse coding and dictionary learning in the multiple kernel space, where the weights of the ensemble kernel are tuned based on graph-embedding principles such that class discrimination is maximized. In our proposed algorithm, dictionaries are inferred using multiple levels of 1D subspace clustering in the kernel space, and the sparse codes are obtained using a simple levelwise pursuit scheme. Empirical results for object recognition and image clustering show that our algorithm outperforms existing sparse coding based approaches, and compares favorably to other state-of-the-art methods."
https://openalex.org/W4328117340,Unsupervised Learning Methods for Data-Driven Vibration-Based Structural Health Monitoring: A Review,"{'Structural': [0], 'damage': [1, 61], 'detection': [2, 62, 97], 'using': [3, 98], 'unsupervised': [4, 29, 85, 109], 'learning': [5, 30, 86, 110], 'methods': [6, 31, 87, 174], 'has': [7], 'been': [8], 'a': [9, 89, 122], 'trending': [10], 'topic': [11], 'in': [12, 57, 64, 118, 130, 163, 196], 'the': [13, 21, 25, 42, 79, 104, 127, 135, 144, 158, 164, 183], 'structural': [14, 75], 'health': [15, 76], 'monitoring': [16, 77], '(SHM)': [17], 'research': [18, 176], 'community': [19], 'during': [20], 'past': [22], 'decades.': [23], 'In': [24, 67], 'context': [26], 'of': [27, 137], 'SHM,': [28, 132], 'rely': [32], 'only': [33], 'on': [34, 73, 84, 91], 'data': [35, 100], 'acquired': [36], 'from': [37, 78, 175], 'intact': [38], 'structures': [39], 'for': [40, 108, 190], 'training': [41], 'statistical': [43], 'models.': [44], 'Consequently,': [45], 'they': [46], 'are': [47, 147], 'often': [48], 'seen': [49], 'as': [50], 'more': [51, 116, 198], 'practical': [52, 178], 'than': [53], 'their': [54], 'supervised': [55], 'counterpart': [56], 'implementing': [58], 'an': [59], 'early-warning': [60], 'system': [63], 'civil': [65], 'structures.': [66], 'this': [68, 119], 'article,': [69], 'we': [70, 125, 181], 'review': [71], 'publications': [72], 'data-driven': [74], 'last': [80], 'decade': [81], 'that': [82, 146, 167], 'relies': [83], 'with': [88], 'focus': [90], 'real-world': [92], 'application': [93], 'and': [94, 112, 161, 187], 'practicality.': [95], 'Novelty': [96], 'vibration': [99], 'is': [101], 'by': [102, 134], 'far': [103], 'most': [105], 'common': [106], 'approach': [107], 'SHM': [111, 153, 173, 200], 'is,': [113], 'therefore,': [114], 'given': [115], 'attention': [117], 'article.': [120], 'Following': [121], 'brief': [123], 'introduction,': [124], 'present': [126], 'state-of-the-art': [128], 'studies': [129], 'unsupervised-learning': [131, 152], 'categorized': [133], 'types': [136], 'used': [138, 149], 'machine-learning': [139], 'methods.': [140, 154, 201], 'We': [141, 155], 'then': [142], 'examine': [143], 'benchmarks': [145], 'commonly': [148], 'to': [150, 171, 177, 193], 'validate': [151], 'also': [156], 'discuss': [157], 'main': [159], 'challenges': [160], 'limitations': [162], 'existing': [165], 'literature': [166], 'make': [168], 'it': [169], 'difficult': [170], 'translate': [172], 'applications.': [179], 'Accordingly,': [180], 'outline': [182], 'current': [184], 'knowledge': [185], 'gaps': [186], 'provide': [188], 'recommendations': [189], 'future': [191], 'directions': [192], 'assist': [194], 'researchers': [195], 'developing': [197], 'reliable': [199]}",2023,"['Structural health monitoring', 'Unsupervised learning', 'Novelty detection', 'Computer science', 'Machine learning', 'Context (archaeology)', 'Artificial intelligence', 'Novelty', 'Data science', 'Engineering', 'Philosophy', 'Biology', 'Structural engineering', 'Theology', 'Paleontology']","Structural damage detection using unsupervised learning methods has been a trending topic in the structural health monitoring (SHM) research community during the past decades. In the context of SHM, unsupervised learning methods rely only on data acquired from intact structures for training the statistical models. Consequently, they are often seen as more practical than their supervised counterpart in implementing an early-warning damage detection system in civil structures. In this article, we review publications on data-driven structural health monitoring from the last decade that relies on unsupervised learning methods with a focus on real-world application and practicality. Novelty detection using vibration data is by far the most common approach for unsupervised learning SHM and is, therefore, given more attention in this article. Following a brief introduction, we present the state-of-the-art studies in unsupervised-learning SHM, categorized by the types of used machine-learning methods. We then examine the benchmarks that are commonly used to validate unsupervised-learning SHM methods. We also discuss the main challenges and limitations in the existing literature that make it difficult to translate SHM methods from research to practical applications. Accordingly, we outline the current knowledge gaps and provide recommendations for future directions to assist researchers in developing more reliable SHM methods."
https://openalex.org/W2777416523,Mol2vec: Unsupervised Machine Learning Approach with Chemical Intuition,"{'Inspired': [0], 'by': [1, 58], 'natural\\nlanguage': [2], 'processing': [3], 'techniques,': [4], 'we': [5], 'here': [6], 'introduce\\nMol2vec,': [7], 'which': [8, 153], 'is': [9, 105, 167], 'an': [10, 85], 'unsupervised': [11, 86], 'machine': [12, 71, 87], 'learning': [13, 72, 88], 'approach': [14, 89, 165], 'to': [15, 74], 'learn\\nvector': [16], 'representations': [17, 40], 'of': [18, 26, 41, 61, 93, 97, 114], 'molecular': [19], 'substructures.': [20], 'Like': [21], 'the': [22, 34, 62, 155], 'Word2vec\\nmodels,': [23], 'where': [24], 'vectors': [25, 57, 60], 'closely': [27], 'related': [28], 'words': [29], 'are': [30, 82, 126], 'in': [31, 45, 162], 'close': [32], 'proximity\\nin': [33], 'vector': [35, 39, 80], 'space,': [36], 'Mol2vec': [37, 103, 147], 'learns': [38], 'molecular\\nsubstructures': [42], 'that': [43, 95, 166], 'point': [44], 'similar': [46], 'directions': [47], 'for': [48, 66, 140, 175], 'chemically': [49], 'related\\nsubstructures.': [50], 'Compounds': [51], 'can': [52, 148, 170], 'finally': [53], 'be': [54, 149, 172], 'encoded': [55], 'as': [56, 119], 'summing\\nthe': [59], 'individual': [63], 'substructures': [64], 'and,': [65], 'instance,': [67], 'be\\nfed': [68], 'into': [69], 'supervised': [70], 'approaches': [73], 'predict': [75], 'compound\\nproperties.': [76], 'The': [77, 124], 'underlying': [78], 'substructure': [79], 'embeddings': [81], 'obtained\\nby': [83], 'training': [84], 'on': [90, 128, 159], 'a': [91, 143, 163], 'so-called\\ncorpus': [92], 'compounds': [94], 'consists': [96], 'all': [98], 'available': [99], 'chemical': [100], 'matter.\\nThe': [101], 'resulting': [102], 'model': [104], 'pretrained': [106], 'once,': [107], 'yields': [108], 'dense': [109], 'vector\\nrepresentations,': [110], 'and': [111, 121, 132, 135], 'overcomes': [112], 'drawbacks': [113], 'common': [115], 'compound': [116, 130, 145], 'feature\\nrepresentations': [117], 'such': [118], 'sparseness': [120], 'bit': [122], 'collisions.': [123], 'prediction\\ncapabilities': [125], 'demonstrated': [127], 'several': [129], 'property': [131], 'bioactivity\\ndata': [133], 'sets': [134], 'compared': [136], 'with': [137, 177], 'results': [138], 'obtained': [139], 'Morgan': [141], 'fingerprints\\nas': [142], 'reference': [144], 'representation.': [146], 'easily': [150, 173], 'combined\\nwith': [151], 'ProtVec,': [152], 'employs': [154], 'same': [156], 'Word2vec': [157], 'concept': [158], 'protein': [160], 'sequences,\\nresulting': [161], 'proteochemometric': [164], 'alignment-independent\\nand': [168], 'thus': [169], 'also': [171], 'used': [174], 'proteins': [176], 'low': [178], 'sequence': [179], 'similarities.': [180]}",2017,"['Word2vec', 'Artificial intelligence', 'Computer science', 'Feature vector', 'Unsupervised learning', 'Support vector machine', 'Vector space', 'Chemical space', 'Feature learning', 'Pattern recognition (psychology)', 'Machine learning', 'Mathematics', 'Drug discovery', 'Embedding', 'Chemistry', 'Geometry', 'Biochemistry']","Inspired by natural\nlanguage processing techniques, we here introduce\nMol2vec, which is an unsupervised machine learning approach to learn\nvector representations of molecular substructures. Like the Word2vec\nmodels, where vectors of closely related words are in close proximity\nin the vector space, Mol2vec learns vector representations of molecular\nsubstructures that point in similar directions for chemically related\nsubstructures. Compounds can finally be encoded as vectors by summing\nthe vectors of the individual substructures and, for instance, be\nfed into supervised machine learning approaches to predict compound\nproperties. The underlying substructure vector embeddings are obtained\nby training an unsupervised machine learning approach on a so-called\ncorpus of compounds that consists of all available chemical matter.\nThe resulting Mol2vec model is pretrained once, yields dense vector\nrepresentations, and overcomes drawbacks of common compound feature\nrepresentations such as sparseness and bit collisions. The prediction\ncapabilities are demonstrated on several compound property and bioactivity\ndata sets and compared with results obtained for Morgan fingerprints\nas a reference compound representation. Mol2vec can be easily combined\nwith ProtVec, which employs the same Word2vec concept on protein sequences,\nresulting in a proteochemometric approach that is alignment-independent\nand thus can also be easily used for proteins with low sequence similarities."
https://openalex.org/W1544277926,Unsupervised Learning of Event Classes from Video,"{'We': [0], 'present': [1], 'a': [2, 65, 83, 111, 156], 'method': [3], 'for': [4, 133], 'unsupervised': [5], 'learning': [6, 37], 'of': [7, 32, 51, 61, 67, 72, 78, 98, 106, 119, 143, 148], 'event': [8, 33, 52, 175, 186], 'classes': [9, 53, 176, 187], 'from': [10, 28, 46, 56], 'videos': [11], 'in': [12, 103], 'which': [13, 104], 'multiple': [14], 'actions': [15], 'might': [16], 'occur': [17], 'simultaneously.': [18], 'It': [19], 'is': [20, 39, 54, 128], 'assumed': [21], 'that': [22, 87, 172], 'all': [23], 'such': [24], 'activities': [25], 'are': [26, 80, 177], 'produced': [27], 'an': [29], 'underlying': [30], 'set': [31, 50, 66], 'class': [34, 109], 'generators.': [35], 'The': [36, 95], 'task': [38], 'then': [40], 'to': [41, 130, 158], 'recover': [42], 'this': [43, 162], 'generative': [44], 'process': [45], 'visual': [47], 'data.': [48], 'A': [49, 121], 'derived': [55], 'the': [57, 62, 107, 134, 144, 173], 'most': [58], 'likely': [59], 'decomposition': [60], 'tracks': [63, 79, 145], 'into': [64, 146], 'labelled': [68], 'events': [69, 105, 150], 'involving': [70], 'subsets': [71, 77], 'interacting': [73], 'tracks.': [74, 94], 'Interactions': [75], 'between': [76, 92, 140], 'modelled': [81], 'as': [82], 'relational': [84, 113], 'graph': [85], 'structure': [86], 'captures': [88], 'qualitative': [89], 'spatio-temporal': [90], 'relationships': [91], 'these': [93], 'posterior': [96], 'probability': [97], 'candidate': [99], 'solutions': [100], 'favours': [101], 'decompositions': [102, 142], 'same': [108], 'have': [110], 'similar': [112], 'structure,': [114], 'together': [115], 'with': [116, 184], 'other': [117], 'measures': [118], 'well-formedness.': [120], 'Markov': [122], 'Chain': [123], 'Monte': [124], 'Carlo': [125], '(MCMC)': [126], 'procedure': [127], 'used': [129], 'efficiently': [131], 'search': [132, 138], 'MAP': [135], 'solution.': [136], 'This': [137], 'moves': [139], 'possible': [141], 'sets': [147], 'unlabelled': [149], 'and': [151, 181], 'at': [152], 'each': [153], 'move': [154], 'adds': [155], 'close': [157], 'optimal': [159], 'labelling': [160], '(for': [161], 'decomposition)': [163], 'using': [164], 'spectral': [165], 'clustering.': [166], 'Experiments': [167], 'on': [168], 'real': [169], 'data': [170], 'show': [171], 'discovered': [174], 'often': [178], 'semantically': [179], 'meaningful': [180], 'correspond': [182], 'well': [183], 'groundtruth': [185], 'assigned': [188], 'by': [189], 'hand.': [190]}",2010,"['Event (particle physics)', 'Computer science', 'Cluster analysis', 'Set (abstract data type)', 'Class (philosophy)', 'Artificial intelligence', 'Generative model', 'Hidden Markov model', 'Graph', 'Spectral clustering', 'Unsupervised learning', 'Markov chain Monte Carlo', 'Pattern recognition (psychology)', 'Machine learning', 'Theoretical computer science', 'Generative grammar', 'Bayesian probability', 'Physics', 'Quantum mechanics', 'Programming language']","We present a method for unsupervised learning of event classes from videos in which multiple actions might occur simultaneously. It is assumed that all such activities are produced from an underlying set of event class generators. The learning task is then to recover this generative process from visual data. A set of event classes is derived from the most likely decomposition of the tracks into a set of labelled events involving subsets of interacting tracks. Interactions between subsets of tracks are modelled as a relational graph structure that captures qualitative spatio-temporal relationships between these tracks. The posterior probability of candidate solutions favours decompositions in which events of the same class have a similar relational structure, together with other measures of well-formedness. A Markov Chain Monte Carlo (MCMC) procedure is used to efficiently search for the MAP solution. This search moves between possible decompositions of the tracks into sets of unlabelled events and at each move adds a close to optimal labelling (for this decomposition) using spectral clustering. Experiments on real data show that the discovered event classes are often semantically meaningful and correspond well with groundtruth event classes assigned by hand."
https://openalex.org/W3030535797,Elucidating ecological complexity: Unsupervised learning determines global marine eco-provinces,"{'Global': [0], 'marine': [1], 'eco-provinces': [2], 'are': [3], 'determined': [4], 'toward': [5], 'tackling': [6], 'complexity': [7], 'and': [8], 'to': [9], 'explore': [10], 'community': [11], 'structure': [12], 'using': [13], 'unsupervised': [14], 'ML.': [15]}",2020,"['Marine ecosystem', 'Cluster analysis', 'Computer science', 'Ecology', 'Ecosystem', 'Curse of dimensionality', 'Metric (unit)', 'Nonlinear dimensionality reduction', 'Geography', 'Machine learning', 'Dimensionality reduction', 'Environmental science', 'Biology', 'Operations management', 'Economics']",Global marine eco-provinces are determined toward tackling complexity and to explore community structure using unsupervised ML.
https://openalex.org/W1758770588,Unsupervised learning of models for object recognition,"{'A': [0], 'method': [1, 83, 132], 'is': [2, 29, 45], 'presented': [3], 'to': [4, 97, 123], 'learn': [5], 'object': [6, 20, 125], 'class': [7, 26], 'models': [8, 117], 'from': [9], 'unlabeled': [10], 'and': [11, 60, 121, 145], 'unsegmented': [12], 'cluttered': [13], 'scenes': [14], 'for': [15], 'the': [16, 55, 58, 61, 81, 89, 107], 'purpose': [17], 'of': [18, 27, 40, 57, 63, 115], 'visual': [19], 'recognition.': [21], 'The': [22, 131], 'variability': [23], 'across': [24], 'a': [25, 32, 48, 73, 78, 94], 'objects': [28, 36], 'modeled': [30], 'in': [31, 72, 88, 127], 'principled': [33], 'way,': [34], 'treating': [35], 'as': [37], 'flexible': [38], 'constellations': [39], 'rigid': [41], 'parts': [42, 87], '(features).': [43], 'Variability': [44], 'represented': [46], 'by': [47, 92, 100], 'joint': [49], 'probability': [50], 'density': [51], 'function': [52], '(pdf)': [53], 'on': [54, 138], 'shape': [56, 109], 'constellation': [59, 116], 'output': [62], 'part': [64], 'detectors.': [65], 'Corresponding': [66], '""constellation': [67], 'models""': [68], 'can': [69, 118], 'be': [70, 119], 'learned': [71], 'completely': [74], 'unsupervised': [75, 129], 'fashion.': [76], 'In': [77], 'first': [79], 'stage,': [80], 'learning': [82], 'automatically': [84], 'identifies': [85], 'distinctive': [86], 'training': [90], 'set': [91], 'applying': [93], 'clustering': [95], 'algorithm': [96], 'patterns': [98], 'selected': [99], 'an': [101, 128], 'interest': [102], 'operator.': [103], 'It': [104], 'then': [105], 'learns': [106], 'statistical': [108], 'model': [110], 'using': [111], 'expectation': [112], 'maximization.': [113], 'Mixtures': [114], 'defined': [120], 'applied': [122], '""discover""': [124], 'categories': [126], 'manner.': [130], 'achieves': [133], 'very': [134], 'good': [135], 'classification': [136], 'results': [137], 'human': [139], 'faces,': [140], 'cars,': [141], 'leaves,': [142], 'handwritten': [143], 'letters,': [144], 'cartoon': [146], 'characters.': [147]}",2010,"['Artificial intelligence', 'Computer science', 'Object (grammar)', 'Cluster analysis', 'Pattern recognition (psychology)', 'Constellation', 'Set (abstract data type)', 'Class (philosophy)', 'Cognitive neuroscience of visual object recognition', 'Unsupervised learning', 'Maximization', 'Computer vision', 'Mathematics', 'Programming language', 'Physics', 'Mathematical optimization', 'Astronomy']","A method is presented to learn object class models from unlabeled and unsegmented cluttered scenes for the purpose of visual object recognition. The variability across a class of objects is modeled in a principled way, treating objects as flexible constellations of rigid parts (features). Variability is represented by a joint probability density function (pdf) on the shape of the constellation and the output of part detectors. Corresponding ""constellation models"" can be learned in a completely unsupervised fashion. In a first stage, the learning method automatically identifies distinctive parts in the training set by applying a clustering algorithm to patterns selected by an interest operator. It then learns the statistical shape model using expectation maximization. Mixtures of constellation models can be defined and applied to ""discover"" object categories in an unsupervised manner. The method achieves very good classification results on human faces, cars, leaves, handwritten letters, and cartoon characters."
https://openalex.org/W3103897295,Unsupervised Learning of Dense Visual Representations,"{'Contrastive': [0], 'self-supervised': [1], 'learning': [2, 57], 'has': [3], 'emerged': [4], 'as': [5], 'a': [6, 115], 'promising': [7], 'approach': [8], 'to': [9, 25, 69, 125], 'unsupervised': [10, 56, 136], 'visual': [11, 39], 'representation': [12, 117], 'learning.': [13], 'In': [14, 46], 'general,': [15], 'these': [16], 'methods': [17], 'learn': [18], 'global': [19], '(image-level)': [20], 'representations': [21, 64], 'that': [22, 89], 'are': [23], 'invariant': [24], 'different': [26, 73, 98], 'views': [27], '(i.e.,': [28], 'compositions': [29], 'of': [30, 33, 58, 94], 'data': [31], 'augmentation)': [32], 'the': [34, 91, 95], 'same': [35, 92], 'image.': [36], 'However,': [37], 'many': [38], 'understanding': [40], 'tasks': [41, 121], 'require': [42], 'dense': [43, 59, 119, 140], '(pixel-level)': [44], 'representations.': [45, 60], 'this': [47, 77], 'paper,': [48], 'we': [49], 'propose': [50], 'View-Agnostic': [51], 'Dense': [52], 'Representation': [53], '(VADeR)': [54], 'for': [55, 118], 'VADeR': [61, 113], 'learns': [62], 'pixelwise': [63], 'by': [65], 'forcing': [66], 'local': [67], 'features': [68, 85, 88, 109], 'remain': [70], 'constant': [71], 'over': [72], 'viewing': [74], 'conditions.': [75], 'Specifically,': [76], 'is': [78], 'achieved': [79], 'through': [80], 'pixel-level': [81], 'contrastive': [82], 'learning:': [83], 'matching': [84], '(that': [86], 'is,': [87], 'describes': [90], 'location': [93], 'scene': [96], 'on': [97], 'views)': [99], 'should': [100, 110], 'be': [101, 111], 'close': [102], 'in': [103, 138], 'an': [104], 'embedding': [105], 'space,': [106], 'while': [107], 'non-matching': [108], 'apart.': [112], 'provides': [114], 'natural': [116], 'prediction': [120, 141], 'and': [122], 'transfers': [123], 'well': [124], 'downstream': [126], 'tasks.': [127, 142], 'Our': [128], 'method': [129], 'outperforms': [130], 'ImageNet': [131], 'supervised': [132], 'pretraining': [133], '(and': [134], 'strong': [135], 'baselines)': [137], 'multiple': [139]}",2020,"['Artificial intelligence', 'Computer science', 'Unsupervised learning', 'Pattern recognition (psychology)', 'Embedding', 'Feature learning', 'Representation (politics)', 'Matching (statistics)', 'Pixel', 'Invariant (physics)', 'Mathematics', 'Politics', 'Political science', 'Law', 'Statistics', 'Mathematical physics']","Contrastive self-supervised learning has emerged as a promising approach to unsupervised visual representation learning. In general, these methods learn global (image-level) representations that are invariant to different views (i.e., compositions of data augmentation) of the same image. However, many visual understanding tasks require dense (pixel-level) representations. In this paper, we propose View-Agnostic Dense Representation (VADeR) for unsupervised learning of dense representations. VADeR learns pixelwise representations by forcing local features to remain constant over different viewing conditions. Specifically, this is achieved through pixel-level contrastive learning: matching features (that is, features that describes the same location of the scene on different views) should be close in an embedding space, while non-matching features should be apart. VADeR provides a natural representation for dense prediction tasks and transfers well to downstream tasks. Our method outperforms ImageNet supervised pretraining (and strong unsupervised baselines) in multiple dense prediction tasks."
https://openalex.org/W3033312235,Quantum process tomography with unsupervised learning and tensor networks,"{'Abstract': [0], 'The': [1], 'impressive': [2], 'pace': [3], 'of': [4, 6, 20, 28, 51, 60, 90, 118, 136], 'advance': [5], 'quantum': [7, 21, 31, 43, 77, 116, 160, 166], 'technology': [8], 'calls': [9], 'for': [10, 15, 75, 110, 158], 'robust': [11], 'and': [12, 18, 55, 67, 113, 123, 155, 164], 'scalable': [13], 'techniques': [14], 'the': [16, 26, 37, 48, 52, 91], 'characterization': [17], 'validation': [19], 'hardware.': [22], 'Quantum': [23], 'process': [24, 78, 129], 'tomography,': [25], 'reconstruction': [27], 'an': [29], 'unknown': [30], 'channel': [32, 92], 'from': [33], 'measurement': [34, 140], 'data,': [35], 'remains': [36], 'quintessential': [38], 'primitive': [39], 'to': [40, 47, 65, 120], 'completely': [41], 'characterize': [42], 'devices.': [44], 'However,': [45], 'due': [46], 'exponential': [49], 'scaling': [50], 'required': [53], 'data': [54, 109], 'classical': [56], 'post-processing,': [57], 'its': [58], 'range': [59], 'applicability': [61], 'is': [62], 'typically': [63], 'restricted': [64], 'one-': [66, 112], 'two-qubit': [68], 'gates.': [69], 'Here,': [70], 'we': [71], 'present': [72], 'a': [73, 86, 94, 124, 153], 'technique': [74, 105], 'performing': [76], 'tomography': [79], 'that': [80], 'addresses': [81], 'these': [82], 'issues': [83], 'by': [84, 98], 'combining': [85], 'tensor': [87], 'network': [88], 'representation': [89], 'with': [93], 'data-driven': [95], 'optimization': [96], 'inspired': [97], 'unsupervised': [99], 'machine': [100], 'learning.': [101], 'We': [102], 'demonstrate': [103], 'our': [104], 'through': [106], 'synthetically': [107], 'generated': [108], 'ideal': [111], 'two-dimensional': [114], 'random': [115], 'circuits': [117, 161], 'up': [119], '10': [121], 'qubits,': [122], 'noisy': [125], '5-qubit': [126], 'circuit,': [127], 'reaching': [128], 'fidelities': [130], 'above': [131], '0.99': [132], 'using': [133], 'several': [134], 'orders': [135], 'magnitude': [137], 'fewer': [138], '(single-qubit)': [139], 'shots': [141], 'than': [142], 'traditional': [143], 'tomographic': [144], 'techniques.': [145], 'Our': [146], 'results': [147], 'go': [148], 'far': [149], 'beyond': [150], 'state-of-the-art,': [151], 'providing': [152], 'practical': [154], 'timely': [156], 'tool': [157], 'benchmarking': [159], 'in': [162], 'current': [163], 'near-term': [165], 'computers.': [167]}",2023,"['Computer science', 'Qubit', 'Quantum circuit', 'Quantum computer', 'Quantum', 'Quantum error correction', 'Quantum tomography', 'Theoretical computer science', 'Quantum state', 'Computer engineering', 'Algorithm', 'Physics', 'Quantum mechanics']","Abstract The impressive pace of advance of quantum technology calls for robust and scalable techniques for the characterization and validation of quantum hardware. Quantum process tomography, the reconstruction of an unknown quantum channel from measurement data, remains the quintessential primitive to completely characterize quantum devices. However, due to the exponential scaling of the required data and classical post-processing, its range of applicability is typically restricted to one- and two-qubit gates. Here, we present a technique for performing quantum process tomography that addresses these issues by combining a tensor network representation of the channel with a data-driven optimization inspired by unsupervised machine learning. We demonstrate our technique through synthetically generated data for ideal one- and two-dimensional random quantum circuits of up to 10 qubits, and a noisy 5-qubit circuit, reaching process fidelities above 0.99 using several orders of magnitude fewer (single-qubit) measurement shots than traditional tomographic techniques. Our results go far beyond state-of-the-art, providing a practical and timely tool for benchmarking quantum circuits in current and near-term quantum computers."
https://openalex.org/W2796429358,Learning Unsupervised Learning Rules,"{'A': [0], 'major': [1], 'goal': [2, 26], 'of': [3, 40, 94], 'unsupervised': [4, 75, 107, 125, 159, 167], 'learning': [5, 76, 160], 'is': [6, 27, 91], 'to': [7, 19, 65, 80, 128, 138, 140, 171, 183, 198], 'discover': [8], 'data': [9, 186], 'representations': [10, 48, 81, 114], 'that': [11, 47, 84, 112, 115, 147, 164], 'are': [12], 'useful': [13, 49, 82, 153], 'for': [14, 50, 83], 'subsequent': [15, 51], 'tasks,': [16], 'without': [17], 'access': [18], 'supervised': [20], 'labels': [21], 'during': [22], 'training.': [23], 'Typically,': [24], 'this': [25, 60, 119], 'approached': [28], 'by': [29, 72], 'minimizing': [30], 'a': [31, 41, 56, 68, 129, 131, 199], 'surrogate': [32], 'objective,': [33], 'such': [34], 'as': [35, 55], 'the': [36, 45, 92, 95, 148, 165], 'negative': [37], 'log': [38], 'likelihood': [39], 'generative': [42], 'model,': [43], 'with': [44, 174, 187], 'hope': [46], 'tasks': [52], 'will': [53], 'arise': [54], 'side': [57], 'effect.': [58], 'In': [59], 'work,': [61], 'we': [62, 101, 122], 'propose': [63], 'instead': [64], 'directly': [66], 'target': [67], 'later': [69], 'desired': [70, 88], 'task': [71, 89], 'meta-learning': [73], 'an': [74, 103, 106], 'rule,': [77], 'which': [78, 135], 'leads': [79], 'task.': [85, 201], 'Here,': [86], 'our': [87, 124], '(meta-objective)': [90], 'performance': [93], 'representation': [96], 'on': [97, 185], 'semi-supervised': [98], 'classification,': [99], 'and': [100, 155, 178, 192], 'meta-learn': [102], 'algorithm': [104], '--': [105, 111], 'weight': [108], 'update': [109, 126, 150, 168], 'rule': [110, 127, 151, 169], 'produces': [113, 152], 'perform': [116], 'well': [117], 'under': [118], 'meta-objective.': [120], 'Additionally,': [121], 'constrain': [123], 'be': [130], 'biologically-motivated,': [132], 'neuron-local': [133], 'function,': [134], 'enables': [136], 'it': [137], 'generalize': [139], 'novel': [141], 'neural': [142], 'network': [143], 'architectures.': [144], 'We': [145, 162], 'show': [146, 163], 'meta-learned': [149, 166], 'features': [154], 'sometimes': [156], 'outperforms': [157], 'existing': [158], 'techniques.': [161], 'generalizes': [170, 182, 194], 'train': [172, 184], 'networks': [173], 'different': [175], 'widths,': [176], 'depths,': [177], 'nonlinearities.': [179], 'It': [180], 'also': [181], 'randomly': [188], 'permuted': [189], 'input': [190], 'dimensions': [191], 'even': [193], 'from': [195], 'image': [196], 'datasets': [197], 'text': [200]}",2018,"['Unsupervised learning', 'Meta learning (computer science)', 'Computer science', 'Artificial intelligence', 'Machine learning', 'Task (project management)', 'Feature learning', 'Representation (politics)', 'Artificial neural network', 'Generative model', 'Generative grammar', 'Function (biology)', 'Supervised learning', 'Pattern recognition (psychology)', 'Politics', 'Economics', 'Biology', 'Political science', 'Evolutionary biology', 'Law', 'Management']","A major goal of unsupervised learning is to discover data representations that are useful for subsequent tasks, without access to supervised labels during training. Typically, this goal is approached by minimizing a surrogate objective, such as the negative log likelihood of a generative model, with the hope that representations useful for subsequent tasks will arise as a side effect. In this work, we propose instead to directly target a later desired task by meta-learning an unsupervised learning rule, which leads to representations useful for that task. Here, our desired task (meta-objective) is the performance of the representation on semi-supervised classification, and we meta-learn an algorithm -- an unsupervised weight update rule -- that produces representations that perform well under this meta-objective. Additionally, we constrain our unsupervised update rule to a be a biologically-motivated, neuron-local function, which enables it to generalize to novel neural network architectures. We show that the meta-learned update rule produces useful features and sometimes outperforms existing unsupervised learning techniques. We show that the meta-learned unsupervised update rule generalizes to train networks with different widths, depths, and nonlinearities. It also generalizes to train on data with randomly permuted input dimensions and even generalizes from image datasets to a text task."
https://openalex.org/W1990444568,Unsupervised Learning of Overlapping Image Components Using Divisive Input Modulation,"{'This': [0, 25], 'paper': [1], 'demonstrates': [2], 'that': [3, 16, 159, 187], 'nonnegative': [4], 'matrix': [5], 'factorisation': [6], 'is': [7, 75, 78, 171], 'mathematically': [8, 44], 'related': [9], 'to': [10, 80, 91, 191], 'a': [11, 21, 28, 43, 71], 'class': [12], 'of': [13, 23, 54, 95, 112, 116, 123, 147], 'neural': [14], 'networks': [15], 'employ': [17], 'negative': [18], 'feedback': [19], 'as': [20], 'mechanism': [22], 'competition.': [24], 'observation': [26], 'inspires': [27], 'novel': [29, 72], 'learning': [30, 53], 'algorithm': [31, 41, 150, 170], 'which': [32, 77], 'we': [33, 102, 129], 'call': [34], 'Divisive': [35], 'Input': [36], 'Modulation': [37], '(DIM).': [38], 'The': [39, 168], 'proposed': [40, 69, 106, 149, 169], 'provides': [42], 'simple': [45], 'and': [46, 127, 181], 'computationally': [47], 'efficient': [48], 'method': [49, 107], 'for': [50], 'the': [51, 68, 81, 93, 105, 110, 120, 124, 136, 145, 148, 165, 184], 'unsupervised': [52], 'image': [55], 'components,': [56], 'even': [57], 'in': [58, 177, 183], 'conditions': [59], 'where': [60], 'these': [61, 157], 'elementary': [62, 137], 'features': [63], 'overlap': [64, 96, 180], 'considerably.': [65], 'To': [66], 'test': [67], 'algorithm,': [70], 'artificial': [73, 113, 140, 185], 'task': [74, 186], 'introduced': [76], 'similar': [79], 'frequently‐used': [82], 'bars': [83, 90, 166], 'problem': [84], 'but': [85], 'employs': [86], 'squares': [87], 'rather': [88], 'than': [89, 174], 'increase': [92], 'degree': [94], 'between': [97], 'components.': [98], 'Using': [99], 'this': [100], 'task,': [101], 'investigate': [103, 130], 'how': [104, 131], 'performs': [108], 'on': [109, 156, 164], 'parsing': [111], 'images': [114], 'composed': [115], 'overlapping': [117], 'features,': [118], 'given': [119], 'correct': [121], 'representation': [122], 'individual': [125], 'components;': [126], 'secondly,': [128], 'well': [132], 'it': [133], 'can': [134], 'learn': [135], 'components': [138], 'from': [139], 'training': [141], 'images.': [142], 'We': [143], 'compare': [144], 'performance': [146, 163], 'with': [151, 179], 'its': [152, 175], 'predecessors': [153, 176], 'including': [154], 'variations': [155], 'algorithms': [158], 'have': [160], 'produced': [161], 'state‐of‐the‐art': [162], 'problem.': [167], 'more': [172], 'successful': [173], 'dealing': [178], 'occlusion': [182], 'has': [188], 'been': [189], 'used': [190], 'assess': [192], 'performance.': [193]}",2009,"['Computer science', 'Modulation (music)', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Unsupervised learning', 'Image (mathematics)', 'Computer vision', 'Physics', 'Acoustics']","This paper demonstrates that nonnegative matrix factorisation is mathematically related to a class of neural networks that employ negative feedback as a mechanism of competition. This observation inspires a novel learning algorithm which we call Divisive Input Modulation (DIM). The proposed algorithm provides a mathematically simple and computationally efficient method for the unsupervised learning of image components, even in conditions where these elementary features overlap considerably. To test the proposed algorithm, a novel artificial task is introduced which is similar to the frequently‐used bars problem but employs squares rather than bars to increase the degree of overlap between components. Using this task, we investigate how the proposed method performs on the parsing of artificial images composed of overlapping features, given the correct representation of the individual components; and secondly, we investigate how well it can learn the elementary components from artificial training images. We compare the performance of the proposed algorithm with its predecessors including variations on these algorithms that have produced state‐of‐the‐art performance on the bars problem. The proposed algorithm is more successful than its predecessors in dealing with overlap and occlusion in the artificial task that has been used to assess performance."
https://openalex.org/W2096046065,Dimensionality reduction in unsupervised learning of conditional Gaussian networks,"{'This': [0], 'paper': [1], 'introduces': [2], 'a': [3, 125], 'novel': [4], 'enhancement': [5], 'for': [6, 57, 87, 109, 138, 166], 'unsupervised': [7], 'learning': [8, 59, 111], 'of': [9, 29, 35, 38, 50, 106, 118, 146], 'conditional': [10], 'Gaussian': [11], 'networks': [12], 'that': [13, 43], 'benefits': [14], 'from': [15], 'feature': [16, 75], 'selection.': [17], 'Our': [18], 'proposal': [19, 148], 'is': [20, 76, 92, 113], 'based': [21], 'on': [22], 'the': [23, 27, 32, 39, 48, 51, 58, 69, 79, 88, 104, 107, 110, 116, 131, 144, 167], 'assumption': [24], 'that,': [25], 'in': [26], 'absence': [28], 'labels': [30], 'reflecting': [31], 'cluster': [33], 'membership': [34], 'each': [36], 'case': [37], 'database,': [40], 'those': [41], 'features': [42, 52, 108, 155], 'exhibit': [44], 'low': [45], 'correlation': [46], 'with': [47], 'rest': [49], 'can': [53], 'be': [54], 'considered': [55], 'irrelevant': [56, 74, 154], 'process.': [60], 'Thus,': [61], 'we': [62], 'suggest': [63], 'performing': [64], 'this': [65, 119], 'process': [66, 112], 'using': [67], 'only': [68], 'relevant': [70, 132, 152], 'features.': [71, 133], 'Then,': [72], 'every': [73], 'added': [77], 'to': [78, 82, 102, 123, 128, 149, 157], 'learned': [80], 'model': [81, 86], 'obtain': [83], 'an': [84], 'explanatory': [85, 164], 'original': [89, 168], 'database': [90], 'which': [91], 'our': [93, 147], 'primary': [94], 'goal.': [95], 'A': [96], 'simple': [97], 'and,': [98], 'thus,': [99], 'efficient': [100], 'measure': [101, 120], 'assess': [103], 'relevance': [105, 126], 'presented.': [114], 'Additionally,': [115], 'form': [117], 'allows': [121], 'us': [122], 'calculate': [124], 'threshold': [127], 'automatically': [129], 'identify': [130], 'The': [134], 'experimental': [135], 'results': [136], 'reported': [137], 'synthetic': [139], 'and': [140, 153, 156], 'real-world': [141], 'databases': [142], 'show': [143], 'ability': [145], 'distinguish': [150], 'between': [151], 'accelerate': [158], 'learning;': [159], 'however,': [160], 'still': [161], 'obtaining': [162], 'good': [163], 'models': [165], 'database.': [169]}",2001,"['Artificial intelligence', 'Computer science', 'Dimensionality reduction', 'Machine learning', 'Relevance (law)', 'Unsupervised learning', 'Measure (data warehouse)', 'Gaussian process', 'Feature (linguistics)', 'Curse of dimensionality', 'Pattern recognition (psychology)', 'Data mining', 'Gaussian', 'Linguistics', 'Law', 'Physics', 'Philosophy', 'Quantum mechanics', 'Political science']","This paper introduces a novel enhancement for unsupervised learning of conditional Gaussian networks that benefits from feature selection. Our proposal is based on the assumption that, in the absence of labels reflecting the cluster membership of each case of the database, those features that exhibit low correlation with the rest of the features can be considered irrelevant for the learning process. Thus, we suggest performing this process using only the relevant features. Then, every irrelevant feature is added to the learned model to obtain an explanatory model for the original database which is our primary goal. A simple and, thus, efficient measure to assess the relevance of the features for the learning process is presented. Additionally, the form of this measure allows us to calculate a relevance threshold to automatically identify the relevant features. The experimental results reported for synthetic and real-world databases show the ability of our proposal to distinguish between relevant and irrelevant features and to accelerate learning; however, still obtaining good explanatory models for the original database."
https://openalex.org/W2794337790,Unsupervised Learning of Monocular Depth Estimation and Visual Odometry with Deep Feature Reconstruction,"{'Despite': [0], 'learning': [1, 36, 55, 193], 'based': [2, 194], 'methods': [3, 195], 'showing': [4], 'promising': [5], 'results': [6, 165], 'in': [7, 21, 91, 201], 'single': [8, 28, 105, 145, 182], 'view': [9, 29, 106, 146, 183], 'depth': [10, 30, 56, 85, 107, 147, 152, 184], 'estimation': [11, 31, 185], 'and': [12, 57, 74, 81, 86, 108, 148, 162, 186], 'visual': [13, 58, 149, 167, 187], 'odometry,': [14], 'most': [15], 'existing': [16, 192], 'approaches': [17, 26], 'treat': [18], 'the': [19, 33, 49, 66, 83, 156, 197], 'tasks': [20], 'a': [22, 92, 112, 123, 130], 'supervised': [23], 'manner.': [24], 'Recent': [25], 'to': [27, 89, 103], 'explore': [32, 48], 'possibility': [34], 'of': [35, 51, 62, 68, 132, 155], 'without': [37], 'full': [38], 'supervision': [39], 'via': [40], 'minimizing': [41], 'photometric': [42, 78, 125, 177], 'error.': [43], 'In': [44], 'this': [45], 'paper,': [46], 'we': [47, 119], 'use': [50, 61, 67], 'stereo': [52, 63], 'sequences': [53, 64], 'for': [54, 144, 166, 180], 'odometry.': [59, 188], 'The': [60, 204], 'enables': [65], 'both': [69, 181, 202], 'spatial': [70], '(between': [71], 'left-right': [72], 'pairs)': [73], 'temporal': [75], '(forward': [76], 'backward)': [77], 'warp': [79, 126, 131, 178], 'error,': [80], 'constrains': [82], 'scene': [84], 'camera': [87], 'motion': [88], 'be': [90], 'common,': [93], 'real-world': [94], 'scale.': [95], 'At': [96], 'test': [97], 'time': [98], 'our': [99], 'framework': [100], 'is': [101, 207], 'able': [102], 'estimate': [104], 'two-view': [109], 'odometry': [110, 150], 'from': [111], 'monocular': [113], 'sequence.': [114], 'We': [115, 135], 'also': [116], 'show': [117, 136], 'how': [118], 'can': [120], 'improve': [121], 'on': [122, 160, 196], 'standard': [124], 'loss': [127, 173, 179], 'by': [128], 'considering': [129], 'deep': [133, 170], 'features.': [134], 'through': [137], 'extensive': [138], 'experiments': [139], 'that:': [140], '(i)': [141], 'jointly': [142], 'training': [143], 'improves': [151, 174], 'prediction': [153], 'because': [154], 'additional': [157], 'constraint': [158], 'imposed': [159], 'depths': [161], 'achieves': [163], 'competitive': [164], 'odometry;': [168], '(ii)': [169], 'feature-based': [171], 'warping': [172], 'upon': [175], 'simple': [176], 'Our': [189], 'method': [190], 'outperforms': [191], 'KITTI': [198], 'driving': [199], 'dataset': [200], 'tasks.': [203], 'source': [205], 'code': [206], 'available': [208], 'at': [209], 'https://github.com/Huangying-Zhan/Depth-VO-Feat': [210]}",2018,"['Visual odometry', 'Artificial intelligence', 'Odometry', 'Monocular', 'Computer science', 'Computer vision', 'Image warping', 'Feature (linguistics)', 'Depth map', 'Deep learning', 'Image (mathematics)', 'Robot', 'Mobile robot', 'Philosophy', 'Linguistics']","Despite learning based methods showing promising results in single view depth estimation and visual odometry, most existing approaches treat the tasks in a supervised manner. Recent approaches to single view depth estimation explore the possibility of learning without full supervision via minimizing photometric error. In this paper, we explore the use of stereo sequences for learning depth and visual odometry. The use of stereo sequences enables the use of both spatial (between left-right pairs) and temporal (forward backward) photometric warp error, and constrains the scene depth and camera motion to be in a common, real-world scale. At test time our framework is able to estimate single view depth and two-view odometry from a monocular sequence. We also show how we can improve on a standard photometric warp loss by considering a warp of deep features. We show through extensive experiments that: (i) jointly training for single view depth and visual odometry improves depth prediction because of the additional constraint imposed on depths and achieves competitive results for visual odometry; (ii) deep feature-based warping loss improves upon simple photometric warp loss for both single view depth estimation and visual odometry. Our method outperforms existing learning based methods on the KITTI driving dataset in both tasks. The source code is available at https://github.com/Huangying-Zhan/Depth-VO-Feat"
https://openalex.org/W2148349024,Discriminative Unsupervised Feature Learning with Convolutional Neural Networks,"{'Current': [0], 'methods': [1], 'for': [2, 14, 24, 98], 'training': [3, 25], 'convolutional': [4, 27], 'neural': [5, 28], 'networks': [6], 'depend': [7], 'on': [8, 101], 'large': [9], 'amounts': [10], 'of': [11, 43, 55], 'labeled': [12], 'samples': [13], 'supervised': [15], 'training.': [16], 'In': [17], 'this': [18, 68], 'paper': [19], 'we': [20], 'present': [21], 'an': [22], 'approach': [23], 'a': [26, 41, 53, 58], 'network': [29, 37], 'using': [30], 'only': [31], 'unlabeled': [32], 'data.': [33], 'We': [34, 65], 'train': [35], 'the': [36, 95], 'to': [38, 57, 78], 'discriminate': [39], 'between': [40], 'set': [42], 'surrogate': [44, 47], 'classes.': [45], 'Each': [46], 'class': [48], 'is': [49, 73], 'formed': [50], 'by': [51, 86], 'applying': [52], 'variety': [54], 'transformations': [56], 'randomly': [59], 'sampled': [60], '’seed': [61], '’': [62], 'image': [63], 'patch.': [64], 'find': [66], 'that': [67], 'simple': [69], 'feature': [70, 83], 'learning': [71, 100], 'algorithm': [72, 88], 'surprisingly': [74], 'successful': [75], 'when': [76], 'applied': [77], 'visual': [79], 'object': [80], 'recognition.': [81], 'The': [82], 'representation': [84], 'learned': [85], 'our': [87], 'achieves': [89], 'classification': [90], 'results': [91], 'matching': [92], 'or': [93], 'outperforming': [94], 'current': [96], 'state-of-the-art': [97], 'unsupervised': [99], 'several': [102], 'popular': [103], 'datasets': [104], '(STL-10,': [105], 'CIFAR-10,': [106], 'Caltech-101).': [107], '1': [108]}",2014,"['Artificial intelligence', 'Convolutional neural network', 'Pattern recognition (psychology)', 'Computer science', 'Discriminative model', 'Feature learning', 'Feature (linguistics)', 'Matching (statistics)', 'Unsupervised learning', 'Representation (politics)', 'Feature extraction', 'Machine learning', 'Set (abstract data type)', 'Artificial neural network', 'Cognitive neuroscience of visual object recognition', 'Deep learning', 'Mathematics', 'Political science', 'Statistics', 'Law', 'Politics', 'Linguistics', 'Philosophy', 'Programming language']","Current methods for training convolutional neural networks depend on large amounts of labeled samples for supervised training. In this paper we present an approach for training a convolutional neural network using only unlabeled data. We train the network to discriminate between a set of surrogate classes. Each surrogate class is formed by applying a variety of transformations to a randomly sampled ’seed ’ image patch. We find that this simple feature learning algorithm is surprisingly successful when applied to visual object recognition. The feature representation learned by our algorithm achieves classification results matching or outperforming the current state-of-the-art for unsupervised learning on several popular datasets (STL-10, CIFAR-10, Caltech-101). 1"
https://openalex.org/W2185744359,Anomaly Detection in Bitcoin Network Using Unsupervised Learning Methods,"{'The': [0], 'problem': [1], 'of': [2, 33], 'anomaly': [3, 85], 'detection': [4, 86], 'has': [5, 148, 155], 'been': [6, 59], 'studied': [7], 'for': [8, 114], 'a': [9, 34, 112], 'long': [10], 'time.': [11], 'In': [12, 20, 80], 'short,': [13], 'anomalies': [14, 39], 'are': [15, 27, 102], 'abnormal': [16], 'or': [17], 'unlikely': [18], 'things.': [19], 'financial': [21], 'networks,': [22], 'thieves': [23], 'and': [24, 52, 100, 131, 152], 'illegal': [25], 'activities': [26], 'often': [28], 'anomalous': [29, 109], 'in': [30, 106], 'nature.': [31], 'Members': [32], 'network': [35], 'want': [36], 'to': [37, 44, 61, 69, 88, 96], 'detect': [38, 97], 'as': [40, 42, 150, 157], 'soon': [41], 'possible': [43], 'prevent': [45], 'them': [46], 'from': [47], 'harming': [48], 'the': [49, 89, 103, 142, 153], ""network's"": [50], 'community': [51], 'integrity.': [53], 'Many': [54], 'Machine': [55, 135], 'Learning': [56], 'techniques': [57], 'have': [58], 'proposed': [60], 'deal': [62], 'with': [63], 'this': [64, 81, 107, 118], 'problem;': [65], 'some': [66], 'results': [67], 'appear': [68], 'be': [70], 'quite': [71], 'promising': [72], 'but': [73], 'there': [74], 'is': [75, 95, 111], 'no': [76], 'obvious': [77], 'superior': [78], 'method.': [79], 'paper,': [82], 'we': [83, 120], 'consider': [84], 'particular': [87], 'Bitcoin': [90, 143], 'transaction': [91, 144], 'network.': [92], 'Our': [93], 'goal': [94], 'which': [98], 'users': [99, 149], 'transactions': [101, 156], 'most': [104], 'suspicious;': [105], 'case,': [108], 'behavior': [110], 'proxy': [113], 'suspicious': [115], 'behavior.': [116], 'To': [117], 'end,': [119], 'use': [121], 'three': [122], 'unsupervised': [123], 'learning': [124], 'methods': [125], 'including': [126], 'k-means': [127], 'clustering,': [128], 'Mahalanobis': [129], 'distance,': [130], 'Unsupervised': [132], 'Support': [133], 'Vector': [134], '(SVM)': [136], 'on': [137], 'two': [138], 'graphs': [139], 'generated': [140], 'by': [141], 'network:': [145], 'one': [146], 'graph': [147], 'nodes,': [151], 'other': [154], 'nodes.': [158]}",2016,"['Anomaly detection', 'Computer science', 'Database transaction', 'Support vector machine', 'Mahalanobis distance', 'Cluster analysis', 'Unsupervised learning', 'Anomaly (physics)', 'Artificial intelligence', 'Data mining', 'Machine learning', 'Condensed matter physics', 'Programming language', 'Physics']","The problem of anomaly detection has been studied for a long time. In short, anomalies are abnormal or unlikely things. In financial networks, thieves and illegal activities are often anomalous in nature. Members of a network want to detect anomalies as soon as possible to prevent them from harming the network's community and integrity. Many Machine Learning techniques have been proposed to deal with this problem; some results appear to be quite promising but there is no obvious superior method. In this paper, we consider anomaly detection particular to the Bitcoin transaction network. Our goal is to detect which users and transactions are the most suspicious; in this case, anomalous behavior is a proxy for suspicious behavior. To this end, we use three unsupervised learning methods including k-means clustering, Mahalanobis distance, and Unsupervised Support Vector Machine (SVM) on two graphs generated by the Bitcoin transaction network: one graph has users as nodes, and the other has transactions as nodes."
https://openalex.org/W2971202257,Unsupervised Learning of Object Keypoints for Perception and Control,"{'The': [0, 93], 'study': [1], 'of': [2, 64], 'object': [3, 20, 35, 60, 99], 'representations': [4, 13, 36, 61], 'in': [5, 62, 76, 118], 'computer': [6], 'vision': [7], 'has': [8], 'primarily': [9], 'focused': [10], 'on': [11], 'developing': [12], 'that': [14, 37], 'are': [15, 38], 'useful': [16, 39], 'for': [17, 40, 56], 'image': [18, 84, 129], 'classification,': [19], 'detection,': [21], 'or': [22, 66], 'semantic': [23], 'segmentation': [24], 'as': [25, 131], 'downstream': [26], 'tasks.': [27], 'In': [28], 'this': [29, 47], 'work': [30], 'we': [31, 49], 'aim': [32], 'to': [33, 140, 155], 'learn': [34], 'control': [41, 119], 'and': [42, 98, 127], 'reinforcement': [43, 136], 'learning': [44, 139], '(RL).': [45], 'To': [46], 'end,': [48], 'introduce': [50], 'Transporter,': [51], 'a': [52, 77, 90], 'neural': [53], 'network': [54], 'architecture': [55], 'discovering': [57], 'concise': [58], 'geometric': [59], 'terms': [63], 'keypoints': [65, 95], 'image-space': [67], 'coordinates.': [68], 'Our': [69], 'method': [70], 'learns': [71], 'from': [72], 'raw': [73], 'video': [74, 87], 'frames': [75, 88], 'fully': [78], 'unsupervised': [79], 'manner,': [80], 'by': [81, 142], 'transporting': [82], 'learnt': [83], 'features': [85, 130], 'between': [86], 'using': [89, 123], 'keypoint': [91, 125, 144], 'bottleneck.': [92], 'discovered': [94], 'track': [96], 'objects': [97], 'parts': [100], 'across': [101], 'long': [102], 'time-horizons': [103], 'more': [104], 'accurately': [105], 'than': [106], 'recent': [107], 'similar': [108], 'methods.': [109], 'Furthermore,': [110], 'consistent': [111], 'long-term': [112], 'tracking': [113], 'enables': [114, 133], 'two': [115], 'notable': [116], 'results': [117], 'domains': [120], '--': [121], '(1)': [122], 'the': [124, 148], 'co-ordinates': [126], 'corresponding': [128], 'inputs': [132], 'highly': [134], 'sample-efficient': [135], 'learning;': [137], '(2)': [138], 'explore': [141], 'controlling': [143], 'locations': [145], 'drastically': [146], 'reduces': [147], 'search': [149], 'space,': [150], 'enabling': [151], 'deep': [152], 'exploration': [153], '(leading': [154], 'states': [156], 'unreachable': [157], 'through': [158], 'random': [159], 'action': [160], 'exploration)': [161], 'without': [162], 'any': [163], 'extrinsic': [164], 'rewards.': [165]}",2019,"['Artificial intelligence', 'Computer science', 'Reinforcement learning', 'Object (grammar)', 'Computer vision', 'Object detection', 'Unsupervised learning', 'Bottleneck', 'Segmentation', 'Cognitive neuroscience of visual object recognition', 'Pattern recognition (psychology)', 'Artificial neural network', 'Video tracking', 'Image segmentation', 'Embedded system']","The study of object representations in computer vision has primarily focused on developing representations that are useful for image classification, object detection, or semantic segmentation as downstream tasks. In this work we aim to learn object representations that are useful for control and reinforcement learning (RL). To this end, we introduce Transporter, a neural network architecture for discovering concise geometric object representations in terms of keypoints or image-space coordinates. Our method learns from raw video frames in a fully unsupervised manner, by transporting learnt image features between video frames using a keypoint bottleneck. The discovered keypoints track objects and object parts across long time-horizons more accurately than recent similar methods. Furthermore, consistent long-term tracking enables two notable results in control domains -- (1) using the keypoint co-ordinates and corresponding image features as inputs enables highly sample-efficient reinforcement learning; (2) learning to explore by controlling keypoint locations drastically reduces the search space, enabling deep exploration (leading to states unreachable through random action exploration) without any extrinsic rewards."
https://openalex.org/W2124151298,Modeling language and cognition with deep unsupervised learning: a tutorial overview,"{'Deep': [0], 'unsupervised': [1], 'learning': [2, 118, 138], 'in': [3, 18], 'stochastic': [4], 'recurrent': [5], 'neural': [6, 19], 'networks': [7, 23, 67], 'with': [8], 'many': [9], 'layers': [10], 'of': [11, 27, 33, 51, 65, 81, 136, 156], 'hidden': [12], 'units': [13], 'is': [14, 86], 'a': [15, 25, 39, 89, 120, 132, 142], 'recent': [16], 'breakthrough': [17], 'computation': [20], 'research.': [21], 'These': [22], 'build': [24], 'hierarchy': [26], 'progressively': [28], 'more': [29, 133], 'complex': [30], 'distributed': [31], 'representations': [32, 98], 'the': [34, 48, 108, 125, 146], 'sensory': [35], 'data': [36], 'by': [37], 'fitting': [38], 'hierarchical': [40], 'generative': [41, 103, 114], 'model.': [42], 'In': [43], 'this': [44, 52], 'article': [45], 'we': [46, 55], 'discuss': [47], 'theoretical': [49], 'foundations': [50], 'approach': [53], 'and': [54, 63, 71, 77, 83, 96, 113, 152], 'review': [56], 'key': [57], 'issues': [58], 'related': [59], 'to': [60, 92, 144], 'training,': [61], 'testing': [62], 'analysis': [64], 'deep': [66, 102, 111], 'for': [68, 124], 'modeling': [69, 127], 'language': [70], 'cognitive': [72], 'processing.': [73], 'The': [74], 'classic': [75], 'letter': [76], 'word': [78], 'perception': [79], 'problem': [80], 'McClelland': [82], 'Rumelhart': [84], '(1981)': [85], 'used': [87], 'as': [88, 139, 141], 'tutorial': [90], 'example': [91], 'illustrate': [93], 'how': [94], 'structured': [95, 153], 'abstract': [97], 'may': [99], 'emerge': [100], 'from': [101], 'learning.': [104], 'We': [105], 'argue': [106], 'that': [107], 'focus': [109], 'on': [110], 'architectures': [112], '(rather': [115], 'than': [116], 'discriminative)': [117], 'represents': [119], 'crucial': [121], 'step': [122], 'forward': [123], 'connectionist': [126, 150], 'enterprise,': [128], 'because': [129], 'it': [130], 'offers': [131], 'plausible': [134], 'model': [135], 'cortical': [137], 'well': [140], 'way': [143], 'bridge': [145], 'gap': [147], 'between': [148], 'emergentist': [149], 'models': [151, 155], 'Bayesian': [154], 'cognition.': [157]}",2013,"['Cognition', 'Psychology', 'Cognitive science', 'Cognitive psychology', 'Artificial intelligence', 'Computer science', 'Neuroscience']","Deep unsupervised learning in stochastic recurrent neural networks with many layers of hidden units is a recent breakthrough in neural computation research. These networks build a hierarchy of progressively more complex distributed representations of the sensory data by fitting a hierarchical generative model. In this article we discuss the theoretical foundations of this approach and we review key issues related to training, testing and analysis of deep networks for modeling language and cognitive processing. The classic letter and word perception problem of McClelland and Rumelhart (1981) is used as a tutorial example to illustrate how structured and abstract representations may emerge from deep generative learning. We argue that the focus on deep architectures and generative (rather than discriminative) learning represents a crucial step forward for the connectionist modeling enterprise, because it offers a more plausible model of cortical learning as well as a way to bridge the gap between emergentist connectionist models and structured Bayesian models of cognition."
https://openalex.org/W2964677288,Unsupervised Learning of Scene Flow Estimation Fusing with Local Rigidity,"{'Scene': [0], 'flow': [1, 13, 20, 49, 70], 'estimation': [2], 'in': [3, 90], 'the': [4, 68, 83, 87, 91, 95, 99, 103, 110, 138, 141, 147], 'dynamic': [5], 'scene': [6, 12, 56], 'remains': [7], 'a': [8, 15, 37, 64], 'challenging': [9], 'task.': [10], 'Computing': [11], 'by': [14, 63, 98], 'combination': [16], 'of': [17, 44], '2D': [18], 'optical': [19, 48, 69, 116, 128], 'and': [21, 47, 71, 86, 102, 115, 133, 158], 'depth': [22, 46, 72, 114], 'has': [23], 'shown': [24], 'to': [25, 54, 81], 'be': [26, 119], 'considerably': [27], 'faster': [28], 'with': [29, 50, 74, 109], 'acceptable': [30], 'performance.': [31], 'In': [32, 79], 'this': [33], 'work,': [34], 'we': [35, 93, 144], 'present': [36], 'unified': [38], 'framework': [39, 122, 149], 'for': [40], 'joint': [41, 107], 'unsupervised': [42, 154], 'learning': [43, 108], 'stereo': [45], 'explicit': [51], 'local': [52, 111], 'rigidity': [53], 'estimate': [55, 59], 'flow.': [57], 'We': [58], 'camera': [60, 88, 130], 'motion': [61, 85, 89, 131, 135], 'directly': [62], 'Perspective-n-Point': [65], 'method': [66], 'from': [67], 'predictions,': [73], 'RANSAC': [75], 'outlier': [76], 'rejection': [77], 'scheme.': [78], 'order': [80], 'disambiguate': [82], 'object': [84, 134], 'scene,': [92], 'distinguish': [94], 'rigid': [96], 'region': [97], 're-project': [100], 'error': [101], 'photometric': [104], 'similarity.': [105], 'By': [106], 'rigidity,': [112], 'both': [113], 'networks': [117], 'can': [118], 'refined.': [120], 'This': [121], 'boosts': [123], 'all': [124], 'four': [125], 'tasks:': [126], 'depth,': [127], 'flow,': [129], 'estimation,': [132], 'segmentation.': [136], 'Through': [137], 'evaluation': [139], 'on': [140], 'KITTI': [142], 'benchmark,': [143], 'show': [145], 'that': [146], 'proposed': [148], 'achieves': [150], 'state-of-the-art': [151], 'results': [152], 'amongst': [153], 'methods.': [155], 'Our': [156], 'models': [157], 'code': [159], 'are': [160], 'available': [161], 'at': [162], 'https://github.com/lliuz/unrigidflow.': [163]}",2019,"['Optical flow', 'Artificial intelligence', 'Computer science', 'Computer vision', 'RANSAC', 'Outlier', 'Motion estimation', 'Motion field', 'Point cloud', 'Unsupervised learning', 'Segmentation', 'Boosting (machine learning)', 'Structure from motion', 'Image (mathematics)']","Scene flow estimation in the dynamic scene remains a challenging task. Computing scene flow by a combination of 2D optical flow and depth has shown to be considerably faster with acceptable performance. In this work, we present a unified framework for joint unsupervised learning of stereo depth and optical flow with explicit local rigidity to estimate scene flow. We estimate camera motion directly by a Perspective-n-Point method from the optical flow and depth predictions, with RANSAC outlier rejection scheme. In order to disambiguate the object motion and the camera motion in the scene, we distinguish the rigid region by the re-project error and the photometric similarity. By joint learning with the local rigidity, both depth and optical networks can be refined. This framework boosts all four tasks: depth, optical flow, camera motion estimation, and object motion segmentation. Through the evaluation on the KITTI benchmark, we show that the proposed framework achieves state-of-the-art results amongst unsupervised methods. Our models and code are available at https://github.com/lliuz/unrigidflow."
https://openalex.org/W199424061,Quantum algorithms for supervised and unsupervised machine learning,"{'Machine-learning': [0], 'tasks': [1], 'frequently': [2], 'involve': [3], 'problems': [4, 21], 'of': [5, 11, 29, 34, 77], 'manipulating': [6, 42], 'and': [7, 31, 54, 63, 79], 'classifying': [8], 'large': [9, 46], 'numbers': [10], 'vectors': [12, 30, 44, 78], 'in': [13, 26, 45, 73], 'high-dimensional': [14, 43], 'spaces.': [15, 49], 'Classical': [16], 'algorithms': [17, 59], 'for': [18, 60], 'solving': [19], 'such': [20], 'typically': [22], 'take': [23, 70], 'time': [24, 71], 'polynomial': [25], 'the': [27, 32, 35, 75], 'number': [28, 76], 'dimension': [33], 'space.': [36], 'Quantum': [37, 66], 'computers': [38], 'are': [39], 'good': [40], 'at': [41], 'tensor': [47], 'product': [48], 'This': [50], 'paper': [51], 'provides': [52], 'supervised': [53], 'unsupervised': [55], 'quantum': [56], 'machine': [57, 67], 'learning': [58, 68], 'cluster': [61, 64], 'assignment': [62], 'finding.': [65], 'can': [69], 'logarithmic': [72], 'both': [74], 'their': [80], 'dimension,': [81], 'an': [82], 'exponential': [83], 'speed-up': [84], 'over': [85], 'classical': [86], 'algorithms.': [87]}",2013,"['Dimension (graph theory)', 'Logarithm', 'Computer science', 'Unsupervised learning', 'Quantum algorithm', 'Algorithm', 'Quantum', 'Space (punctuation)', 'Artificial intelligence', 'Machine learning', 'Mathematics', 'Combinatorics', 'Quantum mechanics', 'Mathematical analysis', 'Operating system', 'Physics']","Machine-learning tasks frequently involve problems of manipulating and classifying large numbers of vectors in high-dimensional spaces. Classical algorithms for solving such problems typically take time polynomial in the number of vectors and the dimension of the space. Quantum computers are good at manipulating high-dimensional vectors in large tensor product spaces. This paper provides supervised and unsupervised quantum machine learning algorithms for cluster assignment and cluster finding. Quantum machine learning can take time logarithmic in both the number of vectors and their dimension, an exponential speed-up over classical algorithms."
https://openalex.org/W3022118338,Application of unsupervised learning and process simulation for energy optimization of a WWTP under various weather conditions,"{'Abstract': [0], 'This': [1, 50], 'paper': [2], 'outlines': [3], 'a': [4], 'hybrid': [5], 'modeling': [6], 'approach': [7], 'to': [8, 41, 97, 109], 'facilitate': [9], 'weather-based': [10, 104, 126], 'operation': [11, 131], 'and': [12, 28, 47, 82, 114], 'energy': [13, 137], 'optimization': [14], 'for': [15], 'the': [16, 35, 53, 57, 68, 77, 83, 99, 110, 130, 133], 'largest': [17], 'Italian': [18], 'wastewater': [19], 'treatment': [20], 'plant': [21, 136], '(WWTP).': [22], 'Two': [23, 73], 'clustering': [24, 100], 'methods,': [25], 'K-means': [26], 'algorithm': [27], 'Gaussian': [29], 'mixture': [30], 'model': [31], '(GMM)': [32], 'based': [33], 'on': [34], 'expectation-maximization': [36], '(EM)': [37], 'algorithm,': [38], 'were': [39, 95, 107], 'applied': [40], 'an': [42], 'extensive': [43], 'dataset': [44], 'of': [45, 55, 60, 116, 132], 'historical': [46], 'meteorological': [48], 'records.': [49], 'study': [51], 'addresses': [52], 'problem': [54], 'determining': [56], 'intrinsic': [58], 'structure': [59], 'clustered': [61], 'data': [62], 'when': [63], 'no': [64], 'information': [65, 79], 'other': [66], 'than': [67], 'observed': [69], 'values': [70], 'is': [71], 'available.': [72], 'quantitative': [74], 'indexes,': [75], 'namely': [76], 'Bayesian': [78], 'criterion': [80], '(BIC)': [81], 'Silhouette': [84], 'coefficient': [85], 'using': [86], 'Euclidean': [87], 'distance,': [88], 'as': [89, 91], 'well': [90], 'two': [92], 'general': [93], 'criteria,': [94], 'implemented': [96], 'assess': [98], 'quality.': [101], 'Furthermore,': [102], 'seven': [103], 'influent': [105], 'scenarios': [106], 'introduced': [108], 'process': [111], 'simulation': [112], 'model,': [113], 'sets': [115], 'aeration': [117, 127], 'strategies': [118, 128], 'are': [119], 'proposed.': [120], 'The': [121], 'results': [122], 'indicate': [123], 'that': [124], 'incorporating': [125], 'in': [129], 'WWTP': [134], 'improves': [135], 'efficiency.': [138]}",2020,"['Cluster analysis', 'Bayesian information criterion', 'Silhouette', 'Process (computing)', 'Computer science', 'Euclidean distance', 'Data mining', 'Artificial intelligence', 'Operating system']","Abstract This paper outlines a hybrid modeling approach to facilitate weather-based operation and energy optimization for the largest Italian wastewater treatment plant (WWTP). Two clustering methods, K-means algorithm and Gaussian mixture model (GMM) based on the expectation-maximization (EM) algorithm, were applied to an extensive dataset of historical and meteorological records. This study addresses the problem of determining the intrinsic structure of clustered data when no information other than the observed values is available. Two quantitative indexes, namely the Bayesian information criterion (BIC) and the Silhouette coefficient using Euclidean distance, as well as two general criteria, were implemented to assess the clustering quality. Furthermore, seven weather-based influent scenarios were introduced to the process simulation model, and sets of aeration strategies are proposed. The results indicate that incorporating weather-based aeration strategies in the operation of the WWTP improves plant energy efficiency."
https://openalex.org/W3022061250,Prototypical Contrastive Learning of Unsupervised Representations,"{'This': [0], 'paper': [1], 'presents': [2], 'Prototypical': [3], 'Contrastive': [4], 'Learning': [5], '(PCL),': [6], 'an': [7, 67], 'unsupervised': [8], 'representation': [9], 'learning': [10, 120], 'method': [11], 'that': [12], 'addresses': [13], 'the': [14, 28, 42, 45, 59, 63, 76, 86, 99], 'fundamental': [15], 'limitations': [16], 'of': [17, 30, 41, 62, 78, 98], 'instance-wise': [18, 118], 'contrastive': [19, 89, 103, 119], 'learning.': [20, 90, 131], 'PCL': [21, 115], 'not': [22], 'only': [23], 'learns': [24], 'low-level': [25], 'features': [26], 'for': [27, 102], 'task': [29], 'instance': [31], 'discrimination,': [32], 'but': [33], 'more': [34], 'importantly,': [35], 'it': [36], 'implicitly': [37], 'encodes': [38], 'semantic': [39], 'structures': [40], 'data': [43], 'into': [44], 'learned': [46], 'embedding': [47], 'space.': [48], 'Specifically,': [49], 'we': [50], 'introduce': [51], 'prototypes': [52, 79], 'as': [53, 74, 84], 'latent': [54], 'variables': [55], 'to': [56, 108, 111], 'help': [57], 'find': [58], 'maximum-likelihood': [60], 'estimation': [61], 'network': [64, 87], 'parameters': [65], 'in': [66, 128], 'Expectation-Maximization': [68], 'framework.': [69], 'We': [70, 91], 'iteratively': [71], 'perform': [72], 'E-step': [73], 'finding': [75], 'distribution': [77], 'via': [80, 88], 'clustering': [81], 'and': [82, 133], 'M-step': [83], 'optimizing': [85], 'propose': [92], 'ProtoNCE': [93], 'loss,': [94], 'a': [95], 'generalized': [96], 'version': [97], 'InfoNCE': [100], 'loss': [101], 'learning,': [104], 'which': [105], 'encourages': [106], 'representations': [107], 'be': [109], 'closer': [110], 'their': [112], 'assigned': [113], 'prototypes.': [114], 'outperforms': [116], 'state-of-the-art': [117], 'methods': [121], 'on': [122], 'multiple': [123], 'benchmarks': [124], 'with': [125], 'substantial': [126], 'improvement': [127], 'low-resource': [129], 'transfer': [130], 'Code': [132], 'pretrained': [134], 'models': [135], 'are': [136], 'available': [137], 'at': [138], 'https://github.com/salesforce/PCL.': [139]}",2020,"['Computer science', 'Artificial intelligence', 'Feature learning', 'Machine learning', 'Embedding', 'Unsupervised learning', 'Representation (politics)', 'Transfer of learning', 'Cluster analysis', 'Code (set theory)', 'Task (project management)', 'Latent variable', 'Natural language processing', 'Pattern recognition (psychology)', 'Economics', 'Set (abstract data type)', 'Management', 'Programming language', 'Law', 'Politics', 'Political science']","This paper presents Prototypical Contrastive Learning (PCL), an unsupervised representation learning method that addresses the fundamental limitations of instance-wise contrastive learning. PCL not only learns low-level features for the task of instance discrimination, but more importantly, it implicitly encodes semantic structures of the data into the learned embedding space. Specifically, we introduce prototypes as latent variables to help find the maximum-likelihood estimation of the network parameters in an Expectation-Maximization framework. We iteratively perform E-step as finding the distribution of prototypes via clustering and M-step as optimizing the network via contrastive learning. We propose ProtoNCE loss, a generalized version of the InfoNCE loss for contrastive learning, which encourages representations to be closer to their assigned prototypes. PCL outperforms state-of-the-art instance-wise contrastive learning methods on multiple benchmarks with substantial improvement in low-resource transfer learning. Code and pretrained models are available at https://github.com/salesforce/PCL."
https://openalex.org/W2983040767,Unsupervised Cross-lingual Representation Learning at Scale,"{'This': [0], 'paper': [1], 'shows': [2], 'that': [3, 109], 'pretraining': [4], 'multilingual': [5, 49, 148], 'language': [6, 28], 'models': [7, 161, 175], 'at': [8, 136], 'scale': [9], 'leads': [10], 'to': [11, 112], 'significant': [12], 'performance': [13, 129], 'gains': [14], 'for': [15, 88, 92, 141], 'a': [16, 25, 53, 101], 'wide': [17], 'range': [18], 'of': [19, 39, 55, 105, 130, 147], 'cross-lingual': [20, 56], 'transfer': [21, 122], 'tasks.': [22], 'We': [23, 98, 168], 'train': [24], 'Transformer-based': [26], 'masked': [27], 'model': [29], 'on': [30, 52, 62, 68, 74, 80, 162], 'one': [31], 'hundred': [32], 'languages,': [33, 82], 'using': [34], 'more': [35], 'than': [36], 'two': [37], 'terabytes': [38], 'filtered': [40], 'CommonCrawl': [41], 'data.': [42], 'Our': [43], 'model,': [44], 'dubbed': [45], 'XLM-R,': [46], 'significantly': [47], 'outperforms': [48], 'BERT': [50], '(mBERT)': [51], 'variety': [54], 'benchmarks,': [57], 'including': [58, 116], '+14.6%': [59], 'average': [60, 65], 'accuracy': [61, 87], 'XNLI,': [63], '+13%': [64], 'F1': [66, 72], 'score': [67, 73], 'MLQA,': [69], 'and': [70, 90, 123, 126, 132, 165, 174], '+2.4%': [71], 'NER.': [75], 'XLM-R': [76, 154], 'performs': [77], 'particularly': [78], 'well': [79], 'low-resource': [81], 'improving': [83], '15.7%': [84], 'in': [85], 'XNLI': [86, 166], 'Swahili': [89], '11.4%': [91], 'Urdu': [93], 'over': [94], 'previous': [95], 'XLM': [96], 'models.': [97], 'also': [99], 'present': [100], 'detailed': [102], 'empirical': [103], 'analysis': [104], 'the': [106, 117, 128, 142, 145, 163], 'key': [107], 'factors': [108], 'are': [110], 'required': [111], 'achieve': [113], 'these': [114], 'gains,': [115], 'trade-offs': [118], 'between': [119], '(1)': [120], 'positive': [121], 'capacity': [124], 'dilution': [125], '(2)': [127], 'high': [131], 'low': [133], 'resource': [134], 'languages': [135], 'scale.': [137], 'Finally,': [138], 'we': [139], 'show,': [140], 'first': [143], 'time,': [144], 'possibility': [146], 'modeling': [149], 'without': [150], 'sacrificing': [151], 'per-language': [152], 'performance;': [153], 'is': [155], 'very': [156], 'competitive': [157], 'with': [158], 'strong': [159], 'monolingual': [160], 'GLUE': [164], 'benchmarks.': [167], 'will': [169], 'make': [170], 'our': [171], 'code,': [172], 'data': [173], 'publicly': [176], 'available.': [177]}",2020,"['Computer science', 'Terabyte', 'Language model', 'Transformer', 'Natural language processing', 'Artificial intelligence', 'Voltage', 'Physics', 'Quantum mechanics', 'Operating system']","This paper shows that pretraining multilingual language models at scale leads to significant performance gains for a wide range of cross-lingual transfer tasks. We train a Transformer-based masked language model on one hundred languages, using more than two terabytes of filtered CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms multilingual BERT (mBERT) on a variety of cross-lingual benchmarks, including +14.6% average accuracy on XNLI, +13% average F1 score on MLQA, and +2.4% F1 score on NER. XLM-R performs particularly well on low-resource languages, improving 15.7% in XNLI accuracy for Swahili and 11.4% for Urdu over previous XLM models. We also present a detailed empirical analysis of the key factors that are required to achieve these gains, including the trade-offs between (1) positive transfer and capacity dilution and (2) the performance of high and low resource languages at scale. Finally, we show, for the first time, the possibility of multilingual modeling without sacrificing per-language performance; XLM-R is very competitive with strong monolingual models on the GLUE and XNLI benchmarks. We will make our code, data and models publicly available."
https://openalex.org/W2992361169,Robust blind spectral unmixing for fluorescence microscopy using unsupervised learning,"{'Due': [0], 'to': [1, 16, 90, 134, 168, 203, 216, 220, 231, 245], 'the': [2, 27, 37, 86, 92, 100, 150, 162, 184, 198, 243, 247], 'overlapping': [3], 'emission': [4, 82], 'spectra': [5, 83], 'of': [6, 81, 88, 103, 123, 152, 165, 186, 191, 200], 'fluorophores,': [7, 35], 'fluorescence': [8, 60, 226], 'microscopy': [9, 61, 167, 193], 'images': [10], 'often': [11], 'have': [12, 51], 'bleed-through': [13], 'problems,': [14], 'leading': [15], 'a': [17, 46, 113, 233, 239], 'false': [18], 'positive': [19], 'detection.': [20], 'This': [21, 158], 'problem': [22], 'is': [23, 39, 174], 'almost': [24], 'unavoidable': [25], 'when': [26, 43], 'samples': [28], 'are': [29], 'labeled': [30], 'with': [31, 176], 'three': [32], 'or': [33, 84], 'more': [34, 171], 'and': [36, 54, 72, 115, 143, 180, 206, 237], 'situation': [38], 'complicated': [40], 'even': [41], 'further': [42], 'imaged': [44], 'under': [45], 'multiphoton': [47], 'microscope.': [48], 'Several': [49], 'methods': [50], 'been': [52], 'developed': [53, 112], 'commonly': [55], 'used': [56], 'by': [57], 'biologists': [58], 'for': [59, 225], 'spectral': [62, 105, 117, 138, 222, 235], 'unmixing,': [63, 67], 'such': [64], 'as': [65, 94], 'linear': [66], 'non-negative': [68], 'matrix': [69], 'factorization,': [70], 'deconvolution,': [71], 'principal': [73], 'component': [74], 'analysis.': [75, 208], 'However,': [76], 'they': [77], 'either': [78], 'require': [79], 'pre-knowledge': [80], 'restrict': [85], 'number': [87, 151], 'fluorophores': [89, 153, 172], 'be': [91, 156], 'same': [93], 'detection': [95], 'channels,': [96], 'which': [97, 126], 'highly': [98, 160], 'limits': [99], 'real-world': [101], 'applications': [102], 'those': [104], 'unmixing': [106, 118, 223], 'methods.': [107], 'In': [108], 'this': [109, 201, 212], 'paper,': [110], 'we': [111, 210], 'robust': [114], 'flexible': [116], 'method:': [119], 'Learning': [120], 'Unsupervised': [121], 'Means': [122], 'Spectra': [124], '(LUMoS),': [125], 'uses': [127], 'an': [128, 218], 'unsupervised': [129], 'machine': [130], 'learning': [131], 'clustering': [132], 'method': [133, 159, 202], 'learn': [135], 'individual': [136], ""fluorophores'"": [137], 'signatures': [139], 'from': [140], 'mixed': [141], 'images,': [142], 'blindly': [144], 'separate': [145], 'channels': [146], 'without': [147, 242], 'restrictions': [148], 'on': [149], 'that': [154], 'can': [155], 'imaged.': [157], 'expands': [161], 'hardware': [163, 249], 'capability': [164], 'two-photon': [166, 192], 'simultaneously': [169], 'image': [170, 241], 'than': [173], 'possible': [175], 'instrumentation': [177], 'alone.': [178], 'Experimental': [179], 'simulated': [181], 'results': [182], 'demonstrated': [183], 'robustness': [185], 'LUMoS': [187, 228], 'in': [188], 'multi-channel': [189], 'separations': [190], 'images.': [194], 'We': [195], 'also': [196], 'extended': [197], 'application': [199], 'background/autofluorescence': [204], 'removal': [205], 'colocalization': [207], 'Lastly,': [209], 'integrated': [211], 'tool': [213, 224], 'into': [214], 'ImageJ': [215], 'offer': [217], 'easy': [219], 'use': [221], 'imaging.': [227], 'allows': [229], 'us': [230], 'gain': [232], 'higher': [234], 'resolution': [236], 'obtain': [238], 'cleaner': [240], 'need': [244], 'upgrade': [246], 'imaging': [248], 'capabilities.': [250]}",2019,"['Microscopy', 'Fluorescence microscope', 'Fluorescence', 'Artificial intelligence', 'Computational biology', 'Computer science', 'Biology', 'Physics', 'Optics']","Due to the overlapping emission spectra of fluorophores, fluorescence microscopy images often have bleed-through problems, leading to a false positive detection. This problem is almost unavoidable when the samples are labeled with three or more fluorophores, and the situation is complicated even further when imaged under a multiphoton microscope. Several methods have been developed and commonly used by biologists for fluorescence microscopy spectral unmixing, such as linear unmixing, non-negative matrix factorization, deconvolution, and principal component analysis. However, they either require pre-knowledge of emission spectra or restrict the number of fluorophores to be the same as detection channels, which highly limits the real-world applications of those spectral unmixing methods. In this paper, we developed a robust and flexible spectral unmixing method: Learning Unsupervised Means of Spectra (LUMoS), which uses an unsupervised machine learning clustering method to learn individual fluorophores' spectral signatures from mixed images, and blindly separate channels without restrictions on the number of fluorophores that can be imaged. This method highly expands the hardware capability of two-photon microscopy to simultaneously image more fluorophores than is possible with instrumentation alone. Experimental and simulated results demonstrated the robustness of LUMoS in multi-channel separations of two-photon microscopy images. We also extended the application of this method to background/autofluorescence removal and colocalization analysis. Lastly, we integrated this tool into ImageJ to offer an easy to use spectral unmixing tool for fluorescence imaging. LUMoS allows us to gain a higher spectral resolution and obtain a cleaner image without the need to upgrade the imaging hardware capabilities."
https://openalex.org/W2962953132,Unsupervised Learning on Resistive Memory Array Based Spiking Neural Networks,"{'Spiking': [0], 'Neural': [1], 'Networks': [2], '(SNNs)': [3], 'offer': [4], 'great': [5], 'potential': [6, 38], 'to': [7, 80, 161], 'promote': [8], 'both': [9, 162], 'the': [10, 19, 64, 78, 83, 98, 136, 141, 146, 149, 173], 'performance': [11], 'and': [12, 102, 157, 164], 'efficiency': [13], 'of': [14, 22, 87, 151, 154, 189], 'real-world': [15], 'computing': [16], 'systems,': [17], 'considering': [18], 'biological': [20], 'plausibility': [21], 'SNNs.': [23, 44], 'The': [24, 90, 132], 'emerging': [25], 'analog': [26], 'Resistive': [27], 'Random': [28], 'Access': [29], 'Memory': [30], '(RRAM)': [31], 'devices': [32, 113, 181], 'have': [33, 121, 159], 'drawn': [34], 'increasing': [35], 'interest': [36], 'as': [37, 97], 'neuromorphic': [39, 193], 'hardware': [40], 'for': [41, 57, 148, 195], 'implementing': [42], 'practical': [43], 'In': [45], 'this': [46, 103], 'article,': [47], 'we': [48], 'propose': [49], 'a': [50], 'novel': [51], 'training': [52], 'approach': [53], '(called': [54], 'greedy': [55], 'training)': [56], 'SNNs': [58, 76, 91, 138, 170], 'by': [59, 140, 172], 'diluting': [60], 'spike': [61], 'events': [62], 'on': [63, 70, 108, 129], 'temporal': [65], 'dimension': [66], 'with': [67, 77, 82, 117, 178, 182], 'necessary': [68], 'controls': [69], 'input': [71], 'encoding': [72], 'phase': [73], 'switching,': [74], 'endowing': [75], 'ability': [79], 'cooperate': [81, 177], 'inevitable': [84], 'conductance': [85, 167], 'variations': [86], 'RRAM': [88, 112, 155, 166, 180, 190], 'devices.': [89], 'could': [92, 144, 176], 'utilize': [93], 'Spike-Timing-Dependent': [94], 'Plasticity': [95], '(STDP)': [96], 'unsupervised': [99, 137], 'learning': [100], 'rule,': [101], 'plasticity': [104], 'has': [105], 'been': [106], 'observed': [107], 'our': [109], 'one-transistor-one-resistor': [110], '(1T1R)': [111], 'under': [114], 'voltage': [115], 'pulses': [116], 'designed': [118], 'waveforms.': [119], 'We': [120], 'also': [122, 158], 'conducted': [123], 'handwritten': [124], 'digit': [125], 'recognition': [126], 'task': [127], 'simulations': [128], 'MNIST': [130], 'dataset.': [131], 'results': [133], 'show': [134], 'that': [135], 'trained': [139, 171], 'proposed': [142, 174], 'method': [143], 'mitigate': [145], 'requirement': [147], 'number': [150], 'gradual': [152], 'levels': [153], 'devices,': [156], 'immunity': [160], 'cycle-to-cycle': [163], 'device-to-device': [165], 'variations.': [168], 'Unsupervised': [169], 'methods': [175], 'real': [179], 'non-ideal': [183], 'behaviors': [184], 'better,': [185], 'promising': [186], 'high': [187], 'feasibility': [188], 'array': [191], 'based': [192], 'systems': [194], 'online': [196], 'training.': [197]}",2019,"['Neuromorphic engineering', 'Spiking neural network', 'Resistive random-access memory', 'Computer science', 'MNIST database', 'Spike-timing-dependent plasticity', 'Artificial intelligence', 'Unsupervised learning', 'Pattern recognition (psychology)', 'Artificial neural network', 'Voltage', 'Electrical engineering', 'Engineering', 'Long-term potentiation', 'Chemistry', 'Biochemistry', 'Receptor']","Spiking Neural Networks (SNNs) offer great potential to promote both the performance and efficiency of real-world computing systems, considering the biological plausibility of SNNs. The emerging analog Resistive Random Access Memory (RRAM) devices have drawn increasing interest as potential neuromorphic hardware for implementing practical SNNs. In this article, we propose a novel training approach (called greedy training) for SNNs by diluting spike events on the temporal dimension with necessary controls on input encoding phase switching, endowing SNNs with the ability to cooperate with the inevitable conductance variations of RRAM devices. The SNNs could utilize Spike-Timing-Dependent Plasticity (STDP) as the unsupervised learning rule, and this plasticity has been observed on our one-transistor-one-resistor (1T1R) RRAM devices under voltage pulses with designed waveforms. We have also conducted handwritten digit recognition task simulations on MNIST dataset. The results show that the unsupervised SNNs trained by the proposed method could mitigate the requirement for the number of gradual levels of RRAM devices, and also have immunity to both cycle-to-cycle and device-to-device RRAM conductance variations. Unsupervised SNNs trained by the proposed methods could cooperate with real RRAM devices with non-ideal behaviors better, promising high feasibility of RRAM array based neuromorphic systems for online training."
https://openalex.org/W4200583473,Drug-likeness scoring based on unsupervised learning,"{'A': [0], 'new': [1], 'quantification': [2], 'method': [3, 11], 'of': [4], 'drug-likeness': [5], 'based': [6], 'on': [7], 'unsupervised': [8], 'learning.': [9], 'The': [10], 'only': [12], 'uses': [13], 'drug': [14], 'molecules': [15], 'as': [16], 'training': [17], 'set': [18], 'without': [19], 'any': [20], 'non-drug-like': [21], 'molecules.': [22]}",2021,"['Computer science', 'Artificial intelligence', 'Machine learning', 'Unsupervised learning', 'Dependency (UML)', 'Artificial neural network', 'Binary classification', 'Set (abstract data type)', 'Graph', 'Regression', 'Pattern recognition (psychology)', 'Support vector machine', 'Mathematics', 'Statistics', 'Theoretical computer science', 'Programming language']",A new quantification method of drug-likeness based on unsupervised learning. The method only uses drug molecules as training set without any non-drug-like molecules.
https://openalex.org/W1948599600,Unsupervised learning of depth and motion,"{'We': [0, 36], 'present': [1], 'a': [2, 29, 54, 60, 114], 'model': [3, 13], 'for': [4], 'the': [5, 19, 32, 78, 88], 'joint': [6], 'estimation': [7], 'of': [8, 34, 57, 63, 90], 'disparity': [9], 'and': [10, 41, 59, 92, 105], 'motion.': [11], 'The': [12], 'is': [14, 51], 'based': [15], 'on': [16], 'learning': [17, 39, 64, 89], 'about': [18], 'interrelations': [20], 'between': [21, 77], 'images': [22], 'from': [23, 49], 'multiple': [24, 26], 'cameras,': [25], 'frames': [27], 'in': [28, 101], 'video,': [30], 'or': [31], 'combination': [33], 'both.': [35], 'show': [37, 86], 'that': [38, 87], 'depth': [40, 91], 'motion': [42, 93, 111], 'cues,': [43], 'as': [44, 46], 'well': [45], 'their': [47], 'combinations,': [48], 'data': [50], 'possible': [52, 96], 'within': [53], 'single': [55, 61], 'type': [56, 62], 'architecture': [58], 'algorithm,': [65], 'by': [66, 113], 'using': [67], 'biologically': [68], 'inspired': [69], '""complex': [70], 'cell""': [71], 'like': [72], 'units,': [73], 'which': [74], 'encode': [75], 'correlations': [76], 'pixels': [79], 'across': [80], 'image': [81], 'pairs.': [82], 'Our': [83], 'experimental': [84], 'results': [85], 'makes': [94], 'it': [95], 'to': [97, 106], 'achieve': [98], 'state-of-the-art': [99], 'performance': [100], '3-D': [102, 110], 'activity': [103], 'analysis,': [104], 'outperform': [107], 'existing': [108], 'hand-engineered': [109], 'features': [112], 'very': [115], 'large': [116], 'margin.': [117]}",2013,"['ENCODE', 'Artificial intelligence', 'Computer science', 'Motion (physics)', 'Margin (machine learning)', 'Computer vision', 'Motion estimation', 'Pixel', 'Image (mathematics)', 'Pattern recognition (psychology)', 'Type (biology)', 'Joint (building)', 'Unsupervised learning', 'Machine learning', 'Engineering', 'Geology', 'Gene', 'Chemistry', 'Paleontology', 'Biochemistry', 'Architectural engineering']","We present a model for the joint estimation of disparity and motion. The model is based on learning about the interrelations between images from multiple cameras, multiple frames in a video, or the combination of both. We show that learning depth and motion cues, as well as their combinations, from data is possible within a single type of architecture and a single type of learning algorithm, by using biologically inspired ""complex cell"" like units, which encode correlations between the pixels across image pairs. Our experimental results show that the learning of depth and motion makes it possible to achieve state-of-the-art performance in 3-D activity analysis, and to outperform existing hand-engineered 3-D motion features by a very large margin."
https://openalex.org/W2778361827,FoldingNet: Interpretable Unsupervised Learning on 3D Point Clouds,"{'Recent': [0], 'deep': [1, 35], 'networks': [2], 'that': [3, 111, 136], 'directly': [4], 'handle': [5], 'points': [6], 'in': [7, 71, 129], 'a': [8, 32, 51, 65, 76, 86, 98, 107, 133, 146, 162], 'point': [9, 22, 45, 87, 143, 172], 'set,': [10], 'e.g.,': [11], 'PointNet,': [12], 'have': [13], 'been': [14], 'state-of-the-art': [15], 'for': [16], 'supervised': [17], 'semantic': [18], 'learning': [19, 42], 'tasks': [20], 'on': [21, 44, 60], 'clouds': [23], 'such': [24], 'as': [25, 161], 'classification': [26, 116], 'and': [27], 'segmentation.': [28], 'In': [29, 121], 'this': [30, 150], 'work,': [31], 'novel': [33, 66], 'end-to-end': [34], 'auto-encoder': [36], 'is': [37, 54, 69, 127, 137, 153], 'proposed': [38, 70, 90, 124], 'to': [39, 56, 106, 131, 139, 170], 'address': [40], 'unsupervised': [41], 'challenges': [43], 'clouds.': [46], 'On': [47], 'the': [48, 72, 80, 119, 123, 156, 167, 171], 'encoder': [49], 'side,': [50], 'graph-based': [52], 'enhancement': [53], 'enforced': [55], 'promote': [57], 'local': [58], 'structures': [59], 'top': [61], 'of': [62, 85, 97], 'PointNet.': [63], 'Then,': [64], 'folding-based': [67, 151], 'approach': [68], 'decoder,': [73], 'which': [74], 'folds': [75], '2D': [77, 147, 168], 'grid': [78, 169], 'onto': [79], 'underlying': [81], '3D': [82], 'object': [83], 'surface': [84], 'cloud.': [88], 'The': [89], 'decoder': [91, 99, 125, 152], 'only': [92], 'uses': [93], 'about': [94], '7\\%': [95], 'parameters': [96], 'with': [100], 'fully-connected': [101], 'neural': [102], 'networks,': [103], 'yet': [104], 'leads': [105], 'more': [108], 'discriminative': [109], 'representation': [110], 'achieves': [112], 'higher': [113], 'linear': [114], 'SVM': [115], 'accuracy': [117], 'than': [118], 'benchmark.': [120], 'addition,': [122], 'structure': [126], 'shown,': [128], 'theory,': [130], 'be': [132, 159], 'generic': [134], 'architecture': [135], 'able': [138], 'reconstruct': [140], 'an': [141], 'arbitrary': [142], 'cloud': [144, 173], 'from': [145, 166], 'grid.': [148], 'Finally,': [149], 'interpretable': [154], 'since': [155], 'reconstruction': [157], 'could': [158], 'viewed': [160], 'fine': [163], 'granular': [164], 'warping': [165], 'surface.': [174]}",2017,"['Point cloud', 'Computer science', 'Artificial intelligence', 'Deep learning', 'Grid', 'Feature learning', 'Benchmark (surveying)', 'Unsupervised learning', 'Segmentation', 'Pattern recognition (psychology)', 'Mathematics', 'Geodesy', 'Geometry', 'Geography']","Recent deep networks that directly handle points in a point set, e.g., PointNet, have been state-of-the-art for supervised semantic learning tasks on point clouds such as classification and segmentation. In this work, a novel end-to-end deep auto-encoder is proposed to address unsupervised learning challenges on point clouds. On the encoder side, a graph-based enhancement is enforced to promote local structures on top of PointNet. Then, a novel folding-based approach is proposed in the decoder, which folds a 2D grid onto the underlying 3D object surface of a point cloud. The proposed decoder only uses about 7\% parameters of a decoder with fully-connected neural networks, yet leads to a more discriminative representation that achieves higher linear SVM classification accuracy than the benchmark. In addition, the proposed decoder structure is shown, in theory, to be a generic architecture that is able to reconstruct an arbitrary point cloud from a 2D grid. Finally, this folding-based decoder is interpretable since the reconstruction could be viewed as a fine granular warping from the 2D grid to the point cloud surface."
https://openalex.org/W3041261371,Identifying Different Classes of Seismic Noise Signals Using Unsupervised Learning,"{'Abstract': [0], 'Proper': [1], 'classification': [2], 'of': [3, 17, 31, 52, 68, 97, 99, 106, 114, 124], 'nontectonic': [4, 147], 'seismic': [5, 33, 70, 75, 116, 140], 'signals': [6, 87, 144], 'is': [7, 61], 'critical': [8], 'for': [9], 'detecting': [10], 'microearthquakes': [11], 'and': [12, 40, 54, 92, 110], 'developing': [13], 'an': [14], 'improved': [15], 'understanding': [16], 'ongoing': [18], 'weak': [19, 107], 'ground': [20, 108], 'motions.': [21], 'We': [22, 82], 'use': [23], 'unsupervised': [24], 'machine': [25], 'learning': [26], 'to': [27, 48, 63, 131], 'label': [28], 'five': [29], 'classes': [30], 'nonstationary': [32], 'noise': [34, 86], 'common': [35], 'in': [36, 136], 'continuous': [37, 69], 'waveforms.': [38, 56], 'Temporal': [39], 'spectral': [41], 'features': [42], 'describing': [43], 'the': [44, 104, 112, 129], 'data': [45], 'are': [46], 'clustered': [47], 'identify': [49], 'separable': [50], 'types': [51], 'emergent': [53], 'impulsive': [55], 'The': [57, 101], 'trained': [58], 'clustering': [59], 'model': [60], 'used': [62], 'classify': [64], 'every': [65], '1': [66], 's': [67], 'records': [71], 'from': [72, 146], 'a': [73, 119], 'dense': [74], 'array': [76], 'with': [77, 118], '10–30': [78], 'm': [79], 'station': [80], 'spacing.': [81], 'show': [83], 'that': [84], 'dominate': [85], 'can': [88], 'be': [89], 'highly': [90], 'localized': [91], 'vary': [93], 'on': [94], 'length': [95], 'scales': [96], 'hundreds': [98], 'meters.': [100], 'methodology': [102], 'demonstrates': [103], 'complexity': [105], 'motions': [109], 'improves': [111], 'standard': [113], 'analyzing': [115], 'waveforms': [117], 'low': [120], 'signal‐to‐noise': [121], 'ratio.': [122], 'Application': [123], 'this': [125], 'technique': [126], 'will': [127], 'improve': [128], 'ability': [130], 'detect': [132], 'genuine': [133], 'microseismic': [134], 'events': [135], 'noisy': [137], 'environments': [138], 'where': [139], 'sensors': [141], 'record': [142], 'earthquake‐like': [143], 'originating': [145], 'sources.': [148]}",2020,"['Waveform', 'Microseism', 'Noise (video)', 'Seismic noise', 'Cluster analysis', 'Geology', 'Seismology', 'Computer science', 'SIGNAL (programming language)', 'Pattern recognition (psychology)', 'Speech recognition', 'Acoustics', 'Artificial intelligence', 'Physics', 'Telecommunications', 'Programming language', 'Radar', 'Image (mathematics)']",Abstract Proper classification of nontectonic seismic signals is critical for detecting microearthquakes and developing an improved understanding of ongoing weak ground motions. We use unsupervised machine learning to label five classes of nonstationary seismic noise common in continuous waveforms. Temporal and spectral features describing the data are clustered to identify separable types of emergent and impulsive waveforms. The trained clustering model is used to classify every 1 s of continuous seismic records from a dense seismic array with 10–30 m station spacing. We show that dominate noise signals can be highly localized and vary on length scales of hundreds of meters. The methodology demonstrates the complexity of weak ground motions and improves the standard of analyzing seismic waveforms with a low signal‐to‐noise ratio. Application of this technique will improve the ability to detect genuine microseismic events in noisy environments where seismic sensors record earthquake‐like signals originating from nontectonic sources.
https://openalex.org/W1980276779,Visualization of Support Vector Machines with Unsupervised Learning,"{'The': [0], 'visualization': [1, 46, 104, 125], 'of': [2, 18, 30, 48, 65, 77, 92, 105, 121], 'support': [3, 49, 111, 122], 'vector': [4, 50, 112, 123], 'machines': [5, 51], 'in': [6, 38], 'realistic': [7], 'settings': [8], 'is': [9], 'a': [10, 44, 71, 86, 119], 'difficult': [11], 'problem': [12], 'due': [13], 'to': [14], 'the': [15, 19, 28, 31, 34, 39, 83, 90, 93, 103], 'high': [16], 'dimensionality': [17], 'typical': [20], 'datasets': [21, 107], 'involved.': [22], 'However,': [23], 'such': [24], 'visualizations': [25], 'usually': [26], 'aid': [27], 'understanding': [29], 'model': [32], 'and': [33, 80], 'underlying': [35], 'processes,': [36], 'especially': [37], 'biosciences.': [40], 'Here': [41], 'we': [42, 117], 'propose': [43], 'novel': [45], 'technique': [47, 116], 'based': [52, 127], 'on': [53, 128], 'unsupervised': [54], 'learning,': [55], 'specifically': [56], 'self-organizing': [57, 60], 'maps.': [58], 'Conceptually,': [59], 'maps': [61], 'can': [62], 'be': [63], 'thought': [64], 'as': [66, 96, 98], 'neural': [67], 'networks': [68], 'that': [69], 'investigate': [70, 118], 'high-dimensional': [72, 106], 'data': [73, 78], 'space': [74], 'for': [75, 102], 'clusters': [76, 84, 95], 'points': [79], 'then': [81], 'project': [82], 'onto': [85], 'two-dimensional': [87], 'map': [88], 'preserving': [89], 'topologies': [91], 'original': [94], 'much': [97], 'possible.': [99], 'This': [100], 'allows': [101], 'together': [108], 'with': [109], 'their': [110], 'models.': [113], 'With': [114], 'this': [115], 'number': [120], 'machine': [124], 'scenarios': [126], 'real': [129], 'world': [130], 'biomedical': [131], 'datasets.': [132], '©2006': [133], 'IEEE.': [134]}",2006,"['Visualization', 'Computer science', 'Curse of dimensionality', 'Data visualization', 'Support vector machine', 'Self-organizing map', 'Artificial intelligence', 'Unsupervised learning', 'Machine learning', 'Artificial neural network', 'Space (punctuation)', 'Data mining', 'Operating system']","The visualization of support vector machines in realistic settings is a difficult problem due to the high dimensionality of the typical datasets involved. However, such visualizations usually aid the understanding of the model and the underlying processes, especially in the biosciences. Here we propose a novel visualization technique of support vector machines based on unsupervised learning, specifically self-organizing maps. Conceptually, self-organizing maps can be thought of as neural networks that investigate a high-dimensional data space for clusters of data points and then project the clusters onto a two-dimensional map preserving the topologies of the original clusters as much as possible. This allows for the visualization of high-dimensional datasets together with their support vector models. With this technique we investigate a number of support vector machine visualization scenarios based on real world biomedical datasets. ©2006 IEEE."
https://openalex.org/W2167301710,Unsupervised learning of Arabic stemming using a parallel corpus,"{'This': [0], 'paper': [1], 'presents': [2], 'an': [3, 25, 120, 130], 'unsupervised': [4, 121], 'learning': [5], 'approach': [6, 82, 94], 'to': [7, 56, 64, 66, 85, 119], 'building': [8], 'a': [9, 29, 67, 100], 'non-English': [10], '(Arabic)': [11], 'stemmer.': [12], 'The': [13], 'stemming': [14], 'model': [15], 'is': [16, 44, 83], 'based': [17], 'on': [18], 'statistical': [19], 'machine': [20], 'translation': [21], 'and': [22, 28, 73, 113, 140], 'it': [23, 63], 'uses': [24], 'English': [26], 'stemmer': [27, 60, 107, 148], 'small': [30], '(10': [31], 'K': [32], 'sentences)': [33], 'parallel': [34, 42], 'corpus': [35], 'as': [36], 'its': [37], 'sole': [38], 'training': [39, 48], 'resources.': [40], 'No': [41], 'text': [43, 52], 'needed': [45], 'after': [46], 'the': [47, 59, 81, 103, 143, 146], 'phase.': [49], 'Monolingual,': [50], 'unannotated': [51], 'can': [53], 'be': [54, 76], 'used': [55], 'further': [57], 'improve': [58], 'by': [61], 'allowing': [62], 'adapt': [65], 'desired': [68], 'domain': [69], 'or': [70], 'genre.': [71], 'Examples': [72], 'results': [74, 95], 'will': [75], 'given': [77], 'for': [78], 'Arabic,': [79], 'but': [80], 'applicable': [84], 'any': [86], 'language': [87], 'that': [88], 'needs': [89], 'affix': [90, 111], 'removal.': [91], 'Our': [92], 'resource-frugal': [93], 'in': [96, 117, 134], '87.5%': [97], 'agreement': [98], 'with': [99], 'state': [101], 'of': [102, 132, 142, 145], 'art,': [104], 'proprietary': [105, 147], 'Arabic': [106, 126], 'built': [108], 'using': [109, 125], 'rules,': [110], 'lists,': [112], 'human': [114], 'annotated': [115], 'text,': [116, 139], 'addition': [118], 'component.': [122], 'Task-based': [123], 'evaluation': [124], 'information': [127], 'retrieval': [128], 'indicates': [129], 'improvement': [131], '22-38%': [133], 'average': [135], 'precision': [136], 'over': [137], 'unstemmed': [138], '96%': [141], 'performance': [144], 'above.': [149]}",2003,"['Affix', 'Computer science', 'Natural language processing', 'Artificial intelligence', 'Machine translation', 'Arabic', 'Parallel corpora', 'Component (thermodynamics)', 'Task (project management)', 'Text corpus', 'Domain (mathematical analysis)', 'Unsupervised learning', 'Linguistics', 'Physics', 'Thermodynamics', 'Management', 'Mathematics', 'Philosophy', 'Mathematical analysis', 'Economics']","This paper presents an unsupervised learning approach to building a non-English (Arabic) stemmer. The stemming model is based on statistical machine translation and it uses an English stemmer and a small (10 K sentences) parallel corpus as its sole training resources. No parallel text is needed after the training phase. Monolingual, unannotated text can be used to further improve the stemmer by allowing it to adapt to a desired domain or genre. Examples and results will be given for Arabic, but the approach is applicable to any language that needs affix removal. Our resource-frugal approach results in 87.5% agreement with a state of the art, proprietary Arabic stemmer built using rules, affix lists, and human annotated text, in addition to an unsupervised component. Task-based evaluation using Arabic information retrieval indicates an improvement of 22-38% in average precision over unstemmed text, and 96% of the performance of the proprietary stemmer above."
https://openalex.org/W4366773827,On the Philosophy of Unsupervised Learning,"{'Abstract': [0], 'Unsupervised': [1], 'learning': [2, 41, 66, 145], 'algorithms': [3], 'are': [4], 'widely': [5, 46], 'used': [6], 'for': [7, 87, 181], 'many': [8], 'important': [9], 'statistical': [10], 'tasks': [11], 'with': [12, 52], 'numerous': [13], 'applications': [14], 'in': [15, 34, 105], 'science': [16], 'and': [17, 39, 48, 70, 81, 91, 174, 190], 'industry.': [18], 'Yet': [19], 'despite': [20], 'their': [21], 'prevalence,': [22], 'they': [23], 'have': [24, 44], 'attracted': [25], 'remarkably': [26], 'little': [27], 'philosophical': [28, 107, 153], 'scrutiny': [29], 'to': [30, 37, 118], 'date.': [31], 'This': [32, 96], 'stands': [33], 'stark': [35], 'contrast': [36], 'supervised': [38, 131], 'reinforcement': [40, 133], 'algorithms,': [42], 'which': [43], 'been': [45], 'studied': [47], 'critically': [49], 'evaluated,': [50], 'often': [51, 123], 'an': [53, 165], 'emphasis': [54], 'on': [55, 109, 168], 'ethical': [56, 175], 'concerns.': [57], 'In': [58], 'this': [59, 196], 'article,': [60], 'I': [61, 73, 141, 177], 'analyze': [62], 'three': [63], 'canonical': [64], 'unsupervised': [65, 110, 144, 169], 'problems:': [67], 'clustering,': [68], 'abstraction,': [69], 'generative': [71], 'modeling.': [72], 'argue': [74], 'that': [75, 143, 186], 'these': [76], 'methods': [77, 170], 'raise': [78], 'unique': [79], 'epistemological': [80], 'ontological': [82], 'questions,': [83], 'providing': [84], 'data-driven': [85], 'tools': [86], 'discovering': [88], 'natural': [89], 'kinds': [90], 'distinguishing': [92], 'essence': [93], 'from': [94], 'contingency.': [95], 'analysis': [97], 'goes': [98], 'some': [99], 'way': [100], 'toward': [101], 'filling': [102], 'the': [103, 157, 188, 192], 'lacuna': [104], 'contemporary': [106], 'discourse': [108], 'learning,': [111], 'as': [112, 114], 'well': [113], 'bringing': [115], 'conceptual': [116], 'unity': [117], 'a': [119, 149, 182], 'heterogeneous': [120], 'field': [121], 'more': [122], 'described': [124], 'by': [125, 136, 179, 195], 'what': [126, 137], 'it': [127, 138], 'is': [128, 139, 146], 'not': [129, 147], '(i.e.,': [130], 'or': [132], 'learning)': [134], 'than': [135], '.': [140], 'submit': [142], 'just': [148], 'legitimate': [150], 'subject': [151], 'of': [152, 161, 199], 'inquiry': [154], 'but': [155], 'perhaps': [156], 'most': [158], 'fundamental': [159], 'branch': [160], 'all': [162], 'AI.': [163], 'However,': [164], 'uncritical': [166], 'overreliance': [167], 'poses': [171], 'major': [172], 'epistemic': [173], 'risks.': [176], 'conclude': [178], 'advocating': [180], 'pragmatic,': [183], 'error-statistical': [184], 'approach': [185], 'embraces': [187], 'opportunities': [189], 'mitigates': [191], 'challenges': [193], 'posed': [194], 'powerful': [197], 'class': [198], 'algorithms.': [200]}",2023,"['Unsupervised learning', 'Artificial intelligence', 'Computer science', 'Epistemology', 'Philosophy of science', 'Cluster analysis', 'Philosophy of technology', 'Reinforcement learning', 'Contingency', 'Scrutiny', 'Generative grammar', 'Cognitive science', 'Machine learning', 'Psychology', 'Philosophy', 'Theology']","Abstract Unsupervised learning algorithms are widely used for many important statistical tasks with numerous applications in science and industry. Yet despite their prevalence, they have attracted remarkably little philosophical scrutiny to date. This stands in stark contrast to supervised and reinforcement learning algorithms, which have been widely studied and critically evaluated, often with an emphasis on ethical concerns. In this article, I analyze three canonical unsupervised learning problems: clustering, abstraction, and generative modeling. I argue that these methods raise unique epistemological and ontological questions, providing data-driven tools for discovering natural kinds and distinguishing essence from contingency. This analysis goes some way toward filling the lacuna in contemporary philosophical discourse on unsupervised learning, as well as bringing conceptual unity to a heterogeneous field more often described by what it is not (i.e., supervised or reinforcement learning) than by what it is . I submit that unsupervised learning is not just a legitimate subject of philosophical inquiry but perhaps the most fundamental branch of all AI. However, an uncritical overreliance on unsupervised methods poses major epistemic and ethical risks. I conclude by advocating for a pragmatic, error-statistical approach that embraces the opportunities and mitigates the challenges posed by this powerful class of algorithms."
https://openalex.org/W2003296078,Unsupervised learning for graph matching,"{'Graph': [0], 'matching': [1, 17, 35, 45, 127], 'is': [2, 10, 24, 40, 73, 90], 'an': [3, 69], 'important': [4, 41], 'problem': [5], 'in': [6, 12, 68, 92], 'computer': [7], 'vision.': [8], 'It': [9], 'used': [11], '2D': [13], 'and': [14, 18, 51, 94], '3D': [15], 'object': [16], 'recognition.': [19], 'Despite': [20], 'its': [21], 'importance,': [22], 'there': [23], 'little': [25], 'literature': [26], 'on': [27], 'learning': [28, 39, 67, 89, 116], 'the': [29, 33, 44, 60, 97, 102, 120], 'parameters': [30], 'that': [31, 72, 87, 114], 'control': [32], 'graph': [34, 126], 'problem,': [36], 'even': [37], 'though': [38], 'for': [42, 59], 'improving': [43], 'rate,': [46], 'as': [47], 'shown': [48], 'by': [49], 'this': [50, 55, 115], 'other': [52], 'work.': [53], 'In': [54], 'paper': [56], 'we': [57], 'show': [58, 85], 'first': [61], 'time': [62], 'how': [63], 'to': [64], 'perform': [65], 'parameter': [66], 'unsupervised': [70, 88], 'fashion,': [71], 'when': [74], 'no': [75], 'correct': [76], 'correspondences': [77], 'between': [78], 'graphs': [79], 'are': [80], 'given': [81], 'during': [82], 'training.': [83], 'We': [84, 110], 'empirically': [86], 'comparable': [91], 'efficiency': [93], 'quality': [95], 'with': [96], 'supervised': [98], 'one,': [99], 'while': [100], 'avoiding': [101], 'tedious': [103], 'manual': [104], 'labeling': [105], 'of': [106, 122], 'ground': [107], 'truth': [108], 'correspondences.': [109], 'also': [111], 'verify': [112], 'experimentally': [113], 'method': [117], 'can': [118], 'improve': [119], 'performance': [121], 'several': [123], 'state-of-the': [124], 'art': [125], 'algorithms.': [128]}",2009,"['Computer science', 'Matching (statistics)', 'Unsupervised learning', 'Artificial intelligence', 'Graph', 'Ground truth', 'Machine learning', 'Pattern recognition (psychology)', '3-dimensional matching', 'Theoretical computer science', 'Mathematics', 'Bipartite graph', 'Statistics']","Graph matching is an important problem in computer vision. It is used in 2D and 3D object matching and recognition. Despite its importance, there is little literature on learning the parameters that control the graph matching problem, even though learning is important for improving the matching rate, as shown by this and other work. In this paper we show for the first time how to perform parameter learning in an unsupervised fashion, that is when no correct correspondences between graphs are given during training. We show empirically that unsupervised learning is comparable in efficiency and quality with the supervised one, while avoiding the tedious manual labeling of ground truth correspondences. We also verify experimentally that this learning method can improve the performance of several state-of-the art graph matching algorithms."
https://openalex.org/W2887799638,Evaluating Insider Threat Detection Workflow Using Supervised and Unsupervised Learning,"{'Insider': [0], 'threat': [1, 21], 'is': [2], 'a': [3, 46], 'prominent': [4], 'cyber-security': [5], 'danger': [6], 'faced': [7], 'by': [8], 'organizations': [9], 'and': [10, 17, 26, 37, 41, 55, 62], 'companies.': [11], 'In': [12], 'this': [13, 31, 66], 'research,': [14], 'we': [15, 33], 'study': [16, 34], 'evaluate': [18, 52], 'an': [19], 'insider': [20], 'detection': [22, 40], 'workflow': [23], 'using': [24, 65], 'supervised': [25, 54], 'unsupervised': [27, 56], 'learning': [28, 57], 'algorithms.': [29], 'To': [30], 'end,': [32], 'data': [35, 49], 'exploration': [36], 'analysis,': [38], 'anomaly': [39], 'malicious': [42], 'behaviour': [43], 'classification': [44], 'on': [45], 'publicly': [47], 'available': [48], 'set.': [50], 'We': [51], 'several': [53], 'algorithms': [58], '-': [59, 64], 'HMM,': [60], 'SOM,': [61], 'DT': [63], 'workflow.': [67]}",2018,"['Insider threat', 'Workflow', 'Anomaly detection', 'Computer science', 'Unsupervised learning', 'Insider', 'Artificial intelligence', 'Supervised learning', 'Machine learning', 'Hidden Markov model', 'Set (abstract data type)', 'Database', 'Artificial neural network', 'Programming language', 'Law', 'Political science']","Insider threat is a prominent cyber-security danger faced by organizations and companies. In this research, we study and evaluate an insider threat detection workflow using supervised and unsupervised learning algorithms. To this end, we study data exploration and analysis, anomaly detection and malicious behaviour classification on a publicly available data set. We evaluate several supervised and unsupervised learning algorithms - HMM, SOM, and DT - using this workflow."
https://openalex.org/W3159631325,Unsupervised Learning of Probably Symmetric Deformable 3D Objects from Images in the Wild,"{'We': [0, 58], 'propose': [1], 'a': [2, 55, 95, 135], 'method': [3, 18, 113, 148], 'to': [4, 37, 66, 80, 146], 'learn': [5], '3D': [6, 119], 'deformable': [7], 'object': [8, 49, 70], 'categories': [9, 50], 'from': [10, 128], 'raw': [11], 'single-view': [12, 129], 'images,': [13, 130], 'without': [14, 41, 131], 'external': [15], 'supervision.': [16], 'The': [17], 'is': [19, 76], 'based': [20], 'on': [21], 'an': [22], 'autoencoder': [23], 'that': [24, 47, 60, 86, 111, 149], 'factors': [25], 'each': [26], 'input': [27], 'image': [28, 157], 'into': [29], 'depth,': [30], 'albedo,': [31], 'viewpoint': [32], 'and': [33, 126], 'illumination.': [34], 'In': [35], 'order': [36], 'disentangle': [38], 'these': [39], 'components': [40, 104], 'supervision,': [42], 'we': [43, 83, 141], 'use': [44], 'the': [45, 68, 74, 102, 106, 118, 153], 'fact': [46], 'many': [48], 'have,': [51], 'at': [52, 152], 'least': [53], 'approximately,': [54], 'symmetric': [56, 78, 92], 'structure.': [57], 'show': [59, 110], 'reasoning': [61], 'about': [62], 'illumination': [63], 'allows': [64], 'us': [65], 'exploit': [67], 'underlying': [69], 'symmetry': [71, 96], 'even': [72], 'if': [73], 'appearance': [75], 'not': [77, 90], 'due': [79], 'shading.': [81], 'Furthermore,': [82], 'model': [84], 'objects': [85], 'are': [87], 'probably,': [88], 'but': [89], 'certainly,': [91], 'by': [93], 'predicting': [94], 'probability': [97], 'map,': [98], 'learned': [99], 'end-to-end': [100], 'with': [101], 'other': [103], 'of': [105, 121, 155], 'model.': [107, 138], 'Our': [108], 'experiments': [109], 'this': [112], 'can': [114], 'recover': [115], 'very': [116], 'accurately': [117], 'shape': [120, 137], 'human': [122], 'faces,': [123], 'cat': [124], 'faces': [125], 'cars': [127], 'any': [132], 'supervision': [133, 151], 'or': [134], 'prior': [136], 'On': [139], 'benchmarks,': [140], 'demonstrate': [142], 'superior': [143], 'accuracy': [144], 'compared': [145], 'another': [147], 'uses': [150], 'level': [154], '2D': [156], 'correspondences.': [158]}",2021,"['Artificial intelligence', 'Computer vision', 'Object (grammar)', 'Computer science', 'Autoencoder', 'Symmetry (geometry)', 'Image (mathematics)', 'Pattern recognition (psychology)', 'Deep learning', 'Mathematics', 'Geometry']","We propose a method to learn 3D deformable object categories from raw single-view images, without external supervision. The method is based on an autoencoder that factors each input image into depth, albedo, viewpoint and illumination. In order to disentangle these components without supervision, we use the fact that many object categories have, at least approximately, a symmetric structure. We show that reasoning about illumination allows us to exploit the underlying object symmetry even if the appearance is not symmetric due to shading. Furthermore, we model objects that are probably, but not certainly, symmetric by predicting a symmetry probability map, learned end-to-end with the other components of the model. Our experiments show that this method can recover very accurately the 3D shape of human faces, cat faces and cars from single-view images, without any supervision or a prior shape model. On benchmarks, we demonstrate superior accuracy compared to another method that uses supervision at the level of 2D image correspondences."
https://openalex.org/W2963823554,Unsupervised learning of object frames by dense equivariant image\n labelling,"{'One': [0], 'of': [1, 5, 38, 50, 52, 71, 95], 'the': [2, 35, 72, 93], 'key': [3], 'challenges': [4], 'visual': [6, 19], 'perception': [7], 'is': [8, 67], 'to': [9, 69, 87, 97], 'extract': [10, 59], 'abstract': [11], 'models\\nof': [12], '3D': [13], 'objects': [14, 100, 103], 'and': [15, 55, 74, 101], 'object': [16, 54, 89], 'categories': [17], 'from': [18, 34, 109], 'measurements,': [20], 'which': [21], 'are\\naffected': [22], 'by': [23], 'complex': [24], 'nuisance': [25], 'factors': [26], 'such': [27, 104], 'as': [28, 105], 'viewpoint,': [29], 'occlusion,': [30], 'motion,': [31], 'and\\ndeformations.': [32], 'Starting': [33], 'recent': [36], 'idea': [37], 'viewpoint': [39], 'factorization,': [40], 'we\\npropose': [41], 'a': [42, 47, 60], 'new': [43], 'approach': [44], 'that,': [45], 'given': [46], 'large': [48], 'number': [49], 'images': [51, 73], 'an': [53], 'no\\nother': [56], 'supervision,': [57], 'can': [58, 83], 'dense': [61], 'object-centric': [62], 'coordinate': [63], 'frame.': [64], 'This\\ncoordinate': [65], 'frame': [66], 'invariant': [68], 'deformations': [70], 'comes': [75], 'with': [76], 'a\\ndense': [77], 'equivariant': [78], 'labelling': [79], 'neural': [80], 'network': [81], 'that': [82], 'map': [84], 'image': [85], 'pixels': [86], 'their\\ncorresponding': [88], 'coordinates.': [90], 'We': [91], 'demonstrate': [92], 'applicability': [94], 'this\\nmethod': [96], 'simple': [98], 'articulated': [99], 'deformable': [102], 'human\\nfaces,': [106], 'learning': [107], 'embeddings': [108], 'random': [110], 'synthetic': [111], 'transformations': [112], 'or': [113], 'optical\\nflow': [114], 'correspondences,': [115], 'all': [116], 'without': [117], 'any': [118], 'manual': [119], 'supervision.\\n': [120]}",2017,"['Artificial intelligence', 'Equivariant map', 'Computer vision', 'Invariant (physics)', 'Object (grammar)', 'Computer science', 'Pixel', 'Optical flow', 'Frame (networking)', 'Perception', 'Image (mathematics)', 'Pattern recognition (psychology)', 'Mathematics', 'Pure mathematics', 'Biology', 'Telecommunications', 'Neuroscience', 'Mathematical physics']","One of the key challenges of visual perception is to extract abstract models\nof 3D objects and object categories from visual measurements, which are\naffected by complex nuisance factors such as viewpoint, occlusion, motion, and\ndeformations. Starting from the recent idea of viewpoint factorization, we\npropose a new approach that, given a large number of images of an object and no\nother supervision, can extract a dense object-centric coordinate frame. This\ncoordinate frame is invariant to deformations of the images and comes with a\ndense equivariant labelling neural network that can map image pixels to their\ncorresponding object coordinates. We demonstrate the applicability of this\nmethod to simple articulated objects and deformable objects such as human\nfaces, learning embeddings from random synthetic transformations or optical\nflow correspondences, all without any manual supervision.\n"
https://openalex.org/W2604672944,Unsupervised Learning of Evolving Relationships Between Literary Characters,"{'Understanding': [0], 'inter-character': [1, 54], 'relationships': [2, 20, 25], 'is': [3, 46], 'fundamental': [4], 'for': [5], 'understanding': [6], 'character': [7], 'intentions': [8], 'and': [9, 64, 67, 98], 'goals': [10], 'in': [11], 'a': [12], 'narrative.': [13], 'This': [14, 49], 'paper': [15], 'addresses': [16], 'unsupervised': [17], 'modeling': [18], 'of': [19, 33, 53, 71, 82], 'between': [21], 'characters.': [22], 'We': [23, 74, 91], 'model': [24, 107], 'as': [26, 30], 'dynamic': [27], 'phenomenon,': [28], 'represented': [29], 'evolving': [31], 'sequences': [32], 'latent': [34], 'states': [35], 'empirically': [36], 'learned': [37, 104], 'from': [38], 'data.': [39], 'Unlike': [40], 'most': [41], 'previous': [42], 'work': [43], 'our': [44, 106], 'approach': [45], 'completely': [47], 'unsupervised.': [48], 'enables': [50], 'data-driven': [51], 'inference': [52], 'relationship': [55, 102], 'types': [56], 'beyond': [57], 'simple': [58], 'sentiment': [59], 'polarities,': [60], 'by': [61, 105], 'incorporating': [62], 'lexical': [63], 'semantic': [65], 'representations,': [66], 'leveraging': [68], 'large': [69], 'quantities': [70], 'raw': [72], 'text.': [73], 'present': [75], 'three': [76], 'models': [77, 94], 'based': [78], 'on': [79], 'rich': [80], 'sets': [81], 'linguistic': [83], 'features': [84], 'that': [85, 101], 'capture': [86], 'various': [87], 'cues': [88], 'about': [89], 'relationships.': [90], 'compare': [92], 'these': [93], 'with': [95], 'existing': [96], 'techniques': [97], 'also': [99], 'demonstrate': [100], 'categories': [103], 'are': [108], 'semantically': [109], 'coherent.': [110]}",2017,"['Computer science', 'Character (mathematics)', 'Inference', 'Artificial intelligence', 'Narrative', 'Natural language processing', 'Phenomenon', 'Unsupervised learning', 'Linguistics', 'Epistemology', 'Mathematics', 'Geometry', 'Philosophy']","Understanding inter-character relationships is fundamental for understanding character intentions and goals in a narrative. This paper addresses unsupervised modeling of relationships between characters. We model relationships as dynamic phenomenon, represented as evolving sequences of latent states empirically learned from data. Unlike most previous work our approach is completely unsupervised. This enables data-driven inference of inter-character relationship types beyond simple sentiment polarities, by incorporating lexical and semantic representations, and leveraging large quantities of raw text. We present three models based on rich sets of linguistic features that capture various cues about relationships. We compare these models with existing techniques and also demonstrate that relationship categories learned by our model are semantically coherent."
https://openalex.org/W4327967141,Robust hydrogel sensors for unsupervised learning enabled sign‐to‐verbal translation,"{'Abstract': [0], 'Highly': [1], 'stretchable': [2], 'and': [3, 33, 46, 75, 100, 134, 154, 178], 'robust': [4], 'strain': [5], 'sensors': [6], 'are': [7], 'rapidly': [8], 'emerging': [9], 'as': [10, 64, 125, 161, 163], 'promising': [11], 'candidates': [12], 'for': [13, 22, 139, 172], 'a': [14, 49, 59, 65, 128], 'diverse': [15], 'of': [16, 26, 43, 72, 78, 120, 142, 182], 'wearable': [17, 27, 79, 183], 'electronics.': [18, 80, 184], 'The': [19, 81], 'main': [20], 'challenge': [21], 'the': [23, 30, 41, 44, 70, 140, 180], 'practical': [24], 'application': [25, 181], 'electronics': [28], 'is': [29, 48, 118], 'energy': [31, 73], 'consumption': [32, 37, 74], 'device': [34, 54, 76], 'aging.': [35, 55], 'Energy': [36], 'mainly': [38], 'depends': [39], 'on': [40], 'conductivity': [42, 87], 'sensor,': [45], 'it': [47], 'key': [50], 'factor': [51], 'in': [52], 'determining': [53], 'Here,': [56], 'we': [57], 'design': [58], 'liquid': [60], 'metal': [61], '(LM)‐embedded': [62], 'hydrogel': [63, 124], 'sensing': [66, 82, 126], 'material': [67, 83], 'to': [68, 89], 'overcome': [69], 'barrier': [71], 'aging': [77], 'simultaneously': [84], 'exhibits': [85], 'high': [86], '(up': [88], '22': [90], 'S': [91], 'm': [92], '−1': [93], '),': [94], 'low': [95], 'elastic': [96], 'modulus': [97], '(23': [98], 'kPa),': [99], 'ultrahigh': [101], 'stretchability': [102], '(1500%)': [103], 'with': [104, 175], 'excellent': [105], 'robustness': [106], '(consistent': [107], 'performance': [108], 'against': [109], '12': [110], '000': [111], 'mechanical': [112], 'cycling).': [113], 'A': [114], 'motion': [115], 'monitoring': [116], 'system': [117, 146], 'composed': [119], 'intrinsically': [121], 'soft': [122], 'LM‐embedded': [123], 'material,': [127], 'microcontroller,': [129], 'signal‐processing': [130], 'circuits,': [131], 'Bluetooth': [132], 'transceiver,': [133], 'self‐organizing': [135], 'map': [136], 'developed': [137], 'software': [138], 'visualization': [141], 'multi‐dimensional': [143], 'data.': [144], 'This': [145, 166], 'integrating': [147], 'multiple': [148], 'functions': [149], 'including': [150], 'signal': [151], 'conditioning,': [152], 'processing,': [153], 'wireless': [155], 'transmission': [156], 'achieves': [157], 'monitor': [158], 'hand': [159], 'gesture': [160], 'well': [162], 'sign‐to‐verbal': [164], 'translation.': [165], 'approach': [167], 'provides': [168], 'an': [169], 'ideal': [170], 'strategy': [171], 'deaf‐mute': [173], 'communicating': [174], 'normal': [176], 'people': [177], 'broadens': [179], 'image': [185]}",2023,"['Wearable computer', 'Electronics', 'Wearable technology', 'Computer science', 'Robustness (evolution)', 'Microcontroller', 'Wireless', 'Bluetooth', 'Embedded system', 'Electrical engineering', 'Telecommunications', 'Engineering', 'Biochemistry', 'Gene', 'Chemistry']","Abstract Highly stretchable and robust strain sensors are rapidly emerging as promising candidates for a diverse of wearable electronics. The main challenge for the practical application of wearable electronics is the energy consumption and device aging. Energy consumption mainly depends on the conductivity of the sensor, and it is a key factor in determining device aging. Here, we design a liquid metal (LM)‐embedded hydrogel as a sensing material to overcome the barrier of energy consumption and device aging of wearable electronics. The sensing material simultaneously exhibits high conductivity (up to 22 S m −1 ), low elastic modulus (23 kPa), and ultrahigh stretchability (1500%) with excellent robustness (consistent performance against 12 000 mechanical cycling). A motion monitoring system is composed of intrinsically soft LM‐embedded hydrogel as sensing material, a microcontroller, signal‐processing circuits, Bluetooth transceiver, and self‐organizing map developed software for the visualization of multi‐dimensional data. This system integrating multiple functions including signal conditioning, processing, and wireless transmission achieves monitor hand gesture as well as sign‐to‐verbal translation. This approach provides an ideal strategy for deaf‐mute communicating with normal people and broadens the application of wearable electronics. image"
https://openalex.org/W2964293202,Unsupervised Learning of View-invariant Action Representations,"{'The': [0], 'recent': [1], 'success': [2], 'in': [3, 59, 72], 'human': [4], 'action': [5, 125], 'recognition': [6, 126], 'with': [7], 'deep': [8], 'learning': [9, 15, 45, 65, 84, 112], 'methods': [10], 'mostly': [11], 'adopt': [12], 'the': [13, 89, 100, 118, 121], 'supervised': [14], 'paradigm,': [16], 'which': [17, 47, 96], 'requires': [18], 'significant': [19], 'amount': [20], 'of': [21, 113, 120], 'manually': [22], 'labeled': [23], 'data': [24, 50], 'to': [25, 51, 68, 85, 110], 'achieve': [26], 'good': [27], 'performance.': [28], 'However,': [29], 'label': [30], 'collection': [31], 'is': [32, 67, 97], 'an': [33, 43], 'expensive': [34], 'and': [35], 'time-consuming': [36], 'process.': [37], 'In': [38, 102], 'this': [39], 'work,': [40], 'we': [41, 104], 'propose': [42, 105], 'unsupervised': [44, 64], 'framework,': [46], 'exploits': [48], 'unlabeled': [49], 'learn': [52], 'video': [53, 60, 77], 'representations.': [54], 'Different': [55], 'from': [56, 79], 'previous': [57], 'works': [58], 'representation': [61, 78, 90], 'learning,': [62], 'our': [63], 'task': [66], 'predict': [69], '3D': [70], 'motion': [71, 94], 'multiple': [73, 128], 'target': [74], 'views': [75], 'using': [76], 'a': [80, 106], 'source': [81], 'view.': [82], 'By': [83], 'extrapolate': [86], 'cross-view': [87], 'motions,': [88], 'can': [91], 'capture': [92], 'view-invariant': [93, 114], 'dynamics': [95], 'discriminative': [98], 'for': [99, 124], 'action.': [101], 'addition,': [103], 'view-adversarial': [107], 'training': [108], 'method': [109], 'enhance': [111], 'features.': [115], 'We': [116], 'demonstrate': [117], 'effectiveness': [119], 'learned': [122], 'representations': [123], 'on': [127], 'datasets.': [129]}",2018,"['Discriminative model', 'Artificial intelligence', 'Computer science', 'Feature learning', 'Unsupervised learning', 'Invariant (physics)', 'Machine learning', 'Representation (politics)', 'Exploit', 'Adversarial system', 'Labeled data', 'Semi-supervised learning', 'Multi-task learning', 'Pattern recognition (psychology)', 'Task (project management)', 'Mathematics', 'Law', 'Economics', 'Computer security', 'Political science', 'Management', 'Mathematical physics', 'Politics']","The recent success in human action recognition with deep learning methods mostly adopt the supervised learning paradigm, which requires significant amount of manually labeled data to achieve good performance. However, label collection is an expensive and time-consuming process. In this work, we propose an unsupervised learning framework, which exploits unlabeled data to learn video representations. Different from previous works in video representation learning, our unsupervised learning task is to predict 3D motion in multiple target views using video representation from a source view. By learning to extrapolate cross-view motions, the representation can capture view-invariant motion dynamics which is discriminative for the action. In addition, we propose a view-adversarial training method to enhance learning of view-invariant features. We demonstrate the effectiveness of the learned representations for action recognition on multiple datasets."
https://openalex.org/W2099062766,Unsupervised learning for text-to-speech synthesis,"{'This': [0, 124], 'thesis': [1], 'introduces': [2], 'a': [3, 44, 113, 119, 146, 190], 'general': [4], 'method': [5, 83, 151], 'for': [6, 89, 171], 'incorporating': [7], 'the': [8, 35, 72, 109, 130, 138, 161], 'distributional': [9, 104], 'analysis&#13;\\nof': [10], 'textual': [11, 76, 110, 158], 'and': [12, 32, 69, 167, 175], 'linguistic': [13, 94], 'objects': [14, 111], 'into': [15], 'text-to-speech': [16], '(TTS)': [17], 'conversion': [18, 21], 'systems.&#13;\\nConventional': [19], 'TTS': [20], 'uses': [22], 'intermediate': [23, 41], 'layers': [24, 42], 'of': [25, 87, 122, 132, 157, 189], 'representation': [26], 'to': [27, 39, 101, 154, 160], 'bridge&#13;\\nthe': [28], 'gap': [29], 'between': [30], 'text': [31], 'speech.': [33], 'Collecting': [34], 'annotated': [36], 'data': [37, 77, 184], 'needed': [38], 'produce&#13;\\nthese': [40], 'is': [43, 98, 126, 152], 'far': [45], 'from': [46], 'trivial': [47], 'task,': [48], 'possibly': [49], 'prohibitively': [50], 'so&#13;\\nfor': [51], 'languages': [52, 90], 'in': [53, 59, 65, 91, 145], 'which': [54, 92], 'no': [55, 180], 'such': [56], 'resources': [57], 'are': [58, 79, 177], 'existence.': [60], 'Distributional': [61], 'analysis,&#13;\\nin': [62], 'contrast,': [63], 'proceeds': [64], 'an': [66], 'unsupervised': [67], 'manner,': [68], 'so': [70, 136], 'enables': [71], 'creation': [73], 'of&#13;\\nsystems': [74], 'using': [75], 'that': [78, 137], 'not': [80, 99], 'annotated.': [81], 'The': [82], 'therefore': [84], 'aids&#13;\\nthe': [85], 'building': [86], 'systems': [88, 170], 'conventional': [93], 'resources&#13;\\nare': [95], 'scarce,': [96], 'but': [97], 'restricted': [100], 'these': [102], 'languages.&#13;\\nThe': [103], 'analysis': [105], 'proposed': [106], 'here': [107], 'places': [108], 'analysed&#13;\\nin': [112], 'continuous-valued': [114], 'space,': [115], 'rather': [116], 'than': [117], 'specifying': [118], 'hard': [120], 'categorisation': [121], 'those&#13;\\nobjects.': [123], 'space': [125], 'then': [127], 'partitioned': [128], 'during': [129], 'training': [131], 'acoustic': [133], 'models': [134, 139], 'for&#13;\\nsynthesis,': [135], 'generalise': [140], 'over': [141], ""objects'"": [142], 'surface': [143], 'forms': [144], 'way': [147], 'that&#13;\\nis': [148], 'acoustically': [149], 'relevant.&#13;\\nThe': [150], 'applied': [153], 'three': [155], 'levels': [156], 'analysis:': [159], 'characterisation&#13;\\nof': [162], 'sub-syllabic': [163], 'units,': [164], 'word': [165], 'units': [166], 'utterances.': [168], 'Entire': [169], 'three&#13;\\nlanguages': [172], '(English,': [173], 'Finnish': [174], 'Romanian)': [176], 'built': [178], 'with': [179], 'reliance': [181], 'on': [182], 'manually&#13;\\nlabelled': [183], 'or': [185], 'language-specific': [186], 'expertise.': [187], 'Results': [188], 'subjective': [191], 'evaluation&#13;\\nare': [192], 'presented.': [193]}",2013,"['Computer science', 'Natural language processing', 'Syllabic verse', 'Artificial intelligence', 'Word (group theory)', 'Space (punctuation)', 'Representation (politics)', 'Bridge (graph theory)', 'Speech recognition', 'Linguistics', 'Internal medicine', 'Operating system', 'Medicine', 'Law', 'Political science', 'Politics', 'Philosophy']","This thesis introduces a general method for incorporating the distributional analysis&#13;\nof textual and linguistic objects into text-to-speech (TTS) conversion systems.&#13;\nConventional TTS conversion uses intermediate layers of representation to bridge&#13;\nthe gap between text and speech. Collecting the annotated data needed to produce&#13;\nthese intermediate layers is a far from trivial task, possibly prohibitively so&#13;\nfor languages in which no such resources are in existence. Distributional analysis,&#13;\nin contrast, proceeds in an unsupervised manner, and so enables the creation of&#13;\nsystems using textual data that are not annotated. The method therefore aids&#13;\nthe building of systems for languages in which conventional linguistic resources&#13;\nare scarce, but is not restricted to these languages.&#13;\nThe distributional analysis proposed here places the textual objects analysed&#13;\nin a continuous-valued space, rather than specifying a hard categorisation of those&#13;\nobjects. This space is then partitioned during the training of acoustic models for&#13;\nsynthesis, so that the models generalise over objects' surface forms in a way that&#13;\nis acoustically relevant.&#13;\nThe method is applied to three levels of textual analysis: to the characterisation&#13;\nof sub-syllabic units, word units and utterances. Entire systems for three&#13;\nlanguages (English, Finnish and Romanian) are built with no reliance on manually&#13;\nlabelled data or language-specific expertise. Results of a subjective evaluation&#13;\nare presented."
https://openalex.org/W2887420797,Unsupervised Learning of Foreground Object Segmentation,"{'Unsupervised': [0], 'learning': [1, 45, 129], 'poses': [2], 'one': [3, 184], 'of': [4, 50, 67, 116, 135, 141, 187], 'the': [5, 43, 48, 52, 93, 105, 109, 145, 150, 178], 'most': [6], 'difficult': [7], 'challenges': [8], 'in': [9, 47, 55, 144, 168], 'computer\\nvision': [10], 'today.': [11], 'The': [12], 'task': [13], 'has': [14, 114], 'an': [15], 'immense': [16], 'practical': [17], 'value': [18], 'with': [19], 'many': [20], 'applications': [21], 'in\\nartificial': [22], 'intelligence': [23], 'and': [24], 'emerging': [25], 'technologies,': [26], 'as': [27], 'large': [28, 78], 'quantities': [29], 'of\\nunlabeled': [30], 'videos': [31], 'can': [32, 131], 'be': [33], 'collected': [34], 'at': [35, 100, 125, 152], 'relatively': [36], 'low': [37], 'cost.': [38], 'In': [39, 155], 'this': [40], 'paper,': [41], 'we\\naddress': [42], 'unsupervised': [44, 73, 88, 94, 128, 170, 192], 'problem': [46], 'context': [49], 'detecting': [51], 'main\\nforeground': [53], 'objects': [54], 'single': [56], 'images.': [57], 'We': [58, 91], 'train': [59], 'a': [60, 68, 139], 'student': [61, 110], 'deep': [62], 'network': [63], 'to': [64], 'predict\\nthe': [65], 'output': [66], 'teacher': [69, 151], 'pathway': [70], 'that': [71], 'performs': [72], 'object': [74, 89, 166], 'discovery': [75, 167], 'in\\nvideos': [76], 'or': [77], 'image': [79, 171], 'collections.': [80], 'Our': [81, 127], 'approach': [82], 'is': [83, 181], 'different': [84], 'from': [85], 'published\\nmethods': [86], 'on': [87, 162], 'discovery.': [90], 'move': [92], 'learning\\nphase': [95], 'during': [96, 121], 'training': [97], 'time,': [98], 'then': [99], 'test': [101, 176], 'time': [102, 177], 'we': [103], 'apply': [104], 'standard\\nfeed-forward': [106], 'processing': [107], 'along': [108], 'pathway.': [111], 'This': [112], 'strategy': [113], 'the\\nbenefit': [115], 'allowing': [117], 'increased': [118], 'generalization': [119], 'possibilities': [120], 'training,\\nwhile': [122], 'remaining': [123], 'fast': [124], 'testing.': [126], 'algorithm': [130], 'run\\nover': [132], 'several': [133], 'generations': [134], 'student-teacher': [136], 'training.': [137], 'Thus,': [138], 'group': [140], 'student\\nnetworks': [142], 'trained': [143], 'first': [146], 'generation': [147], 'collectively': [148], 'create': [149], 'the\\nnext': [153], 'generation.': [154], 'experiments': [156], 'our': [157], 'method': [158], 'achieves': [159], 'top': [160], 'results': [161], 'three\\ncurrent': [163], 'datasets': [164], 'for': [165], 'video,': [169], 'segmentation\\nand': [172], 'saliency': [173], 'detection.': [174], 'At': [175], 'proposed': [179], 'system': [180], 'fast,': [182], 'being': [183], 'to\\ntwo': [185], 'orders': [186], 'magnitude': [188], 'faster': [189], 'than': [190], 'published': [191], 'methods.\\n': [193]}",2019,[],"Unsupervised learning poses one of the most difficult challenges in computer\nvision today. The task has an immense practical value with many applications in\nartificial intelligence and emerging technologies, as large quantities of\nunlabeled videos can be collected at relatively low cost. In this paper, we\naddress the unsupervised learning problem in the context of detecting the main\nforeground objects in single images. We train a student deep network to predict\nthe output of a teacher pathway that performs unsupervised object discovery in\nvideos or large image collections. Our approach is different from published\nmethods on unsupervised object discovery. We move the unsupervised learning\nphase during training time, then at test time we apply the standard\nfeed-forward processing along the student pathway. This strategy has the\nbenefit of allowing increased generalization possibilities during training,\nwhile remaining fast at testing. Our unsupervised learning algorithm can run\nover several generations of student-teacher training. Thus, a group of student\nnetworks trained in the first generation collectively create the teacher at the\nnext generation. In experiments our method achieves top results on three\ncurrent datasets for object discovery in video, unsupervised image segmentation\nand saliency detection. At test time the proposed system is fast, being one to\ntwo orders of magnitude faster than published unsupervised methods.\n"
https://openalex.org/W2130121108,Cross-Validation for Unsupervised Learning,"{'Cross-validation': [0], '(CV)': [1], 'is': [2, 10, 81], 'a': [3, 69, 82], 'popular': [4], 'method': [5], 'for': [6, 85], 'model-selection.': [7], 'Unfortunately,': [8], 'it': [9], 'not': [11], 'immediately': [12], 'obvious': [13], 'how': [14, 40, 58], 'to': [15, 18, 30, 44, 63], 'apply': [16], 'CV': [17, 59], 'unsupervised': [19, 31, 86], 'or': [20], 'exploratory': [21], 'contexts.': [22], 'This': [23], 'thesis': [24], 'discusses': [25], 'some': [26], 'extensions': [27], 'of': [28, 38, 68], 'cross-validation': [29, 80], 'learning,': [32], 'specifically': [33], 'focusing': [34], 'on': [35], 'the': [36, 48, 65], 'problem': [37], 'choosing': [39], 'many': [41], 'principal': [42], 'components': [43], 'keep.': [45], 'We': [46], 'introduce': [47], 'latent': [49], 'factor': [50], 'model,': [51], 'define': [52], 'an': [53], 'objective': [54], 'criterion,': [55], 'and': [56, 75], 'show': [57], 'can': [60], 'be': [61], 'used': [62], 'estimate': [64], 'intrinsic': [66], 'dimensionality': [67], 'data': [70], 'set.': [71], 'Through': [72], 'both': [73], 'simulation': [74], 'theory,': [76], 'we': [77], 'demonstrate': [78], 'that': [79], 'valuable': [83], 'tool': [84], 'learning.': [87]}",2009,"['Unsupervised learning', 'Computer science', 'Cross-validation', 'Artificial intelligence', 'Machine learning', 'Curse of dimensionality', 'Set (abstract data type)', 'Model selection', 'Selection (genetic algorithm)', 'Programming language']","Cross-validation (CV) is a popular method for model-selection. Unfortunately, it is not immediately obvious how to apply CV to unsupervised or exploratory contexts. This thesis discusses some extensions of cross-validation to unsupervised learning, specifically focusing on the problem of choosing how many principal components to keep. We introduce the latent factor model, define an objective criterion, and show how CV can be used to estimate the intrinsic dimensionality of a data set. Through both simulation and theory, we demonstrate that cross-validation is a valuable tool for unsupervised learning."
https://openalex.org/W2888844359,Unsupervised Learning of Syntactic Structure with Invertible Neural Projections,"{'Unsupervised': [0], 'learning': [1], 'of': [2], 'syntactic': [3, 42], 'structure': [4, 43], 'is': [5, 86], 'typically': [6], 'performed': [7], 'using': [8], 'generative': [9, 36, 61], 'models': [10, 22], 'with': [11, 58, 94], 'discrete': [12, 41], 'latent': [13], 'variables': [14], 'and': [15, 44, 74, 97, 107], 'multinomial': [16], 'parameters.': [17], 'In': [18, 29, 88], 'most': [19], 'cases,': [20], 'these': [21], 'have': [23], 'not': [24], 'leveraged': [25], 'continuous': [26, 45], 'word': [27, 46], 'representations.': [28], 'this': [30], 'work,': [31], 'we': [32, 90, 129], 'propose': [33], 'a': [34, 59], 'novel': [35], 'model': [37, 80, 121, 134], 'that': [38, 65, 131], 'jointly': [39], 'learns': [40], 'representations': [47], 'in': [48, 78], 'an': [49, 54], 'unsupervised': [50, 108, 139], 'fashion': [51], 'by': [52], 'cascading': [53], 'invertible': [55], 'neural': [56], 'network': [57], 'structured': [60], 'prior.': [62], 'We': [63], 'show': [64], 'the': [66, 84, 116, 143], 'invertibility': [67], 'condition': [68, 146], 'allows': [69], 'for': [70, 142, 160], 'efficient': [71], 'exact': [72], 'inference': [73], 'marginal': [75], 'likelihood': [76], 'computation': [77], 'our': [79, 92, 119, 132], 'so': [81], 'long': [82], 'as': [83], 'prior': [85], 'well-behaved.': [87], 'experiments': [89], 'instantiate': [91], 'approach': [93], 'both': [95], 'Markov': [96], 'tree-structured': [98, 133], 'priors,': [99], 'evaluating': [100], 'on': [101, 125, 138], 'two': [102], 'tasks:': [103], 'part-of-speech': [104], '(POS)': [105], 'induction,': [106], 'dependency': [109, 140], 'parsing': [110, 141], 'without': [111], 'gold': [112, 149], 'POS': [113, 126, 150], 'annotation.': [114], 'On': [115], 'Penn': [117], 'Treebank,': [118], 'Markov-structured': [120], 'surpasses': [122], 'state-of-the-art': [123, 136], 'results': [124], 'induction.': [127], 'Similarly,': [128], 'find': [130], 'achieves': [135], 'performance': [137], 'difficult': [144], 'training': [145], 'where': [147], 'neither': [148], 'annotation': [151], 'nor': [152], 'punctuation-based': [153], 'constraints': [154], 'are': [155], 'available.': [156], '©': [157], '2018': [158], 'Association': [159], 'Computational': [161], 'Linguistics': [162]}",2018,"['Treebank', 'Computer science', 'Dependency grammar', 'Artificial intelligence', 'Generative model', 'Inference', 'Parsing', 'Unsupervised learning', 'Dependency (UML)', 'Prior probability', 'Tree (set theory)', 'Tree structure', 'Natural language processing', 'Machine learning', 'Generative grammar', 'Bayesian probability', 'Algorithm', 'Mathematics', 'Binary tree', 'Mathematical analysis']","Unsupervised learning of syntactic structure is typically performed using generative models with discrete latent variables and multinomial parameters. In most cases, these models have not leveraged continuous word representations. In this work, we propose a novel generative model that jointly learns discrete syntactic structure and continuous word representations in an unsupervised fashion by cascading an invertible neural network with a structured generative prior. We show that the invertibility condition allows for efficient exact inference and marginal likelihood computation in our model so long as the prior is well-behaved. In experiments we instantiate our approach with both Markov and tree-structured priors, evaluating on two tasks: part-of-speech (POS) induction, and unsupervised dependency parsing without gold POS annotation. On the Penn Treebank, our Markov-structured model surpasses state-of-the-art results on POS induction. Similarly, we find that our tree-structured model achieves state-of-the-art performance on unsupervised dependency parsing for the difficult training condition where neither gold POS annotation nor punctuation-based constraints are available. © 2018 Association for Computational Linguistics"
https://openalex.org/W2560778841,Multilingual Metaphor Processing: Experiments with Semi-Supervised and Unsupervised Learning,"{'Highly': [0], 'frequent': [1], 'in': [2, 42, 114, 161], 'language': [3, 166], 'and': [4, 57, 72, 93, 116, 119, 151, 169, 184], 'communication,': [5], 'metaphor': [6, 20, 46, 83], 'represents': [7], 'a': [8, 40, 62, 104, 134], 'significant': [9], 'challenge': [10], 'for': [11, 133], 'Natural': [12], 'Language': [13], 'Processing': [14], '(NLP)': [15], 'applications.': [16], 'Computational': [17], 'work': [18], 'on': [19, 189], 'has': [21], 'traditionally': [22], 'evolved': [23], 'around': [24], 'the': [25, 31, 128, 149], 'use': [26], 'of': [27, 82, 87, 95, 107, 131, 140, 153], 'hand-coded': [28], 'knowledge,': [29], 'making': [30], 'systems': [32], 'hard': [33], 'to': [34, 45, 126, 147, 159], 'scale.': [35], 'Recent': [36], 'years': [37], 'have': [38], 'witnessed': [39], 'rise': [41], 'statistical': [43, 180], 'approaches': [44, 50], 'processing.': [47], 'However,': [48], 'these': [49], 'often': [51], 'require': [52], 'extensive': [53], 'human': [54], 'annotation': [55], 'effort': [56], 'are': [58], 'predominantly': [59], 'evaluated': [60], 'within': [61], 'limited': [63], 'domain.': [64], 'In': [65, 145], 'contrast,': [66], 'we': [67, 156, 177], 'experiment': [68], 'with': [69, 173], 'weakly': [70], 'supervised': [71], 'unsupervised': [73], 'techniques—with': [74], 'little': [75, 174], 'or': [76], 'no': [77], 'annotation—to': [78], 'generalize': [79], 'higher-level': [80], 'mechanisms': [81], 'from': [84, 98, 103, 143, 164], 'distributional': [85], 'properties': [86], 'concepts.': [88], 'We': [89], 'investigate': [90, 148], 'different': [91, 165], 'levels': [92], 'types': [94], 'supervision': [96, 132], '(learning': [97], 'linguistic': [99], 'examples': [100], 'vs.': [101, 110], 'learning': [102, 111, 135], 'given': [105], 'set': [106], 'metaphorical': [108, 141], 'mappings': [109], 'without': [112], 'annotation)': [113], 'flat': [115], 'hierarchical,': [117], 'unconstrained': [118], 'constrained': [120], 'clustering': [121], 'settings.': [122], 'Our': [123], 'aim': [124], 'is': [125], 'identify': [127], 'optimal': [129], 'type': [130], 'algorithm': [136], 'that': [137, 179], 'discovers': [138], 'patterns': [139], 'association': [142], 'text.': [144], 'order': [146], 'scalability': [150], 'adaptability': [152], 'our': [154], 'models,': [155], 'applied': [157], 'them': [158], 'data': [160], 'three': [162], 'languages': [163], 'groups—English,': [167], 'Spanish,': [168], 'Russian—achieving': [170], 'state-of-the-art': [171], 'results': [172], 'supervision.': [175], 'Finally,': [176], 'demonstrate': [178], 'methods': [181], 'can': [182], 'facilitate': [183], 'scale': [185], 'up': [186], 'cross-linguistic': [187], 'research': [188], 'metaphor.': [190]}",2016,"['Metaphor', 'Computer science', 'Artificial intelligence', 'Natural language processing', 'Scalability', 'Annotation', 'Set (abstract data type)', 'Unsupervised learning', 'Cluster analysis', 'Adaptability', 'Domain (mathematical analysis)', 'Linguistics', 'Database', 'Philosophy', 'Mathematical analysis', 'Mathematics', 'Programming language', 'Biology', 'Ecology']","Highly frequent in language and communication, metaphor represents a significant challenge for Natural Language Processing (NLP) applications. Computational work on metaphor has traditionally evolved around the use of hand-coded knowledge, making the systems hard to scale. Recent years have witnessed a rise in statistical approaches to metaphor processing. However, these approaches often require extensive human annotation effort and are predominantly evaluated within a limited domain. In contrast, we experiment with weakly supervised and unsupervised techniques—with little or no annotation—to generalize higher-level mechanisms of metaphor from distributional properties of concepts. We investigate different levels and types of supervision (learning from linguistic examples vs. learning from a given set of metaphorical mappings vs. learning without annotation) in flat and hierarchical, unconstrained and constrained clustering settings. Our aim is to identify the optimal type of supervision for a learning algorithm that discovers patterns of metaphorical association from text. In order to investigate the scalability and adaptability of our models, we applied them to data in three languages from different language groups—English, Spanish, and Russian—achieving state-of-the-art results with little supervision. Finally, we demonstrate that statistical methods can facilitate and scale up cross-linguistic research on metaphor."
https://openalex.org/W4226112977,Hierarchical Exploration of Continuous Seismograms With Unsupervised Learning,"{'Abstract': [0], 'Continuous': [1], 'seismograms': [2, 41], 'contain': [3], 'a': [4, 9, 21, 31, 56, 78, 88, 111, 142, 168, 177], 'wealth': [5], 'of': [6, 12, 36, 85, 103, 118, 210, 225, 244], 'information': [7], 'with': [8, 14, 61, 185, 191], 'large': [10], 'variety': [11], 'signals': [13, 19, 37, 190, 211, 245], 'different': [15, 101], 'origin.': [16, 197], 'Identifying': [17], 'these': [18, 75], 'is': [20, 220, 248], 'crucial': [22], 'step': [23], 'in': [24, 38, 42, 77, 87, 115, 145, 171, 232], 'understanding': [25], 'physical': [26], 'geological': [27], 'objects.': [28], 'We': [29, 90, 124], 'propose': [30], 'strategy': [32, 47], 'to': [33, 94, 154, 164, 206, 213], 'identify': [34, 100, 176, 207], 'classes': [35, 102], 'continuous': [39], 'single‐station': [40], 'an': [43, 62, 195], 'unsupervised': [44], 'fashion.': [45], 'Our': [46], 'relies': [48], 'on': [49, 55, 67], 'extracting': [50], 'meaningful': [51], 'waveform': [52, 137], 'features': [53], 'based': [54], 'deep': [57], 'scattering': [58], 'network': [59], 'combined': [60], 'independent': [63], 'component': [64], 'analysis.': [65, 218], 'Based': [66], 'the': [68, 83, 92, 96, 116, 119, 126, 146, 172, 202, 233], 'extracted': [69], 'features,': [70], 'agglomerative': [71], 'clustering': [72, 86], 'then': [73], 'groups': [74], 'waveforms': [76, 187], 'hierarchical': [79], 'fashion': [80], 'and': [81, 99, 136, 138, 156, 160, 188, 194, 212], 'reveals': [82], 'process': [84], 'dendrogram.': [89], 'use': [91], 'dendrogram': [93], 'explore': [95], 'seismic': [97, 158, 178], 'data': [98], 'signals.': [104], 'To': [105], 'test': [106], 'our': [107], 'strategy,': [108], 'we': [109, 149, 175], 'investigate': [110], 'two‐day‐long': [112], 'seismogram': [113], 'collected': [114], 'vicinity': [117], 'North': [120], 'Anatolian': [121], 'Fault,': [122], 'Turkey.': [123], 'analyze': [125], 'automatically': [127], 'inferred': [128], ""clusters'"": [129], 'occurrence': [130], 'rate,': [131], 'spectral': [132], 'characteristics,': [133], 'cluster': [134, 147, 162, 173, 203], 'size,': [135], 'envelope': [139], 'characteristics.': [140], 'At': [141, 167], 'low': [143], 'level': [144, 170], 'hierarchy,': [148, 174], 'obtain': [150], 'three': [151], 'clusters': [152], 'related': [153, 163], 'anthropogenic': [155, 196], 'ambient': [157], 'noise': [159], 'one': [161], 'earthquake': [165], 'activity.': [166], 'high': [169], 'burst': [179], 'that': [180, 201], 'includes': [181], 'around': [182], '200': [183], 'events': [184], 'similar': [186], 'high‐frequent': [189], 'correlating': [192], 'envelopes': [193], 'The': [198, 235], 'application': [199], 'shows': [200], 'hierarchy': [204], 'helps': [205], 'particular': [208], 'families': [209], 'extract': [214], 'subclusters': [215], 'for': [216], 'further': [217], 'This': [219], 'valuable': [221], 'when': [222], 'certain': [223], 'types': [224, 243], 'signals,': [226], 'such': [227], 'as': [228], 'earthquakes,': [229], 'are': [230], 'under‐represented': [231], 'data.': [234], 'proposed': [236], 'method': [237], 'may': [238], 'also': [239], 'successfully': [240], 'discover': [241], 'new': [242], 'since': [246], 'it': [247], 'entirely': [249], 'data‐driven.': [250]}",2021,"['Seismogram', 'Waveform', 'Cluster analysis', 'Hierarchy', 'Hierarchical clustering', 'Computer science', 'Pattern recognition (psychology)', 'Dendrogram', 'Cluster (spacecraft)', 'Data mining', 'Seismology', 'Artificial intelligence', 'Geology', 'Population', 'Telecommunications', 'Demography', 'Economics', 'Radar', 'Market economy', 'Genetic diversity', 'Programming language', 'Sociology']","Abstract Continuous seismograms contain a wealth of information with a large variety of signals with different origin. Identifying these signals is a crucial step in understanding physical geological objects. We propose a strategy to identify classes of signals in continuous single‐station seismograms in an unsupervised fashion. Our strategy relies on extracting meaningful waveform features based on a deep scattering network combined with an independent component analysis. Based on the extracted features, agglomerative clustering then groups these waveforms in a hierarchical fashion and reveals the process of clustering in a dendrogram. We use the dendrogram to explore the seismic data and identify different classes of signals. To test our strategy, we investigate a two‐day‐long seismogram collected in the vicinity of the North Anatolian Fault, Turkey. We analyze the automatically inferred clusters' occurrence rate, spectral characteristics, cluster size, and waveform and envelope characteristics. At a low level in the cluster hierarchy, we obtain three clusters related to anthropogenic and ambient seismic noise and one cluster related to earthquake activity. At a high level in the cluster hierarchy, we identify a seismic burst that includes around 200 events with similar waveforms and high‐frequent signals with correlating envelopes and an anthropogenic origin. The application shows that the cluster hierarchy helps to identify particular families of signals and to extract subclusters for further analysis. This is valuable when certain types of signals, such as earthquakes, are under‐represented in the data. The proposed method may also successfully discover new types of signals since it is entirely data‐driven."
https://openalex.org/W2396178844,Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data,"{'We': [0], 'introduce': [1], 'Deep': [2], 'Variational': [3, 27], 'Bayes': [4], 'Filters': [5], '(DVBF),': [6], 'a': [7], 'new': [8], 'method': [9], 'for': [10], 'unsupervised': [11], 'learning': [12], 'and': [13, 48, 70], 'identification': [14], 'of': [15, 75], 'latent': [16, 77], 'Markovian': [17], 'state': [18, 67], 'space': [19, 68], 'models.': [20], 'Leveraging': [21], 'recent': [22], 'advances': [23], 'in': [24], 'Stochastic': [25], 'Gradient': [26], 'Bayes,': [28], 'DVBF': [29], 'can': [30, 40], 'overcome': [31], 'intractable': [32], 'inference': [33], 'distributions': [34], 'via': [35], 'variational': [36], 'inference.': [37], 'Thus,': [38], 'it': [39], 'handle': [41], 'highly': [42], 'nonlinear': [43], 'input': [44], 'data': [45], 'with': [46], 'temporal': [47], 'spatial': [49], 'dependencies': [50], 'such': [51], 'as': [52], 'image': [53], 'sequences': [54], 'without': [55], 'domain': [56], 'knowledge.': [57], 'Our': [58], 'experiments': [59], 'show': [60], 'that': [61], 'enabling': [62], 'backpropagation': [63], 'through': [64], 'transitions': [65], 'enforces': [66], 'assumptions': [69], 'significantly': [71], 'improves': [72], 'information': [73], 'content': [74], 'the': [76], 'embedding.': [78], 'This': [79], 'also': [80], 'enables': [81], 'realistic': [82], 'long-term': [83], 'prediction.': [84]}",2016,"['Inference', ""Bayes' theorem"", 'Computer science', 'Artificial intelligence', 'Embedding', 'Bayesian inference', 'Backpropagation', 'Machine learning', 'Pattern recognition (psychology)', 'Algorithm', 'Artificial neural network', 'Bayesian probability']","We introduce Deep Variational Bayes Filters (DVBF), a new method for unsupervised learning and identification of latent Markovian state space models. Leveraging recent advances in Stochastic Gradient Variational Bayes, DVBF can overcome intractable inference distributions via variational inference. Thus, it can handle highly nonlinear input data with temporal and spatial dependencies such as image sequences without domain knowledge. Our experiments show that enabling backpropagation through transitions enforces state space assumptions and significantly improves information content of the latent embedding. This also enables realistic long-term prediction."
https://openalex.org/W3190041651,Supervised and unsupervised learning of directed percolation,"{'Machine': [0], 'learning': [1, 89, 143], '(ML)': [2], 'has': [3], 'been': [4], 'well': [5, 106], 'applied': [6], 'to': [7, 74, 124, 145], 'studying': [8], 'equilibrium': [9], 'phase': [10, 32, 102], 'transition': [11, 103, 120], 'models': [12], 'by': [13, 60], 'accurately': [14], 'predicating': [15], 'critical': [16, 20, 78, 172], 'thresholds': [17], 'and': [18, 83, 110, 150], 'some': [19, 62], 'exponents.': [21, 113], 'Difficulty': [22], 'will': [23], 'be': [24], 'raised,': [25], 'however,': [26], 'for': [27], 'integrating': [28], 'ML': [29], 'into': [30], 'nonequilibrium': [31, 40], 'transitions.': [33], 'The': [34, 114], 'extra': [35], 'dimension': [36], 'in': [37, 80], 'a': [38, 129, 163, 167], 'given': [39], 'system,': [41], 'namely': [42], 'time,': [43], 'can': [44, 99, 165], 'greatly': [45], 'slow': [46], 'down': [47], 'the': [48, 51, 87, 91, 101, 108, 119, 133, 138, 171], 'procedure': [49], 'toward': [50], 'steady': [52], 'state.': [53], 'In': [54], 'this': [55], 'paper': [56], 'we': [57, 136], 'find': [58], 'that': [59, 161], 'using': [61], 'simple': [63], 'techniques': [64], 'of': [65, 69, 93, 132, 153, 170], 'ML,': [66], 'non-steady-state': [67], 'configurations': [68, 152], 'directed': [70], 'percolation': [71], '(DP)': [72], 'suffice': [73], 'capture': [75], 'its': [76], 'essential': [77], 'behaviors': [79], 'both': [81], '(1+1)': [82, 154], '(2+1)': [84], 'dimensions.': [85], 'With': [86], 'supervised': [88], 'method,': [90], 'framework': [92], 'our': [94], 'binary': [95], 'classification': [96], 'neural': [97], 'networks': [98], 'identify': [100], 'threshold,': [104], 'as': [105, 107], 'spatial': [109], 'temporal': [111], 'correlation': [112], 'characteristic': [115], 'time': [116], 't_{c},': [117], 'specifying': [118], 'from': [121], 'active': [122], 'phases': [123], 'absorbing': [125], 'ones,': [126], 'is': [127, 158], 'also': [128], 'major': [130], 'product': [131], 'learning.': [134], 'Moreover,': [135], 'employ': [137], 'convolutional': [139], 'autoencoder,': [140], 'an': [141], 'unsupervised': [142], 'technique,': [144], 'extract': [146], 'dimensionality': [147], 'reduction': [148], 'representations': [149], 'cluster': [151], 'bond': [155], 'DP.': [156], 'It': [157], 'quite': [159], 'appealing': [160], 'such': [162], 'method': [164], 'yield': [166], 'reasonable': [168], 'estimation': [169], 'point.': [173]}",2021,"['Percolation (cognitive psychology)', 'Unsupervised learning', 'Artificial intelligence', 'Machine learning', 'Computer science', 'Psychology', 'Neuroscience']","Machine learning (ML) has been well applied to studying equilibrium phase transition models by accurately predicating critical thresholds and some critical exponents. Difficulty will be raised, however, for integrating ML into nonequilibrium phase transitions. The extra dimension in a given nonequilibrium system, namely time, can greatly slow down the procedure toward the steady state. In this paper we find that by using some simple techniques of ML, non-steady-state configurations of directed percolation (DP) suffice to capture its essential critical behaviors in both (1+1) and (2+1) dimensions. With the supervised learning method, the framework of our binary classification neural networks can identify the phase transition threshold, as well as the spatial and temporal correlation exponents. The characteristic time t_{c}, specifying the transition from active phases to absorbing ones, is also a major product of the learning. Moreover, we employ the convolutional autoencoder, an unsupervised learning technique, to extract dimensionality reduction representations and cluster configurations of (1+1) bond DP. It is quite appealing that such a method can yield a reasonable estimation of the critical point."
https://openalex.org/W2785512290,Unsupervised Learning of Depth and Ego-Motion from Monocular Video Using 3D Geometric Constraints,"{'We': [0, 96, 120, 135, 192], 'present': [1], 'a': [2, 80, 87, 145, 178], 'novel': [3, 88, 99], 'approach': [4, 157], 'for': [5, 20, 92, 169], 'unsupervised': [6, 35], 'learning': [7, 16, 37, 181], 'of': [8, 62, 67, 109], 'depth': [9, 36, 114, 160, 171, 182], 'and': [10, 73, 83, 115, 143, 165, 172, 183, 187, 204], 'ego-motion': [11, 26, 74, 116, 184], 'from': [12, 117], 'monocular': [13], 'video.': [14], 'Unsupervised': [15], 'removes': [17], 'the': [18, 58, 63, 68, 140, 167, 198], 'need': [19], 'separate': [21], 'supervisory': [22], 'signals': [23], '(depth': [24], 'or': [25, 29, 40], 'ground': [27], 'truth,': [28], 'multi-view': [30], 'video).': [31], 'Prior': [32], 'work': [33], 'in': [34, 47, 129], 'uses': [38], 'pixel-wise': [39], 'gradient-based': [41], 'losses,': [42], 'which': [43, 130, 214], 'only': [44, 176], 'consider': [45, 57], 'pixels': [46], 'small': [48], 'local': [49], 'neighborhoods.': [50], 'Our': [51, 155], 'main': [52], 'contribution': [53], 'is': [54, 79, 84], 'to': [55, 125], 'explicitly': [56], 'inferred': [59], '3D': [60, 70, 94], 'geometry': [61], 'scene,': [64], 'enforcing': [65], 'consistency': [66], 'estimated': [69, 113], 'point': [71], 'clouds': [72], 'across': [75], 'consecutive': [76], 'frames.': [77, 119], 'This': [78], 'challenging': [81], 'task': [82], 'solved': [85], 'by': [86, 195], '(approximate)': [89], 'backpropagation': [90], 'algorithm': [91, 138], 'aligning': [93], 'structures.': [95], 'combine': [97], 'this': [98, 194], '3D-based': [100], 'loss': [101], 'with': [102], '2D': [103], 'losses': [104], 'based': [105], 'on': [106, 139, 144, 149, 162, 185, 197, 206, 217], 'photometric': [107], 'quality': [108, 200], 'frame': [110], 'reconstructions': [111], 'using': [112], 'adjacent': [118], 'also': [121], 'incorporate': [122], 'validity': [123], 'masks': [124], 'avoid': [126], 'penalizing': [127], 'areas': [128], 'no': [131], 'useful': [132], 'information': [133], 'exists.': [134], 'test': [136], 'our': [137], 'KITTI': [141, 218], 'dataset': [142, 147, 203], 'video': [146, 202], 'captured': [148], 'an': [150], 'uncalibrated': [151, 201], 'mobile': [152], 'phone': [153], 'camera.': [154], 'proposed': [156], 'consistently': [158], 'improves': [159], 'estimates': [161], 'both': [163, 170], 'datasets,': [164], 'outperforms': [166], 'state-of-the-art': [168], 'ego-motion.': [173], 'Because': [174], 'we': [175], 'require': [177], 'simple': [179], 'video,': [180], 'large': [186], 'varied': [188], 'datasets': [189], 'becomes': [190], 'possible.': [191], 'demonstrate': [193], 'training': [196], 'low': [199], 'evaluating': [205], 'KITTI,': [207], 'ranking': [208], 'among': [209], 'top': [210], 'performing': [211], 'prior': [212], 'methods': [213], 'are': [215], 'trained': [216], 'itself.': [219]}",2018,"['Artificial intelligence', 'Computer science', 'Computer vision', 'Monocular', 'Motion (physics)', 'Pixel', 'Unsupervised learning']","We present a novel approach for unsupervised learning of depth and ego-motion from monocular video. Unsupervised learning removes the need for separate supervisory signals (depth or ego-motion ground truth, or multi-view video). Prior work in unsupervised depth learning uses pixel-wise or gradient-based losses, which only consider pixels in small local neighborhoods. Our main contribution is to explicitly consider the inferred 3D geometry of the scene, enforcing consistency of the estimated 3D point clouds and ego-motion across consecutive frames. This is a challenging task and is solved by a novel (approximate) backpropagation algorithm for aligning 3D structures. We combine this novel 3D-based loss with 2D losses based on photometric quality of frame reconstructions using estimated depth and ego-motion from adjacent frames. We also incorporate validity masks to avoid penalizing areas in which no useful information exists. We test our algorithm on the KITTI dataset and on a video dataset captured on an uncalibrated mobile phone camera. Our proposed approach consistently improves depth estimates on both datasets, and outperforms the state-of-the-art for both depth and ego-motion. Because we only require a simple video, learning depth and ego-motion on large and varied datasets becomes possible. We demonstrate this by training on the low quality uncalibrated video dataset and evaluating on KITTI, ranking among top performing prior methods which are trained on KITTI itself."
https://openalex.org/W2604912015,Unsupervised Learning of Multi-Level Descriptors for Person Re-Identification,"{'In': [0], 'this': [1], 'paper,': [2], 'we': [3, 69, 84, 103], 'propose': [4], 'a': [5, 38, 46, 113], 'novel': [6], 'coding': [7, 12], 'method': [8], 'named': [9], 'weighted': [10], 'linear': [11], '(WLC)': [13], 'to': [14, 78, 87], 'learn': [15], 'multi-level': [16, 43, 110], '(e.g.,': [17], 'pixel-level,': [18], 'patch-level': [19], 'and': [20, 52, 90, 126], 'image-level)': [21], 'descriptors': [22, 44, 111], 'from': [23, 59], 'raw': [24], 'pixel': [25], 'data': [26, 58], 'in': [27, 109], 'an': [28], 'unsupervised': [29], 'manner.': [30], 'It': [31], 'guarantees': [32], 'the': [33, 50, 60, 71, 80, 98, 105, 119, 130], 'property': [34], 'of': [35, 100, 132], 'saliency': [36], 'with': [37], 'similarity': [39], 'constraint.': [40], 'The': [41], 'resulting': [42], 'have': [45], 'good': [47], 'balance': [48], 'between': [49], 'robustness': [51], 'distinctiveness.': [53], 'Based': [54], 'on': [55, 118], 'WLC,': [56], 'all': [57], 'same': [61], 'region': [62], 'can': [63], 'be': [64], 'jointly': [65], 'encoded.': [66], 'Consequently,': [67], 'when': [68], 'extract': [70], 'holistic': [72], 'image': [73], 'features,': [74], 'it': [75], 'is': [76], 'able': [77], 'preserve': [79], 'spatial': [81], 'consistency.': [82], 'Furthermore,': [83], 'apply': [85], 'PCA': [86], 'these': [88], 'features': [89], 'compact': [91], 'person': [92, 121], 'representations': [93], 'are': [94], 'then': [95], 'achieved.': [96], 'During': [97], 'stage': [99], 'matching': [101], 'persons,': [102], 'exploit': [104], 'complementary': [106], 'information': [107], 'resided': [108], 'via': [112], 'score-level': [114], 'fusion': [115], 'strategy.': [116], 'Experiments': [117], 'challenging': [120], 're-identification': [122], 'datasets': [123], '-': [124], 'VIPeR': [125], 'CUHK': [127], '01,': [128], 'demonstrate': [129], 'effectiveness': [131], 'our': [133], 'method.': [134]}",2017,"['Artificial intelligence', 'Pattern recognition (psychology)', 'Computer science', 'Optimal distinctiveness theory', 'Coding (social sciences)', 'Robustness (evolution)', 'Pixel', 'Matching (statistics)', 'Exploit', 'Data mining', 'Mathematics', 'Statistics', 'Biochemistry', 'Computer security', 'Psychotherapist', 'Gene', 'Psychology', 'Chemistry']","In this paper, we propose a novel coding method named weighted linear coding (WLC) to learn multi-level (e.g., pixel-level, patch-level and image-level) descriptors from raw pixel data in an unsupervised manner. It guarantees the property of saliency with a similarity constraint. The resulting multi-level descriptors have a good balance between the robustness and distinctiveness. Based on WLC, all data from the same region can be jointly encoded. Consequently, when we extract the holistic image features, it is able to preserve the spatial consistency. Furthermore, we apply PCA to these features and compact person representations are then achieved. During the stage of matching persons, we exploit the complementary information resided in multi-level descriptors via a score-level fusion strategy. Experiments on the challenging person re-identification datasets - VIPeR and CUHK 01, demonstrate the effectiveness of our method."
https://openalex.org/W2792039411,Unsupervised Learning for Mental Stress Detection,"{'Copyright': [0], '©': [1], '2018': [2], 'by': [3, 165], 'SCITEPRESS': [4], '–': [5], 'Science': [6], 'and': [7, 53, 114, 123, 146], 'Technology': [8], 'Publications,': [9], 'Lda.': [10], 'All': [11], 'rights': [12], 'reserved': [13], 'One': [14], 'of': [15, 22, 34, 80, 126, 134, 144, 158, 167, 188, 196], 'the': [16, 20, 28, 78, 94, 132, 135, 159, 200, 202], 'major': [17], 'challenges': [18], 'in': [19, 27, 51], 'field': [21], 'ambulant': [23, 218], 'stress': [24, 41, 46, 88, 98, 107, 115, 183], 'detection': [25], 'lies': [26], 'model': [29], 'validation.': [30], 'Commonly,': [31], 'different': [32], 'types': [33], 'questionnaires': [35], 'are': [36, 54, 100], 'used': [37, 154], 'to': [38, 56, 155, 178, 205, 216], 'record': [39], 'perceived': [40, 97], 'levels.': [42], 'These': [43], 'only': [44], 'capture': [45], 'levels': [47, 99], 'at': [48], 'discrete': [49], 'moments': [50], 'time': [52], 'prone': [55], 'subjective': [57], 'inaccuracies.': [58], 'Although,': [59], 'many': [60], 'studies': [61], 'have': [62], 'already': [63], 'reported': [64], 'such': [65], 'issues,': [66], 'a': [67, 105, 141, 194, 212], 'solution': [68], 'for': [69, 87], 'these': [70, 207], 'difficulties': [71], 'is': [72, 204], 'still': [73], 'lacking.': [74], 'This': [75], 'paper': [76], 'explores': [77], 'potential': [79], 'unsupervised': [81, 91], 'learning': [82, 92], 'with': [83, 161, 193], 'Self-Organizing': [84], 'Maps': [85], '(SOM)': [86], 'detection.': [89], 'In': [90, 199], 'settings,': [93], 'labels': [95], 'from': [96, 211], 'not': [101], 'needed': [102], 'anymore.': [103], 'First,': [104], 'controlled': [106, 213], 'experiment': [108], 'was': [109, 137, 153, 191], 'conducted': [110], 'during': [111], 'which': [112], 'relax': [113, 180], 'phases': [116, 181], 'were': [117, 129], 'alternated.': [118], 'The': [119], 'skin': [120], 'conductance': [121], '(SC)': [122], 'electrocardiogram': [124], '(ECG)': [125], 'test': [127], 'subjects': [128], 'recorded.': [130], 'Then,': [131], 'structure': [133], 'SOM': [136, 160], 'built': [138], 'based': [139], 'on': [140], 'training': [142], 'set': [143], 'SC': [145], 'ECG': [147], 'features.': [148], 'A': [149, 185], 'Gaussian': [150], 'Mixture': [151], 'Model': [152], 'cluster': [156], 'regions': [157], 'similar': [162], 'characteristics.': [163], 'Finally,': [164], 'comparison': [166], 'features': [168], 'values': [169], 'within': [170], 'each': [171], 'cluster,': [172], 'two': [173], 'clusters': [174], 'could': [175], 'be': [176], 'associated': [177], 'either': [179], 'or': [182], 'phases.': [184], 'classification': [186], 'performance': [187], '79.0%': [189], '(±5.16)': [190], 'reached': [192], 'sensitivity': [195], '75.6%': [197], '(±11.2).': [198], 'future,': [201], 'goal': [203], 'transfer': [206], 'first': [208], 'initial': [209], 'results': [210], 'laboratory': [214], 'setting': [215], 'an': [217], 'environment.': [219]}",2018,"['Stress (linguistics)', 'Computer science', 'Unsupervised learning', 'Mental stress', 'Artificial intelligence', 'Machine learning', 'Medicine', 'Philosophy', 'Internal medicine', 'Linguistics']","Copyright © 2018 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved One of the major challenges in the field of ambulant stress detection lies in the model validation. Commonly, different types of questionnaires are used to record perceived stress levels. These only capture stress levels at discrete moments in time and are prone to subjective inaccuracies. Although, many studies have already reported such issues, a solution for these difficulties is still lacking. This paper explores the potential of unsupervised learning with Self-Organizing Maps (SOM) for stress detection. In unsupervised learning settings, the labels from perceived stress levels are not needed anymore. First, a controlled stress experiment was conducted during which relax and stress phases were alternated. The skin conductance (SC) and electrocardiogram (ECG) of test subjects were recorded. Then, the structure of the SOM was built based on a training set of SC and ECG features. A Gaussian Mixture Model was used to cluster regions of the SOM with similar characteristics. Finally, by comparison of features values within each cluster, two clusters could be associated to either relax phases or stress phases. A classification performance of 79.0% (±5.16) was reached with a sensitivity of 75.6% (±11.2). In the future, the goal is to transfer these first initial results from a controlled laboratory setting to an ambulant environment."
https://openalex.org/W2911338114,Challenging the Boundaries of Unsupervised Learning for Semantic Similarity,"{'The': [0], 'semantic': [1, 19, 65, 71], 'analysis': [2], 'field': [3], 'has': [4], 'a': [5, 24, 49, 63, 85, 102], 'crucial': [6], 'role': [7], 'to': [8, 14], 'play': [9], 'in': [10, 27], 'the': [11, 18, 28, 39, 70, 77, 99, 124], 'research': [12], 'related': [13], 'text': [15], 'analytics.': [16], 'Calculating': [17], 'similarity': [20, 66, 72, 97, 114], 'between': [21, 73], 'sentences': [22], 'is': [23], 'long-standing': [25], 'problem': [26], 'area': [29], 'of': [30, 41], 'natural': [31], 'language': [32], 'processing,': [33], 'and': [34, 75, 94, 112, 120, 123], 'it': [35], 'differs': [36], 'significantly': [37], 'as': [38], 'domain': [40], 'operation': [42], 'differs.': [43], 'In': [44], 'this': [45], 'paper,': [46], 'we': [47], 'present': [48], 'methodology': [50, 100], 'that': [51], 'can': [52], 'be': [53], 'applied': [54], 'across': [55], 'multiple': [56], 'domains': [57], 'by': [58], 'incorporating': [59], 'corpora-based': [60], 'statistics': [61], 'into': [62], 'standardized': [64], 'algorithm.': [67], 'To': [68], 'calculate': [69], 'words': [74], 'sentences,': [76], 'proposed': [78], 'method': [79], 'follows': [80], 'an': [81], 'edge-based': [82], 'approach': [83], 'using': [84], 'lexical': [86], 'database.': [87], 'When': [88], 'tested': [89], 'on': [90], 'both': [91, 107], 'benchmark': [92], 'standards': [93], 'mean': [95], 'human': [96], 'dataset,': [98], 'achieves': [101], 'high': [103], 'correlation': [104], 'value': [105], 'for': [106], 'word': [108], '(r': [109, 115, 127], '=': [110, 116, 128], '0.8753)': [111], 'sentence': [113], '0.8793)': [117], 'concerning': [118], 'Rubenstein': [119], 'Goodenough': [121], 'standard': [122], 'SICK': [125], 'dataset': [126], '0.83241)': [129], 'outperforming': [130], 'other': [131], 'unsupervised': [132], 'models.': [133]}",2019,"['Computer science', 'Semantic similarity', 'Artificial intelligence', 'Similarity (geometry)', 'Natural language processing', 'Benchmark (surveying)', 'Sentence', 'Word (group theory)', 'Unsupervised learning', 'Mathematics', 'Image (mathematics)', 'Geodesy', 'Geometry', 'Geography']","The semantic analysis field has a crucial role to play in the research related to text analytics. Calculating the semantic similarity between sentences is a long-standing problem in the area of natural language processing, and it differs significantly as the domain of operation differs. In this paper, we present a methodology that can be applied across multiple domains by incorporating corpora-based statistics into a standardized semantic similarity algorithm. To calculate the semantic similarity between words and sentences, the proposed method follows an edge-based approach using a lexical database. When tested on both benchmark standards and mean human similarity dataset, the methodology achieves a high correlation value for both word (r = 0.8753) and sentence similarity (r = 0.8793) concerning Rubenstein and Goodenough standard and the SICK dataset (r = 0.83241) outperforming other unsupervised models."
https://openalex.org/W2906498146,DeepAnT: A Deep Learning Approach for Unsupervised Anomaly Detection in Time Series,"{'Traditional': [0], 'distance': [1], 'and': [2, 12, 80, 103, 128, 164, 329], 'density-based': [3], 'anomaly': [4, 30, 49, 90, 129, 254, 265, 319, 340], 'detection': [5, 31, 50, 91, 255, 320, 341], 'techniques': [6], 'are': [7, 95, 219], 'unable': [8], 'to': [9, 61, 88, 101, 111, 142, 166, 178, 221, 244, 280, 288], 'detect': [10], 'periodic': [11], 'seasonality': [13], 'related': [14], 'point': [15, 76], 'anomalies': [16, 94, 204], 'which': [17, 57, 183, 322], 'occur': [18], 'commonly': [19], 'in': [20, 27, 32, 82, 211, 226, 256, 343], 'streaming': [21], 'data,': [22, 56], 'leaving': [23], 'a': [24, 45, 70, 117, 155, 162, 215, 223, 228, 290, 311, 324], 'big': [25, 291], 'gap': [26], 'time': [28, 54, 83, 118, 125, 146, 158, 170, 190, 269, 331], 'series': [29, 55, 84, 126, 133, 159], 'the': [33, 37, 62, 89, 105, 113, 144, 149, 168, 179, 188, 203, 206, 245, 250, 253, 268, 338, 346], 'current': [34], 'era': [35], 'of': [36, 68, 73, 116, 122, 157, 217, 249, 270, 293, 300, 314, 326, 345], 'IoT.': [38], 'To': [39], 'address': [40], 'this': [41, 274], 'problem,': [42], 'we': [43], 'present': [44], 'novel': [46], 'deep': [47, 137, 212], 'learning-based': [48, 213], 'approach': [51, 275], '(DeepAnT)': [52], 'for': [53, 186], 'is': [58, 66, 109, 175, 184, 258, 285], 'equally': [59], 'applicable': [60], 'non-streaming': [63], 'cases.': [64], 'DeepAnT': [65, 97, 120, 196, 257, 336], 'capable': [67], 'detecting': [69], 'wide': [71], 'range': [72], 'anomalies,': [74, 77, 79], 'i.e.,': [75], 'contextual': [78], 'discords': [81], 'data.': [85], 'In': [86], 'contrast': [87], 'methods': [92, 342], 'where': [93, 283], 'learned,': [96], 'uses': [98, 136], 'unlabeled': [99], 'data': [100, 106, 208, 218, 236, 294], 'capture': [102], 'learn': [104], 'distribution': [107], 'that': [108, 335], 'used': [110], 'forecast': [112], 'normal': [114, 193, 302], 'behavior': [115], 'series.': [119, 332], 'consists': [121], 'two': [123], 'modules:': [124], 'predictor': [127], 'detector.': [130], 'The': [131, 172], '<italic>time': [132], 'predictor</italic>': [134], 'module': [135, 153], 'convolutional': [138], 'neural': [139], 'network': [140], '(CNN)': [141], 'predict': [143, 167], 'next': [145, 169], 'stamp': [147, 191], 'on': [148, 233, 264, 317, 350], 'defined': [150], 'horizon.': [151], 'This': [152], 'takes': [154], 'window': [156], '(used': [160], 'as': [161, 192, 303, 305], 'context)': [163], 'attempts': [165], 'stamp.': [171], 'predicted': [173], 'value': [174], 'then': [176], 'passed': [177], '<italic>anomaly': [180], 'detector</italic>': [181], 'module,': [182], 'responsible': [185], 'tagging': [187], 'corresponding': [189], 'or': [194], 'abnormal.': [195], 'can': [197, 230, 276], 'be': [198, 231, 277], 'trained': [199, 232], 'even': [200], 'without': [201], 'removing': [202], 'from': [205, 296], 'given': [207], 'set.': [209], 'Generally,': [210], 'approaches,': [214], 'lot': [216], 'required': [220], 'train': [222], 'model.': [224], 'Whereas': [225], 'DeepAnT,': [227], 'model': [229, 271], 'relatively': [234], 'small': [235], 'set': [237], 'while': [238, 348], 'achieving': [239], 'good': [240], 'generalization': [241], 'capabilities': [242], 'due': [243], 'effective': [246], 'parameter': [247], 'sharing': [248], 'CNN.': [251], 'As': [252], 'unsupervised,': [259], 'it': [260, 284], 'does': [261], 'not': [262], 'rely': [263], 'labels': [266], 'at': [267], 'generation.': [272], 'Therefore,': [273], 'directly': [278], 'applied': [279], 'real-life': [281], 'scenarios': [282], 'practically': [286], 'impossible': [287], 'label': [289], 'stream': [292], 'coming': [295], 'heterogeneous': [297], 'sensors': [298], 'comprising': [299], 'both': [301], 'well': [304], 'anomalous': [306], 'points.': [307], 'We': [308], 'have': [309], 'performed': [310], 'detailed': [312], 'evaluation': [313], '15': [315], 'algorithms': [316], '10': [318], 'benchmarks,': [321], 'contain': [323], 'total': [325], '433': [327], 'real': [328], 'synthetic': [330], 'Experiments': [333], 'show': [334], 'outperforms': [337], 'state-of-the-art': [339], 'most': [344], 'cases,': [347], 'performing': [349], 'par': [351], 'with': [352], 'others.': [353]}",2018,"['Anomaly detection', 'Computer science', 'Series (stratigraphy)', 'Anomaly (physics)', 'Artificial intelligence', 'Context (archaeology)', 'Time series', 'Deep learning', 'Convolutional neural network', 'Machine learning', 'Data mining', 'Pattern recognition (psychology)', 'Condensed matter physics', 'Physics', 'Paleontology', 'Biology']","Traditional distance and density-based anomaly detection techniques are unable to detect periodic and seasonality related point anomalies which occur commonly in streaming data, leaving a big gap in time series anomaly detection in the current era of the IoT. To address this problem, we present a novel deep learning-based anomaly detection approach (DeepAnT) for time series data, which is equally applicable to the non-streaming cases. DeepAnT is capable of detecting a wide range of anomalies, i.e., point anomalies, contextual anomalies, and discords in time series data. In contrast to the anomaly detection methods where anomalies are learned, DeepAnT uses unlabeled data to capture and learn the data distribution that is used to forecast the normal behavior of a time series. DeepAnT consists of two modules: time series predictor and anomaly detector. The <italic>time series predictor</italic> module uses deep convolutional neural network (CNN) to predict the next time stamp on the defined horizon. This module takes a window of time series (used as a context) and attempts to predict the next time stamp. The predicted value is then passed to the <italic>anomaly detector</italic> module, which is responsible for tagging the corresponding time stamp as normal or abnormal. DeepAnT can be trained even without removing the anomalies from the given data set. Generally, in deep learning-based approaches, a lot of data are required to train a model. Whereas in DeepAnT, a model can be trained on relatively small data set while achieving good generalization capabilities due to the effective parameter sharing of the CNN. As the anomaly detection in DeepAnT is unsupervised, it does not rely on anomaly labels at the time of model generation. Therefore, this approach can be directly applied to real-life scenarios where it is practically impossible to label a big stream of data coming from heterogeneous sensors comprising of both normal as well as anomalous points. We have performed a detailed evaluation of 15 algorithms on 10 anomaly detection benchmarks, which contain a total of 433 real and synthetic time series. Experiments show that DeepAnT outperforms the state-of-the-art anomaly detection methods in most of the cases, while performing on par with others."
https://openalex.org/W3167114847,Evaluation of MRI Denoising Methods Using Unsupervised Learning,"{'In': [0], 'this': [1], 'paper': [2], 'we': [3], 'evaluate': [4], 'two': [5, 57], 'unsupervised': [6], 'approaches': [7], 'to': [8, 119], 'denoise': [9], 'Magnetic': [10], 'Resonance': [11], 'Images': [12], '(MRI)': [13], 'in': [14], 'the': [15, 20, 37, 48, 66, 78], 'complex': [16, 79], 'image': [17, 80], 'space': [18, 81], 'using': [19, 100], 'raw': [21], 'information': [22, 76], 'that': [23], 'k-space': [24], 'holds.': [25], 'The': [26], 'first': [27], 'method': [28], 'is': [29, 40], 'based': [30, 41], 'on': [31, 42, 56], 'Stein’s': [32], 'Unbiased': [33], 'Risk': [34], 'Estimator,': [35], 'while': [36], 'second': [38], 'approach': [39], 'a': [43, 94], 'blindspot': [44], 'network,': [45], 'which': [46, 82], 'limits': [47], 'network’s': [49], 'receptive': [50], 'field.': [51], 'Both': [52, 89], 'methods': [53], 'are': [54, 91], 'tested': [55], 'different': [58], 'datasets,': [59], 'one': [60], 'containing': [61], 'real': [62], 'knee': [63], 'MRI': [64], 'and': [65, 102, 109, 116], 'other': [67], 'consists': [68], 'of': [69], 'synthetic': [70], 'brain': [71], 'MRI.': [72], 'These': [73], 'datasets': [74], 'contain': [75], 'about': [77], 'will': [83], 'be': [84, 120], 'used': [85], 'for': [86], 'denoising': [87, 122], 'purposes.': [88], 'networks': [90, 113], 'compared': [92], 'against': [93], 'state-of-the-art': [95], 'algorithm,': [96], 'Non-Local': [97], 'Means': [98], '(NLM)': [99], 'quantitative': [101], 'qualitative': [103, 110], 'measures.': [104], 'For': [105], 'most': [106], 'given': [107], 'metrics': [108], 'measures,': [111], 'both': [112], 'outperformed': [114], 'NLM,': [115], 'they': [117], 'prove': [118], 'reliable': [121], 'methods.': [123]}",2021,"['Noise reduction', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Computer science', 'Estimator', 'Field (mathematics)', 'Mathematics', 'Statistics', 'Pure mathematics']","In this paper we evaluate two unsupervised approaches to denoise Magnetic Resonance Images (MRI) in the complex image space using the raw information that k-space holds. The first method is based on Stein’s Unbiased Risk Estimator, while the second approach is based on a blindspot network, which limits the network’s receptive field. Both methods are tested on two different datasets, one containing real knee MRI and the other consists of synthetic brain MRI. These datasets contain information about the complex image space which will be used for denoising purposes. Both networks are compared against a state-of-the-art algorithm, Non-Local Means (NLM) using quantitative and qualitative measures. For most given metrics and qualitative measures, both networks outperformed NLM, and they prove to be reliable denoising methods."
https://openalex.org/W2592017964,Double-Barrier Memristive Devices for Unsupervised Learning and Pattern Recognition,"{'The': [0, 34, 54, 106, 227], 'use': [1, 101], 'of': [2, 38, 58, 93, 96, 115, 119, 167, 192, 219, 239], 'interface-based': [3], 'resistive': [4], 'switching': [5], 'devices': [6, 60, 264], 'for': [7, 90, 99, 157, 208, 245, 262], 'neuromorphic': [8, 28], 'computing': [9, 155], 'is': [10, 128, 147, 180, 183, 225, 251], 'investigated.': [11], 'In': [12], 'a': [13, 27, 39, 51, 62, 70, 103, 154, 184, 189, 200, 204, 247], 'combined': [14], 'experimental': [15, 131], 'and': [16, 23, 47, 69, 110, 145, 160, 203, 237], 'numerical': [17, 228], 'study,': [18], 'the': [19, 59, 87, 91, 113, 116, 137, 151, 165, 209, 215, 222, 232, 240, 260], 'important': [20], 'device': [21], 'parameters': [22], 'their': [24, 254], 'impact': [25], 'on': [26, 50, 124, 164], 'pattern': [29, 158], 'recognition': [30, 104, 159], 'system': [31], 'are': [32, 48, 61, 83, 108, 243], 'studied.': [33], 'memristive': [35, 78, 193, 241], 'cells': [36, 98, 242], 'consist': [37], 'layer': [40], 'sequence': [41], 'Al/Al<sub>2</sub>O<sub>3</sub>/Nb': [42], '<sub><i>x</i></sub>': [43, 75], 'O': [44, 76], '<sub><i>y</i></sub>': [45, 77], '/Au': [46], 'fabricated': [49], '4-inch': [52], 'wafer.': [53], 'key': [55], 'functional': [56], 'ingredients': [57], '1.3': [63], 'nm': [64], 'thick': [65, 73], 'Al<sub>2</sub>O<sub>3</sub>': [66], 'tunnel': [67], 'barrier': [68], '2.5': [71], 'mm': [72], 'Nb': [74], 'layer.': [79], 'Voltage': [80], 'pulse': [81], 'measurements': [82], 'used': [84], 'to': [85, 130, 142], 'study': [86], 'electrical': [88], 'conditions': [89], 'emulation': [92], 'synaptic': [94], 'functionality': [95], 'single': [97], 'later': [100], 'in': [102, 112, 265], 'system.': [105], 'results': [107], 'evaluated': [109], 'modeled': [111], 'framework': [114], 'plasticity': [117], 'model': [118], 'Ziegler': [120], 'et': [121, 169, 173, 177], 'al.': [122, 170, 174, 178], 'Based': [123], 'this': [125], 'model,': [126, 153], 'which': [127], 'matched': [129], 'data': [132, 217], 'from': [133, 221], '84': [134], 'individual': [135], 'devices,': [136, 194], 'network': [138, 152, 187], 'performance': [139], 'with': [140, 188], 'regard': [141], 'yield,': [143, 235], 'reliability,': [144, 236], 'variability': [146, 238], 'investigated': [148], 'numerically.': [149], 'As': [150, 212], 'scheme': [156, 207], 'unsupervised': [161], 'learning': [162], 'based': [163], 'work': [166], 'Querlioz': [168], '(2011),': [171], 'Sheridan': [172], '(2014),': [175], 'Zahari': [176], '(2015)': [179], 'employed.': [181], 'This': [182], 'two-layer': [185], 'feedforward': [186], 'crossbar': [190, 266], 'array': [191, 267], 'leaky': [195], 'integrate-and-fire': [196], 'output': [197], 'neurons': [198], 'including': [199], 'winner-takes-all': [201], 'strategy,': [202], 'stochastic': [205], 'coding': [206], 'input': [210, 213], 'pattern.': [211], 'pattern,': [214], 'full': [216], 'set': [218], 'digits': [220], 'MNIST': [223], 'database': [224], 'used.': [226], 'investigation': [229], 'indicates': [230], 'that': [231, 253], 'experimentally': [233], 'obtained': [234], 'suitable': [244], 'such': [246], 'network.': [248], 'Furthermore,': [249], 'evidence': [250], 'presented': [252], 'strong': [255], '<i>I</i>-<i>V</i>': [256], 'non-linearity': [257], 'might': [258], 'avoid': [259], 'need': [261], 'selector': [263], 'structures.': [268]}",2017,"['Unsupervised learning', 'Computer science', 'Artificial intelligence', 'Pattern recognition (psychology)']","The use of interface-based resistive switching devices for neuromorphic computing is investigated. In a combined experimental and numerical study, the important device parameters and their impact on a neuromorphic pattern recognition system are studied. The memristive cells consist of a layer sequence Al/Al<sub>2</sub>O<sub>3</sub>/Nb <sub><i>x</i></sub> O <sub><i>y</i></sub> /Au and are fabricated on a 4-inch wafer. The key functional ingredients of the devices are a 1.3 nm thick Al<sub>2</sub>O<sub>3</sub> tunnel barrier and a 2.5 mm thick Nb <sub><i>x</i></sub> O <sub><i>y</i></sub> memristive layer. Voltage pulse measurements are used to study the electrical conditions for the emulation of synaptic functionality of single cells for later use in a recognition system. The results are evaluated and modeled in the framework of the plasticity model of Ziegler et al. Based on this model, which is matched to experimental data from 84 individual devices, the network performance with regard to yield, reliability, and variability is investigated numerically. As the network model, a computing scheme for pattern recognition and unsupervised learning based on the work of Querlioz et al. (2011), Sheridan et al. (2014), Zahari et al. (2015) is employed. This is a two-layer feedforward network with a crossbar array of memristive devices, leaky integrate-and-fire output neurons including a winner-takes-all strategy, and a stochastic coding scheme for the input pattern. As input pattern, the full data set of digits from the MNIST database is used. The numerical investigation indicates that the experimentally obtained yield, reliability, and variability of the memristive cells are suitable for such a network. Furthermore, evidence is presented that their strong <i>I</i>-<i>V</i> non-linearity might avoid the need for selector devices in crossbar array structures."
https://openalex.org/W2997909961,Collaborative Graph Convolutional Networks: Unsupervised Learning Meets Semi-Supervised Learning,"{'Graph': [0], 'convolutional': [1, 74], 'networks': [2, 75], '(GCN)': [3], 'have': [4], 'achieved': [5], 'promising': [6], 'performance': [7, 57, 156, 188, 211], 'in': [8, 41], 'attributed': [9, 82, 109, 183], 'graph': [10, 68, 73, 83, 110, 118, 170, 184], 'clustering': [11, 84, 111, 185], 'and': [12, 25, 30, 86], 'semi-supervised': [13, 59, 88, 147, 158, 213], 'node': [14, 89, 190], 'classification': [15, 90, 191], 'because': [16], 'it': [17, 149], 'is': [18, 78, 113, 140, 150, 192], 'capable': [19], 'of': [20, 32, 38, 44, 58, 80, 133, 145, 157, 163, 175, 189, 212], 'modeling': [21], 'complex': [22, 101], 'graphical': [23], 'structure,': [24], 'jointly': [26], 'learning': [27, 40, 52, 69, 159, 203], 'both': [28], 'features': [29], 'relations': [31], 'nodes.': [33], 'Inspired': [34], 'by': [35, 115, 138, 195], 'the': [36, 42, 56, 99, 127, 131, 143, 146, 155, 161, 164, 173, 181, 210], 'success': [37], 'unsupervised': [39, 51, 202], 'training': [43], 'deep': [45], 'models,': [46], 'we': [47, 64], 'wonder': [48], 'whether': [49], 'graph-based': [50, 201], 'can': [53, 96, 204], 'collaboratively': [54], 'boost': [55, 154], 'learning.': [60, 214], 'In': [61], 'this': [62], 'paper,': [63], 'propose': [65], 'a': [66, 87, 104], 'multi-task': [67], 'model,': [70], 'called': [71], 'collaborative': [72], '(CGCN).': [76], 'CGCN': [77], 'composed': [79], 'an': [81, 134], 'network': [85, 112], 'network.': [91], 'As': [92], 'Gaussian': [93, 121], 'mixture': [94, 122], 'models': [95, 123], 'effectively': [97], 'discover': [98], 'inherent': [100], 'data': [102], 'distributions,': [103], 'new': [105], 'end': [106, 108], 'to': [107, 152, 208], 'designed': [114], 'combining': [116], 'variational': [117], 'auto-encoder': [119], 'with': [120, 142, 160, 180], '(GMM-VGAE)': [124], 'rather': [125], 'than': [126], 'classic': [128], 'k-means.': [129], 'If': [130], 'pseudo-label': [132], 'unlabeled': [135], 'sample': [136], 'assigned': [137], 'GMM-VGAE': [139, 178], 'consistent': [141], 'prediction': [144], 'GCN,': [148], 'selected': [151], 'further': [153], 'help': [162], 'pseudo-labels.': [165], 'Extensive': [166], 'experiments': [167], 'on': [168], 'benchmark': [169], 'datasets': [171], 'validate': [172], 'superiority': [174], 'our': [176, 196], 'proposed': [177, 197], 'compared': [179], 'state-of-the-art': [182], 'networks.': [186], 'The': [187], 'greatly': [193], 'improved': [194], 'CGCN,': [198], 'which': [199], 'verifies': [200], 'be': [205], 'well': [206], 'exploited': [207], 'enhance': [209]}",2020,"['Computer science', 'Semi-supervised learning', 'Artificial intelligence', 'Unsupervised learning', 'Graph', 'Cluster analysis', 'Machine learning', 'Clustering coefficient', 'Pattern recognition (psychology)', 'Deep learning', 'Autoencoder', 'Supervised learning', 'Artificial neural network', 'Theoretical computer science']","Graph convolutional networks (GCN) have achieved promising performance in attributed graph clustering and semi-supervised node classification because it is capable of modeling complex graphical structure, and jointly learning both features and relations of nodes. Inspired by the success of unsupervised learning in the training of deep models, we wonder whether graph-based unsupervised learning can collaboratively boost the performance of semi-supervised learning. In this paper, we propose a multi-task graph learning model, called collaborative graph convolutional networks (CGCN). CGCN is composed of an attributed graph clustering network and a semi-supervised node classification network. As Gaussian mixture models can effectively discover the inherent complex data distributions, a new end to end attributed graph clustering network is designed by combining variational graph auto-encoder with Gaussian mixture models (GMM-VGAE) rather than the classic k-means. If the pseudo-label of an unlabeled sample assigned by GMM-VGAE is consistent with the prediction of the semi-supervised GCN, it is selected to further boost the performance of semi-supervised learning with the help of the pseudo-labels. Extensive experiments on benchmark graph datasets validate the superiority of our proposed GMM-VGAE compared with the state-of-the-art attributed graph clustering networks. The performance of node classification is greatly improved by our proposed CGCN, which verifies graph-based unsupervised learning can be well exploited to enhance the performance of semi-supervised learning."
https://openalex.org/W3095463428,Unsupervised Learning of Non-Hermitian Topological Phases,"{'Non-Hermitian': [0], 'topological': [1, 35, 69, 78, 123], 'phases': [2, 36, 70, 124], 'bear': [3], 'a': [4, 57, 114], 'number': [5], 'of': [6, 18, 64, 86, 103], 'exotic': [7], 'properties,': [8], 'such': [9], 'as': [10, 107], 'the': [11, 16, 51, 61, 100, 104, 108], 'non-Hermitian': [12, 34, 52, 77, 122], 'skin': [13, 53], 'effect': [14, 54], 'and': [15, 83, 132], 'breakdown': [17], 'conventional': [19], 'bulk-boundary': [20], 'correspondence.': [21], 'In': [22], 'this': [23, 93], 'Letter,': [24], 'we': [25, 90], 'introduce': [26], 'an': [27, 126], 'unsupervised': [28, 65, 127], 'machine': [29], 'learning': [30, 66, 121], 'approach': [31], 'to': [32, 68], 'classify': [33], 'based': [37], 'on': [38, 120], 'diffusion': [39], 'maps,': [40], 'which': [41], 'are': [42], 'widely': [43], 'used': [44], 'in': [45, 75, 125, 130], 'manifold': [46], 'learning.': [47], 'We': [48], 'find': [49], 'that': [50, 92], 'will': [55], 'pose': [56], 'notable': [58], 'obstacle,': [59], 'rendering': [60], 'straightforward': [62], 'extension': [63], 'approaches': [67], 'for': [71, 117], 'Hermitian': [72], 'systems': [73], 'ineffective': [74], 'clustering': [76], 'phases.': [79], 'Through': [80], 'theoretical': [81], 'analysis': [82], 'numerical': [84], 'simulations': [85], 'two': [87], 'prototypical': [88], 'models,': [89], 'show': [91], 'difficulty': [94], 'can': [95], 'be': [96], 'circumvented': [97], 'by': [98], 'choosing': [99], '""on-site""': [101], 'elements': [102], 'projective': [105], 'matrix': [106], 'input': [109], 'data.': [110], 'Our': [111], 'results': [112], 'provide': [113], 'valuable': [115], 'guidance': [116], 'future': [118], 'studies': [119], 'fashion,': [128], 'both': [129], 'theory': [131], 'experiment.': [133]}",2021,"['Hermitian matrix', 'Unsupervised learning', 'Topological data analysis', 'Topology (electrical circuits)', 'Cluster analysis', 'Persistent homology', 'Computer science', 'Mathematics', 'Pure mathematics', 'Artificial intelligence', 'Algorithm', 'Combinatorics']","Non-Hermitian topological phases bear a number of exotic properties, such as the non-Hermitian skin effect and the breakdown of conventional bulk-boundary correspondence. In this Letter, we introduce an unsupervised machine learning approach to classify non-Hermitian topological phases based on diffusion maps, which are widely used in manifold learning. We find that the non-Hermitian skin effect will pose a notable obstacle, rendering the straightforward extension of unsupervised learning approaches to topological phases for Hermitian systems ineffective in clustering non-Hermitian topological phases. Through theoretical analysis and numerical simulations of two prototypical models, we show that this difficulty can be circumvented by choosing the ""on-site"" elements of the projective matrix as the input data. Our results provide a valuable guidance for future studies on learning non-Hermitian topological phases in an unsupervised fashion, both in theory and experiment."
https://openalex.org/W2786917922,Unsupervised Learning of Goal Spaces for Intrinsically Motivated Goal Exploration,"{'Intrinsically': [0], 'motivated': [1], 'goal': [2, 81, 113], 'exploration': [3, 22, 114, 143], 'algorithms': [4, 23, 76, 97, 144], 'enable': [5], 'machines': [6], 'to': [7, 27, 32, 71, 77, 106], 'discover': [8], 'repertoires': [9], 'of': [10, 16, 103], 'policies': [11], 'that': [12, 52, 142], 'produce': [13], 'a': [14, 58, 85, 91, 108, 117, 131], 'diversity': [15], 'effects': [17], 'in': [18, 39, 57, 90, 116, 123], 'complex': [19], 'environments.': [20], 'These': [21], 'have': [24, 48], 'been': [25], 'shown': [26], 'allow': [28], 'real': [29], 'world': [30, 104], 'robots': [31], 'acquire': [33], 'skills': [34], 'such': [35, 146], 'as': [36], 'tool': [37], 'use': [38, 72, 98], 'high-dimensional': [40], 'continuous': [41], 'state': [42], 'and': [43, 139], 'action': [44], 'spaces.': [45], 'However,': [46], 'they': [47], 'so': [49], 'far': [50], 'assumed': [51], 'self-generated': [53], 'goals': [54, 122], 'are': [55], 'sampled': [56], 'specifically': [59], 'engineered': [60, 155], 'feature': [61], 'space,': [62], 'limiting': [63], 'their': [64], 'autonomy.': [65], 'In': [66], 'this': [67, 124], 'work,': [68], 'we': [69, 140], 'propose': [70], 'deep': [73, 95], 'representation': [74], 'learning': [75, 93, 96], 'learn': [78, 107], 'an': [79, 137], 'adequate': [80], 'space.': [82, 126], 'This': [83], 'is': [84], 'developmental': [86], '2-stage': [87], 'approach:': [88], 'first,': [89], 'perceptual': [92], 'stage,': [94], 'passive': [99], 'raw': [100], 'sensor': [101], 'observations': [102], 'changes': [105], 'corresponding': [109], 'latent': [110, 125], 'space;': [111], 'then': [112], 'happens': [115], 'second': [118], 'stage': [119], 'by': [120], 'sampling': [121], 'We': [127], 'present': [128], 'experiments': [129], 'where': [130], 'simulated': [132], 'robot': [133], 'arm': [134], 'interacts': [135], 'with': [136], 'object,': [138], 'show': [141], 'using': [145, 154], 'learned': [147], 'representations': [148], 'can': [149], 'match': [150], 'the': [151], 'performance': [152], 'obtained': [153], 'representations.': [156]}",2018,"['Computer science', 'Goal orientation', 'Artificial intelligence', 'Human–computer interaction', 'Psychology', 'Social psychology']","Intrinsically motivated goal exploration algorithms enable machines to discover repertoires of policies that produce a diversity of effects in complex environments. These exploration algorithms have been shown to allow real world robots to acquire skills such as tool use in high-dimensional continuous state and action spaces. However, they have so far assumed that self-generated goals are sampled in a specifically engineered feature space, limiting their autonomy. In this work, we propose to use deep representation learning algorithms to learn an adequate goal space. This is a developmental 2-stage approach: first, in a perceptual learning stage, deep learning algorithms use passive raw sensor observations of world changes to learn a corresponding latent space; then goal exploration happens in a second stage by sampling goals in this latent space. We present experiments where a simulated robot arm interacts with an object, and we show that exploration algorithms using such learned representations can match the performance obtained using engineered representations."
https://openalex.org/W3172159586,Deep Unsupervised Learning for Joint Antenna Selection and Hybrid Beamforming,"{'In': [0], 'this': [1], 'paper,': [2], 'we': [3], 'propose': [4], 'a': [5, 63, 68, 93, 104], 'novel': [6], 'deep': [7], 'unsupervised': [8, 106], 'learning-based': [9], 'approach\\nthat': [10], 'jointly': [11, 101], 'optimizes': [12], 'antenna': [13, 43, 56], 'selection': [14, 44, 57], 'and': [15, 21, 46, 58, 67, 77, 99], 'hybrid': [16, 48, 59], 'beamforming': [17, 49], 'to': [18, 32, 79], 'improve': [19], 'the\\nhardware': [20], 'spectral': [22], 'efficiencies': [23], 'of': [24, 92, 113, 124, 133], 'massive': [25], 'multiple-input-multiple-output\\n(MIMO)': [26], 'downlink': [27], 'systems.': [28], 'By': [29], 'employing': [30], 'ResNet': [31], 'extract': [33], 'features': [34], 'from': [35], 'the\\nchannel': [36], 'matrices,': [37], 'two': [38], 'neural': [39], 'networks,': [40], 'i.e.,': [41], 'the': [42, 47, 87, 90, 110, 122, 125, 135, 138], 'network\\n(ASNet)': [45], 'network': [50], '(BFNet),': [51], 'are': [52], 'respectively': [53, 73], 'proposed\\nfor': [54], 'dynamic': [55], 'beamformer': [60], 'design.': [61], 'Furthermore,': [62], 'deep\\nprobabilistic': [64], 'subsampling': [65], 'trick': [66], 'specially': [69], 'designed': [70, 95], 'quantization': [71], 'function\\nare': [72], 'developed': [74], 'for': [75], 'ASNet': [76, 98], 'BFNet': [78], 'preserve': [80], 'the\\ndifferentiability': [81], 'while': [82], 'embedding': [83], 'discrete': [84], 'constraints': [85], 'into': [86], 'network\\nstructures.': [88], 'With': [89], 'aid': [91], 'flexibly': [94], 'loss': [96], 'function,': [97], 'BFNet\\nare': [100], 'trained': [102], 'in': [103, 117, 131], 'phased': [105], 'way,': [107], 'which': [108], 'avoids': [109], 'prohibitive\\ncomputational': [111], 'cost': [112], 'acquiring': [114], 'training': [115], 'labels': [116], 'supervised': [118], 'learning.\\nSimulation': [119], 'results': [120], 'demonstrate': [121], 'advantage': [123], 'proposed': [126], 'approach': [127], 'over\\nconventional': [128], 'optimization-based': [129], 'algorithms': [130], 'terms': [132], 'both': [134], 'achieved': [136], 'rate\\nand': [137], 'computational': [139], 'complexity.\\n': [140]}",2022,"['Computer science', 'Beamforming', 'Unsupervised learning', 'Artificial neural network', 'Artificial intelligence', 'Antenna (radio)', 'Deep learning', 'MIMO', 'Computational complexity theory', 'Telecommunications link', 'Selection (genetic algorithm)', 'Machine learning', 'Algorithm', 'Telecommunications']","In this paper, we propose a novel deep unsupervised learning-based approach\nthat jointly optimizes antenna selection and hybrid beamforming to improve the\nhardware and spectral efficiencies of massive multiple-input-multiple-output\n(MIMO) downlink systems. By employing ResNet to extract features from the\nchannel matrices, two neural networks, i.e., the antenna selection network\n(ASNet) and the hybrid beamforming network (BFNet), are respectively proposed\nfor dynamic antenna selection and hybrid beamformer design. Furthermore, a deep\nprobabilistic subsampling trick and a specially designed quantization function\nare respectively developed for ASNet and BFNet to preserve the\ndifferentiability while embedding discrete constraints into the network\nstructures. With the aid of a flexibly designed loss function, ASNet and BFNet\nare jointly trained in a phased unsupervised way, which avoids the prohibitive\ncomputational cost of acquiring training labels in supervised learning.\nSimulation results demonstrate the advantage of the proposed approach over\nconventional optimization-based algorithms in terms of both the achieved rate\nand the computational complexity.\n"
https://openalex.org/W2155486857,Neural models of incremental supervised and unsupervised learning,"{'These': [0], 'Ecole': [1], 'polytechnique': [2], 'federale': [3], 'de': [4], 'Lausanne': [5], 'EPFL,': [6], 'n°': [7], '863': [8], '(1990)': [9], 'Reference': [10], 'doi:10.5075/epfl-thesis-863Print': [11], 'copy': [12], 'in': [13], 'library': [14], 'catalog': [15], 'Record': [16], 'created': [17], 'on': [18, 21], '2005-03-16,': [19], 'modified': [20], '2016-08-08': [22]}",1990,"['Artificial intelligence', 'Unsupervised learning', 'Computer science', 'Artificial neural network', 'Machine learning', 'Supervised learning']","These Ecole polytechnique federale de Lausanne EPFL, n° 863 (1990) Reference doi:10.5075/epfl-thesis-863Print copy in library catalog Record created on 2005-03-16, modified on 2016-08-08"
https://openalex.org/W2770257943,UnFlow: Unsupervised Learning of Optical Flow With a Bidirectional Census Loss,"{'In': [0, 20], 'the': [1, 21, 57, 89, 95, 102, 135, 147], 'era': [2], 'of': [3, 17, 159, 167], 'end-to-end': [4, 44], 'deep': [5, 111], 'learning,': [6], 'many': [7], 'advances': [8], 'in': [9, 154], 'computer': [10], 'vision': [11], 'are': [12], 'driven': [13], 'by': [14, 71, 113], 'large': [15, 115], 'amounts': [16, 166], 'labeled': [18], 'data.': [19], 'optical': [22, 48, 74, 143], 'flow': [23, 49, 75, 86, 144], 'setting,': [24], 'however,': [25], 'obtaining': [26], 'dense': [27], 'per-pixel': [28], 'ground': [29, 98, 168], 'truth': [30, 99], 'for': [31, 47, 54, 97, 162], 'real': [32], 'scenes': [33], 'is': [34, 40, 118], 'difficult': [35], 'and': [36, 62, 88, 117, 150], 'thus': [37, 153], 'such': [38], 'data': [39], 'rare.': [41], 'Therefore,': [42], 'recent': [43], 'convolutional': [45], 'networks': [46, 112, 161], 'rely': [50], 'on': [51, 83, 127, 134, 146], 'synthetic': [52, 128], 'datasets': [53, 129, 163], 'supervision,': [55], 'but': [56], 'domain': [58], 'mismatch': [59], 'between': [60], 'training': [61, 137], 'test': [63], 'scenarios': [64], 'continues': [65], 'to': [66, 93], 'be': [67], 'a': [68, 114], 'challenge.': [69], 'Inspired': [70], 'classical': [72], 'energy-based': [73], 'methods,': [76], 'we': [77], 'design': [78], 'an': [79], 'unsupervised': [80, 106, 110], 'loss': [81], 'based': [82], 'occlusion-aware': [84], 'bidirectional': [85], 'estimation': [87], 'robust': [90], 'census': [91], 'transform': [92], 'circumvent': [94], 'need': [96], 'flow.': [100], 'On': [101], 'KITTI': [103, 136, 148], 'benchmarks,': [104, 152], 'our': [105, 139], 'approach': [107], 'outperforms': [108], 'previous': [109], 'margin,': [116], 'even': [119], 'more': [120], 'accurate': [121], 'than': [122], 'similar': [123], 'supervised': [124, 160], 'methods': [125], 'trained': [126], 'alone.': [130], 'By': [131], 'optionally': [132], 'fine-tuning': [133], 'data,': [138], 'method': [140], 'achieves': [141], 'competitive': [142], 'accuracy': [145], '2012': [149], '2015': [151], 'addition': [155], 'enabling': [156], 'generic': [157], 'pre-training': [158], 'with': [164], 'limited': [165], 'truth.': [169]}",2018,"['Ground truth', 'Margin (machine learning)', 'Computer science', 'Artificial intelligence', 'Deep learning', 'Unsupervised learning', 'Optical flow', 'Machine learning', 'Pattern recognition (psychology)', 'Supervised learning', 'Synthetic data', 'Flow (mathematics)', 'Computer vision', 'Image (mathematics)', 'Artificial neural network', 'Mathematics', 'Geometry']","In the era of end-to-end deep learning, many advances in computer vision are driven by large amounts of labeled data. In the optical flow setting, however, obtaining dense per-pixel ground truth for real scenes is difficult and thus such data is rare. Therefore, recent end-to-end convolutional networks for optical flow rely on synthetic datasets for supervision, but the domain mismatch between training and test scenarios continues to be a challenge. Inspired by classical energy-based optical flow methods, we design an unsupervised loss based on occlusion-aware bidirectional flow estimation and the robust census transform to circumvent the need for ground truth flow. On the KITTI benchmarks, our unsupervised approach outperforms previous unsupervised deep networks by a large margin, and is even more accurate than similar supervised methods trained on synthetic datasets alone. By optionally fine-tuning on the KITTI training data, our method achieves competitive optical flow accuracy on the KITTI 2012 and 2015 benchmarks, thus in addition enabling generic pre-training of supervised networks for datasets with limited amounts of ground truth."
https://openalex.org/W3007774126,"Unsupervised Learning of Depth, Optical Flow and Pose With Occlusion From 3D Geometry","{'In': [0, 46, 141], 'autonomous': [1], 'driving,': [2], 'monocular': [3], 'sequences': [4], 'contain': [5], 'lots': [6], 'of': [7, 49, 105, 123, 162, 180], 'information.\\nMonocular': [8], 'depth': [9, 50, 106, 132, 136, 145], 'estimation,': [10], 'camera': [11, 147], 'ego-motion': [12], 'estimation': [13], 'and': [14, 42, 51, 69, 107, 146, 177], 'optical': [15, 70, 163], 'flow\\nestimation': [16], 'in': [17, 28, 64, 83, 102, 120, 138, 166], 'consecutive': [18], 'frames': [19], 'are': [20, 32], 'high-profile': [21], 'concerns': [22], 'recently.': [23], 'By\\nanalyzing': [24], 'tasks': [25, 198], 'above,': [26], 'pixels': [27, 95, 119], 'the': [29, 39, 43, 56, 73, 93, 103, 121, 142, 171, 181, 184], 'middle': [30], 'frame': [31], 'modeled': [33], 'into': [34], 'three': [35, 175, 197], 'parts:\\nthe': [36], 'rigid': [37, 185], 'region,': [38, 41, 183, 186], 'non-rigid': [40, 188], 'occluded': [44, 57, 84], 'region.': [45], 'joint\\nunsupervised': [47], 'training': [48, 104, 122], 'pose,': [52], 'we': [53], 'can': [54, 149, 155, 194], 'segment': [55], 'region\\nexplicitly.': [58], 'The': [59, 200], 'occlusion': [60, 182], 'information': [61], 'is': [62, 129, 203], 'used': [63, 113, 157], 'unsupervised': [65, 160, 192], 'learning': [66, 161], 'of\\ndepth,': [67], 'pose': [68, 108], 'flow,': [71], 'as': [72, 144], 'image': [74], 'reconstructed': [75], 'by': [76, 98], 'depth-pose': [77], 'and\\noptical': [78], 'flow': [79, 125], 'will': [80], 'be': [81, 156], 'invalid': [82], 'regions.': [85, 140], 'A': [86], 'less-than-mean': [87], 'mask': [88], 'is\\ndesigned': [89], 'to': [90, 114, 134, 158], 'further': [91], 'exclude': [92, 115], 'mismatched': [94, 118], 'interfered': [96], 'with': [97, 190], 'motion': [99, 148, 153], 'or\\nillumination': [100], 'change': [101], 'networks.': [109], 'This': [110], 'method': [111], 'is\\nalso': [112], 'some': [116], 'trivial': [117], 'the\\noptical': [124], 'network.': [126], 'Maximum': [127], 'normalization': [128], 'proposed': [130], 'for': [131], 'smoothness\\nterm': [133], 'restrain': [135], 'degradation': [137], 'textureless': [139], 'occluded\\nregion,': [143], 'provide': [150], 'more': [151], 'reliable': [152], 'estimation,\\nthey': [154], 'instruct': [159], 'flow.': [164], 'Our\\nexperiments': [165], 'KITTI': [167], 'dataset': [168], 'demonstrate': [169], 'that': [170], 'model': [172], 'based': [173], 'on': [174, 196], 'regions,\\nfull': [176], 'explicit': [178], 'segmentation': [179], 'and\\nthe': [187], 'region': [189], 'corresponding': [191], 'losses': [193], 'improve\\nperformance': [195], 'significantly.': [199], 'source': [201], 'code': [202], 'available': [204], 'at:\\nhttps://github.com/guangmingw/DOPlearning.\\n': [205]}",2020,"['Artificial intelligence', 'Geometry', 'Computer vision', 'Optical flow', 'Geometrical optics', 'Flow (mathematics)', 'Occlusion', 'Computer science', 'Geology', 'Mathematics', 'Optics', 'Physics', 'Image (mathematics)', 'Medicine', 'Cardiology']","In autonomous driving, monocular sequences contain lots of information.\nMonocular depth estimation, camera ego-motion estimation and optical flow\nestimation in consecutive frames are high-profile concerns recently. By\nanalyzing tasks above, pixels in the middle frame are modeled into three parts:\nthe rigid region, the non-rigid region, and the occluded region. In joint\nunsupervised training of depth and pose, we can segment the occluded region\nexplicitly. The occlusion information is used in unsupervised learning of\ndepth, pose and optical flow, as the image reconstructed by depth-pose and\noptical flow will be invalid in occluded regions. A less-than-mean mask is\ndesigned to further exclude the mismatched pixels interfered with by motion or\nillumination change in the training of depth and pose networks. This method is\nalso used to exclude some trivial mismatched pixels in the training of the\noptical flow network. Maximum normalization is proposed for depth smoothness\nterm to restrain depth degradation in textureless regions. In the occluded\nregion, as depth and camera motion can provide more reliable motion estimation,\nthey can be used to instruct unsupervised learning of optical flow. Our\nexperiments in KITTI dataset demonstrate that the model based on three regions,\nfull and explicit segmentation of the occlusion region, the rigid region, and\nthe non-rigid region with corresponding unsupervised losses can improve\nperformance on three tasks significantly. The source code is available at:\nhttps://github.com/guangmingw/DOPlearning.\n"
https://openalex.org/W2118479872,An unsupervised learning algorithm: application to the discrimination of seismic events and quarry blasts in the vicinity of Istanbul,"{'Abstract.': [0], 'The': [1, 35, 101, 139], 'results': [2, 102], 'of': [3, 6, 28, 61, 78, 85, 111, 158], 'the': [4, 26, 82, 112], 'application': [5], 'an': [7], 'unsupervised': [8], 'learning': [9], '(neural': [10], 'network)': [11], 'approach': [12, 167], 'comprising': [13], 'a': [14, 40, 119, 144], 'Self': [15], 'Organizing': [16], 'Map': [17], '(SOM),': [18], 'to': [19, 47, 130, 180], 'distinguish': [20, 48], 'micro-earthquakes': [21], 'from': [22, 81], 'quarry': [23], 'blasts': [24], 'in': [25, 152], 'vicinity': [27], 'Istanbul,': [29], 'Turkey,': [30], 'are': [31], 'presented': [32], 'and': [33, 43, 51, 63, 75, 106, 125, 133], 'discussed.': [34], 'SOM': [36, 140], 'is': [37], 'constructed': [38], 'as': [39, 90, 163], 'neural': [41], 'classifier': [42], 'complementary': [44], 'reliability': [45, 146], 'estimator': [46], 'seismic': [49], 'events,': [50], 'was': [52, 168], 'employed': [53, 150], 'for': [54, 92, 118, 136, 171], 'varying': [55], 'map': [56], 'sizes.': [57], 'Input': [58], 'parameters': [59, 110], 'consisting': [60], 'frequency': [62], 'time': [64, 77, 124], 'domain': [65], 'data': [66], '(complexity,': [67], 'spectral': [68, 126], 'ratio,': [69], 'S/P': [70], 'wave': [71], 'amplitude': [72, 107], 'peak': [73, 108], 'ratio': [74, 109, 127], 'origin': [76, 123], 'events)': [79], 'extracted': [80], 'vertical': [83], 'components': [84], 'digital': [86], 'seismograms': [87], 'were': [88, 128, 161], 'estimated': [89], 'discriminants': [91], '179': [93], '(1.8': [94], '&lt;': [95, 97], 'Md': [96], '3.0)': [98], 'local': [99], 'events.': [100], 'show': [103], 'that': [104, 147], 'complexity': [105], 'observed': [113], 'velocity': [114], 'seismogram': [115], 'may': [116], 'suffice': [117], 'reliable': [120], 'discrimination,': [121], 'while': [122], 'found': [129], 'be': [131, 149, 178], 'fuzzy': [132], 'misleading': [134], 'classifiers': [135], 'this': [137, 172], 'problem.': [138], 'discussed': [141], 'here': [142], 'achieved': [143], 'discrimination': [145], 'could': [148, 177], 'routinely': [151], 'observatory': [153], 'practice;': [154], 'however,': [155], 'about': [156], '6%': [157], 'all': [159], 'events': [160], 'classified': [162], 'ambiguous': [164], 'cases.': [165], 'This': [166], 'developed': [169], 'independently': [170], 'particular': [173], 'classification,': [174], 'but': [175], 'it': [176], 'applied': [179], 'different': [181], 'earthquake': [182], 'regions.': [183]}",2011,"['Seismogram', 'Amplitude', 'Artificial neural network', 'Seismology', 'Estimator', 'Pattern recognition (psychology)', 'Geology', 'Unsupervised learning', 'Reliability (semiconductor)', 'Cluster analysis', 'Algorithm', 'Classifier (UML)', 'Artificial intelligence', 'Computer science', 'Mathematics', 'Statistics', 'Physics', 'Power (physics)', 'Quantum mechanics']","Abstract. The results of the application of an unsupervised learning (neural network) approach comprising a Self Organizing Map (SOM), to distinguish micro-earthquakes from quarry blasts in the vicinity of Istanbul, Turkey, are presented and discussed. The SOM is constructed as a neural classifier and complementary reliability estimator to distinguish seismic events, and was employed for varying map sizes. Input parameters consisting of frequency and time domain data (complexity, spectral ratio, S/P wave amplitude peak ratio and origin time of events) extracted from the vertical components of digital seismograms were estimated as discriminants for 179 (1.8 &lt; Md &lt; 3.0) local events. The results show that complexity and amplitude peak ratio parameters of the observed velocity seismogram may suffice for a reliable discrimination, while origin time and spectral ratio were found to be fuzzy and misleading classifiers for this problem. The SOM discussed here achieved a discrimination reliability that could be employed routinely in observatory practice; however, about 6% of all events were classified as ambiguous cases. This approach was developed independently for this particular classification, but it could be applied to different earthquake regions."
https://openalex.org/W3080719725,Unsupervised Learning and Multipartite Network Models: A Promising Approach for Understanding Traditional Medicine,"{'The': [0], 'ultimate': [1], 'goal': [2], 'of': [3, 24, 38, 99, 117, 135, 145, 162, 175, 190, 211, 213], 'precision': [4], 'medicine': [5, 148], 'is': [6, 32, 96], 'to': [7, 59, 91, 112], 'determine': [8], 'right': [9, 12], 'treatment': [10], 'for': [11, 71, 164, 207], 'patients': [13, 25, 93], 'based': [14], 'on': [15, 43, 159], 'precise': [16], 'diagnosis.': [17], 'To': [18], 'achieve': [19], 'this': [20, 127, 153], 'goal,': [21], 'correct': [22], 'stratification': [23], 'using': [26, 171], 'molecular': [27, 53], 'features': [28], 'and': [29, 52, 77, 119, 138], 'clinical': [30], 'phenotypes': [31], 'crucial.': [33], 'During': [34], 'the': [35, 114, 123, 132, 143, 160, 181, 187, 191, 209], 'long': [36], 'history': [37], 'medical': [39], 'science,': [40], 'our': [41], 'understanding': [42, 208], 'disease': [44, 120], 'classification': [45, 163], 'has': [46], 'been': [47], 'improved': [48], 'greatly': [49], 'by': [50, 64], 'chemistry': [51], 'biology.': [54], 'Nowadays,': [55], 'we': [56, 129, 178], 'gain': [57], 'access': [58], 'large': [60], 'scale': [61], 'patient-derived': [62], 'data': [63, 72, 204], 'high-throughput': [65], 'technologies,': [66], 'generating': [67], 'a': [68, 88, 97, 168, 172, 202], 'greater': [69], 'need': [70], 'science': [73], 'including': [74], 'unsupervised': [75], 'learning': [76, 81], 'network': [78, 103, 139, 198], 'modeling.': [79], 'Unsupervised': [80], 'methods': [82, 107], 'such': [83], 'as': [84], 'clustering': [85, 106, 136], 'could': [86], 'be': [87, 109], 'better': [89], 'solution': [90], 'stratify': [92], 'when': [94], 'there': [95], 'lack': [98], 'predefined': [100], 'classifiers.': [101], 'In': [102, 126, 167], 'modularity': [104, 173], 'analysis,': [105], 'can': [108, 155], 'also': [110], 'applied': [111], 'elucidate': [113], 'complex': [115], 'structure': [116], 'biological': [118], 'networks': [121], 'at': [122], 'systems': [124], 'level.': [125], 'review,': [128], 'went': [130], 'over': [131], 'main': [133], 'points': [134], 'analysis': [137, 174], 'modeling,': [140], 'particularly': [141], 'in': [142], 'context': [144], 'Traditional': [146], 'Chinese': [147], '(TCM).': [149], 'We': [150, 194], 'showed': [151], 'that': [152, 180, 196], 'approach': [154], 'provide': [156], 'novel': [157], 'insights': [158], 'rationale': [161], 'TCM': [165, 182], 'herbs.': [166], 'case': [169], 'study,': [170], 'multipartite': [176, 197], 'networks,': [177], 'illustrated': [179], 'classifications': [183], 'are': [184], 'associated': [185], 'with': [186], 'chemical': [188], 'properties': [189], 'herb': [192], 'ingredients.': [193], 'concluded': [195], 'modeling': [199], 'may': [200], 'become': [201], 'suitable': [203], 'integration': [205], 'tool': [206], 'mechanisms': [210], 'actions': [212], 'traditional': [214], 'medicine.': [215]}",2020,"['Computer science', 'Cluster analysis', 'Artificial intelligence', 'Machine learning', 'Multipartite', 'Context (archaeology)', 'Unsupervised learning', 'Modularity (biology)', 'Biological network', 'Complex network', 'Data science', 'Bioinformatics', 'Biology', 'Quantum entanglement', 'Paleontology', 'Quantum', 'Quantum mechanics', 'World Wide Web', 'Genetics', 'Physics']","The ultimate goal of precision medicine is to determine right treatment for right patients based on precise diagnosis. To achieve this goal, correct stratification of patients using molecular features and clinical phenotypes is crucial. During the long history of medical science, our understanding on disease classification has been improved greatly by chemistry and molecular biology. Nowadays, we gain access to large scale patient-derived data by high-throughput technologies, generating a greater need for data science including unsupervised learning and network modeling. Unsupervised learning methods such as clustering could be a better solution to stratify patients when there is a lack of predefined classifiers. In network modularity analysis, clustering methods can be also applied to elucidate the complex structure of biological and disease networks at the systems level. In this review, we went over the main points of clustering analysis and network modeling, particularly in the context of Traditional Chinese medicine (TCM). We showed that this approach can provide novel insights on the rationale of classification for TCM herbs. In a case study, using a modularity analysis of multipartite networks, we illustrated that the TCM classifications are associated with the chemical properties of the herb ingredients. We concluded that multipartite network modeling may become a suitable data integration tool for understanding the mechanisms of actions of traditional medicine."
https://openalex.org/W2076363162,Joint Embedding Learning and Sparse Regression: A Framework for Unsupervised Feature Selection,"{'Feature': [0], 'selection': [1, 15, 32, 117, 158], 'has': [2], 'aroused': [3], 'considerable': [4], 'research': [5], 'interests': [6], 'during': [7], 'the': [8, 36, 46, 56, 71, 74, 83, 91, 102, 114, 120, 130, 164, 190], 'last': [9], 'few': [10], 'decades.': [11], 'Traditional': [12], 'learning-based': [13], 'feature': [14, 21, 31, 67, 116, 151, 157], 'methods': [16, 142], 'separate': [17], 'embedding': [18, 38, 47, 60, 167], 'learning': [19, 39, 48, 61, 168], 'and': [20, 40, 49, 89, 95, 125, 169, 185], 'ranking.': [22], 'In': [23, 128], 'this': [24], 'paper,': [25], 'we': [26, 77, 107], 'propose': [27], 'a': [28, 80, 136], 'novel': [29], 'unsupervised': [30, 156], 'framework,': [33, 76], 'termed': [34], 'as': [35], 'joint': [37], 'sparse': [41, 50, 63, 170], 'regression': [42, 51, 64], '(JELSR),': [43], 'in': [44], 'which': [45], 'are': [52], 'jointly': [53], 'performed.': [54], 'Specifically,': [55], 'proposed': [57, 75, 115, 131, 194], 'JELSR': [58], 'joins': [59], 'with': [62, 154], 'to': [65, 100, 139], 'perform': [66], 'selection.': [68, 152], 'To': [69], 'show': [70], 'effectiveness': [72, 191], 'of': [73, 166, 178, 192], 'also': [78, 108, 144], 'provide': [79], 'method': [81], 'using': [82], 'weight': [84], 'via': [85], 'local': [86], 'linear': [87], 'approximation': [88], 'adding': [90], 'l2,1': [92], '-norm': [93], 'regularization,': [94], 'design': [96], 'an': [97], 'effective': [98], 'algorithm': [99], 'solve': [101], 'corresponding': [103], 'optimization': [104], 'problem.': [105], 'Furthermore,': [106], 'conduct': [109], 'some': [110, 146], 'insightful': [111], 'discussion': [112], 'on': [113, 175], 'approach,': [118], 'including': [119, 181], 'convergence': [121], 'analysis,': [122], 'computational': [123], 'complexity,': [124], 'parameter': [126], 'determination.': [127], 'all,': [129], 'framework': [132], 'not': [133], 'only': [134], 'provides': [135], 'new': [137], 'perspective': [138], 'view': [140], 'traditional': [141, 155], 'but': [143], 'evokes': [145], 'other': [147], 'deep': [148], 'researches': [149], 'for': [150], 'Compared': [153], 'methods,': [159], 'our': [160, 193], 'approach': [161], 'could': [162], 'integrate': [163], 'merits': [165], 'regression.': [171], 'Promising': [172], 'experimental': [173], 'results': [174], 'different': [176], 'kinds': [177], 'data': [179, 184], 'sets,': [180], 'image,': [182], 'voice': [183], 'biological': [186], 'data,': [187], 'have': [188], 'validated': [189], 'algorithm.': [195]}",2013,"['Feature selection', 'Artificial intelligence', 'Computer science', 'Machine learning', 'Embedding', 'Lasso (programming language)', 'Feature (linguistics)', 'Feature learning', 'Regularization (linguistics)', 'Regression', 'Pattern recognition (psychology)', 'Selection (genetic algorithm)', 'Mathematics', 'Statistics', 'World Wide Web', 'Philosophy', 'Linguistics']","Feature selection has aroused considerable research interests during the last few decades. Traditional learning-based feature selection methods separate embedding learning and feature ranking. In this paper, we propose a novel unsupervised feature selection framework, termed as the joint embedding learning and sparse regression (JELSR), in which the embedding learning and sparse regression are jointly performed. Specifically, the proposed JELSR joins embedding learning with sparse regression to perform feature selection. To show the effectiveness of the proposed framework, we also provide a method using the weight via local linear approximation and adding the l2,1 -norm regularization, and design an effective algorithm to solve the corresponding optimization problem. Furthermore, we also conduct some insightful discussion on the proposed feature selection approach, including the convergence analysis, computational complexity, and parameter determination. In all, the proposed framework not only provides a new perspective to view traditional methods but also evokes some other deep researches for feature selection. Compared with traditional unsupervised feature selection methods, our approach could integrate the merits of embedding learning and sparse regression. Promising experimental results on different kinds of data sets, including image, voice data and biological data, have validated the effectiveness of our proposed algorithm."
https://openalex.org/W1991414581,Unsupervised Learning by Examples: On-line versus Off-line,"{'We': [0], 'study': [1], 'both': [2], 'on-line': [3], 'and': [4, 75, 87, 91], 'off-line': [5, 107], 'unsupervised': [6], 'learning': [7, 37], 'from': [8, 38], 'p': [9], 'random': [10], 'patterns': [11, 43], 'which': [12, 30], 'are': [13], 'uniformly': [14], 'distributed': [15], 'on': [16, 84], 'the': [17, 20, 39, 51, 64, 71, 76, 85, 92, 106], 'N-sphere': [18], 'with': [19, 57, 81], 'exception': [21], 'of': [22, 42, 94], 'a': [23, 47, 100], 'single': [24], 'symmetry': [25], 'breaking': [26], 'orientation': [27], 'B,': [28], 'along': [29], 'they': [31], 'may': [32], 'be': [33], 'arbitrarily': [34], 'distributed.': [35], 'Supervised': [36], 'same': [40], 'kind': [41], 'is': [44], 'included': [45], 'as': [46], 'special': [48], 'case.': [49], 'In': [50], 'thermodynamic': [52], 'limit': [53], 'N': [54], '--&gt;': [55], 'infinity': [56], 'alpha': [58], '=': [59], 'p/N': [60], 'fixed': [61], 'we': [62, 98], 'calculate': [63], 'overlap': [65], 'R(alpha)=': [66], 'B': [67, 74], '.': [68], 'J/\\\\J\\\\\\\\B\\\\': [69], 'between': [70], 'unknown': [72], ""''true''"": [73], 'optimal': [77], ""''Bayes''"": [78], 'hypothesis': [79], 'J': [80], 'particular': [82], 'emphasis': [83], 'small': [86], 'large': [88], 'cu': [89], 'asymptotics': [90], 'phenomenon': [93], 'retarded': [95], 'learning.': [96], 'Finally,': [97], 'identify': [99], 'cost': [101], 'function': [102], 'whose': [103], 'minimum': [104], 'reproduces': [105], 'Bayes': [108], 'overlap.': [109]}",1996,"['Physics', 'Line (geometry)', 'Combinatorics', 'Mathematics', 'Geometry']","We study both on-line and off-line unsupervised learning from p random patterns which are uniformly distributed on the N-sphere with the exception of a single symmetry breaking orientation B, along which they may be arbitrarily distributed. Supervised learning from the same kind of patterns is included as a special case. In the thermodynamic limit N --&gt; infinity with alpha = p/N fixed we calculate the overlap R(alpha)= B . J/\\J\\\\B\\ between the unknown ''true'' B and the optimal ''Bayes'' hypothesis J with particular emphasis on the small and large cu asymptotics and the phenomenon of retarded learning. Finally, we identify a cost function whose minimum reproduces the off-line Bayes overlap."
https://openalex.org/W2884607399,Deep Encoder-Decoder Models for Unsupervised Learning of Controllable Speech Synthesis,"{'Generating': [0], 'versatile': [1], 'and': [2], 'appropriate': [3], 'synthetic': [4], 'speech': [5, 19, 53, 125], 'requires': [6], 'control': [7, 28, 50, 134], 'over': [8], 'the': [9, 14, 111, 114, 128, 152], 'output': [10, 27], 'expression': [11, 133], 'separate': [12], 'from': [13, 94], 'spoken': [15], 'text.': [16], 'Important': [17], 'non-textual': [18], 'variation': [20], 'is': [21], 'seldom': [22], 'annotated,': [23], 'in': [24, 32, 51, 70, 146], 'which': [25, 88], 'case': [26], 'must': [29], 'be': [30, 65, 92], 'learned': [31], 'an': [33, 41, 118], 'unsupervised': [34, 47, 61, 129], 'fashion.': [35], 'In': [36], 'this': [37], 'paper,': [38], 'we': [39, 57, 89], 'perform': [40], 'in-depth': [42], 'study': [43], 'of': [44, 49, 84, 102, 113], 'methods': [45, 130], 'for': [46, 123, 131], 'learning': [48, 132], 'statistical': [52], 'synthesis.': [54], 'For': [55], 'example,': [56], 'show': [58, 90], 'that': [59, 145], 'popular': [60], 'training': [62], 'heuristics': [63], 'can': [64, 91], 'interpreted': [66], 'as': [67], 'variational': [68, 86], 'inference': [69], 'certain': [71], 'autoencoder': [72], 'models.': [73], 'We': [74, 109], 'additionally': [75], 'connect': [76], 'these': [77, 103], 'models': [78], 'to': [79, 120, 137, 142], 'VQ-VAEs,': [80], 'another,': [81], 'recently-proposed': [82], 'class': [83], 'deep': [85], 'autoencoders,': [87], 'derived': [93], 'a': [95], 'very': [96], 'similar': [97], 'mathematical': [98], 'argument.': [99], 'The': [100], 'implications': [101], 'new': [104], 'probabilistic': [105], 'interpretations': [106], 'are': [107, 140], 'discussed.': [108], 'illustrate': [110], 'utility': [112], 'various': [115], 'approaches': [116], 'with': [117], 'application': [119], 'acoustic': [121], 'modelling': [122], 'emotional': [124, 138], 'synthesis,': [126], 'where': [127], '(without': [135], 'access': [136], 'labels)': [139], 'found': [141], 'give': [143], 'results': [144], 'many': [147], 'aspects': [148], 'match': [149], 'or': [150], 'surpass': [151], 'previous': [153], 'best': [154], 'supervised': [155], 'approach.': [156]}",2018,"['Autoencoder', 'Computer science', 'Unsupervised learning', 'Artificial intelligence', 'Heuristics', 'Encoder', 'Inference', 'Grammar induction', 'Deep learning', 'Class (philosophy)', 'Artificial neural network', 'Probabilistic logic', 'Speech recognition', 'Speech synthesis', 'Machine learning', 'Pattern recognition (psychology)', 'Rule-based machine translation', 'Operating system']","Generating versatile and appropriate synthetic speech requires control over the output expression separate from the spoken text. Important non-textual speech variation is seldom annotated, in which case output control must be learned in an unsupervised fashion. In this paper, we perform an in-depth study of methods for unsupervised learning of control in statistical speech synthesis. For example, we show that popular unsupervised training heuristics can be interpreted as variational inference in certain autoencoder models. We additionally connect these models to VQ-VAEs, another, recently-proposed class of deep variational autoencoders, which we show can be derived from a very similar mathematical argument. The implications of these new probabilistic interpretations are discussed. We illustrate the utility of the various approaches with an application to acoustic modelling for emotional speech synthesis, where the unsupervised methods for learning expression control (without access to emotional labels) are found to give results that in many aspects match or surpass the previous best supervised approach."
https://openalex.org/W2775678896,Unsupervised Learning for Color Constancy,"{'Most': [0], 'digital': [1], 'camera': [2, 15], 'pipelines': [3], 'use': [4], 'color': [5, 27, 33, 69, 166, 173], 'constancy': [6, 34, 70, 174], 'methods': [7, 73], 'to': [8, 153], 'reduce': [9], 'the': [10, 18, 101, 106, 116, 129, 136, 200], 'influence': [11], 'of': [12, 20, 26, 42, 105, 114, 128], 'illumination': [13, 104], 'and': [14, 61, 122, 146, 186, 194, 199], 'sensor': [16, 59, 145], 'on': [17], 'colors': [19], 'scene': [21], 'objects.': [22], 'The': [23, 190, 196], 'highest': [24], 'accuracy': [25, 115], 'correction': [28], 'is': [29, 52, 92, 131, 181], 'obtained': [30], 'with': [31, 46, 143, 156, 177], 'learning-based': [32, 90, 124], 'methods,': [35], 'but': [36, 80], 'they': [37, 81], 'require': [38, 76], 'a': [39, 63, 169], 'significant': [40], 'amount': [41], 'calibrated': [43, 77, 179], 'training': [44, 78, 107], 'images': [45, 141, 154, 180], 'known': [47], 'ground-truth': [48, 103], 'illumination.': [49], 'Such': [50], 'calibration': [51], 'time': [53], 'consuming,': [54], 'preferably': [55], 'done': [56], 'for': [57, 165, 184], 'each': [58], 'individually,': [60], 'therefore': [62], 'major': [64], 'bottleneck': [65], 'in': [66], 'acquiring': [67], 'high': [68, 171], 'accuracy.': [71], 'Statistics-based': [72], 'do': [74], 'not': [75], 'images,': [79, 108], 'are': [82, 192, 202], 'less': [83], 'accurate.': [84], 'In': [85, 112], 'this': [86], 'paper': [87], 'an': [88], 'unsupervised': [89, 163], 'method': [91, 118, 130], 'proposed': [93, 117], 'that': [94], 'learns': [95, 135], 'its': [96], 'parameter': [97], 'values': [98], 'after': [99], 'approximating': [100], 'unknown': [102], 'thus': [109], 'avoiding': [110], 'calibration.': [111], 'terms': [113], 'outperforms': [119], 'all': [120], 'statistics-based': [121], 'many': [123], 'methods.': [125], 'An': [126], 'extension': [127], 'also': [132], 'proposed,': [133], 'which': [134, 147], 'needed': [137], 'parameters': [138], 'from': [139], 'non-calibrated': [140], 'taken': [142, 155], 'one': [144], 'can': [148], 'then': [149], 'be': [150], 'successfully': [151], 'applied': [152], 'another': [157], 'sensor.': [158], 'This': [159], 'effectively': [160], 'enables': [161], 'inter-camera': [162], 'learning': [164], 'constancy.': [167], 'Additionally,': [168], 'new': [170], 'quality': [172], 'benchmark': [175], 'dataset': [176, 201], '1707': [178], 'created,': [182], 'used': [183], 'testing,': [185], 'made': [187], 'publicly': [188], 'available.': [189], 'results': [191], 'presented': [193], 'discussed.': [195], 'source': [197], 'code': [198], 'available': [203], 'at': [204], 'http://www.fer.unizg.hr/ipg/resources/color_constancy/.': [205]}",2018,"['Color constancy', 'Artificial intelligence', 'Computer science', 'Benchmark (surveying)', 'Computer vision', 'Ground truth', 'Calibration', 'Color balance', 'Pattern recognition (psychology)', 'Image (mathematics)', 'Color image', 'Mathematics', 'Image processing', 'Statistics', 'Geodesy', 'Geography']","Most digital camera pipelines use color constancy methods to reduce the influence of illumination and camera sensor on the colors of scene objects. The highest accuracy of color correction is obtained with learning-based color constancy methods, but they require a significant amount of calibrated training images with known ground-truth illumination. Such calibration is time consuming, preferably done for each sensor individually, and therefore a major bottleneck in acquiring high color constancy accuracy. Statistics-based methods do not require calibrated training images, but they are less accurate. In this paper an unsupervised learning-based method is proposed that learns its parameter values after approximating the unknown ground-truth illumination of the training images, thus avoiding calibration. In terms of accuracy the proposed method outperforms all statistics-based and many learning-based methods. An extension of the method is also proposed, which learns the needed parameters from non-calibrated images taken with one sensor and which can then be successfully applied to images taken with another sensor. This effectively enables inter-camera unsupervised learning for color constancy. Additionally, a new high quality color constancy benchmark dataset with 1707 calibrated images is created, used for testing, and made publicly available. The results are presented and discussed. The source code and the dataset are available at http://www.fer.unizg.hr/ipg/resources/color_constancy/."
https://openalex.org/W2141766442,Cluster Analysis: Unsupervised Learning via Supervised Learning with a Non-convex Penalty.,"{'Clustering': [0], 'analysis': [1], 'is': [2, 10, 30, 78], 'widely': [3], 'used': [4], 'in': [5, 28, 32, 67, 86, 104], 'many': [6], 'fields.': [7], 'Traditionally': [8], 'clustering': [9, 43, 70, 105], 'regarded': [11], 'as': [12, 36, 44, 91], 'unsupervised': [13], 'learning': [14, 34], 'for': [15], 'its': [16, 62, 79], 'lack': [17], 'of': [18, 56, 75, 99, 120, 127], 'a': [19, 23, 57, 72, 101, 131], 'class': [20], 'label': [21], 'or': [22], 'quantitative': [24], 'response': [25], 'variable,': [26], 'which': [27], 'contrast': [29], 'present': [31], 'supervised': [33], 'such': [35, 90], 'classification': [37, 87], 'and': [38, 61, 88], 'regression.': [39], 'Here': [40], 'we': [41, 109], 'formulate': [42], 'penalized': [45], 'regression': [46], 'with': [47, 141], 'grouping': [48], 'pursuit.': [49], 'In': [50, 107], 'addition': [51], 'to': [52, 95, 123, 136], 'the': [53, 68, 97, 112, 125], 'novel': [54], 'use': [55, 130], 'non-convex': [58], 'group': [59], 'penalty': [60], 'associated': [63], 'unique': [64], 'operating': [65], 'characteristics': [66], 'proposed': [69, 139], 'method,': [71], 'main': [73], 'advantage': [74], 'this': [76], 'formulation': [77], 'allowing': [80], 'borrowing': [81], 'some': [82, 142], 'well': [83], 'established': [84], 'results': [85], 'regression,': [89], 'model': [92], 'selection': [93], 'criteria': [94], 'select': [96, 124], 'number': [98, 126], 'clusters,': [100], 'difficult': [102], 'problem': [103], 'analysis.': [106], 'particular,': [108], 'propose': [110], 'using': [111], 'generalized': [113, 118], 'cross-validation': [114], '(GCV)': [115], 'based': [116], 'on': [117], 'degrees': [119], 'freedom': [121], '(GDF)': [122], 'clusters.': [128], 'We': [129], 'few': [132], 'simple': [133], 'numerical': [134], 'examples': [135], 'compare': [137], 'our': [138, 146], 'method': [140], 'existing': [143], 'approaches,': [144], 'demonstrating': [145], ""method's"": [147], 'promising': [148], 'performance.': [149]}",2013,"['Cluster analysis', 'Artificial intelligence', 'Unsupervised learning', 'Machine learning', 'Computer science', 'Supervised learning', 'Regression', 'Contrast (vision)', 'Pattern recognition (psychology)', 'Regression analysis', 'Mathematics', 'Artificial neural network', 'Statistics']","Clustering analysis is widely used in many fields. Traditionally clustering is regarded as unsupervised learning for its lack of a class label or a quantitative response variable, which in contrast is present in supervised learning such as classification and regression. Here we formulate clustering as penalized regression with grouping pursuit. In addition to the novel use of a non-convex group penalty and its associated unique operating characteristics in the proposed clustering method, a main advantage of this formulation is its allowing borrowing some well established results in classification and regression, such as model selection criteria to select the number of clusters, a difficult problem in clustering analysis. In particular, we propose using the generalized cross-validation (GCV) based on generalized degrees of freedom (GDF) to select the number of clusters. We use a few simple numerical examples to compare our proposed method with some existing approaches, demonstrating our method's promising performance."
https://openalex.org/W2994631335,Deep Unsupervised Learning of 3D Point Clouds via Graph Topology Inference and Filtering,"{'We': [0, 218, 227], 'propose': [1], 'a': [2, 72, 92, 126, 135, 146, 187, 200, 248, 297, 326, 336], 'deep': [3], 'autoencoder': [4, 69], 'with': [5, 71], 'graph': [6, 147, 189, 202, 242, 298, 310, 314], 'topology': [7, 148, 190, 203, 299, 311], 'inference': [8], 'and': [9, 32, 39, 118, 164, 173, 212, 236, 272, 293, 323], 'filtering': [10, 315], 'to': [11, 30, 37, 47, 56, 130, 149, 160, 191, 204, 208, 250, 320], 'achieve': [12], 'compact': [13], 'representations': [14], 'of': [15, 80, 98, 104, 134, 167, 223, 241], 'unorganized': [16], '3D': [17, 28, 41, 59, 99, 136, 154, 170, 252, 267], 'point': [18, 100, 137, 171, 253, 268], 'clouds': [19], 'in': [20, 88, 169, 263, 288], 'an': [21, 229], 'unsupervised': [22], 'manner.': [23], 'Many': [24], 'previous': [25], 'works': [26], 'discretize': [27], 'points': [29, 60, 168], 'voxels': [31], 'then': [33], 'use': [34], 'lattice-based': [35], 'methods': [36, 287], 'process': [38], 'learn': [40], 'spatial': [42, 245], 'information;': [43], 'however,': [44], 'this': [45, 52], 'leads': [46], 'inevitable': [48], 'discretization': [49], 'errors.': [50], 'In': [51, 255], 'work,': [53], 'we': [54, 258], 'try': [55], 'handle': [57], 'raw': [58], 'without': [61, 306], 'such': [62], 'compromise.': [63], 'The': [64, 78, 102, 122, 196, 275], 'proposed': [65, 82, 106, 197, 225, 261, 282], 'networks': [66, 83, 107, 262, 283], 'follow': [67], 'the': [68, 76, 81, 105, 112, 115, 119, 131, 142, 157, 174, 178, 183, 193, 206, 215, 224, 233, 239, 256, 260, 281, 285, 317, 331], 'framework': [70], 'focus': [73], 'on': [74, 309], 'designing': [75, 325], 'decoder.': [77], 'encoder': [79], 'adopts': [84], 'similar': [85], 'architectures': [86], 'as': [87, 247, 303], 'PointNet,': [89], 'which': [90], 'is': [91], 'well-acknowledged': [93], 'method': [94], 'for': [95, 232], 'supervised': [96], 'learning': [97], 'clouds.': [101, 254], 'decoder': [103, 198, 328], 'involves': [108], 'three': [109, 264], 'novel': [110], 'modules:': [111], 'folding': [113, 123], 'module,': [114, 117], 'graph-topology-inference': [116, 143], 'graph-filtering': [120, 175], 'module.': [121], 'module': [124, 144, 176], 'folds': [125], 'canonical': [127], '2D': [128], 'lattice': [129], 'underlying': [132], 'surface': [133], 'cloud,': [138], 'achieving': [139], 'coarse': [140, 184], 'reconstruction;': [141], 'learns': [145], 'represent': [150], 'pairwise': [151, 165], 'relationships': [152, 166], 'between': [153], 'points,': [155], 'pushing': [156], 'latent': [158], 'code': [159], 'preserve': [161, 209], 'both': [162], 'coordinates': [163], 'clouds;': [172], 'couples': [177], 'above': [179], 'two': [180], 'modules,': [181], 'refining': [182], 'reconstruction': [185, 234, 292], 'through': [186], 'learnt': [188], 'obtain': [192], 'final': [194], 'reconstruction.': [195], 'leverages': [199], 'learnable': [201], 'push': [205], 'codeword': [207], 'representative': [210], 'features': [211], 'further': [213, 219, 237], 'improve': [214, 330], 'unsupervised-learning': [216, 332], 'performance.': [217], 'provide': [220, 228], 'theoretical': [221], 'analyses': [222], 'architecture.': [226], 'upper': [230], 'bound': [231], 'loss': [235], 'show': [238, 278], 'superiority': [240], 'smoothness': [243, 246], 'over': [244], 'prior': [249], 'model': [251], 'experiments,': [257], 'validate': [259], 'tasks,': [265, 290], 'including': [266, 291], 'cloud': [269], 'reconstruction,': [270, 318], 'visualization,': [271], 'transfer': [273, 294], 'classification.': [274], 'experimental': [276], 'results': [277], 'that': [279], '(1)': [280], 'outperform': [284], 'state-of-the-art': [286], 'various': [289], 'classification;': [295], '(2)': [296], 'can': [300], 'be': [301], 'inferred': [302], 'auxiliary': [304], 'information': [305], 'specific': [307], 'supervision': [308], 'inference;': [312], '(3)': [313], 'refines': [316], 'leading': [319], 'better': [321], 'performances;': [322], '(4)': [324], 'powerful': [327, 337], 'could': [329], 'performance,': [333], 'just': [334], 'like': [335], 'encoder.': [338]}",2019,[],"We propose a deep autoencoder with graph topology inference and filtering to achieve compact representations of unorganized 3D point clouds in an unsupervised manner. Many previous works discretize 3D points to voxels and then use lattice-based methods to process and learn 3D spatial information; however, this leads to inevitable discretization errors. In this work, we try to handle raw 3D points without such compromise. The proposed networks follow the autoencoder framework with a focus on designing the decoder. The encoder of the proposed networks adopts similar architectures as in PointNet, which is a well-acknowledged method for supervised learning of 3D point clouds. The decoder of the proposed networks involves three novel modules: the folding module, the graph-topology-inference module, and the graph-filtering module. The folding module folds a canonical 2D lattice to the underlying surface of a 3D point cloud, achieving coarse reconstruction; the graph-topology-inference module learns a graph topology to represent pairwise relationships between 3D points, pushing the latent code to preserve both coordinates and pairwise relationships of points in 3D point clouds; and the graph-filtering module couples the above two modules, refining the coarse reconstruction through a learnt graph topology to obtain the final reconstruction. The proposed decoder leverages a learnable graph topology to push the codeword to preserve representative features and further improve the unsupervised-learning performance. We further provide theoretical analyses of the proposed architecture. We provide an upper bound for the reconstruction loss and further show the superiority of graph smoothness over spatial smoothness as a prior to model 3D point clouds. In the experiments, we validate the proposed networks in three tasks, including 3D point cloud reconstruction, visualization, and transfer classification. The experimental results show that (1) the proposed networks outperform the state-of-the-art methods in various tasks, including reconstruction and transfer classification; (2) a graph topology can be inferred as auxiliary information without specific supervision on graph topology inference; (3) graph filtering refines the reconstruction, leading to better performances; and (4) designing a powerful decoder could improve the unsupervised-learning performance, just like a powerful encoder."
https://openalex.org/W2889636191,Auto-Dialabel: Labeling Dialogue Data with Unsupervised Learning,"{'The': [0], 'lack': [1], 'of': [2, 7, 59], 'labeled': [3], 'data': [4], 'is': [5, 26], 'one': [6], 'the': [8, 47], 'main': [9], 'challenges': [10], 'when': [11], 'building': [12], 'a': [13, 57, 70, 92], 'task-oriented': [14], 'dialogue': [15, 18, 48], 'system.': [16], 'Existing': [17], 'datasets': [19], 'usually': [20], 'rely': [21], 'on': [22], 'human': [23, 88], 'labeling,': [24], 'which': [25], 'expensive,': [27], 'limited': [28], 'in': [29, 32], 'size,': [30], 'and': [31, 50, 68, 77, 101, 104], 'low': [33], 'coverage.': [34], 'In': [35, 52], 'this': [36, 53], 'paper,': [37], 'we': [38, 55], 'instead': [39], 'propose': [40], 'our': [41, 84], 'framework': [42, 85], 'auto-dialabel': [43], 'to': [44, 91], 'automatically': [45], 'cluster': [46], 'intents': [49], 'slots.': [51], 'framework,': [54], 'collect': [56], 'set': [58], 'context': [60], 'features,': [61], 'leverage': [62], 'an': [63], 'autoencoder': [64], 'for': [65, 75], 'feature': [66], 'assembly,': [67], 'adapt': [69], 'dynamic': [71], 'hierarchical': [72], 'clustering': [73, 98], 'method': [74], 'intent': [76, 97], 'slot': [78, 106], 'labeling.': [79], 'Experimental': [80], 'results': [81], 'show': [82], 'that': [83], 'can': [86], 'promote': [87], 'labeling': [89, 107], 'cost': [90], 'great': [93], 'extent,': [94], 'achieve': [95], 'good': [96], 'accuracy': [99], '(84.1%),': [100], 'provide': [102], 'reasonable': [103], 'instructive': [105], 'results.': [108]}",2018,"['Leverage (statistics)', 'Computer science', 'Autoencoder', 'Cluster analysis', 'Labeled data', 'Artificial intelligence', 'Context (archaeology)', 'Machine learning', 'Unsupervised learning', 'Set (abstract data type)', 'Task (project management)', 'Feature (linguistics)', 'Data mining', 'Deep learning', 'Engineering', 'Paleontology', 'Programming language', 'Linguistics', 'Biology', 'Systems engineering', 'Philosophy']","The lack of labeled data is one of the main challenges when building a task-oriented dialogue system. Existing dialogue datasets usually rely on human labeling, which is expensive, limited in size, and in low coverage. In this paper, we instead propose our framework auto-dialabel to automatically cluster the dialogue intents and slots. In this framework, we collect a set of context features, leverage an autoencoder for feature assembly, and adapt a dynamic hierarchical clustering method for intent and slot labeling. Experimental results show that our framework can promote human labeling cost to a great extent, achieve good intent clustering accuracy (84.1%), and provide reasonable and instructive slot labeling results."
https://openalex.org/W3000332922,Unsupervised Learning of Persistent and Sequential Activity,"{'Two': [0], 'strikingly': [1], 'distinct': [2], 'types': [3, 59, 97, 122], 'of': [4, 16, 27, 46, 60, 72, 78, 98, 123, 130, 144, 149, 160, 180, 193, 209, 256, 264], 'activity': [5, 21, 41, 124], 'have': [6], 'been': [7, 55], 'observed': [8], 'in': [9, 23, 43, 51, 100, 301], 'various': [10], 'brain': [11], 'structures': [12], 'during': [13, 230, 236], 'delay': [14, 37], 'periods': [15], 'delayed': [17], 'response': [18], 'tasks:': [19], 'Persistent': [20], '(PA),': [22], 'which': [24, 44], 'a': [25, 86, 101, 113, 145, 158, 206, 262, 288], 'sub-population': [26], 'neurons': [28, 47], 'maintains': [29], 'an': [30, 35, 154, 170, 197, 302], 'elevated': [31], 'firing': [32, 146], 'rate': [33, 147], 'throughout': [34], 'entire': [36], 'period;': [38], 'and': [39, 90, 195, 232, 252, 295, 299], 'Sequential': [40], '(SA),': [42], 'sub-populations': [45], 'are': [48, 104], 'activated': [49], 'sequentially': [50], 'time.': [52], 'It': [53], 'has': [54], 'hypothesized': [56], 'that': [57, 189, 205], 'both': [58, 121], 'dynamics': [61, 99, 179], 'can': [62, 293], 'be': [63], '""learned""': [64], 'by': [65, 225], 'the': [66, 70, 82, 128, 131, 134, 140, 161, 178, 181, 210, 239, 249, 253, 257, 267], 'relevant': [67], 'networks': [68], 'from': [69], 'statistics': [71, 92, 129], 'their': [73], 'inputs,': [74], 'thanks': [75], 'to': [76, 93, 119, 274, 281], 'mechanisms': [77], 'synaptic': [79, 87], 'plasticity.': [80], 'However,': [81], 'necessary': [83], 'conditions': [84], 'for': [85, 190, 243], 'plasticity': [88, 175, 214], 'rule': [89, 116, 176], 'input': [91], 'learn': [94, 120, 297], 'these': [95], 'two': [96], 'stable': [102, 191], 'fashion': [103], 'still': [105], 'unclear.': [106], 'In': [107], 'particular,': [108], 'it': [109], 'is': [110, 117, 201], 'unclear': [111], 'whether': [112], 'single': [114], 'learning': [115, 192, 224], 'able': [118], 'patterns,': [125], 'depending': [126], 'on': [127], 'inputs': [132], 'driving': [133], 'network.': [135, 182], 'Here,': [136], 'we': [137, 187, 246], 'first': [138], 'characterize': [139], 'complete': [141], 'bifurcation': [142, 240], 'diagram': [143, 241], 'model': [148, 285], 'multiple': [150], 'excitatory': [151, 228], 'populations': [152], 'with': [153, 184, 290], 'inhibitory': [155], 'mechanism,': [156], 'as': [157, 261], 'function': [159, 263], 'parameters': [162, 265], 'characterizing': [163, 266], 'its': [164], 'connectivity.': [165], 'We': [166, 203], 'then': [167], 'investigate': [168], 'how': [169, 287], 'unsupervised': [171, 303], 'temporally': [172], 'asymmetric': [173], 'Hebbian': [174], 'shapes': [177], 'Consistent': [183], 'previous': [185], 'studies,': [186], 'find': [188], 'PA': [194, 298], 'SA,': [196], 'additional': [198], 'stabilization': [199], 'mechanism': [200], 'necessary.': [202], 'show': [204], 'generalized': [207], 'version': [208], 'standard': [211], 'multiplicative': [212], 'homeostatic': [213], '(Renart': [215], 'et': [216, 220], 'al.,': [217, 221], '2003;': [218], 'Toyoizumi': [219], '2014)': [222], 'stabilizes': [223], 'effectively': [226], '<i>masking</i>': [227], 'connections': [229, 235], 'stimulation': [231], '<i>unmasking</i>': [233], 'those': [234], 'retrieval.': [237], 'Using': [238], 'derived': [242], 'fixed': [244], 'connectivity,': [245], 'study': [247], 'analytically': [248], 'temporal': [250], 'evolution': [251], 'steady': [254], 'state': [255], 'learned': [258], 'recurrent': [259], 'architecture': [260], 'external': [268], 'inputs.': [269], 'Slow': [270], 'changing': [271, 278], 'stimuli': [272, 279], 'lead': [273, 280], 'PA,': [275], 'while': [276], 'fast': [277], 'SA.': [282], 'Our': [283], 'network': [284, 289], 'shows': [286], 'plastic': [291], 'synapses': [292], 'stably': [294], 'flexibly': [296], 'SA': [300], 'manner.': [304]}",2020,"['Hebbian theory', 'Homeostatic plasticity', 'Learning rule', 'Computer science', 'Neuroscience', 'Synaptic plasticity', 'Population', 'Excitatory postsynaptic potential', 'Mechanism (biology)', 'Bifurcation diagram', 'Spike-timing-dependent plasticity', 'Artificial intelligence', 'Inhibitory postsynaptic potential', 'Bifurcation', 'Metaplasticity', 'Artificial neural network', 'Physics', 'Psychology', 'Biology', 'Quantum mechanics', 'Receptor', 'Biochemistry', 'Demography', 'Sociology', 'Nonlinear system']","Two strikingly distinct types of activity have been observed in various brain structures during delay periods of delayed response tasks: Persistent activity (PA), in which a sub-population of neurons maintains an elevated firing rate throughout an entire delay period; and Sequential activity (SA), in which sub-populations of neurons are activated sequentially in time. It has been hypothesized that both types of dynamics can be ""learned"" by the relevant networks from the statistics of their inputs, thanks to mechanisms of synaptic plasticity. However, the necessary conditions for a synaptic plasticity rule and input statistics to learn these two types of dynamics in a stable fashion are still unclear. In particular, it is unclear whether a single learning rule is able to learn both types of activity patterns, depending on the statistics of the inputs driving the network. Here, we first characterize the complete bifurcation diagram of a firing rate model of multiple excitatory populations with an inhibitory mechanism, as a function of the parameters characterizing its connectivity. We then investigate how an unsupervised temporally asymmetric Hebbian plasticity rule shapes the dynamics of the network. Consistent with previous studies, we find that for stable learning of PA and SA, an additional stabilization mechanism is necessary. We show that a generalized version of the standard multiplicative homeostatic plasticity (Renart et al., 2003; Toyoizumi et al., 2014) stabilizes learning by effectively <i>masking</i> excitatory connections during stimulation and <i>unmasking</i> those connections during retrieval. Using the bifurcation diagram derived for fixed connectivity, we study analytically the temporal evolution and the steady state of the learned recurrent architecture as a function of parameters characterizing the external inputs. Slow changing stimuli lead to PA, while fast changing stimuli lead to SA. Our network model shows how a network with plastic synapses can stably and flexibly learn PA and SA in an unsupervised manner."
https://openalex.org/W2147354085,Unsupervised learning of morphology for English and Inuktitut,"{'We': [0, 36], 'describe': [1], 'a': [2, 18, 21, 24, 38, 43], 'simple': [3], 'unsupervised': [4], 'technique': [5], 'for': [6], 'learning': [7], 'morphology': [8], 'by': [9], 'identifying': [10], 'hubs': [11, 50], 'in': [12, 23], 'an': [13], 'automaton.': [14], 'For': [15], 'our': [16], 'purposes,': [17], 'hub': [19], 'is': [20], 'node': [22], 'graph': [25], 'with': [26], 'in-degree': [27], 'greater': [28, 33], 'than': [29, 34], 'one': [30], 'and': [31, 56], 'out-degree': [32], 'one.': [35], 'create': [37], 'word-trie,': [39], 'transform': [40], 'it': [41], 'into': [42], 'minimal': [44], 'DFA,': [45], 'then': [46], 'identify': [47], 'hubs.': [48], 'Those': [49], 'mark': [51], 'the': [52], 'boundary': [53], 'between': [54], 'root': [55], 'suffix,': [57], 'achieving': [58], 'similar': [59], 'performance': [60], 'to': [61], 'more': [62], 'complex': [63], 'mixtures': [64], 'of': [65], 'techniques.': [66]}",2003,"['Computer science', 'Suffix', 'Artificial intelligence', 'Trie', 'Cellular automaton', 'Degree (music)', 'Automaton', 'Word (group theory)', 'Graph', 'Simple (philosophy)', 'Natural language processing', 'Theoretical computer science', 'Mathematics', 'Data structure', 'Philosophy', 'Epistemology', 'Geometry', 'Physics', 'Programming language', 'Acoustics', 'Linguistics']","We describe a simple unsupervised technique for learning morphology by identifying hubs in an automaton. For our purposes, a hub is a node in a graph with in-degree greater than one and out-degree greater than one. We create a word-trie, transform it into a minimal DFA, then identify hubs. Those hubs mark the boundary between root and suffix, achieving similar performance to more complex mixtures of techniques."
https://openalex.org/W4385452929,From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy,"{'Undoubtedly,': [0], 'the': [1, 10, 16, 20, 51, 58, 68, 81, 91, 100, 116, 120, 137, 148, 157, 224, 234, 252], 'evolution': [2], 'of': [3, 12, 53, 63, 88, 93, 102, 230], 'Generative': [4], 'AI': [5], '(GenAI)': [6], 'models': [7, 23], 'has': [8], 'been': [9], 'highlight': [11], 'digital': [13], 'transformation': [14], 'in': [15, 56, 90, 151], 'year': [17], '2022.': [18], 'As': [19], 'different': [21], 'GenAI': [22, 54, 89, 149, 191, 245], 'like': [24, 128], 'ChatGPT': [25, 160], 'and': [26, 34, 60, 65, 71, 86, 95, 132, 155, 180, 189, 207, 217, 227, 239, 249], 'Google': [27], 'Bard': [28], 'continue': [29], 'to': [30, 38, 111, 166, 193, 242], 'foster': [31], 'their': [32], 'complexity': [33], 'capability,': [35], 'it&#x2019;s': [36], 'critical': [37], 'understand': [39], 'its': [40, 255], 'consequences': [41], 'from': [42], 'a': [43], 'cybersecurity': [44, 94, 256], 'perspective.': [45], 'Several': [46], 'instances': [47], 'recently': [48], 'have': [49], 'demonstrated': [50], 'use': [52, 147], 'tools': [55, 150, 192], 'both': [57], 'defensive': [59], 'offensive': [61], 'side': [62], 'cybersecurity,': [64], 'focusing': [66], 'on': [67, 119, 136], 'social,': [69, 225], 'ethical': [70, 117, 212, 228, 250], 'privacy': [72], 'implications': [73, 229], 'this': [74, 244], 'technology': [75], 'possesses.': [76], 'This': [77, 122, 183], 'research': [78], 'paper': [79, 123, 140, 184, 235], 'highlights': [80, 236], 'limitations,': [82], 'challenges,': [83], 'potential': [84], 'risks,': [85], 'opportunities': [87], 'domain': [92], 'privacy.': [96], 'The': [97, 139], 'work': [98], 'presents': [99], 'vulnerabilities': [101], 'ChatGPT,': [103], 'which': [104], 'can': [105, 146, 161], 'be': [106, 162], 'exploited': [107], 'by': [108, 164], 'malicious': [109, 113], 'users': [110], 'exfiltrate': [112], 'information': [114], 'bypassing': [115], 'constraints': [118], 'model.': [121], 'demonstrates': [124], 'successful': [125], 'example': [126], 'attacks': [127, 135], 'Jailbreaks,': [129], 'reverse': [130], 'psychology,': [131], 'prompt': [133], 'injection': [134], 'ChatGPT.': [138, 231], 'also': [141, 222], 'investigates': [142], 'how': [143], 'cyber': [144, 153, 198], 'offenders': [145], 'developing': [152, 211], 'attacks,': [154, 170, 172], 'explore': [156], 'scenarios': [158], 'where': [159], 'used': [163], 'adversaries': [165], 'create': [167], 'social': [168], 'engineering': [169], 'phishing': [171], 'automated': [173], 'hacking,': [174], 'attack': [175, 209], 'payload': [176], 'generation,': [177], 'malware': [178, 218], 'creation,': [179], 'polymorphic': [181], 'malware.': [182], 'then': [185], 'examines': [186], 'defense': [187, 199], 'techniques': [188], 'uses': [190], 'improve': [194], 'security': [195], 'measures,': [196], 'including': [197], 'automation,': [200], 'reporting,': [201], 'threat': [202], 'intelligence,': [203], 'secure': [204], 'code': [205], 'generation': [206], 'detection,': [208], 'identification,': [210], 'guidelines,': [213], 'incidence': [214], 'response': [215], 'plans,': [216], 'detection.': [219], 'We': [220], 'will': [221], 'discuss': [223], 'legal,': [226], 'In': [232], 'conclusion,': [233], 'open': [237], 'challenges': [238], 'future': [240], 'directions': [241], 'make': [243], 'secure,': [246], 'safe,': [247], 'trustworthy,': [248], 'as': [251], 'community': [253], 'understands': [254], 'impacts.': [257]}",2023,"['Computer science', 'Computer security', 'Information privacy', 'Generative grammar', 'Internet privacy', 'Artificial intelligence']","Undoubtedly, the evolution of Generative AI (GenAI) models has been the highlight of digital transformation in the year 2022. As the different GenAI models like ChatGPT and Google Bard continue to foster their complexity and capability, it&#x2019;s critical to understand its consequences from a cybersecurity perspective. Several instances recently have demonstrated the use of GenAI tools in both the defensive and offensive side of cybersecurity, and focusing on the social, ethical and privacy implications this technology possesses. This research paper highlights the limitations, challenges, potential risks, and opportunities of GenAI in the domain of cybersecurity and privacy. The work presents the vulnerabilities of ChatGPT, which can be exploited by malicious users to exfiltrate malicious information bypassing the ethical constraints on the model. This paper demonstrates successful example attacks like Jailbreaks, reverse psychology, and prompt injection attacks on the ChatGPT. The paper also investigates how cyber offenders can use the GenAI tools in developing cyber attacks, and explore the scenarios where ChatGPT can be used by adversaries to create social engineering attacks, phishing attacks, automated hacking, attack payload generation, malware creation, and polymorphic malware. This paper then examines defense techniques and uses GenAI tools to improve security measures, including cyber defense automation, reporting, threat intelligence, secure code generation and detection, attack identification, developing ethical guidelines, incidence response plans, and malware detection. We will also discuss the social, legal, and ethical implications of ChatGPT. In conclusion, the paper highlights open challenges and future directions to make this GenAI secure, safe, trustworthy, and ethical as the community understands its cybersecurity impacts."
https://openalex.org/W4396833271,"Deepfakes, Phrenology, Surveillance, and More! A Taxonomy of AI Privacy Risks","{'Privacy': [0], 'is': [1, 100], 'a': [2, 25, 106, 129], 'key': [3], 'principle': [4], 'for': [5], 'developing': [6], 'ethical': [7], 'AI': [8, 14, 28, 35, 47, 75, 103], 'technologies,': [9], 'but': [10], 'how': [11, 40], 'does': [12], 'including': [13], 'technologies': [15, 48, 76, 104], 'in': [16, 50], 'products': [17], 'and': [18, 44, 139], 'services': [19], 'change': [20], 'privacy': [21, 29, 36, 55, 72, 111, 133], 'risks?': [22], 'We': [23, 38, 68], 'constructed': [24], 'taxonomy': [26], 'of': [27, 46, 97, 131, 142], 'risks': [30, 73, 82, 90, 112, 134], 'by': [31], 'analyzing': [32], '321': [33], 'documented': [34], 'incidents.': [37], 'codified': [39], 'the': [41, 66, 110, 132, 137], 'unique': [42], 'capabilities': [43, 138], 'requirements': [45, 141], 'described': [49], 'those': [51], 'incidents': [52], 'generated': [53], 'new': [54], 'risks,': [56], 'exacerbated': [57, 87], 'known': [58], 'ones,': [59], 'or': [60, 86], 'otherwise': [61], 'did': [62], 'not': [63], 'meaningfully': [64], 'alter': [65, 109], 'risk.': [67], 'present': [69], '12': [70], 'high-level': [71], 'that': [74, 101], 'either': [77], 'newly': [78], 'created': [79], '(e.g.,': [80, 88, 121], 'exposure': [81], 'from': [83, 91, 136], 'deepfake': [84], 'pornography)': [85], 'surveillance': [89], 'collecting': [92], 'training': [93], 'data).': [94], 'One': [95], 'upshot': [96], 'our': [98], 'work': [99], 'incorporating': [102], 'into': [105], 'product': [107], 'can': [108], 'it': [113], 'entails.': [114], 'Yet,': [115], 'current': [116], 'approaches': [117], 'to': [118], 'privacy-preserving': [119], 'AI/ML': [120], 'federated': [122], 'learning,': [123], 'differential': [124], 'privacy,': [125], 'checklists)': [126], 'only': [127], 'address': [128], 'subset': [130], 'arising': [135], 'data': [140], 'AI.': [143]}",2024,"['Differential privacy', 'Computer science', 'Internet privacy', 'Information privacy', 'Privacy by Design', 'Privacy software', 'Computer security', 'Privacy protection', 'Data science', 'Data mining']","Privacy is a key principle for developing ethical AI technologies, but how does including AI technologies in products and services change privacy risks? We constructed a taxonomy of AI privacy risks by analyzing 321 documented AI privacy incidents. We codified how the unique capabilities and requirements of AI technologies described in those incidents generated new privacy risks, exacerbated known ones, or otherwise did not meaningfully alter the risk. We present 12 high-level privacy risks that AI technologies either newly created (e.g., exposure risks from deepfake pornography) or exacerbated (e.g., surveillance risks from collecting training data). One upshot of our work is that incorporating AI technologies into a product can alter the privacy risks it entails. Yet, current approaches to privacy-preserving AI/ML (e.g., federated learning, differential privacy, checklists) only address a subset of the privacy risks arising from the capabilities and data requirements of AI."
https://openalex.org/W4390829176,"Balancing Privacy and Progress: A Review of Privacy Challenges, Systemic Oversight, and Patient Perceptions in AI-Driven Healthcare","{'Integrating': [0], 'Artificial': [1], 'Intelligence': [2], '(AI)': [3], 'in': [4, 31, 57, 98, 133, 167, 199], 'healthcare': [5, 59, 73, 134, 183], 'represents': [6], 'a': [7, 50], 'transformative': [8], 'shift': [9], 'with': [10, 112, 121, 185], 'substantial': [11], 'potential': [12], 'for': [13, 53, 95, 142, 170], 'enhancing': [14], 'patient': [15, 32, 55, 103, 151, 163, 200], 'care.': [16, 201], 'This': [17], 'paper': [18, 86, 179], 'critically': [19], 'examines': [20], 'this': [21], 'integration,': [22], 'confronting': [23], 'significant': [24], 'ethical,': [25], 'legal,': [26], 'and': [27, 36, 68, 82, 91, 105, 146, 162, 175, 191, 196], 'technological': [28], 'challenges,': [29], 'particularly': [30], 'privacy,': [33], 'decision-making': [34], 'autonomy,': [35], 'data': [37, 158], 'integrity.': [38], 'A': [39], 'structured': [40], 'exploration': [41], 'of': [42, 72, 78, 108, 115, 130, 156], 'these': [43], 'issues': [44], 'focuses': [45], 'on': [46], 'Differential': [47, 80], 'Privacy': [48], 'as': [49], 'critical': [51], 'method': [52], 'preserving': [54], 'confidentiality': [56], 'AI-driven': [58], 'systems.': [60], 'We': [61, 100], 'analyze': [62], 'the': [63, 69, 76, 88, 106, 113, 122, 139, 178], 'balance': [64], 'between': [65], 'privacy': [66], 'preservation': [67], 'practical': [70], 'utility': [71], 'data,': [74], 'emphasizing': [75], 'effectiveness': [77], 'encryption,': [79], 'Privacy,': [81], 'mixed-model': [83], 'approaches.': [84], 'The': [85, 128, 153], 'navigates': [87], 'complex': [89], 'ethical': [90, 186], 'legal': [92], 'frameworks': [93], 'essential': [94], 'AI': [96, 184, 193], 'integration': [97], 'healthcare.': [99], 'comprehensively': [101], 'examine': [102], 'rights': [104], 'nuances': [107], 'informed': [109], 'consent,': [110], 'along': [111], 'challenges': [114], 'harmonizing': [116], 'advanced': [117], 'technologies': [118], 'like': [119], 'blockchain': [120], 'General': [123], 'Data': [124], 'Protection': [125], 'Regulation': [126], '(GDPR).': [127], 'issue': [129], 'algorithmic': [131], 'bias': [132, 144], 'is': [135], 'also': [136], 'explored,': [137], 'underscoring': [138], 'urgent': [140], 'need': [141], 'effective': [143], 'detection': [145], 'mitigation': [147], 'strategies': [148], 'to': [149, 181], 'build': [150], 'trust.': [152], 'evolving': [154], 'roles': [155], 'decentralized': [157], 'sharing,': [159], 'regulatory': [160], 'frameworks,': [161], 'agency': [164], 'are': [165], 'discussed': [166], 'depth.': [168], 'Advocating': [169], 'an': [171], 'interdisciplinary,': [172], 'multi-stakeholder': [173], 'approach': [174], 'responsive': [176], 'governance,': [177], 'aims': [180], 'align': [182], 'principles,': [187], 'prioritize': [188], 'patient-centered': [189], 'outcomes,': [190], 'steer': [192], 'towards': [194], 'responsible': [195], 'equitable': [197], 'enhancements': [198]}",2024,"['Health care', 'Autonomy', 'Confidentiality', 'Transformative learning', 'Information privacy', 'Data sharing', 'Data governance', 'Corporate governance', 'Business', 'Internet privacy', 'Knowledge management', 'Political science', 'Psychology', 'Computer science', 'Medicine', 'Computer security', 'Law', 'Service (business)', 'Data quality', 'Marketing', 'Alternative medicine', 'Pedagogy', 'Pathology', 'Finance']","Integrating Artificial Intelligence (AI) in healthcare represents a transformative shift with substantial potential for enhancing patient care. This paper critically examines this integration, confronting significant ethical, legal, and technological challenges, particularly in patient privacy, decision-making autonomy, and data integrity. A structured exploration of these issues focuses on Differential Privacy as a critical method for preserving patient confidentiality in AI-driven healthcare systems. We analyze the balance between privacy preservation and the practical utility of healthcare data, emphasizing the effectiveness of encryption, Differential Privacy, and mixed-model approaches. The paper navigates the complex ethical and legal frameworks essential for AI integration in healthcare. We comprehensively examine patient rights and the nuances of informed consent, along with the challenges of harmonizing advanced technologies like blockchain with the General Data Protection Regulation (GDPR). The issue of algorithmic bias in healthcare is also explored, underscoring the urgent need for effective bias detection and mitigation strategies to build patient trust. The evolving roles of decentralized data sharing, regulatory frameworks, and patient agency are discussed in depth. Advocating for an interdisciplinary, multi-stakeholder approach and responsive governance, the paper aims to align healthcare AI with ethical principles, prioritize patient-centered outcomes, and steer AI towards responsible and equitable enhancements in patient care."
https://openalex.org/W4403827347,AI Privacy in Context: A Comparative Study of Public and Institutional Discourse on Conversational AI Privacy in the US and Chinese Social Media,"{'The': [0], 'proliferation': [1], 'of': [2, 50, 100, 119, 128, 140], 'conversational': [3, 36], 'artificial': [4], 'intelligence': [5], '(AI)': [6], 'systems,': [7], 'such': [8], 'as': [9], 'chatbots,': [10], 'has': [11], 'sparked': [12], 'widespread': [13], 'privacy': [14, 20, 38, 65, 81, 92, 133, 141], 'concerns.': [15], 'Previous': [16], 'research': [17, 134], 'suggests': [18], 'that': [19], 'perceptions': [21], 'and': [22, 32, 43, 47, 55, 67, 69, 94, 116], 'practices': [23], 'vary': [24], 'across': [25], 'sociocultural': [26], 'contexts.': [27, 144], 'This': [28], 'study': [29, 124], 'examines': [30], 'public': [31, 62, 86], 'institutional': [33, 75, 105], 'discourses': [34], 'on': [35, 53, 84, 91, 96], 'AI': [37], 'in': [39, 131, 142], 'the': [40, 97, 112, 120, 126], 'United': [41], 'States': [42], 'China.': [44], 'Semantic': [45], 'network': [46], 'discourse': [48, 63, 76, 87], 'analyses': [49], 'privacy-related': [51], 'discussions': [52], 'Twitter': [54], 'Weibo': [56], 'reveal': [57], 'divergent': [58], 'patterns.': [59], 'On': [60], 'Twitter,': [61], 'emphasizes': [64], 'risks': [66, 93], 'concerns': [68], 'advocates': [70], 'for': [71], 'systemic': [72], 'changes,': [73], 'while': [74], 'promotes': [77], 'individualistic': [78], 'approaches': [79], 'to': [80, 135], 'protection.': [82], 'Conversely,': [83], 'Weibo,': [85], 'is': [88], 'less': [89], 'focused': [90], 'more': [95], 'positive': [98], 'impacts': [99], 'AI,': [101], 'aligning': [102], 'closely': [103], 'with': [104, 111], 'narratives.': [106], 'These': [107], 'variations': [108], 'are': [109], 'intertwined': [110], 'cultural,': [113], 'political,': [114], 'economic,': [115], 'regulatory': [117], 'contexts': [118], 'two': [121], 'countries.': [122], 'Our': [123], 'underscores': [125], 'importance': [127], 'multi-level': [129], 'analysis': [130], 'comparative': [132], 'provide': [136], 'a': [137], 'holistic': [138], 'view': [139], 'various': [143]}",2024,"['Internet privacy', 'Context (archaeology)', 'Social media', 'Public discourse', 'Information privacy', 'Privacy policy', 'Psychology', 'Sociology', 'Political science', 'Computer science', 'World Wide Web', 'Law', 'History', 'Archaeology', 'Politics']","The proliferation of conversational artificial intelligence (AI) systems, such as chatbots, has sparked widespread privacy concerns. Previous research suggests that privacy perceptions and practices vary across sociocultural contexts. This study examines public and institutional discourses on conversational AI privacy in the United States and China. Semantic network and discourse analyses of privacy-related discussions on Twitter and Weibo reveal divergent patterns. On Twitter, public discourse emphasizes privacy risks and concerns and advocates for systemic changes, while institutional discourse promotes individualistic approaches to privacy protection. Conversely, on Weibo, public discourse is less focused on privacy risks and more on the positive impacts of AI, aligning closely with institutional narratives. These variations are intertwined with the cultural, political, economic, and regulatory contexts of the two countries. Our study underscores the importance of multi-level analysis in comparative privacy research to provide a holistic view of privacy in various contexts."
https://openalex.org/W4392599656,Generative AI in Medical Practice: In-Depth Exploration of Privacy and Security Challenges,"{'As': [0], 'advances': [1], 'in': [2, 22, 43, 75, 130, 175, 202], 'artificial': [3], 'intelligence': [4], '(AI)': [5], 'continue': [6], 'to': [7, 60, 68, 122, 178, 240, 262], 'transform': [8], 'and': [9, 37, 50, 88, 95, 113, 135, 137, 150, 156, 168, 182, 205, 215, 226, 248], 'revolutionize': [10], 'the': [11, 16, 102, 124, 162, 166, 180, 195, 212, 223], 'field': [12], 'of': [13, 19, 72, 101, 105, 118, 127, 164, 185, 190, 197, 228], 'medicine,': [14], 'understanding': [15], 'potential': [17, 213], 'uses': [18], 'generative': [20, 34, 73, 128, 173, 199, 229, 264], 'AI': [21, 74, 129, 174, 200, 230, 244, 265], 'health': [23, 62, 76, 84, 131, 147, 176, 203, 207, 235], 'care': [24, 148, 177, 204, 208], 'becomes': [25], 'increasingly': [26], 'important.': [27], 'Generative': [28], 'AI,': [29], 'including': [30, 78], 'models': [31], 'such': [32, 106], 'as': [33], 'adversarial': [35], 'networks': [36], 'large': [38], 'language': [39], 'models,': [40], 'shows': [41], 'promise': [42], 'transforming': [44], 'medical': [45, 79, 86], 'diagnostics,': [46, 80], 'research,': [47, 87], 'treatment': [48], 'planning,': [49], 'patient': [51], 'care.': [52], 'However,': [53], 'these': [54, 143, 186, 219], 'data-intensive': [55], 'systems': [56, 107, 201], 'pose': [57], 'new': [58], 'threats': [59, 97, 170], 'protected': [61], 'information.': [63], 'This': [64, 159], 'Viewpoint': [65], 'paper': [66, 238], 'aims': [67], 'explore': [69], 'various': [70], 'categories': [71], 'care,': [77, 132, 236], 'drug': [81], 'discovery,': [82], 'virtual': [83], 'assistants,': [85], 'clinical': [89], 'decision': [90], 'support,': [91], 'while': [92], 'identifying': [93], 'security': [94, 138, 155, 167, 246], 'privacy': [96, 136, 157, 169, 250], 'within': [98, 234, 267], 'each': [99], 'phase': [100], 'life': [103], 'cycle': [104], '(ie,': [108], 'data': [109, 249], 'collection,': [110], 'model': [111], 'development,': [112], 'implementation': [114], 'phases).': [115], 'The': [116, 188], 'objectives': [117], 'this': [119, 191, 237, 254], 'study': [120, 160, 192, 255], 'were': [121], 'analyze': [123], 'current': [125], 'state': [126], 'identify': [133], 'opportunities': [134], 'challenges': [139], 'posed': [140], 'by': [141], 'integrating': [142], 'technologies': [144], 'into': [145], 'existing': [146], 'infrastructure,': [149], 'propose': [151], 'strategies': [152], 'for': [153, 259], 'mitigating': [154], 'risks.': [158], 'highlights': [161], 'importance': [163], 'addressing': [165], 'associated': [171, 217], 'with': [172, 218], 'ensure': [179], 'safe': [181], 'effective': [183], 'use': [184, 224], 'systems.': [187, 220], 'findings': [189], 'can': [193], 'inform': [194], 'development': [196], 'future': [198], 'help': [206], 'organizations': [209], 'better': [210], 'understand': [211], 'benefits': [214, 227], 'risks': [216], 'By': [221], 'examining': [222], 'cases': [225], 'across': [231], 'diverse': [232], 'domains': [233], 'contributes': [239], 'theoretical': [241], 'discussions': [242], 'surrounding': [243], 'ethics,': [245], 'vulnerabilities,': [247], 'regulations.': [251], 'In': [252], 'addition,': [253], 'provides': [256], 'practical': [257], 'insights': [258], 'stakeholders': [260], 'looking': [261], 'adopt': [263], 'solutions': [266], 'their': [268], 'organizations.': [269]}",2024,"['Generative grammar', 'Health care', 'Computer science', 'Field (mathematics)', 'Knowledge management', 'Data science', 'Artificial intelligence', 'Political science', 'Law', 'Pure mathematics', 'Mathematics']","As advances in artificial intelligence (AI) continue to transform and revolutionize the field of medicine, understanding the potential uses of generative AI in health care becomes increasingly important. Generative AI, including models such as generative adversarial networks and large language models, shows promise in transforming medical diagnostics, research, treatment planning, and patient care. However, these data-intensive systems pose new threats to protected health information. This Viewpoint paper aims to explore various categories of generative AI in health care, including medical diagnostics, drug discovery, virtual health assistants, medical research, and clinical decision support, while identifying security and privacy threats within each phase of the life cycle of such systems (ie, data collection, model development, and implementation phases). The objectives of this study were to analyze the current state of generative AI in health care, identify opportunities and privacy and security challenges posed by integrating these technologies into existing health care infrastructure, and propose strategies for mitigating security and privacy risks. This study highlights the importance of addressing the security and privacy threats associated with generative AI in health care to ensure the safe and effective use of these systems. The findings of this study can inform the development of future generative AI systems in health care and help health care organizations better understand the potential benefits and risks associated with these systems. By examining the use cases and benefits of generative AI across diverse domains within health care, this paper contributes to theoretical discussions surrounding AI ethics, security vulnerabilities, and data privacy regulations. In addition, this study provides practical insights for stakeholders looking to adopt generative AI solutions within their organizations."
https://openalex.org/W4223947403,"AI Technologies, Privacy, and Security","{'Privacy': [0], 'remains': [1], 'one': [2], 'of': [3, 16, 19, 152, 167, 187], 'the': [4, 17, 28, 51, 88, 135, 150, 165, 185], 'most': [5], 'recurrent': [6], 'concerns': [7, 29, 86, 102], 'that': [8, 76, 90, 128, 137], 'people': [9, 30, 100], 'have': [10, 31, 143], 'about': [11, 32, 87, 103, 157, 175], 'AI': [12, 55, 108, 168, 188], 'technologies.': [13], 'The': [14], 'meaning': [15], 'concept': [18], '“privacy”': [20], 'has': [21], 'proven': [22], 'to': [23, 44, 49, 63, 72, 107, 114, 147, 170], 'be': [24], 'fairly': [25], 'elusive.': [26], 'Accordingly,': [27], 'privacy': [33, 104, 121, 140], 'are': [34, 77, 111, 178, 180], 'often': [35], 'vague': [36], 'and': [37, 48, 80, 149, 179], 'ill-formed,': [38], 'which': [39, 54], 'makes': [40], 'it': [41, 162], 'correspondingly': [42], 'difficult': [43], 'address': [45], 'these': [46, 158], 'concerns,': [47], 'explain': [50], 'ways': [52], 'in': [53, 105, 120, 139], 'technologies': [56, 169], 'do': [57, 59], 'or': [58], 'not': [60, 181], 'pose': [61], 'threats': [62, 89], ""people's"": [64], 'interests.': [65], 'In': [66], 'this': [67], 'article,': [68], 'we': [69, 126], 'draw': [70], 'attention': [71], 'some': [73], 'important': [74], 'distinctions': [75], 'frequently': [78], 'overlooked,': [79], 'spell': [81], 'out': [82], 'their': [83, 145], 'implications': [84], 'for': [85, 94, 164, 173], 'AI-related': [91], 'technology': [92], 'poses': [93], 'privacy.': [95], 'We': [96], 'argue': [97, 127], 'that,': [98], 'when': [99], 'express': [101], 'relation': [106], 'technologies,': [109], 'they': [110], 'usually': [112], 'referring': [113], 'security': [115, 132], 'interests': [116, 119, 133, 138, 177], 'rather': [117], 'than': [118], 'per': [122, 141], 'se': [123, 142], '.': [124], 'Nevertheless,': [125], 'focusing': [129], 'primarily': [130], 'on': [131], 'misses': [134], 'importance': [136], 'through': [144, 184], 'contribution': [146], 'autonomy': [148], 'development': [151], 'our': [153], 'identities.': [154], 'Improving': [155], 'insight': [156], 'issues': [159], 'can': [160], 'make': [161], 'easier': [163], 'developers': [166], 'provide': [171], 'explanations': [172], 'users': [174], 'what': [176], 'at': [182], 'stake': [183], 'use': [186], 'systems.': [189]}",2022,"['Internet privacy', 'Computer security', 'Computer science']","Privacy remains one of the most recurrent concerns that people have about AI technologies. The meaning of the concept of “privacy” has proven to be fairly elusive. Accordingly, the concerns people have about privacy are often vague and ill-formed, which makes it correspondingly difficult to address these concerns, and to explain the ways in which AI technologies do or do not pose threats to people's interests. In this article, we draw attention to some important distinctions that are frequently overlooked, and spell out their implications for concerns about the threats that AI-related technology poses for privacy. We argue that, when people express concerns about privacy in relation to AI technologies, they are usually referring to security interests rather than interests in privacy per se . Nevertheless, we argue that focusing primarily on security interests misses the importance that interests in privacy per se have through their contribution to autonomy and the development of our identities. Improving insight about these issues can make it easier for the developers of AI technologies to provide explanations for users about what interests are and are not at stake through the use of AI systems."
https://openalex.org/W3003326204,"Smart Contract Privacy Protection Using AI in Cyber-Physical Systems: Tools, Techniques and Challenges","{'Applications': [0], 'of': [1, 30, 208], 'Blockchain': [2], '(BC)': [3], 'technology': [4], 'and': [5, 15, 43, 50, 77, 99, 147, 176, 188, 197, 216, 222], 'Cyber-Physical': [6], 'Systems': [7], '(CPS)': [8], 'are': [9, 85, 149, 202], 'increasing': [10], 'exponentially.': [11], 'However,': [12, 83], 'framing': [13], 'resilient': [14], 'correct': [16], 'smart': [17, 22], 'contracts': [18], '(SCs)': [19], 'for': [20, 59, 190, 199], 'these': [21], 'application': [23], 'is': [24, 37, 47, 135, 211], 'a': [25, 109, 125, 169, 205], 'quite': [26], 'challenging': [27], 'task': [28], 'because': [29], 'the': [31, 39, 53, 57, 79, 88, 116, 131, 139, 141, 154, 157, 160], 'complexity': [32], 'associated': [33, 80], 'with': [34], 'them.': [35], 'SC': [36, 112, 145, 191, 201, 217], 'modernizing': [38], 'traditional': [40], 'industrial,': [41], 'technical,': [42], 'business': [44], 'processes.': [45], 'It': [46, 72], 'self-executable,': [48], 'self-verifiable,': [49], 'embedded': [51], 'into': [52], 'BC': [54, 133], 'that': [55, 119, 167], 'eliminates': [56], 'need': [58, 102], 'trusted': [60], 'third-party': [61], 'systems,': [62], 'which': [63, 213], 'ultimately': [64], 'saves': [65], 'administration': [66], 'as': [67, 69], 'well': [68, 86], 'service': [70], 'costs.': [71], 'also': [73], 'improves': [74], 'system': [75], 'efficiency': [76], 'reduces': [78], 'security': [81, 98, 113, 146, 177, 221], 'risks.': [82], 'SCs': [84, 171], 'encouraging': [87], 'new': [89], 'technological': [90], 'reforms': [91], 'in': [92, 115], 'Industry': [93], '4.0,': [94], 'but': [95], 'still,': [96], 'various': [97, 183], 'privacy': [100, 148, 175, 192], 'challenges': [101, 142, 198], 'to': [103, 144, 218], 'be': [104, 121], 'addressed.': [105], 'In': [106], 'this': [107, 180], 'paper,': [108], 'survey': [110], 'on': [111], 'vulnerabilities': [114], 'software': [117], 'code': [118], 'can': [120], 'easily': [122], 'hacked': [123], 'by': [124, 153], 'malicious': [126], 'user': [127], 'or': [128], 'may': [129], 'compromise': [130], 'entire': [132], 'network': [134], 'presented.': [136], 'As': [137], 'per': [138], 'literature,': [140], 'related': [143], 'not': [150], 'explored': [151], 'much': [152], 'authors': [155], 'around': [156], 'world.': [158], 'From': [159], 'existing': [161], 'proposals,': [162], 'it': [163], 'has': [164], 'been': [165], 'observed': [166], 'designing': [168], 'complex': [170], 'cannot': [172], 'mitigate': [173], 'its': [174, 220], 'issues.': [178], 'So,': [179], 'paper': [181], 'investigates': [182], 'Artificial': [184], 'Intelligence': [185], '(AI)': [186], 'techniques': [187], 'tools': [189], 'protection.': [193], 'Then,': [194], 'open': [195], 'issues': [196], 'AI-based': [200], 'analyzed.': [203], 'Finally,': [204], 'case': [206], 'study': [207], 'retail': [209], 'marketing': [210], 'presented,': [212], 'uses': [214], 'AI': [215], 'preserve': [219], 'privacy.': [223]}",2020,"['Computer security', 'Computer science', 'Verifiable secret sharing', 'Compromise', 'Privacy by Design', 'Security service', 'Information privacy', 'Software security assurance', 'Cyber-physical system', 'Information security', 'Programming language', 'Sociology', 'Set (abstract data type)', 'Operating system', 'Social science']","Applications of Blockchain (BC) technology and Cyber-Physical Systems (CPS) are increasing exponentially. However, framing resilient and correct smart contracts (SCs) for these smart application is a quite challenging task because of the complexity associated with them. SC is modernizing the traditional industrial, technical, and business processes. It is self-executable, self-verifiable, and embedded into the BC that eliminates the need for trusted third-party systems, which ultimately saves administration as well as service costs. It also improves system efficiency and reduces the associated security risks. However, SCs are well encouraging the new technological reforms in Industry 4.0, but still, various security and privacy challenges need to be addressed. In this paper, a survey on SC security vulnerabilities in the software code that can be easily hacked by a malicious user or may compromise the entire BC network is presented. As per the literature, the challenges related to SC security and privacy are not explored much by the authors around the world. From the existing proposals, it has been observed that designing a complex SCs cannot mitigate its privacy and security issues. So, this paper investigates various Artificial Intelligence (AI) techniques and tools for SC privacy protection. Then, open issues and challenges for AI-based SC are analyzed. Finally, a case study of retail marketing is presented, which uses AI and SC to preserve its security and privacy."
https://openalex.org/W4393170828,Privacy and Security Concerns in Generative AI: A Comprehensive Survey,"{'Generative': [0], 'Artificial': [1], 'Intelligence': [2], '(GAI)': [3], 'has': [4], 'sparked': [5], 'a': [6, 32, 51], 'transformative': [7], 'wave': [8], 'across': [9], 'various': [10], 'domains,': [11], 'including': [12], 'machine': [13], 'learning,': [14], 'healthcare,': [15], 'business,': [16], 'and': [17, 38, 70, 83, 91], 'entertainment,': [18], 'owing': [19], 'to': [20, 24, 42], 'its': [21], 'remarkable': [22], 'ability': [23], 'generate': [25], 'lifelike': [26], 'data.': [27], 'This': [28], 'comprehensive': [29, 52], 'survey': [30], 'offers': [31], 'meticulous': [33], 'examination': [34], 'of': [35, 54], 'the': [36, 74], 'privacy': [37], 'security': [39, 81], 'challenges': [40], 'inherent': [41], 'GAI.': [43], 'It': [44], 'provides': [45], 'five': [46], 'pivotal': [47], 'perspectives': [48], 'essential': [49], 'for': [50], 'understanding': [53], 'these': [55], 'intricacies.': [56], 'The': [57], 'paper': [58], 'encompasses': [59], 'discussions': [60], 'on': [61], 'GAI': [62], 'architectures,': [63], 'diverse': [64], 'generative': [65], 'model': [66], 'types,': [67], 'practical': [68], 'applications,': [69], 'recent': [71], 'advancements': [72], 'within': [73], 'field.': [75], 'In': [76], 'addition,': [77], 'it': [78], 'highlights': [79], 'current': [80], 'strategies': [82], 'proposes': [84], 'sustainable': [85], 'solutions,': [86], 'emphasizing': [87], 'user,': [88], 'developer,': [89], 'institutional,': [90], 'policymaker': [92], 'involvement.': [93]}",2024,"['Computer science', 'Computer security', 'Internet privacy', 'Information privacy', 'Data science']","Generative Artificial Intelligence (GAI) has sparked a transformative wave across various domains, including machine learning, healthcare, business, and entertainment, owing to its remarkable ability to generate lifelike data. This comprehensive survey offers a meticulous examination of the privacy and security challenges inherent to GAI. It provides five pivotal perspectives essential for a comprehensive understanding of these intricacies. The paper encompasses discussions on GAI architectures, diverse generative model types, practical applications, and recent advancements within the field. In addition, it highlights current security strategies and proposes sustainable solutions, emphasizing user, developer, institutional, and policymaker involvement."
https://openalex.org/W3013109186,"Emotional AI, soft biometrics and the surveillance of emotional life: An unusual consensus on privacy","{'By': [0], 'the': [1, 47, 76, 86, 107, 111, 117, 164, 198], 'early': [2], '2020s,': [3], 'emotional': [4, 48, 90, 105], 'artificial': [5], 'intelligence': [6], '(emotional': [7], 'AI)': [8], 'will': [9], 'become': [10], 'increasingly': [11], 'present': [12], 'in': [13, 39, 128], 'everyday': [14], 'objects': [15], 'and': [16, 31, 45, 62, 125, 173, 197], 'practices': [17, 92], 'such': [18, 52], 'as': [19, 53], 'assistants,': [20], 'cars,': [21], 'games,': [22], 'mobile': [23], 'phones,': [24], 'wearables,': [25], 'toys,': [26], 'marketing,': [27], 'insurance,': [28], 'policing,': [29], 'education': [30], 'border': [32], 'controls.': [33], 'There': [34], 'is': [35], 'also': [36], 'keen': [37], 'interest': [38], 'using': [40, 139], 'these': [41], 'technologies': [42], 'to': [43, 134, 189], 'regulate': [44], 'optimize': [46], 'experiences': [49], 'of': [50, 89, 146, 187, 193, 200], 'spaces,': [51], 'workplaces,': [54], 'hospitals,': [55], 'prisons,': [56], 'classrooms,': [57], 'travel': [58], 'infrastructures,': [59], 'restaurants,': [60], 'retail': [61], 'chain': [63], 'stores.': [64], 'Developers': [65], 'frequently': [66], 'claim': [67, 77], 'that': [68, 93, 181], 'their': [69], 'applications': [70], 'do': [71, 94], 'not': [72, 95], 'identify': [73, 96], 'people.': [74], 'Taking': [75], 'at': [78], 'face': [79], 'value,': [80], 'this': [81, 168, 176], 'paper': [82, 108], 'asks,': [83], 'what': [84], 'are': [85], 'privacy': [87, 100, 196], 'implications': [88], 'AI': [91], 'individuals?': [97], 'To': [98], 'investigate': [99], 'perspectives': [101], 'on': [102, 149, 163], 'soft': [103], 'non-identifying': [104], 'AI,': [106], 'draws': [109], 'upon': [110], 'following:': [112], 'over': [113], '100': [114], 'interviews': [115], 'with': [116, 132], 'emotion': [118, 152], 'detection': [119], 'industry,': [120], 'legal': [121], 'community,': [122], 'policy-makers,': [123], 'regulators': [124], 'NGOs': [126], 'interested': [127], 'privacy;': [129], 'a': [130, 143, 157, 184], 'workshop': [131], 'stakeholders': [133, 162], 'design': [135], 'ethical': [136], 'codes': [137], 'for': [138, 166], 'data': [140, 201], 'about': [141, 151, 202], 'emotions;': [142], 'UK': [144], 'survey': [145], '2068': [147], 'citizens': [148], 'feelings': [150], 'capture': [153], 'technologies.': [154], 'It': [155], 'finds': [156], 'weak': [158, 177], 'consensus': [159], 'among': [160], 'social': [161], 'need': [165], 'privacy,': [167], 'driven': [169], 'by': [170], 'different': [171], 'interests': [172], 'motivations.': [174], 'Given': [175], 'consensus,': [178], 'it': [179], 'concludes': [180], 'there': [182], 'exists': [183], 'limited': [185], 'window': [186], 'opportunity': [188], 'societally': [190], 'agree': [191], 'principles': [192], 'practice': [194], 'regarding': [195], 'use': [199], 'emotions.': [203]}",2020,"['Feeling', 'Internet privacy', 'Public relations', 'Face (sociological concept)', 'Emotional intelligence', 'Sociology', 'Psychology', 'Social psychology', 'Political science', 'Computer science', 'Social science']","By the early 2020s, emotional artificial intelligence (emotional AI) will become increasingly present in everyday objects and practices such as assistants, cars, games, mobile phones, wearables, toys, marketing, insurance, policing, education and border controls. There is also keen interest in using these technologies to regulate and optimize the emotional experiences of spaces, such as workplaces, hospitals, prisons, classrooms, travel infrastructures, restaurants, retail and chain stores. Developers frequently claim that their applications do not identify people. Taking the claim at face value, this paper asks, what are the privacy implications of emotional AI practices that do not identify individuals? To investigate privacy perspectives on soft non-identifying emotional AI, the paper draws upon the following: over 100 interviews with the emotion detection industry, legal community, policy-makers, regulators and NGOs interested in privacy; a workshop with stakeholders to design ethical codes for using data about emotions; a UK survey of 2068 citizens on feelings about emotion capture technologies. It finds a weak consensus among social stakeholders on the need for privacy, this driven by different interests and motivations. Given this weak consensus, it concludes that there exists a limited window of opportunity to societally agree principles of practice regarding privacy and the use of data about emotions."
https://openalex.org/W4323926479,AI privacy toolkit,"{'The': [0, 64], 'need': [1], 'to': [2, 6, 12, 56, 69], 'analyse': [3], 'personal': [4, 42, 58], 'data': [5, 17], 'drive': [7], 'business': [8], 'alongside': [9], 'the': [10, 14, 37, 90], 'requirement': [11], 'preserve': [13], 'privacy': [15, 86], 'of': [16, 41, 92], 'subjects': [18], 'creates': [19], 'a': [20], 'known': [21], 'tension.': [22], 'Data': [23], 'protection': [24], 'regulations': [25], 'such': [26], 'as': [27], 'GDPR': [28], 'and': [29, 34, 39, 76, 87], 'CCPA': [30], 'define': [31], 'strict': [32], 'restrictions': [33], 'obligations': [35], 'on': [36], 'collection': [38], 'processing': [40], 'data.': [43], 'These': [44], 'are': [45], 'also': [46], 'relevant': [47], 'for': [48], 'machine': [49], 'learning': [50], 'models,': [51], 'which': [52], 'can': [53], 'be': [54], 'used': [55], 'derive': [57], 'information': [59], 'about': [60], 'their': [61], 'training': [62], 'sets.': [63], 'open-source': [65], 'ai-privacy-toolkit': [66], 'is': [67], 'designed': [68], 'help': [70, 88], 'organizations': [71], 'navigate': [72], 'this': [73], 'challenging': [74], 'area': [75], 'build': [77], 'more': [78], 'trustworthy': [79], 'AI': [80, 93], 'solutions,': [81], 'with': [82], 'tools': [83], 'that': [84], 'protect': [85], 'ensure': [89], 'compliance': [91], 'models.': [94]}",2023,"['Computer science', 'World Wide Web', 'Computer security']","The need to analyse personal data to drive business alongside the requirement to preserve the privacy of data subjects creates a known tension. Data protection regulations such as GDPR and CCPA define strict restrictions and obligations on the collection and processing of personal data. These are also relevant for machine learning models, which can be used to derive personal information about their training sets. The open-source ai-privacy-toolkit is designed to help organizations navigate this challenging area and build more trustworthy AI solutions, with tools that protect privacy and help ensure the compliance of AI models."
https://openalex.org/W4407243994,"AI Ethics: Integrating Transparency, Fairness, and Privacy in AI Development","{'The': [0, 102, 179], 'expansion': [1], 'of': [2, 34, 56, 92, 140, 166, 184], 'Artificial': [3], 'Intelligence': [4], 'in': [5, 50, 107, 118, 187], 'sectors': [6], 'such': [7, 76], 'as': [8, 77], 'healthcare,': [9], 'finance,': [10], 'and': [11, 21, 32, 47, 69, 80, 89, 114, 137, 174], 'communication': [12], 'has': [13], 'raised': [14], 'critical': [15], 'ethical': [16, 42, 94, 122, 146, 156, 189], 'concerns': [17], 'surrounding': [18], 'transparency,': [19, 112], 'fairness,': [20, 113], 'privacy.': [22], 'Addressing': [23], 'these': [24, 126], 'issues': [25], 'is': [26, 71], 'essential': [27], 'for': [28, 86, 154, 163], 'the': [29, 64, 93, 138, 159, 164, 182], 'responsible': [30], 'development': [31, 98, 142], 'deployment': [33], 'AI': [35, 51, 58, 97, 147, 160, 167, 190], 'systems.': [36], 'This': [37, 149], 'research': [38], 'establishes': [39], 'a': [40, 87, 120], 'comprehensive': [41], 'framework': [43], 'that': [44, 169], 'mitigates': [45], 'biases': [46], 'promotes': [48], 'accountability': [49], 'technologies.': [52], 'A': [53], 'comparative': [54], 'analysis': [55], 'international': [57], 'policy': [59], 'frameworks': [60], 'from': [61], 'regions': [62, 110], 'including': [63, 132], 'European': [65], 'Union,': [66], 'United': [67], 'States,': [68], 'China': [70], 'conducted': [72], 'using': [73], 'analytical': [74], 'tools': [75, 84], 'Venn': [78], 'diagrams': [79], 'Cartesian': [81], 'graphs.': [82], 'These': [83], 'allow': [85], 'visual': [88], 'systematic': [90], 'evaluation': [91], 'principles': [95], 'guiding': [96], 'across': [99], 'different': [100], 'jurisdictions.': [101], 'results': [103], 'reveal': [104], 'significant': [105], 'variations': [106], 'how': [108], 'global': [109, 185], 'prioritize': [111], 'privacy,': [115], 'with': [116, 176], 'challenges': [117], 'creating': [119], 'unified': [121], 'standard.': [123], 'To': [124], 'address': [125], 'challenges,': [127], 'we': [128], 'propose': [129], 'technical': [130], 'strategies,': [131], 'fairness-aware': [133], 'algorithms,': [134], 'routine': [135], 'audits,': [136], 'establishment': [139], 'diverse': [141], 'teams': [143], 'to': [144], 'ensure': [145], 'practices.': [148], 'paper': [150], 'provides': [151], 'actionable': [152], 'recommendations': [153], 'integrating': [155], 'oversight': [157], 'into': [158], 'lifecycle,': [161], 'advocating': [162], 'creation': [165], 'systems': [168], 'are': [170], 'both': [171], 'technically': [172], 'sophisticated': [173], 'aligned': [175], 'societal': [177], 'values.': [178], 'findings': [180], 'underscore': [181], 'necessity': [183], 'collaboration': [186], 'fostering': [188], 'development.': [191]}",2025,"['Computer science', 'Transparency (behavior)', 'Development (topology)', 'Knowledge management', 'Data science', 'Computer security', 'Mathematics', 'Mathematical analysis']","The expansion of Artificial Intelligence in sectors such as healthcare, finance, and communication has raised critical ethical concerns surrounding transparency, fairness, and privacy. Addressing these issues is essential for the responsible development and deployment of AI systems. This research establishes a comprehensive ethical framework that mitigates biases and promotes accountability in AI technologies. A comparative analysis of international AI policy frameworks from regions including the European Union, United States, and China is conducted using analytical tools such as Venn diagrams and Cartesian graphs. These tools allow for a visual and systematic evaluation of the ethical principles guiding AI development across different jurisdictions. The results reveal significant variations in how global regions prioritize transparency, fairness, and privacy, with challenges in creating a unified ethical standard. To address these challenges, we propose technical strategies, including fairness-aware algorithms, routine audits, and the establishment of diverse development teams to ensure ethical AI practices. This paper provides actionable recommendations for integrating ethical oversight into the AI lifecycle, advocating for the creation of AI systems that are both technically sophisticated and aligned with societal values. The findings underscore the necessity of global collaboration in fostering ethical AI development."
https://openalex.org/W4383911728,"Building Trust in Fintech: An Analysis of Ethical and Privacy Considerations in the Intersection of Big Data, AI, and Customer Trust","{'This': [0], 'research': [1, 123], 'paper': [2], 'explores': [3], 'the': [4, 26, 48, 72, 83, 90, 98, 109, 116, 136], 'ethical': [5, 29], 'considerations': [6], 'in': [7], 'using': [8], 'financial': [9], 'technology': [10], '(fintech),': [11], 'focusing': [12], 'on': [13, 94], 'big': [14], 'data,': [15, 53], 'artificial': [16], 'intelligence': [17], '(AI),': [18], 'and': [19, 30, 43, 59, 81, 89, 108, 128], 'privacy.': [20], 'Using': [21], 'a': [22], 'systematic': [23], 'literature-review': [24], 'methodology,': [25], 'study': [27, 65, 99], 'identifies': [28], 'privacy': [31], 'issues': [32, 138], 'related': [33], 'to': [34, 114, 133], 'fintech,': [35], 'including': [36, 71], 'bias,': [37], 'discrimination,': [38], 'privacy,': [39], 'transparency,': [40], 'justice,': [41], 'ownership,': [42], 'control.': [44], 'The': [45, 64], 'findings': [46], 'emphasize': [47], 'importance': [49], 'of': [50, 74, 85, 92, 105], 'safeguarding': [51], 'customer': [52, 86], 'complying': [54], 'with': [55], 'data': [56, 79, 132], 'protection': [57], 'laws,': [58], 'promoting': [60], 'corporate': [61], 'digital': [62], 'responsibility.': [63], 'provides': [66], 'practical': [67], 'suggestions': [68], 'for': [69, 111], 'companies,': [70], 'use': [73], 'encryption': [75], 'techniques,': [76], 'transparency': [77], 'regarding': [78], 'collection': [80], 'usage,': [82], 'provision': [84], 'opt-out': [87], 'options,': [88], 'training': [91], 'staff': [93], 'data-protection': [95], 'policies.': [96], 'However,': [97], 'is': [100], 'limited': [101], 'by': [102], 'its': [103], 'exclusion': [104], 'non-English-language': [106], 'studies': [107], 'need': [110], 'additional': [112], 'resources': [113], 'deepen': [115], 'findings.': [117], 'To': [118], 'overcome': [119], 'these': [120], 'limitations,': [121], 'future': [122], 'could': [124], 'expand': [125], 'existing': [126], 'knowledge': [127], 'collect': [129], 'more': [130], 'comprehensive': [131], 'better': [134], 'understand': [135], 'complex': [137], 'examined.': [139]}",2023,"['Transparency (behavior)', 'Safeguarding', 'Big data', 'Data Protection Act 1998', 'Business', 'Data governance', 'Data collection', 'Information privacy', 'Internet privacy', 'Profiling (computer programming)', 'Privacy by Design', 'Privacy policy', 'Marketing', 'Computer science', 'Computer security', 'Data quality', 'Sociology', 'Operating system', 'Metric (unit)', 'Social science', 'Nursing', 'Medicine']","This research paper explores the ethical considerations in using financial technology (fintech), focusing on big data, artificial intelligence (AI), and privacy. Using a systematic literature-review methodology, the study identifies ethical and privacy issues related to fintech, including bias, discrimination, privacy, transparency, justice, ownership, and control. The findings emphasize the importance of safeguarding customer data, complying with data protection laws, and promoting corporate digital responsibility. The study provides practical suggestions for companies, including the use of encryption techniques, transparency regarding data collection and usage, the provision of customer opt-out options, and the training of staff on data-protection policies. However, the study is limited by its exclusion of non-English-language studies and the need for additional resources to deepen the findings. To overcome these limitations, future research could expand existing knowledge and collect more comprehensive data to better understand the complex issues examined."
https://openalex.org/W4366547469,"Emotion AI at Work: Implications for Workplace Surveillance, Emotional Labor, and Emotional Privacy","{'Workplaces': [0], 'are': [1], 'increasingly': [2], 'adopting': [3], 'emotion': [4, 23, 44, 60, 104], 'AI,': [5], 'promising': [6], 'benefits': [7], 'to': [8, 22, 64, 83, 94, 113, 120, 138], 'organizations.': [9], 'However,': [10], 'little': [11], 'is': [12], 'known': [13], 'about': [14], 'the': [15, 26, 52, 107, 111, 147], 'perceptions': [16], 'and': [17, 72, 115, 133, 140, 145], 'experiences': [18], 'of': [19, 54, 98, 103], 'workers': [20, 35, 74, 90], 'subject': [21], 'AI': [24, 45, 61, 105], 'in': [25, 77, 106], 'workplace.': [27, 108, 148], 'Our': [28], 'interview': [29], 'study': [30], 'with': [31, 68], '(n=15)': [32], 'US': [33], 'adult': [34], 'addresses': [36], 'this': [37], 'gap,': [38], 'finding': [39], 'that': [40, 73], '(1)': [41], 'participants': [42], 'viewed': [43], 'as': [46, 80, 100, 124, 127, 129], 'a': [47, 81, 95, 101], 'deep': [48], 'privacy': [49, 53, 85, 143], 'violation': [50], 'over': [51, 86], ""workers'"": [55, 66], 'sensitive': [56], 'emotional': [57, 69, 78, 125, 142], 'information;': [58], '(2)': [59], 'may': [62, 75, 91], 'function': [63], 'enforce': [65], 'compliance': [67], 'labor': [70, 79], 'expectations,': [71], 'engage': [76], 'mechanism': [82], 'preserve': [84, 141], 'their': [87], 'emotions;': [88], '(3)': [89], 'be': [92], 'exposed': [93], 'wide': [96], 'range': [97], 'harms': [99], 'consequence': [102], 'Findings': [109], 'reveal': [110], 'need': [112], 'recognize': [114], 'define': [116], 'an': [117], 'individual': [118], 'right': [119], 'what': [121], 'we': [122], 'introduce': [123], 'privacy,': [126], 'well': [128], 'raise': [130], 'important': [131], 'research': [132], 'policy': [134], 'questions': [135], 'on': [136], 'how': [137], 'protect': [139], 'within': [144], 'beyond': [146]}",2023,"['Emotional labor', 'Work (physics)', 'Psychology', 'Emotion work', 'Applied psychology', 'Social psychology', 'Computer science', 'Engineering', 'Mechanical engineering']","Workplaces are increasingly adopting emotion AI, promising benefits to organizations. However, little is known about the perceptions and experiences of workers subject to emotion AI in the workplace. Our interview study with (n=15) US adult workers addresses this gap, finding that (1) participants viewed emotion AI as a deep privacy violation over the privacy of workers' sensitive emotional information; (2) emotion AI may function to enforce workers' compliance with emotional labor expectations, and that workers may engage in emotional labor as a mechanism to preserve privacy over their emotions; (3) workers may be exposed to a wide range of harms as a consequence of emotion AI in the workplace. Findings reveal the need to recognize and define an individual right to what we introduce as emotional privacy, as well as raise important research and policy questions on how to protect and preserve emotional privacy within and beyond the workplace."
https://openalex.org/W4285740054,You Can’t Have AI Both Ways: Balancing Health Data Privacy and Access Fairly,"{'Artificial': [0], 'intelligence': [1], '(AI)': [2], 'in': [3, 77, 96, 104, 198], 'healthcare': [4, 8, 108, 199], 'promises': [5], 'to': [6, 30, 46, 116, 142, 145, 150, 154, 165], 'make': [7, 151], 'safer,': [9], 'more': [10, 13], 'accurate,': [11], 'and': [12, 16, 42, 64, 80, 99, 102, 125, 128, 134, 222, 228], 'cost-effective.': [14], 'Public': [15], 'private': [17], 'actors': [18], 'have': [19, 44], 'been': [20, 50], 'investing': [21], 'significant': [22, 167], 'amounts': [23, 168], 'of': [24, 107, 122, 169, 192], 'resources': [25, 144], 'into': [26, 172], 'the': [27, 54, 91, 97, 105, 112, 120, 129, 177, 214], 'field.': [28], 'However,': [29], 'benefit': [31], 'from': [32, 36], 'data-intensive': [33, 62, 117], 'medicine,': [34, 63, 118], 'particularly': [35, 119], 'AI': [37, 133, 173, 226], 'technologies,': [38], 'one': [39], 'must': [40], 'first': [41], 'foremost': [43], 'access': [45, 182], 'data.': [47], 'It': [48], 'has': [49], 'previously': [51], 'argued': [52], 'that': [53, 161], 'conventionally': [55], 'used': [56], '“consent': [57], 'or': [58], 'anonymize': [59], 'approach”': [60], 'undermines': [61], 'worse,': [65], 'may': [66], 'ultimately': [67], 'harm': [68], 'patients.': [69], 'Yet,': [70], 'this': [71, 87, 188], 'is': [72, 163], 'still': [73], 'a': [74, 190, 207], 'dominant': [75], 'approach': [76], 'European': [78], 'countries': [79, 140], 'framed': [81], 'as': [82, 187], 'an': [83], 'either-or': [84], 'choice.': [85], 'In': [86], 'paper,': [88], 'we': [89], 'contrast': [90], 'different': [92], 'data': [93, 123, 126, 157, 181, 219], 'governance': [94, 220], 'approaches': [95], 'EU': [98], 'their': [100, 223], 'advantages': [101], 'disadvantages': [103], 'context': [106], 'AI.': [109], 'We': [110, 159], 'detail': [111], 'ethical': [113], 'trade-offs': [114], 'inherent': [115], 'balancing': [121], 'privacy': [124, 185], 'access,': [127], 'subsequent': [130], 'prioritization': [131], 'between': [132], 'other': [135], 'effective': [136], 'health': [137], 'interventions.': [138], 'If': [139], 'wish': [141], 'allocate': [143], 'AI,': [146], 'they': [147], 'also': [148], 'need': [149], 'corresponding': [152], 'efforts': [153], 'improve': [155], '(secure)': [156], 'access.': [158], 'conclude': [160], 'it': [162], 'unethical': [164], 'invest': [166], 'public': [170, 193], 'funds': [171], 'development': [174], 'whilst': [175], 'at': [176], 'same': [178], 'time': [179], 'limiting': [180], 'through': [183], 'strict': [184], 'measures,': [186], 'constitutes': [189], 'waste': [191], 'resources.': [194], 'The': [195], '“AI': [196], 'revolution”': [197], 'can': [200], 'only': [201], 'realise': [202], 'its': [203], 'full': [204], 'potential': [205], 'if': [206], 'fair,': [208], 'inclusive': [209], 'engagement': [210], 'process': [211], 'spells': [212], 'out': [213], 'values': [215], 'underlying': [216], '(trans)': [217], 'national': [218], 'policies': [221], 'impact': [224], 'on': [225], 'development,': [227], 'priorities': [229], 'are': [230], 'set': [231], 'accordingly.': [232]}",2022,"['Context (archaeology)', 'Data governance', 'Harm', 'Health care', 'Internet privacy', 'Data Protection Act 1998', 'Corporate governance', 'Data access', 'Information privacy', 'General Data Protection Regulation', 'Big data', 'SAFER', 'Computer science', 'Business', 'Computer security', 'Public relations', 'Data quality', 'Political science', 'Law', 'Marketing', 'Data mining', 'Finance', 'Paleontology', 'Metric (unit)', 'Programming language', 'Biology']","Artificial intelligence (AI) in healthcare promises to make healthcare safer, more accurate, and more cost-effective. Public and private actors have been investing significant amounts of resources into the field. However, to benefit from data-intensive medicine, particularly from AI technologies, one must first and foremost have access to data. It has been previously argued that the conventionally used “consent or anonymize approach” undermines data-intensive medicine, and worse, may ultimately harm patients. Yet, this is still a dominant approach in European countries and framed as an either-or choice. In this paper, we contrast the different data governance approaches in the EU and their advantages and disadvantages in the context of healthcare AI. We detail the ethical trade-offs inherent to data-intensive medicine, particularly the balancing of data privacy and data access, and the subsequent prioritization between AI and other effective health interventions. If countries wish to allocate resources to AI, they also need to make corresponding efforts to improve (secure) data access. We conclude that it is unethical to invest significant amounts of public funds into AI development whilst at the same time limiting data access through strict privacy measures, as this constitutes a waste of public resources. The “AI revolution” in healthcare can only realise its full potential if a fair, inclusive engagement process spells out the values underlying (trans) national data governance policies and their impact on AI development, and priorities are set accordingly."
https://openalex.org/W3211102095,AI-enabled Automation for Completeness Checking of Privacy Policies,"{'Technological': [0], 'advances': [1], 'in': [2, 84, 175, 252, 257, 261], 'information': [3, 173], 'sharing': [4], 'have': [5], 'raised': [6], 'concerns': [7], 'about': [8, 16], 'data': [9, 20], 'protection.': [10], 'Privacy': [11], 'policies': [12, 43, 81, 177, 195], 'contain': [13], 'privacy-related': [14, 94, 131], 'requirements': [15], 'how': [17], 'the': [18, 49, 65, 75, 113, 130, 171, 183, 197, 213], 'personal': [19], 'of': [21, 67, 77, 116, 133, 142, 153, 160, 203, 212, 215, 218, 234, 238, 255], 'individuals': [22], 'will': [23], 'be': [24], 'handled': [25], 'by': [26, 156], 'an': [27, 38, 148, 253], 'organization': [28, 89], 'or': [29, 37], 'a': [30, 34, 68, 136, 140, 158, 201, 232, 242], 'software': [31, 95], 'system': [32], '(e.g.,': [33], 'web': [35], 'service': [36], 'app).': [39], 'In': [40, 105], 'Europe,': [41], 'privacy': [42, 69, 80, 117, 176, 194, 206], 'are': [44], 'subject': [45], 'to': [46, 62, 74, 128, 241], 'compliance': [47, 59], 'with': [48], 'General': [50], 'Data': [51], 'Protection': [52], 'Regulation': [53], '(GDPR).': [54], 'A': [55], 'prerequisite': [56], 'for': [57, 112], 'GDPR': [58], 'checking': [60, 99, 115], 'is': [61, 71, 100], 'verify': [63], 'whether': [64], 'content': [66, 174], 'policy': [70], 'complete': [72], 'according': [73], 'provisions': [76, 132], 'GDPR.': [78], 'Incomplete': [79], 'might': [82], 'result': [83], 'large': [85], 'fines': [86], 'on': [87, 151], 'violating': [88], 'as': [90, 92], 'well': [91], 'incomplete': [93], 'specifications.': [96], 'Manual': [97], 'completeness': [98, 114, 143, 184, 220], 'both': [101], 'time-consuming': [102], 'and': [103, 139, 164, 178, 236, 259], 'error-prone.': [104], 'this': [106], 'paper,': [107], 'we': [108, 123, 146, 169, 190], 'propose': [109], 'AI-based': [110], 'automation': [111], 'policies.': [118], 'Through': [119], 'systematic': [120], 'qualitative': [121], 'methods,': [122], 'first': [124], 'build': [125], 'two': [126], 'artifacts': [127, 155], 'characterize': [129], 'GDPR,': [134], 'namely': [135], 'conceptual': [137], 'model': [138], 'set': [141, 202], 'criteria.': [144, 185], 'Then,': [145], 'develop': [147], 'automated': [149], 'solution': [150], 'top': [152], 'these': [154], 'leveraging': [157], 'combination': [159], 'natural': [161], 'language': [162], 'processing': [163], 'supervised': [165], 'machine': [166], 'learning.': [167], 'Specifically,': [168], 'identify': [170], 'GDPR-relevant': [172], 'subsequently': [179], 'check': [180], 'them': [181], 'against': [182], 'To': [186], 'evaluate': [187], 'our': [188, 208, 249], 'approach,': [189], 'collected': [191], '234': [192], 'real': [193], 'from': [196], 'fund': [198], 'industry.': [199], 'Over': [200], '48': [204], 'unseen': [205], 'policies,': [207], 'approach': [209, 229, 250], 'detected': [210], '300': [211], 'total': [214], '334': [216], 'violations': [217], 'some': [219], 'criteria': [221], 'correctly,': [222], 'while': [223], 'producing': [224], '23': [225], 'false': [226], 'positives.': [227], 'The': [228], 'thus': [230], 'has': [231], 'precision': [233, 258], '92.9%': [235], 'recall': [237], '89.8%.': [239], 'Compared': [240], 'baseline': [243], 'that': [244], 'applies': [245], 'keyword': [246], 'search': [247], 'only,': [248], 'results': [251], 'improvement': [254], '24.5%': [256], '38%': [260], 'recall.': [262]}",2021,"['Computer science', 'Privacy policy', 'Completeness (order theory)', 'General Data Protection Regulation', 'Information privacy', 'Privacy software', 'Privacy by Design', 'Computer security', 'Privacy law', 'Data Protection Act 1998', 'Mathematical analysis', 'Mathematics']","Technological advances in information sharing have raised concerns about data protection. Privacy policies contain privacy-related requirements about how the personal data of individuals will be handled by an organization or a software system (e.g., a web service or an app). In Europe, privacy policies are subject to compliance with the General Data Protection Regulation (GDPR). A prerequisite for GDPR compliance checking is to verify whether the content of a privacy policy is complete according to the provisions of GDPR. Incomplete privacy policies might result in large fines on violating organization as well as incomplete privacy-related software specifications. Manual completeness checking is both time-consuming and error-prone. In this paper, we propose AI-based automation for the completeness checking of privacy policies. Through systematic qualitative methods, we first build two artifacts to characterize the privacy-related provisions of GDPR, namely a conceptual model and a set of completeness criteria. Then, we develop an automated solution on top of these artifacts by leveraging a combination of natural language processing and supervised machine learning. Specifically, we identify the GDPR-relevant information content in privacy policies and subsequently check them against the completeness criteria. To evaluate our approach, we collected 234 real privacy policies from the fund industry. Over a set of 48 unseen privacy policies, our approach detected 300 of the total of 334 violations of some completeness criteria correctly, while producing 23 false positives. The approach thus has a precision of 92.9% and recall of 89.8%. Compared to a baseline that applies keyword search only, our approach results in an improvement of 24.5% in precision and 38% in recall."
https://openalex.org/W4383895105,Privacy and Data Protection in ChatGPT and Other AI Chatbots,"{'The': [0, 92], 'evolution': [1], 'of': [2, 15, 36, 45, 59, 68, 98, 112], 'artificial': [3, 139], 'intelligence': [4], '(AI)': [5], 'and': [6, 39, 78, 88, 129], 'machine': [7, 69], 'learning': [8, 70], '(ML)': [9], 'has': [10], 'led': [11], 'to': [12, 101, 106, 120, 132], 'the': [13, 33, 43, 56, 66, 110, 133], 'development': [14], 'sophisticated': [16], 'large': [17], 'language': [18], 'models': [19], '(LLMs)': [20], 'that': [21], 'are': [22], 'used': [23], 'extensively': [24], 'in': [25, 42, 138], 'applications': [26], 'such': [27, 82], 'as': [28, 83, 122], 'chatbots.': [29], 'This': [30, 116], 'research': [31], 'investigates': [32], 'critical': [34], 'issues': [35], 'data': [37, 89, 107, 136], 'protection': [38, 137], 'privacy': [40, 108], 'enhancement': [41], 'context': [44], 'LLM-based': [46, 114], 'chatbots,': [47], 'with': [48, 109], 'a': [49, 96, 123], 'focus': [50], 'on': [51, 135], ""OpenAI's"": [52], 'ChatGPT.': [53], 'It': [54, 72], 'explores': [55], 'dual': [57], 'challenges': [58], 'safeguarding': [60], 'sensitive': [61], 'user': [62], 'information': [63], 'while': [64], 'ensuring': [65], 'efficiency': [67], 'models.': [71], 'assesses': [73], 'existing': [74], 'privacy-enhancing': [75], 'technologies': [76], '(PETs)': [77], 'proposes': [79], 'innovative': [80], 'methods,': [81], 'differential': [84], 'privacy,': [85], 'federated': [86], 'learning,': [87], 'minimization': [90], 'techniques.': [91], 'study': [93, 117], 'also': [94], 'includes': [95], 'survey': [97], 'Chatbot': [99], 'users': [100], 'measure': [102], 'their': [103], 'concerns': [104], 'related': [105], 'use': [111], 'these': [113], 'applications.': [115], 'is': [118], 'meant': [119], 'serve': [121], 'comprehensive': [124], 'guide': [125], 'for': [126], 'developers,': [127], 'policymakers,': [128], 'researchers,': [130], 'contributing': [131], 'discourse': [134], 'intelligence.': [140]}",2023,"['Safeguarding', 'Chatbot', 'Computer science', 'Context (archaeology)', 'Information privacy', 'Data Protection Act 1998', 'Internet privacy', 'Data science', 'Privacy by Design', 'Differential privacy', 'Computer security', 'Artificial intelligence', 'Data mining', 'Nursing', 'Paleontology', 'Biology', 'Medicine']","The evolution of artificial intelligence (AI) and machine learning (ML) has led to the development of sophisticated large language models (LLMs) that are used extensively in applications such as chatbots. This research investigates the critical issues of data protection and privacy enhancement in the context of LLM-based chatbots, with a focus on OpenAI's ChatGPT. It explores the dual challenges of safeguarding sensitive user information while ensuring the efficiency of machine learning models. It assesses existing privacy-enhancing technologies (PETs) and proposes innovative methods, such as differential privacy, federated learning, and data minimization techniques. The study also includes a survey of Chatbot users to measure their concerns related to data privacy with the use of these LLM-based applications. This study is meant to serve as a comprehensive guide for developers, policymakers, and researchers, contributing to the discourse on data protection in artificial intelligence."
https://openalex.org/W4387461693,"Artificial Intelligence (AI) Trust Framework and Maturity Model: Applying an Entropy Lens to Improve Security, Privacy, and Ethical AI","{'Recent': [0], 'advancements': [1], 'in': [2, 38, 59, 68, 91, 99, 110, 118, 135, 144, 153, 162, 178], 'artificial': [3], 'intelligence': [4], '(AI)': [5], 'technology': [6, 37], 'have': [7], 'raised': [8], 'concerns': [9], 'about': [10, 78], 'the': [11, 60, 89, 171, 179], 'ethical,': [12], 'moral,': [13], 'and': [14, 28, 33, 51, 62, 76, 94, 97, 120, 133, 139, 181], 'legal': [15], 'safeguards.': [16], 'There': [17], 'is': [18, 54], 'a': [19, 39], 'pressing': [20], 'need': [21], 'to': [22, 34, 56, 87, 130, 150, 159, 169, 175], 'improve': [23, 131, 151], 'metrics': [24], 'for': [25], 'assessing': [26], 'security': [27], 'privacy': [29], 'of': [30, 64, 183], 'AI': [31, 36, 48, 65, 69, 102, 111, 154, 172, 184], 'systems': [32, 112], 'manage': [35], 'more': [40], 'ethical': [41, 106], 'manner.': [42], 'To': [43], 'address': [44], 'these': [45], 'challenges,': [46], 'an': [47, 71, 84], 'Trust': [49, 67], 'Framework': [50], 'Maturity': [52], 'Model': [53], 'proposed': [55], 'enhance': [57, 95], 'trust': [58, 98, 132, 152, 177], 'design': [61, 180], 'management': [63, 182], 'systems.': [66, 146, 185], 'involves': [70], 'agreed-upon': [72], 'understanding': [73], 'between': [74], 'humans': [75], 'machines': [77], 'system': [79], 'performance.': [80], 'The': [81, 123], 'framework': [82], 'utilizes': [83], '“entropy': [85], 'lens”': [86], 'root': [88], 'study': [90], 'information': [92], 'theory': [93], 'transparency': [96], '“black': [100], 'box”': [101], 'systems,': [103, 140], 'which': [104], 'lack': [105], 'guardrails.': [107], 'High': [108], 'entropy': [109, 128], 'can': [113], 'decrease': [114], 'human': [115], 'trust,': [116], 'particularly': [117], 'uncertain': [119], 'competitive': [121], 'environments.': [122], 'research': [124], 'draws': [125], 'inspiration': [126], 'from': [127], 'studies': [129], 'performance': [134, 161], 'autonomous': [136], 'human–machine': [137], 'teams': [138], 'including': [141], 'interconnected': [142], 'elements': [143], 'hierarchical': [145], 'Applying': [147], 'this': [148], 'lens': [149], 'also': [155], 'highlights': [156], 'new': [157], 'opportunities': [158], 'optimize': [160], 'teams.': [163], 'Two': [164], 'use': [165], 'cases': [166], 'are': [167], 'described': [168], 'validate': [170], 'framework’s': [173], 'ability': [174], 'measure': [176]}",2023,"['Computer science', 'Transparency (behavior)', 'Through-the-lens metering', 'Entropy (arrow of time)', 'Artificial intelligence', 'Maturity (psychological)', 'Trust management (information system)', 'Knowledge management', 'Computer security', 'Lens (geology)', 'Engineering', 'Psychology', 'Physics', 'Quantum mechanics', 'Developmental psychology', 'Petroleum engineering']","Recent advancements in artificial intelligence (AI) technology have raised concerns about the ethical, moral, and legal safeguards. There is a pressing need to improve metrics for assessing security and privacy of AI systems and to manage AI technology in a more ethical manner. To address these challenges, an AI Trust Framework and Maturity Model is proposed to enhance trust in the design and management of AI systems. Trust in AI involves an agreed-upon understanding between humans and machines about system performance. The framework utilizes an “entropy lens” to root the study in information theory and enhance transparency and trust in “black box” AI systems, which lack ethical guardrails. High entropy in AI systems can decrease human trust, particularly in uncertain and competitive environments. The research draws inspiration from entropy studies to improve trust and performance in autonomous human–machine teams and systems, including interconnected elements in hierarchical systems. Applying this lens to improve trust in AI also highlights new opportunities to optimize performance in teams. Two use cases are described to validate the AI framework’s ability to measure trust in the design and management of AI systems."
https://openalex.org/W4396215553,Transparency and Privacy: The Role of Explainable AI and Federated Learning in Financial Fraud Detection,"{'Fraudulent': [0], 'transactions': [1, 60, 79, 171], 'and': [2, 27, 44, 63, 151, 181, 199, 209, 241], 'how': [3], 'to': [4, 24, 99, 110, 115, 155, 163, 168, 211], 'detect': [5, 169], 'them': [6], 'remain': [7], 'a': [8, 49, 117, 144, 166, 205], 'significant': [9, 75], 'problem': [10], 'for': [11, 19, 33], 'financial': [12, 34, 106, 161], 'institutions': [13, 107, 162], 'around': [14], 'the': [15, 40, 56, 88, 93, 100, 124, 137, 184, 190, 194, 212, 223, 245], 'world.': [16], 'The': [17], 'need': [18], 'advanced': [20], 'fraud': [21, 46, 94, 125, 225], 'detection': [22, 47, 95, 126, 226], 'systems': [23, 48], 'safeguard': [25], 'assets': [26], 'maintain': [28], 'customer': [29, 113, 175], 'trust': [30, 210], 'is': [31, 55, 121], 'paramount': [32], 'institutions,': [35], 'but': [36], 'some': [37], 'factors': [38, 54], 'make': [39], 'development': [41], 'of': [42, 52, 77, 92, 186, 207], 'effective': [43, 240], 'efficient': [45], 'challenge.': [50], 'One': [51], 'such': [53], 'fact': [57], 'that': [58, 64, 70, 104, 132, 189, 222], 'fraudulent': [59, 78, 170], 'are': [61, 68, 73, 108], 'rare': [62], 'many': [65], 'transaction': [66, 219], 'datasets': [67], 'imbalanced;': [69], 'is,': [71], 'there': [72], 'fewer': [74], 'samples': [76], 'than': [80], 'legitimate': [81], 'ones.': [82], 'This': [83, 233], 'data': [84, 101, 114, 179], 'imbalance': [85], 'can': [86, 196], 'affect': [87, 136], 'performance': [89, 231], 'or': [90], 'reliability': [91], 'model.': [96], 'Moreover,': [97], 'due': [98], 'privacy': [102, 180], 'laws': [103], 'all': [105], 'subject': [109], 'follow,': [111], 'sharing': [112, 174], 'facilitate': [116], 'higher-performing': [118], 'centralized': [119], 'model': [120, 167, 195], 'impossible.': [122], 'Furthermore,': [123], 'technique': [127], 'should': [128], 'be': [129, 197], 'transparent': [130], 'so': [131], 'it': [133], 'does': [134], 'not': [135], 'user': [138], 'experience.': [139], 'Hence,': [140], 'this': [141], 'research': [142], 'introduces': [143], 'novel': [145], 'approach': [146], 'using': [147], 'Federated': [148], 'Learning': [149], '(FL)': [150], 'Explainable': [152], 'AI': [153], '(XAI)': [154], 'address': [156], 'these': [157], 'challenges.': [158], 'FL': [159], 'enables': [160], 'collaboratively': [164], 'train': [165], 'without': [172], 'directly': [173], 'data,': [176], 'thereby': [177], 'preserving': [178], 'confidentiality.': [182], 'Meanwhile,': [183], 'integration': [185], 'XAI': [187], 'ensures': [188], 'predictions': [191], 'made': [192], 'by': [193, 201], 'understood': [198], 'interpreted': [200], 'human': [202], 'experts,': [203], 'adding': [204], 'layer': [206], 'transparency': [208], 'system.': [213], 'Experimental': [214], 'results,': [215], 'based': [216], 'on': [217], 'realistic': [218], 'datasets,': [220], 'reveal': [221], 'FL-based': [224], 'system': [227], 'consistently': [228], 'demonstrates': [229], 'high': [230], 'metrics.': [232], 'study': [234], 'grounds': [235], 'FL&#x2019;s': [236], 'potential': [237], 'as': [238], 'an': [239], 'privacy-preserving': [242], 'tool': [243], 'in': [244], 'fight': [246], 'against': [247], 'fraud.': [248]}",2024,"['Transparency (behavior)', 'Computer science', 'Internet privacy', 'Information privacy', 'Computer security', 'Accounting', 'Business']","Fraudulent transactions and how to detect them remain a significant problem for financial institutions around the world. The need for advanced fraud detection systems to safeguard assets and maintain customer trust is paramount for financial institutions, but some factors make the development of effective and efficient fraud detection systems a challenge. One of such factors is the fact that fraudulent transactions are rare and that many transaction datasets are imbalanced; that is, there are fewer significant samples of fraudulent transactions than legitimate ones. This data imbalance can affect the performance or reliability of the fraud detection model. Moreover, due to the data privacy laws that all financial institutions are subject to follow, sharing customer data to facilitate a higher-performing centralized model is impossible. Furthermore, the fraud detection technique should be transparent so that it does not affect the user experience. Hence, this research introduces a novel approach using Federated Learning (FL) and Explainable AI (XAI) to address these challenges. FL enables financial institutions to collaboratively train a model to detect fraudulent transactions without directly sharing customer data, thereby preserving data privacy and confidentiality. Meanwhile, the integration of XAI ensures that the predictions made by the model can be understood and interpreted by human experts, adding a layer of transparency and trust to the system. Experimental results, based on realistic transaction datasets, reveal that the FL-based fraud detection system consistently demonstrates high performance metrics. This study grounds FL&#x2019;s potential as an effective and privacy-preserving tool in the fight against fraud."
https://openalex.org/W3092011919,An AI-assisted Approach for Checking the Completeness of Privacy Policies Against GDPR,"{'Privacy': [0], 'policies': [1, 17, 140, 194, 219], 'are': [2, 18], 'critical': [3], 'for': [4, 49, 81, 89, 125, 132], 'helping': [5], 'individuals': [6], 'make': [7], 'informed': [8], 'decisions': [9], 'about': [10], 'their': [11], 'personal': [12], 'data.': [13], 'In': [14, 69], 'Europe,': [15], 'privacy': [16, 37, 82, 97, 126, 139, 169, 193, 218], 'subject': [19], 'to': [20, 102, 117], 'compliance': [21, 79], 'with': [22, 40], 'the': [23, 56, 67, 92, 103, 119, 134, 146, 150, 196, 209, 216, 227], 'General': [24], 'Data': [25], 'Protection': [26], 'Regulation': [27], '(GDPR).': [28], 'If': [29], 'done': [30], 'entirely': [31], 'manually,': [32], 'checking': [33, 80, 90, 143], 'whether': [34, 91], 'a': [35, 95, 114, 163, 175, 237], 'given': [36, 96], 'policy': [38, 98], 'complies': [39], 'GDPR': [41, 78, 124, 138], 'is': [42, 52, 59, 99, 188], 'both': [43], 'time-consuming': [44], 'and': [45, 141, 155, 181, 241], 'error-prone.': [46], 'Automated': [47], 'support': [48, 65, 88], 'this': [50, 70], 'task': [51], 'thus': [53, 235], 'advantageous.': [54], 'At': [55], 'moment,': [57], 'there': [58], 'an': [60, 74, 129, 157], 'evident': [61], 'lack': [62], 'of': [63, 77, 94, 153, 159, 177, 190, 208, 211, 239, 243], 'such': [64], 'on': [66], 'market.': [68], 'paper,': [71], 'we': [72, 85, 111, 173], 'tackle': [73], 'important': [75], 'dimension': [76], 'policies.': [83, 170], 'Specifically,': [84], 'provide': [86], 'automated': [87], 'content': [93, 121, 136, 148], 'complete': [100], 'according': [101], 'provisions': [104], 'stipulated': [105], 'by': [106, 123], 'GDPR.': [107], 'To': [108], 'do': [109], 'so,': [110], 'present:': [112], '(1)': [113], 'conceptual': [115], 'model': [116], 'characterize': [118], 'information': [120, 135], 'envisaged': [122], 'policies,': [127, 226], '(2)': [128], 'AI-assisted': [130], 'approach': [131, 161, 205, 228, 234], 'classifying': [133], 'in': [137, 215], 'subsequently': [142], 'how': [144], 'well': [145], 'classified': [147], 'meets': [149], 'completeness': [151], 'criteria': [152], 'interest;': [154], '(3)': [156], 'evaluation': [158], 'our': [160, 204, 246], 'through': [162], 'case': [164, 247], 'study': [165], 'over': [166, 245], '24': [167, 217], 'unseen': [168], 'For': [171], 'classification,': [172], 'leverage': [174], 'combination': [176], 'Natural': [178], 'Language': [179], 'Processing': [180], 'supervised': [182], 'Machine': [183], 'Learning.': [184], 'Our': [185, 199], 'experimental': [186], 'material': [187], 'comprised': [189], '234': [191], 'real': [192], 'from': [195], 'fund': [197], 'industry.': [198], 'empirical': [200], 'results': [201], 'indicate': [202], 'that': [203], 'detected': [206], '45': [207], 'total': [210], '47': [212], 'incompleteness': [213], 'issues': [214], 'it': [220], 'was': [221], 'applied': [222], 'to.': [223], 'Over': [224], 'these': [225], 'had': [229], 'eight': [230], 'false': [231], 'positives.': [232], 'The': [233], 'has': [236], 'precision': [238], '85%': [240], 'recall': [242], '96%': [244], 'study.': [248]}",2020,"['Computer science', 'Privacy policy', 'General Data Protection Regulation', 'Information privacy', 'Leverage (statistics)', 'Computer security', 'Privacy by Design', 'Privacy software', 'Privacy law', 'Completeness (order theory)', 'Internet privacy', 'Artificial intelligence', 'Data Protection Act 1998', 'Mathematical analysis', 'Mathematics']","Privacy policies are critical for helping individuals make informed decisions about their personal data. In Europe, privacy policies are subject to compliance with the General Data Protection Regulation (GDPR). If done entirely manually, checking whether a given privacy policy complies with GDPR is both time-consuming and error-prone. Automated support for this task is thus advantageous. At the moment, there is an evident lack of such support on the market. In this paper, we tackle an important dimension of GDPR compliance checking for privacy policies. Specifically, we provide automated support for checking whether the content of a given privacy policy is complete according to the provisions stipulated by GDPR. To do so, we present: (1) a conceptual model to characterize the information content envisaged by GDPR for privacy policies, (2) an AI-assisted approach for classifying the information content in GDPR privacy policies and subsequently checking how well the classified content meets the completeness criteria of interest; and (3) an evaluation of our approach through a case study over 24 unseen privacy policies. For classification, we leverage a combination of Natural Language Processing and supervised Machine Learning. Our experimental material is comprised of 234 real privacy policies from the fund industry. Our empirical results indicate that our approach detected 45 of the total of 47 incompleteness issues in the 24 privacy policies it was applied to. Over these policies, the approach had eight false positives. The approach thus has a precision of 85% and recall of 96% over our case study."
https://openalex.org/W4383176079,From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy,"{'Undoubtedly,': [0], 'the': [1, 10, 16, 20, 51, 58, 68, 81, 91, 100, 116, 120, 137, 148, 157, 224, 234, 252], 'evolution': [2], 'of': [3, 12, 53, 63, 88, 93, 102, 230], 'Generative': [4], 'AI': [5], '(GenAI)': [6], 'models': [7, 23], 'has': [8], 'been': [9], 'highlight': [11], 'digital': [13], 'transformation': [14], 'in': [15, 56, 90, 151], 'year': [17], '2022.': [18], 'As': [19], 'different': [21], 'GenAI': [22, 54, 89, 149, 191, 245], 'like': [24, 128], 'ChatGPT': [25, 160], 'and': [26, 34, 60, 65, 71, 86, 95, 132, 155, 180, 189, 207, 217, 227, 239, 249], 'Google': [27], 'Bard': [28], 'continue': [29], 'to': [30, 38, 111, 166, 193, 242], 'foster': [31], 'their': [32], 'complexity': [33], 'capability,': [35], ""it's"": [36], 'critical': [37], 'understand': [39], 'its': [40, 255], 'consequences': [41], 'from': [42], 'a': [43], 'cybersecurity': [44, 94, 256], 'perspective.': [45], 'Several': [46], 'instances': [47], 'recently': [48], 'have': [49], 'demonstrated': [50], 'use': [52, 147], 'tools': [55, 150, 192], 'both': [57], 'defensive': [59], 'offensive': [61], 'side': [62], 'cybersecurity,': [64], 'focusing': [66], 'on': [67, 119, 136], 'social,': [69, 225], 'ethical': [70, 117, 212, 228, 250], 'privacy': [72], 'implications': [73, 229], 'this': [74, 244], 'technology': [75], 'possesses.': [76], 'This': [77, 122, 183], 'research': [78], 'paper': [79, 123, 140, 184, 235], 'highlights': [80, 236], 'limitations,': [82], 'challenges,': [83], 'potential': [84], 'risks,': [85], 'opportunities': [87], 'domain': [92], 'privacy.': [96], 'The': [97, 139], 'work': [98], 'presents': [99], 'vulnerabilities': [101], 'ChatGPT,': [103], 'which': [104], 'can': [105, 146, 161], 'be': [106, 162], 'exploited': [107], 'by': [108, 164], 'malicious': [109, 113], 'users': [110], 'exfiltrate': [112], 'information': [114], 'bypassing': [115], 'constraints': [118], 'model.': [121], 'demonstrates': [124], 'successful': [125], 'example': [126], 'attacks': [127, 135], 'Jailbreaks,': [129], 'reverse': [130], 'psychology,': [131], 'prompt': [133], 'injection': [134], 'ChatGPT.': [138, 231], 'also': [141, 222], 'investigates': [142], 'how': [143], 'cyber': [144, 153, 198], 'offenders': [145], 'developing': [152, 211], 'attacks,': [154, 170, 172], 'explore': [156], 'scenarios': [158], 'where': [159], 'used': [163], 'adversaries': [165], 'create': [167], 'social': [168], 'engineering': [169], 'phishing': [171], 'automated': [173], 'hacking,': [174], 'attack': [175, 209], 'payload': [176], 'generation,': [177], 'malware': [178, 218], 'creation,': [179], 'polymorphic': [181], 'malware.': [182], 'then': [185], 'examines': [186], 'defense': [187, 199], 'techniques': [188], 'uses': [190], 'improve': [194], 'security': [195], 'measures,': [196], 'including': [197], 'automation,': [200], 'reporting,': [201], 'threat': [202], 'intelligence,': [203], 'secure': [204], 'code': [205], 'generation': [206], 'detection,': [208], 'identification,': [210], 'guidelines,': [213], 'incidence': [214], 'response': [215], 'plans,': [216], 'detection.': [219], 'We': [220], 'will': [221], 'discuss': [223], 'legal,': [226], 'In': [232], 'conclusion,': [233], 'open': [237], 'challenges': [238], 'future': [240], 'directions': [241], 'make': [243], 'secure,': [246], 'safe,': [247], 'trustworthy,': [248], 'as': [251], 'community': [253], 'understands': [254], 'impacts.': [257]}",2023,"['Computer security', 'Phishing', 'Malware', 'Computer science', 'Hacker', 'Offensive', 'Social engineering (security)', 'Internet privacy', 'Cyber-attack', 'The Internet', 'Engineering', 'World Wide Web', 'Operations research']","Undoubtedly, the evolution of Generative AI (GenAI) models has been the highlight of digital transformation in the year 2022. As the different GenAI models like ChatGPT and Google Bard continue to foster their complexity and capability, it's critical to understand its consequences from a cybersecurity perspective. Several instances recently have demonstrated the use of GenAI tools in both the defensive and offensive side of cybersecurity, and focusing on the social, ethical and privacy implications this technology possesses. This research paper highlights the limitations, challenges, potential risks, and opportunities of GenAI in the domain of cybersecurity and privacy. The work presents the vulnerabilities of ChatGPT, which can be exploited by malicious users to exfiltrate malicious information bypassing the ethical constraints on the model. This paper demonstrates successful example attacks like Jailbreaks, reverse psychology, and prompt injection attacks on the ChatGPT. The paper also investigates how cyber offenders can use the GenAI tools in developing cyber attacks, and explore the scenarios where ChatGPT can be used by adversaries to create social engineering attacks, phishing attacks, automated hacking, attack payload generation, malware creation, and polymorphic malware. This paper then examines defense techniques and uses GenAI tools to improve security measures, including cyber defense automation, reporting, threat intelligence, secure code generation and detection, attack identification, developing ethical guidelines, incidence response plans, and malware detection. We will also discuss the social, legal, and ethical implications of ChatGPT. In conclusion, the paper highlights open challenges and future directions to make this GenAI secure, safe, trustworthy, and ethical as the community understands its cybersecurity impacts."
https://openalex.org/W3048763337,Privacy Issues of AI,"{'This': [0], 'chapter': [1], 'sheds': [2], 'light': [3], 'on': [4], 'how': [5], 'private': [6], 'data': [7, 35], 'is': [8, 42], 'systematically': [9], 'collected,': [10], 'stored': [11], 'and': [12, 29], 'analysed': [13], 'with': [14], 'the': [15, 44], 'help': [16], 'of': [17, 24], 'artificial': [18], 'intelligence.': [19], 'We': [20], 'discuss': [21], 'various': [22], 'forms': [23], 'persistent': [25], 'surveillance': [26], 'at': [27], 'home': [28], 'in': [30], 'public': [31], 'spaces.': [32], 'While': [33], 'massive': [34], 'collection': [36], 'raises': [37], 'considerable': [38], 'ethical': [39], 'concerns,': [40], 'it': [41], 'also': [43], 'basis': [45], 'for': [46, 49], 'better': [47], 'performance': [48], 'AI': [50], 'systems.': [51]}",2020,"['Internet privacy', 'Computer science', 'Data science', 'Data collection', 'Computer security', 'Political science', 'Sociology', 'Social science']","This chapter sheds light on how private data is systematically collected, stored and analysed with the help of artificial intelligence. We discuss various forms of persistent surveillance at home and in public spaces. While massive data collection raises considerable ethical concerns, it is also the basis for better performance for AI systems."
https://openalex.org/W4360765051,AI privacy preserving robots working in a smart sensor environment,"{'sponsorship:': [0], 'This': [1], 'research': [2], 'received': [3], 'funding': [4], 'from': [5], 'the': [6], 'Flemish': [7], 'regional': [8, 14], 'government': [9, 15], '(AI': [10, 16], 'Research': [11, 17], 'Program).': [12], '(Flemish': [13], 'Program))': [18]}",2022,"['Computer science', 'Robot', 'Broadcasting (networking)', 'Bandwidth (computing)', 'Real-time computing', 'Inference', 'Information privacy', 'Artificial intelligence', 'Embedded system', 'Computer network', 'Computer security']",sponsorship: This research received funding from the Flemish regional government (AI Research Program). (Flemish regional government (AI Research Program))
https://openalex.org/W4404024323,Privacy-Preserving Techniques in Generative AI and Large Language Models: A Narrative Review,"{'Generative': [0], 'AI,': [1, 48, 147, 186], 'including': [2, 90], 'large': [3, 189], 'language': [4, 190], 'models': [5, 26], '(LLMs),': [6], 'has': [7], 'transformed': [8], 'the': [9, 85, 114, 117, 137, 148, 151, 167, 182], 'paradigm': [10], 'of': [11, 38, 119, 142, 184], 'data': [12, 44, 72, 132], 'generation': [13], 'and': [14, 60, 74, 93, 125, 139, 161, 172, 196], 'creative': [15], 'content,': [16], 'but': [17], 'this': [18], 'progress': [19], 'raises': [20], 'critical': [21], 'privacy': [22, 45, 52, 101, 110, 143, 162], 'concerns,': [23], 'especially': [24, 187], 'when': [25], 'are': [27, 79], 'trained': [28], 'on': [29], 'sensitive': [30], 'data.': [31], 'This': [32], 'review': [33, 86, 115, 149], 'provides': [34], 'a': [35, 154], 'comprehensive': [36], 'overview': [37], 'privacy-preserving': [39, 176], 'techniques': [40, 66, 177], 'aimed': [41], 'at': [42], 'safeguarding': [43], 'in': [46, 102, 145, 188], 'generative': [47, 103, 146, 185], 'such': [49], 'as': [50, 96], 'differential': [51], '(DP),': [53], 'federated': [54], 'learning': [55], '(FL),': [56], 'homomorphic': [57], 'encryption': [58], '(HE),': [59], 'secure': [61], 'multi-party': [62], 'computation': [63], '(SMPC).': [64], 'These': [65], 'mitigate': [67], 'risks': [68, 144], 'like': [69], 'model': [70], 'inversion,': [71], 'leakage,': [73], 'membership': [75], 'inference': [76], 'attacks,': [77], 'which': [78], 'particularly': [80], 'relevant': [81], 'to': [82, 128, 174, 194], 'LLMs.': [83], 'Additionally,': [84], 'explores': [87], 'emerging': [88], 'solutions,': [89], 'privacy-enhancing': [91], 'technologies': [92], 'post-quantum': [94], 'cryptography,': [95], 'future': [97], 'directions': [98], 'for': [99, 153, 169], 'enhancing': [100], 'AI': [104], 'systems.': [105], 'Recognizing': [106], 'that': [107, 157, 178], 'achieving': [108], 'absolute': [109], 'is': [111], 'mathematically': [112], 'impossible,': [113], 'emphasizes': [116], 'necessity': [118], 'aligning': [120], 'technical': [121], 'safeguards': [122], 'with': [123, 131, 181], 'legal': [124, 140], 'regulatory': [126, 195], 'frameworks': [127], 'ensure': [129], 'compliance': [130], 'protection': [133], 'laws.': [134], 'By': [135], 'discussing': [136], 'ethical': [138, 197], 'implications': [141], 'underscores': [150], 'need': [152, 168], 'balanced': [155], 'approach': [156], 'considers': [158], 'performance,': [159], 'scalability,': [160], 'preservation.': [163], 'The': [164], 'findings': [165], 'highlight': [166], 'ongoing': [170], 'research': [171], 'innovation': [173], 'develop': [175], 'keep': [179], 'pace': [180], 'scaling': [183], 'models,': [191], 'while': [192], 'adhering': [193], 'standards.': [198]}",2024,"['Generative grammar', 'Narrative', 'Computer science', 'Linguistics', 'Natural language processing', 'Artificial intelligence', 'Philosophy']","Generative AI, including large language models (LLMs), has transformed the paradigm of data generation and creative content, but this progress raises critical privacy concerns, especially when models are trained on sensitive data. This review provides a comprehensive overview of privacy-preserving techniques aimed at safeguarding data privacy in generative AI, such as differential privacy (DP), federated learning (FL), homomorphic encryption (HE), and secure multi-party computation (SMPC). These techniques mitigate risks like model inversion, data leakage, and membership inference attacks, which are particularly relevant to LLMs. Additionally, the review explores emerging solutions, including privacy-enhancing technologies and post-quantum cryptography, as future directions for enhancing privacy in generative AI systems. Recognizing that achieving absolute privacy is mathematically impossible, the review emphasizes the necessity of aligning technical safeguards with legal and regulatory frameworks to ensure compliance with data protection laws. By discussing the ethical and legal implications of privacy risks in generative AI, the review underscores the need for a balanced approach that considers performance, scalability, and privacy preservation. The findings highlight the need for ongoing research and innovation to develop privacy-preserving techniques that keep pace with the scaling of generative AI, especially in large language models, while adhering to regulatory and ethical standards."
https://openalex.org/W4399906749,Reconciling privacy and accuracy in AI for medical imaging,"{'Abstract': [0], 'Artificial': [1], 'intelligence': [2, 119, 169], '(AI)': [3], 'models': [4, 44, 120, 170], 'are': [5, 153], 'vulnerable': [6], 'to': [7, 32, 110, 171, 178], 'information': [8, 78], 'leakage': [9], 'of': [10, 49, 53, 77, 86, 102, 117, 133], 'their': [11], 'training': [12, 43, 54], 'data,': [13], 'which': [14], 'can': [15, 144], 'be': [16], 'highly': [17], 'sensitive,': [18], 'for': [19, 42, 182], 'example,': [20], 'in': [21, 151], 'medical': [22], 'imaging.': [23], 'Privacy-enhancing': [24], 'technologies,': [25], 'such': [26, 87], 'as': [27], 'differential': [28], 'privacy': [29, 68, 104, 123, 142, 190], '(DP),': [30], 'aim': [31], 'circumvent': [33], 'these': [34], 'susceptibilities.': [35], 'DP': [36, 61, 161], 'is': [37, 164], 'the': [38, 47, 51, 58, 75, 84, 100, 115], 'strongest': [39], 'possible': [40], 'protection': [41], 'while': [45, 149], 'bounding': [46], 'risks': [48, 191], 'inferring': [50], 'inclusion': [52], 'samples': [55], 'or': [56], 'reconstructing': [57], 'original': [59], 'data.': [60, 173], 'achieves': [62], 'this': [63], 'by': [64], 'setting': [65], 'a': [66, 71, 91, 103, 180, 187], 'quantifiable': [67], 'budget.': [69], 'Although': [70], 'lower': [72], 'budget': [73, 105], 'decreases': [74], 'risk': [76, 128], 'leakage,': [79], 'it': [80], 'typically': [81], 'also': [82], 'reduces': [83], 'performance': [85, 95, 116, 152], 'models.': [88], 'This': [89], 'imposes': [90], 'trade-off': [92], 'between': [93, 189], 'robust': [94], 'and': [96, 108, 130, 192], 'stringent': [97], 'privacy.': [98], 'Additionally,': [99], 'interpretation': [101], 'remains': [106], 'abstract': [107], 'challenging': [109], 'contextualize.': [111], 'Here': [112], 'we': [113], 'contrast': [114], 'artificial': [118, 168], 'at': [121, 162], 'various': [122], 'budgets': [124, 143], 'against': [125], 'both': [126], 'theoretical': [127], 'bounds': [129], 'empirical': [131], 'success': [132], 'reconstruction': [134, 146], 'attacks.': [135], 'We': [136, 155, 174], 'show': [137], 'that': [138, 158], 'using': [139, 160], 'very': [140], 'large': [141], 'render': [145], 'attacks': [147], 'impossible,': [148], 'drops': [150], 'negligible.': [154], 'thus': [156], 'conclude': [157], 'not': [159], 'all': [163], 'negligent': [165], 'when': [166], 'applying': [167], 'sensitive': [172], 'deem': [175], 'our': [176], 'results': [177], 'lay': [179], 'foundation': [181], 'further': [183], 'debates': [184], 'on': [185], 'striking': [186], 'balance': [188], 'model': [193], 'performance.': [194]}",2024,"['Internet privacy', 'Computer security', 'Computer science', 'Business', 'Medicine']","Abstract Artificial intelligence (AI) models are vulnerable to information leakage of their training data, which can be highly sensitive, for example, in medical imaging. Privacy-enhancing technologies, such as differential privacy (DP), aim to circumvent these susceptibilities. DP is the strongest possible protection for training models while bounding the risks of inferring the inclusion of training samples or reconstructing the original data. DP achieves this by setting a quantifiable privacy budget. Although a lower budget decreases the risk of information leakage, it typically also reduces the performance of such models. This imposes a trade-off between robust performance and stringent privacy. Additionally, the interpretation of a privacy budget remains abstract and challenging to contextualize. Here we contrast the performance of artificial intelligence models at various privacy budgets against both theoretical risk bounds and empirical success of reconstruction attacks. We show that using very large privacy budgets can render reconstruction attacks impossible, while drops in performance are negligible. We thus conclude that not using DP at all is negligent when applying artificial intelligence models to sensitive data. We deem our results to lay a foundation for further debates on striking a balance between privacy risks and model performance."
https://openalex.org/W4404199748,Is AI-based digital marketing ethical? Assessing a new data privacy paradox,"{'The': [0, 73, 88, 107], 'rapid': [1], 'development': [2], 'of': [3, 28, 39, 63, 66, 93, 123, 141, 153, 171, 199, 222, 314], 'artificial': [4], 'intelligence': [5], '(AI)': [6], 'has': [7], 'significantly': [8], 'transformed': [9], 'digital': [10, 30, 130, 155, 286], 'marketing': [11], 'enhancing': [12], 'its': [13], 'effectiveness': [14], 'and': [15, 19, 80, 100, 120, 192, 226, 279, 319, 326], 'raising': [16], 'new': [17], 'ethical': [18, 26, 121, 294, 320], 'privacy': [20, 119, 181, 213, 253, 282], 'concerns.': [21], 'This': [22], 'study': [23, 140, 258], 'investigates': [24], 'the': [25, 61, 97, 104, 110, 139, 151, 160, 197, 217, 219, 230, 323], 'implications': [27], 'AI-based': [29, 129, 154, 285], 'marketing,': [31, 156], 'particularly': [32], 'focusing': [33], 'on': [34], 'user': [35, 118, 237, 309], 'privacy.': [36], 'In': [37], 'terms': [38], 'methodology,': [40], 'a': [41, 91, 113, 184, 249], 'systematic': [42], 'literature': [43], 'review': [44], '(SLR)': [45], 'was': [46], 'conducted': [47], 'to': [48, 180, 212, 233, 252, 299], 'identify': [49], 'relevant': [50], 'variables,': [51], 'followed': [52], 'by': [53], 'Multiple': [54], 'Correspondence': [55], 'Analysis': [56], '(MCA)': [57], 'using': [58, 68, 128], 'R': [59], 'within': [60], 'framework': [62], 'homogeneity': [64], 'analysis': [65, 75], 'variance': [67], 'alternating': [69], 'least': [70], 'squares': [71], '(HOMALS).': [72], 'MCA': [74, 89], 'identified': [76, 90], '3': [77], 'multivariate': [78], 'groupings,': [79], '21': [81, 260], 'individual': [82], 'variables': [83, 142, 228], 'extracted': [84], 'from': [85], '28': [86], 'studies.': [87], 'total': [92], '4': [94], 'clusters': [95, 102], 'in': [96, 103, 164, 203, 239, 284], 'eigenvalues/variances': [98], 'analysis,': [99], '5': [101], 'biplot': [105], 'analysis.': [106], 'findings': [108], 'emphasize': [109], 'need': [111, 232], 'for': [112, 307], 'balanced': [114], 'approach': [115], 'that': [116, 264], 'respects': [117], 'use': [122], 'data': [124, 303, 310, 324], 'when': [125], 'developing': [126, 172], 'actions': [127, 163], 'marketing.': [131, 287], 'However,': [132, 183], 'no': [133, 169], 'significant': [134], 'relationship': [135], 'is': [136, 168, 194, 209, 241, 297], 'evident': [137], 'between': [138, 187], 'such': [143], 'as': [144, 207, 244, 311], 'cross-device': [145], 'tracking': [146], 'or': [147, 177, 214, 254, 277], 'data-driven': [148], 'technologies': [149], 'and,': [150], 'ethics': [152], 'despite': [157], 'these': [158, 267, 290], 'being': [159, 242, 270], 'most': [161], 'profitable': [162], 'this': [165, 200, 204, 257], 'environment.': [166], 'There': [167], 'evidence': [170], 'personalized': [173], 'social': [174], 'media': [175], 'content': [176, 191], 'ads': [178], 'linked': [179, 211], 'standards.': [182], 'strong': [185, 220, 250], 'connection': [186], 'behavioral': [188], 'analytics,': [189], 'smart': [190], 'metaverse': [193], 'identified,': [195], 'highlighting': [196], 'risks': [198], 'emerging': [201], 'technology': [202], 'research': [205, 262], 'field,': [206], 'it': [208, 296], 'not': [210, 247], 'ethics.': [215, 255], 'Among': [216], 'results,': [218], 'proximity': [221], 'real-time': [223, 240], 'tracking,': [224], 'IoT,': [225], 'surveillance': [227], 'underscores': [229], 'critical': [231], 'ethically': [234, 271], 'understand': [235], 'how': [236], 'behavior': [238], 'monitored,': [243], 'they': [245], 'do': [246], 'offer': [248], 'link': [251], 'Additionally,': [256], 'provides': [259], 'future': [261], 'questions': [263], 'address': [265], 'whether': [266], 'practices': [268, 291], 'are': [269], 'implemented,': [272], 'following': [273], 'standards': [274], 'like': [275], '“privacy-by-default”': [276], '“privacy-by-design,”': [278], 'complying': [280], 'with': [281, 293], 'laws': [283], 'To': [288], 'ensure': [289], 'align': [292], 'standards,': [295], 'essential': [298], 'adopt': [300], 'frameworks': [301], 'prioritizing': [302], 'dignity,': [304], 'which': [305], 'calls': [306], 'treating': [308], 'an': [312], 'extension': [313], 'personal': [315], 'identity,': [316], 'requiring': [317], 'responsible': [318], 'handling': [321], 'throughout': [322], 'collection': [325], 'processing': [327], 'lifecycle.': [328]}",2024,"['Internet privacy', 'Information privacy', 'Consumer privacy', 'Psychology', 'Computer science', 'Business', 'Marketing']","The rapid development of artificial intelligence (AI) has significantly transformed digital marketing enhancing its effectiveness and raising new ethical and privacy concerns. This study investigates the ethical implications of AI-based digital marketing, particularly focusing on user privacy. In terms of methodology, a systematic literature review (SLR) was conducted to identify relevant variables, followed by Multiple Correspondence Analysis (MCA) using R within the framework of homogeneity analysis of variance using alternating least squares (HOMALS). The MCA analysis identified 3 multivariate groupings, and 21 individual variables extracted from 28 studies. The MCA identified a total of 4 clusters in the eigenvalues/variances analysis, and 5 clusters in the biplot analysis. The findings emphasize the need for a balanced approach that respects user privacy and ethical use of data when developing actions using AI-based digital marketing. However, no significant relationship is evident between the study of variables such as cross-device tracking or data-driven technologies and, the ethics of AI-based digital marketing, despite these being the most profitable actions in this environment. There is no evidence of developing personalized social media content or ads linked to privacy standards. However, a strong connection between behavioral analytics, smart content and metaverse is identified, highlighting the risks of this emerging technology in this research field, as it is not linked to privacy or ethics. Among the results, the strong proximity of real-time tracking, IoT, and surveillance variables underscores the critical need to ethically understand how user behavior in real-time is being monitored, as they do not offer a strong link to privacy or ethics. Additionally, this study provides 21 future research questions that address whether these practices are being ethically implemented, following standards like “privacy-by-default” or “privacy-by-design,” and complying with privacy laws in AI-based digital marketing. To ensure these practices align with ethical standards, it is essential to adopt frameworks prioritizing data dignity, which calls for treating user data as an extension of personal identity, requiring responsible and ethical handling throughout the data collection and processing lifecycle."
https://openalex.org/W2789589462,"An agent on my shoulder: AI, privacy and the application of human-like computing technologies to music creation","{'Human-Like': [0], 'Computing': [1], 'technologies': [2, 44, 55], 'are': [3, 34], 'intelligent': [4], 'systems': [5], 'that': [6, 42, 64, 74], 'interact': [7], 'with': [8], 'people': [9], 'in': [10, 28, 50, 79], 'human-like': [11], 'way.': [12], 'By': [13], 'bringing': [14], 'together': [15], 'the': [16, 40, 57, 68, 80], 'disciplines': [17], 'of': [18, 39, 70], 'Artificial': [19], 'Intelligence,': [20], 'Ethnography': [21], 'and': [22, 25, 60], 'Interaction': [23], 'Design,': [24], 'applying': [26], 'them': [27], 'a': [29, 62], 'real': [30], 'world': [31], 'context': [32], 'we': [33], 'able': [35, 76], 'to': [36, 56, 77], 'understand': [37], 'some': [38], 'ways': [41], 'such': [43, 54], 'can': [45], 'be': [46], 'applied.': [47], 'This': [48], 'work': [49], 'progress': [51], 'poster': [52], 'applies': [53], 'music': [58, 81], 'creation': [59, 82], 'develops': [61], 'design': [63], 'is': [65, 75], 'based': [66], 'on': [67], 'notion': [69], 'an': [71], '‘Intelligent’': [72], 'Agent': [73], 'support': [78], 'process.': [83]}",2017,"['Computer science', 'Process (computing)', 'Context (archaeology)', 'Intelligent agent', 'Ethnography', 'Ubiquitous computing', 'Human–computer interaction', 'Data science', 'Artificial intelligence', 'Sociology', 'Paleontology', 'Anthropology', 'Operating system', 'Biology']","Human-Like Computing technologies are intelligent systems that interact with people in human-like way. By bringing together the disciplines of Artificial Intelligence, Ethnography and Interaction Design, and applying them in a real world context we are able to understand some of the ways that such technologies can be applied. This work in progress poster applies such technologies to the music creation and develops a design that is based on the notion of an ‘Intelligent’ Agent that is able to support in the music creation process."
https://openalex.org/W4410721456,A Comparative Analysis of AI Privacy Concerns in Higher Education: News Coverage in China and Western Countries,"{'This': [0], 'study': [1], 'examines': [2], 'how': [3, 54], 'Chinese': [4, 106, 130], 'and': [5, 46, 67, 86, 98, 107, 113, 123, 138, 148, 185], 'Western': [6, 117], 'news': [7], 'media': [8, 55], 'covered': [9], 'artificial': [10], 'intelligence': [11], '(AI)': [12], 'privacy': [13, 40, 121, 162, 183], 'issues': [14], 'in': [15, 42, 58, 104, 125, 163], 'higher': [16, 164], 'education': [17, 145], 'from': [18, 26, 154], '2019': [19], 'to': [20, 36, 60, 79, 143, 175], '2024.': [21], 'News': [22], 'articles': [23], 'were': [24], 'retrieved': [25], 'Nexis': [27], 'Uni.': [28], 'First,': [29], 'non-negative': [30], 'matrix': [31], 'factorization': [32], '(NMF)': [33], 'was': [34, 77], 'employed': [35], 'identify': [37], 'core': [38], 'AI': [39, 153, 161, 180], 'topics': [41], 'university': [43], 'teaching,': [44], 'administration,': [45], 'research.': [47], 'Next,': [48], 'a': [49, 74, 169, 187], 'time': [50], 'trend': [51], 'analysis': [52, 76], 'investigated': [53], 'attention': [56], 'shifted': [57], 'relation': [59], 'key': [61], 'events,': [62], 'including': [63], 'the': [64, 68, 81, 111, 149, 177], 'COVID-19': [65], 'pandemic': [66], 'emergence': [69], 'of': [70, 83, 151, 179], 'generative': [71, 152], 'AI.': [72], 'Finally,': [73], 'sentiment': [75], 'conducted': [78], 'compare': [80], 'distribution': [82], 'positive,': [84], 'negative,': [85], 'neutral': [87], 'reporting.': [88], 'The': [89, 141, 166], 'findings': [90], 'indicate': [91], 'that': [92], 'AI-driven': [93, 135], 'proctoring,': [94], 'student': [95], 'data': [96, 191], 'security,': [97], 'institutional': [99], 'governance': [100, 192], 'are': [101], 'central': [102], 'concerns': [103], 'both': [105], 'English': [108], 'media.': [109], 'However,': [110], 'focus': [112], 'framing': [114], 'differ:': [115], 'some': [116], 'outlets': [118], 'highlight': [119], 'individual': [120], 'rights': [122], 'controversies': [124], 'remote': [126, 144], 'exam': [127], 'monitoring,': [128], 'while': [129], 'coverage': [131], 'more': [132], 'frequently': [133], 'addresses': [134], 'educational': [136], 'innovation': [137], 'policy': [139], 'support.': [140], 'shift': [142], 'after': [146], '2020': [147], 'rise': [150], '2023': [155], 'onward': [156], 'have': [157], 'intensified': [158], 'discussions': [159], 'on': [160], 'education.': [165], 'results': [167], 'offer': [168], 'cross-cultural': [170], 'perspective': [171], 'for': [172, 189], 'institutions': [173], 'seeking': [174], 'reconcile': [176], 'adoption': [178], 'with': [181], 'robust': [182], 'safeguards': [184], 'provide': [186], 'foundation': [188], 'future': [190], 'frameworks': [193], 'under': [194], 'diverse': [195], 'regulatory': [196], 'environments.': [197]}",2025,"['Framing (construction)', 'Corporate governance', 'China', 'Public relations', 'Political science', 'Big data', 'Internet privacy', 'Sociology', 'Business', 'Computer science', 'Law', 'Engineering', 'Structural engineering', 'Finance', 'Operating system']","This study examines how Chinese and Western news media covered artificial intelligence (AI) privacy issues in higher education from 2019 to 2024. News articles were retrieved from Nexis Uni. First, non-negative matrix factorization (NMF) was employed to identify core AI privacy topics in university teaching, administration, and research. Next, a time trend analysis investigated how media attention shifted in relation to key events, including the COVID-19 pandemic and the emergence of generative AI. Finally, a sentiment analysis was conducted to compare the distribution of positive, negative, and neutral reporting. The findings indicate that AI-driven proctoring, student data security, and institutional governance are central concerns in both Chinese and English media. However, the focus and framing differ: some Western outlets highlight individual privacy rights and controversies in remote exam monitoring, while Chinese coverage more frequently addresses AI-driven educational innovation and policy support. The shift to remote education after 2020 and the rise of generative AI from 2023 onward have intensified discussions on AI privacy in higher education. The results offer a cross-cultural perspective for institutions seeking to reconcile the adoption of AI with robust privacy safeguards and provide a foundation for future data governance frameworks under diverse regulatory environments."
https://openalex.org/W4390577108,Data Security and Privacy in the Age of AI and Digital Twins,"{'Data': [0], 'security': [1, 39, 78, 105, 129], 'and': [2, 15, 26, 34, 40, 47, 63, 71, 86, 99, 106, 117, 127, 137], 'privacy': [3, 41], 'have': [4], 'emerged': [5], 'as': [6, 81], 'businesses': [7], 'struggle': [8], 'with': [9], 'the': [10, 16, 21, 32, 43, 58, 67, 108, 111], 'growing': [11], 'digitization': [12], 'of': [13, 18, 23, 31, 45, 60, 76, 113], 'operations': [14], 'abundance': [17], 'data': [19, 38, 61, 68, 95, 104], 'in': [20, 42, 52, 91], 'age': [22], 'artificial': [24], 'intelligence': [25], 'digital': [27, 48], 'twins.': [28], 'An': [29], 'overview': [30], 'issues': [33], 'solutions': [35], 'relating': [36], 'to': [37, 93, 124], 'context': [44], 'AI': [46], 'twins': [49], 'is': [50, 89], 'given': [51], 'this': [53], 'chapter.': [54], 'The': [55, 74], 'chapter': [56, 109], 'emphasizes': [57], 'value': [59], 'classification': [62], 'recognizing': [64], 'how': [65, 123], 'sensitive': [66], 'being': [69], 'created': [70], 'used': [72], 'is.': [73], 'necessity': [75], 'strong': [77], 'measures,': [79], 'such': [80], 'access': [82, 98], 'controls,': [83], 'authentication': [84], 'procedures,': [85], 'encryption': [87], 'methods,': [88], 'emphasized': [90], 'order': [92], 'safeguard': [94], 'against': [96], 'unwanted': [97], 'breaches.': [100], 'To': [101], 'further': [102], 'assure': [103], 'compliance,': [107], 'underlines': [110], 'significance': [112], 'ongoing': [114], 'monitoring,': [115, 134], 'auditing,': [116], 'risk': [118, 139], 'assessment': [119], 'procedures.': [120], 'It': [121], 'examines': [122], 'successfully': [125], 'detect': [126], 'mitigate': [128], 'problems': [130], 'by': [131], 'utilizing': [132], 'real-time': [133], 'routine': [135], 'audits,': [136], 'proactive': [138], 'assessments.': [140]}",2024,"['Digitization', 'Computer security', 'Audit', 'Computer science', 'Encryption', 'Data security', 'Context (archaeology)', 'Internet privacy', 'Authentication (law)', 'Business', 'Accounting', 'Geography', 'Archaeology', 'Computer vision']","Data security and privacy have emerged as businesses struggle with the growing digitization of operations and the abundance of data in the age of artificial intelligence and digital twins. An overview of the issues and solutions relating to data security and privacy in the context of AI and digital twins is given in this chapter. The chapter emphasizes the value of data classification and recognizing how sensitive the data being created and used is. The necessity of strong security measures, such as access controls, authentication procedures, and encryption methods, is emphasized in order to safeguard data against unwanted access and breaches. To further assure data security and compliance, the chapter underlines the significance of ongoing monitoring, auditing, and risk assessment procedures. It examines how to successfully detect and mitigate security problems by utilizing real-time monitoring, routine audits, and proactive risk assessments."
https://openalex.org/W3094276725,Evaluating If Trust and Personal Information Privacy Concerns Are Barriers to Using Health Insurance That Explicitly Utilizes AI,"{'Trust': [0], 'and': [1, 22, 50, 77, 95], 'privacy': [2, 51], 'have': [3], 'emerged': [4], 'as': [5], 'significant': [6, 140], 'concerns': [7, 130], 'in': [8, 34, 60, 74, 121], 'online\\ntransactions.': [9], 'Sharing': [10], 'information': [11], 'on': [12], 'health': [13, 24], 'is': [14, 80, 91, 99, 119, 127, 137], 'especially': [15], 'sensitive': [16], 'but': [17, 134], 'it': [18], 'is\\nnecessary': [19], 'for': [20], 'purchasing': [21], 'utilizing': [23], 'insurance.': [25], 'Evidence': [26], 'shows': [27], 'that\\nconsumers': [28], 'are': [29, 53, 64, 131], 'increasingly': [30], 'comfortable': [31], 'with': [32], 'technology': [33], 'place': [35], 'of': [36, 41, 58], 'humans,': [37], 'but\\nthe': [38], 'expanding': [39], 'use': [40], 'AI': [42, 59, 71, 93, 96, 126, 133], 'potentially': [43], 'changes': [44], 'this.': [45], 'This': [46], 'research': [47], 'explores\\nwhether': [48], 'trust': [49, 118], 'concern': [52], 'barriers': [54], 'to': [55, 84, 102], 'the': [56, 75, 87, 103, 122, 135, 142], 'adoption': [57], 'health\\ninsurance.': [61], 'Two': [62], 'scenarios': [63, 107], 'compared:': [65], 'The': [66, 105, 114], 'first': [67], 'scenario': [68, 89, 124], 'has': [69], 'limited': [70], 'that\\nis': [72], 'not': [73, 81, 138], 'interface': [76, 94], 'its': [78], 'presence': [79], 'explicitly': [82, 100], 'revealed': [83, 101], 'the\\nconsumer.': [85], 'In': [86], 'second': [88, 123], 'there': [90], 'an': [92], 'evaluation,\\nand': [97], 'this': [98], 'consumer.': [104], 'two': [106], 'were': [108], 'modeled\\nand': [109], 'compared': [110], 'using': [111], 'SEM': [112], 'PLS-MGA.': [113], 'findings': [115], 'show': [116], 'that': [117], 'significantly\\nlower': [120], 'where': [125], 'visible.': [128], 'Privacy': [129], 'higher\\nwith': [132], 'difference': [136], 'statistically': [139], 'within': [141], 'model.\\n': [143]}",2020,"['Purchasing', 'Internet privacy', 'Business', 'Personally identifiable information', 'Interface (matter)', 'Computer science', 'Computer security', 'Marketing', 'Bubble', 'Parallel computing', 'Maximum bubble pressure method']","Trust and privacy have emerged as significant concerns in online\ntransactions. Sharing information on health is especially sensitive but it is\nnecessary for purchasing and utilizing health insurance. Evidence shows that\nconsumers are increasingly comfortable with technology in place of humans, but\nthe expanding use of AI potentially changes this. This research explores\nwhether trust and privacy concern are barriers to the adoption of AI in health\ninsurance. Two scenarios are compared: The first scenario has limited AI that\nis not in the interface and its presence is not explicitly revealed to the\nconsumer. In the second scenario there is an AI interface and AI evaluation,\nand this is explicitly revealed to the consumer. The two scenarios were modeled\nand compared using SEM PLS-MGA. The findings show that trust is significantly\nlower in the second scenario where AI is visible. Privacy concerns are higher\nwith AI but the difference is not statistically significant within the model.\n"
https://openalex.org/W4399771211,"Evaluating privacy, security, and trust perceptions in conversational AI: A systematic review","{'Conversational': [0], 'AI': [1], '(CAI)': [2], 'systems': [3], 'which': [4, 150], 'encompass': [5], 'voice-': [6], 'and': [7, 14, 33, 49, 51, 57, 80, 92, 106, 109, 115, 127, 132, 163, 191, 204, 212, 215], 'text-based': [8], 'assistants': [9], 'are': [10, 151], 'on': [11, 46, 89, 112, 167, 200], 'the': [12, 39, 52, 61, 72, 84, 96, 125, 140, 158, 168, 173, 218], 'rise': [13], 'have': [15], 'been': [16], 'largely': [17], 'integrated': [18], 'into': [19, 83, 124], 'people’s': [20], 'everyday': [21], 'lives.': [22], 'Despite': [23], 'their': [24, 44], 'widespread': [25], 'adoption,': [26], 'users': [27], 'voice': [28], 'concerns': [29], 'regarding': [30], 'privacy,': [31, 55, 90, 130, 189, 210], 'security': [32, 56, 91, 131, 164, 190, 211], 'trust': [34, 58, 93, 133, 192, 213], 'in': [35, 60, 95], 'these': [36, 42, 180], 'systems.': [37, 100, 223], 'However,': [38], 'composition': [40], 'of': [41, 87, 98, 129, 142, 160, 175, 179, 220], 'perceptions,': [43], 'impact': [45], 'technology': [47], 'adoption': [48], 'usage': [50], 'relationship': [53], 'between': [54], 'perceptions': [59, 94, 159, 193, 214], 'CAI': [62, 99, 222], 'context': [63, 97], 'remain': [64], 'open': [65], 'research': [66, 88, 196], 'challenges.': [67], 'This': [68], 'study': [69], 'contributes': [70], 'to': [71, 198, 202, 217], 'field': [73], 'by': [74], 'conducting': [75], 'a': [76, 183], 'Systematic': [77], 'Literature': [78], 'Review': [79], 'offers': [81], 'insights': [82, 123], 'current': [85], 'state': [86], 'The': [101], 'review': [102], 'covers': [103], 'application': [104], 'fields': [105], 'user': [107], 'groups': [108], 'sheds': [110], 'light': [111], 'empirical': [113], 'methods': [114], 'tools': [116], 'used': [117], 'for': [118, 208], 'assessment.': [119], 'Moreover,': [120], 'it': [121], 'provides': [122], 'reliability': [126], 'validity': [128], 'scales,': [134], 'as': [135, 137, 145, 147], 'well': [136, 146], 'extensively': [138], 'investigating': [139], 'subconstructs': [141, 169], 'each': [143], 'item': [144], 'additional': [148], 'concepts': [149], 'concurrently': [152], 'collected.': [153], 'We': [154], 'point': [155], 'out': [156], 'that': [157], 'trust,': [161], 'privacy': [162], 'overlap': [165], 'based': [166], 'we': [170], 'identified.': [171], 'While': [172], 'majority': [174], 'studies': [176, 185], 'investigate': [177], 'one': [178], 'concepts,': [181], 'only': [182], 'few': [184], 'were': [186], 'found': [187], 'exploring': [188], 'jointly.': [194], 'Our': [195], 'aims': [197], 'inform': [199], 'directions': [201], 'develop': [203], 'use': [205], 'reliable': [206], 'scales': [207], 'users’': [209], 'contribute': [216], 'development': [219], 'trustworthy': [221]}",2024,"['Internet privacy', 'Perception', 'Psychology', 'Computer security', 'Computer science', 'Neuroscience']","Conversational AI (CAI) systems which encompass voice- and text-based assistants are on the rise and have been largely integrated into people’s everyday lives. Despite their widespread adoption, users voice concerns regarding privacy, security and trust in these systems. However, the composition of these perceptions, their impact on technology adoption and usage and the relationship between privacy, security and trust perceptions in the CAI context remain open research challenges. This study contributes to the field by conducting a Systematic Literature Review and offers insights into the current state of research on privacy, security and trust perceptions in the context of CAI systems. The review covers application fields and user groups and sheds light on empirical methods and tools used for assessment. Moreover, it provides insights into the reliability and validity of privacy, security and trust scales, as well as extensively investigating the subconstructs of each item as well as additional concepts which are concurrently collected. We point out that the perceptions of trust, privacy and security overlap based on the subconstructs we identified. While the majority of studies investigate one of these concepts, only a few studies were found exploring privacy, security and trust perceptions jointly. Our research aims to inform on directions to develop and use reliable scales for users’ privacy, security and trust perceptions and contribute to the development of trustworthy CAI systems."
https://openalex.org/W3012606812,Privacy-preserving AI Services Through Data Decentralization,"{'User': [0], 'services': [1, 53], 'increasingly': [2], 'base': [3], 'their': [4, 41], 'actions': [5], 'on': [6], 'AI': [7, 19, 83, 113, 136], 'models,': [8], 'e.g.,': [9], 'to': [10, 28, 35, 50, 55, 79, 91], 'offer': [11], 'personalized': [12, 82], 'and': [13, 68, 123, 143, 155], 'proactive': [14], 'support.': [15], 'However,': [16], 'the': [17, 56, 73, 98, 107, 153], 'underlying': [18], 'algorithms': [20, 114], 'require': [21], 'a': [22, 65, 139], 'continuous': [23], 'stream': [24], 'of': [25, 40, 58, 100, 126, 157], 'personal': [26, 92], 'data—leading': [27], 'privacy': [29], 'issues,': [30], 'as': [31, 162], 'users': [32], 'typically': [33], 'have': [34], 'share': [36], 'this': [37], 'data': [38, 78, 93], 'out': [39], 'territory.': [42], 'Current': [43], 'privacy-preserving': [44], 'concepts': [45], 'are': [46], 'either': [47], 'not': [48], 'applicable': [49], 'such': [51], 'AI-based': [52], 'or': [54], 'disadvantage': [57], 'any': [59], 'party.': [60], 'This': [61], 'paper': [62], 'presents': [63], 'PrivAI,': [64], 'new': [66, 130], 'decentralized': [67], 'privacy-by-design': [69], 'platform': [70], 'for': [71, 75, 129], 'overcoming': [72], 'need': [74], 'sharing': [76, 125], 'user': [77, 102], 'benefit': [80], 'from': [81], 'services.': [84], 'In': [85], 'short,': [86], 'PrivAI': [87, 104, 158], 'complements': [88], 'existing': [89], 'approaches': [90], 'stores,': [94], 'but': [95], 'strictly': [96], 'enforces': [97], 'confinement': [99], 'raw': [101], 'data.': [103], 'further': [105], 'addresses': [106], 'resulting': [108], 'challenges': [109], 'by': [110, 132], '(1)': [111], 'dividing': [112], 'into': [115, 138], 'cloud-based': [116], 'general': [117], 'model': [118, 127], 'training,': [119], 'subsequent': [120], 'local': [121], 'personalization,': [122], 'community-based': [124], 'updates': [128], 'users;': [131], '(2)': [133], 'loading': [134], 'confidential': [135], 'models': [137], 'trusted': [140], 'execution': [141], 'environment,': [142], 'thus,': [144], 'protecting': [145], ""provider's"": [146], 'intellectual': [147], 'property': [148], '(IP).': [149], 'Our': [150], 'experiments': [151], 'show': [152], 'feasibility': [154], 'effectiveness': [156], 'with': [159], 'comparable': [160], 'performance': [161], 'currently-practiced': [163], 'approaches.': [164]}",2020,"['Computer science', 'Personalization', 'Information privacy', 'Confidentiality', 'Cloud computing', 'Data sharing', 'Computer security', 'Raw data', 'Decentralization', 'World Wide Web', 'Internet privacy', 'Operating system', 'Law', 'Programming language', 'Pathology', 'Alternative medicine', 'Medicine', 'Political science']","User services increasingly base their actions on AI models, e.g., to offer personalized and proactive support. However, the underlying AI algorithms require a continuous stream of personal data—leading to privacy issues, as users typically have to share this data out of their territory. Current privacy-preserving concepts are either not applicable to such AI-based services or to the disadvantage of any party. This paper presents PrivAI, a new decentralized and privacy-by-design platform for overcoming the need for sharing user data to benefit from personalized AI services. In short, PrivAI complements existing approaches to personal data stores, but strictly enforces the confinement of raw user data. PrivAI further addresses the resulting challenges by (1) dividing AI algorithms into cloud-based general model training, subsequent local personalization, and community-based sharing of model updates for new users; by (2) loading confidential AI models into a trusted execution environment, and thus, protecting provider's intellectual property (IP). Our experiments show the feasibility and effectiveness of PrivAI with comparable performance as currently-practiced approaches."
https://openalex.org/W4387634936,"Deepfakes, Phrenology, Surveillance, and More! A Taxonomy of AI Privacy Risks","{'Privacy': [0], 'is': [1, 100], 'a': [2, 25, 106, 129], 'key': [3], 'principle': [4], 'for': [5], 'developing': [6], 'ethical': [7], 'AI': [8, 14, 28, 35, 47, 75, 103], 'technologies,': [9], 'but': [10], 'how': [11, 40], 'does': [12], 'including': [13], 'technologies': [15, 48, 76, 104], 'in': [16, 50], 'products': [17], 'and': [18, 44, 139], 'services': [19], 'change': [20], 'privacy': [21, 29, 36, 55, 72, 111, 133], 'risks?': [22], 'We': [23, 38, 68], 'constructed': [24], 'taxonomy': [26], 'of': [27, 46, 97, 131, 142], 'risks': [30, 73, 82, 90, 112, 134], 'by': [31], 'analyzing': [32], '321': [33], 'documented': [34], 'incidents.': [37], 'codified': [39], 'the': [41, 66, 110, 132, 137], 'unique': [42], 'capabilities': [43, 138], 'requirements': [45, 141], 'described': [49], 'those': [51], 'incidents': [52], 'generated': [53], 'new': [54], 'risks,': [56], 'exacerbated': [57, 87], 'known': [58], 'ones,': [59], 'or': [60, 86], 'otherwise': [61], 'did': [62], 'not': [63], 'meaningfully': [64], 'alter': [65, 109], 'risk.': [67], 'present': [69], '12': [70], 'high-level': [71], 'that': [74, 101], 'either': [77], 'newly': [78], 'created': [79], '(e.g.,': [80, 88, 121], 'exposure': [81], 'from': [83, 91, 136], 'deepfake': [84], 'pornography)': [85], 'surveillance': [89], 'collecting': [92], 'training': [93], 'data).': [94], 'One': [95], 'upshot': [96], 'our': [98], 'work': [99], 'incorporating': [102], 'into': [105], 'product': [107], 'can': [108], 'it': [113], 'entails.': [114], 'Yet,': [115], 'current': [116], 'approaches': [117], 'to': [118], 'privacy-preserving': [119], 'AI/ML': [120], 'federated': [122], 'learning,': [123], 'differential': [124], 'privacy,': [125], 'checklists)': [126], 'only': [127], 'address': [128], 'subset': [130], 'arising': [135], 'data': [140], 'AI.': [143]}",2023,"['Internet privacy', 'Differential privacy', 'Computer science', 'Privacy by Design', 'Information privacy', 'Privacy software', 'Computer security', 'Data science', 'Data mining']","Privacy is a key principle for developing ethical AI technologies, but how does including AI technologies in products and services change privacy risks? We constructed a taxonomy of AI privacy risks by analyzing 321 documented AI privacy incidents. We codified how the unique capabilities and requirements of AI technologies described in those incidents generated new privacy risks, exacerbated known ones, or otherwise did not meaningfully alter the risk. We present 12 high-level privacy risks that AI technologies either newly created (e.g., exposure risks from deepfake pornography) or exacerbated (e.g., surveillance risks from collecting training data). One upshot of our work is that incorporating AI technologies into a product can alter the privacy risks it entails. Yet, current approaches to privacy-preserving AI/ML (e.g., federated learning, differential privacy, checklists) only address a subset of the privacy risks arising from the capabilities and data requirements of AI."
https://openalex.org/W4405064614,Ontology for Healthcare AI Privacy in Brazil,"{'This': [0], 'article': [1], 'details': [2], 'the': [3, 11, 92], 'creation': [4], 'of': [5, 13, 68, 94, 102], 'a': [6, 22, 99], 'novel': [7], 'domain': [8], 'ontology': [9, 104], 'at': [10], 'intersection': [12], 'epidemiology,': [14], 'medicine,': [15], 'statistics,': [16], 'and': [17, 70, 88, 110], 'computer': [18], 'science.': [19], 'It': [20, 96], 'outlines': [21], 'systematic': [23], 'approach': [24], 'to': [25, 83, 108], 'handling': [26], 'structured': [27], 'data': [28, 69, 75], 'anonymously': [29], 'in': [30, 35, 40, 61, 105], 'preparation': [31], 'for': [32, 90], 'its': [33], 'use': [34], 'Artificial': [36], 'Intelligence': [37], '(AI)': [38], 'applications': [39], 'healthcare.': [41], 'The': [42], 'development': [43], 'followed': [44], '7': [45], 'steps,': [46], 'including': [47], 'defining': [48], 'scope,': [49], 'selecting': [50], 'knowledge,': [51], 'reviewing': [52], 'important': [53], 'terms,': [54], 'constructing': [55], 'classes': [56], 'that': [57, 73], 'describe': [58], 'designs': [59], 'used': [60], 'epidemiological': [62], 'studies,': [63], 'machine': [64], 'learning': [65], 'paradigms,': [66], 'types': [67], 'attributes,': [71], 'risks': [72], 'anonymized': [74], 'may': [76], 'be': [77], 'exposed': [78], 'to,': [79], 'privacy': [80, 86], 'attacks,': [81], 'techniques': [82], 'mitigate': [84], 're-identification,': [85], 'models,': [87], 'metrics': [89], 'measuring': [91], 'effects': [93], 'anonymization.': [95], 'concludes': [97], 'with': [98], 'practical': [100], 'implementation': [101], 'this': [103], 'hospital': [106], 'settings': [107], 'develop': [109], 'validate': [111], 'AI': [112], 'systems.': [113]}",2024,"['Ontology', 'Computer science', 'Scope (computer science)', 'Intersection (aeronautics)', 'Data science', 'Identification (biology)', 'Domain (mathematical analysis)', 'Health care', 'Information privacy', 'Computer security', 'Engineering', 'Philosophy', 'Aerospace engineering', 'Botany', 'Economics', 'Epistemology', 'Economic growth', 'Programming language', 'Mathematical analysis', 'Biology', 'Mathematics']","This article details the creation of a novel domain ontology at the intersection of epidemiology, medicine, statistics, and computer science. It outlines a systematic approach to handling structured data anonymously in preparation for its use in Artificial Intelligence (AI) applications in healthcare. The development followed 7 steps, including defining scope, selecting knowledge, reviewing important terms, constructing classes that describe designs used in epidemiological studies, machine learning paradigms, types of data and attributes, risks that anonymized data may be exposed to, privacy attacks, techniques to mitigate re-identification, privacy models, and metrics for measuring the effects of anonymization. It concludes with a practical implementation of this ontology in hospital settings to develop and validate AI systems."
https://openalex.org/W4391614477,"Trustworthy Distributed AI Systems: Robustness, Privacy, and Governance","{'Emerging': [0], 'Distributed': [1], 'AI': [2, 37, 53, 86, 154, 187, 191], 'systems': [3], 'are': [4, 96], 'revolutionizing': [5], 'big': [6], 'data': [7, 10, 137, 162], 'computing': [8], 'and': [9, 16, 27, 33, 47, 59, 83, 91, 123, 128, 135, 147, 152, 156, 163, 173, 194, 196], 'processing': [11], 'capabilities': [12], 'with': [13, 158, 167], 'growing': [14], 'economic': [15], 'societal': [17], 'impact.': [18], 'However,': [19], 'recent': [20], 'studies': [21], 'have': [22], 'identified': [23], 'new': [24], 'attack': [25], 'surfaces': [26], 'risks': [28], 'caused': [29], 'by': [30], 'security,': [31, 81], 'privacy,': [32, 82], 'fairness': [34, 60, 84, 155], 'issues': [35], 'in': [36, 62, 88, 98], 'systems.': [38], 'In': [39], 'this': [40], 'article,': [41], 'we': [42, 106], 'review': [43], 'representative': [44], 'techniques,': [45], 'algorithms,': [46], 'theoretical': [48], 'foundations': [49], 'for': [50, 74, 80, 113, 185], 'trustworthy': [51, 114, 178, 186], 'distributed': [52, 63, 75, 89, 99, 115, 145, 179], 'through': [54], 'robustness': [55, 119, 129], 'guarantee,': [56], 'privacy': [57, 142], 'protection,': [58], 'awareness': [61], 'learning.': [64], 'We': [65, 165], 'first': [66], 'provide': [67, 107], 'a': [68, 108, 168], 'brief': [69], 'overview': [70], 'of': [71, 85, 102, 111], 'alternative': [72], 'architectures': [73], 'learning,': [76, 90], 'discuss': [77], 'inherent': [78], 'vulnerabilities': [79], 'algorithms': [87], 'analyze': [92], 'why': [93], 'these': [94], 'problems': [95], 'present': [97], 'learning': [100, 146], 'regardless': [101], 'specific': [103], 'architectures.': [104], 'Then,': [105], 'unique': [109], 'taxonomy': [110], 'countermeasures': [112], 'AI,': [116, 180], 'covering': [117], '(1)': [118], 'to': [120, 130, 160], 'evasion': [121], 'attacks': [122], 'irregular': [124, 136], 'queries': [125], 'at': [126, 150], 'inference,': [127], 'poisoning': [131], 'attacks,': [132, 134], 'Byzantine': [133], 'distribution': [138], 'during': [139, 144], 'training;': [140], '(2)': [141], 'protection': [143], 'model': [148], 'inference': [149], 'deployment;': [151], '(3)': [153], 'governance': [157], 'respect': [159], 'both': [161], 'models.': [164], 'conclude': [166], 'discussion': [169], 'on': [170], 'open': [171], 'challenges': [172], 'future': [174], 'research': [175], 'directions': [176], 'toward': [177], 'such': [181], 'as': [182], 'the': [183, 190], 'need': [184], 'policy': [188], 'guidelines,': [189], 'responsibility-utility': [192], 'co-design,': [193], 'incentives': [195], 'compliance.': [197]}",2024,"['Computer science', 'Robustness (evolution)', 'Trustworthiness', 'Computer security', 'Distributed learning', 'Information privacy', 'Software deployment', 'Inference', 'Corporate governance', 'Incentive', 'Artificial intelligence', 'Software engineering', 'Psychology', 'Chemistry', 'Biochemistry', 'Pedagogy', 'Economics', 'Gene', 'Finance', 'Microeconomics']","Emerging Distributed AI systems are revolutionizing big data computing and data processing capabilities with growing economic and societal impact. However, recent studies have identified new attack surfaces and risks caused by security, privacy, and fairness issues in AI systems. In this article, we review representative techniques, algorithms, and theoretical foundations for trustworthy distributed AI through robustness guarantee, privacy protection, and fairness awareness in distributed learning. We first provide a brief overview of alternative architectures for distributed learning, discuss inherent vulnerabilities for security, privacy, and fairness of AI algorithms in distributed learning, and analyze why these problems are present in distributed learning regardless of specific architectures. Then, we provide a unique taxonomy of countermeasures for trustworthy distributed AI, covering (1) robustness to evasion attacks and irregular queries at inference, and robustness to poisoning attacks, Byzantine attacks, and irregular data distribution during training; (2) privacy protection during distributed learning and model inference at deployment; and (3) AI fairness and governance with respect to both data and models. We conclude with a discussion on open challenges and future research directions toward trustworthy distributed AI, such as the need for trustworthy AI policy guidelines, the AI responsibility-utility co-design, and incentives and compliance."
https://openalex.org/W4401713109,AI Privacy in Context: A Comparative Study of Public and Institutional Discourse on Conversational AI Privacy in the US and China,"{'The': [0], 'proliferation': [1], 'of': [2, 93, 110, 118], 'conversational': [3, 35], 'AI': [4, 36], 'systems,': [5], 'such': [6], 'as': [7], 'chatbots,': [8], 'has': [9], 'sparked': [10], 'widespreadprivacy': [11], 'concerns.': [12], 'Previous': [13], 'research': [14, 124], 'suggests': [15], 'that': [16], 'privacy': [17, 33, 60, 75, 85, 123], 'perceptions': [18], 'and': [19, 23, 29, 40, 44, 51, 62, 64, 87, 107], 'practices': [20], 'vary': [21], 'acrosscultures': [22], 'contexts.': [24], 'This': [25], 'study': [26, 115], 'examines': [27], 'public': [28, 79], 'institutional': [30, 97], 'discourses': [31], 'on': [32, 49, 84, 89], 'issuesregarding': [34], 'in': [37, 121], 'the': [38, 90, 104, 111], 'U.S.': [39], 'China.': [41], 'Semantic': [42], 'network': [43], 'discourse': [45, 70, 80], 'analyses': [46], 'ofprivacy-related': [47], 'discussions': [48], 'Twitter': [50], 'Weibo': [52], 'reveal': [53], 'divergent': [54], 'patterns.': [55], 'On': [56], 'Twitter,': [57], 'publicdiscourse': [58], 'emphasizes': [59], 'risks': [61, 86], 'concerns': [63], 'advocates': [65], 'for': [66], 'systemic': [67], 'changes,': [68], 'whileinstitutional': [69], 'promotes': [71], 'individualistic': [72], 'approaches': [73], 'to': [74, 125], 'protection.': [76], 'Conversely,': [77], 'onWeibo,': [78], 'is': [81], 'less': [82], 'focused': [83], 'more': [88], 'positive': [91], 'impacts': [92], 'AI,aligning': [94], 'closely': [95], 'with': [96, 103], 'narratives.': [98], 'These': [99], 'variations': [100], 'are': [101], 'intertwined': [102], 'cultural,political,': [105], 'economic,': [106], 'regulatory': [108], 'contexts': [109], 'two': [112], 'countries.': [113], 'Our': [114], 'underscores': [116], 'theimportance': [117], 'multi-level': [119], 'analysis': [120], 'comparative': [122], 'provide': [126], 'a': [127], 'holistic': [128], 'view': [129], 'ofprivacy': [130], 'dynamics.': [131]}",2024,"['China', 'Context (archaeology)', 'Information privacy', 'Internet privacy', 'Privacy policy', 'Public discourse', 'Political science', 'Public relations', 'Computer science', 'Law', 'Geography', 'Politics', 'Archaeology']","The proliferation of conversational AI systems, such as chatbots, has sparked widespreadprivacy concerns. Previous research suggests that privacy perceptions and practices vary acrosscultures and contexts. This study examines public and institutional discourses on privacy issuesregarding conversational AI in the U.S. and China. Semantic network and discourse analyses ofprivacy-related discussions on Twitter and Weibo reveal divergent patterns. On Twitter, publicdiscourse emphasizes privacy risks and concerns and advocates for systemic changes, whileinstitutional discourse promotes individualistic approaches to privacy protection. Conversely, onWeibo, public discourse is less focused on privacy risks and more on the positive impacts of AI,aligning closely with institutional narratives. These variations are intertwined with the cultural,political, economic, and regulatory contexts of the two countries. Our study underscores theimportance of multi-level analysis in comparative privacy research to provide a holistic view ofprivacy dynamics."
https://openalex.org/W4401305868,Navigating the nexus of AI and IoT: A comprehensive review of data analytics and privacy paradigms,"{'Integrating': [0], 'Artificial': [1], 'Intelligence': [2], '(AI)': [3], 'with': [4, 32, 132, 202], 'the': [5, 22, 79, 83, 101, 124, 129, 156, 161, 178, 251, 263], 'Internet': [6], 'of': [7, 28, 48, 82, 103, 128, 181, 266], 'Things': [8], '(IoT)': [9], 'has': [10, 56], 'propelled': [11], 'technological': [12], 'innovation': [13], 'across': [14], 'various': [15], 'industries.': [16], 'This': [17, 87, 139], 'systematic': [18, 137, 140], 'literature': [19, 98, 141], 'review': [20, 88, 142], 'explores': [21], 'current': [23, 157], 'state': [24], 'and': [25, 43, 99, 126, 151, 159, 170, 189, 209, 215, 223, 234, 240, 248, 257], 'future': [26, 164], 'trajectories': [27], 'AI': [29, 182, 201], 'in': [30, 39, 183, 192, 212], 'IoT,': [31, 184], 'a': [33, 109, 145, 173, 186], 'particular': [34], 'focus': [35], 'on': [36], 'emerging': [37], 'trends': [38, 169], 'intelligent': [40], 'data': [41, 54, 58, 232, 246, 258], 'analysis': [42, 197, 235], 'privacy': [44, 247], 'protection.': [45], 'The': [46, 106, 120, 167], 'proliferation': [47], 'IoT': [49, 85, 203, 231, 268], 'devices,': [50], 'marked': [51], 'by': [52, 94, 113, 236], 'voluminous': [53], 'generation,': [55], 'reshaped': [57], 'processing': [59, 233], 'methods,': [60], 'providing': [61], 'actionable': [62], 'insights': [63, 154], 'for': [64, 136, 148, 163, 176, 253], 'informed': [65], 'decision-making.': [66], 'While': [67], 'previous': [68], 'reviews': [69], 'have': [70], 'offered': [71], 'valuable': [72, 174], 'insights,': [73], 'they': [74], 'often': [75], 'must': [76], 'comprehensively': [77], 'address': [78], 'multifaceted': [80], 'dimensions': [81], 'AI-driven': [84, 267], 'landscape.': [86], 'aims': [89], 'to': [90, 116, 229, 261], 'bridge': [91], 'this': [92, 118, 193], 'gap': [93], 'systematically': [95], 'examining': [96], 'existing': [97], 'acknowledging': [100], 'limitations': [102], 'past': [104], 'studies.': [105], 'study': [107], 'uses': [108], 'meticulous': [110], 'approach': [111], 'guided': [112], 'established': [114], 'methodologies': [115], 'achieve': [117], 'aim.': [119], 'chosen': [121], 'methodology': [122], 'ensures': [123], 'rigour': [125], 'validity': [127], 'review,': [130], 'aligning': [131], 'PRISMA': [133], '2020': [134], 'guidelines': [135], 'reviews.': [138], 'serves': [143], 'as': [144], 'comprehensive': [146], 'guide': [147], 'researchers,': [149], 'practitioners,': [150], 'policymakers,': [152], 'offering': [153], 'into': [155], 'landscape': [158], 'paving': [160], 'way': [162], 'research': [165], 'directions.': [166], 'identified': [168], 'challenges': [171], 'provide': [172], 'resource': [175, 217], 'navigating': [177], 'evolving': [179], 'domain': [180], 'fostering': [185], 'balanced,': [187], 'secure,': [188], 'sustainable': [190], 'advancement': [191], 'dynamic': [194], 'field.': [195], 'Our': [196], 'shows': [198], 'that': [199], 'integrating': [200], 'improves': [204], 'operational': [205], 'efficiency,': [206], 'service': [207], 'personalisation,': [208], 'data-driven': [210], 'decisions': [211], 'healthcare,': [213], 'manufacturing,': [214], 'urban': [216], 'management.': [218], 'Real-time': [219], 'machine': [220], 'learning': [221], 'algorithms': [222], 'edge': [224], 'computing': [225], 'solutions': [226], 'are': [227], 'set': [228], 'revolutionise': [230], 'improving': [237], 'system': [238], 'responsiveness': [239], 'privacy.': [241], 'However,': [242], 'increasing': [243], 'concerns': [244], 'about': [245], 'security': [249], 'emphasise': [250], 'need': [252], 'new': [254], 'regulatory': [255], 'frameworks': [256], 'protection': [259], 'technologies': [260], 'ensure': [262], 'ethical': [264], 'adoption': [265], 'technologies.': [269]}",2024,"['Computer science', 'Data science', 'Big data', 'Analytics', 'Nexus (standard)', 'Field (mathematics)', 'Systematic review', 'Knowledge management', 'Data mining', 'Mathematics', 'Embedded system', 'Political science', 'MEDLINE', 'Pure mathematics', 'Law']","Integrating Artificial Intelligence (AI) with the Internet of Things (IoT) has propelled technological innovation across various industries. This systematic literature review explores the current state and future trajectories of AI in IoT, with a particular focus on emerging trends in intelligent data analysis and privacy protection. The proliferation of IoT devices, marked by voluminous data generation, has reshaped data processing methods, providing actionable insights for informed decision-making. While previous reviews have offered valuable insights, they often must comprehensively address the multifaceted dimensions of the AI-driven IoT landscape. This review aims to bridge this gap by systematically examining existing literature and acknowledging the limitations of past studies. The study uses a meticulous approach guided by established methodologies to achieve this aim. The chosen methodology ensures the rigour and validity of the review, aligning with PRISMA 2020 guidelines for systematic reviews. This systematic literature review serves as a comprehensive guide for researchers, practitioners, and policymakers, offering insights into the current landscape and paving the way for future research directions. The identified trends and challenges provide a valuable resource for navigating the evolving domain of AI in IoT, fostering a balanced, secure, and sustainable advancement in this dynamic field. Our analysis shows that integrating AI with IoT improves operational efficiency, service personalisation, and data-driven decisions in healthcare, manufacturing, and urban resource management. Real-time machine learning algorithms and edge computing solutions are set to revolutionise IoT data processing and analysis by improving system responsiveness and privacy. However, increasing concerns about data privacy and security emphasise the need for new regulatory frameworks and data protection technologies to ensure the ethical adoption of AI-driven IoT technologies."
https://openalex.org/W3008110138,Edge AI and Blockchain for Privacy-Critical and Data-Sensitive Applications,"{'The': [0], 'edge': [1, 72, 80], 'and': [2, 9, 20, 64, 84], 'fog': [3], 'computing': [4], 'paradigms': [5], 'enable': [6], 'more': [7, 55], 'responsive': [8], 'smarter': [10], 'systems': [11], 'without': [12], 'relying': [13], 'on': [14], 'cloud': [15], 'servers': [16], 'for': [17], 'data': [18, 77], 'processing': [19], 'storage.': [21], 'This': [22], 'reduces': [23], 'network': [24, 38, 83], 'load': [25], 'as': [26, 28], 'well': [27], 'latency.': [29], 'Nonetheless,': [30], 'the': [31, 37, 41, 49, 79, 82, 88, 92, 95], 'addition': [32], 'of': [33, 43, 51, 81, 87, 94], 'new': [34, 52], 'layers': [35], 'in': [36, 100], 'architecture': [39, 70], 'increases': [40], 'number': [42], 'security': [44], 'vulnerabilities.': [45], 'In': [46], 'privacy-critical': [47], 'systems,': [48], 'appearance': [50], 'vulnerabilities': [53], 'is': [54], 'significant.': [56], 'To': [57], 'cope': [58], 'with': [59, 71], 'this': [60], 'issue,': [61], 'we': [62], 'propose': [63], 'implement': [65], 'an': [66], 'Ethereum': [67], 'Blockchain': [68], 'based': [69], 'artificial': [73], 'intelligence': [74], 'to': [75], 'analyze': [76], 'at': [78], 'keep': [85], 'track': [86], 'parties': [89], 'that': [90], 'access': [91], 'results': [93], 'analysis,': [96], 'which': [97], 'are': [98], 'stored': [99], 'distributed': [101], 'databases.<br': [102], '/>': [103]}",2019,"['Blockchain', 'Computer science', 'Server', 'Edge computing', 'Enhanced Data Rates for GSM Evolution', 'Cloud computing', 'Architecture', 'Edge device', 'Computer network', 'Information privacy', 'Computer security', 'Latency (audio)', 'Distributed computing', 'Operating system', 'Artificial intelligence', 'Telecommunications', 'Visual arts', 'Art']","The edge and fog computing paradigms enable more responsive and smarter systems without relying on cloud servers for data processing and storage. This reduces network load as well as latency. Nonetheless, the addition of new layers in the network architecture increases the number of security vulnerabilities. In privacy-critical systems, the appearance of new vulnerabilities is more significant. To cope with this issue, we propose and implement an Ethereum Blockchain based architecture with edge artificial intelligence to analyze data at the edge of the network and keep track of the parties that access the results of the analysis, which are stored in distributed databases.<br />"
https://openalex.org/W4385154445,When AI Meets Information Privacy: The Adversarial Role of AI in Data Sharing Scenario,"{'Artificial': [0], 'intelligence': [1], '(AI)': [2], 'is': [3, 80, 90, 279], 'a': [4, 8, 41, 49, 166, 178, 233, 261, 277], 'transformative': [5], 'technology': [6], 'with': [7, 30, 63, 92, 177], 'substantial': [9], 'number': [10], 'of': [11, 73, 95, 105, 110, 131, 163, 193, 206, 211, 216, 223, 242, 269], 'practical': [12], 'applications': [13], 'in': [14, 153, 208, 271], 'commercial': [15], 'sectors': [16], 'such': [17, 118], 'as': [18, 40, 48, 119, 165, 186], 'healthcare,': [19], 'finance,': [20], 'aviation,': [21], 'and': [22, 47, 77, 98, 129, 220], 'smart': [23], 'cities.': [24], 'AI': [25, 59, 96, 164, 170, 270], 'also': [26], 'has': [27], 'strong': [28], 'synergy': [29], 'the': [31, 56, 64, 74, 84, 93, 103, 108, 132, 147, 161, 237, 240, 251, 267, 272], 'information': [32, 124, 202], 'privacy': [33, 79, 104, 125, 151, 194], '(IP)': [34], 'domain': [35], 'from': [36], 'two': [37], 'distinct': [38], 'aspects:': [39], 'protection': [42], 'tool': [43, 51, 168], '(i.e.,': [44, 52, 169], 'safeguarding': [45], 'privacy),': [46, 176], 'threat': [50, 167], 'compromising': [53], 'privacy).': [54], 'In': [55, 83, 156], 'former': [57], 'case,': [58, 86], 'techniques': [60, 67, 97], 'are': [61, 126], 'amalgamated': [62], 'traditional': [65], 'anonymization': [66, 134], 'to': [68, 101, 123, 146, 150, 172, 190, 236, 249, 265, 285], 'improve': [69], 'various': [70, 191], 'key': [71], 'components': [72], 'anonymity': [75], 'process,': [76], 'therefore,': [78], 'safeguarded': [81], 'effectively.': [82], 'latter': [85], 'some': [87, 154, 224], 'adversarial': [88], 'knowledge': [89, 117, 141, 188], 'aggregated': [91], 'help': [94], 'subsequently': [99, 247], 'used': [100, 171], 'compromise': [102, 173], 'individuals.': [106], 'To': [107], 'best': [109], 'our': [111], 'knowledge,': [112], 'threats': [113], 'posed': [114], 'by': [115], 'AI-generated': [116], 'synthetic': [120], 'data': [121, 229, 273], '(SD)': [122], 'often': [127], 'underestimated,': [128], 'most': [130], 'existing': [133], 'methods': [135], 'do': [136], 'not': [137], 'consider/model': [138], 'this': [139, 157], 'SD-based': [140], 'that': [142, 183, 230, 245], 'can': [143, 184, 199, 231, 246], 'be': [144], 'available': [145], 'adversary,': [148], 'leading': [149, 189], 'breaches': [152], 'cases.': [155], 'paper,': [158], 'we': [159], 'highlight': [160], 'role': [162], 'an': [174], 'individual&#x2019;s': [175], 'special': [179], 'focus': [180], 'on': [181, 260], 'SD': [182, 198], 'serve': [185], 'background': [187], 'kinds': [192], 'breaches.': [195], 'For': [196], 'instance,': [197], 'encompass': [200], 'pertinent': [201], '(e.g.,': [203], 'total': [204], '&#x0023;': [205], 'attributes': [207], 'data,': [209, 244], 'distributions': [210], 'sensitive': [212], 'information,': [213], 'category': [214], 'values': [215, 222], 'each': [217], 'attribute,': [218], 'minor': [219], 'major': [221], 'attributes,': [225], 'etc.)': [226], 'about': [227], 'real': [228], 'offer': [232], 'helpful': [234], 'hint': [235], 'adversary': [238], 'regarding': [239], 'composition': [241], 'anonymized': [243], 'lead': [248], 'uncovering': [250], 'identity': [252], 'or': [253, 282], 'private': [254], 'information.': [255], 'We': [256], 'perform': [257], 'reasonable': [258], 'experiments': [259], 'real-life': [262], 'benchmark': [263], 'dataset': [264], 'prove': [266], 'pitfalls': [268], 'publishing': [274], 'scenario': [275], '(when': [276], 'database': [278], 'either': [280], 'fully': [281], 'partially': [283], 'released': [284], 'public': [286], 'domains': [287], 'for': [288], 'conducting': [289], 'analytics).': [290]}",2023,"['Computer science', 'Adversary', 'Information privacy', 'Adversarial system', 'Compromise', 'Anonymity', 'Computer security', 'Information sensitivity', 'Privacy software', 'Internet privacy', 'Privacy by Design', 'Confidentiality', 'Domain knowledge', 'Data science', 'Artificial intelligence', 'Sociology', 'Social science']","Artificial intelligence (AI) is a transformative technology with a substantial number of practical applications in commercial sectors such as healthcare, finance, aviation, and smart cities. AI also has strong synergy with the information privacy (IP) domain from two distinct aspects: as a protection tool (i.e., safeguarding privacy), and as a threat tool (i.e., compromising privacy). In the former case, AI techniques are amalgamated with the traditional anonymization techniques to improve various key components of the anonymity process, and therefore, privacy is safeguarded effectively. In the latter case, some adversarial knowledge is aggregated with the help of AI techniques and subsequently used to compromise the privacy of individuals. To the best of our knowledge, threats posed by AI-generated knowledge such as synthetic data (SD) to information privacy are often underestimated, and most of the existing anonymization methods do not consider/model this SD-based knowledge that can be available to the adversary, leading to privacy breaches in some cases. In this paper, we highlight the role of AI as a threat tool (i.e., AI used to compromise an individual&#x2019;s privacy), with a special focus on SD that can serve as background knowledge leading to various kinds of privacy breaches. For instance, SD can encompass pertinent information (e.g., total &#x0023; of attributes in data, distributions of sensitive information, category values of each attribute, minor and major values of some attributes, etc.) about real data that can offer a helpful hint to the adversary regarding the composition of anonymized data, that can subsequently lead to uncovering the identity or private information. We perform reasonable experiments on a real-life benchmark dataset to prove the pitfalls of AI in the data publishing scenario (when a database is either fully or partially released to public domains for conducting analytics)."
https://openalex.org/W4200357198,Ciphertext-Policy Attribute-Based Encryption for Cloud Storage: Toward Data Privacy and Authentication in AI-Enabled IoT System,"{'People': [0], 'can': [1, 171], 'store': [2], 'their': [3], 'data': [4, 16, 18, 120], 'on': [5], 'servers': [6], 'in': [7, 106, 161, 183], 'cloud': [8, 44], 'computing': [9], 'and': [10, 92, 119, 141, 165], 'allow': [11], 'public': [12], 'users': [13], 'to': [14, 27, 40, 89], 'access': [15, 32, 47, 65, 95, 99, 135, 177], 'via': [17], 'centers.': [19], 'One': [20], 'of': [21, 34, 67, 71, 96, 163, 175, 186], 'the': [22, 31, 57, 64, 94, 107, 134, 173, 184, 201], 'most': [23], 'difficult': [24], 'tasks': [25], 'is': [26, 37, 83, 102, 155, 197], 'provide': [28, 61], 'security': [29, 62, 143, 190], 'for': [30, 63, 200], 'policy': [33, 66, 100, 136], 'data,': [35, 68], 'which': [36, 132], 'also': [38, 198], 'needed': [39], 'be': [41, 181], 'stored': [42], 'at': [43], 'servers.': [45], 'The': [46, 98, 152], 'structure': [48], '(policy)': [49], 'itself': [50], 'may': [51, 115], 'reveal': [52], 'partial': [53], 'information': [54], 'about': [55], 'what': [56], 'ciphertext': [58, 114, 195], 'contains.': [59], 'To': [60, 122], 'a': [69, 113, 129, 138, 148], 'number': [70], 'encryption': [72], 'schemes': [73, 160], 'are': [74], 'available.': [75], 'Among': [76], 'these,': [77], 'CP-ABE': [78, 109, 159], '(Ciphertext-Policy': [79], 'Attribute-Based': [80], 'Encryption)': [81], 'scheme': [82, 110], 'very': [84], 'significant': [85], 'because': [86], 'it': [87], 'helps': [88], 'protect,': [90], 'broadcast,': [91], 'control': [93, 178], 'information.': [97], 'that': [101, 179], 'sent': [103], 'as': [104], 'plaintext': [105], 'existing': [108, 158], 'along': [111], 'with': [112, 157], 'leak': [116], 'user': [117], 'privacy': [118], 'privacy.': [121], 'resolve': [123], 'this': [124], 'problem,': [125], 'we': [126, 170], 'hereby': [127], 'introduce': [128], 'new': [130], 'technique,': [131], 'hides': [133], 'using': [137, 147], 'hashing': [139], 'algorithm': [140], 'provides': [142], 'against': [144, 191], 'insider': [145], 'attack': [146], 'signature': [149], 'verification': [150], 'scheme.': [151], 'proposed': [153, 202], 'system': [154], 'compared': [156], 'terms': [162], 'computation': [164], 'expressive': [166], 'policies.': [167], 'In': [168], 'addition,': [169], 'test': [172], 'functioning': [174], 'any': [176], 'could': [180], 'implemented': [182], 'Internet': [185], 'Things': [187], '(IoT).': [188], 'Additionally,': [189], 'indistinguishable': [192], 'adaptive': [193], 'chosen': [194], 'attacks': [196], 'analyzed': [199], 'work.': [203]}",2021,"['Ciphertext', 'Attribute-based encryption', 'Computer science', 'Encryption', 'Access control', 'Cloud computing', 'Computer security', 'Semantic security', 'Access structure', 'Server', 'Plaintext', 'Client-side encryption', 'Computer network', 'On-the-fly encryption', 'Public-key cryptography', 'Cryptography', 'Secret sharing', 'Operating system']","People can store their data on servers in cloud computing and allow public users to access data via data centers. One of the most difficult tasks is to provide security for the access policy of data, which is also needed to be stored at cloud servers. The access structure (policy) itself may reveal partial information about what the ciphertext contains. To provide security for the access policy of data, a number of encryption schemes are available. Among these, CP-ABE (Ciphertext-Policy Attribute-Based Encryption) scheme is very significant because it helps to protect, broadcast, and control the access of information. The access policy that is sent as plaintext in the existing CP-ABE scheme along with a ciphertext may leak user privacy and data privacy. To resolve this problem, we hereby introduce a new technique, which hides the access policy using a hashing algorithm and provides security against insider attack using a signature verification scheme. The proposed system is compared with existing CP-ABE schemes in terms of computation and expressive policies. In addition, we can test the functioning of any access control that could be implemented in the Internet of Things (IoT). Additionally, security against indistinguishable adaptive chosen ciphertext attacks is also analyzed for the proposed work."
https://openalex.org/W4401976909,Data security and privacy concerns of AI-driven marketing in the context of economics and business field: an exploration into possible solutions,"{'Interest': [0], 'in': [1, 32, 88], 'artificial': [2], 'intelligence': [3], '(AI)': [4], 'is': [5], 'widespread': [6], 'across': [7], 'several': [8], 'industries,': [9], 'such': [10], 'as': [11], 'marketing,': [12], 'but': [13], 'worries': [14], 'about': [15], 'its': [16], 'ethical': [17], 'and': [18, 30, 35, 62, 77, 117], 'legal': [19], 'consequences': [20], 'are': [21], 'increasing.': [22], 'This': [23, 106], 'article': [24], 'examines': [25], 'concerns': [26, 66], 'regarding': [27], 'data': [28, 57, 104], 'security': [29, 75], 'privacy': [31, 69], 'AI-powered': [33], 'marketing': [34, 94], 'discusses': [36], 'possible': [37], 'remedies.': [38], 'The': [39, 51, 81], 'study': [40], 'compiles': [41], 'information': [42], 'from': [43], 'academic': [44], 'articles': [45], 'using': [46], 'a': [47], 'comprehensive': [48], 'literature': [49], 'review.': [50], 'key': [52], 'conclusions': [53], 'emphasise': [54], 'issues': [55], 'including': [56], 'confidentiality,': [58], 'distribution,': [59], 'cyberattacks,': [60], 'fraud,': [61], 'disinformation.': [63], 'Addressing': [64], 'these': [65], 'involves': [67], 'providing': [68], 'insurance,': [70], 'improving': [71], 'technology': [72], 'readiness,': [73], 'enforcing': [74], 'regulations,': [76], 'building': [78], 'regulatory': [79], 'frameworks.': [80], 'report': [82], 'emphasises': [83], 'the': [84, 89, 97, 109], 'need': [85, 98], 'for': [86, 111], 'transparency': [87], 'use': [90], 'of': [91, 103, 119], 'AI': [92], 'by': [93], 'professionals,': [95], 'highlighting': [96], 'to': [99], 'keep': [100], 'clients': [101], 'aware': [102], 'practices.': [105], 'research': [107], 'establishes': [108], 'foundation': [110], 'future': [112], 'investigation,': [113], 'encouraging': [114], 'continuous': [115], 'discussion': [116], 'examination': [118], 'this': [120], 'developing': [121], 'topic.': [122]}",2024,"['Context (archaeology)', 'Field (mathematics)', 'Information privacy', 'Marketing', 'Business', 'Consumer privacy', 'Data science', 'Computer science', 'Internet privacy', 'Biology', 'Pure mathematics', 'Mathematics', 'Paleontology']","Interest in artificial intelligence (AI) is widespread across several industries, such as marketing, but worries about its ethical and legal consequences are increasing. This article examines concerns regarding data security and privacy in AI-powered marketing and discusses possible remedies. The study compiles information from academic articles using a comprehensive literature review. The key conclusions emphasise issues including data confidentiality, distribution, cyberattacks, fraud, and disinformation. Addressing these concerns involves providing privacy insurance, improving technology readiness, enforcing security regulations, and building regulatory frameworks. The report emphasises the need for transparency in the use of AI by marketing professionals, highlighting the need to keep clients aware of data practices. This research establishes the foundation for future investigation, encouraging continuous discussion and examination of this developing topic."
https://openalex.org/W4315781024,"How AI encourages consumers to share their secrets? The role of anthropomorphism, personalisation, and privacy concerns and avenues for future research","{'Purpose': [0], 'This': [1, 40, 100, 139], 'paper': [2, 101, 124, 140], 'aims': [3], 'to': [4, 53, 82, 86, 142, 171, 179], 'explore': [5], 'the': [6, 44, 55, 129, 149], 'overall': [7], 'research': [8, 41, 56, 111, 165], 'question': [9, 57, 150], '“How': [10], 'can': [11, 62], 'artificial': [12], 'intelligence': [13], '(AI)': [14], 'influence': [15, 29, 63, 77], 'consumer': [16, 64, 78, 137, 152, 174], 'information': [17, 65, 85, 97, 153, 175], 'disclosure?”.': [18], 'It': [19, 67], 'considers': [20], 'how': [21, 60, 151], 'anthropomorphism': [22, 71], 'of': [23, 35, 72, 133], 'AI,': [24], 'personalisation': [25, 75], 'and': [26, 32, 48, 58, 74, 80, 96, 108, 121, 131, 163, 173], 'privacy': [27, 49, 91, 172], 'concerns': [28, 92], 'consumers’': [30], 'attitudes': [31, 79], 'encourage': [33], 'disclosure': [34, 154, 176], 'their': [36], 'private': [37], 'information.': [38], 'Design/methodology/approach': [39], 'draws': [42], 'upon': [43, 119, 147], 'personalisation-privacy': [45], 'paradox': [46], '(PPP)': [47], 'calculus': [50], 'theory': [51], '(PCT)': [52], 'address': [54], 'examine': [59], 'AI': [61, 73, 134], 'disclosure.': [66, 98], 'is': [68, 155], 'proposed': [69], 'that': [70], 'positively': [76], 'intentions': [81], 'disclose': [83], 'personal': [84], 'a': [87, 103, 126, 136], 'digital': [88], 'assistant,': [89], 'while': [90], 'negatively': [93], 'affect': [94], 'attitude': [95], 'Findings': [99], 'develops': [102], 'conceptual': [104], 'model': [105], 'based': [106], 'on': [107, 128, 148], 'presents': [109, 125], 'seven': [110, 161], 'propositions': [112], '(RPs)': [113], 'for': [114], 'future': [115, 164], 'research.': [116], 'Originality/value': [117], 'Building': [118], 'PPP': [120], 'PCT,': [122], 'this': [123], 'view': [127], 'benefits': [130], 'drawbacks': [132], 'from': [135], 'perspective.': [138], 'contributes': [141], 'literature': [143], 'by': [144, 157], 'critically': [145], 'reflecting': [146], 'influenced': [156], 'AI.': [158, 180], 'In': [159], 'addition,': [160], 'RPs': [162], 'areas': [166], 'are': [167], 'outlined': [168], 'in': [169, 177], 'relation': [170, 178]}",2023,"['Personalization', 'Relation (database)', 'Originality', 'Personally identifiable information', 'Perspective (graphical)', 'Private information retrieval', 'Internet privacy', 'Information privacy', 'Value (mathematics)', 'Affect (linguistics)', 'Psychology', 'Business', 'Social psychology', 'Marketing', 'Computer science', 'Computer security', 'Artificial intelligence', 'Communication', 'Creativity', 'Database', 'Machine learning']","Purpose This paper aims to explore the overall research question “How can artificial intelligence (AI) influence consumer information disclosure?”. It considers how anthropomorphism of AI, personalisation and privacy concerns influence consumers’ attitudes and encourage disclosure of their private information. Design/methodology/approach This research draws upon the personalisation-privacy paradox (PPP) and privacy calculus theory (PCT) to address the research question and examine how AI can influence consumer information disclosure. It is proposed that anthropomorphism of AI and personalisation positively influence consumer attitudes and intentions to disclose personal information to a digital assistant, while privacy concerns negatively affect attitude and information disclosure. Findings This paper develops a conceptual model based on and presents seven research propositions (RPs) for future research. Originality/value Building upon PPP and PCT, this paper presents a view on the benefits and drawbacks of AI from a consumer perspective. This paper contributes to literature by critically reflecting upon on the question how consumer information disclosure is influenced by AI. In addition, seven RPs and future research areas are outlined in relation to privacy and consumer information disclosure in relation to AI."
https://openalex.org/W3154716059,Distributed learning: a reliable privacy-preserving strategy to change multicenter collaborations using AI,"{'Distributed': [0, 33], 'learning': [1, 34], 'resulted': [2], 'in': [3], 'a': [4, 36], 'reliable': [5], 'strategy': [6], 'for': [7, 30, 39, 50], 'model': [8, 31], 'development;': [9], 'indeed,': [10], 'it': [11], 'performed': [12], 'equally': [13], 'to': [14], 'models': [15], 'trained': [16], 'on': [17], 'centralized': [18], 'datasets.': [19], 'Sensitive': [20], 'data': [21], 'can': [22], 'get': [23], 'preserved': [24], 'since': [25, 44], 'they': [26], 'are': [27, 48], 'not': [28], 'shared': [29], 'development.': [32], 'constitutes': [35], 'promising': [37], 'solution': [38], 'ML-based': [40], 'research': [41], 'and': [42], 'practice': [43], 'large,': [45], 'diverse': [46], 'datasets': [47], 'crucial': [49], 'success.': [51]}",2021,"['Machine learning', 'Computer science', 'Artificial intelligence', 'Distributed learning', 'MEDLINE', 'Classifier (UML)', 'Pedagogy', 'Political science', 'Psychology', 'Law']","Distributed learning resulted in a reliable strategy for model development; indeed, it performed equally to models trained on centralized datasets. Sensitive data can get preserved since they are not shared for model development. Distributed learning constitutes a promising solution for ML-based research and practice since large, diverse datasets are crucial for success."
https://openalex.org/W4386219844,Security and Privacy in Fog/Cloud-based IoT Systems for AI and Robotics,"{'Integration': [0], 'of': [1, 3, 30, 33, 44, 56, 102, 139, 156, 159, 165], 'Internet': [2, 158], 'Things': [4, 160], '(IoT)': [5], 'systems': [6, 66, 96, 161], 'based': [7, 69], 'on': [8], 'the': [9, 12, 22, 54, 71, 74, 89, 112, 143, 153, 163], 'fog': [10, 72], 'or': [11, 73], 'cloud': [13, 75], 'with': [14], 'Artificial': [15], 'Intelligence': [16], '(AI)': [17], 'and': [18, 47, 60, 76, 81, 107, 123, 134, 148, 168], 'Robotics': [19], 'has': [20], 'prepared': [21], 'way': [23], 'for': [24, 79, 145], 'breakthrough': [25], 'advancements': [26], 'in': [27, 42, 64, 70, 162], 'a': [28], 'variety': [29], 'different': [31], 'fields': [32], 'business.': [34], 'However,': [35], 'these': [36], 'cross-disciplinary': [37], 'technologies': [38], 'present': [39], 'significant': [40], 'difficulties': [41], 'terms': [43], 'maintaining': [45], 'confidentiality': [46], 'safeguarding': [48], 'data.': [49], 'This': [50, 84], 'article': [51], 'digs': [52], 'into': [53, 88], 'issues': [55], 'establishing': [57], 'robust': [58], 'security': [59, 104, 116, 147], 'protecting': [61], 'user': [62, 135], 'privacy': [63, 108, 149], 'IoT': [65], 'that': [67, 126], 'are': [68, 77], 'utilized': [78, 129], 'AI': [80], 'robotics': [82], 'applications.': [83], 'study': [85, 113, 141], 'gives': [86], 'insights': [87], 'possible': [90], 'hazards': [91], 'encountered': [92], 'by': [93, 97], 'such': [94], 'interconnected': [95], 'conducting': [98], 'an': [99], 'in-depth': [100], 'review': [101], 'existing': [103], 'threats,': [105], 'vulnerabilities,': [106], 'concerns.': [109], 'In': [110], 'addition,': [111], 'investigates': [114], 'cutting-edge': [115], 'mechanisms,': [117], 'encryption': [118], 'approaches,': [119], 'access': [120], 'control': [121], 'strategies,': [122], 'privacy-preserving': [124], 'solutions': [125, 150], 'can': [127], 'be': [128], 'to': [130, 151], 'safeguard': [131], 'data,': [132], 'communications,': [133], 'identities.': [136], 'The': [137], 'results': [138], 'this': [140], 'highlight': [142], 'demand': [144], 'comprehensive': [146], 'support': [152], 'mainstream': [154], 'deployment': [155], 'Fog/Cloud-based': [157], 'field': [164], 'artificial': [166], 'intelligence': [167], 'robotics.': [169]}",2023,"['Cloud computing', 'Computer security', 'Computer science', 'Software deployment', 'Robotics', 'Artificial intelligence', 'Confidentiality', 'Robot', 'Operating system']","Integration of Internet of Things (IoT) systems based on the fog or the cloud with Artificial Intelligence (AI) and Robotics has prepared the way for breakthrough advancements in a variety of different fields of business. However, these cross-disciplinary technologies present significant difficulties in terms of maintaining confidentiality and safeguarding data. This article digs into the issues of establishing robust security and protecting user privacy in IoT systems that are based in the fog or the cloud and are utilized for AI and robotics applications. This study gives insights into the possible hazards encountered by such interconnected systems by conducting an in-depth review of existing security threats, vulnerabilities, and privacy concerns. In addition, the study investigates cutting-edge security mechanisms, encryption approaches, access control strategies, and privacy-preserving solutions that can be utilized to safeguard data, communications, and user identities. The results of this study highlight the demand for comprehensive security and privacy solutions to support the mainstream deployment of Fog/Cloud-based Internet of Things systems in the field of artificial intelligence and robotics."
https://openalex.org/W3182941862,Consumer Privacy Protection With the Growth of AI-Empowered Online Shopping Based on the Evolutionary Game Model,"{'Social': [0], 'distancing': [1], 'due': [2], 'to': [3, 11, 70, 105, 177, 185, 192, 211], 'the': [4, 24, 45, 58, 81, 107, 125, 136, 138, 144, 183, 201, 219], 'COVID-19': [5], 'pandemic': [6, 17], 'has': [7], 'driven': [8], 'some': [9], 'consumers': [10, 38, 102], 'online': [12], 'shopping,': [13], 'and': [14, 19, 37, 85, 101, 115, 189, 196, 224], 'concerns': [15], 'about': [16], 'risks': [18], 'personal': [20, 160], 'hygiene': [21], 'have': [22, 66, 77], 'increased': [23], 'demand': [25], 'for': [26, 34, 167, 174], 'e-commerce.': [27], 'Providing': [28], 'personalized': [29, 42], 'recommendations': [30], 'seems': [31], 'quite': [32], 'profitable': [33, 173], 'e-commerce': [35, 99, 150, 163, 175, 222], 'platforms,': [36], 'also': [39], 'benefit': [40, 153], 'from': [41, 80, 121], 'content': [43], 'with': [44, 130, 162, 165], 'advancement': [46], 'of': [47, 83, 95, 146, 203, 206, 221], 'AI': [48, 147, 187], 'technologies.': [49], 'However,': [50], 'this': [51, 89], 'possible': [52], 'win-win': [53], 'situation': [54], 'is': [55, 103, 172], 'marred': [56], 'by': [57, 109, 181], 'increase': [59, 218], 'in': [60, 149], ""consumers'"": [61, 226], 'privacy': [62, 96], 'concerns.': [63], 'Technical': [64], 'solutions': [65], 'been': [67, 78], 'widely': [68], 'studied': [69], 'protect': [71, 225], 'consumer': [72, 213], 'privacy,': [73], 'while': [74], 'few': [75], 'analyses': [76], 'conducted': [79], 'perspective': [82], 'psychological': [84], 'behavioral': [86], 'implications.': [87], 'In': [88], 'paper,': [90], 'an': [91], 'evolutionary': [92, 116], 'game': [93], 'model': [94], 'protection': [97], 'between': [98], 'platforms': [100, 164, 176, 223], 'established': [104], 'determine': [106], 'mechanisms': [108], 'which': [110, 155, 215], 'various': [111], 'factors': [112], 'exert': [113], 'influence,': [114], 'stable': [117], 'strategies': [118], 'are': [119, 128, 141], 'obtained': [120], 'equilibrium': [122], 'points.': [123], 'Then,': [124], 'strategy': [126], 'selections': [127], 'simulated': [129], 'MATLAB': [131], '2020': [132], 'software.': [133], 'Based': [134], 'on': [135], 'results,': [137], 'following': [139], 'conclusions': [140], 'drawn:': [142], '(1)': [143], 'application': [145], 'technologies': [148, 188], 'will': [151], 'fundamentally': [152], 'consumers,': [154], 'makes': [156], 'them': [157], 'actively': [158], 'share': [159], 'information': [161], 'incentives': [166], 'generous': [168], 'rewards;': [169], '(2)': [170], 'it': [171], 'conduct': [178], 'data': [179], 'mining': [180], 'improving': [182], 'ability': [184], 'use': [186], 'making': [190], 'efforts': [191], 'reduce': [193], 'technical': [194], 'costs;': [195], '(3)': [197], 'regulators': [198], 'should': [199], 'improve': [200], 'level': [202], 'supervision': [204], 'instead': [205], 'imposing': [207], 'a': [208], 'large': [209], 'penalty': [210], 'enhance': [212], 'trust,': [214], 'could': [216], 'effectively': [217], 'profits': [220], 'privacy.': [227]}",2021,"['Cheating', 'Internet privacy', 'Incentive', 'E-commerce', 'Consumer privacy', 'Business', 'Computer science', 'Computer security', 'Information privacy', 'Economics', 'World Wide Web', 'Microeconomics', 'Social psychology', 'Psychology']","Social distancing due to the COVID-19 pandemic has driven some consumers to online shopping, and concerns about pandemic risks and personal hygiene have increased the demand for e-commerce. Providing personalized recommendations seems quite profitable for e-commerce platforms, and consumers also benefit from personalized content with the advancement of AI technologies. However, this possible win-win situation is marred by the increase in consumers' privacy concerns. Technical solutions have been widely studied to protect consumer privacy, while few analyses have been conducted from the perspective of psychological and behavioral implications. In this paper, an evolutionary game model of privacy protection between e-commerce platforms and consumers is established to determine the mechanisms by which various factors exert influence, and evolutionary stable strategies are obtained from equilibrium points. Then, the strategy selections are simulated with MATLAB 2020 software. Based on the results, the following conclusions are drawn: (1) the application of AI technologies in e-commerce will fundamentally benefit consumers, which makes them actively share personal information with e-commerce platforms with incentives for generous rewards; (2) it is profitable for e-commerce platforms to conduct data mining by improving the ability to use AI technologies and making efforts to reduce technical costs; and (3) regulators should improve the level of supervision instead of imposing a large penalty to enhance consumer trust, which could effectively increase the profits of e-commerce platforms and protect consumers' privacy."
https://openalex.org/W4392902292,Insights Into Privacy Protection Research in AI,"{'This': [0], 'paper': [1, 222], 'presents': [2], 'a': [3, 85, 150, 170, 191, 198], 'systematic': [4], 'bibliometric': [5, 39], 'analysis': [6, 58, 180], 'of': [7, 49, 107, 119, 138, 239], 'the': [8, 41, 47, 74, 81, 99, 108, 113, 120, 221, 232, 237], 'artificial': [9], 'intelligence': [10], '(AI)': [11], 'domain': [12], 'to': [13, 55, 149, 157, 182, 213], 'explore': [14], 'privacy': [15, 24, 139, 158, 216, 234], 'protection': [16], 'research': [17, 35, 141, 188, 195], 'as': [18, 71, 84], 'AI': [19, 240], 'technologies': [20], 'integrate': [21], 'and': [22, 30, 64, 67, 80, 112, 129, 155, 176, 186, 197, 202, 241], 'data': [23, 153], 'concerns': [25, 235], 'rise.': [26], 'Understanding': [27], 'evolutionary': [28], 'patterns': [29], 'current': [31], 'trends': [32], 'in': [33, 93, 127, 194, 200, 236], 'this': [34], 'is': [36, 142, 211], 'crucial.': [37], 'Leveraging': [38], 'techniques,': [40], 'authors': [42], 'analyze': [43], '8,322': [44], 'papers': [45], 'from': [46, 145], 'Web': [48], 'Science': [50], '(WoS)': [51], 'database,': [52], 'spanning': [53], '1990': [54], '2023.': [56], 'The': [57, 88, 136, 179], 'highlights': [59], 'IEEE': [60, 68], 'Transactions': [61], 'on': [62, 152], 'Knowledge': [63], 'Data': [65], 'Engineering': [66], 'Access': [69], 'journals': [70], 'highly': [72], 'influential,': [73], 'former': [75], 'being': [76], 'an': [77, 146], 'early': [78], 'contributor': [79], 'latter': [82], 'emerging': [83, 184], 'pivotal': [86, 228], 'source.': [87], 'study': [89], 'demonstrates': [90], 'substantial': [91], 'disparities': [92], 'scientific': [94, 134], 'productivity': [95], 'across': [96], 'countries.': [97], 'Specifically,': [98, 220], 'top': [100], '10': [101], 'countries': [102], 'collectively': [103], 'accounted': [104], 'for': [105, 218, 229], '74.8%': [106], 'articles,': [109], 'with': [110], 'China': [111], 'USA': [114], 'making': [115], 'up': [116], 'nearly': [117], 'half': [118], 'total': [121], 'contribution': [122], '(46.1%).': [123], 'In': [124, 164], 'contrast,': [125], 'regions': [126], 'Africa': [128], 'South': [130], 'America': [131], 'exhibited': [132], 'lower': [133], 'production.': [135], 'evolution': [137], 'preservation': [140], 'reflected,': [143], 'shifting': [144], 'algorithm-oriented': [147], 'approach': [148], 'focus': [151], 'orientation,': [154], 'subsequently,': [156], 'solutions': [159, 217], 'centered': [160], 'around': [161], 'Cloud': [162], 'Computing.': [163], 'recent': [165], 'years,': [166], 'there': [167], 'has': [168], 'been': [169], 'shift': [171], 'towards': [172], 'embracing': [173], 'Federated': [174], 'Learning': [175], 'Differential': [177], 'Privacy.': [178], 'brings': [181], 'light': [183], 'themes': [185], 'identifies': [187], 'gaps,': [189], 'notably': [190], 'global': [192], 'disparity': [193], 'output': [196], 'lag': [199], 'ethical': [201], 'legal': [203], 'inquiry.': [204], 'It': [205], 'asserts': [206], 'that': [207, 226], 'enhanced': [208], 'interdisciplinary': [209], 'collaboration': [210], 'imperative': [212], 'formulate': [214], 'comprehensive': [215], 'AI.': [219], 'imparts': [223], 'invaluable': [224], 'insights': [225], 'are': [227], 'effectively': [230], 'addressing': [231], 'evolving': [233], 'era': [238], 'big': [242], 'data.': [243]}",2024,"['Privacy protection', 'Computer science', 'Information privacy', 'Internet privacy', 'Computer security', 'Privacy software']","This paper presents a systematic bibliometric analysis of the artificial intelligence (AI) domain to explore privacy protection research as AI technologies integrate and data privacy concerns rise. Understanding evolutionary patterns and current trends in this research is crucial. Leveraging bibliometric techniques, the authors analyze 8,322 papers from the Web of Science (WoS) database, spanning 1990 to 2023. The analysis highlights IEEE Transactions on Knowledge and Data Engineering and IEEE Access journals as highly influential, the former being an early contributor and the latter emerging as a pivotal source. The study demonstrates substantial disparities in scientific productivity across countries. Specifically, the top 10 countries collectively accounted for 74.8% of the articles, with China and the USA making up nearly half of the total contribution (46.1%). In contrast, regions in Africa and South America exhibited lower scientific production. The evolution of privacy preservation research is reflected, shifting from an algorithm-oriented approach to a focus on data orientation, and subsequently, to privacy solutions centered around Cloud Computing. In recent years, there has been a shift towards embracing Federated Learning and Differential Privacy. The analysis brings to light emerging themes and identifies research gaps, notably a global disparity in research output and a lag in ethical and legal inquiry. It asserts that enhanced interdisciplinary collaboration is imperative to formulate comprehensive privacy solutions for AI. Specifically, the paper imparts invaluable insights that are pivotal for effectively addressing the evolving privacy concerns in the era of AI and big data."
https://openalex.org/W4399159256,AI-driven anonymization: Protecting personal data privacy while leveraging machine learning,"{'AbstractThe': [0], 'development': [1], 'of': [2, 25, 33, 45, 91, 109], 'artificial': [3], 'intelligence': [4, 58], 'has': [5, 12, 52], 'significantly': [6], 'transformed': [7], ""people's"": [8], 'lives.': [9], 'However,': [10], 'it': [11], 'also': [13, 118], 'posed': [14], 'a': [15, 54], 'significant': [16], 'threat': [17], 'to': [18, 41, 64, 126, 140], 'privacy': [19, 86, 102, 113, 127, 145], 'and': [20, 31, 36, 62, 67, 75, 88, 104, 128, 135, 147], 'security,': [21], 'with': [22], 'numerous': [23], 'instances': [24], 'personal': [26, 46, 69, 84, 100, 129, 143], 'information': [27, 47], 'being': [28], 'exposed': [29], 'online': [30], 'reports': [32], 'criminal': [34], 'attacks': [35], 'theft.': [37], 'Consequently,': [38], 'the': [39, 89, 107], 'need': [40], 'achieve': [42], 'intelligent': [43], 'protection': [44, 87, 103, 114], 'through': [48, 106], 'machine': [49, 110, 123], 'learning': [50, 124], 'algorithms': [51, 61], 'become': [53], 'paramount': [55], 'concern.': [56], 'Artificial': [57], 'leverages': [59], 'advanced': [60], 'technologies': [63], 'effectively': [65], 'encrypt': [66], 'anonymize': [68], 'data,': [70], 'enabling': [71], 'valuable': [72], 'data': [73, 85, 101, 130, 144], 'analysis': [74], 'utilization': [76], 'while': [77], 'safeguarding': [78], 'privacy.': [79], 'This': [80], 'paper': [81, 117], 'focuses': [82], 'on': [83], 'promotion': [90], 'anonymity': [92], 'as': [93], 'its': [94], 'core': [95], 'research': [96], 'objectives.': [97], 'It': [98], 'achieves': [99], 'detection': [105, 146], 'use': [108], ""learning's"": [111], 'differential': [112], 'algorithm.': [115], 'The': [116], 'addresses': [119], 'existing': [120], 'challenges': [121], 'in': [122], 'related': [125], 'protection,': [131], 'offers': [132], 'improvement': [133], 'suggestions,': [134], 'analyzes': [136], 'factors': [137], 'impacting': [138], 'datasets': [139], 'enable': [141], 'timely': [142], 'protection.': [148]}",2024,"['Personally identifiable information', 'Safeguarding', 'Computer science', 'Data Protection Act 1998', 'Internet privacy', 'Computer security', 'Information privacy', 'Encryption', 'Anonymity', 'Differential privacy', 'Privacy by Design', 'Privacy protection', 'Privacy software', 'Data mining', 'Nursing', 'Medicine']","AbstractThe development of artificial intelligence has significantly transformed people's lives. However, it has also posed a significant threat to privacy and security, with numerous instances of personal information being exposed online and reports of criminal attacks and theft. Consequently, the need to achieve intelligent protection of personal information through machine learning algorithms has become a paramount concern. Artificial intelligence leverages advanced algorithms and technologies to effectively encrypt and anonymize personal data, enabling valuable data analysis and utilization while safeguarding privacy. This paper focuses on personal data privacy protection and the promotion of anonymity as its core research objectives. It achieves personal data privacy protection and detection through the use of machine learning's differential privacy protection algorithm. The paper also addresses existing challenges in machine learning related to privacy and personal data protection, offers improvement suggestions, and analyzes factors impacting datasets to enable timely personal data privacy detection and protection."
https://openalex.org/W4401862241,The role of deep learning in ensuring privacy integrity and security: Applications in AI-driven cybersecurity solutions,"{'This': [0], 'article': [1, 49], 'explores': [2], 'the': [3, 52, 61, 80], 'critical': [4], 'role': [5], 'of': [6, 54, 66], 'deep': [7, 27, 89], 'learning': [8, 34, 90], 'in': [9, 45, 99], 'developing': [10], 'AI-driven': [11], 'cybersecurity': [12], 'solutions,': [13], 'with': [14], 'a': [15, 100], 'particular': [16], 'focus': [17], 'on': [18], 'privacy': [19, 97], 'integrity': [20, 98], 'and': [21, 31, 41, 64, 77, 96], 'information': [22], 'security.': [23], 'It': [24], 'investigates': [25], 'how': [26, 85], 'neural': [28], 'networks': [29], '(DNNs)': [30], 'advanced': [32], 'machine': [33], 'techniques': [35], 'are': [36], 'being': [37], 'used': [38], 'to': [39, 69, 92], 'detect': [40], 'neutralize': [42], 'cyber': [43], 'threats': [44], 'real': [46], 'time.': [47], 'The': [48], 'also': [50], 'considers': [51], 'implications': [53], 'these': [55], 'technologies': [56], 'for': [57], 'data': [58], 'privacy,': [59], 'discussing': [60], 'potential': [62], 'risks': [63], 'benefits': [65], 'using': [67], 'AI': [68], 'protect': [70], 'sensitive': [71], 'information.': [72], 'By': [73], 'examining': [74], 'case': [75], 'studies': [76], 'current': [78], 'research,': [79], 'piece': [81], 'provides': [82], 'insights': [83], 'into': [84], 'organizations': [86], 'can': [87], 'deploy': [88], 'models': [91], 'enhance': [93], 'both': [94], 'security': [95], 'digital': [101], 'world.': [102]}",2024,"['Computer security', 'Computer science', 'Data integrity', 'Internet privacy']","This article explores the critical role of deep learning in developing AI-driven cybersecurity solutions, with a particular focus on privacy integrity and information security. It investigates how deep neural networks (DNNs) and advanced machine learning techniques are being used to detect and neutralize cyber threats in real time. The article also considers the implications of these technologies for data privacy, discussing the potential risks and benefits of using AI to protect sensitive information. By examining case studies and current research, the piece provides insights into how organizations can deploy deep learning models to enhance both security and privacy integrity in a digital world."
https://openalex.org/W4388947060,"Open AI meets open notes: surveillance capitalism, patient privacy and online record access","{'Patient': [0], 'online': [1], 'record': [2], 'access': [3, 17, 24], '(ORA)': [4], 'is': [5, 18], 'spreading': [6], 'worldwide,': [7], 'and': [8, 14, 61, 78, 83, 119, 157, 194], 'in': [9, 122, 130], 'some': [10], 'countries,': [11], 'including': [12, 72, 88, 146], 'Sweden,': [13], 'the': [15, 30, 40, 117, 147, 154], 'USA,': [16], 'advanced': [19], 'with': [20, 128, 153, 189], 'patients': [21, 58], 'obtaining': [22], 'rapid': [23], 'to': [25, 54, 57, 103, 113, 137, 179], 'their': [26, 69, 80], 'full': [27], 'records.': [28], 'In': [29], 'UK': [31], 'context,': [32], 'from': [33, 67, 107], '31': [34], 'October': [35], '2023': [36], 'as': [37], 'part': [38], 'of': [39, 95, 116, 132, 150, 159, 163, 198], 'new': [41, 161], 'NHS': [42], 'England': [43], 'general': [44], 'practitioner': [45], '(GP)': [46], 'contract': [47], 'it': [48], 'will': [49], 'be': [50, 206], 'mandatory': [51], 'for': [52, 174, 201], 'GPs': [53], 'offer': [55], 'ORA': [56, 187], 'aged': [59], '16': [60], 'older.': [62], 'Patients': [63], 'report': [64], 'many': [65], 'benefits': [66, 100], 'reading': [68], 'clinical': [70], 'records': [71], 'feeling': [73], 'more': [74], 'empowered,': [75], 'better': [76, 207], 'understanding': [77], 'remembering': [79], 'treatment': [81], 'plan,': [82], 'greater': [84], 'awareness': [85], 'about': [86], 'medications': [87], 'possible': [89], 'adverse': [90], 'effects.': [91], 'However,': [92], 'a': [93, 160, 170, 196], 'variety': [94, 197], 'indirect': [96], 'evidence': [97], 'suggests': [98], 'these': [99, 203], 'are': [101], 'unlikely': [102], 'accrue': [104], 'without': [105], 'supplementation': [106], 'internet-based': [108], 'resources.': [109], 'Using': [110], 'such': [111], 'routes': [112], 'augment': [114], 'interpretation': [115], 'data': [118], 'notes': [120], 'housed': [121], 'electronic': [123], 'health': [124], 'records,': [125], 'however,': [126], 'comes': [127], 'trade-offs': [129], 'terms': [131], 'exposing': [133, 175], 'sensitive': [134, 176], 'patient': [135, 177], 'information': [136, 178], 'internet': [138, 190], 'corporations.': [139], 'Furthermore,': [140], 'increased': [141], 'work': [142], 'burdens': [143], 'on': [144], 'clinicians,': [145], 'unique': [148], 'demands': [149], 'ORA,': [151], 'combined': [152], 'easy': [155], 'availability': [156], 'capability': [158], 'generation': [162], 'large': [164], 'language': [165], 'model': [166], '(LLM)-powered': [167], 'chatbots,': [168], 'create': [169], 'perfect': [171], 'collision': [172], 'course': [173], 'private': [180], 'tech': [181], 'companies.': [182], 'This': [183], 'paper': [184], 'surveys': [185], 'how': [186, 202], 'intersects': [188], 'associated': [191], 'privacy': [192], 'risks': [193, 204], 'offers': [195], 'multilevel': [199], 'suggestions': [200], 'might': [205], 'mitigated.': [208]}",2023,"['Internet privacy', 'Variety (cybernetics)', 'Context (archaeology)', 'The Internet', 'Medicine', 'Reading (process)', 'Feeling', 'Patient portal', 'Business', 'Public relations', 'World Wide Web', 'Computer science', 'Health care', 'Psychology', 'Political science', 'Artificial intelligence', 'Law', 'Social psychology', 'Paleontology', 'Biology']","Patient online record access (ORA) is spreading worldwide, and in some countries, including Sweden, and the USA, access is advanced with patients obtaining rapid access to their full records. In the UK context, from 31 October 2023 as part of the new NHS England general practitioner (GP) contract it will be mandatory for GPs to offer ORA to patients aged 16 and older. Patients report many benefits from reading their clinical records including feeling more empowered, better understanding and remembering their treatment plan, and greater awareness about medications including possible adverse effects. However, a variety of indirect evidence suggests these benefits are unlikely to accrue without supplementation from internet-based resources. Using such routes to augment interpretation of the data and notes housed in electronic health records, however, comes with trade-offs in terms of exposing sensitive patient information to internet corporations. Furthermore, increased work burdens on clinicians, including the unique demands of ORA, combined with the easy availability and capability of a new generation of large language model (LLM)-powered chatbots, create a perfect collision course for exposing sensitive patient information to private tech companies. This paper surveys how ORA intersects with internet associated privacy risks and offers a variety of multilevel suggestions for how these risks might be better mitigated."
https://openalex.org/W4408256503,Recent Innovations in AI Privacy: Protecting Data in the Age of Machine Learning,"{'This': [0], 'comprehensive': [1], 'article': [2, 32, 52, 81], 'explores': [3], 'recent': [4], 'advancements': [5], 'in': [6, 41, 63, 71], 'privacy-preserving': [7, 24], 'technologies': [8, 36, 85], 'within': [9], 'artificial': [10], 'intelligence': [11], 'systems,': [12], 'focusing': [13], 'on': [14], 'five': [15], 'key': [16], 'approaches:': [17], 'federated': [18], 'learning,': [19], 'differential': [20], 'privacy,': [21], 'homomorphic': [22], 'encryption,': [23], 'machine': [25, 42, 77], 'learning': [26, 43, 78], '(PPML),': [27], 'and': [28, 49, 65], 'zero-knowledge': [29], 'proofs.': [30], 'The': [31, 51, 80], 'examines': [33], 'how': [34, 83], 'these': [35, 57, 84], 'address': [37], 'critical': [38], 'privacy': [39, 92], 'challenges': [40], 'environments': [44], 'while': [45, 95], 'maintaining': [46], 'model': [47], 'performance': [48], 'utility.': [50], 'highlights': [53], 'the': [54, 76, 100], 'implementation': [55], 'of': [56, 102], 'approaches': [58], 'across': [59], 'various': [60], 'domains,': [61], 'particularly': [62], 'healthcare': [64], 'financial': [66], 'services,': [67], 'demonstrating': [68], 'their': [69], 'effectiveness': [70], 'protecting': [72], 'sensitive': [73], 'data': [74, 106], 'throughout': [75], 'lifecycle.': [79], 'reveals': [82], 'complement': [86], 'each': [87], 'other': [88], 'to': [89, 98], 'create': [90], 'robust': [91], 'protection': [93], 'frameworks': [94], 'enabling': [96], 'organizations': [97], 'leverage': [99], 'power': [101], 'AI': [103], 'without': [104], 'compromising': [105], 'confidentiality.': [107]}",2025,"['Computer science', 'Internet privacy', 'Computer security', 'Information privacy', 'Data science', 'Artificial intelligence']","This comprehensive article explores recent advancements in privacy-preserving technologies within artificial intelligence systems, focusing on five key approaches: federated learning, differential privacy, homomorphic encryption, privacy-preserving machine learning (PPML), and zero-knowledge proofs. The article examines how these technologies address critical privacy challenges in machine learning environments while maintaining model performance and utility. The article highlights the implementation of these approaches across various domains, particularly in healthcare and financial services, demonstrating their effectiveness in protecting sensitive data throughout the machine learning lifecycle. The article reveals how these technologies complement each other to create robust privacy protection frameworks while enabling organizations to leverage the power of AI without compromising data confidentiality."
https://openalex.org/W4220703535,Privacy-preserving AI for future networks,"{'No': [0], 'abstract': [1], 'available.': [2]}",2022,"['Computer science', 'Computer security', 'Internet privacy', 'Artificial intelligence']",No abstract available.
https://openalex.org/W3198090163,IoT Solution for AI-Enabled PRIVACY-PREServing with Big Data Transferring: An Application for Healthcare Using Blockchain,"{'Internet': [0], 'of': [1, 36, 66, 85, 140, 188], 'Things': [2], '(IoT)': [3], 'performs': [4], 'a': [5, 120, 124], 'vital': [6], 'role': [7], 'in': [8, 44, 186], 'providing': [9], 'connectivity': [10], 'between': [11], 'computing': [12], 'devices,': [13], 'processes,': [14], 'and': [15, 23, 41, 54, 59, 76, 87, 126, 131, 147, 164, 183], 'things.': [16], 'It': [17], 'significantly': [18], 'increases': [19], 'the': [20, 31, 34, 63, 67, 92, 116, 138, 143, 152], 'communication': [21, 168], 'facilities': [22], 'giving': [24], 'up-to-date': [25], 'information': [26], 'to': [27, 56, 101, 122, 161], 'distributed': [28], 'networks.': [29], 'On': [30], 'other': [32], 'hand,': [33], 'techniques': [35], 'artificial': [37, 144], 'intelligence': [38, 145], 'offer': [39, 162], 'numerous': [40], 'valuable': [42], 'services': [43, 150], 'emerging': [45], 'fields.': [46], 'An': [47], 'IoT-based': [48], 'healthcare': [49, 153], 'solution': [50, 68, 105], 'facilitates': [51], 'patients,': [52], 'hospitals,': [53], 'professionals': [55], 'observe': [57], 'real-time': [58], 'critical': [60], 'data.': [61, 133], 'In': [62, 134], 'literature,': [64], 'most': [65], 'suffers': [69], 'from': [70], 'data': [71, 90, 111], 'intermission,': [72], 'high': [73], 'ethical': [74], 'standards,': [75], 'trustworthiness': [77], 'communication.': [78], 'Moreover,': [79], 'network': [80, 95], 'interruption': [81], 'with': [82, 109, 167, 177], 'recurrent': [83], 'expose': [84], 'sensitive': [86], 'personal': [88], 'health': [89], 'decreases': [91], 'reliance': [93], 'on': [94], 'systems.': [96], 'Therefore,': [97], 'this': [98], 'paper': [99], 'intends': [100], 'propose': [102], 'an': [103], 'IoT': [104], 'for': [106, 129, 151], 'AI-enabled': [107], 'privacy-preserving': [108], 'big': [110], 'transferring': [112], 'using': [113, 142, 170], 'blockchain.': [114, 171], 'Firstly,': [115], 'proposed': [117, 173], 'algorithm': [118, 174], 'uses': [119], 'graph-modeling': [121], 'develop': [123], 'scalable': [125], 'reliable': [127], 'system': [128], 'gathering': [130], 'transmitting': [132], 'addition,': [135], 'it': [136], 'extracts': [137], 'subset': [139], 'nodes': [141], 'approach': [146], 'achieves': [148], 'efficient': [149], 'system.': [154], 'Secondly,': [155], 'symmetric-based': [156], 'digital': [157], 'certificates': [158], 'are': [159], 'utilized': [160], 'authentic': [163], 'confidential': [165], 'transmission': [166], 'resources': [169], 'The': [172], 'is': [175], 'explored': [176], 'existing': [178], 'solutions': [179], 'through': [180], 'multiple': [181], 'simulations': [182], 'proved': [184], 'improvement': [185], 'terms': [187], 'realistic': [189], 'parameters.': [190]}",2021,"['Computer science', 'Scalability', 'Blockchain', 'Big data', 'Confidentiality', 'Internet of Things', 'Computer security', 'Distributed computing', 'Computer network', 'Data mining', 'Database']","Internet of Things (IoT) performs a vital role in providing connectivity between computing devices, processes, and things. It significantly increases the communication facilities and giving up-to-date information to distributed networks. On the other hand, the techniques of artificial intelligence offer numerous and valuable services in emerging fields. An IoT-based healthcare solution facilitates patients, hospitals, and professionals to observe real-time and critical data. In the literature, most of the solution suffers from data intermission, high ethical standards, and trustworthiness communication. Moreover, network interruption with recurrent expose of sensitive and personal health data decreases the reliance on network systems. Therefore, this paper intends to propose an IoT solution for AI-enabled privacy-preserving with big data transferring using blockchain. Firstly, the proposed algorithm uses a graph-modeling to develop a scalable and reliable system for gathering and transmitting data. In addition, it extracts the subset of nodes using the artificial intelligence approach and achieves efficient services for the healthcare system. Secondly, symmetric-based digital certificates are utilized to offer authentic and confidential transmission with communication resources using blockchain. The proposed algorithm is explored with existing solutions through multiple simulations and proved improvement in terms of realistic parameters."
https://openalex.org/W4402915134,Security and Privacy in E-Health Systems: A Review of AI and Machine Learning Techniques,"{'The': [0, 108, 188], 'adoption': [1], 'of': [2, 31, 35, 105, 132, 156, 190], 'electronic': [3], 'health': [4, 23, 83, 238], '(e-health)': [5], 'systems': [6, 160], 'has': [7], 'transformed': [8], 'healthcare': [9, 60, 231], 'delivery': [10], 'by': [11], 'harnessing': [12], 'digital': [13], 'technologies': [14], 'to': [15, 45, 168], 'enhance': [16], 'patient': [17, 179, 235], 'care,': [18], 'optimize': [19], 'operations,': [20], 'and': [21, 51, 56, 62, 98, 123, 130, 135, 144, 173, 199, 220, 229, 237], 'improve': [22], 'outcomes.': [24, 239], 'This': [25], 'paper': [26, 109, 139], 'provides': [27], 'a': [28], 'comprehensive': [29], 'overview': [30], 'the': [32, 53, 69, 102, 128, 138, 154, 223], 'current': [33], 'state': [34], 'e-health': [36, 106, 224], 'systems,': [37], 'tracing': [38], 'their': [39], 'evolution': [40], 'from': [41], 'traditional': [42], 'paper-based': [43], 'records': [44], 'advanced': [46, 90, 157], 'Electronic': [47], 'Health': [48], 'Record': [49], 'Systems(EHRs)': [50], 'examining': [52], 'diverse': [54], 'components': [55], 'applications': [57], 'that': [58, 161, 177], 'support': [59], 'providers': [61], 'patients.': [63], 'A': [64], 'key': [65], 'focus': [66], 'is': [67], 'on': [68], 'emerging': [70], 'trends': [71], 'in': [72, 87, 147], 'AI-driven': [73, 148], 'cybersecurity': [74, 149], 'for': [75, 80, 150, 186], 'e-health,': [76], 'which': [77], 'are': [78, 204], 'essential': [79], 'protecting': [81], 'sensitive': [82], 'data.': [84], 'AI&#x2019;s': [85], 'capabilities': [86], 'continuous': [88, 164], 'monitoring,': [89], 'pattern': [91], 'recognition,': [92], 'real-time': [93], 'threat': [94, 133, 158], 'response,': [95], 'predictive': [96], 'analytics,': [97], 'scalability': [99], 'fundamentally': [100], 'change': [101], 'security': [103, 115, 214], 'landscape': [104], 'systems.': [107], 'discusses': [110], 'how': [111], 'AI': [112, 175, 202], 'strengthens': [113], 'data': [114, 183, 195], 'through': [116, 163], 'techniques': [117, 176], 'like': [118], 'anomaly': [119], 'detection,': [120], 'automated': [121], 'countermeasures,': [122], 'adaptive': [124], 'learning': [125], 'algorithms,': [126], 'enhancing': [127, 234], 'efficiency': [129], 'accuracy': [131], 'detection': [134, 159], 'response.': [136], 'Furthermore,': [137], 'delves': [140], 'into': [141], 'future': [142, 171], 'directions': [143], 'research': [145, 209], 'opportunities': [146], 'e-health.': [151], 'These': [152], 'include': [153], 'development': [155, 203], 'adapt': [162], 'learning,': [165], 'quantum-resistant': [166], 'encryption': [167], 'safeguard': [169], 'against': [170], 'threats,': [172], 'privacy-preserving': [174], 'protect': [178], 'confidentiality': [180], 'while': [181], 'ensuring': [182], 'remains': [184], 'useful': [185], 'analysis.': [187], 'importance': [189], 'automating': [191], 'regulatory': [192], 'compliance,': [193], 'securing': [194], 'interoperability': [196], 'via': [197], 'blockchain,': [198], 'prioritizing': [200], 'ethical': [201, 221], 'also': [205], 'highlighted': [206], 'as': [207], 'critical': [208], 'areas.': [210], 'By': [211], 'emphasizing': [212], 'innovative': [213], 'solutions,': [215], 'collaborative': [216], 'efforts,': [217], 'ongoing': [218], 'research,': [219], 'practices,': [222], 'sector': [225], 'can': [226], 'build': [227], 'resilient': [228], 'secure': [230], 'infrastructures,': [232], 'ultimately': [233], 'care': [236]}",2024,"['Computer science', 'Computer security', 'Information privacy', 'Internet privacy']","The adoption of electronic health (e-health) systems has transformed healthcare delivery by harnessing digital technologies to enhance patient care, optimize operations, and improve health outcomes. This paper provides a comprehensive overview of the current state of e-health systems, tracing their evolution from traditional paper-based records to advanced Electronic Health Record Systems(EHRs) and examining the diverse components and applications that support healthcare providers and patients. A key focus is on the emerging trends in AI-driven cybersecurity for e-health, which are essential for protecting sensitive health data. AI&#x2019;s capabilities in continuous monitoring, advanced pattern recognition, real-time threat response, predictive analytics, and scalability fundamentally change the security landscape of e-health systems. The paper discusses how AI strengthens data security through techniques like anomaly detection, automated countermeasures, and adaptive learning algorithms, enhancing the efficiency and accuracy of threat detection and response. Furthermore, the paper delves into future directions and research opportunities in AI-driven cybersecurity for e-health. These include the development of advanced threat detection systems that adapt through continuous learning, quantum-resistant encryption to safeguard against future threats, and privacy-preserving AI techniques that protect patient confidentiality while ensuring data remains useful for analysis. The importance of automating regulatory compliance, securing data interoperability via blockchain, and prioritizing ethical AI development are also highlighted as critical research areas. By emphasizing innovative security solutions, collaborative efforts, ongoing research, and ethical practices, the e-health sector can build resilient and secure healthcare infrastructures, ultimately enhancing patient care and health outcomes."
https://openalex.org/W4283373744,Privacy-Preserving and Explainable AI in Industrial Applications,"{'The': [0], 'industrial': [1, 24, 33, 75, 156], 'environment': [2], 'has': [3, 48, 64, 94], 'gone': [4], 'through': [5], 'the': [6, 14, 32, 58, 66, 115, 124, 150, 155, 181, 184, 188], 'fourth': [7], 'revolution,': [8], 'also': [9, 123, 168], 'called': [10, 31], '“Industry': [11], '4.0”,': [12], 'where': [13], 'main': [15], 'aspect': [16], 'is': [17, 26, 106, 122], 'digitalization.': [18], 'Each': [19], 'device': [20], 'employed': [21], 'in': [22, 77, 187], 'an': [23], 'process': [25, 83], 'connected': [27], 'to': [28, 51, 73, 98, 126, 134, 149, 172], 'a': [29, 108], 'network': [30], 'Internet': [34], 'of': [35, 43, 61, 68, 101, 158], 'things': [36], '(IIOT).': [37], 'With': [38], 'IIOT': [39], 'manufacturers': [40], 'being': [41], 'capable': [42], 'tracking': [44], 'every': [45], 'device,': [46], 'it': [47, 112], 'become': [49], 'easier': [50], 'prevent': [52], 'or': [53], 'quickly': [54], 'solve': [55], 'failures.': [56], 'Specifically,': [57], 'large': [59], 'amount': [60], 'available': [62], 'data': [63, 89], 'allowed': [65], 'use': [67], 'artificial': [69], 'intelligence': [70], '(AI)': [71], 'algorithms': [72, 130], 'improve': [74], 'applications': [76], 'many': [78], 'ways': [79], '(e.g.,': [80], 'failure': [81], 'detection,': [82], 'optimization,': [84], 'and': [85, 161, 174, 178], 'abnormality': [86], 'detection).': [87], 'Although': [88], 'are': [90], 'abundant,': [91], 'their': [92], 'access': [93], 'raised': [95], 'problems': [96], 'due': [97], 'privacy': [99], 'concerns': [100], 'manufacturers.': [102], 'Censoring': [103], 'sensitive': [104], 'information': [105], 'not': [107], 'desired': [109], 'approach': [110], 'because': [111], 'negatively': [113], 'impacts': [114], 'AI': [116, 129, 176], 'performance.': [117], 'To': [118], 'increase': [119], 'trust,': [120], 'there': [121], 'need': [125], 'understand': [127], 'how': [128], 'make': [131], 'choices,': [132], 'i.e.,': [133], 'no': [135], 'longer': [136], 'regard': [137], 'them': [138], 'as': [139], 'black': [140], 'boxes.': [141], 'This': [142], 'paper': [143], 'focuses': [144], 'on': [145, 180], 'recent': [146], 'advancements': [147], 'related': [148, 171], 'challenges': [151, 163, 186], 'mentioned': [152], 'above,': [153], 'discusses': [154], 'impact': [157], 'proposed': [159], 'solutions,': [160, 177], 'identifies': [162], 'for': [164], 'future': [165], 'research.': [166], 'It': [167], 'presents': [169], 'examples': [170], 'privacy-preserving': [173], 'explainable': [175], 'comments': [179], 'interaction': [182], 'between': [183], 'identified': [185], 'conclusions.': [189]}",2022,"['Industrial Internet', 'Computer science', 'Industry 4.0', 'Process (computing)', 'Computer security', 'Risk analysis (engineering)', 'Data science', 'Internet of Things', 'Data mining', 'Business', 'Operating system']","The industrial environment has gone through the fourth revolution, also called “Industry 4.0”, where the main aspect is digitalization. Each device employed in an industrial process is connected to a network called the industrial Internet of things (IIOT). With IIOT manufacturers being capable of tracking every device, it has become easier to prevent or quickly solve failures. Specifically, the large amount of available data has allowed the use of artificial intelligence (AI) algorithms to improve industrial applications in many ways (e.g., failure detection, process optimization, and abnormality detection). Although data are abundant, their access has raised problems due to privacy concerns of manufacturers. Censoring sensitive information is not a desired approach because it negatively impacts the AI performance. To increase trust, there is also the need to understand how AI algorithms make choices, i.e., to no longer regard them as black boxes. This paper focuses on recent advancements related to the challenges mentioned above, discusses the industrial impact of proposed solutions, and identifies challenges for future research. It also presents examples related to privacy-preserving and explainable AI solutions, and comments on the interaction between the identified challenges in the conclusions."
https://openalex.org/W4200581430,Openness and privacy in born-digital archives: reflecting the role of AI development,"{'Abstract': [0], 'Galleries,': [1], 'libraries,': [2], 'archives': [3, 85, 119, 170, 219], 'and': [4, 55, 66, 94, 108, 125, 128, 138, 148, 175, 202], 'museums': [5], '(GLAMs)': [6], 'are': [7, 50, 80], 'striving': [8], 'to': [9, 13, 16, 82, 86, 89, 114, 133, 166, 193, 206, 220], 'retain': [10], 'audience': [11, 25], 'attention': [12], 'issues': [14, 109], 'related': [15], 'cultural': [17, 35], 'heritage,': [18], 'by': [19, 172], 'implementing': [20], 'various': [21], 'novel': [22], 'opportunities': [23], 'for': [24, 34, 196, 214], 'engagement': [26, 93], 'through': [27, 141], 'technological': [28], 'means': [29], 'online.': [30], 'Although': [31], 'born-digital': [32, 84, 118, 169, 218], 'assets': [33], 'heritage': [36], 'may': [37], 'have': [38], 'inundated': [39], 'the': [40, 47, 56, 59, 91, 97, 104, 115, 151, 180, 183, 187, 207, 215], 'Internet': [41], 'in': [42, 52, 164, 179], 'some': [43], 'areas,': [44], 'most': [45], 'of': [46, 58, 69, 99, 106, 110, 153, 158, 182, 210, 217], 'time': [48], 'they': [49], 'stored': [51], '“digital': [53], 'warehouses,”': [54], 'questions': [57], 'digital': [60], 'ecosystem’s': [61], 'sustainability,': [62], 'meaningful': [63], 'public': [64, 116], 'participation': [65], 'creative': [67], 'reuse': [68], 'data': [70, 107], 'still': [71], 'remain.': [72], 'Emerging': [73], 'technologies,': [74], 'such': [75], 'as': [76], 'artificial': [77], 'intelligence': [78], '(AI),': [79], 'used': [81], 'bring': [83], 'light,': [87], 'aiming': [88], 'enhance': [90], 'public’s': [92], 'participation.': [95], 'At': [96], 'core': [98], 'this': [100], 'debate': [101], 'lies': [102], 'both': [103], 'openness': [105, 137], 'privacy.': [111], 'How': [112], 'open': [113, 124], 'should': [117], 'be?': [120], 'Should': [121], 'everything': [122], 'be': [123], 'available': [126], 'online,': [127, 171], 'what': [129], 'does': [130], 'it': [131], 'take': [132], 'achieve': [134], 'balance': [135], 'between': [136], 'privacy,': [139], 'especially': [140], 'AI': [142, 159, 194], 'initiatives?': [143], 'The': [144, 156], 'study': [145], 'is': [146, 161], 'qualitative': [147], 'builds': [149], 'on': [150], 'rationale': [152], 'grounded': [154], 'theory.': [155], 'role': [157], 'development': [160, 195, 199], 'critically': [162], 'investigated': [163], 'relation': [165], 'opening': [167], 'up': [168], 'considering': [173], 'privacy': [174], 'ethics': [176], 'issues.': [177], 'Grounded': [178], 'context': [181], 'author’s': [184], 'PhD': [185], 'research,': [186], 'paper': [188], 'proposes': [189], 'a': [190], 'human-centred': [191], 'approach': [192], 'democratising': [197], 'its': [198], 'towards': [200], 'fairness': [201], 'social': [203], 'inclusion,': [204], 'contrary': [205], 'stereotypical': [208], 'cliché': [209], 'blackboxing,': [211], 'allowing': [212], 'space': [213], 'plurality': [216], 'flourish.': [221]}",2021,"['Sociology', 'Context (archaeology)', 'Internet privacy', 'Public relations', 'Grounded theory', 'Public participation', 'World Wide Web', 'Political science', 'Computer science', 'Qualitative research', 'Social science', 'Paleontology', 'Biology']","Abstract Galleries, libraries, archives and museums (GLAMs) are striving to retain audience attention to issues related to cultural heritage, by implementing various novel opportunities for audience engagement through technological means online. Although born-digital assets for cultural heritage may have inundated the Internet in some areas, most of the time they are stored in “digital warehouses,” and the questions of the digital ecosystem’s sustainability, meaningful public participation and creative reuse of data still remain. Emerging technologies, such as artificial intelligence (AI), are used to bring born-digital archives to light, aiming to enhance the public’s engagement and participation. At the core of this debate lies both the openness of data and issues of privacy. How open to the public should born-digital archives be? Should everything be open and available online, and what does it take to achieve balance between openness and privacy, especially through AI initiatives? The study is qualitative and builds on the rationale of grounded theory. The role of AI development is critically investigated in relation to opening up born-digital archives online, by considering privacy and ethics issues. Grounded in the context of the author’s PhD research, the paper proposes a human-centred approach to AI development for democratising its development towards fairness and social inclusion, contrary to the stereotypical cliché of blackboxing, allowing space for the plurality of born-digital archives to flourish."
https://openalex.org/W3186952419,Privacy-preserving AI-enabled video surveillance for social distancing: responsible design and deployment for public spaces,"{'Purpose': [0], 'The': [1, 19, 97, 113, 147], 'paper': [2, 20, 148], 'proposes': [3, 21, 154, 182], 'a': [4, 22, 67, 93, 103, 155, 167, 183, 202, 209], 'privacy-preserving': [5], 'artificial': [6, 40, 144, 189], 'intelligence-enabled': [7], 'video': [8, 192], 'surveillance': [9, 193], 'technology': [10], 'to': [11, 29, 47, 52, 71, 78, 135, 176, 186, 215], 'monitor': [12], 'social': [13, 108, 157], 'distancing': [14, 109, 158], 'in': [15, 126, 191, 205], 'public': [16], 'spaces.': [17], 'Design/methodology/approach': [18], 'new': [23], 'Responsible': [24], 'Artificial': [25], 'Intelligence': [26], 'Implementation': [27], 'Framework': [28], 'guide': [30], 'the': [31, 44, 54, 57, 63, 87, 117, 122, 136, 206, 217], 'proposed': [32, 64, 98, 218], ""solution's"": [33], 'design': [34, 184], 'and': [35, 49, 81, 85, 139, 173, 199, 222], 'development.': [36], 'It': [37], 'defines': [38], 'responsible': [39, 143, 188], 'intelligence': [41, 190], 'criteria': [42, 55], 'that': [43, 164], 'solution': [45], 'needs': [46], 'meet': [48], 'provides': [50], 'checklists': [51], 'enforce': [53], 'throughout': [56], 'process.': [58], 'To': [59], 'preserve': [60], 'data': [61, 83], 'privacy,': [62], 'system': [65, 99, 118, 161], 'incorporates': [66], 'federated': [68], 'learning': [69], 'approach': [70, 185], 'allow': [72], 'computation': [73], 'performed': [74], 'on': [75, 162], 'edge': [76, 163], 'devices': [77], 'limit': [79], 'sensitive': [80], 'identifiable': [82], 'movement': [84], 'eliminate': [86], 'dependency': [88], 'of': [89, 106, 128, 169, 208], 'cloud': [90], 'computing': [91], 'at': [92, 110, 212], 'central': [94], 'server.': [95], 'Findings': [96], 'is': [100], 'evaluated': [101], 'through': [102], 'case': [104, 123, 210], 'study': [105, 211], 'monitoring': [107], 'an': [111, 213], 'airport.': [112], 'results': [114, 198], 'discuss': [115], 'how': [116], 'can': [119], 'fully': [120], 'address': [121], ""study's"": [124], 'requirements': [125], 'terms': [127], 'its': [129, 131, 140], 'reliability,': [130], 'usefulness': [132], 'when': [133], 'deployed': [134], ""airport's"": [137], 'cameras,': [138], 'compliance': [141], 'with': [142], 'intelligence.': [145], 'Originality/value': [146], 'makes': [149], 'three': [150], 'contributions.': [151], 'First,': [152], 'it': [153, 181, 196], 'real-time': [156], 'breach': [159], 'detection': [160, 172], 'extends': [165], 'from': [166, 201], 'combination': [168], 'cutting-edge': [170], 'people': [171], 'tracking': [174], 'algorithms': [175], 'achieve': [177], 'robust': [178, 220], 'performance.': [179], 'Second,': [180], 'develop': [187], 'contexts.': [194], 'Third,': [195], 'presents': [197], 'discussion': [200], 'comprehensive': [203], 'evaluation': [204], 'context': [207], 'airport': [214], 'demonstrate': [216], ""system's"": [219], 'performance': [221], 'practical': [223], 'usefulness.': [224]}",2021,"['Computer science', 'Software deployment', 'Context (archaeology)', 'Cloud computing', 'Computer security', 'Social distance', 'Process (computing)', 'Artificial intelligence', 'Medicine', 'Pathology', 'Paleontology', 'Infectious disease (medical specialty)', 'Biology', 'Disease', 'Coronavirus disease 2019 (COVID-19)', 'Operating system']","Purpose The paper proposes a privacy-preserving artificial intelligence-enabled video surveillance technology to monitor social distancing in public spaces. Design/methodology/approach The paper proposes a new Responsible Artificial Intelligence Implementation Framework to guide the proposed solution's design and development. It defines responsible artificial intelligence criteria that the solution needs to meet and provides checklists to enforce the criteria throughout the process. To preserve data privacy, the proposed system incorporates a federated learning approach to allow computation performed on edge devices to limit sensitive and identifiable data movement and eliminate the dependency of cloud computing at a central server. Findings The proposed system is evaluated through a case study of monitoring social distancing at an airport. The results discuss how the system can fully address the case study's requirements in terms of its reliability, its usefulness when deployed to the airport's cameras, and its compliance with responsible artificial intelligence. Originality/value The paper makes three contributions. First, it proposes a real-time social distancing breach detection system on edge that extends from a combination of cutting-edge people detection and tracking algorithms to achieve robust performance. Second, it proposes a design approach to develop responsible artificial intelligence in video surveillance contexts. Third, it presents results and discussion from a comprehensive evaluation in the context of a case study at an airport to demonstrate the proposed system's robust performance and practical usefulness."
https://openalex.org/W4405021351,Generative AI model privacy: a survey,"{'Abstract': [0], 'The': [1], 'rapid': [2], 'progress': [3], 'of': [4, 17, 78, 89, 137], 'generative': [5, 60, 90, 119, 140], 'AI': [6, 61, 91, 120, 141], 'models': [7, 34], 'has': [8], 'yielded': [9], 'substantial': [10], 'breakthroughs': [11], 'in': [12, 59, 115, 134], 'AI,': [13], 'facilitating': [14], 'the': [15, 33, 79, 107, 127, 131, 135], 'generation': [16], 'realistic': [18], 'synthetic': [19], 'data': [20], 'across': [21], 'various': [22], 'modalities.': [23], 'However,': [24], 'these': [25], 'advancements': [26], 'also': [27], 'introduce': [28], 'significant': [29], 'privacy': [30, 52, 58, 138], 'risks,': [31], 'as': [32], 'may': [35], 'inadvertently': [36], 'expose': [37], 'sensitive': [38], 'information': [39], 'from': [40], 'their': [41, 102], 'training': [42], 'data.': [43], 'Currently,': [44], 'there': [45], 'is': [46], 'no': [47], 'comprehensive': [48], 'survey': [49, 84], 'work': [50], 'investigating': [51], 'issues,': [53], 'e.g.,': [54], 'attacking': [55], 'and': [56, 70, 73, 101, 113, 129, 139], 'defending': [57], 'models.': [62, 121, 142], 'We': [63], 'strive': [64], 'to': [65, 74], 'identify': [66], 'existing': [67], 'attack': [68], 'techniques': [69, 117], 'mitigation': [71], 'strategies': [72], 'offer': [75, 124], 'a': [76, 86], 'summary': [77], 'current': [80], 'research': [81, 112], 'landscape.': [82], 'Our': [83], 'encompasses': [85], 'wide': [87], 'array': [88], 'models,': [92, 95, 100], 'including': [93], 'language': [94], 'Generative': [96], 'Adversarial': [97], 'Networks,': [98], 'diffusion': [99], 'multi-modal': [103], 'counterparts.': [104], 'It': [105], 'indicates': [106], 'critical': [108], 'need': [109], 'for': [110, 118], 'continued': [111], 'development': [114], 'privacy-preserving': [116], 'Furthermore,': [122], 'we': [123], 'insights': [125], 'into': [126], 'challenges': [128], 'discuss': [130], 'open': [132], 'problems': [133], 'intersection': [136]}",2024,"['Generative grammar', 'Computer science', 'Intersection (aeronautics)', 'Generative model', 'Modalities', 'Adversarial system', 'Data science', 'Artificial intelligence', 'Machine learning', 'Sociology', 'Engineering', 'Aerospace engineering', 'Social science']","Abstract The rapid progress of generative AI models has yielded substantial breakthroughs in AI, facilitating the generation of realistic synthetic data across various modalities. However, these advancements also introduce significant privacy risks, as the models may inadvertently expose sensitive information from their training data. Currently, there is no comprehensive survey work investigating privacy issues, e.g., attacking and defending privacy in generative AI models. We strive to identify existing attack techniques and mitigation strategies and to offer a summary of the current research landscape. Our survey encompasses a wide array of generative AI models, including language models, Generative Adversarial Networks, diffusion models, and their multi-modal counterparts. It indicates the critical need for continued research and development in privacy-preserving techniques for generative AI models. Furthermore, we offer insights into the challenges and discuss the open problems in the intersection of privacy and generative AI models."
https://openalex.org/W4399530860,Privacy and Copyright Protection in Generative AI: A Lifecycle Perspective,"{'The': [0], 'advent': [1], 'of': [2, 73], 'Generative': [3, 129], 'AI': [4], 'has': [5], 'marked': [6], 'a': [7, 115], 'significant': [8], 'milestone': [9], 'in': [10, 16, 128], 'artificial': [11], 'intelligence,': [12], 'demonstrating': [13], 'remarkable': [14], 'capabilities': [15], 'generating': [17], 'realistic': [18], 'images,': [19], 'texts,': [20], 'and': [21, 34, 55, 75, 100, 118, 125], 'data': [22, 32, 56, 80, 123], 'patterns.': [23], 'However,': [24], 'these': [25, 63, 96], 'advancements': [26], 'come': [27], 'with': [28, 91], 'heightened': [29], 'concerns': [30, 97], 'over': [31], 'privacy': [33, 74, 124], 'copyright': [35, 76, 126], 'infringement,': [36], 'primarily': [37], 'due': [38], 'to': [39, 62, 113], 'the': [40, 70, 79, 107], 'reliance': [41], 'on': [42], 'vast': [43], 'datasets': [44], 'for': [45, 84], 'model': [46], 'training.': [47], 'Traditional': [48], 'approaches': [49, 86], 'like': [50], 'differential': [51], 'privacy,': [52], 'machine': [53], 'unlearning,': [54], 'poisoning': [57], 'only': [58], 'offer': [59], 'fragmented': [60], 'solutions': [61, 102], 'complex': [64], 'issues.': [65], 'Our': [66], 'paper': [67], 'delves': [68], 'into': [69], 'multifaceted': [71], 'challenges': [72], 'protection': [77], 'within': [78], 'lifecycle.': [81], 'We': [82], 'advocate': [83], 'integrated': [85], 'that': [87, 103], 'combines': [88], 'technical': [89], 'innovation': [90], 'ethical': [92], 'foresight,': [93], 'holistically': [94], 'addressing': [95], 'by': [98, 106], 'investigating': [99], 'devising': [101], 'are': [104], 'informed': [105], 'lifecycle': [108], 'perspective.': [109], 'This': [110], 'work': [111], 'aims': [112], 'catalyze': [114], 'broader': [116], 'discussion': [117], 'inspire': [119], 'concerted': [120], 'efforts': [121], 'towards': [122], 'integrity': [127], 'AI.': [130]}",2024,"['Generative grammar', 'Perspective (graphical)', 'Futures studies', 'Computer science', 'Differential privacy', 'Data Protection Act 1998', 'Milestone', 'Data science', 'Information privacy', 'Knowledge management', 'Computer security', 'Artificial intelligence', 'Data mining', 'History', 'Archaeology']","The advent of Generative AI has marked a significant milestone in artificial intelligence, demonstrating remarkable capabilities in generating realistic images, texts, and data patterns. However, these advancements come with heightened concerns over data privacy and copyright infringement, primarily due to the reliance on vast datasets for model training. Traditional approaches like differential privacy, machine unlearning, and data poisoning only offer fragmented solutions to these complex issues. Our paper delves into the multifaceted challenges of privacy and copyright protection within the data lifecycle. We advocate for integrated approaches that combines technical innovation with ethical foresight, holistically addressing these concerns by investigating and devising solutions that are informed by the lifecycle perspective. This work aims to catalyze a broader discussion and inspire concerted efforts towards data privacy and copyright integrity in Generative AI."
https://openalex.org/W4395480811,AI-powered malware detection with Differential Privacy for zero trust security in Internet of Things networks,"{'<p': [0], 'dir=""ltr"">The': [1], 'widespread': [2], 'usage': [3], 'of': [4, 10, 46, 50, 67, 122, 170, 189, 200, 248, 298, 310], 'Android-powered': [5], 'devices': [6, 22], 'in': [7, 23, 83, 182], 'the': [8, 44, 65, 129, 159, 168, 173, 187, 196, 201, 205, 291, 296, 308, 315], '<u>Internet': [9], 'Things</u>': [11], '(IoT)': [12], 'makes': [13], 'them': [14], 'susceptible': [15], 'to': [16, 98, 114, 139, 207, 235, 243, 251, 274, 289, 318], 'evolving': [17], 'cybersecurity': [18, 183], 'threats.': [19], 'Most': [20], 'healthcare': [21], 'IoT': [24, 68, 84, 156], 'networks,': [25, 85], 'such': [26], 'as': [27], 'smart': [28, 30], 'watches,': [29], 'thermometers,': [31], 'biosensors,': [32], 'and': [33, 63, 93, 191, 211, 215, 241, 301, 326], 'more,': [34], 'are': [35, 125, 261], 'powered': [36], 'by': [37, 293], 'the<u>': [38], 'Android</u>': [39], 'operating': [40], 'system,': [41], 'where': [42], 'preserving': [43], 'privacy': [45, 181, 222, 265], 'user-sensitive': [47], 'data': [48, 171], 'is': [49, 255, 314], '<u>utmost': [51], 'importance</u>.': [52], 'Detecting': [53], '<u>Android': [54, 75], 'malware': [55, 213, 256, 321], '</u>is': [56], 'thus': [57], 'vital': [58], 'for': [59, 78, 110, 155, 180, 245], 'protecting': [60], '<u>sensitive</u>': [61], 'information': [62], 'ensuring': [64], 'reliability': [66], 'networks.': [69], 'This': [70], 'article': [71, 345], 'focuses': [72], 'on': [73, 117, 323, 346], 'AI-enabled': [74], 'malware</u>': [76], 'detection': [77, 142, 174], 'improving': [79, 305], 'zero': [80, 102, 160, 192], 'trust': [81, 103, 161, 193], 'security': [82, 104, 194], 'which': [86], 'requires': [87, 106], '<u>Android</u><u>': [88], 'applications': [89, 250], '</u>to': [90], 'be': [91], 'verified': [92], 'authenticated': [94], 'before': [95], 'providing': [96], 'access': [97, 115], 'network': [99, 333], 'resources.': [100], 'The': [101], 'model': [105], 'strict': [107, 221], '<u>identity': [108], '</u>verification': [109], 'every': [111], 'entity': [112], 'trying': [113], 'resources': [116], 'a': [118, 149, 177, 330], 'private': [119], 'network,': [120], 'regardless': [121], 'whether': [123, 253], 'they': [124], 'inside': [126], 'or': [127, 257], 'outside': [128], '<u>network': [130], 'perimeter</u>.': [131], 'Our': [132], 'proposed': [133, 283], 'solution,': [134], 'DP-RFECV-FNN,': [135], 'an': [136, 230], 'innovative': [137], 'approach': [138], 'Android': [140, 249, 320], '<u>malware</u>': [141], 'that': [143], 'employs': [144], 'Differential': [145], 'Privacy': [146], '(<u>DP</u>)': [147], 'within': [148], 'Feedforward': [150], 'Neural': [151], 'Network': [152], '(<u>FNN</u>)': [153], 'designed': [154], 'networks': [157], 'under': [158, 263], 'model.': [162], 'By': [163, 185], 'integrating': [164], '<u>DP</u>,': [165], 'we': [166], 'ensure': [167], 'confidentiality': [169], 'during': [172], 'process,': [175], 'setting': [176], 'new': [178], 'standard': [179], 'solutions.': [184], 'combining': [186], 'strengths': [188], 'DP': [190], 'with': [195, 225], 'powerful': [197], 'learning': [198], 'capacity': [199], 'FNN,': [202], 'DP-RFECV-FNN': [203, 228], 'demonstrates': [204], 'ability': [206], 'identify': [208], 'both': [209, 324], 'known': [210], 'novel': [212], 'types': [214], 'achieves': [216, 229], 'higher': [217], 'accuracy': [218, 231], 'while': [219, 237, 304], 'maintaining': [220], 'controls': [223], 'compared': [224], 'recent': [226], 'papers.': [227], 'ranging': [232, 267], 'from': [233, 268], '97.78%': [234], '99.21%': [236], 'utilizing': [238], 'static': [239, 325], 'features': [240, 247, 300, 328], '93.49%': [242], '94.36%': [244], 'dynamic': [246, 327], 'detect': [252], 'it': [254], 'benign.': [258], 'These': [259], 'results': [260], 'achieved': [262], 'varying': [264], 'budgets,': [266], 'ϵ': [269, 275], '=': [270, 276], '0': [271, 279], '.': [272, 278, 280], '1': [273, 277], 'Furthermore,': [281], 'our': [282, 311], 'feature': [284], 'selection': [285], 'pipeline': [286], 'enables': [287], 'us': [288], 'outperform': [290], 'state-of-the-art': [292], 'significantly': [294], 'reducing': [295], 'number': [297], 'selected': [299], 'training': [302], 'time': [303], 'accuracy.': [306], 'To': [307], 'best': [309], 'knowledge,': [312], 'this': [313], 'first': [316], 'work': [317], 'categorize': [319], 'based': [322], 'through': [329], 'privacy-preserving': [331], '<u>neural': [332], 'model.</u>': [334], '<h2>Other': [335], 'Information</h2><p': [336], 'dir=""ltr"">Published': [337], 'in:': [338], 'Ad': [339], 'Hoc': [340], 'Networks<br>License:': [341], '<a': [342, 349], 'href=""http://creativecommons.org/licenses/by/4.0/""': [343], 'target=""_blank"">http://creativecommons.org/licenses/by/4.0/</a><br>See': [344], ""publisher's"": [347], 'website:': [348], 'href=""https://dx.doi.org/10.1016/j.adhoc.2024.103523""': [350], 'target=""_blank"">https://dx.doi.org/10.1016/j.adhoc.2024.103523</a>': [351]}",2024,"['Internet of Things', 'Computer security', 'Internet privacy', 'Malware', 'Zero (linguistics)', 'Computer science', 'Differential privacy', 'Zero-knowledge proof', 'The Internet', 'Cryptography', 'World Wide Web', 'Data mining', 'Philosophy', 'Linguistics']","<p dir=""ltr"">The widespread usage of Android-powered devices in the <u>Internet of Things</u> (IoT) makes them susceptible to evolving cybersecurity threats. Most healthcare devices in IoT networks, such as smart watches, smart thermometers, biosensors, and more, are powered by the<u> Android</u> operating system, where preserving the privacy of user-sensitive data is of <u>utmost importance</u>. Detecting <u>Android malware </u>is thus vital for protecting <u>sensitive</u> information and ensuring the reliability of IoT networks. This article focuses on AI-enabled <u>Android malware</u> detection for improving zero trust security in IoT networks, which requires <u>Android</u><u> applications </u>to be verified and authenticated before providing access to network resources. The zero trust security model requires strict <u>identity </u>verification for every entity trying to access resources on a private network, regardless of whether they are inside or outside the <u>network perimeter</u>. Our proposed solution, DP-RFECV-FNN, an innovative approach to Android <u>malware</u> detection that employs Differential Privacy (<u>DP</u>) within a Feedforward Neural Network (<u>FNN</u>) designed for IoT networks under the zero trust model. By integrating <u>DP</u>, we ensure the confidentiality of data during the detection process, setting a new standard for privacy in cybersecurity solutions. By combining the strengths of DP and zero trust security with the powerful learning capacity of the FNN, DP-RFECV-FNN demonstrates the ability to identify both known and novel malware types and achieves higher accuracy while maintaining strict privacy controls compared with recent papers. DP-RFECV-FNN achieves an accuracy ranging from 97.78% to 99.21% while utilizing static features and 93.49% to 94.36% for dynamic features of Android applications to detect whether it is malware or benign. These results are achieved under varying privacy budgets, ranging from ϵ = 0 . 1 to ϵ = 1 . 0 . Furthermore, our proposed feature selection pipeline enables us to outperform the state-of-the-art by significantly reducing the number of selected features and training time while improving accuracy. To the best of our knowledge, this is the first work to categorize Android malware based on both static and dynamic features through a privacy-preserving <u>neural network model.</u> <h2>Other Information</h2><p dir=""ltr"">Published in: Ad Hoc Networks<br>License: <a href=""http://creativecommons.org/licenses/by/4.0/"" target=""_blank"">http://creativecommons.org/licenses/by/4.0/</a><br>See article on publisher's website: <a href=""https://dx.doi.org/10.1016/j.adhoc.2024.103523"" target=""_blank"">https://dx.doi.org/10.1016/j.adhoc.2024.103523</a>"
https://openalex.org/W3138069867,How Blockchain and AI Enable Personal Data Privacy and Support Cybersecurity,"{'Recent': [0], 'increases': [1], 'in': [2, 22], 'security': [3], 'breaches': [4], 'and': [5, 14, 24, 33, 47, 65, 78, 84], 'digital': [6], 'surveillance': [7], 'highlight': [8], 'the': [9], 'need': [10], 'for': [11, 40, 75], 'improved': [12, 86], 'privacy': [13, 49], 'security,': [15, 80], 'particularly': [16], 'over': [17], 'users’': [18], 'personal': [19], 'data.': [20, 69], 'Advances': [21], 'cybersecurity': [23], 'new': [25], 'legislation': [26], 'promise': [27], 'to': [28, 63], 'improve': [29], 'data': [30, 43, 82], 'protection.': [31], 'Blockchain': [32], 'distributed': [34], 'ledger': [35], 'technologies': [36], 'provide': [37], 'novel': [38], 'opportunities': [39], 'protecting': [41], 'user': [42, 79], 'through': [44, 58], 'decentralized': [45], 'identity': [46], 'other': [48], 'mechanisms.': [50], 'These': [51], 'systems': [52], 'can': [53], 'allow': [54], 'users': [55], 'greater': [56], 'sovereignty': [57], 'tools': [59], 'that': [60], 'enable': [61], 'them': [62], 'own': [64, 68], 'control': [66], 'their': [67], 'Artificial': [70], 'intelligence': [71], 'provides': [72], 'further': [73], 'possibilities': [74], 'enhancing': [76], 'system': [77], 'enriching': [81], 'sets,': [83], 'supporting': [85], 'analytical': [87], 'models.': [88]}",2021,"['Blockchain', 'Computer security', 'Data Protection Act 1998', 'Data breach', 'Computer science', 'Information privacy', 'Internet privacy', 'Digital identity', 'Identity theft', 'Access control']","Recent increases in security breaches and digital surveillance highlight the need for improved privacy and security, particularly over users’ personal data. Advances in cybersecurity and new legislation promise to improve data protection. Blockchain and distributed ledger technologies provide novel opportunities for protecting user data through decentralized identity and other privacy mechanisms. These systems can allow users greater sovereignty through tools that enable them to own and control their own data. Artificial intelligence provides further possibilities for enhancing system and user security, enriching data sets, and supporting improved analytical models."
https://openalex.org/W4400042109,Privacy-Centric AI and IoT Solutions for Smart Rural Farm Monitoring and Control,"{'The': [0, 46, 132, 150], 'integration': [1], 'of': [2, 9, 22, 116, 142, 157, 186, 204, 212], 'artificial': [3], 'intelligence': [4], '(AI)': [5], 'and': [6, 29, 35, 43, 62, 93, 121, 124, 146, 160, 168, 178, 192], 'the': [7, 20, 87, 89, 94, 98, 101, 114, 117, 122, 126, 139, 155, 158], 'Internet': [8, 143], 'Things': [10], '(IoT)': [11], 'in': [12, 166, 207], 'agriculture': [13], 'has': [14, 25], 'significantly': [15], 'transformed': [16], 'rural': [17, 68, 171], 'farming.': [18], 'However,': [19], 'adoption': [21], 'these': [23, 50], 'technologies': [24], 'also': [26, 136], 'introduced': [27], 'privacy': [28], 'security': [30, 152], 'concerns,': [31], 'particularly': [32], 'unauthorized': [33], 'breaches': [34], 'cyber-attacks': [36], 'on': [37], 'data': [38, 84, 127], 'collected': [39], 'from': [40], 'IoT': [41, 63, 90, 118], 'devices': [42, 120], 'sensitive': [44], 'information.': [45], 'present': [47], 'study': [48], 'addresses': [49], 'concerns': [51], 'by': [52, 73, 112], 'developing': [53], 'a': [54, 75, 79, 108, 183, 193, 202, 208], 'comprehensive': [55], 'framework': [56, 76], 'that': [57, 77, 82], 'provides': [58], 'practical,': [59], 'privacy-centric': [60], 'AI': [61, 167], 'solutions': [64], 'for': [65, 106, 163, 189], 'monitoring': [66], 'smart': [67, 170], 'farms.': [69], 'This': [70], 'is': [71, 104, 135], 'performed': [72], 'designing': [74], 'includes': [78], 'three-phase': [80], 'protocol': [81, 134, 159], 'secures': [83], 'exchange': [85], 'between': [86], 'User,': [88], 'Sensor': [91, 119], 'Layer,': [92], 'Central': [95, 102], 'Server.': [96], 'In': [97], 'proposed': [99, 133], 'protocol,': [100], 'Server': [103], 'responsible': [105], 'establishing': [107], 'secure': [109], 'communication': [110], 'channel': [111], 'verifying': [113], 'legitimacy': [115], 'User': [123], 'securing': [125], 'using': [128, 138], 'rigorous': [129], 'cryptographic': [130], 'techniques.': [131], 'validated': [137], 'Automated': [140], 'Validation': [141], 'Security': [144], 'Protocols': [145], 'Applications': [147], '(AVISPA)': [148], 'tool.': [149], 'formal': [151], 'analysis': [153], 'confirms': [154], 'robustness': [156], 'its': [161], 'suitability': [162], 'real-time': [164], 'applications': [165], 'IoT-enabled': [169], 'farms,': [172], 'demonstrating': [173], 'resistance': [174], 'against': [175], 'various': [176], 'attacks': [177], 'enhanced': [179], 'performance': [180], 'metrics,': [181], 'including': [182], 'computation': [184], 'time': [185, 211], '0.04': [187], 's': [188], '11': [190], 'messages': [191], 'detailed': [194], 'search': [195, 210], 'where': [196], '119': [197], 'nodes': [198], 'were': [199], 'visited': [200], 'at': [201], 'depth': [203], '12': [205], 'plies': [206], 'mere': [209], '0.28': [213], 's.': [214]}",2024,"['Computer science', 'Computer security', 'Cryptographic protocol', 'Protocol (science)', 'Robustness (evolution)', 'Cryptography', 'Medicine', 'Gene', 'Pathology', 'Chemistry', 'Alternative medicine', 'Biochemistry']","The integration of artificial intelligence (AI) and the Internet of Things (IoT) in agriculture has significantly transformed rural farming. However, the adoption of these technologies has also introduced privacy and security concerns, particularly unauthorized breaches and cyber-attacks on data collected from IoT devices and sensitive information. The present study addresses these concerns by developing a comprehensive framework that provides practical, privacy-centric AI and IoT solutions for monitoring smart rural farms. This is performed by designing a framework that includes a three-phase protocol that secures data exchange between the User, the IoT Sensor Layer, and the Central Server. In the proposed protocol, the Central Server is responsible for establishing a secure communication channel by verifying the legitimacy of the IoT Sensor devices and the User and securing the data using rigorous cryptographic techniques. The proposed protocol is also validated using the Automated Validation of Internet Security Protocols and Applications (AVISPA) tool. The formal security analysis confirms the robustness of the protocol and its suitability for real-time applications in AI and IoT-enabled smart rural farms, demonstrating resistance against various attacks and enhanced performance metrics, including a computation time of 0.04 s for 11 messages and a detailed search where 119 nodes were visited at a depth of 12 plies in a mere search time of 0.28 s."
https://openalex.org/W4399732513,Responsible AI for cardiovascular disease detection: Towards a privacy-preserving and interpretable model,"{'Our': [0], 'study': [1], 'endorses': [2], 'a': [3, 54], 'novel': [4], 'approach': [5], 'in': [6, 42], 'predicting': [7], 'CD,': [8, 52], 'amalgamating': [9], 'data': [10], 'anonymization,': [11], 'privacy-preserving': [12], 'methods,': [13], 'interpretability': [14], 'tools': [15], 'SHAP,': [16], 'LIME,': [17], 'and': [18, 30, 38, 63], 'ethical': [19], 'considerations.': [20], 'This': [21], 'responsible': [22], 'AI': [23], 'framework': [24], 'ensures': [25], 'accurate': [26], 'predictions,': [27], 'privacy': [28], 'preservation,': [29], 'user': [31], 'trust,': [32], 'underscoring': [33], 'the': [34, 48], 'significance': [35], 'of': [36, 59], 'comprehensive': [37], 'transparent': [39], 'ML': [40], 'models': [41], 'healthcare.': [43], 'Therefore,': [44], 'this': [45], 'research': [46], 'empowers': [47], 'ability': [49], 'to': [50, 57], 'forecast': [51], 'providing': [53], 'vital': [55], 'lifeline': [56], 'millions': [58], 'CD': [60], 'patients': [61], 'globally': [62], 'potentially': [64], 'preventing': [65], 'numerous': [66], 'fatalities.': [67]}",2024,"['Computer science', 'Disease', 'Artificial intelligence', 'Patient privacy', 'Machine learning', 'Internet privacy', 'Data science', 'Medicine', 'Health care', 'Internal medicine', 'Economics', 'Economic growth']","Our study endorses a novel approach in predicting CD, amalgamating data anonymization, privacy-preserving methods, interpretability tools SHAP, LIME, and ethical considerations. This responsible AI framework ensures accurate predictions, privacy preservation, and user trust, underscoring the significance of comprehensive and transparent ML models in healthcare. Therefore, this research empowers the ability to forecast CD, providing a vital lifeline to millions of CD patients globally and potentially preventing numerous fatalities."
https://openalex.org/W4405213382,"The Ethical Implications of AI in Education: Privacy, Bias, and Accountability","{'As': [0], 'artificial': [1], 'intelligence': [2], '(AI)': [3], 'technologies': [4], 'become': [5], 'more': [6], 'prevalent': [7], 'in': [8, 29, 41], 'education,': [9], 'their': [10], 'influence': [11], 'on': [12], 'privacy,': [13, 37], 'fairness,': [14], 'and': [15, 44, 59, 74], 'responsibility': [16], 'is': [17], 'under': [18], 'increasing': [19], 'scrutiny.': [20], 'This': [21], 'paper': [22, 54], 'investigates': [23], 'the': [24, 45], 'ethical': [25, 63], 'implications': [26], 'of': [27], 'AI': [28, 42, 51, 67], 'educational': [30], 'settings,': [31], 'specifically': [32], 'examining': [33], 'concerns': [34], 'about': [35], 'student': [36], 'potential': [38], 'biases': [39], 'embedded': [40], 'systems,': [43], 'accountability': [46], 'structures': [47], 'necessary': [48], 'to': [49], 'manage': [50], 'responsibly.': [52], 'The': [53], 'advocates': [55], 'for': [56, 72], 'proactive': [57], 'policies': [58], 'practices': [60], 'that': [61, 81], 'prioritize': [62], 'standards,': [64], 'thereby': [65], 'ensuring': [66], 'serves': [68], 'as': [69], 'a': [70], 'tool': [71], 'equity': [73], 'improved': [75], 'learning': [76], 'outcomes': [77], 'rather': [78], 'than': [79], 'one': [80], 'exacerbates': [82], 'existing': [83], 'inequalities.': [84]}",2024,"['Accountability', 'Scrutiny', 'Equity (law)', 'Ethical issues', 'Engineering ethics', 'Psychology', 'Information privacy', 'Public relations', 'Political science', 'Internet privacy', 'Computer science', 'Law', 'Engineering']","As artificial intelligence (AI) technologies become more prevalent in education, their influence on privacy, fairness, and responsibility is under increasing scrutiny. This paper investigates the ethical implications of AI in educational settings, specifically examining concerns about student privacy, potential biases embedded in AI systems, and the accountability structures necessary to manage AI responsibly. The paper advocates for proactive policies and practices that prioritize ethical standards, thereby ensuring AI serves as a tool for equity and improved learning outcomes rather than one that exacerbates existing inequalities."
https://openalex.org/W4403485296,"Transparency, Privacy, and Accountability in AI-Enhanced HR Processes","{'The': [0, 70, 143], 'proliferation': [1], 'of': [2, 131, 148, 192], 'Artificial': [3], 'Intelligence': [4], '(AI)': [5], 'in': [6, 41, 82, 140, 152, 176, 194, 203, 215], 'Human': [7], 'Resource': [8], 'Management': [9], '(HRM)': [10], 'has': [11], 'transformed': [12], 'how': [13], 'organizations': [14], 'approach': [15], 'recruitment,': [16], 'performance': [17], 'evaluations,': [18], 'employee': [19], 'engagement,': [20], 'and': [21, 30, 47, 79, 86, 89, 92, 94, 115, 137, 161, 168], 'workforce': [22], 'planning.': [23], 'Despite': [24], 'AI’s': [25], 'potential': [26], 'to': [27, 64, 187, 207], 'improve': [28], 'efficiency': [29], 'reduce': [31], 'human': [32], 'biases,': [33], 'it': [34], 'also': [35, 97], 'introduces': [36], 'significant': [37], 'ethical': [38, 104, 132, 150, 190], 'challenges,': [39], 'particularly': [40], 'areas': [42], 'such': [43], 'as': [44], 'fairness,': [45], 'transparency,': [46], 'privacy.': [48], 'This': [49, 170], 'study': [50], 'develops': [51], 'a': [52, 124, 174], 'comprehensive': [53], 'theoretical': [54], 'framework': [55, 71, 202], 'that': [56, 154], 'equips': [57], 'HR': [58, 185], 'managers': [59, 186], 'with': [60, 117, 158], 'the': [61, 128, 146, 177, 189], 'competencies': [62, 105], 'necessary': [63], 'ethically': [65], 'govern': [66], 'AI-augmented': [67, 141], 'HRM': [68], 'processes.': [69], 'focuses': [72], 'on': [73, 134, 212], 'five': [74], 'key': [75], 'areas:': [76], 'bias': [77, 136], 'detection': [78], 'mitigation,': [80], 'fairness': [81, 139], 'AI-driven': [83], 'decisions,': [84], 'transparency': [85], 'explainability,': [87], 'privacy': [88], 'data': [90], 'protection,': [91], 'accountability': [93], 'oversight.': [95], 'It': [96], 'provides': [98], 'actionable': [99], 'strategies': [100], 'for': [101, 184], 'integrating': [102], 'these': [103], 'into': [106], 'organizational': [107, 159, 205], 'AI': [108, 118, 155, 193, 213], 'governance': [109, 133, 151, 214], 'through': [110], 'continuous': [111], 'training,': [112], 'policy': [113], 'development,': [114], 'collaboration': [116], 'specialists.': [119], 'Theoretical': [120], 'analysis,': [121], 'supported': [122], 'by': [123, 180], 'probability': [125], 'model,': [126], 'demonstrates': [127], 'positive': [129], 'impact': [130, 211], 'mitigating': [135], 'promoting': [138], 'decision-making.': [142], 'findings': [144], 'highlight': [145], 'importance': [147], 'proactive': [149], 'ensuring': [153], 'systems': [156], 'align': [157], 'values': [160], 'legal': [162], 'standards,': [163], 'fostering': [164], 'trust': [165], 'among': [166], 'employees': [167], 'stakeholders.': [169], 'paper’s': [171], 'contributions': [172], 'fill': [173], 'gap': [175], 'current': [178], 'literature': [179], 'offering': [181], 'practical': [182], 'guidance': [183], 'navigate': [188], 'complexities': [191], 'HRM.': [195, 216], 'Future': [196], 'research': [197], 'should': [198], 'empirically': [199], 'test': [200], 'this': [201], 'various': [204], 'contexts': [206], 'assess': [208], 'its': [209], 'long-term': [210]}",2024,"['Transparency (behavior)', 'Accountability', 'Internet privacy', 'Computer science', 'Information privacy', 'Business', 'Computer security', 'Political science', 'Law']","The proliferation of Artificial Intelligence (AI) in Human Resource Management (HRM) has transformed how organizations approach recruitment, performance evaluations, employee engagement, and workforce planning. Despite AI’s potential to improve efficiency and reduce human biases, it also introduces significant ethical challenges, particularly in areas such as fairness, transparency, and privacy. This study develops a comprehensive theoretical framework that equips HR managers with the competencies necessary to ethically govern AI-augmented HRM processes. The framework focuses on five key areas: bias detection and mitigation, fairness in AI-driven decisions, transparency and explainability, privacy and data protection, and accountability and oversight. It also provides actionable strategies for integrating these ethical competencies into organizational AI governance through continuous training, policy development, and collaboration with AI specialists. Theoretical analysis, supported by a probability model, demonstrates the positive impact of ethical governance on mitigating bias and promoting fairness in AI-augmented decision-making. The findings highlight the importance of proactive ethical governance in ensuring that AI systems align with organizational values and legal standards, fostering trust among employees and stakeholders. This paper’s contributions fill a gap in the current literature by offering practical guidance for HR managers to navigate the ethical complexities of AI in HRM. Future research should empirically test this framework in various organizational contexts to assess its long-term impact on AI governance in HRM."
https://openalex.org/W4392271008,AI-Driven Anonymization: Protecting Personal Data Privacy While Leveraging Machine Learning,"{'The': [0, 116], 'development': [1], 'of': [2, 25, 33, 45, 91, 109], 'artificial': [3], 'intelligence': [4, 58], 'has': [5, 12, 52], 'significantly': [6], 'transformed': [7], ""people's"": [8], 'lives.': [9], 'However,': [10], 'it': [11], 'also': [13, 118], 'posed': [14], 'a': [15, 54], 'significant': [16], 'threat': [17], 'to': [18, 41, 64, 126, 140], 'privacy': [19, 86, 102, 113, 127, 145], 'and': [20, 31, 36, 62, 67, 75, 88, 104, 128, 135, 147], 'security,': [21], 'with': [22], 'numerous': [23], 'instances': [24], 'personal': [26, 46, 69, 84, 100, 129, 143], 'information': [27, 47], 'being': [28], 'exposed': [29], 'online': [30], 'reports': [32], 'criminal': [34], 'attacks': [35], 'theft.': [37], 'Consequently,': [38], 'the': [39, 89, 107], 'need': [40], 'achieve': [42], 'intelligent': [43], 'protection': [44, 87, 103, 114], 'through': [48, 106], 'machine': [49, 110, 123], 'learning': [50, 124], 'algorithms': [51, 61], 'become': [53], 'paramount': [55], 'concern.': [56], 'Artificial': [57], 'leverages': [59], 'advanced': [60], 'technologies': [63], 'effectively': [65], 'encrypt': [66], 'anonymize': [68], 'data,': [70], 'enabling': [71], 'valuable': [72], 'data': [73, 85, 101, 130, 144], 'analysis': [74], 'utilization': [76], 'while': [77], 'safeguarding': [78], 'privacy.': [79], 'This': [80], 'paper': [81, 117], 'focuses': [82], 'on': [83], 'promotion': [90], 'anonymity': [92], 'as': [93], 'its': [94], 'core': [95], 'research': [96], 'objectives.': [97], 'It': [98], 'achieves': [99], 'detection': [105, 146], 'use': [108], ""learning's"": [111], 'differential': [112], 'algorithm.': [115], 'addresses': [119], 'existing': [120], 'challenges': [121], 'in': [122], 'related': [125], 'protection,': [131], 'offers': [132], 'improvement': [133], 'suggestions,': [134], 'analyzes': [136], 'factors': [137], 'impacting': [138], 'datasets': [139], 'enable': [141], 'timely': [142], 'protection.': [148]}",2024,"['Computer science', 'Internet privacy', 'Computer security', 'Data anonymization', 'Information privacy', 'Privacy protection']","The development of artificial intelligence has significantly transformed people's lives. However, it has also posed a significant threat to privacy and security, with numerous instances of personal information being exposed online and reports of criminal attacks and theft. Consequently, the need to achieve intelligent protection of personal information through machine learning algorithms has become a paramount concern. Artificial intelligence leverages advanced algorithms and technologies to effectively encrypt and anonymize personal data, enabling valuable data analysis and utilization while safeguarding privacy. This paper focuses on personal data privacy protection and the promotion of anonymity as its core research objectives. It achieves personal data privacy protection and detection through the use of machine learning's differential privacy protection algorithm. The paper also addresses existing challenges in machine learning related to privacy and personal data protection, offers improvement suggestions, and analyzes factors impacting datasets to enable timely personal data privacy detection and protection."
https://openalex.org/W4296349771,No secrets between the two of us: Privacy concerns over using AI agents.,"{'The': [0, 88, 116], 'diverse': [1], 'spread': [2], 'of': [3, 10, 30, 68, 136, 166], 'artificial': [4], 'intelligence': [5], '(AI)': [6], 'agents': [7, 21], 'provides': [8], 'evidence': [9], 'the': [11, 16, 43, 55, 63, 133, 143, 164], 'most': [12], 'notable': [13], 'changes': [14], 'in': [15, 163], 'current': [17], 'media': [18], 'landscape.': [19], 'AI': [20, 48, 105, 156], 'mostly': [22], 'function': [23], 'based': [24], 'on': [25, 142], 'voluntary': [26], 'and': [27, 73, 78, 113, 123, 139, 151], 'involuntary': [28], 'sharing': [29], 'users’': [31, 35, 127], 'personal': [32], 'information.': [33], 'Accordingly,': [34], 'privacy': [36, 76, 128, 152, 161], 'concerns': [37, 77, 153, 162], 'have': [38], 'become': [39], 'key': [40], 'to': [41, 61, 79, 102], 'understanding': [42], 'varied': [44], 'psychological': [45], 'responses': [46], 'towards': [47], 'agents.': [49, 157], 'In': [50], 'this': [51, 86, 99], 'study,': [52], 'we': [53], 'adopt': [54], '“computers': [56], 'are': [57, 169], 'social': [58, 74, 121, 149], 'actors”': [59], 'paradigm': [60], 'identify': [62], 'association': [64], 'between': [65, 145], 'a': [66, 82], 'set': [67], 'relational': [69], 'variables—intimacy,': [70], 'para-social': [71, 147], 'interactions,': [72], 'presence—and': [75], 'determine': [80], 'whether': [81], 'user’s': [83], 'motivations': [84], 'moderate': [85], 'relationship.': [87], 'results': [89, 117, 131], 'from': [90], 'an': [91], 'online': [92], 'survey': [93], '(N': [94], '=': [95], '562)': [96], 'revealed': [97], 'that': [98, 120], 'occurs': [100], 'primarily': [101], 'gratify': [103], 'three': [104], 'agent': [106], 'user': [107], 'needs:': [108], 'entertainment': [109, 138], 'motivation,': [110, 112], 'instrumental': [111, 140], 'passing': [114], 'time.': [115], 'also': [118], 'confirmed': [119], 'presence': [122], 'intimacy': [124], 'significantly': [125], 'influence': [126], 'concerns.': [129], 'These': [130], 'support': [132], 'moderating': [134], 'effect': [135], 'both': [137], 'motivation': [141], 'relationship': [144], 'intimacy,': [146], 'interaction,': [148], 'presence,': [150], 'about': [154], 'using': [155], 'Further': [158], 'implications': [159], 'for': [160], 'context': [165], 'AI-mediated': [167], 'communications': [168], 'discussed.': [170]}",2022,"['Internet privacy', 'Entertainment', 'Set (abstract data type)', 'Context (archaeology)', 'Psychology', 'Social media', 'Social psychology', 'Function (biology)', 'Computer science', 'World Wide Web', 'Political science', 'Evolutionary biology', 'Paleontology', 'Biology', 'Programming language', 'Law']","The diverse spread of artificial intelligence (AI) agents provides evidence of the most notable changes in the current media landscape. AI agents mostly function based on voluntary and involuntary sharing of users’ personal information. Accordingly, users’ privacy concerns have become key to understanding the varied psychological responses towards AI agents. In this study, we adopt the “computers are social actors” paradigm to identify the association between a set of relational variables—intimacy, para-social interactions, and social presence—and privacy concerns and to determine whether a user’s motivations moderate this relationship. The results from an online survey (N = 562) revealed that this occurs primarily to gratify three AI agent user needs: entertainment motivation, instrumental motivation, and passing time. The results also confirmed that social presence and intimacy significantly influence users’ privacy concerns. These results support the moderating effect of both entertainment and instrumental motivation on the relationship between intimacy, para-social interaction, social presence, and privacy concerns about using AI agents. Further implications for privacy concerns in the context of AI-mediated communications are discussed."
https://openalex.org/W4375957465,An Overview of AI and Blockchain Integration for Privacy-Preserving,"{'With': [0], 'the': [1, 76, 101, 132], 'widespread': [2], 'attention': [3], 'and': [4, 10, 36, 48, 72, 96, 103, 114, 124, 142, 148], 'application': [5, 63, 122], 'of': [6, 21, 29, 38, 46, 82, 135, 157], 'artificial': [7], 'intelligence': [8], '(AI)': [9], 'blockchain': [11, 143], 'technologies,': [12], 'privacy': [13, 28, 56, 84, 116, 136, 155], 'protection': [14, 57, 85, 117, 137, 156], 'techniques': [15, 32, 118], 'arising': [16], 'from': [17, 140], 'their': [18, 51, 104], 'integration': [19], 'are': [20], 'notable': [22], 'significance.': [23], 'In': [24, 127], 'addition': [25], 'to': [26, 150], 'protecting': [27], 'individuals,': [30], 'these': [31], 'also': [33, 112], 'guarantee': [34], 'security': [35, 149], 'dependability': [37], 'data.': [39], 'This': [40, 110], 'paper': [41, 77, 130], 'initially': [42], 'presents': [43], 'an': [44], 'overview': [45], 'AI': [47, 141], 'blockchain,': [49], 'summarizing': [50], 'combination': [52], 'along': [53], 'with': [54], 'derived': [55], 'technologies.': [58], 'It': [59], 'then': [60], 'explores': [61], 'specific': [62], 'scenarios': [64, 123], 'in': [65], 'data': [66, 92], 'encryption,': [67], 'de-identification,': [68], 'multi-tier': [69], 'distributed': [70], 'ledgers,': [71], 'k-anonymity': [73], 'methods.': [74], 'Moreover,': [75], 'evaluates': [78], 'five': [79], 'critical': [80], 'aspects': [81], 'AI-blockchain-integration': [83], 'systems,': [86], 'including': [87, 145], 'authorization': [88], 'management,': [89], 'access': [90], 'control,': [91], 'protection,': [93], 'network': [94], 'security,': [95], 'scalability.': [97], 'Furthermore,': [98], 'it': [99], 'analyzes': [100], 'deficiencies': [102], 'actual': [105], 'cause,': [106], 'offering': [107], 'corresponding': [108], 'suggestions.': [109], 'research': [111], 'classifies': [113], 'summarizes': [115], 'based': [119], 'on': [120], 'AI-blockchain': [121], 'technical': [125], 'schemes.': [126], 'conclusion,': [128], 'this': [129], 'outlines': [131], 'future': [133], 'directions': [134], 'technologies': [138], 'emerging': [139], 'integration,': [144], 'enhancing': [146], 'efficiency': [147], 'achieve': [151], 'a': [152], 'more': [153], 'comprehensive': [154], 'privacy.': [158]}",2023,"['Blockchain', 'Computer science', 'Computer security', 'Anonymity', 'Scalability', 'Dependability', 'Information privacy', 'Data Protection Act 1998', 'Privacy protection', 'Encryption', 'Access control', 'Database', 'Software engineering']","With the widespread attention and application of artificial intelligence (AI) and blockchain technologies, privacy protection techniques arising from their integration are of notable significance. In addition to protecting privacy of individuals, these techniques also guarantee security and dependability of data. This paper initially presents an overview of AI and blockchain, summarizing their combination along with derived privacy protection technologies. It then explores specific application scenarios in data encryption, de-identification, multi-tier distributed ledgers, and k-anonymity methods. Moreover, the paper evaluates five critical aspects of AI-blockchain-integration privacy protection systems, including authorization management, access control, data protection, network security, and scalability. Furthermore, it analyzes the deficiencies and their actual cause, offering corresponding suggestions. This research also classifies and summarizes privacy protection techniques based on AI-blockchain application scenarios and technical schemes. In conclusion, this paper outlines the future directions of privacy protection technologies emerging from AI and blockchain integration, including enhancing efficiency and security to achieve a more comprehensive privacy protection of privacy."
https://openalex.org/W4402354544,"Security, Trust and Privacy Challenges in AI-Driven 6G Networks","{'The': [0, 91], 'advent': [1], 'of': [2, 27, 41, 66, 72, 104], '6G': [3, 28, 58], 'networks': [4], 'promises': [5], 'unprecedented': [6], 'advancements': [7], 'in': [8, 57, 106], 'wireless': [9], 'communication,': [10], 'offering': [11], 'wider': [12], 'bandwidth': [13], 'and': [14, 38, 52, 55, 80, 98], 'lower': [15], 'latency': [16], 'compared': [17], 'to': [18, 63, 84, 101], 'its': [19, 77], 'predecessors.': [20], 'This': [21], 'article': [22], 'explores': [23, 48, 81], 'the': [24, 31, 39, 49, 64, 96, 102], 'evolving': [25], 'infrastructure': [26], 'networks,': [29, 59], 'emphasizing': [30], 'transition': [32], 'towards': [33], 'a': [34, 70, 108], 'more': [35], 'disaggregated': [36], 'structure': [37], 'integration': [40], 'artificial': [42], 'intelligence': [43], '(AI)': [44], 'technologies.': [45], 'Furthermore,': [46], 'it': [47], 'security,': [50], 'trust': [51], 'privacy': [53], 'challenges': [54], 'attacks': [56, 74], 'particularly': [60], 'those': [61], 'related': [62], 'use': [65], 'AI.': [67], 'It': [68], 'presents': [69], 'classification': [71], 'network': [73], 'stemming': [75], 'from': [76], 'AI-centric': [78], 'architecture': [79], 'technologies': [82], 'designed': [83], 'detect': [85], 'or': [86], 'mitigate': [87], 'these': [88], 'emerging': [89], 'threats.': [90], 'paper': [92], 'concludes': [93], 'by': [94], 'examining': [95], 'implications': [97], 'risks': [99], 'linked': [100], 'utilization': [103], 'AI': [105], 'ensuring': [107], 'robust': [109], 'network.': [110]}",2024,"['Computer science', 'Computer security', 'Architecture', 'Wireless network', 'Wireless', 'Emerging technologies', 'Telecommunications', 'Artificial intelligence', 'Art', 'Visual arts']","The advent of 6G networks promises unprecedented advancements in wireless communication, offering wider bandwidth and lower latency compared to its predecessors. This article explores the evolving infrastructure of 6G networks, emphasizing the transition towards a more disaggregated structure and the integration of artificial intelligence (AI) technologies. Furthermore, it explores the security, trust and privacy challenges and attacks in 6G networks, particularly those related to the use of AI. It presents a classification of network attacks stemming from its AI-centric architecture and explores technologies designed to detect or mitigate these emerging threats. The paper concludes by examining the implications and risks linked to the utilization of AI in ensuring a robust network."
https://openalex.org/W3088384496,Survey on Federated Learning Towards Privacy Preserving AI,"{'One': [0], 'of': [1, 5, 30, 72, 82, 97, 112, 126], 'the': [2, 28, 43, 51, 59, 104], 'significant': [3], 'challenges': [4], 'Artificial': [6], 'Intelligence': [7], '(AI)': [8], 'and': [9, 18, 108, 137], 'Machine': [10, 84, 138], 'learning': [11, 61], 'models': [12, 62], 'is': [13, 101, 122], 'to': [14, 19, 27, 48, 68, 102], 'preserve': [15], 'data': [16, 21, 37, 65], 'privacy': [17, 41, 66, 106], 'ensure': [20], 'security.': [22], 'Addressing': [23], 'this': [24, 75, 98], 'problem': [25], 'lead': [26], 'application': [29], 'Federated': [31, 83, 113, 120], 'Learning': [32, 114, 121], '(FL)': [33], 'mechanism': [34], 'towards': [35], 'preserving': [36, 64], 'privacy.': [38], 'Preserving': [39], 'user': [40], 'in': [42, 79, 135], 'European': [44], 'Union': [45], '(EU)': [46], 'has': [47, 67], 'abide': [49], 'by': [50], 'General': [52], 'Data': [53], 'Protection': [54], 'Regulation': [55], '(GDPR).': [56], 'Therefore,': [57], 'exploring': [58], 'machine': [60], 'for': [63], 'take': [69], 'into': [70], 'consideration': [71], 'GDPR.': [73], 'In': [74], 'paper,': [76], 'we': [77, 116], 'present': [78], 'detail': [80], 'understanding': [81], 'Learning,': [85], 'various': [86], 'federated': [87], 'architectures': [88], 'along': [89], 'with': [90], 'different': [91], 'privacy-preserving': [92], 'mechanisms.': [93], 'The': [94], 'main': [95], 'goal': [96], 'survey': [99], 'work': [100], 'highlight': [103], 'existing': [105], 'techniques': [107], 'also': [109, 117], 'propose': [110], 'applications': [111], 'inIndustries.Finally,': [115], 'depict': [118], 'how': [119], 'an': [123], 'emerging': [124], 'area': [125], 'future': [127], 'research': [128], 'that': [129], 'would': [130], 'bring': [131], 'a': [132], 'new': [133], 'era': [134], 'AI': [136], 'learning.': [139]}",2020,"['Computer science', 'Information privacy', 'Internet privacy', 'Data science']","One of the significant challenges of Artificial Intelligence (AI) and Machine learning models is to preserve data privacy and to ensure data security. Addressing this problem lead to the application of Federated Learning (FL) mechanism towards preserving data privacy. Preserving user privacy in the European Union (EU) has to abide by the General Data Protection Regulation (GDPR). Therefore, exploring the machine learning models for preserving data privacy has to take into consideration of GDPR. In this paper, we present in detail understanding of Federated Machine Learning, various federated architectures along with different privacy-preserving mechanisms. The main goal of this survey work is to highlight the existing privacy techniques and also propose applications of Federated Learning inIndustries.Finally, we also depict how Federated Learning is an emerging area of future research that would bring a new era in AI and Machine learning."
https://openalex.org/W3173155549,"AI in My Life: AI, Ethics &amp; Privacy Workshops for 15-16-Year-Olds","{'‘AI': [0], 'in': [1, 13, 28, 53, 84, 140, 149, 234, 248, 251, 288], 'My': [2], 'Life’': [3], 'project': [4, 112], 'will': [5, 42, 99, 162, 191, 205], 'engage': [6], '500': [7], 'Dublin': [8], 'teenagers': [9], 'from': [10, 81, 93, 102, 136], 'disadvantaged': [11], 'backgrounds': [12], 'a': [14, 29, 125, 160, 183, 193, 285], '15-week': [15], '(20-&#13;\\nhour)': [16], 'co-created,': [17], 'interactive': [18], 'workshop': [19], 'series': [20], 'encouraging': [21], 'them': [22], 'to': [23, 44, 56, 61, 113, 116, 131, 244, 258, 269], 'reflect': [24], 'on': [25, 221], 'their': [26, 54, 58], 'experiences': [27], 'world&#13;\\nshaped': [30], 'by': [31, 172], 'Artificial': [32], 'Intelligence': [33], '(AI),': [34], 'personal': [35], 'data': [36, 231, 239], 'processing': [37], 'and': [38, 48, 65, 86, 89, 108, 152, 170, 182, 198, 227, 241, 292], 'digital': [39, 59], 'transformation.': [40], 'Students': [41], 'be&#13;\\nempowered': [43], 'evaluate': [45], 'the': [46, 70, 94, 103, 109, 117, 164, 211, 276, 289], 'ethical': [47], 'privacy': [49, 240], 'implications': [50], 'of': [51, 105, 127, 157, 166, 210, 217, 225, 238, 267], 'AI': [52, 226], 'lives,': [55], 'protect': [57, 245], 'privacy&#13;\\nand': [60], 'activate': [62], 'STEM': [63, 260, 271], 'careers': [64], 'university': [66], 'awareness.': [67], 'It': [68, 204], 'extends': [69], '‘DCU': [71], 'TY’': [72], 'programme': [73, 115, 218], 'for': [74, 77, 134, 185, 200], 'innovative&#13;\\neducational': [75], 'opportunities': [76], 'Transition': [78], 'Year': [79], 'students': [80, 135], 'underrepresented': [82, 139], 'communities': [83], 'higher&#13;\\neducation.&#13;\\nPrivacy': [85], 'cybersecurity': [87], 'researchers': [88], 'public': [90, 252], 'engagement': [91], 'professionals': [92], 'SFI': [95], 'Centres': [96], 'ADAPT1&#13;\\nand': [97], 'Lero2': [98], 'join': [100], 'experts': [101], 'Future': [104], 'Privacy': [106], 'Forum3': [107], 'INTEGRITY': [110], 'H20204': [111], 'deliver&#13;\\nthe': [114], 'DCU': [118, 122, 177], 'Access5': [119], '22-school': [120], 'network.': [121], 'Access': [123], 'has': [124], 'mission': [126], 'creating': [128], 'equality': [129], 'of&#13;\\naccess': [130], 'third-level': [132], 'education': [133], 'groups': [137], 'currently': [138], 'higher': [141], 'education.': [142], 'Each': [143], 'partner': [144], 'brings': [145], 'proven': [146], 'training': [147], 'activities': [148], 'AI,': [150], 'ethics': [151], 'privacy.': [153], 'A': [154], 'novel': [155], 'blending': [156], 'material': [158, 174, 190, 212], 'into': [159], 'youthdriven&#13;\\nnarrative': [161], 'be': [163], 'subject': [165], 'initial': [167], 'co-creation': [168, 281], 'workshops': [169, 181, 282], 'supported': [171], 'pilot': [173], 'delivery&#13;\\nby': [175], 'undergraduate': [176], 'Student': [178], 'Ambassadors.': [179], 'Train-the-trainer': [180], 'toolkit': [184], 'teachers': [186, 268], 'will&#13;\\nenable': [187], 'delivery.': [188], 'The': [189], 'use': [192, 209], 'blended': [194], 'approach': [195], '(in': [196], 'person': [197], 'online)': [199], 'delivery': [201], 'during': [202], 'COVID-&#13;\\n19.': [203], 'also': [206], 'enable': [207], 'wider': [208], 'developed.': [213], 'An': [214], 'external': [215], 'study': [216], 'effectiveness': [219], 'will&#13;\\nreport': [220], 'participants’:': [222], 'enhanced': [223], 'understanding': [224, 237], 'its': [228], 'impact,': [229], 'improved': [230], 'literacy': [232], 'skills': [233], 'terms': [235], 'of&#13;\\ntheir': [236], 'security,': [242], 'empowerment': [243], 'privacy,': [246], 'growth': [247], 'confidence': [249], 'in&#13;\\nparticipating': [250], 'discourse': [253], 'about': [254, 280], 'STEM,': [255], 'increased': [256], 'propensity': [257], 'consider': [259], 'subjects': [261], 'at': [262], 'all': [263], 'levels,&#13;\\nand': [264], 'greater': [265], 'capacity': [266], 'facilitate': [270], 'interventions.': [272], 'This': [273], 'paper': [274], 'introduces': [275], 'project,': [277], 'presents&#13;\\nmore': [278], 'details': [279], 'that': [283], 'is': [284], 'particular': [286], 'step': [287], 'proposed': [290], 'methodology': [291], 'reports&#13;\\nsome': [293], 'preliminary': [294], 'results.': [295]}",2021,"['Disadvantaged', 'Psychology', 'Information privacy', 'Medical education', 'Internet privacy', 'Computer science', 'Political science', 'Medicine', 'Law']","‘AI in My Life’ project will engage 500 Dublin teenagers from disadvantaged backgrounds in a 15-week (20-&#13;\nhour) co-created, interactive workshop series encouraging them to reflect on their experiences in a world&#13;\nshaped by Artificial Intelligence (AI), personal data processing and digital transformation. Students will be&#13;\nempowered to evaluate the ethical and privacy implications of AI in their lives, to protect their digital privacy&#13;\nand to activate STEM careers and university awareness. It extends the ‘DCU TY’ programme for innovative&#13;\neducational opportunities for Transition Year students from underrepresented communities in higher&#13;\neducation.&#13;\nPrivacy and cybersecurity researchers and public engagement professionals from the SFI Centres ADAPT1&#13;\nand Lero2 will join experts from the Future of Privacy Forum3 and the INTEGRITY H20204 project to deliver&#13;\nthe programme to the DCU Access5 22-school network. DCU Access has a mission of creating equality of&#13;\naccess to third-level education for students from groups currently underrepresented in higher education. Each partner brings proven training activities in AI, ethics and privacy. A novel blending of material into a youthdriven&#13;\nnarrative will be the subject of initial co-creation workshops and supported by pilot material delivery&#13;\nby undergraduate DCU Student Ambassadors. Train-the-trainer workshops and a toolkit for teachers will&#13;\nenable delivery. The material will use a blended approach (in person and online) for delivery during COVID-&#13;\n19. It will also enable wider use of the material developed. An external study of programme effectiveness will&#13;\nreport on participants’: enhanced understanding of AI and its impact, improved data literacy skills in terms of&#13;\ntheir understanding of data privacy and security, empowerment to protect privacy, growth in confidence in&#13;\nparticipating in public discourse about STEM, increased propensity to consider STEM subjects at all levels,&#13;\nand greater capacity of teachers to facilitate STEM interventions. This paper introduces the project, presents&#13;\nmore details about co-creation workshops that is a particular step in the proposed methodology and reports&#13;\nsome preliminary results."
https://openalex.org/W4410040324,"AI-Driven Optimization of Blockchain Scalability, Security, and Privacy Protection","{'With': [0], 'the': [1, 53, 60, 65, 72, 84, 89, 109, 117, 195], 'continuous': [2], 'development': [3], 'of': [4, 16, 57, 74, 78, 83, 91, 112, 119, 127, 133, 140, 194], 'technology,': [5], 'blockchain': [6, 25, 75, 94, 128, 165, 210], 'has': [7], 'been': [8, 160], 'widely': [9], 'used': [10], 'in': [11, 76, 93, 123, 131], 'various': [12], 'fields': [13], 'by': [14], 'virtue': [15], 'its': [17, 39], 'decentralization,': [18], 'data': [19, 41], 'integrity,': [20], 'traceability,': [21], 'and': [22, 33, 47, 63, 80, 102, 136, 156, 173, 180, 186, 199, 209], 'anonymity.': [23], 'However,': [24], 'still': [26], 'faces': [27], 'many': [28], 'challenges,': [29], 'such': [30, 152], 'as': [31, 95, 153], 'scalability': [32, 79], 'security': [34, 61], 'issues.': [35], 'Artificial': [36], 'intelligence,': [37], 'with': [38], 'powerful': [40], 'processing': [42, 55], 'capability,': [43], 'pattern': [44], 'recognition': [45], 'ability,': [46], 'adaptive': [48], 'optimization': [49], 'algorithms,': [50, 167], 'can': [51, 107], 'improve': [52, 168], 'transaction': [54], 'efficiency': [56], 'blockchain,': [58], 'enhance': [59, 174], 'mechanism,': [62], 'optimize': [64, 164], 'privacy': [66, 137], 'protection': [67], 'strategy,': [68], 'thus': [69], 'effectively': [70, 161], 'alleviating': [71], 'limitations': [73], 'terms': [77, 132], 'security.': [81], 'Most': [82], 'existing': [85], 'related': [86], 'reviews': [87], 'explore': [88], 'application': [90, 118], 'AI': [92, 106, 150, 208], 'a': [96, 142, 191], 'whole': [97], 'but': [98], 'lack': [99], 'in-depth': [100], 'classification': [101, 185], 'discussion': [103], 'on': [104, 148], 'how': [105, 149], 'empower': [108], 'core': [110, 125], 'aspects': [111], 'blockchain.': [113], 'This': [114], 'paper': [115, 189], 'explores': [116], 'artificial': [120], 'intelligence': [121], 'technologies': [122], 'addressing': [124], 'challenges': [126], 'systems,': [129], 'specifically': [130], 'scalability,': [134], 'security,': [135], 'protection.': [138], 'Instead': [139], 'claiming': [141], 'deep': [143, 157], 'theoretical': [144], 'integration,': [145], 'we': [146], 'focus': [147], 'methods,': [151], 'machine': [154], 'learning': [155, 179], 'learning,': [158], 'have': [159], 'adopted': [162], 'to': [163], 'consensus': [166], 'smart': [169], 'contract': [170], 'vulnerability': [171], 'detection,': [172], 'privacy-preserving': [175], 'mechanisms': [176], 'like': [177], 'federated': [178], 'differential': [181], 'privacy.': [182], 'Through': [183], 'comprehensive': [184], 'discussion,': [187], 'this': [188], 'provides': [190], 'structured': [192], 'overview': [193], 'current': [196], 'research': [197], 'landscape': [198], 'identifies': [200], 'potential': [201], 'directions': [202], 'for': [203], 'further': [204], 'technical': [205], 'collaboration': [206], 'between': [207], 'technologies.': [211]}",2025,"['Blockchain', 'Scalability', 'Computer science', 'Privacy protection', 'Computer security', 'Distributed computing', 'Database']","With the continuous development of technology, blockchain has been widely used in various fields by virtue of its decentralization, data integrity, traceability, and anonymity. However, blockchain still faces many challenges, such as scalability and security issues. Artificial intelligence, with its powerful data processing capability, pattern recognition ability, and adaptive optimization algorithms, can improve the transaction processing efficiency of blockchain, enhance the security mechanism, and optimize the privacy protection strategy, thus effectively alleviating the limitations of blockchain in terms of scalability and security. Most of the existing related reviews explore the application of AI in blockchain as a whole but lack in-depth classification and discussion on how AI can empower the core aspects of blockchain. This paper explores the application of artificial intelligence technologies in addressing core challenges of blockchain systems, specifically in terms of scalability, security, and privacy protection. Instead of claiming a deep theoretical integration, we focus on how AI methods, such as machine learning and deep learning, have been effectively adopted to optimize blockchain consensus algorithms, improve smart contract vulnerability detection, and enhance privacy-preserving mechanisms like federated learning and differential privacy. Through comprehensive classification and discussion, this paper provides a structured overview of the current research landscape and identifies potential directions for further technical collaboration between AI and blockchain technologies."
https://openalex.org/W4404148466,Ethical AI in Retail: Consumer Privacy and Fairness,"{'The': [0, 202, 218], 'adoption': [1], 'of': [2, 24, 44, 99, 106, 119, 199], 'artificial': [3], 'intelligence': [4], '(AI)': [5], 'in': [6, 47, 121, 223, 235], 'retail': [7, 112], 'has': [8], 'significantly': [9], 'transformed': [10], 'the': [11, 21, 41, 104], 'industry,': [12], 'enabling': [13], 'more': [14], 'personalized': [15], 'services': [16], 'and': [17, 34, 60, 91, 159, 169, 173, 196, 211, 238], 'efficient': [18], 'operations.': [19], 'However,': [20], 'rapid': [22], 'implementation': [23], 'AI': [25, 45, 54, 65, 137, 154, 200, 216, 224, 236], 'technologies': [26, 55], 'raises': [27], 'ethical': [28, 42, 64, 163], 'concerns,': [29], 'particularly': [30], 'regarding': [31, 103], 'consumer': [32, 233, 240], 'privacy': [33, 168, 172], 'fairness.': [35, 170], 'This': [36], 'study': [37, 203, 219], 'aims': [38], 'to': [39, 73, 183, 229], 'analyze': [40], 'challenges': [43], 'applications': [46], 'retail,': [48], 'explore': [49], 'ways': [50], 'retailers': [51, 181, 206], 'can': [52, 155], 'implement': [53], 'ethically': [56], 'while': [57], 'remaining': [58], 'competitive,': [59], 'provide': [61], 'recommendations': [62], 'on': [63], 'practices.': [66], 'A': [67], 'descriptive': [68, 87], 'survey': [69], 'design': [70], 'was': [71, 150], 'used': [72], 'collect': [74], 'data': [75, 108, 124, 167, 193, 212, 241], 'from': [76], '300': [77], 'respondents': [78], 'across': [79], 'major': [80, 131], 'e-commerce': [81], 'platforms.': [82], 'Data': [83, 171], 'were': [84, 175], 'analyzed': [85], 'using': [86], 'statistics,': [88], 'including': [89], 'percentages': [90], 'mean': [92], 'scores.': [93], 'Findings': [94], 'shows': [95], 'a': [96, 117, 134, 188], 'high': [97], 'level': [98], 'concerns': [100, 145], 'among': [101], 'consumers': [102, 142], 'amount': [105], 'personal': [107], 'collected': [109], 'by': [110], 'AI-driven': [111], 'applications,': [113], 'with': [114], 'many': [115], 'expressing': [116], 'lack': [118], 'trust': [120], 'how': [122], 'their': [123, 185], 'is': [125, 129], 'managed.': [126], 'Also,': [127], 'fairness': [128], 'another': [130], 'issue,': [132], 'as': [133, 166, 177], 'majority': [135], 'believe': [136], 'systems': [138], 'do': [139], 'not': [140], 'treat': [141], 'equally,': [143], 'raising': [144], 'about': [146], 'algorithmic': [147], 'bias.': [148], 'It': [149], 'also': [151], 'found': [152], 'that': [153, 205], 'enhance': [156], 'business': [157], 'competitiveness': [158], 'efficiency': [160], 'without': [161], 'compromising': [162], 'principles,': [164], 'such': [165], 'transparency': [174, 222], 'highlighted': [176], 'critical': [178], 'areas': [179], 'where': [180], 'need': [182], 'focus': [184], 'efforts,': [186], 'indicating': [187], 'strong': [189], 'demand': [190], 'for': [191], 'stricter': [192], 'protection': [194, 213], 'protocols': [195], 'ongoing': [197], 'scrutiny': [198], 'systems.': [201, 217], 'concludes': [204], 'must': [207], 'prioritize': [208], 'transparency,': [209], 'fairness,': [210], 'when': [214], 'deploying': [215], 'recommends': [220], 'ensuring': [221], 'processes,': [225], 'conducting': [226], 'regular': [227], 'audits': [228], 'address': [230], 'biases,': [231], 'incorporating': [232], 'feedback': [234], 'development,': [237], 'emphasizing': [239], 'privacy.': [242]}",2024,"['Business', 'Consumer privacy', 'Internet privacy', 'Information privacy', 'Marketing', 'Computer science']","The adoption of artificial intelligence (AI) in retail has significantly transformed the industry, enabling more personalized services and efficient operations. However, the rapid implementation of AI technologies raises ethical concerns, particularly regarding consumer privacy and fairness. This study aims to analyze the ethical challenges of AI applications in retail, explore ways retailers can implement AI technologies ethically while remaining competitive, and provide recommendations on ethical AI practices. A descriptive survey design was used to collect data from 300 respondents across major e-commerce platforms. Data were analyzed using descriptive statistics, including percentages and mean scores. Findings shows a high level of concerns among consumers regarding the amount of personal data collected by AI-driven retail applications, with many expressing a lack of trust in how their data is managed. Also, fairness is another major issue, as a majority believe AI systems do not treat consumers equally, raising concerns about algorithmic bias. It was also found that AI can enhance business competitiveness and efficiency without compromising ethical principles, such as data privacy and fairness. Data privacy and transparency were highlighted as critical areas where retailers need to focus their efforts, indicating a strong demand for stricter data protection protocols and ongoing scrutiny of AI systems. The study concludes that retailers must prioritize transparency, fairness, and data protection when deploying AI systems. The study recommends ensuring transparency in AI processes, conducting regular audits to address biases, incorporating consumer feedback in AI development, and emphasizing consumer data privacy."
https://openalex.org/W2887202973,Privacy and DRM Requirements for Collaborative Development of AI Applications,"{'The': [0], 'use': [1], 'of': [2, 9, 37, 67], 'data': [3, 22, 30], 'is': [4, 55], 'essential': [5], 'for': [6], 'the': [7, 27, 82, 97, 105, 112, 121], 'capabilities': [8], 'Data-driven': [10], 'Artificial': [11], 'intelligence': [12], '(AI),': [13], 'Deep': [14], 'Learning': [15], 'and': [16, 71, 84, 101, 103, 125], 'Big': [17], 'Data': [18], 'analysis': [19], 'techniques.': [20], 'This': [21, 79], 'usage,': [23], 'however,': [24], 'raises': [25], 'intrinsically': [26], 'concerns': [28], 'on': [29, 123], 'privacy.': [31], 'In': [32], 'addition,': [33], 'supporting': [34], 'collaborative': [35, 88, 128], 'development': [36], 'AI': [38, 48, 89, 93, 129, 132], 'applications': [39], 'across': [40], 'organisations': [41], 'has': [42], 'become': [43], 'a': [44, 65], 'major': [45], 'need': [46], 'in': [47, 61, 87, 127], 'system': [49, 90], 'design.': [50], 'Digital': [51], 'Rights': [52], 'Management': [53], '(DRM)': [54], 'required': [56], 'to': [57, 118], 'protect': [58, 119], 'intellectual': [59], 'property': [60], 'such': [62], 'collaboration.': [63], 'As': [64], 'consequence': [66], 'DRM,': [68], 'privacy': [69, 83, 102, 126], 'threats': [70, 106, 122], 'privacy-enforcing': [72], 'mechanisms': [73], 'will': [74], 'interact': [75], 'with': [76], 'each': [77], 'other.': [78], 'paper': [80, 113], 'describes': [81, 96], 'DRM': [85, 100, 124], 'requirements': [86], 'design': [91, 130], 'using': [92, 131], 'pipelines.': [94, 133], 'It': [95], 'relationships': [98], 'between': [99], 'outlines': [104], 'against': [107, 120], 'these': [108], 'non-functional': [109], 'features.': [110], 'Finally,': [111], 'provides': [114], 'first': [115], 'security': [116], 'architecture': [117]}",2018,"['Intellectual property', 'Computer science', 'Information privacy', 'Digital rights management', 'Big data', 'Privacy by Design', 'Computer security', 'Internet privacy', 'Data science', 'Operating system']","The use of data is essential for the capabilities of Data-driven Artificial intelligence (AI), Deep Learning and Big Data analysis techniques. This data usage, however, raises intrinsically the concerns on data privacy. In addition, supporting collaborative development of AI applications across organisations has become a major need in AI system design. Digital Rights Management (DRM) is required to protect intellectual property in such collaboration. As a consequence of DRM, privacy threats and privacy-enforcing mechanisms will interact with each other. This paper describes the privacy and DRM requirements in collaborative AI system design using AI pipelines. It describes the relationships between DRM and privacy and outlines the threats against these non-functional features. Finally, the paper provides first security architecture to protect against the threats on DRM and privacy in collaborative AI design using AI pipelines."
https://openalex.org/W2803648454,Taking AI Personally: How the E.U. Must Learn to Balance the Interests of Personal Data Privacy & Artificial Intelligence,"{'Taking': [0], 'AI': [1], 'Personally:': [2], 'How': [3], 'the': [4, 10], 'E.U.': [5], 'Must': [6], 'Learn': [7], 'to': [8], 'Balance': [9], 'Interests': [11], 'of': [12], 'Personal': [13], 'Data': [14], 'Privacy': [15], '&': [16], 'Artificial': [17], 'Intelligence': [18]}",2018,"['Internet privacy', 'Balance (ability)', 'Computer science', 'Information privacy', 'Computer security', 'Psychology', 'Neuroscience']",Taking AI Personally: How the E.U. Must Learn to Balance the Interests of Personal Data Privacy & Artificial Intelligence
https://openalex.org/W4400654443,Data Privacy and Security Concerns in AI-Integrated Educational Platforms,"{'As': [0], 'educational': [1, 40, 124], 'institutions': [2], 'increasingly': [3], 'embrace': [4], 'AI': [5, 38, 73, 122, 147], 'technologies': [6], 'to': [7, 53, 63, 89, 107, 113, 133, 137, 153], 'enhance': [8], 'learning': [9], 'experiences,': [10], 'a': [11, 67], 'paramount': [12], 'concern': [13], 'arises': [14], 'regarding': [15], 'the': [16, 29, 35, 78, 90, 97, 115, 138, 143, 151, 155], 'privacy': [17, 46, 84, 156], 'and': [18, 31, 47, 60, 69, 83, 111, 117, 157], 'security': [19, 48, 158], 'of': [20, 37, 72, 80, 99, 119, 146, 159], 'sensitive': [21], 'student': [22], 'data.': [23], 'This': [24], 'research': [25, 87, 105], 'paper': [26], 'delves': [27], 'into': [28], 'challenges': [30], 'implications': [32], 'associated': [33], 'with': [34, 150], 'integration': [36], 'in': [39, 74, 96, 121, 148], 'platforms,': [41], 'focusing': [42], 'specifically': [43], 'on': [44, 93, 141], 'data': [45, 120], 'issues.': [49], 'The': [50], 'study': [51], 'aims': [52], 'identify': [54], 'potential': [55], 'risks,': [56], 'assess': [57], 'current': [58], 'safeguards,': [59], 'propose': [61, 108], 'strategies': [62, 112], 'mitigate': [64], 'threats,': [65], 'ensuring': [66], 'responsible': [68], 'secure': [70], 'implementation': [71], 'education.': [75], 'By': [76, 126], 'examining': [77], 'intersection': [79], 'technological': [81], 'advancement': [82], 'concerns,': [85], 'this': [86, 104], 'contributes': [88], 'ongoing': [91, 139], 'dialogue': [92], 'ethical': [94], 'considerations': [95], 'realm': [98], 'AI-driven': [100], 'education': [101, 149], 'transformation.': [102], 'Furthermore,': [103], 'endeavors': [106], 'robust': [109], 'frameworks': [110], 'safeguard': [114], 'integrity': [116], 'confidentiality': [118], 'driven': [123], 'environments.': [125], 'addressing': [127], 'these': [128], 'concerns': [129], 'head-on,': [130], 'we': [131], 'strive': [132], 'contribute': [134], 'valuable': [135], 'insights': [136], 'discourse': [140], 'balancing': [142], 'transformative': [144], 'benefits': [145], 'imperative': [152], 'protect': [154], 'all': [160], 'stakeholders': [161], 'involved.': [162]}",2024,"['Internet privacy', 'Computer security', 'Computer science', 'Information privacy']","As educational institutions increasingly embrace AI technologies to enhance learning experiences, a paramount concern arises regarding the privacy and security of sensitive student data. This research paper delves into the challenges and implications associated with the integration of AI in educational platforms, focusing specifically on data privacy and security issues. The study aims to identify potential risks, assess current safeguards, and propose strategies to mitigate threats, ensuring a responsible and secure implementation of AI in education. By examining the intersection of technological advancement and privacy concerns, this research contributes to the ongoing dialogue on ethical considerations in the realm of AI-driven education transformation. Furthermore, this research endeavors to propose robust frameworks and strategies to safeguard the integrity and confidentiality of data in AI driven educational environments. By addressing these concerns head-on, we strive to contribute valuable insights to the ongoing discourse on balancing the transformative benefits of AI in education with the imperative to protect the privacy and security of all stakeholders involved."
https://openalex.org/W4392916557,AI to V2X Privacy and Security Issues in Autonomous Vehicles: Survey,"{'Artificial': [0], 'Intelligence': [1], '(AI)': [2], 'is': [3, 174], 'transforming': [4], 'all': [5], 'of': [6, 23, 37, 42, 49, 105, 137, 166, 190], 'the': [7, 21, 40, 47, 54, 135, 164, 179], 'technologies': [8], 'we': [9, 16, 116], 'use': [10], 'every': [11], 'day.': [12], 'More': [13], 'than': [14], 'ever,': [15], 'are': [17, 33, 53, 78, 95], 'very': [18], 'near': [19], 'to': [20, 158, 161, 175, 186], 'objective': [22], 'vehicle': [24], 'autonomy,': [25], 'which': [26, 107], 'has': [27], 'long': [28], 'been': [29], 'desired.': [30], 'Large': [31], 'automakers': [32], 'also': [34, 79, 149], 'spending': [35], 'billions': [36], 'dollars': [38], 'on': [39, 145], 'development': [41], 'autonomous': [43], 'vehicles': [44, 94], '(AVs).': [45], 'Among': [46], 'advantages': [48], 'this': [50, 87, 114], 'new': [51, 80], 'technology': [52], 'possibility': [55], 'for': [56], 'increased': [57], 'passenger': [58], 'safety,': [59], 'less': [60, 70], 'congested': [61], 'roads,': [62], 'reduced': [63, 67], 'traffic,': [64, 66], 'optimized': [65], 'fuel': [68], 'consumption,': [69], 'pollution,': [71], 'and': [72, 82, 99, 120, 141, 153, 185], 'improved': [73], 'travel': [74], 'experiences.': [75], 'However,': [76], 'there': [77], 'security': [81, 121], 'privacy': [83, 118], 'problems': [84, 152], 'associated': [85], 'with': [86], 'paradigm': [88], 'change.': [89], 'Previously': [90], 'simple': [91], 'mechanical': [92], 'devices,': [93], 'today': [96], 'computerized,': [97], 'networked,': [98], 'intelligent.': [100], 'They': [101], 'gather': [102], 'vast': [103], 'amounts': [104], 'data,': [106], 'must': [108], 'be': [109, 159], 'shielded': [110], 'from': [111], 'intrusions.': [112], 'In': [113], 'paper,': [115], 'examine': [117], 'issues': [119, 182], 'hurdles': [122], 'in': [123, 168], 'AVs.': [124], 'We': [125], 'investigate': [126], 'several': [127], 'attacks': [128], 'using': [129], 'a': [130], 'layer-by-layer': [131], 'methodology.': [132], 'It': [133, 148], 'summarizes': [134], 'contributions': [136], 'these': [138], 'research': [139, 154, 181], 'works': [140], 'categorizes': [142], 'them': [143], 'based': [144], 'application': [146], 'domains.': [147], 'identifies': [150], 'open': [151], 'challenges': [155], 'that': [156], 'need': [157], 'addressed': [160], 'fully': [162], 'realize': [163], 'potential': [165], 'AI': [167], 'advancing': [169], 'V2X': [170], 'systems.': [171], 'Our': [172], 'intention': [173], 'provide': [176], 'insights': [177], 'into': [178], 'unresolved': [180], 'surrounding': [183], 'AVs': [184], 'suggest': [187], 'future': [188], 'lines': [189], 'inquiry.': [191]}",2024,"['Autonomy', 'Computer security', 'Computer science', 'Intelligent transportation system', 'Emerging technologies', 'Internet privacy', 'Transport engineering', 'Engineering', 'Artificial intelligence', 'Political science', 'Law']","Artificial Intelligence (AI) is transforming all of the technologies we use every day. More than ever, we are very near to the objective of vehicle autonomy, which has long been desired. Large automakers are also spending billions of dollars on the development of autonomous vehicles (AVs). Among the advantages of this new technology are the possibility for increased passenger safety, less congested roads, reduced traffic, optimized traffic, reduced fuel consumption, less pollution, and improved travel experiences. However, there are also new security and privacy problems associated with this paradigm change. Previously simple mechanical devices, vehicles are today computerized, networked, and intelligent. They gather vast amounts of data, which must be shielded from intrusions. In this paper, we examine privacy issues and security hurdles in AVs. We investigate several attacks using a layer-by-layer methodology. It summarizes the contributions of these research works and categorizes them based on application domains. It also identifies open problems and research challenges that need to be addressed to fully realize the potential of AI in advancing V2X systems. Our intention is to provide insights into the unresolved research issues surrounding AVs and to suggest future lines of inquiry."
https://openalex.org/W4387587548,Preserving Privacy in Arabic Judgments: AI-Powered Anonymization for Enhanced Legal Data Privacy,"{'Jurisprudence': [0], 'involves': [1, 118], 'studying,': [2], 'interpreting,': [3], 'and': [4, 101, 166, 171, 177], 'applying': [5], 'the': [6, 33, 40, 43, 51, 125, 130, 137, 153, 161, 187, 196], 'law': [7, 20], 'to': [8, 17, 90, 123, 208], 'comprehend': [9], 'its': [10, 59], 'societal': [11], 'impact.': [12], 'Judges': [13], 'annually': [14], 'review': [15], 'cases': [16], 'ensure': [18], 'accurate': [19], 'application,': [21], 'which': [22], 'raises': [23], 'privacy': [24], 'concerns': [25], 'when': [26, 149], 'accessing': [27], 'files': [28], 'from': [29, 39], 'other': [30], 'courts.': [31], 'While': [32], 'legal': [34, 113, 199], 'field': [35], 'has': [36], 'garnered': [37], 'interest': [38], 'research': [41, 65], 'community,': [42], 'challenge': [44], 'of': [45, 139, 147, 169, 175], 'masking': [46], 'personal': [47, 81, 126], 'data,': [48], 'particularly': [49], 'in': [50, 58, 152, 213], 'Arabic': [52, 75, 112, 155, 193, 198, 214], 'language': [53], 'with': [54, 164], 'limited': [55], 'resources,': [56], 'remains': [57], 'early': [60], 'stages.': [61], 'To': [62], 'address': [63], 'this': [64, 107], 'gap,': [66], 'we': [67], 'develop': [68], 'a': [69, 80, 110, 119, 202], 'two-component': [70], 'system': [71, 185], 'for': [72, 190, 205], 'generating': [73, 191], 'anonymous': [74, 140, 192], 'judgments.': [76, 141, 194], 'The': [77, 115], 'first': [78, 131], 'component,': [79], 'data': [82], 'extractor': [83], 'model,': [84], 'utilizes': [85], 'Named': [86], 'Entity': [87], 'Recognition': [88], '(NER)': [89], 'identify': [91], 'key': [92], 'individual': [93], 'entities': [94, 127, 151], 'like': [95], 'names,': [96], 'addresses,': [97], 'birthdays,': [98], 'case': [99], 'numbers,': [100], 'national': [102], 'identity': [103], 'codes.': [104], 'We': [105], 'train': [106], 'model': [108, 143], 'on': [109, 160], 'purpose-built': [111], 'corpus.': [114, 157], 'second': [116], 'component': [117], 'Python': [120], 'module': [121], 'designed': [122], 'mask': [124], 'extracted': [128], 'by': [129], 'component.': [132], 'Together,': [133], 'these': [134, 181], 'components': [135], 'enable': [136], 'generation': [138], 'Our': [142], 'achieves': [144], 'an': [145], 'F1-score': [146], '96.14&#x0025;': [148], 'detecting': [150], 'created': [154], 'Legal': [156], 'Additionally,': [158], 'experiments': [159], 'ANERCorp': [162], 'corpus,': [163], 'training': [165], 'testing': [167], 'splits': [168], '70&#x0025;-30&#x0025;': [170], '90&#x0025;-10&#x0025;,': [172], 'yield': [173], 'F1-scores': [174], '93.78&#x0025;': [176], '95.77&#x0025;,': [178], 'respectively.': [179], 'With': [180], 'results,': [182], 'our': [183], 'proposed': [184], 'demonstrates': [186], 'promising': [188], 'potential': [189], 'Furthermore,': [195], 'built': [197], 'corpus': [200], 'provides': [201], 'valuable': [203], 'resource': [204], 'researchers': [206], 'aiming': [207], 'enhance': [209], 'domain-specific': [210], 'NER': [211], 'models': [212], 'text.': [215]}",2023,"['Computer science', 'Component (thermodynamics)', 'Artificial intelligence', 'Natural language processing', 'Python (programming language)', 'Arabic', 'Information retrieval', 'Linguistics', 'Operating system', 'Thermodynamics', 'Physics', 'Philosophy']","Jurisprudence involves studying, interpreting, and applying the law to comprehend its societal impact. Judges annually review cases to ensure accurate law application, which raises privacy concerns when accessing files from other courts. While the legal field has garnered interest from the research community, the challenge of masking personal data, particularly in the Arabic language with limited resources, remains in its early stages. To address this research gap, we develop a two-component system for generating anonymous Arabic judgments. The first component, a personal data extractor model, utilizes Named Entity Recognition (NER) to identify key individual entities like names, addresses, birthdays, case numbers, and national identity codes. We train this model on a purpose-built Arabic legal corpus. The second component involves a Python module designed to mask the personal entities extracted by the first component. Together, these components enable the generation of anonymous judgments. Our model achieves an F1-score of 96.14&#x0025; when detecting entities in the created Arabic Legal corpus. Additionally, experiments on the ANERCorp corpus, with training and testing splits of 70&#x0025;-30&#x0025; and 90&#x0025;-10&#x0025;, yield F1-scores of 93.78&#x0025; and 95.77&#x0025;, respectively. With these results, our proposed system demonstrates the promising potential for generating anonymous Arabic judgments. Furthermore, the built Arabic legal corpus provides a valuable resource for researchers aiming to enhance domain-specific NER models in Arabic text."
https://openalex.org/W3174674735,Privacy-Preserving and Explainable AI for Cardiovascular Imaging,"{'Medical': [0], 'imaging': [1, 64], 'provides': [2, 153], 'valuable': [3], 'input': [4], 'for': [5, 108, 121, 155, 176], 'managing': [6], 'cardiovascular': [7], 'disease': [8], '(CVD),': [9], 'ranging': [10], 'from': [11], 'risk': [12], 'assessment': [13, 178], 'to': [14, 36, 48, 51, 81, 84, 103, 124, 141, 164, 184], 'diagnosis,': [15], 'therapy': [16], 'planning': [17, 189], 'and': [18, 42, 65, 74, 100, 115, 152, 158, 183, 187], 'follow-up.Artificial': [19], 'intelligence': [20], '(AI)': [21], 'based': [22, 57], 'medical': [23, 63], 'image': [24], 'analysis': [25], 'algorithms': [26, 88], 'provide': [27], 'nowadays': [28], 'state-of-the-art': [29], 'results': [30, 107], 'in': [31, 39, 59, 66], 'CVD': [32, 61], 'management,': [33], 'mainly': [34], 'due': [35, 83], 'the': [37, 53, 72, 127, 146, 165, 177, 185], 'increase': [38], 'computational': [40], 'power': [41], 'data': [43, 69, 78], 'storage': [44], 'capacities.Various': [45], 'challenges': [46], 'remain': [47], 'be': [49, 133], 'addressed': [50], 'speed-up': [52], 'adoption': [54], 'of': [55, 76, 149, 167, 179, 190], 'AI': [56, 87, 122], 'solutions': [58], 'routine': [60], 'management.Although': [62], 'general': [67], 'health': [68], 'are': [70, 89], 'abundant,': [71], 'access': [73], 'transfer': [75], 'such': [77], 'is': [79], 'difficult': [80], 'realize': [82], 'ethical': [85], 'considerations.Hence,': [86], 'often': [90], 'trained': [91], 'on': [92, 137], 'relatively': [93], 'small': [94], 'datasets,': [95], 'thus': [96], 'limiting': [97], 'their': [98], 'robustness,': [99], 'potentially': [101], 'leading': [102], 'biased': [104], 'or': [105, 111], 'skewed': [106], 'certain': [109], 'patient': [110], 'pathology': [112], 'sub-groups.Furthermore,': [113], 'explainability': [114], 'interpretability': [116], 'have': [117], 'become': [118], 'core': [119], 'requirements': [120], 'algorithms,': [123], 'ensure': [125], 'that': [126], 'rationale': [128], 'behind': [129], 'output': [130], 'inference': [131], 'can': [132], 'revealed.The': [134], 'paper': [135], 'focuses': [136], 'recent': [138], 'developments': [139], 'related': [140, 163], 'these': [142], 'two': [143], 'challenges,': [144], 'discusses': [145], 'clinical': [147], 'impact': [148], 'proposed': [150], 'solutions,': [151], 'conclusions': [154], 'further': [156], 'research': [157], 'development.It': [159], 'also': [160], 'presents': [161], 'examples': [162], 'diagnosis': [166, 186], 'stable': [168], 'coronary': [169], 'artery': [170], 'disease,': [171, 182], 'a': [172, 193], 'whole-body': [173], 'circulation': [174], 'model': [175], 'structural': [180], 'heart': [181, 195], 'treatment': [188], 'aortic': [191], 'coarctation,': [192], 'congenital': [194], 'disease.': [196]}",2021,"['Computer science', 'Artificial intelligence']","Medical imaging provides valuable input for managing cardiovascular disease (CVD), ranging from risk assessment to diagnosis, therapy planning and follow-up.Artificial intelligence (AI) based medical image analysis algorithms provide nowadays state-of-the-art results in CVD management, mainly due to the increase in computational power and data storage capacities.Various challenges remain to be addressed to speed-up the adoption of AI based solutions in routine CVD management.Although medical imaging and in general health data are abundant, the access and transfer of such data is difficult to realize due to ethical considerations.Hence, AI algorithms are often trained on relatively small datasets, thus limiting their robustness, and potentially leading to biased or skewed results for certain patient or pathology sub-groups.Furthermore, explainability and interpretability have become core requirements for AI algorithms, to ensure that the rationale behind output inference can be revealed.The paper focuses on recent developments related to these two challenges, discusses the clinical impact of proposed solutions, and provides conclusions for further research and development.It also presents examples related to the diagnosis of stable coronary artery disease, a whole-body circulation model for the assessment of structural heart disease, and to the diagnosis and treatment planning of aortic coarctation, a congenital heart disease."
https://openalex.org/W4392828253,Towards a Privacy and Security-Aware Framework for Ethical AI: Guiding the Development and Assessment of AI Systems,"{'As': [0], 'artificial': [1], 'intelligence': [2], 'continues': [3], 'its': [4], 'unprecedented': [5], 'global': [6], 'expansion,\\naccompanied': [7], 'by': [8, 54], 'a': [9, 39, 56, 80, 103, 113, 118, 144, 181, 194], 'proliferation': [10], 'of': [11, 21, 27, 89, 120, 136, 173, 230], 'benefits,': [12], 'an': [13, 186], 'increasing': [14], 'apprehension': [15], 'about\\nthe': [16], 'privacy': [17, 130, 211], 'and': [18, 34, 48, 93, 131, 164, 170, 192, 207, 212, 228], 'security': [19, 87, 213], 'implications': [20], 'AI-enabled': [22], 'systems': [23], 'emerges.': [24], 'The\\npivotal': [25], 'question': [26], 'effectively': [28], 'controlling': [29], 'AI': [30, 62, 66, 77, 91, 124, 151, 174, 189, 231], 'development': [31, 169], 'at': [32], 'both\\njurisdictional': [33], 'organizational': [35], 'levels': [36], 'has': [37], 'become': [38], 'prominent': [40], 'theme': [41], 'in\\ncontemporary': [42], 'discourse.': [43], 'While': [44], 'the': [45, 60, 64, 85, 128, 134, 168, 176, 202, 210, 226], 'European': [46], 'Parliament': [47], 'Council': [49], 'have': [50], 'taken': [51], 'a\\ndecisive': [52], 'step': [53], 'reaching': [55], 'political': [57], 'agreement': [58], 'on': [59, 116, 225], 'EU': [61], 'Act,': [63], 'first\\ncomprehensive': [65], 'law,': [67], 'organizations': [68], 'still': [69], 'find': [70], 'it': [71], 'challenging': [72], 'to': [73, 75, 97, 110, 157, 197, 222], 'adapt': [74], 'the\\nfast-evolving': [76], 'landscape,': [78], 'lacking': [79], 'universal': [81], 'tool': [82], 'for': [83, 148, 183, 217], 'evaluating': [84], 'privacy\\nand': [86], 'dimensions': [88], 'their': [90], 'models': [92], 'systems.': [94, 152], 'In': [95, 200], 'response': [96], 'this\\ncritical': [98], 'challenge,': [99], 'this': [100, 141], 'study': [101, 142, 203], 'conducts': [102], 'systematic': [104], 'literature': [105], 'review': [106], 'spanning\\nthe': [107], 'years': [108], '2020': [109], '2023,': [111], 'with': [112], 'primary': [114], 'focus': [115], 'establishing': [117], 'unified\\ndefinition': [119], 'key': [121, 205], 'concepts': [122], 'in': [123, 166], 'Ethics,': [125], 'particularly': [126], 'emphasizing': [127], 'domains\\nof': [129], 'security.': [132], 'Through': [133], 'synthesis': [135], 'knowledge': [137], 'extracted': [138], 'from': [139], 'the\\nSLR,': [140], 'presents': [143], 'conceptual': [145], 'framework': [146, 154, 178], 'tailored': [147], 'privacy-': [149], 'and\\nsecurity-aware': [150], 'This': [153], 'is': [155, 190], 'designed': [156], 'assist': [158], 'diverse\\nstakeholders,': [159], 'including': [160], 'organizations,': [161], 'academic': [162], 'institutions,': [163], 'governmental\\nbodies,': [165], 'both': [167], 'critical': [171], 'assessment': [172], 'systems.\\nEssentially,': [175], 'proposed': [177], 'serves': [179], 'as': [180], 'guide': [182], 'ethical\\ndecision-making,': [184], 'fostering': [185], 'environment': [187], 'wherein': [188], 'developed': [191], 'utilized\\nwith': [193], 'strong': [195], 'commitment': [196], 'ethical': [198], 'principles.': [199], 'addition,': [201], 'unravels\\nthe': [204], 'issues': [206], 'challenges': [208], 'surrounding': [209], 'dimensions,\\ndelineating': [214], 'promising': [215], 'avenues': [216], 'future': [218], 'research,': [219], 'thereby': [220], 'contributing': [221], 'the\\nongoing': [223], 'dialogue': [224], 'globalization': [227], 'democratization': [229], 'ethics.\\n': [232]}",2024,"['Computer security', 'Development (topology)', 'Computer science', 'Internet privacy', 'Business', 'Mathematical analysis', 'Mathematics']","As artificial intelligence continues its unprecedented global expansion,\naccompanied by a proliferation of benefits, an increasing apprehension about\nthe privacy and security implications of AI-enabled systems emerges. The\npivotal question of effectively controlling AI development at both\njurisdictional and organizational levels has become a prominent theme in\ncontemporary discourse. While the European Parliament and Council have taken a\ndecisive step by reaching a political agreement on the EU AI Act, the first\ncomprehensive AI law, organizations still find it challenging to adapt to the\nfast-evolving AI landscape, lacking a universal tool for evaluating the privacy\nand security dimensions of their AI models and systems. In response to this\ncritical challenge, this study conducts a systematic literature review spanning\nthe years 2020 to 2023, with a primary focus on establishing a unified\ndefinition of key concepts in AI Ethics, particularly emphasizing the domains\nof privacy and security. Through the synthesis of knowledge extracted from the\nSLR, this study presents a conceptual framework tailored for privacy- and\nsecurity-aware AI systems. This framework is designed to assist diverse\nstakeholders, including organizations, academic institutions, and governmental\nbodies, in both the development and critical assessment of AI systems.\nEssentially, the proposed framework serves as a guide for ethical\ndecision-making, fostering an environment wherein AI is developed and utilized\nwith a strong commitment to ethical principles. In addition, the study unravels\nthe key issues and challenges surrounding the privacy and security dimensions,\ndelineating promising avenues for future research, thereby contributing to the\nongoing dialogue on the globalization and democratization of AI ethics.\n"
https://openalex.org/W4229064268,Sixth‐Generation (6G) Mobile Cloud Security and Privacy Risks for AI System Using High‐Performance Computing Implementation,"{'The': [0, 22, 96, 247], 'exchange': [1], 'of': [2, 46, 89, 238, 335], 'information': [3], 'from': [4], 'one': [5], 'person': [6], 'to': [7, 77, 159, 166, 186, 234, 267, 279, 286, 309], 'another': [8], 'is': [9, 102, 119, 142, 251, 261, 276, 340], 'called': [10], 'communication.': [11], 'Telecommunication': [12], 'makes': [13], 'it': [14], 'possible': [15], 'with': [16, 136, 192, 245, 331], 'electronic': [17], 'devices': [18, 146], 'and': [19, 56, 163, 179, 184, 217, 240, 297, 318, 322, 345, 351], 'their': [20], 'tools.': [21], 'scientist': [23], 'Alexander': [24], 'Graham': [25], 'Bell': [26], 'has': [27, 256], 'invented': [28], 'the': [29, 35, 40, 44, 51, 72, 81, 90, 100, 107, 116, 167, 187, 199, 224, 232, 262, 287, 301, 327], 'basic': [30], 'telephone': [31], 'in': [32, 34, 43, 80, 99, 145, 147, 154, 181, 194, 198, 221, 243, 303], '1876': [33], 'USA.': [36], 'Telephones': [37], 'now': [38], 'have': [39], 'new': [41], 'format': [42], 'form': [45], 'mobile': [47, 63, 83, 130, 155, 182, 195, 249], 'phones,': [48], 'which': [49], 'are': [50, 60, 68, 75, 231], 'primary': [52], 'media': [53], 'for': [54, 71, 228, 283, 349], 'communicating': [55], 'transmitting': [57], 'data.': [58], 'We': [59], 'using': [61, 94, 271], '5th‐generation': [62], 'network': [64, 84, 156, 171, 174, 196, 250], 'standards.': [65, 85], 'Still,': [66], 'there': [67], 'some': [69], 'requirements': [70], 'users': [73], 'that': [74, 113, 265], 'believed': [76], 'be': [78, 93, 152, 268], 'solved': [79], '6th‐generation': [82], 'By': [86, 325], '2030,': [87], 'all': [88], 'people': [91], 'would': [92, 114, 202], '6G.': [95], 'computing': [97, 132, 282, 306], 'model': [98], 'cloud': [101, 131, 191], 'not': [103], 'dependent': [104], 'on': [105, 300], 'either': [106], 'location': [108], 'or': [109], 'any': [110], 'specific': [111], 'device': [112], 'provide': [115, 160], 'service.': [117], 'It': [118], 'an': [120], 'on‐demand': [121, 353], 'computational': [122], 'service‐oriented': [123], 'mechanism.': [124], 'Combining': [125, 190], 'these': [126], 'two': [127, 310], 'technologies': [128], 'as': [129, 170, 208, 314], 'provides': [133], 'customized': [134, 164], 'options': [135], 'more': [137, 161], 'flexible': [138], 'implementations.': [139], 'Artificial': [140], 'intelligence': [141], 'being': [143], 'used': [144, 153], 'many': [148, 257], 'fields.': [149], 'AI': [150, 193], 'can': [151], 'services': [157, 165, 197, 285], '(MNS)': [158], 'reliable': [162, 350], 'users,': [168], 'such': [169, 207, 313], 'operation': [172, 175], 'monitoring,': [173], 'management,': [176], 'fraud': [177], 'detection,': [178], 'reduction': [180], 'transactions': [183], 'security': [185], 'cyber': [188], 'devices.': [189], '6th': [200], 'generation': [201, 255], 'improve': [203], 'human': [204], 'beings’': [205], 'lives,': [206], 'zero': [209, 218], 'road': [210], 'accidents,': [211], 'advanced': [212], 'level': [213], 'special': [214], 'health': [215], 'care,': [216], 'crime': [219], 'rates': [220], 'society.': [222], 'However,': [223], 'most': [225], 'vital': [226], 'needs': [227, 266], 'sixth‐generation': [229, 248], 'standards': [230], 'capability': [233], 'manage': [235], 'large': [236], 'volumes': [237], 'records': [239], 'excessive‐statistics‐fee': [241], 'connectivity': [242], 'step': [244], 'gadgets.': [246], 'under': [252], 'development.': [253], 'This': [254], 'exciting': [258], 'features.': [259], 'Security': [260], 'central': [263], 'issue': [264], 'sorted': [269], 'out': [270], 'appropriate': [272], 'forensic': [273], 'mechanisms.': [274], 'There': [275], 'a': [277, 304, 332], 'need': [278], 'approach': [280], 'high‐performance': [281, 305], 'improved': [284], 'end‐user.': [288], 'Considering': [289], 'three‐dimensional': [290], 'research': [291], 'methodologies': [292], '(technical': [293], 'dimension,': [294, 296], 'organizational': [295], 'applications': [298], 'hosted': [299], 'cloud)': [302], 'environment': [307], 'leads': [308], 'different': [311], 'cases': [312], 'real‐time': [315], 'stream': [316], 'processing': [317], 'remote': [319], 'desktop': [320], 'connection': [321], 'performance': [323], 'test.': [324], '‘narrowing': [326], 'targeted': [328], 'worldwide': [329], 'audience': [330], 'wide': [333], 'range': [334], 'experiential': [336], 'opportunities,’': [337], 'this': [338], 'paper': [339], 'aimed': [341], 'at': [342], 'delivering': [343], 'dynamic': [344], 'varied': [346], 'resource': [347], 'allocation': [348], 'justified': [352], 'services.': [354]}",2022,"['Computer science', 'Cloud computing', 'Mobile cloud computing', 'Computer security', 'Implementation', 'Mobile device', 'Mobile computing', 'Service (business)', 'Mobile telephony', 'Telecommunications', 'World Wide Web', 'Operating system', 'Mobile radio', 'Programming language', 'Economy', 'Economics']","The exchange of information from one person to another is called communication. Telecommunication makes it possible with electronic devices and their tools. The scientist Alexander Graham Bell has invented the basic telephone in 1876 in the USA. Telephones now have the new format in the form of mobile phones, which are the primary media for communicating and transmitting data. We are using 5th‐generation mobile network standards. Still, there are some requirements for the users that are believed to be solved in the 6th‐generation mobile network standards. By 2030, all of the people would be using 6G. The computing model in the cloud is not dependent on either the location or any specific device that would provide the service. It is an on‐demand computational service‐oriented mechanism. Combining these two technologies as mobile cloud computing provides customized options with more flexible implementations. Artificial intelligence is being used in devices in many fields. AI can be used in mobile network services (MNS) to provide more reliable and customized services to the users, such as network operation monitoring, network operation management, fraud detection, and reduction in mobile transactions and security to the cyber devices. Combining cloud with AI in mobile network services in the 6th generation would improve human beings’ lives, such as zero road accidents, advanced level special health care, and zero crime rates in society. However, the most vital needs for sixth‐generation standards are the capability to manage large volumes of records and excessive‐statistics‐fee connectivity in step with gadgets. The sixth‐generation mobile network is under development. This generation has many exciting features. Security is the central issue that needs to be sorted out using appropriate forensic mechanisms. There is a need to approach high‐performance computing for improved services to the end‐user. Considering three‐dimensional research methodologies (technical dimension, organizational dimension, and applications hosted on the cloud) in a high‐performance computing environment leads to two different cases such as real‐time stream processing and remote desktop connection and performance test. By ‘narrowing the targeted worldwide audience with a wide range of experiential opportunities,’ this paper is aimed at delivering dynamic and varied resource allocation for reliable and justified on‐demand services."
https://openalex.org/W4323359493,The Right Not to Be Subjected to AI Profiling Based on Publicly Available Data—Privacy and the Exceptionalism of AI Profiling,"{'Abstract': [0], 'Social': [1], 'media': [2], 'data': [3, 57, 77, 110], 'hold': [4], 'considerable': [5], 'potential': [6], 'for': [7, 70, 124], 'predicting': [8], 'health-related': [9, 24], 'conditions.': [10], 'Recent': [11], 'studies': [12], 'suggest': [13], 'that': [14, 38, 89, 141, 151], 'machine-learning': [15], 'models': [16], 'may': [17], 'accurately': [18], 'predict': [19], 'depression': [20], 'and': [21, 30, 85, 104, 125, 137], 'other': [22, 107, 122], 'mental': [23], 'conditions': [25], 'based': [26, 53, 132, 161], 'on': [27, 54, 79, 133, 162], 'Instagram': [28], 'photos': [29], 'Tweets.': [31], 'In': [32], 'this': [33], 'article,': [34], 'it': [35], 'is': [36], 'argued': [37], 'individuals': [39, 98, 128, 152], 'should': [40], 'have': [41, 153], 'a': [42, 71, 90, 119, 154], 'sui': [43], 'generis': [44], 'right': [45, 72, 155], 'not': [46, 149, 156], 'to': [47, 50, 73, 101, 157], 'be': [48, 158], 'subjected': [49], 'AI': [51, 95, 115, 130, 159], 'profiling': [52, 96, 131], 'publicly': [55, 134, 163], 'available': [56, 135, 164], 'without': [58], 'their': [59], 'explicit': [60], 'informed': [61], 'consent.': [62], 'The': [63], 'article': [64], '(1)': [65], 'develops': [66], 'three': [67], 'basic': [68], 'arguments': [69], 'protection': [74], 'of': [75, 82, 92, 94, 109, 114, 121], 'personal': [76], 'trading': [78], 'the': [80, 142], 'notions': [81], 'social': [83, 102], 'control': [84, 103], 'stigmatization,': [86], '(2)': [87], 'argues': [88, 140], 'number': [91], 'features': [93], 'make': [97], 'more': [99], 'exposed': [100], 'stigmatization': [105], 'than': [106], 'types': [108], 'processing': [111], '(the': [112], 'exceptionalism': [113], 'profiling),': [116], '(3)': [117], 'considers': [118], 'series': [120], 'reasons': [123], 'against': [126, 129], 'protecting': [127], 'data,': [136], 'finally': [138], '(4)': [139], 'EU': [143], 'General': [144], 'Data': [145], 'Protection': [146], 'Regulation': [147], 'does': [148], 'ensure': [150], 'profiled': [160], 'data.': [165]}",2023,"['Profiling (computer programming)', 'Philosophy of technology', 'Exceptionalism', 'Internet privacy', 'Computer science', 'Political science', 'Law', 'Philosophy', 'Philosophy of science', 'Epistemology', 'Operating system', 'Politics']","Abstract Social media data hold considerable potential for predicting health-related conditions. Recent studies suggest that machine-learning models may accurately predict depression and other mental health-related conditions based on Instagram photos and Tweets. In this article, it is argued that individuals should have a sui generis right not to be subjected to AI profiling based on publicly available data without their explicit informed consent. The article (1) develops three basic arguments for a right to protection of personal data trading on the notions of social control and stigmatization, (2) argues that a number of features of AI profiling make individuals more exposed to social control and stigmatization than other types of data processing (the exceptionalism of AI profiling), (3) considers a series of other reasons for and against protecting individuals against AI profiling based on publicly available data, and finally (4) argues that the EU General Data Protection Regulation does not ensure that individuals have a right not to be AI profiled based on publicly available data."
https://openalex.org/W4308532266,Lost in translation? Conceptions of privacy and independence in the technical development of AI-based AAL,"{'Abstract': [0], 'AAL': [1, 186, 204], 'encompasses': [2], 'smart': [3], 'home': [4], 'technologies': [5], 'that': [6, 129, 143], 'are': [7, 110, 120, 134, 212], 'installed': [8], 'in': [9, 14, 38, 56, 113, 126, 151, 178], 'the': [10, 27, 53, 79, 90, 97, 101, 107, 114, 123, 127, 152, 155, 159, 165, 179, 190, 217], 'personal': [11], 'living': [12], 'environment': [13], 'order': [15], 'to': [16, 77, 163, 201], 'support': [17], 'older,': [18], 'disabled,': [19], 'as': [20, 22, 47, 136, 173], 'well': [21], 'chronically': [23], 'ill': [24], 'people': [25], 'with': [26, 214], 'goal': [28], 'of': [29, 67, 81, 88, 92, 104, 116, 168, 181, 192], 'delaying': [30], 'or': [31], 'reducing': [32], 'their': [33, 57], 'need': [34], 'for': [35, 51], 'nursing': [36], 'care': [37, 40], 'a': [39, 207], 'facility.': [41], 'Artificial': [42], 'intelligence': [43], '(AI)': [44], 'is': [45], 'seen': [46], 'an': [48, 85], 'important': [49, 137], 'tool': [50], 'assisting': [52], 'target': [54], 'group': [55], 'daily': [58], 'lives.': [59], 'A': [60], 'literature': [61], 'search': [62], 'and': [63, 73, 94, 100, 132, 149, 154, 171, 195], 'qualitative': [64], 'content': [65], 'analysis': [66], '255': [68], 'articles': [69], 'from': [70, 216], 'computer': [71], 'science': [72], 'engineering': [74], 'was': [75], 'conducted': [76], 'explore': [78], 'usage': [80], 'ethical': [82, 86, 153, 194, 218], 'concepts.': [83], 'From': [84], 'point': [87], 'view,': [89], 'concept': [91], 'independence': [93], 'self-determination': [95, 131, 170], 'on': [96, 106, 184, 220], 'one': [98], 'hand': [99, 109], 'possible': [102], 'loss': [103], 'privacy': [105, 133, 172], 'other': [108], 'widely': [111], 'discussed': [112], 'context': [115, 180], 'AAL.': [117], 'These': [118], 'concepts': [119, 145, 197, 215], 'adopted': [121], 'by': [122], 'technical': [124, 156], 'discourse': [125, 219], 'sense': [128], 'independence,': [130, 169], 'recognized': [135], 'values.': [138], 'Nevertheless,': [139], 'our': [140], 'research': [141, 183], 'shows': [142], 'these': [144, 193, 210], 'have': [146], 'different': [147, 166], 'usages': [148], 'meanings': [150, 167], 'discourses.': [157], 'In': [158, 206], 'paper,': [160], 'we': [161], 'aim': [162], 'map': [164], 'they': [174], 'can': [175], 'be': [176], 'found': [177], 'technological': [182], 'AI-based': [185, 221], 'systems.': [187, 205], 'It': [188], 'investigates': [189], 'interpretation': [191], 'social': [196], 'which': [198], 'technicians': [199], 'try': [200], 'build': [202], 'into': [203], 'second': [208], 'step,': [209], 'interpretations': [211], 'contextualized': [213], 'assistive': [222], 'technologies.': [223]}",2022,"['Philosophy of medicine', 'Independence (probability theory)', 'Context (archaeology)', 'Philosophy of biology', 'Medical law', 'Computer science', 'Interpretation (philosophy)', 'Internet privacy', 'Engineering ethics', 'Sociology', 'Psychology', 'Philosophy of science', 'Epistemology', 'Medicine', 'Engineering', 'Alternative medicine', 'Statistics', 'Mathematics', 'Biology', 'Programming language', 'Philosophy', 'Pathology', 'Paleontology', 'Psychiatry']","Abstract AAL encompasses smart home technologies that are installed in the personal living environment in order to support older, disabled, as well as chronically ill people with the goal of delaying or reducing their need for nursing care in a care facility. Artificial intelligence (AI) is seen as an important tool for assisting the target group in their daily lives. A literature search and qualitative content analysis of 255 articles from computer science and engineering was conducted to explore the usage of ethical concepts. From an ethical point of view, the concept of independence and self-determination on the one hand and the possible loss of privacy on the other hand are widely discussed in the context of AAL. These concepts are adopted by the technical discourse in the sense that independence, self-determination and privacy are recognized as important values. Nevertheless, our research shows that these concepts have different usages and meanings in the ethical and the technical discourses. In the paper, we aim to map the different meanings of independence, self-determination and privacy as they can be found in the context of technological research on AI-based AAL systems. It investigates the interpretation of these ethical and social concepts which technicians try to build into AAL systems. In a second step, these interpretations are contextualized with concepts from the ethical discourse on AI-based assistive technologies."
https://openalex.org/W4402576628,"Ethical AI in Information Technology: Navigating Bias, Privacy, Transparency, and Accountability","{'The': [0], 'rapid': [1], 'advancement': [2, 108], 'of': [3, 13, 34, 58, 65, 109], 'artificial': [4], 'intelligence': [5], '(AI)': [6], 'technologies': [7], 'has': [8], 'fundamentally': [9], 'transformed': [10], 'the': [11, 53, 74, 104], 'landscape': [12], 'information': [14], 'technology': [15], '(IT),': [16], 'offering': [17], 'unprecedented': [18], 'opportunities': [19], 'for': [20, 52], 'innovation': [21], 'and': [22, 38, 46, 56, 70, 88, 106], 'efficiency.': [23], 'However,': [24], 'these': [25, 43], 'advancements': [26], 'also': [27], 'bring': [28], 'significant': [29], 'ethical': [30, 44, 50, 96], 'challenges,': [31], 'including': [32], 'issues': [33], 'bias,': [35], 'privacy,': [36, 85], 'transparency,': [37, 87], 'accountability.': [39], 'This': [40], 'paper': [41], 'explores': [42], 'challenges': [45], 'proposes': [47], 'a': [48, 116], 'comprehensive': [49], 'framework': [51, 75, 100], 'responsible': [54], 'development': [55], 'deployment': [57], 'AI': [59, 92, 97, 110], 'in': [60, 91], 'IT.': [61], 'Through': [62], 'an': [63], 'examination': [64], 'historical': [66], 'context,': [67], 'current': [68], 'trends,': [69], 'detailed': [71], 'case': [72], 'studies,': [73], 'aims': [76], 'to': [77, 81, 102], 'provide': [78], 'actionable': [79], 'guidelines': [80], 'mitigate': [82], 'biases,': [83], 'protect': [84], 'enhance': [86], 'ensure': [89], 'accountability': [90], 'systems.': [93], 'By': [94], 'fostering': [95], 'practices,': [98], 'this': [99], 'aspires': [101], 'support': [103], 'sustainable': [105], 'equitable': [107], 'technologies,': [111], 'ultimately': [112], 'benefiting': [113], 'society': [114], 'as': [115], 'whole': [117]}",2024,"['Transparency (behavior)', 'Accountability', 'Internet privacy', 'Information privacy', 'Business', 'Public relations', 'Political science', 'Computer science', 'Computer security', 'Law']","The rapid advancement of artificial intelligence (AI) technologies has fundamentally transformed the landscape of information technology (IT), offering unprecedented opportunities for innovation and efficiency. However, these advancements also bring significant ethical challenges, including issues of bias, privacy, transparency, and accountability. This paper explores these ethical challenges and proposes a comprehensive ethical framework for the responsible development and deployment of AI in IT. Through an examination of historical context, current trends, and detailed case studies, the framework aims to provide actionable guidelines to mitigate biases, protect privacy, enhance transparency, and ensure accountability in AI systems. By fostering ethical AI practices, this framework aspires to support the sustainable and equitable advancement of AI technologies, ultimately benefiting society as a whole"
https://openalex.org/W4399354491,Fairness &amp; Privacy in an Age of Generative AI,"{'Generative': [0], 'AI': [1, 166, 208, 235], 'technologies': [2, 32], 'have': [3, 9], 'made': [4], 'tremendous': [5], 'strides': [6], 'recently': [7], 'and': [8, 40, 77, 102, 131, 174, 183, 189, 203, 210, 220, 238, 257], 'captured': [10], 'the': [11, 56, 178, 199, 211, 231, 249], 'public’s': [12], 'imagination': [13], 'with': [14], 'their': [15, 51, 99, 106], 'ability': [16], 'to': [17, 23, 36, 73, 96, 119, 223, 253], 'mimic': [18], 'what': [19, 243], 'was': [20], 'previously': [21], 'thought': [22], 'be': [24, 91, 151, 246, 263], 'a': [25, 162], 'fundamentally': [26], 'human': [27, 38], 'capability:': [28], 'creativity.': [29], 'While': [30], 'such': [31, 155, 255], 'hold': [33], 'great': [34], 'promise': [35], 'augment': [37], 'creativity': [39], 'automate': [41], 'tedious': [42], 'processes,': [43], 'they': [44], 'also': [45, 161], 'carry': [46], 'risks': [47], 'that': [48, 89, 206, 230], 'stem': [49], 'from': [50, 154], 'development': [52], 'process.': [53], 'In': [54], 'particular,': [55], 'reliance': [57], 'of': [58, 64, 122, 133, 172, 201, 214, 233, 269], 'foundation': [59], 'models': [60, 94, 115, 167], 'on': [61], 'vast': [62], 'amounts': [63, 171], 'typically': [65], 'uncurated,': [66], 'often': [67], 'web-scraped': [68], 'training': [69, 100, 179, 250], 'data': [70, 101, 251], 'has': [71], 'led': [72], 'concerns': [74, 85, 205], 'around': [75, 86, 147, 241, 248], 'fairness': [76, 80, 202], 'privacy.': [78], 'Algorithmic': [79], 'in': [81, 98, 105, 177, 266], 'this': [82], 'context': [83], 'encompasses': [84], 'potential': [87], 'biases': [88], 'can': [90, 168], 'learned': [92], 'by': [93], 'due': [95], 'skews': [97], 'then': [103], 'reflected': [104], 'generated': [107], 'outputs.': [108], 'For': [109], 'example,': [110], 'without': [111], 'intervention,': [112], 'image': [113, 187], 'generation': [114, 188], 'are': [116], 'more': [117], 'likely': [118], 'generate': [120], 'images': [121, 132], 'lighter': [123], 'skin': [124, 135], 'tone': [125, 136], 'male': [126], 'individuals': [127, 138], 'for': [128, 139, 186, 192], 'professional': [129], 'occupations': [130], 'darker': [134], 'female': [137], 'working': [140], 'class': [141], 'occupations.': [142], 'This': [143, 195, 227], 'further': [144], 'raises': [145, 209, 236], 'questions': [146, 240], 'whether': [148, 259], 'there': [149], 'should': [150, 245, 262], 'legal': [152, 215], 'protections': [153, 216, 244], 'pernicious': [156], 'stereotypical': [157], 'representations.': [158], 'Privacy': [159], 'is': [160], 'concern': [163], 'as': [164], 'generative': [165, 207, 234], 'ingest': [169], 'large': [170], 'personal': [173], 'biometric': [175], 'information': [176], 'process,': [180], 'including': [181], 'face': [182], 'body': [184], 'biometrics': [185, 191], 'voice': [190], 'speech': [193], 'generation.': [194], 'Essay': [196, 228], 'will': [197], 'discuss': [198], 'types': [200], 'privacy': [204, 221], 'existing': [212], 'landscape': [213], 'under': [217], 'anti-discrimination': [218], 'law': [219, 222], 'address': [224], 'these': [225], 'concerns.': [226], 'argues': [229], 'proliferation': [232], 'challenging': [237], 'novel': [239], '(i)': [242], 'offered': [247], 'used': [252], 'develop': [254], 'systems': [256], '(ii)': [258], 'representational': [260], 'harms': [261], 'protected': [264], 'against': [265], 'an': [267], 'age': [268], 'AI-generated': [270], 'content.': [271]}",2024,"['Generative grammar', 'Internet privacy', 'Psychology', 'Computer science', 'Artificial intelligence']","Generative AI technologies have made tremendous strides recently and have captured the public’s imagination with their ability to mimic what was previously thought to be a fundamentally human capability: creativity. While such technologies hold great promise to augment human creativity and automate tedious processes, they also carry risks that stem from their development process. In particular, the reliance of foundation models on vast amounts of typically uncurated, often web-scraped training data has led to concerns around fairness and privacy. Algorithmic fairness in this context encompasses concerns around potential biases that can be learned by models due to skews in their training data and then reflected in their generated outputs. For example, without intervention, image generation models are more likely to generate images of lighter skin tone male individuals for professional occupations and images of darker skin tone female individuals for working class occupations. This further raises questions around whether there should be legal protections from such pernicious stereotypical representations. Privacy is also a concern as generative AI models can ingest large amounts of personal and biometric information in the training process, including face and body biometrics for image generation and voice biometrics for speech generation. This Essay will discuss the types of fairness and privacy concerns that generative AI raises and the existing landscape of legal protections under anti-discrimination law and privacy law to address these concerns. This Essay argues that the proliferation of generative AI raises challenging and novel questions around (i) what protections should be offered around the training data used to develop such systems and (ii) whether representational harms should be protected against in an age of AI-generated content."
https://openalex.org/W3215435188,AI Model for Predicting Legal Judgments to Improve Accuracy and Explainability of Online Privacy Invasion Cases,"{'Since': [0, 74], 'there': [1], 'are': [2, 27, 68, 78], 'growing': [3], 'concerns': [4], 'regarding': [5], 'online': [6, 37, 45, 71], 'privacy,': [7, 38], 'firms': [8, 26, 149], 'may': [9], 'have': [10, 151], 'the': [11, 54, 104, 109, 132, 177, 197], 'risk': [12], 'of': [13, 29, 34, 36, 56, 116, 126, 155, 179], 'being': [14], 'involved': [15], 'in': [16, 22], 'various': [17, 61], 'privacy': [18, 46, 72, 135], 'infringement': [19, 136], 'cases': [20, 33, 66], 'resulting': [21], 'legal': [23, 75, 98, 189], 'causations.': [24], 'If': [25], 'aware': [28], 'consequences': [30], 'from': [31], 'possible': [32], 'invasion': [35], 'they': [39, 163], 'can': [40, 95], 'more': [41], 'actively': [42], 'prevent': [43], 'future': [44], 'infringements.': [47], 'Thus,': [48], 'this': [49, 87], 'study': [50, 88, 105], 'attempts': [51], 'to': [52, 70, 90, 171], 'predict': [53, 97], 'probability': [55], 'judgment': [57, 76, 99], 'types': [58, 115], 'caused': [59], 'by': [60, 81, 112, 140], 'invasions': [62], 'within': [63], 'US': [64], 'judicial': [65], 'that': [67, 94, 148], 'related': [69], 'invasions.': [73], 'results': [77, 146], 'significantly': [79], 'influenced': [80], 'societal': [82], 'factors': [83, 137], 'and': [84, 123, 138, 158, 183], 'technological': [85], 'development,': [86], 'tries': [89], 'identify': [91], 'a': [92, 152], 'model': [93], 'accurately': [96], 'with': [100], 'explainability.': [101], 'To': [102], 'archive': [103], 'objective,': [106], 'it': [107], 'compares': [108], 'prediction': [110], 'performance': [111], 'applying': [113, 141], 'five': [114], 'classification': [117], 'algorithms': [118], '(LDA,': [119], 'NNET,': [120], 'CART,': [121], 'SVM,': [122], 'random': [124], 'forest)': [125], 'machine': [127], 'learning.': [128], 'We': [129], 'also': [130], 'examined': [131], 'relationship': [133], 'between': [134], 'adjudications': [139], 'network': [142], 'text': [143], 'analysis.': [144], 'The': [145], 'indicate': [147], 'could': [150], 'high': [153], 'possibility': [154], 'both': [156, 181], 'civil': [157], 'criminal': [159], 'law': [160], 'responsibilities': [161], 'if': [162], 'distributed': [164], 'malware': [165], 'or': [166, 169], 'spyware,': [167], 'intentionally': [168], 'non-intentionally,': [170], 'collect': [172], 'unauthorized': [173], 'data.': [174], 'It': [175], 'addresses': [176], 'needs': [178], 'reflecting': [180], 'quantitative': [182], 'qualitative': [184], 'approach': [185], 'for': [186, 191], 'establishing': [187], 'automatic': [188], 'systems': [190], 'improving': [192], 'its': [193], 'accuracy': [194], 'based': [195], 'on': [196], 'socio-technical': [198], 'perspective.': [199]}",2021,"['Adjudication', 'Internet privacy', 'Perspective (graphical)', 'Computer science', 'Computer security', 'Data science', 'Political science', 'Artificial intelligence', 'Law']","Since there are growing concerns regarding online privacy, firms may have the risk of being involved in various privacy infringement cases resulting in legal causations. If firms are aware of consequences from possible cases of invasion of online privacy, they can more actively prevent future online privacy infringements. Thus, this study attempts to predict the probability of judgment types caused by various invasions within US judicial cases that are related to online privacy invasions. Since legal judgment results are significantly influenced by societal factors and technological development, this study tries to identify a model that can accurately predict legal judgment with explainability. To archive the study objective, it compares the prediction performance by applying five types of classification algorithms (LDA, NNET, CART, SVM, and random forest) of machine learning. We also examined the relationship between privacy infringement factors and adjudications by applying network text analysis. The results indicate that firms could have a high possibility of both civil and criminal law responsibilities if they distributed malware or spyware, intentionally or non-intentionally, to collect unauthorized data. It addresses the needs of reflecting both quantitative and qualitative approach for establishing automatic legal systems for improving its accuracy based on the socio-technical perspective."
https://openalex.org/W4411492716,A Review on Federated Learning Architectures for Privacy-Preserving AI: Lightweight and Secure Cloud–Edge–End Collaboration,"{'Federated': [0], 'learning': [1, 15], '(FL)': [2], 'has': [3], 'emerged': [4], 'as': [5], 'a': [6, 44, 58, 68, 110, 127], 'promising': [7], 'paradigm': [8], 'for': [9, 131], 'enabling': [10], 'collaborative': [11], 'training': [12], 'of': [13, 25, 47, 78, 96, 113, 120], 'machine': [14], 'models': [16], 'while': [17], 'preserving': [18], 'data': [19, 26], 'privacy.': [20], 'However,': [21], 'the': [22, 48, 76, 86, 94, 100, 118, 136, 157], 'massive': [23], 'heterogeneity': [24], 'and': [27, 31, 51, 81, 106, 116, 139, 148], 'devices,': [28, 134], 'communication': [29], 'constraints,': [30], 'security': [32], 'threats': [33], 'pose': [34], 'significant': [35], 'challenges': [36, 63], 'to': [37, 152], 'its': [38], 'practical': [39], 'implementation.': [40], 'This': [41], 'paper': [42], 'provides': [43], 'system': [45], 'review': [46], 'state-of-the-art': [49], 'techniques': [50], 'future': [52, 149], 'research': [53, 150], 'directions': [54, 151], 'in': [55, 64, 99], 'FL,': [56], 'with': [57], 'focus': [59], 'on': [60], 'addressing': [61], 'these': [62], 'resource-constrained': [65, 132], 'environments': [66], 'by': [67], 'cloud–edge–end': [69, 79], 'collaboration': [70, 80], 'FL': [71, 129], 'architecture.': [72], 'We': [73, 83, 108], 'first': [74], 'introduce': [75], 'foundations': [77, 119], 'FL.': [82], 'then': [84], 'discuss': [85], 'key': [87], 'technical': [88], 'challenges.': [89], 'Next,': [90], 'we': [91, 125, 144], 'delve': [92], 'into': [93, 156], 'pillars': [95], 'trustworthy': [97], 'AI': [98, 115], 'federated': [101], 'context,': [102], 'covering': [103], 'robustness,': [104], 'fairness,': [105], 'explainability.': [107], 'propose': [109], 'dimension': [111], 'reconstruction': [112], 'trusted': [114], 'analyze': [117], 'each': [121], 'trustworthiness': [122], 'pillar.': [123], 'Furthermore,': [124], 'present': [126], 'lightweight': [128], 'framework': [130], 'edge–end': [133], 'analyzing': [135], 'core': [137], 'contradictions': [138], 'proposing': [140], 'optimization': [141], 'paradigms.': [142], 'Finally,': [143], 'highlight': [145], 'advanced': [146], 'topics': [147], 'provide': [153], 'valuable': [154], 'insights': [155], 'field.': [158]}",2025,"['Computer science', 'Cloud computing', 'Robustness (evolution)', 'Data science', 'Context (archaeology)', 'Enhanced Data Rates for GSM Evolution', 'Architecture', 'Trustworthiness', 'Federated learning', 'Artificial intelligence', 'Distributed computing', 'Computer security', 'Biology', 'Chemistry', 'Art', 'Gene', 'Paleontology', 'Biochemistry', 'Operating system', 'Visual arts']","Federated learning (FL) has emerged as a promising paradigm for enabling collaborative training of machine learning models while preserving data privacy. However, the massive heterogeneity of data and devices, communication constraints, and security threats pose significant challenges to its practical implementation. This paper provides a system review of the state-of-the-art techniques and future research directions in FL, with a focus on addressing these challenges in resource-constrained environments by a cloud–edge–end collaboration FL architecture. We first introduce the foundations of cloud–edge–end collaboration and FL. We then discuss the key technical challenges. Next, we delve into the pillars of trustworthy AI in the federated context, covering robustness, fairness, and explainability. We propose a dimension reconstruction of trusted AI and analyze the foundations of each trustworthiness pillar. Furthermore, we present a lightweight FL framework for resource-constrained edge–end devices, analyzing the core contradictions and proposing optimization paradigms. Finally, we highlight advanced topics and future research directions to provide valuable insights into the field."
https://openalex.org/W4405169132,Data privacy in the era of AI: Navigating regulatory landscapes for global businesses,"{'The': [0, 48, 195], 'convergence': [1], 'of': [2, 131, 161, 168], 'artificial': [3], 'intelligence': [4], '(AI)': [5], 'and': [6, 32, 41, 69, 117, 151, 176, 179, 191, 206, 215, 232], 'data': [7, 37, 109, 112, 170, 189, 216], 'privacy': [8, 44, 132], 'has': [9], 'created': [10], 'a': [11, 77, 210, 238], 'pivotal': [12], 'challenge': [13], 'for': [14, 128, 147, 199, 213], 'global': [15, 49, 129], 'businesses': [16, 91, 148, 223], 'navigating': [17], 'complex': [18], 'regulatory': [19, 50, 98, 155], 'landscapes.': [20], 'As': [21], 'AI': [22, 95, 164, 181, 214], 'systems': [23], 'increasingly': [24], 'depend': [25], 'on': [26], 'vast': [27], 'datasets': [28], 'to': [29, 149, 182, 208], 'deliver': [30], 'insights': [31, 144], 'drive': [33], 'innovation,': [34], 'concerns': [35, 105], 'about': [36], 'protection,': [38], 'algorithmic': [39, 115], 'transparency,': [40], 'compliance': [42, 99, 184], 'with': [43, 97, 227], 'laws': [45], 'have': [46], 'intensified.': [47], 'environment,': [51], 'encompassing': [52], 'frameworks': [53], 'such': [54, 186], 'as': [55, 187], 'the': [56, 88, 126, 137, 159, 166], 'European': [57], 'Union’s': [58], 'General': [59], 'Data': [60], 'Protection': [61, 73], 'Regulation': [62], '(GDPR),': [63], 'California’s': [64], 'Consumer': [65], 'Privacy': [66], 'Act': [67], '(CCPA),': [68], 'China’s': [70], 'Personal': [71], 'Information': [72], 'Law': [74], '(PIPL),': [75], 'presents': [76], 'fragmented': [78], 'legal': [79, 230], 'landscape': [80], 'that': [81], 'requires': [82], 'careful': [83], 'navigation.': [84], 'This': [85], 'paper': [86, 196], 'examines': [87], 'multifaceted': [89], 'challenges': [90], 'face': [92], 'in': [93, 121, 139, 153, 163, 237], 'aligning': [94], 'adoption': [96, 167], 'while': [100], 'maintaining': [101], 'ethical': [102], 'standards.': [103], 'Key': [104], 'include': [106, 158], 'managing': [107], 'cross-border': [108], 'transfers,': [110], 'ensuring': [111], 'minimization,': [113], 'addressing': [114, 220], 'biases,': [116], 'safeguarding': [118], 'consumer': [119], 'rights': [120], 'automated': [122, 188], 'decision-making': [123], 'processes.': [124], 'Furthermore,': [125], 'need': [127], 'harmonization': [130], 'standards': [133], 'is': [134], 'emphasized,': [135], 'given': [136], 'inconsistencies': [138], 'regulations': [140], 'across': [141], 'jurisdictions.': [142], 'Actionable': [143], 'are': [145], 'provided': [146], 'adapt': [150], 'thrive': [152], 'this': [154], 'environment.': [156], 'These': [157], 'implementation': [160], 'privacy-by-design': [162], 'systems,': [165], 'advanced': [169], 'protection': [171], 'technologies': [172], 'like': [173], 'federated': [174], 'learning': [175], 'differential': [177], 'privacy,': [178], 'leveraging': [180], 'enhance': [183], 'processes,': [185], 'audits': [190], 'real-time': [192], 'breach': [193], 'detection.': [194], 'also': [197], 'advocates': [198], 'collaborative': [200], 'efforts': [201], 'among': [202], 'governments,': [203], 'industry': [204], 'stakeholders,': [205], 'regulators': [207], 'establish': [209], 'cohesive': [211], 'framework': [212], 'privacy.': [217], 'By': [218], 'strategically': [219], 'these': [221], 'challenges,': [222], 'can': [224], 'build': [225], 'trust': [226], 'consumers,': [228], 'mitigate': [229], 'risks,': [231], 'unlock': [233], 'AI’s': [234], 'transformative': [235], 'potential': [236], 'privacy-centric': [239], 'era.': [240]}",2024,"['Internet privacy', 'Business', 'Information privacy', 'Privacy policy', 'Computer security', 'Computer science']","The convergence of artificial intelligence (AI) and data privacy has created a pivotal challenge for global businesses navigating complex regulatory landscapes. As AI systems increasingly depend on vast datasets to deliver insights and drive innovation, concerns about data protection, algorithmic transparency, and compliance with privacy laws have intensified. The global regulatory environment, encompassing frameworks such as the European Union’s General Data Protection Regulation (GDPR), California’s Consumer Privacy Act (CCPA), and China’s Personal Information Protection Law (PIPL), presents a fragmented legal landscape that requires careful navigation. This paper examines the multifaceted challenges businesses face in aligning AI adoption with regulatory compliance while maintaining ethical standards. Key concerns include managing cross-border data transfers, ensuring data minimization, addressing algorithmic biases, and safeguarding consumer rights in automated decision-making processes. Furthermore, the need for global harmonization of privacy standards is emphasized, given the inconsistencies in regulations across jurisdictions. Actionable insights are provided for businesses to adapt and thrive in this regulatory environment. These include the implementation of privacy-by-design in AI systems, the adoption of advanced data protection technologies like federated learning and differential privacy, and leveraging AI to enhance compliance processes, such as automated data audits and real-time breach detection. The paper also advocates for collaborative efforts among governments, industry stakeholders, and regulators to establish a cohesive framework for AI and data privacy. By strategically addressing these challenges, businesses can build trust with consumers, mitigate legal risks, and unlock AI’s transformative potential in a privacy-centric era."
https://openalex.org/W4407414557,Generative AI-Enhanced Cybersecurity Framework for Enterprise Data Privacy Management,"{'This': [0, 204], 'study': [1], 'presents': [2], 'a': [3, 120, 207], 'Generative': [4, 24], 'AI-Enhanced': [5], 'Cybersecurity': [6], 'Framework': [7], 'designed': [8], 'to': [9, 177, 189, 198], 'strengthen': [10], 'enterprise': [11, 140], 'data': [12, 175, 179, 217], 'privacy': [13, 46, 218], 'management': [14], 'while': [15, 181], 'improving': [16], 'threat': [17, 201], 'detection': [18, 34, 55], 'accuracy': [19, 124, 149], 'and': [20, 31, 47, 65, 92, 108, 126, 157, 174, 194, 210, 216], 'scalability.': [21], 'By': [22], 'leveraging': [23], 'Adversarial': [25], 'Networks': [26], '(GANs),': [27], 'Variational': [28], 'Autoencoders': [29], '(VAEs),': [30], 'traditional': [32], 'anomaly': [33, 54], 'methods,': [35], 'the': [36, 53, 89, 96, 151], 'framework': [37, 118, 161], 'generates': [38], 'synthetic': [39], 'datasets': [40], 'that': [41, 145], 'mimic': [42], 'real-world': [43], 'data,': [44], 'ensuring': [45], 'regulatory': [48], 'compliance.': [49], 'At': [50], 'its': [51], 'core,': [52], 'engine': [56], 'integrates': [57], 'machine': [58], 'learning': [59, 72, 197], 'models,': [60], 'such': [61], 'as': [62], 'Random': [63], 'Forest': [64], 'Support': [66], 'Vector': [67], 'Machines': [68], '(SVMs),': [69], 'alongside': [70], 'deep': [71], 'techniques': [73], 'like': [74], 'Long': [75], 'Short-Term': [76], 'Memory': [77], '(LSTM)': [78], 'networks,': [79], 'delivering': [80], 'robust': [81], 'performance': [82, 94], 'across': [83], 'diverse': [84, 166], 'domains.': [85], 'Experimental': [86], 'results': [87], 'demonstrate': [88], 'framework’s': [90], 'adaptability': [91], 'high': [93], 'in': [95, 165], 'financial': [97], 'sector': [98], '(accuracy:': [99, 104, 112], '94%,': [100], 'recall:': [101], '95%),': [102], 'healthcare': [103], '96%,': [105], 'precision:': [106], '93%),': [107], 'smart': [109], 'city': [110], 'infrastructures': [111], '91%,': [113], 'F1': [114], 'score:': [115], '90%).': [116], 'The': [117], 'achieves': [119], 'balanced': [121], 'trade-off': [122], 'between': [123], '(0.96)': [125], 'computational': [127], 'efficiency': [128], '(processing': [129], 'time:': [130], '1.5': [131], 's': [132], 'per': [133], 'transaction),': [134], 'making': [135], 'it': [136, 169], 'ideal': [137], 'for': [138, 213], 'real-time': [139, 191], 'deployments.': [141], 'Unlike': [142], 'analog': [143], 'systems': [144], 'achieve': [146], '&gt;': [147], '0.99': [148], 'at': [150], 'cost': [152], 'of': [153], 'higher': [154], 'resource': [155], 'consumption': [156], 'limited': [158], 'scalability,': [159], 'this': [160], 'emphasizes': [162], 'practical': [163, 211], 'applications': [164], 'sectors.': [167], 'Additionally,': [168], 'employs': [170], 'differential': [171], 'privacy,': [172], 'encryption,': [173], 'masking': [176], 'ensure': [178], 'security': [180], 'addressing': [182], 'modern': [183], 'cybersecurity': [184, 215], 'challenges.': [185], 'Future': [186], 'work': [187], 'aims': [188], 'enhance': [190], 'scalability': [192], 'further': [193], 'explore': [195], 'reinforcement': [196], 'advance': [199], 'proactive': [200], 'mitigation': [202], 'measures.': [203], 'research': [205], 'provides': [206], 'scalable,': [208], 'adaptive,': [209], 'solution': [212], 'enterprise-level': [214], 'management.': [219]}",2025,"['Computer security', 'Computer science', 'Internet privacy']","This study presents a Generative AI-Enhanced Cybersecurity Framework designed to strengthen enterprise data privacy management while improving threat detection accuracy and scalability. By leveraging Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and traditional anomaly detection methods, the framework generates synthetic datasets that mimic real-world data, ensuring privacy and regulatory compliance. At its core, the anomaly detection engine integrates machine learning models, such as Random Forest and Support Vector Machines (SVMs), alongside deep learning techniques like Long Short-Term Memory (LSTM) networks, delivering robust performance across diverse domains. Experimental results demonstrate the framework’s adaptability and high performance in the financial sector (accuracy: 94%, recall: 95%), healthcare (accuracy: 96%, precision: 93%), and smart city infrastructures (accuracy: 91%, F1 score: 90%). The framework achieves a balanced trade-off between accuracy (0.96) and computational efficiency (processing time: 1.5 s per transaction), making it ideal for real-time enterprise deployments. Unlike analog systems that achieve &gt; 0.99 accuracy at the cost of higher resource consumption and limited scalability, this framework emphasizes practical applications in diverse sectors. Additionally, it employs differential privacy, encryption, and data masking to ensure data security while addressing modern cybersecurity challenges. Future work aims to enhance real-time scalability further and explore reinforcement learning to advance proactive threat mitigation measures. This research provides a scalable, adaptive, and practical solution for enterprise-level cybersecurity and data privacy management."
https://openalex.org/W4405153018,AI-powered cybersecurity: Strategic approaches to mitigate risk and safeguard data privacy,"{'The': [0, 154], 'proliferation': [1], 'of': [2, 61, 97, 156, 176, 218], 'sophisticated': [3], 'cyber': [4], 'threats': [5], 'has': [6], 'compelled': [7], 'organizations': [8, 52, 119, 135, 188, 213], 'to': [9, 40, 53, 111, 120, 143, 168, 194], 'adopt': [10], 'advanced': [11], 'solutions': [12], 'for': [13, 86], 'safeguarding': [14], 'sensitive': [15], 'data': [16, 147, 169], 'and': [17, 37, 44, 74, 105, 115, 126, 173, 197, 210, 242], 'mitigating': [18], 'enterprise': [19, 92, 234], 'risks.': [20], 'Artificial': [21], 'intelligence': [22], '(AI)-driven': [23], 'cybersecurity': [24, 89, 159, 220], 'systems': [25, 50, 160, 193], 'have': [26, 189], 'emerged': [27], 'as': [28, 67], 'transformative': [29], 'tools': [30], 'in': [31, 59], 'this': [32], 'endeavor,': [33], 'leveraging': [34], 'machine': [35], 'learning': [36], 'predictive': [38], 'analytics': [39], 'detect,': [41], 'respond': [42], 'to,': [43], 'prevent': [45], 'cyberattacks.': [46], 'However,': [47], 'implementing': [48], 'these': [49, 138, 192], 'requires': [51], 'balance': [54], 'innovation': [55], 'with': [56, 140, 146], 'compliance,': [57, 240], 'particularly': [58], 'light': [60], 'stringent': [62], 'global': [63], 'privacy': [64], 'regulations': [65], 'such': [66, 226], 'the': [68, 75, 131, 174, 216], 'General': [69], 'Data': [70], 'Protection': [71], 'Regulation': [72], '(GDPR)': [73], 'California': [76], 'Consumer': [77], 'Privacy': [78], 'Act': [79], '(CCPA).': [80], 'This': [81, 222], 'paper': [82, 132, 223], 'examines': [83], 'strategic': [84, 203], 'approaches': [85], 'integrating': [87], 'AI-based': [88], 'frameworks': [90, 139], 'into': [91], 'risk': [93, 235], 'management.': [94], 'Key': [95], 'areas': [96], 'focus': [98], 'include': [99], 'real-time': [100], 'threat': [101], 'detection,': [102], 'anomaly': [103], 'identification,': [104], 'automated': [106, 179], 'incident': [107], 'response.': [108], 'AI’s': [109], 'ability': [110], 'analyse': [112], 'vast': [113], 'datasets': [114], 'identify': [116], 'patterns': [117], 'enables': [118], 'proactively': [121], 'address': [122], 'vulnerabilities,': [123], 'minimize': [124], 'downtime,': [125], 'protect': [127], 'critical': [128], 'assets.': [129], 'Furthermore,': [130], 'explores': [133], 'how': [134, 187], 'can': [136, 214], 'align': [137], 'privacy-by-design': [141], 'principles': [142], 'ensure': [144], 'compliance': [145], 'protection': [148], 'laws': [149], 'while': [150], 'fostering': [151], 'consumer': [152], 'trust.': [153], 'challenges': [155], 'adopting': [157, 202], 'AI-driven': [158, 219], 'are': [161], 'also': [162, 238], 'addressed,': [163], 'including': [164, 206], 'ethical': [165], 'concerns': [166], 'related': [167], 'use,': [170], 'algorithmic': [171], 'transparency,': [172], 'risks': [175], 'over-reliance': [177], 'on': [178], 'systems.': [180, 221], 'Case': [181], 'studies': [182], 'from': [183], 'leading': [184], 'industries': [185], 'demonstrate': [186], 'successfully': [190], 'implemented': [191], 'enhance': [195], 'resilience': [196], 'maintain': [198], 'competitive': [199], 'advantage.': [200], 'By': [201], 'management': [204], 'practices,': [205], 'robust': [207], 'governance': [208], 'models': [209], 'continuous': [211], 'monitoring,': [212], 'optimize': [215], 'effectiveness': [217], 'concludes': [224], 'that': [225], 'systems,': [227], 'when': [228], 'integrated': [229], 'thoughtfully,': [230], 'not': [231], 'only': [232], 'strengthen': [233], 'mitigation': [236], 'but': [237], 'support': [239], 'innovation,': [241], 'long-term': [243], 'organizational': [244], 'growth.': [245]}",2024,"['Safeguard', 'Computer security', 'Internet privacy', 'Business', 'Privacy protection', 'Data breach', 'Information privacy', 'Computer science', 'International trade']","The proliferation of sophisticated cyber threats has compelled organizations to adopt advanced solutions for safeguarding sensitive data and mitigating enterprise risks. Artificial intelligence (AI)-driven cybersecurity systems have emerged as transformative tools in this endeavor, leveraging machine learning and predictive analytics to detect, respond to, and prevent cyberattacks. However, implementing these systems requires organizations to balance innovation with compliance, particularly in light of stringent global privacy regulations such as the General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA). This paper examines strategic approaches for integrating AI-based cybersecurity frameworks into enterprise risk management. Key areas of focus include real-time threat detection, anomaly identification, and automated incident response. AI’s ability to analyse vast datasets and identify patterns enables organizations to proactively address vulnerabilities, minimize downtime, and protect critical assets. Furthermore, the paper explores how organizations can align these frameworks with privacy-by-design principles to ensure compliance with data protection laws while fostering consumer trust. The challenges of adopting AI-driven cybersecurity systems are also addressed, including ethical concerns related to data use, algorithmic transparency, and the risks of over-reliance on automated systems. Case studies from leading industries demonstrate how organizations have successfully implemented these systems to enhance resilience and maintain competitive advantage. By adopting strategic management practices, including robust governance models and continuous monitoring, organizations can optimize the effectiveness of AI-driven cybersecurity systems. This paper concludes that such systems, when integrated thoughtfully, not only strengthen enterprise risk mitigation but also support compliance, innovation, and long-term organizational growth."
https://openalex.org/W4399791294,Fostering social media user intentions: AI-enabled privacy and intrusiveness concerns,"{'Purpose': [0], 'This': [1, 119], 'paper': [2, 120], 'aims': [3], 'to': [4, 139], 'empirically': [5], 'examine': [6], 'the': [7, 39, 65, 87, 104, 126], 'impact': [8], 'of': [9, 41, 89, 103, 145], 'psychological': [10], 'factors': [11], '(i.e.': [12], 'privacy': [13, 68], 'and': [14, 70, 113, 128], 'intrusiveness': [15], 'concerns)': [16], 'on': [17, 122], 'user': [18, 108], 'intentions': [19, 72], 'regarding': [20], 'artificial': [21], 'intelligence': [22], '(AI)-enabled': [23], 'social': [24, 51, 148], 'commerce': [25, 149], 'applications': [26], 'at': [27], 'their': [28, 95], 'core': [29], 'through': [30], 'perceived': [31, 62, 76], 'usefulness.': [32, 63, 77], 'The': [33], 'theoretical': [34, 127, 135], 'model': [35], 'is': [36], 'supported': [37], 'by': [38, 75, 124], 'theory': [40], 'planned': [42], 'behaviour': [43], '(TPB).': [44], 'Design/methodology/approach': [45], 'Data': [46], 'was': [47, 73], 'gathered': [48], 'from': [49], '488': [50], 'media': [52], 'users': [53], 'in': [54], 'Saudi': [55], 'Arabia.': [56], 'Findings': [57], 'Privacy': [58], 'concerns': [59, 69], 'significantly': [60], 'affect': [61], 'Furthermore,': [64, 98], 'link': [66], 'between': [67], 'behavioural': [71, 96], 'mediated': [74], 'Research': [78], 'limitations/implications': [79], 'Business': [80], 'leaders': [81], 'should': [82], 'raise': [83], 'users’': [84], 'awareness': [85], 'about': [86], 'effectiveness': [88], 'AI-powered': [90, 147], 'tools': [91], 'that': [92, 106], 'can': [93], 'influence': [94], 'intentions.': [97], 'managers': [99], 'must': [100], 'be': [101], 'aware': [102], 'regulations': [105], 'protect': [107], 'privacy,': [109], 'track': [110], 'online': [111], 'activity': [112], 'offer': [114], 'secure': [115], 'communication': [116], 'channels.': [117], 'Originality/value': [118], 'expands': [121], 'TPB': [123], 'bridging': [125], 'practical': [129], 'divide.': [130], 'It': [131], 'further': [132], 'develops': [133], 'a': [134], 'framework': [136], 'for': [137], 'practitioners': [138], 'better': [140], 'understand': [141], 'customers’': [142], 'physiological': [143], 'aspects': [144], 'using': [146], 'platforms.': [150]}",2024,"['Intrusiveness', 'Originality', 'Social media', 'Theory of planned behavior', 'Internet privacy', 'Affect (linguistics)', 'Value (mathematics)', 'Psychology', 'Computer science', 'Knowledge management', 'Social psychology', 'World Wide Web', 'Control (management)', 'Artificial intelligence', 'Communication', 'Creativity', 'Machine learning']","Purpose This paper aims to empirically examine the impact of psychological factors (i.e. privacy and intrusiveness concerns) on user intentions regarding artificial intelligence (AI)-enabled social commerce applications at their core through perceived usefulness. The theoretical model is supported by the theory of planned behaviour (TPB). Design/methodology/approach Data was gathered from 488 social media users in Saudi Arabia. Findings Privacy concerns significantly affect perceived usefulness. Furthermore, the link between privacy concerns and behavioural intentions was mediated by perceived usefulness. Research limitations/implications Business leaders should raise users’ awareness about the effectiveness of AI-powered tools that can influence their behavioural intentions. Furthermore, managers must be aware of the regulations that protect user privacy, track online activity and offer secure communication channels. Originality/value This paper expands on TPB by bridging the theoretical and practical divide. It further develops a theoretical framework for practitioners to better understand customers’ physiological aspects of using AI-powered social commerce platforms."
https://openalex.org/W4411389188,"Privacy, ethics, transparency, and accountability in AI systems for wearable devices","{'The': [0, 142], 'integration': [1], 'of': [2, 32, 53, 62, 86, 93, 139, 203, 226], 'artificial': [3], 'intelligence': [4], '(AI)': [5], 'and': [6, 25, 39, 50, 76, 90, 108, 115, 133, 156, 175, 186, 232], 'machine': [7], 'learning': [8], '(ML)': [9], 'into': [10], 'wearable': [11, 207], 'sensor': [12], 'technologies': [13, 34], 'has': [14, 35], 'substantially': [15], 'advanced': [16], 'health': [17, 81, 235], 'data': [18, 44, 71, 158], 'science,': [19], 'enabling': [20], 'continuous': [21], 'monitoring,': [22], 'personalised': [23], 'interventions,': [24], 'predictive': [26], 'analytics.': [27], 'However,': [28], 'the': [29, 51, 66, 97, 168, 170, 176, 189, 200, 212, 224], 'fast': [30], 'advancement': [31], 'these': [33, 63, 120], 'raised': [36], 'critical': [37], 'ethical': [38, 116, 145], 'regulatory': [40, 134, 217], 'concerns,': [41], 'particularly': [42], 'around': [43], 'privacy,': [45], 'algorithmic': [46], 'bias,': [47], 'informed': [48], 'consent,': [49], 'opacity': [52], 'automated': [54], 'decision-making.': [55], 'This': [56], 'study': [57, 98, 213], 'undertakes': [58], 'a': [59, 125, 184, 196, 216], 'systematic': [60], 'examination': [61], 'challenges,': [64], 'highlighting': [65], 'risks': [67], 'posed': [68], 'by': [69], 'unregulated': [70], 'aggregation,': [72], 'biased': [73], 'model': [74, 103, 198], 'training,': [75], 'inadequate': [77], 'transparency': [78, 182], 'in': [79, 102, 111, 192, 206], 'AI-powered': [80], 'applications.': [82], 'Through': [83], 'an': [84], 'analysis': [85], 'current': [87], 'privacy': [88], 'frameworks': [89], 'empirical': [91], 'assessment': [92], 'publicly': [94], 'available': [95], 'datasets,': [96], 'identifies': [99], 'significant': [100], 'disparities': [101], 'performance': [104], 'across': [105, 136], 'demographic': [106], 'groups': [107], 'exposes': [109], 'vulnerabilities': [110], 'both': [112], 'technical': [113], 'design': [114], 'governance.': [117], 'To': [118], 'address': [119], 'issues,': [121], 'this': [122, 193], 'article': [123, 194], 'introduces': [124], 'data-driven': [126], 'methodological': [127], 'framework': [128, 143, 190], 'that': [129, 219], 'embeds': [130], 'transparency,': [131], 'accountability,': [132], 'alignment': [135], 'all': [137], 'stages': [138], 'AI': [140, 178, 204], 'development.': [141], 'operationalises': [144], 'principles': [146], 'through': [147], 'concrete': [148], 'mechanisms,': [149], 'including': [150], 'explainable': [151], 'AI,': [152], 'bias': [153], 'mitigation': [154], 'techniques,': [155], 'consent-aware': [157], 'processing': [159], 'pipelines,': [160], 'while': [161], 'aligning': [162], 'with': [163, 223], 'legal': [164], 'standards': [165], 'such': [166], 'as': [167, 183], 'GDPR,': [169], 'UK': [171], 'Data': [172], 'Protection': [173], 'Act,': [174], 'EU': [177], 'Act.': [179], 'By': [180], 'incorporating': [181], 'structural': [185], 'procedural': [187], 'requirement,': [188], 'presented': [191], 'offers': [195], 'replicable': [197], 'for': [199, 215], 'responsible': [201], 'development': [202], 'systems': [205], 'healthcare.': [208], 'In': [209], 'doing': [210], 'so,': [211], 'advocates': [214], 'paradigm': [218], 'balances': [220], 'technological': [221], 'innovation': [222], 'protection': [225], 'individual': [227], 'rights,': [228], 'fostering': [229], 'fair,': [230], 'secure,': [231], 'trustworthy': [233], 'AI-driven': [234], 'monitoring.': [236]}",2025,"['Transparency (behavior)', 'Accountability', 'Wearable computer', 'Corporate governance', 'General Data Protection Regulation', 'Computer science', 'Information privacy', 'Wearable technology', 'Data Protection Act 1998', 'Data governance', 'Data science', 'Computer security', 'Business', 'Political science', 'Data quality', 'Marketing', 'Metric (unit)', 'Finance', 'Embedded system', 'Law']","The integration of artificial intelligence (AI) and machine learning (ML) into wearable sensor technologies has substantially advanced health data science, enabling continuous monitoring, personalised interventions, and predictive analytics. However, the fast advancement of these technologies has raised critical ethical and regulatory concerns, particularly around data privacy, algorithmic bias, informed consent, and the opacity of automated decision-making. This study undertakes a systematic examination of these challenges, highlighting the risks posed by unregulated data aggregation, biased model training, and inadequate transparency in AI-powered health applications. Through an analysis of current privacy frameworks and empirical assessment of publicly available datasets, the study identifies significant disparities in model performance across demographic groups and exposes vulnerabilities in both technical design and ethical governance. To address these issues, this article introduces a data-driven methodological framework that embeds transparency, accountability, and regulatory alignment across all stages of AI development. The framework operationalises ethical principles through concrete mechanisms, including explainable AI, bias mitigation techniques, and consent-aware data processing pipelines, while aligning with legal standards such as the GDPR, the UK Data Protection Act, and the EU AI Act. By incorporating transparency as a structural and procedural requirement, the framework presented in this article offers a replicable model for the responsible development of AI systems in wearable healthcare. In doing so, the study advocates for a regulatory paradigm that balances technological innovation with the protection of individual rights, fostering fair, secure, and trustworthy AI-driven health monitoring."
https://openalex.org/W4396775100,"Privacy-Preserving Architectures for AI/ML Applications: Methods, Balances, and Illustrations","{'With': [0], 'the': [1, 23, 31, 51, 75, 139, 147, 154], 'widespread': [2], 'integration': [3, 148], 'of': [4, 15, 25, 35, 43, 54, 82, 105, 141, 149, 166], 'artificial': [5], 'intelligence': [6], '(AI)': [7], 'and': [8, 33, 45, 50, 71, 97, 112, 119, 129, 151, 159], 'blockchain': [9], 'technologies,': [10], 'safeguarding': [11, 165], 'privacy': [12, 55, 83, 121, 142], 'has': [13], 'become': [14], 'paramount': [16], 'importance.': [17], 'These': [18], 'techniques': [19], 'not': [20], 'only': [21], 'ensure': [22], 'confidentiality': [24], ""individuals'"": [26], 'data': [27, 65, 93], 'but': [28], 'also': [29], 'maintain': [30], 'integrity': [32], 'reliability': [34], 'information.': [36], 'This': [37], 'study': [38, 117], 'offers': [39], 'an': [40], 'introductory': [41], 'overview': [42], 'AI': [44, 150], 'blockchain,': [46, 152], 'highlighting': [47], 'their': [48, 109], 'fusion': [49], 'subsequent': [52], 'emergence': [53], 'protection': [56, 84, 122, 143], 'methodologies.': [57], 'It': [58], 'explores': [59], 'various': [60], 'application': [61, 127], 'contexts,': [62], 'such': [63], 'as': [64], 'encryption,': [66], 'de-identification,': [67], 'multi-tier': [68], 'distributed': [69], 'ledgers,': [70], 'k-anonymity': [72], 'techniques.': [73], 'Moreover,': [74], 'paper': [76], 'critically': [77], 'evaluates': [78], 'five': [79], 'essential': [80], 'dimensions': [81], 'systems': [85], 'within': [86], 'AI-blockchain': [87, 126], 'integration:': [88], 'authorization': [89], 'management,': [90], 'access': [91], 'control,': [92], 'security,': [94], 'network': [95], 'integrity,': [96], 'scalability.': [98], 'Additionally,': [99], 'it': [100, 134], 'conducts': [101], 'a': [102, 162], 'comprehensive': [103, 164], 'analysis': [104], 'existing': [106], 'shortcomings,': [107], 'identifying': [108], 'root': [110], 'causes': [111], 'suggesting': [113], 'corresponding': [114], 'remedies.': [115], 'The': [116], 'categorizes': [118], 'synthesizes': [120], 'methodologies': [123], 'based': [124], 'on': [125], 'contexts': [128], 'technical': [130], 'frameworks.': [131], 'In': [132], 'conclusion,': [133], 'outlines': [135], 'prospective': [136], 'avenues': [137], 'for': [138, 161], 'evolution': [140], 'technologies': [144], 'resulting': [145], 'from': [146], 'emphasizing': [153], 'need': [155], 'to': [156], 'enhance': [157], 'efficiency': [158], 'security': [160], 'more': [163], 'privacy.': [167]}",2024,['Computer science'],"With the widespread integration of artificial intelligence (AI) and blockchain technologies, safeguarding privacy has become of paramount importance. These techniques not only ensure the confidentiality of individuals' data but also maintain the integrity and reliability of information. This study offers an introductory overview of AI and blockchain, highlighting their fusion and the subsequent emergence of privacy protection methodologies. It explores various application contexts, such as data encryption, de-identification, multi-tier distributed ledgers, and k-anonymity techniques. Moreover, the paper critically evaluates five essential dimensions of privacy protection systems within AI-blockchain integration: authorization management, access control, data security, network integrity, and scalability. Additionally, it conducts a comprehensive analysis of existing shortcomings, identifying their root causes and suggesting corresponding remedies. The study categorizes and synthesizes privacy protection methodologies based on AI-blockchain application contexts and technical frameworks. In conclusion, it outlines prospective avenues for the evolution of privacy protection technologies resulting from the integration of AI and blockchain, emphasizing the need to enhance efficiency and security for a more comprehensive safeguarding of privacy."
https://openalex.org/W4389379814,Securing Collaborative Medical AI by Using Differential Privacy: Domain Transfer for Classification of Chest Radiographs,"{'PURPOSE:': [0], 'To': [1], 'investigate': [2], 'the': [3, 44, 54, 57, 91, 94, 101, 305], 'integration': [4], 'of': [5, 59, 82, 85, 137, 144, 149, 253], 'differential': [6], 'privacy': [7, 128], '(DP)': [8], 'and': [9, 41, 50, 71, 76, 78, 84, 109, 114, 185, 198, 214, 223, 239, 309], 'analyze': [10], 'its': [11], 'impact': [12], 'on': [13], 'model': [14], 'performance': [15, 75, 151, 156, 252], 'as': [16, 100, 104, 106, 111, 152], 'compared': [17, 89, 139, 153], 'with': [18, 126, 140, 154], 'models': [19, 87, 200, 256], 'trained': [20], 'without': [21], 'DP.': [22, 261], 'MATERIALS': [23], 'AND': [24], 'METHODS:': [25], 'Leveraging': [26], 'more': [27], 'than': [28, 203], '590': [29], '000': [30], 'chest': [31], 'radiographs': [32], 'from': [33, 38, 43, 48, 52], 'five': [34], 'institutions,': [35], 'including': [36], 'VinDr-CXR': [37], 'Vietnam,': [39], 'ChestX-ray14': [40], 'CheXpert': [42], 'United': [45], 'States,': [46], 'UKA-CXR': [47], 'Germany,': [49], 'PadChest': [51], 'Spain,': [53], 'authors': [55], 'evaluated': [56, 115], 'efficacy': [58], 'DP-enhanced': [60], 'domain': [61], 'transfer': [62], '(DP-DT)': [63], 'in': [64, 142, 147, 311], 'classifying': [65], 'cardiomegaly,': [66], 'pleural': [67], 'effusion,': [68], 'pneumonia,': [69], 'atelectasis,': [70], 'healthy': [72], 'individuals.': [73], 'Diagnostic': [74], 'sex-specific': [77], 'age-specific': [79], 'demographic': [80], 'fairness': [81], 'DP-DT': [83, 133, 197], 'non–DP-DT': [86, 141, 199], 'were': [88, 201], 'using': [90, 119], 'area': [92], 'under': [93], 'receiver': [95], 'operating': [96], 'characteristic': [97], 'curve': [98], '(AUC)': [99], 'main': [102], 'metric,': [103], 'well': [105], 'accuracy,': [107], 'sensitivity,': [108], 'specificity': [110], 'secondary': [112], 'metrics,': [113], 'for': [116, 205, 212, 218, 220, 231, 237, 243, 246, 297], 'statistical': [117], 'significance': [118], 'paired': [120], 'Student': [121], 't': [122], 'tests.': [123], 'RESULTS:': [124], 'Even': [125], 'high': [127], 'levels': [129], '(ε': [130], '≈': [131], '1),': [132], 'showed': [134], 'no': [135], 'evidence': [136], 'differences': [138, 195], 'terms': [143], 'a': [145], 'decrease': [146], 'AUC': [148, 194], 'cross-institutional': [150], 'single-institutional': [155], '(VinDr-CXR:': [157], '0.07': [158, 165, 172, 187], 'vs': [159, 166, 173, 180, 188], '0.07,': [160, 174, 189], 'P': [161, 168, 175, 182, 190, 215, 234, 240], '=': [162, 169, 176, 183, 191], '.96;': [163], 'ChestX-ray14:': [164], '0.06,': [167], '.12;': [170], 'CheXpert:': [171], '.18;': [177], 'UKA-CXR:': [178], '0.18': [179], '0.18,': [181], '.90;': [184], 'PadChest:': [186], '.35).': [192], 'Furthermore,': [193], 'between': [196], 'less': [202], '1%': [204], 'all': [206, 221, 225, 248], 'sex': [207], 'subgroups': [208, 227], '(P': [209, 228], '>': [210, 216, 229, 235, 241], '.33': [211, 236], 'female': [213], '.22': [217], 'male,': [219], 'domains)': [222], 'nearly': [224, 247], 'age': [226], '.16': [230], 'younger': [232], 'participants,': [233], 'adults,': [238, 245], '.27': [242], 'older': [244], 'domains).': [249], 'CONCLUSION:': [250], 'Cross-institutional': [251], 'artificial': [254], 'intelligence': [255], 'was': [257], 'not': [258], 'affected': [259], 'by': [260, 307], 'Keywords:': [262], 'Convolutional': [263], 'Neural': [264, 278], 'Network': [265], '(CNN),': [266], 'Transfer': [267], 'Learning,': [268, 270, 284], 'Supervised': [269], 'Diagnosis,': [271, 282], 'Forensics,': [272], 'Computer': [273], 'Applications–General,': [274], 'Image': [275], 'Postprocessing,': [276], 'Informatics,': [277], 'Networks,': [279], 'Thorax,': [280], 'Computer-Aided': [281], 'Deep': [283], 'Domain': [285], 'Transfer,': [286], 'Differential': [287], 'Privacy,': [288], 'Privacy-Preserving': [289], 'AI,': [290], 'Chest': [291], 'Radiograph': [292], 'Supplemental': [293], 'material': [294], 'is': [295], 'available': [296], 'this': [298, 312], 'article.': [299], '©': [300], 'RSNA,': [301], '2023': [302], 'See': [303], 'also': [304], 'commentary': [306], 'Suri': [308], 'Summers': [310], 'issue.': [313]}",2023,"['Medicine', 'Receiver operating characteristic', 'Radiography', 'Pneumonia', 'Pleural effusion', 'Metric (unit)', 'Statistical significance', 'Nuclear medicine', 'Radiology', 'Internal medicine', 'Operations management', 'Economics']","PURPOSE: To investigate the integration of differential privacy (DP) and analyze its impact on model performance as compared with models trained without DP. MATERIALS AND METHODS: Leveraging more than 590 000 chest radiographs from five institutions, including VinDr-CXR from Vietnam, ChestX-ray14 and CheXpert from the United States, UKA-CXR from Germany, and PadChest from Spain, the authors evaluated the efficacy of DP-enhanced domain transfer (DP-DT) in classifying cardiomegaly, pleural effusion, pneumonia, atelectasis, and healthy individuals. Diagnostic performance and sex-specific and age-specific demographic fairness of DP-DT and of non–DP-DT models were compared using the area under the receiver operating characteristic curve (AUC) as the main metric, as well as accuracy, sensitivity, and specificity as secondary metrics, and evaluated for statistical significance using paired Student t tests. RESULTS: Even with high privacy levels (ε ≈ 1), DP-DT showed no evidence of differences compared with non–DP-DT in terms of a decrease in AUC of cross-institutional performance as compared with single-institutional performance (VinDr-CXR: 0.07 vs 0.07, P = .96; ChestX-ray14: 0.07 vs 0.06, P = .12; CheXpert: 0.07 vs 0.07, P = .18; UKA-CXR: 0.18 vs 0.18, P = .90; and PadChest: 0.07 vs 0.07, P = .35). Furthermore, AUC differences between DP-DT and non–DP-DT models were less than 1% for all sex subgroups (P > .33 for female and P > .22 for male, for all domains) and nearly all age subgroups (P > .16 for younger participants, P > .33 for adults, and P > .27 for older adults, for nearly all domains). CONCLUSION: Cross-institutional performance of artificial intelligence models was not affected by DP. Keywords: Convolutional Neural Network (CNN), Transfer Learning, Supervised Learning, Diagnosis, Forensics, Computer Applications–General, Image Postprocessing, Informatics, Neural Networks, Thorax, Computer-Aided Diagnosis, Deep Learning, Domain Transfer, Differential Privacy, Privacy-Preserving AI, Chest Radiograph Supplemental material is available for this article. © RSNA, 2023 See also the commentary by Suri and Summers in this issue."
https://openalex.org/W4386569584,Debiasing Strategies for Conversational AI: Improving Privacy and Security Decision-Making,"{'Abstract': [0], 'With': [1], 'numerous': [2], 'conversational': [3, 56], 'AI': [4, 57], '(CAI)': [5], 'systems': [6, 58], 'being': [7], 'deployed': [8], 'in': [9, 78, 91, 95], 'homes,': [10], 'cars,': [11], 'and': [12, 24, 36, 45, 53, 63, 67, 87, 98, 109, 139, 164], 'public': [13], 'spaces,': [14], 'people': [15], 'are': [16], 'faced': [17], 'with': [18], 'an': [19], 'increasing': [20], 'number': [21], 'of': [22, 55, 137, 145, 154, 161], 'privacy': [23, 62, 97, 128], 'security': [25, 64, 99], 'decisions.': [26], 'They': [27], 'need': [28], 'to': [29, 34, 105, 134, 142, 156], 'decide': [30], 'which': [31], 'personal': [32], 'information': [33], 'disclose': [35], 'how': [37, 126], 'their': [38, 92], 'data': [39], 'can': [40, 82, 103, 131], 'be': [41, 132], 'processed': [42], 'by': [43], 'providers': [44], 'developers.': [46], 'On': [47], 'the': [48, 79, 135, 146, 151, 162], 'other': [49, 76, 88], 'hand,': [50], 'designers,': [51], 'developers,': [52], 'integrators': [54], 'must': [59], 'consider': [60], 'users’': [61], 'during': [65], 'development': [66], 'make': [68], 'appropriate': [69], 'choices.': [70, 100], 'However,': [71], 'users': [72], 'as': [73, 75], 'well': [74], 'actors': [77], 'CAI': [80, 147, 155], 'ecosystem': [81], 'suffer': [83], 'from': [84], 'cognitive': [85], 'biases': [86, 108], 'mental': [89], 'flaws': [90], 'decision-making': [93], 'resulting': [94], 'adverse': [96], 'Debiasing': [101], 'strategies': [102, 130], 'help': [104], 'mitigate': [106], 'these': [107], 'improve': [110], 'decision-making.': [111], 'In': [112], 'this': [113], 'position': [114], 'paper,': [115], 'we': [116], 'establish': [117], 'a': [118], 'novel': [119], 'framework': [120], 'for': [121], 'categorizing': [122], 'debiasing': [123, 129], 'strategies,': [124, 163], 'show': [125], 'existing': [127], 'adapted': [133], 'context': [136], 'CAI,': [138], 'assign': [140], 'them': [141], 'relevant': [143], 'stakeholders': [144], 'ecosystem.': [148], 'We': [149], 'highlight': [150], 'unique': [152], 'possibilities': [153], 'foster': [157], 'debiasing,': [158], 'discuss': [159], 'limitations': [160], 'identify': [165], 'research': [166], 'challenges.': [167]}",2023,"['Debiasing', 'Computer science', 'Context (archaeology)', 'Internet privacy', 'Computer security', 'Psychology', 'Cognitive science', 'Biology', 'Paleontology']","Abstract With numerous conversational AI (CAI) systems being deployed in homes, cars, and public spaces, people are faced with an increasing number of privacy and security decisions. They need to decide which personal information to disclose and how their data can be processed by providers and developers. On the other hand, designers, developers, and integrators of conversational AI systems must consider users’ privacy and security during development and make appropriate choices. However, users as well as other actors in the CAI ecosystem can suffer from cognitive biases and other mental flaws in their decision-making resulting in adverse privacy and security choices. Debiasing strategies can help to mitigate these biases and improve decision-making. In this position paper, we establish a novel framework for categorizing debiasing strategies, show how existing privacy debiasing strategies can be adapted to the context of CAI, and assign them to relevant stakeholders of the CAI ecosystem. We highlight the unique possibilities of CAI to foster debiasing, discuss limitations of the strategies, and identify research challenges."
https://openalex.org/W4405625634,"Harnessing AI for data privacy: Examining risks, opportunities and strategic future directions","{'Artificial': [0], 'intelligence': [1], '(AI)': [2], 'is': [3], 'transforming': [4], 'data': [5, 37, 65, 106, 113, 137, 183, 233], 'privacy': [6, 66, 95, 132, 234], 'management,': [7], 'offering': [8], 'innovative': [9], 'solutions': [10], 'to': [11, 35, 90, 111, 134, 146, 159, 175, 215, 229], 'safeguard': [12], 'sensitive': [13, 80], 'information': [14], 'while': [15, 115, 221], 'simultaneously': [16], 'introducing': [17], 'new': [18], 'risks.': [19], 'AI-driven': [20, 155, 193], 'technologies,': [21], 'such': [22], 'as': [23], 'privacy-preserving': [24], 'machine': [25], 'learning,': [26], 'anomaly': [27, 156], 'detection,': [28], 'and': [29, 52, 82, 130, 149, 151, 161, 189, 203, 212, 242], 'automated': [30], 'compliance': [31, 41], 'tools,': [32], 'enable': [33, 135], 'organizations': [34], 'strengthen': [36], 'protection': [38], 'frameworks,': [39], 'ensuring': [40, 243], 'with': [42, 192], 'global': [43, 173], 'regulations': [44], 'like': [45], 'the': [46, 53, 60, 72, 100, 125, 139, 152, 169, 187, 207, 217, 247], 'General': [47], 'Data': [48], 'Protection': [49], 'Regulation': [50], '(GDPR)': [51], 'California': [54], 'Consumer': [55], 'Privacy': [56], 'Act': [57], '(CCPA).': [58], 'However,': [59], 'use': [61], 'of': [62, 74, 79, 94, 103, 122, 127, 141, 154, 171, 219], 'AI': [63, 85, 104, 143, 180, 220, 231], 'in': [64, 84, 105, 182, 238, 246], 'also': [67, 167], 'raises': [68], 'critical': [69], 'concerns,': [70], 'including': [71], 'risk': [73], 'algorithmic': [75], 'bias,': [76], 'potential': [77, 110, 224], 'misuse': [78], 'data,': [81], 'vulnerabilities': [83], 'systems': [86, 158], 'that': [87], 'could': [88], 'lead': [89], 'breaches': [91], 'or': [92], 'violations': [93], 'rights.': [96], 'This': [97], 'study': [98, 166], 'examines': [99], 'dual-edged': [101], 'role': [102], 'privacy,': [107], 'analysing': [108], 'its': [109, 117, 223], 'revolutionize': [112], 'security': [114], 'addressing': [116], 'inherent': [118], 'challenges.': [119], 'Key': [120], 'areas': [121], 'focus': [123], 'include': [124], 'adoption': [126], 'federated': [128], 'learning': [129], 'differential': [131], 'techniques': [133], 'secure': [136], 'processing,': [138], 'development': [140], 'explainable': [142], '(XAI)': [144], 'models': [145], 'ensure': [147], 'transparency': [148], 'accountability,': [150], 'integration': [153], 'detection': [157], 'monitor': [160], 'prevent': [162], 'unauthorized': [163], 'access.': [164], 'The': [165], 'highlights': [168], 'importance': [170], 'fostering': [172], 'collaboration': [174], 'establish': [176], 'standardized': [177], 'frameworks': [178], 'for': [179, 200, 209, 232], 'governance': [181], 'privacy.': [184], 'By': [185], 'identifying': [186], 'opportunities': [188], 'risks': [190], 'associated': [191], 'innovations,': [194], 'this': [195], 'research': [196], 'provides': [197], 'actionable': [198], 'insights': [199], 'policymakers,': [201], 'organizations,': [202], 'researchers.': [204], 'It': [205], 'emphasizes': [206], 'need': [208], 'robust': [210], 'ethical': [211], 'technical': [213], 'safeguards': [214], 'maximize': [216], 'benefits': [218], 'mitigating': [222], 'harms.': [225], 'A': [226], 'balanced': [227], 'approach': [228], 'leveraging': [230], 'will': [235], 'be': [236], 'pivotal': [237], 'building': [239], 'public': [240], 'trust': [241], 'long-term': [244], 'sustainability': [245], 'digital': [248], 'era.': [249]}",2024,"['Internet privacy', 'Information privacy', 'Business', 'Data science', 'Computer security', 'Computer science']","Artificial intelligence (AI) is transforming data privacy management, offering innovative solutions to safeguard sensitive information while simultaneously introducing new risks. AI-driven technologies, such as privacy-preserving machine learning, anomaly detection, and automated compliance tools, enable organizations to strengthen data protection frameworks, ensuring compliance with global regulations like the General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA). However, the use of AI in data privacy also raises critical concerns, including the risk of algorithmic bias, potential misuse of sensitive data, and vulnerabilities in AI systems that could lead to breaches or violations of privacy rights. This study examines the dual-edged role of AI in data privacy, analysing its potential to revolutionize data security while addressing its inherent challenges. Key areas of focus include the adoption of federated learning and differential privacy techniques to enable secure data processing, the development of explainable AI (XAI) models to ensure transparency and accountability, and the integration of AI-driven anomaly detection systems to monitor and prevent unauthorized access. The study also highlights the importance of fostering global collaboration to establish standardized frameworks for AI governance in data privacy. By identifying the opportunities and risks associated with AI-driven innovations, this research provides actionable insights for policymakers, organizations, and researchers. It emphasizes the need for robust ethical and technical safeguards to maximize the benefits of AI while mitigating its potential harms. A balanced approach to leveraging AI for data privacy will be pivotal in building public trust and ensuring long-term sustainability in the digital era."
https://openalex.org/W4392656950,Exploring Ethical Considerations in AI-driven Autonomous Vehicles: Balancing Safety and Privacy,"{'The': [0], 'deployment': [1], 'of': [2, 86, 112], 'autonomous': [3], 'vehicles': [4], '(AVs)': [5], 'powered': [6], 'by': [7, 29], 'artificial': [8], 'intelligence': [9], '(AI)': [10], 'raises': [11], 'profound': [12], 'ethical': [13, 49, 78, 128], 'questions': [14], 'regarding': [15, 37], 'the': [16, 48, 57, 74, 77, 97, 110, 124], 'balance': [17], 'between': [18], 'safety': [19, 64, 114], 'and': [20, 33, 41, 65, 71, 90, 100, 115, 131], 'privacy.': [21, 66], 'While': [22], 'AI-driven': [23, 52, 118], 'AVs': [24], 'promise': [25], 'to': [26, 61, 123], 'revolutionize': [27], 'transportation': [28], 'potentially': [30], 'reducing': [31], 'accidents': [32], 'increasing': [34], 'efficiency,': [35], 'concerns': [36], 'data': [38, 88], 'privacy,': [39], 'liability,': [40], 'decision-making': [42], 'algorithms': [43], 'persist.': [44], 'This': [45], 'paper': [46, 75], 'explores': [47], 'considerations': [50], 'surrounding': [51], 'AVs,': [53, 119], 'focusing': [54], 'particularly': [55], 'on': [56, 127], 'delicate': [58], 'equilibrium': [59], 'required': [60], 'ensure': [62], 'both': [63], 'Drawing': [67], 'upon': [68], 'existing': [69], 'literature': [70], 'case': [72], 'studies,': [73], 'examines': [76], 'dilemmas': [79], 'inherent': [80], 'in': [81, 117], 'AV': [82], 'technology,': [83], 'including': [84], 'issues': [85], 'consent,': [87], 'collection,': [89], 'algorithmic': [91], 'bias.': [92], 'Additionally,': [93], 'it': [94], 'delves': [95], 'into': [96], 'regulatory': [98], 'frameworks': [99], 'industry': [101], 'standards': [102], 'aimed': [103], 'at': [104], 'addressing': [105], 'these': [106], 'concerns.': [107], 'By': [108], 'highlighting': [109], 'complexities': [111], 'navigating': [113], 'privacy': [116], 'this': [120], 'research': [121], 'contributes': [122], 'ongoing': [125], 'discourse': [126], 'AI': [129], 'development': [130], 'deployment.': [132]}",2024,"['Internet privacy', 'Computer security', 'Computer science']","The deployment of autonomous vehicles (AVs) powered by artificial intelligence (AI) raises profound ethical questions regarding the balance between safety and privacy. While AI-driven AVs promise to revolutionize transportation by potentially reducing accidents and increasing efficiency, concerns regarding data privacy, liability, and decision-making algorithms persist. This paper explores the ethical considerations surrounding AI-driven AVs, focusing particularly on the delicate equilibrium required to ensure both safety and privacy. Drawing upon existing literature and case studies, the paper examines the ethical dilemmas inherent in AV technology, including issues of consent, data collection, and algorithmic bias. Additionally, it delves into the regulatory frameworks and industry standards aimed at addressing these concerns. By highlighting the complexities of navigating safety and privacy in AI-driven AVs, this research contributes to the ongoing discourse on ethical AI development and deployment."
https://openalex.org/W4401021964,Increasing trust in AI through privacy preservation and model explainability: Federated Learning of Fuzzy Regression Trees,"{'Federated': [0], 'Learning': [1], '(FL)': [2], 'lets': [3], 'multiple': [4], 'data': [5, 17, 99], 'owners': [6], 'collaborate': [7], 'in': [8, 28, 48, 133, 159, 170, 190, 243], 'training': [9], 'a': [10, 21, 68, 113, 195], 'global': [11], 'model': [12], 'without': [13], 'any': [14], 'violation': [15], 'of': [16, 44, 58, 73, 96, 106, 144, 161, 187, 198, 212, 219, 223, 230, 238, 240], 'privacy,': [18], 'which': [19, 78, 134, 171], 'is': [20, 91, 101, 122, 139], 'crucial': [22], 'requirement': [23], 'for': [24, 55, 71, 93, 116], 'enhancing': [25], 'users’': [26], 'trust': [27], 'Artificial': [29], 'Intelligence': [30], '(AI)': [31], 'systems.': [32], 'Despite': [33], 'the': [34, 40, 45, 49, 56, 94, 104, 110, 117, 125, 130, 135, 142, 154, 166, 181, 191, 213, 217, 228, 231, 236], 'significant': [35], 'momentum': [36], 'recently': [37], 'gained': [38], 'by': [39, 202], 'FL': [41, 72, 89, 155], 'paradigm,': [42], 'most': [43], 'existing': [46], 'approaches': [47], 'field': [50], 'neglect': [51], 'another': [52], 'key': [53], 'pillar': [54], 'trustworthiness': [57], 'AI': [59], 'systems,': [60], 'namely': [61], 'explainability.': [62], 'In': [63], 'this': [64], 'paper,': [65], 'we': [66, 226], 'propose': [67], 'novel': [69], 'approach': [70, 127, 156], 'fuzzy': [74], 'regression': [75], 'trees': [76], '(FRTs),': [77], 'are': [79], 'generally': [80], 'acknowledged': [81], 'as': [82, 200], 'highly': [83], 'interpretable': [84], 'by-design': [85], 'models.': [86], 'The': [87, 185, 210], 'proposed': [88, 126, 232], 'procedure': [90], 'designed': [92], 'scenario': [95], 'horizontally': [97], 'partitioned': [98], 'and': [100, 221], 'based': [102, 178], 'on': [103, 141, 180, 207], 'transmission': [105], 'aggregated': [107], 'statistics': [108], 'from': [109], 'clients': [111], 'to': [112, 165, 235], 'central': [114], 'server': [115], 'tree': [118, 136], 'induction': [119, 137], 'procedure.': [120], 'It': [121], 'shown': [123], 'that': [124], 'faithfully': [128], 'approximates': [129], 'ideal': [131], 'case': [132], 'algorithm': [138], 'applied': [140], 'union': [143], 'all': [145], 'local': [146, 167], 'datasets,': [147], 'while': [148], 'still': [149], 'ensuring': [150], 'privacy': [151], 'preservation.': [152], 'Furthermore,': [153], 'brings': [157], 'benefits,': [158], 'terms': [160], 'generalization': [162], 'capability,': [163], 'compared': [164], 'learning': [168], 'setting': [169], 'each': [172], 'participant': [173], 'learns': [174], 'its': [175], 'own': [176], 'FRT': [177, 234], 'only': [179], 'private,': [182], 'local,': [183], 'dataset.': [184], 'adoption': [186], 'linear': [188], 'models': [189], 'leaf': [192], 'nodes': [193], 'ensures': [194], 'competitive': [196], 'level': [197], 'performance,': [199], 'assessed': [201], 'an': [203, 244], 'extensive': [204], 'experimental': [205], 'campaign': [206], 'benchmark': [208], 'datasets.': [209], 'analysis': [211], 'results': [214], 'covers': [215], 'both': [216], 'aspects': [218], 'accuracy': [220], 'interpretability': [222], 'FRT.': [224], 'Finally,': [225], 'discuss': [227], 'application': [229], 'federated': [233], 'task': [237], 'Quality': [239], 'Experience': [241], 'forecasting': [242], 'automotive': [245], 'case-study.': [246]}",2024,"['Computer science', 'Interpretability', 'Benchmark (surveying)', 'Artificial intelligence', 'Machine learning', 'Generalization', 'Key (lock)', 'Tree (set theory)', 'Fuzzy logic', 'Field (mathematics)', 'Data mining', 'Computer security', 'Geography', 'Mathematical analysis', 'Mathematics', 'Pure mathematics', 'Geodesy']","Federated Learning (FL) lets multiple data owners collaborate in training a global model without any violation of data privacy, which is a crucial requirement for enhancing users’ trust in Artificial Intelligence (AI) systems. Despite the significant momentum recently gained by the FL paradigm, most of the existing approaches in the field neglect another key pillar for the trustworthiness of AI systems, namely explainability. In this paper, we propose a novel approach for FL of fuzzy regression trees (FRTs), which are generally acknowledged as highly interpretable by-design models. The proposed FL procedure is designed for the scenario of horizontally partitioned data and is based on the transmission of aggregated statistics from the clients to a central server for the tree induction procedure. It is shown that the proposed approach faithfully approximates the ideal case in which the tree induction algorithm is applied on the union of all local datasets, while still ensuring privacy preservation. Furthermore, the FL approach brings benefits, in terms of generalization capability, compared to the local learning setting in which each participant learns its own FRT based only on the private, local, dataset. The adoption of linear models in the leaf nodes ensures a competitive level of performance, as assessed by an extensive experimental campaign on benchmark datasets. The analysis of the results covers both the aspects of accuracy and interpretability of FRT. Finally, we discuss the application of the proposed federated FRT to the task of Quality of Experience forecasting in an automotive case-study."
https://openalex.org/W4380924666,Ethics and Privacy in Irish Higher Education: A Comprehensive Study of Artificial Intelligence (AI) Tools Implementation at University of Limerick,"{'This': [0], 'research': [1, 55], 'paper': [2], 'presents': [3], 'an': [4], 'insightful': [5], 'investigation': [6], 'into': [7], 'the': [8, 16, 28, 59, 67, 79, 82], 'perceptions': [9], 'and': [10, 49, 61, 85, 108, 130, 133], 'ethical': [11, 62], 'considerations': [12, 63], 'of': [13, 18, 30, 69, 87, 115, 121, 143], 'students': [14, 64, 88, 126], 'regarding': [15, 66], 'use': [17, 68], 'Artificial': [19], 'Intelligence': [20], '(AI)': [21], 'tools': [22, 36, 71], 'in': [23, 32, 45, 72], 'academia,': [24], 'particularly': [25], 'focusing': [26], 'on': [27, 97], 'University': [29], 'Limerick': [31], 'Ireland.': [33], 'Herein,': [34], 'AI': [35, 70, 90, 103], 'like': [37], ""OpenAI's"": [38], 'ChatGPT': [39], 'have': [40, 65], 'emerged': [41], 'as': [42], 'valuable': [43], 'assets': [44], 'promoting': [46], 'interactive': [47], 'learning': [48], 'enhancing': [50], 'student': [51], 'engagement.': [52], 'Thus,': [53], 'this': [54], 'aimed': [56], 'to': [57], 'explore': [58], 'privacy': [60, 99, 123], 'education.': [73], 'Using': [74], 'a': [75, 112], 'quantitative': [76], 'methodological': [77], 'approach,': [78], 'study': [80, 93], 'solicited': [81], 'attitudes,': [83], 'opinions,': [84], 'patterns': [86], 'towards': [89], 'utilities.': [91], 'The': [92], 'revealed': [94], 'intriguing': [95], 'perspectives': [96], 'data': [98], 'concerns': [100], 'associated': [101], 'with': [102], 'tools.': [104], 'Students': [105], 'from': [106, 127], 'technology': [107], 'science-focused': [109], 'schools': [110], 'displayed': [111, 139], 'higher': [113], 'degree': [114], 'concern,': [116], 'suggesting': [117], 'their': [118], 'deeper': [119], 'understanding': [120], 'potential': [122], 'implications.': [124], 'Conversely,': [125], 'arts,': [128], 'humanities,': [129], 'social': [131], 'sciences,': [132], 'law': [134], 'politics': [135], '&amp;': [136], 'public': [137], 'administration': [138], 'slightly': [140], 'lower': [141], 'levels': [142], 'concern.': [144]}",2023,"['Irish', 'The arts', 'Perception', 'Ethical issues', 'Higher education', 'Engineering ethics', 'Psychology', 'Sociology', 'Political science', 'Engineering', 'Neuroscience', 'Linguistics', 'Law', 'Philosophy']","This research paper presents an insightful investigation into the perceptions and ethical considerations of students regarding the use of Artificial Intelligence (AI) tools in academia, particularly focusing on the University of Limerick in Ireland. Herein, AI tools like OpenAI's ChatGPT have emerged as valuable assets in promoting interactive learning and enhancing student engagement. Thus, this research aimed to explore the privacy and ethical considerations students have regarding the use of AI tools in education. Using a quantitative methodological approach, the study solicited the attitudes, opinions, and patterns of students towards AI utilities. The study revealed intriguing perspectives on data privacy concerns associated with AI tools. Students from technology and science-focused schools displayed a higher degree of concern, suggesting their deeper understanding of potential privacy implications. Conversely, students from arts, humanities, and social sciences, and law politics &amp; public administration displayed slightly lower levels of concern."
https://openalex.org/W4398184433,"Revolutionizing AI-Assisted Education with Federated Learning: A Pathway to Distributed, Privacy-Preserving, and Debiased Learning Ecosystems","{'The': [0], 'majority': [1], 'of': [2, 8, 71, 102, 113, 124, 132, 147], 'current': [3], 'research': [4, 126], 'on': [5, 25, 129], 'the': [6, 58, 69, 82, 87, 110, 116, 145], 'application': [7, 70], 'artificial': [9], 'intelligence': [10], '(AI)': [11], 'and': [12, 20, 95, 105, 143, 161], 'machine': [13], 'learning': [14, 73], '(ML)': [15], 'in': [16, 115, 135, 150], 'science,': [17], 'technology,': [18], 'engineering,': [19], 'mathematics': [21], '(STEM)': [22], 'education': [23, 117], 'relies': [24], 'centralized': [26, 37], 'model': [27, 42], 'training': [28, 43], 'architectures.': [29], 'Typically,': [30], 'this': [31, 51, 65], 'involves': [32], 'pooling': [33], 'data': [34, 56], 'at': [35], 'a': [36, 47, 75, 100, 122], 'location': [38], 'alongside': [39], 'an': [40], 'ML': [41, 79], 'module,': [44], 'such': [45], 'as': [46], 'cloud': [48], 'server.': [49], 'However,': [50], 'approach': [52], 'necessitates': [53], 'transferring': [54], 'student': [55], 'across': [57], 'network,': [59], 'leading': [60], 'to': [61, 92, 141], 'privacy': [62], 'concerns.': [63], 'In': [64], 'paper,': [66], 'we': [67, 98, 120], 'explore': [68, 142], 'federated': [72], '(FL),': [74], 'highly': [76], 'recognized': [77], 'distributed': [78], 'technique,': [80], 'within': [81], 'educational': [83, 136, 152], 'ecosystem.': [84], 'We': [85], 'highlight': [86], 'potential': [88], 'benefits': [89], 'FL': [90, 114, 133, 149], 'offers': [91], 'students,': [93], 'classrooms,': [94], 'institutions.': [96], 'Also,': [97], 'identify': [99], 'range': [101], 'technical,': [103], 'logistical,': [104], 'ethical': [106], 'challenges': [107], 'that': [108], 'impede': [109], 'sustainable': [111], 'implementation': [112, 134], 'sector.': [118], 'Finally,': [119], 'discuss': [121], 'series': [123], 'open': [125], 'directions,': [127], 'focusing': [128], 'nuanced': [130], 'aspects': [131], 'contexts.': [137], 'These': [138], 'directions': [139], 'aim': [140], 'address': [144], 'complexities': [146], 'applying': [148], 'varied': [151], 'settings,': [153], 'ensuring': [154], 'its': [155], 'deployment': [156], 'is': [157], 'technologically': [158], 'sound,': [159], 'beneficial,': [160], 'equitable': [162], 'for': [163], 'all': [164], 'stakeholders': [165], 'involved.': [166]}",2024,"['Software deployment', 'Pooling', 'Computer science', 'Cloud computing', 'Knowledge management', 'Data science', 'Artificial intelligence', 'Software engineering', 'Operating system']","The majority of current research on the application of artificial intelligence (AI) and machine learning (ML) in science, technology, engineering, and mathematics (STEM) education relies on centralized model training architectures. Typically, this involves pooling data at a centralized location alongside an ML model training module, such as a cloud server. However, this approach necessitates transferring student data across the network, leading to privacy concerns. In this paper, we explore the application of federated learning (FL), a highly recognized distributed ML technique, within the educational ecosystem. We highlight the potential benefits FL offers to students, classrooms, and institutions. Also, we identify a range of technical, logistical, and ethical challenges that impede the sustainable implementation of FL in the education sector. Finally, we discuss a series of open research directions, focusing on nuanced aspects of FL implementation in educational contexts. These directions aim to explore and address the complexities of applying FL in varied educational settings, ensuring its deployment is technologically sound, beneficial, and equitable for all stakeholders involved."
https://openalex.org/W4402806784,Ethical AI in Healthcare: Balancing Innovation with Privacy and Compliance,"{'Within': [0], 'the': [1, 30, 56, 64, 68, 88, 104, 118], 'dynamic': [2], 'and': [3, 14, 25, 49, 78, 84, 121, 133, 144, 151], 'ever-changing': [4], 'healthcare': [5, 37, 65, 94], 'industry,': [6], 'Artificial': [7], 'Intelligence': [8], '(AI)': [9, 35, 62, 136], 'emerges': [10], 'as': [11, 127], 'a': [12, 72], 'powerful': [13], 'revolutionary': [15], 'concept': [16], 'capable': [17], 'of': [18, 32, 59, 70, 90, 106, 123], 'transforming': [19], 'patient': [20], 'care,': [21], 'optimising': [22], 'operational': [23], 'processes,': [24], 'improving': [26], 'clinical': [27], 'decision-making.': [28], 'Nevertheless,': [29], 'incorporation': [31], 'artificial': [33, 60, 91, 134], 'intelligence': [34, 61, 92, 135], 'into': [36], 'systems': [38], 'gives': [39], 'rise': [40], 'to': [41, 47, 51, 97, 102, 140, 148], 'substantial': [42], 'ethical': [43, 57], 'considerations,': [44], 'especially': [45], 'pertaining': [46], 'privacy': [48, 82], 'adherence': [50], 'regulations.': [52], 'This': [53, 108], 'work': [54], 'examines': [55], 'aspects': [58], 'in': [63, 93], 'sector,': [66], 'highlighting': [67], 'importance': [69], 'maintaining': [71], 'harmonious': [73], 'equilibrium': [74], 'between': [75], 'technical': [76], 'advancement': [77], 'strict': [79], 'compliance': [80, 112], 'with': [81, 113], 'regulations': [83], 'legal': [85, 125], 'obligations.': [86], 'Moreover,': [87], 'use': [89], 'must': [95], 'adhere': [96], 'legislative': [98], 'frameworks': [99], 'specifically': [100], 'created': [101], 'safeguard': [103], 'rights': [105], 'humans.': [107], 'encompasses': [109], 'not': [110], 'just': [111], 'current': [114], 'rules': [115], 'but': [116], 'also': [117], 'proactive': [119], 'identification': [120], 'resolution': [122], 'developing': [124], 'norms': [126], 'AI': [128], 'technology': [129], 'advances.': [130], 'Healthcare': [131], 'practitioners': [132], 'developers': [137], 'should': [138], 'cooperate': [139], 'create': [141], 'explicit': [142], 'standards': [143], 'procedures': [145], 'that': [146], 'conform': [147], 'existing': [149], 'legislation': [150], 'expected': [152], 'future': [153], 'rules.': [154]}",2024,"['Compliance (psychology)', 'Health care', 'Internet privacy', 'Business', 'Information privacy', 'Public relations', 'Political science', 'Psychology', 'Computer science', 'Law', 'Social psychology']","Within the dynamic and ever-changing healthcare industry, Artificial Intelligence (AI) emerges as a powerful and revolutionary concept capable of transforming patient care, optimising operational processes, and improving clinical decision-making. Nevertheless, the incorporation of artificial intelligence (AI) into healthcare systems gives rise to substantial ethical considerations, especially pertaining to privacy and adherence to regulations. This work examines the ethical aspects of artificial intelligence (AI) in the healthcare sector, highlighting the importance of maintaining a harmonious equilibrium between technical advancement and strict compliance with privacy regulations and legal obligations. Moreover, the use of artificial intelligence in healthcare must adhere to legislative frameworks specifically created to safeguard the rights of humans. This encompasses not just compliance with current rules but also the proactive identification and resolution of developing legal norms as AI technology advances. Healthcare practitioners and artificial intelligence (AI) developers should cooperate to create explicit standards and procedures that conform to existing legislation and expected future rules."
https://openalex.org/W4386496702,Intelligent Monitoring System with Privacy Preservation Based on Edge AI,"{'Currently,': [0], 'the': [1, 20, 47, 63, 118, 122, 136], 'trend': [2], 'of': [3, 25, 65, 82, 139, 182, 189], 'elderly': [4, 30], 'people': [5, 31], 'living': [6, 32], 'alone': [7, 33], 'is': [8], 'rising': [9], 'due': [10], 'to': [11, 55, 59, 62, 76], 'rapid': [12], 'aging': [13], 'and': [14, 23, 46, 68, 79, 110, 121, 151, 185], 'shifts': [15], 'in': [16, 172], 'family': [17], 'structures.': [18], 'Accordingly,': [19], 'efficient': [21, 137], 'implementation': [22], 'management': [24], 'monitoring': [26, 57, 95], 'systems': [27, 38], 'tailored': [28], 'for': [29, 135], 'have': [34], 'become': [35], 'paramount.': [36], 'Monitoring': [37], 'are': [39, 50, 74], 'generally': [40], 'implemented': [41, 153], 'based': [42, 100], 'on': [43, 52, 71, 101, 154, 163], 'multiple': [44, 66], 'sensors,': [45], 'collected': [48], 'data': [49, 140], 'processed': [51], 'a': [53, 69, 80, 155, 173, 179, 186], 'server': [54, 123], 'provide': [56], 'services': [58], 'users.': [60], 'Due': [61], 'use': [64], 'sensors': [67], 'reliance': [70], 'servers,': [72], 'there': [73], 'limitations': [75], 'economical': [77], 'maintenance': [78], 'risk': [81], 'highly': [83], 'personal': [84], 'information': [85], 'being': [86], 'leaked.': [87], 'In': [88], 'this': [89], 'paper,': [90], 'we': [91, 166], 'propose': [92], 'an': [93, 125], 'intelligent': [94], 'system': [96, 106], 'with': [97, 124, 148], 'privacy': [98], 'preservation': [99], 'edge': [102, 126, 131, 143], 'AI.': [103], 'The': [104, 142], 'proposed': [105], 'achieves': [107], 'cost': [108], 'competitiveness': [109], 'ensures': [111], 'high': [112], 'security': [113], 'by': [114], 'blocking': [115], 'communication': [116], 'between': [117], 'camera': [119], 'module': [120, 145], 'AI': [127, 144], 'module.': [128], 'Additionally,': [129], 'applying': [130], 'computing': [132], 'technology': [133, 177], 'allows': [134], 'processing': [138], 'traffic.': [141], 'was': [146, 152], 'designed': [147], 'Verilog': [149], 'HDL': [150], 'field-programmable': [156], 'gate': [157, 180], 'array': [158], '(FPGA).': [159], 'Through': [160], 'experiments': [161], 'conducted': [162], '6144': [164], 'frames,': [165], 'achieved': [167], '95.34%': [168], 'accuracy.': [169], 'Synthesis': [170], 'results': [171], '180': [174], 'nm': [175], 'CMOS': [176], 'indicated': [178], 'count': [181], '1516': [183], 'K': [184], 'power': [187], 'consumption': [188], '344.44': [190], 'mW.': [191]}",2023,"['Computer science', 'Verilog', 'Field-programmable gate array', 'Enhanced Data Rates for GSM Evolution', 'Embedded system', 'Server', 'Edge computing', 'Power consumption', 'Field (mathematics)', 'Gate array', 'Real-time computing', 'Computer hardware', 'Computer security', 'Power (physics)', 'Computer network', 'Artificial intelligence', 'Quantum mechanics', 'Mathematics', 'Pure mathematics', 'Physics']","Currently, the trend of elderly people living alone is rising due to rapid aging and shifts in family structures. Accordingly, the efficient implementation and management of monitoring systems tailored for elderly people living alone have become paramount. Monitoring systems are generally implemented based on multiple sensors, and the collected data are processed on a server to provide monitoring services to users. Due to the use of multiple sensors and a reliance on servers, there are limitations to economical maintenance and a risk of highly personal information being leaked. In this paper, we propose an intelligent monitoring system with privacy preservation based on edge AI. The proposed system achieves cost competitiveness and ensures high security by blocking communication between the camera module and the server with an edge AI module. Additionally, applying edge computing technology allows for the efficient processing of data traffic. The edge AI module was designed with Verilog HDL and was implemented on a field-programmable gate array (FPGA). Through experiments conducted on 6144 frames, we achieved 95.34% accuracy. Synthesis results in a 180 nm CMOS technology indicated a gate count of 1516 K and a power consumption of 344.44 mW."
https://openalex.org/W2750721083,Smile for the Camera: Privacy and Policy Implications of Emotion AI,"{'The': [0], 'introduction': [1], 'of': [2, 19, 41, 46, 58, 106, 124, 154, 176, 235], 'artificial': [3], 'intelligence': [4], '(AI)': [5], 'on': [6, 31, 81, 136, 151], 'visual': [7], 'images': [8], 'for': [9, 94, 194, 240, 251], 'emotional': [10, 49, 142], 'analysis': [11], 'obliterates': [12], 'the': [13, 39, 88, 137, 173, 177, 182, 186, 215, 229, 233], 'natural': [14], 'subjectivity': [15], 'and': [16, 35, 50, 91, 112, 131, 198, 206, 219, 243], 'contextual': [17], 'dependence': [18], 'our': [20, 32, 48, 152, 169], 'facial': [21], 'displays.': [22], 'Emotion': [23], 'AI': [24, 96, 118, 143, 247], 'places': [25], 'itself': [26], 'as': [27, 63, 97, 245], 'an': [28, 98], 'algorithmic': [29, 121], 'lens': [30], 'digital': [33], 'artifacts': [34], 'real-time': [36], 'interactions,': [37], 'creating': [38], 'illusion': [40], 'a': [42, 55, 104], 'new,': [43], 'objective': [44], 'class': [45], 'data:': [47], 'mental': [51], 'states.': [52], 'Building': [53], 'upon': [54], 'rich': [56], 'network': [57], 'existing': [59], 'public': [60], 'photographs--as': [61], 'well': [62], 'fresh': [64], 'feeds': [65], 'from': [66, 119], 'surveillance': [67], 'footage': [68], 'or': [69, 79, 145, 165], 'smart': [70], 'phone': [71], 'cameras--these': [72], 'emotion': [73, 95, 117, 195, 246], 'algorithms': [74], 'require': [75], 'no': [76], 'additional': [77], 'infrastructure': [78], 'improvements': [80], 'image': [82], 'quality.': [83], 'In': [84], 'order': [85], 'to': [86, 163, 223], 'examine': [87, 158, 214], 'potential': [89, 159], 'policy': [90, 129, 161], 'legal': [92], 'remedies': [93, 162], 'emerging': [99], 'technology,': [100], 'we': [101, 157, 238], 'first': [102], 'establish': [103], 'framework': [105, 153], 'actors,': [107], 'collection': [108], 'motivations,': [109], 'time': [110], 'scales,': [111], 'space': [113], 'considerations': [114], 'that': [115, 140], 'differentiates': [116], 'other': [120], 'lenses.': [122], 'Each': [123], 'these': [125, 236], 'elements': [126], 'influences': [127], 'available': [128, 160], 'remedies,': [130], 'should': [132], 'shape': [133], 'continuing': [134], 'discussions': [135], 'antecedent': [138], 'conditions': [139], 'make': [141], 'acceptable': [144], 'not': [146], 'in': [147, 181, 185, 204, 231], 'particular': [148], 'contexts.': [149], 'Based': [150], 'unique': [155], 'elements,': [156], 'prevent': [164], 'remediate': [166], 'harm.': [167], 'Specifically,': [168], 'paper': [170], 'looks': [171], 'toward': [172], 'regulatory': [174], 'role': [175], 'Federal': [178], 'Trade': [179], 'Commission': [180], 'US,': [183], 'gaps': [184], ""EU's"": [187], 'General': [188], 'Data': [189], 'Protection': [190], 'Regulation': [191], '(GDPR)': [192], 'allowing': [193], 'data': [196], 'collection,': [197], 'precedent': [199], 'set': [200, 209], 'by': [201, 210], 'polygraph': [202], 'technologies': [203], 'evidentiary': [205], 'use': [207], 'restrictions': [208], 'law.': [211], 'We': [212], 'also': [213, 224], 'way': [216], 'social': [217], 'norms': [218], 'adaptations': [220], 'could': [221], 'grow': [222], 'modulate': [225], 'broader': [226], 'use.': [227], 'Given': [228], 'challenges': [230], 'controlling': [232], 'flow': [234], 'data,': [237], 'call': [239], 'further': [241], 'research': [242], 'attention': [244], 'technology': [248], 'remains': [249], 'poised': [250], 'adoption.': [252]}",2017,"['Data Protection Act 1998', 'Set (abstract data type)', 'General Data Protection Regulation', 'Harm', 'Quality (philosophy)', 'Internet privacy', 'Legal aspects of computing', 'Computer science', 'Psychology', 'Social psychology', 'Computer security', 'The Internet', 'Epistemology', 'Philosophy', 'World Wide Web', 'Programming language']","The introduction of artificial intelligence (AI) on visual images for emotional analysis obliterates the natural subjectivity and contextual dependence of our facial displays. Emotion AI places itself as an algorithmic lens on our digital artifacts and real-time interactions, creating the illusion of a new, objective class of data: our emotional and mental states. Building upon a rich network of existing public photographs--as well as fresh feeds from surveillance footage or smart phone cameras--these emotion algorithms require no additional infrastructure or improvements on image quality. In order to examine the potential policy and legal remedies for emotion AI as an emerging technology, we first establish a framework of actors, collection motivations, time scales, and space considerations that differentiates emotion AI from other algorithmic lenses. Each of these elements influences available policy remedies, and should shape continuing discussions on the antecedent conditions that make emotional AI acceptable or not in particular contexts. Based on our framework of unique elements, we examine potential available policy remedies to prevent or remediate harm. Specifically, our paper looks toward the regulatory role of the Federal Trade Commission in the US, gaps in the EU's General Data Protection Regulation (GDPR) allowing for emotion data collection, and precedent set by polygraph technologies in evidentiary and use restrictions set by law. We also examine the way social norms and adaptations could grow to also modulate broader use. Given the challenges in controlling the flow of these data, we call for further research and attention as emotion AI technology remains poised for adoption."
https://openalex.org/W3191985045,The ‘Brussels Effect’ of the EU’s ‘AI Act’ on Data Privacy Outside Europe,"{'The': [0, 119], 'European': [1], 'Commission’s': [2], 'publication': [3], 'of': [4, 30, 59, 99, 116, 217], 'a': [5, 8, 23, 52, 124], 'proposal': [6], 'for': [7, 41, 144, 154, 184, 214], 'Regulation': [9], 'on': [10, 55], 'Artificial': [11], 'Intelligence': [12], '(also': [13], 'described': [14], 'as': [15], 'an': [16, 79], '‘AI': [17], 'Act’)': [18], 'is': [19, 132, 138], 'likely': [20, 139], 'to': [21, 68, 77, 87, 97, 140], 'become': [22], 'pivotal': [24], 'moment': [25], 'in': [26, 81, 111, 150], 'the': [27, 56, 60, 82, 92, 114, 117, 135, 151, 179, 207], 'global': [28, 39], 'regulation': [29, 216], 'artificial': [31], 'intelligence,': [32], 'but': [33, 129, 153], 'it': [34, 159], 'will': [35, 122, 160, 178, 191, 206], 'also': [36, 123], 'have': [37, 78, 211], 'major': [38], 'implications': [40, 213], 'privacy': [42, 127, 146, 185], 'and': [43, 107, 147, 189, 204], 'data': [44, 126, 145], 'protection.\r\n\r\nMany': [45], 'businesses': [46, 85, 156, 192], 'located': [47], 'outside': [48, 113, 157, 193, 219], 'Europe': [49, 158, 194], 'are': [50, 168, 201], 'keeping': [51], 'wary': [53], 'eye': [54], 'GDPR': [57], 'because': [58, 71], 'risks': [61], 'that': [62, 91, 103, 131, 172], 'its': [63], 'extra-territorial': [64], 'application': [65], 'might': [66, 73], 'apply': [67, 96], 'them,': [69], 'or': [70], 'they': [72], 'even': [74], 'be': [75, 88, 125, 141, 161, 182], 'held': [76], 'establishment': [80], 'EU.': [83], 'Such': [84], 'need': [86], 'equally': [89], 'concerned': [90], 'AI': [93, 120, 180, 209, 218], 'Act': [94, 121, 181, 210], 'may': [95, 108], 'any': [98], 'their': [100], 'AI-related': [101], 'activities': [102], 'can': [104], 'affect': [105], 'individuals,': [106], 'do': [109], 'so': [110], 'situations': [112], 'scope': [115], 'GDPR.': [118, 136], 'regulation,': [128], 'one': [130], 'different': [133], 'from': [134], 'This': [137], 'good': [142], 'news': [143], 'human': [148], 'rights': [149], 'EU,': [152], 'some': [155], 'another': [162], 'significant': [163], 'regulatory': [164], 'obligation': [165], 'requiring': [166], 'consideration.\r\n\r\nThere': [167], 'four': [169], 'main': [170], 'questions': [171], 'this': [173], 'article': [174], 'considers:': [175], '(i)': [176], 'why': [177, 190], 'important': [183], 'protection?;': [186], '(ii)': [187], 'how': [188], 'acquire': [195], 'obligations': [196], 'under': [197], 'it?;': [198], '(iii)': [199], 'what': [200], 'those': [202], 'obligations?;': [203], '(iv)': [205], 'EU’s': [208], 'broader': [212], 'local': [215], 'Europe?': [220]}",2021,"['General Data Protection Regulation', 'Data Protection Act 1998', 'Obligation', 'Data Protection Directive', 'Scope (computer science)', 'European commission', 'Information privacy', 'European union', 'Business', 'Political science', 'Privacy law', 'Privacy policy', 'FTC Fair Information Practice', 'Information privacy law', 'Commission', 'Law and economics', 'Internet privacy', 'Law', 'European Union law', 'International trade', 'Economics', 'Computer science', 'Programming language']","The European Commission’s publication of a proposal for a Regulation on Artificial Intelligence (also described as an ‘AI Act’) is likely to become a pivotal moment in the global regulation of artificial intelligence, but it will also have major global implications for privacy and data protection.

Many businesses located outside Europe are keeping a wary eye on the GDPR because of the risks that its extra-territorial application might apply to them, or because they might even be held to have an establishment in the EU. Such businesses need to be equally concerned that the AI Act may apply to any of their AI-related activities that can affect individuals, and may do so in situations outside the scope of the GDPR. The AI Act will also a be data privacy regulation, but one that is different from the GDPR. This is likely to be good news for data privacy and human rights in the EU, but for some businesses outside Europe it will be another significant regulatory obligation requiring consideration.

There are four main questions that this article considers: (i) why will the AI Act be important for privacy protection?; (ii) how and why will businesses outside Europe acquire obligations under it?; (iii) what are those obligations?; and (iv) will the EU’s AI Act have broader implications for local regulation of AI outside Europe?"
https://openalex.org/W4404864108,Privacy‐preserving federated data access and federated learning: Improved data sharing and <scp>AI</scp> model development in transfusion medicine,"{'Abstract': [0], 'Background': [1], 'Health': [2], 'data': [3, 5, 20, 40, 47, 72, 144, 177, 184, 228], 'comprise': [4], 'from': [6, 68, 145], 'different': [7], 'aspects': [8], 'of': [9], 'healthcare': [10, 25, 36, 249], 'including': [11], 'administrative,': [12], 'digital': [13], 'health,': [14], 'and': [15, 23, 29, 42, 50, 79, 87, 94, 100, 116, 153, 166, 180, 186, 198, 240, 248], 'research‐oriented': [16], 'data.': [17], 'Together,': [18], 'health': [19], 'contribute': [21], 'to': [22, 66, 213, 234], 'inform': [24], 'operations,': [26], 'patient': [27, 143, 246], 'care,': [28], 'research.': [30], 'Integrating': [31], 'artificial': [32], 'intelligence': [33], '(AI)': [34], 'into': [35], 'requires': [37], 'understanding': [38], 'these': [39, 61], 'infrastructures': [41], 'addressing': [43], 'challenges': [44, 62, 174], 'such': [45, 175], 'as': [46, 176], 'availability,': [48], 'privacy,': [49, 229], 'governance.': [51], 'Federated': [52], 'learning': [53], '(FL),': [54], 'a': [55, 210], 'decentralized': [56], 'AI': [57, 214], 'training': [58], 'approach,': [59], 'addresses': [60], 'by': [63, 110, 125, 141], 'allowing': [64], 'models': [65, 120, 190], 'learn': [67], 'diverse': [69, 123, 183, 224], 'datasets': [70, 124, 225], 'without': [71], 'leaving': [73], 'its': [74, 89, 170], 'source,': [75], 'thus': [76], 'ensuring': [77, 187], 'privacy': [78], 'security': [80], 'are': [81, 201], 'maintained.': [82], 'This': [83], 'report': [84], 'introduces': [85], 'FL': [86, 102, 126, 172, 205, 208, 230], 'discusses': [88], 'potential': [90, 233], 'in': [91, 107, 130, 216, 219], 'transfusion': [92, 108, 133, 220], 'medicine': [93, 109], 'blood': [95, 132], 'supply': [96], 'chain': [97], 'management.': [98], 'Methods': [99], 'Discussion': [101], 'can': [103, 127, 138, 158], 'offer': [104], 'significant': [105], 'benefits': [106], 'enhancing': [111], 'predictive': [112], 'analytics,': [113], 'personalized': [114, 238], 'medicine,': [115], 'operational': [117], 'efficiency.': [118, 250], 'Predictive': [119], 'trained': [121], 'on': [122], 'improve': [128], 'accuracy': [129], 'forecasting': [131, 165], 'demands.': [134], 'Personalized': [135], 'treatment': [136], 'plans': [137], 'be': [139, 160], 'refined': [140], 'aggregating': [142], 'multiple': [146], 'institutions': [147], 'using': [148], 'FL,': [149], 'reducing': [150], 'adverse': [151], 'reactions': [152], 'improving': [154, 245], 'outcomes.': [155], 'Operational': [156], 'efficiency': [157], 'also': [159], 'achieved': [161], 'through': [162], 'precise': [163], 'demand': [164], 'optimized': [167], 'logistics.': [168], 'Despite': [169], 'advantages,': [171], 'faces': [173], 'standardization,': [178], 'governance,': [179], 'bias.': [181], 'Harmonizing': [182], 'sources': [185], 'fair,': [188], 'unbiased': [189], 'require': [191], 'advanced': [192], 'analytical': [193], 'solutions.': [194], 'Robust': [195], 'IT': [196], 'infrastructure': [197], 'specialized': [199], 'expertise': [200], 'needed': [202], 'for': [203], 'successful': [204], 'implementation.': [206], 'Conclusion': [207], 'represents': [209], 'transformative': [211], 'approach': [212], 'development': [215], 'healthcare,': [217], 'particularly': [218], 'medicine.': [221], 'By': [222], 'leveraging': [223], 'while': [226], 'maintaining': [227], 'has': [231], 'the': [232], 'enhance': [235], 'predictions,': [236], 'support': [237], 'treatments,': [239], 'optimize': [241], 'resource': [242], 'management,': [243], 'ultimately': [244], 'care': [247]}",2024,"['Health care', 'Computer science', 'Big data', 'Data governance', 'Data sharing', 'Standardization', 'Transformative learning', 'Information privacy', 'Corporate governance', 'Personalized medicine', 'Precision medicine', 'Resource allocation', 'Data management', 'Data science', 'Data mining', 'Business', 'Computer security', 'Data quality', 'Medicine', 'Operations management', 'Engineering', 'Finance', 'Genetics', 'Metric (unit)', 'Operating system', 'Psychology', 'Pedagogy', 'Economic growth', 'Computer network', 'Pathology', 'Biology', 'Economics', 'Alternative medicine']","Abstract Background Health data comprise data from different aspects of healthcare including administrative, digital health, and research‐oriented data. Together, health data contribute to and inform healthcare operations, patient care, and research. Integrating artificial intelligence (AI) into healthcare requires understanding these data infrastructures and addressing challenges such as data availability, privacy, and governance. Federated learning (FL), a decentralized AI training approach, addresses these challenges by allowing models to learn from diverse datasets without data leaving its source, thus ensuring privacy and security are maintained. This report introduces FL and discusses its potential in transfusion medicine and blood supply chain management. Methods and Discussion FL can offer significant benefits in transfusion medicine by enhancing predictive analytics, personalized medicine, and operational efficiency. Predictive models trained on diverse datasets by FL can improve accuracy in forecasting blood transfusion demands. Personalized treatment plans can be refined by aggregating patient data from multiple institutions using FL, reducing adverse reactions and improving outcomes. Operational efficiency can also be achieved through precise demand forecasting and optimized logistics. Despite its advantages, FL faces challenges such as data standardization, governance, and bias. Harmonizing diverse data sources and ensuring fair, unbiased models require advanced analytical solutions. Robust IT infrastructure and specialized expertise are needed for successful FL implementation. Conclusion FL represents a transformative approach to AI development in healthcare, particularly in transfusion medicine. By leveraging diverse datasets while maintaining data privacy, FL has the potential to enhance predictions, support personalized treatments, and optimize resource management, ultimately improving patient care and healthcare efficiency."
https://openalex.org/W4404223955,Privacy-preserving explainable AI: a survey,"{'Abstract': [0], 'As': [1], 'the': [2, 11, 41, 72, 81, 92, 119], 'adoption': [3], 'of': [4, 23, 63, 74, 94], 'explainable': [5], 'AI': [6, 26], '(XAI)': [7], 'continues': [8], 'to': [9, 13, 56, 113, 129], 'expand,': [10], 'urgency': [12], 'address': [14], 'its': [15], 'privacy': [16, 27, 46, 75, 95], 'implications': [17], 'intensifies.': [18], 'Despite': [19], 'a': [20, 60, 67, 115], 'growing': [21], 'corpus': [22], 'research': [24, 64, 104, 120], 'in': [25, 107], 'and': [28, 51, 77, 102, 122, 150], 'explainability,': [29], 'there': [30], 'is': [31], 'little': [32], 'attention': [33], 'on': [34, 48, 80], 'privacy-preserving': [35], 'model': [36, 49], 'explanations.': [37, 83], 'This': [38, 84, 110], 'article': [39], 'presents': [40], 'first': [42], 'thorough': [43, 61], 'survey': [44, 111], 'about': [45], 'attacks': [47, 76], 'explanations': [50], 'their': [52], 'countermeasures.': [53], 'Our': [54], 'contribution': [55], 'this': [57, 130], 'field': [58], 'comprises': [59], 'analysis': [62], 'papers': [65], 'with': [66, 148], 'connected': [68], 'taxonomy': [69], 'that': [70], 'facilitates': [71], 'categorization': [73], 'countermeasures': [78], 'based': [79], 'targeted': [82], 'work': [85], 'also': [86], 'includes': [87], 'an': [88, 139], 'initial': [89], 'investigation': [90], 'into': [91], 'causes': [93], 'leaks.': [96], 'Finally,': [97], 'we': [98, 136], 'discuss': [99], 'unresolved': [100], 'issues': [101], 'prospective': [103], 'directions': [105], 'uncovered': [106], 'our': [108], 'analysis.': [109], 'aims': [112], 'be': [114, 145], 'valuable': [116], 'resource': [117, 141], 'for': [118, 126], 'community': [121], 'offers': [123], 'clear': [124], 'insights': [125], 'those': [127], 'new': [128, 149], 'domain.': [131], 'To': [132], 'support': [133], 'ongoing': [134], 'research,': [135], 'have': [137], 'established': [138], 'online': [140], 'repository,': [142], 'which': [143], 'will': [144], 'continuously': [146], 'updated': [147], 'relevant': [151], 'findings.': [152]}",2024,"['Computer science', 'Internet privacy']","Abstract As the adoption of explainable AI (XAI) continues to expand, the urgency to address its privacy implications intensifies. Despite a growing corpus of research in AI privacy and explainability, there is little attention on privacy-preserving model explanations. This article presents the first thorough survey about privacy attacks on model explanations and their countermeasures. Our contribution to this field comprises a thorough analysis of research papers with a connected taxonomy that facilitates the categorization of privacy attacks and countermeasures based on the targeted explanations. This work also includes an initial investigation into the causes of privacy leaks. Finally, we discuss unresolved issues and prospective research directions uncovered in our analysis. This survey aims to be a valuable resource for the research community and offers clear insights for those new to this domain. To support ongoing research, we have established an online resource repository, which will be continuously updated with new and relevant findings."
https://openalex.org/W4396985366,Big data and AI in employment: The dual challenge of workforce replacement and protecting customer privacy in biometric data usage,"{'The': [0, 122, 223], 'integration': [1], 'of': [2, 50, 112, 117, 127, 145, 178, 225, 258, 267, 274, 312, 322, 339], 'Artificial': [3], 'Intelligence': [4], '(AI)': [5], 'and': [6, 31, 46, 60, 72, 83, 95, 114, 125, 135, 170, 208, 214, 242, 260, 276, 292, 303, 315, 324, 346], 'Big': [7, 316], 'Data': [8, 234, 317], 'is': [9, 157, 187, 253], 'ushering': [10], 'in': [11, 147, 162, 190, 212, 238, 249, 255, 269], 'profound': [12], 'transformations': [13], 'across': [14, 78], 'various': [15], 'industries,': [16], 'with': [17, 280], 'biometric': [18, 51, 128, 261, 290], 'data': [19, 52, 119, 129, 227, 291], 'usage': [20], 'standing': [21], 'out': [22], 'due': [23], 'to': [24, 88, 103, 132, 139, 159, 219, 288], 'its': [25], 'deep': [26], 'implications': [27], 'for': [28, 184, 331], 'workforce': [29], 'dynamics': [30], 'customer': [32], 'privacy.': [33, 141, 294, 325], 'This': [34, 182, 202], 'review': [35], 'article': [36, 203, 307], 'critically': [37, 327], 'examines': [38], 'the': [39, 47, 56, 110, 115, 118, 143, 176, 206, 232, 239, 243, 250, 256, 265, 271, 281, 320, 329, 337], 'dual': [40], 'challenges': [41], 'presented': [42], 'by': [43, 154], 'AI-driven': [44], 'automation': [45], 'extensive': [48], 'use': [49, 144, 273], 'analytics,': [53], 'focusing': [54], 'on': [55], 'resultant': [57], 'job': [58, 180], 'displacement': [59], 'escalating': [61], 'privacy': [62, 111], 'concerns.': [63], 'Biometric': [64], 'technologies': [65, 86], 'such': [66, 230], 'as': [67, 231], 'facial': [68], 'recognition,': [69], 'fingerprint': [70], 'identification,': [71], 'voice': [73], 'analysis': [74, 126], 'are': [75, 217, 318], 'increasingly': [76], 'deployed': [77], 'sectors': [79, 191], 'including': [80], 'finance,': [81], 'healthcare,': [82], 'retail.': [84], 'These': [85], 'aim': [87], 'enhance': [89], 'security': [90, 116], 'measures,': [91], 'improve': [92], 'user': [93], 'experience,': [94], 'optimize': [96], 'operational': [97], 'efficiencies.': [98], 'However,': [99], 'they': [100], 'also': [101, 174, 204], 'bring': [102], 'light': [104], 'substantial': [105], 'ethical': [106, 272], 'dilemmas,': [107], 'particularly': [108], 'concerning': [109], 'individuals': [113], 'being': [120], 'collected.': [121], 'pervasive': [123], 'collection': [124], 'can': [130, 167], 'lead': [131], 'invasive': [133], 'surveillance': [134], 'profiling,': [136], 'exacerbating': [137], 'risks': [138], 'personal': [140], 'Moreover,': [142], 'AI': [146, 166, 259, 275, 314], 'automating': [148], 'tasks': [149], 'that': [150, 192, 216, 284, 335], 'were': [151], 'traditionally': [152], 'performed': [153], 'human': [155], 'workers': [156], 'leading': [158], 'significant': [160], 'shifts': [161], 'employment': [163, 347], 'structures.': [164], 'While': [165], 'increase': [168], 'efficiency': [169], 'reduce': [171], 'costs,': [172], 'it': [173], 'raises': [175], 'specter': [177], 'widespread': [179], 'displacement.': [181], 'potential': [183], 'automation-driven': [185], 'unemployment': [186], 'especially': [188], 'pronounced': [189], 'heavily': [193], 'utilize': [194], 'routine,': [195], 'repetitive': [196], 'tasks,': [197], 'posing': [198], 'critical': [199], 'socio-economic': [200], 'challenges.': [201, 222], 'explores': [205], 'regulatory': [207], 'technological': [209, 282, 340], 'frameworks': [210], 'currently': [211], 'place,': [213], 'those': [215], 'needed': [218], 'address': [220], 'these': [221], 'effectiveness': [224], 'existing': [226], 'protection': [228], 'laws,': [229], 'General': [233], 'Protection': [235], 'Regulation': [236], '(GDPR)': [237], 'European': [240], 'Union,': [241], 'California': [244], 'Consumer': [245], 'Privacy': [246], 'Act': [247], '(CCPA)': [248], 'United': [251], 'States,': [252], 'assessed': [254], 'context': [257], 'data.': [262], 'We': [263], 'discuss': [264], 'role': [266], 'policy': [268], 'shaping': [270], 'protecting': [277], 'workers,': [278], 'along': [279], 'safeguards': [283], 'could': [285], 'be': [286], 'implemented': [287], 'secure': [289], 'ensure': [293], 'By': [295], 'synthesizing': [296], 'insights': [297], 'from': [298], 'recent': [299], 'research,': [300], 'case': [301], 'studies,': [302], 'expert': [304], 'analyses,': [305], 'this': [306], 'provides': [308], 'a': [309, 332], 'comprehensive': [310], 'overview': [311], 'how': [313], 'reshaping': [319], 'landscape': [321], 'work': [323], 'It': [326], 'discusses': [328], 'need': [330], 'balanced': [333], 'approach': [334], 'harnesses': [336], 'benefits': [338], 'advancements': [341], 'while': [342], 'safeguarding': [343], 'individual': [344], 'rights': [345], 'security.': [348]}",2024,"['Biometrics', 'Workforce', 'Dual (grammatical number)', 'Internet privacy', 'Business', 'Big data', 'Biometric data', 'Computer security', 'Computer science', 'Data science', 'Data mining', 'Political science', 'Law', 'Literature', 'Art']","The integration of Artificial Intelligence (AI) and Big Data is ushering in profound transformations across various industries, with biometric data usage standing out due to its deep implications for workforce dynamics and customer privacy. This review article critically examines the dual challenges presented by AI-driven automation and the extensive use of biometric data analytics, focusing on the resultant job displacement and escalating privacy concerns. Biometric technologies such as facial recognition, fingerprint identification, and voice analysis are increasingly deployed across sectors including finance, healthcare, and retail. These technologies aim to enhance security measures, improve user experience, and optimize operational efficiencies. However, they also bring to light substantial ethical dilemmas, particularly concerning the privacy of individuals and the security of the data being collected. The pervasive collection and analysis of biometric data can lead to invasive surveillance and profiling, exacerbating risks to personal privacy. Moreover, the use of AI in automating tasks that were traditionally performed by human workers is leading to significant shifts in employment structures. While AI can increase efficiency and reduce costs, it also raises the specter of widespread job displacement. This potential for automation-driven unemployment is especially pronounced in sectors that heavily utilize routine, repetitive tasks, posing critical socio-economic challenges. This article also explores the regulatory and technological frameworks currently in place, and those that are needed to address these challenges. The effectiveness of existing data protection laws, such as the General Data Protection Regulation (GDPR) in the European Union, and the California Consumer Privacy Act (CCPA) in the United States, is assessed in the context of AI and biometric data. We discuss the role of policy in shaping the ethical use of AI and protecting workers, along with the technological safeguards that could be implemented to secure biometric data and ensure privacy. By synthesizing insights from recent research, case studies, and expert analyses, this article provides a comprehensive overview of how AI and Big Data are reshaping the landscape of work and privacy. It critically discusses the need for a balanced approach that harnesses the benefits of technological advancements while safeguarding individual rights and employment security."
https://openalex.org/W4319323493,"Private, fair and accurate: Training large-scale, privacy-preserving AI models in medical imaging","{'Artificial': [0], 'intelligence': [1], '(AI)': [2], 'models': [3, 84, 156, 225], 'are': [4, 24, 56], 'increasingly': [5], 'used': [6, 96], 'in': [7, 58], 'the': [8, 33, 66, 77, 123, 127, 166, 185, 208, 218], 'medical': [9, 13], 'domain.': [10], 'However,': [11], 'as': [12, 163, 174], 'data': [14], 'is': [15, 32, 226], 'highly': [16], 'sensitive,': [17], 'special': [18], 'precautions': [19], 'to': [20, 39, 65, 90, 159], 'ensure': [21], 'its': [22], 'protection': [23], 'required.': [25], 'The': [26], 'gold': [27], 'standard': [28], 'for': [29], 'privacy': [30, 37], 'preservation': [31], 'introduction': [34], 'of': [35, 69, 79, 82, 104, 115, 125, 129, 212, 221], 'differential': [36], '(DP)': [38, 155], 'model': [40, 51], 'training.': [41, 92], 'Prior': [42], 'work': [43], 'indicates': [44], 'that': [45, 205], 'DP': [46], 'has': [47], 'negative': [48], 'implications': [49], 'on': [50], 'accuracy': [52, 86, 231], 'and': [53, 60, 87, 110, 138, 153, 170, 232], 'fairness,': [54], 'which': [55], 'unacceptable': [57], 'medicine': [59], 'represent': [61], 'a': [62, 112, 213], 'main': [63], 'barrier': [64], 'widespread': [67], 'use': [68], 'privacy-preserving': [70, 80, 154, 186, 219], 'techniques.': [71], 'In': [72], 'this': [73], 'work,': [74], 'we': [75, 95], 'evaluated': [76], 'effect': [78], 'training': [81, 220], 'AI': [83], 'regarding': [85], 'fairness': [88], 'compared': [89, 146], 'non-private': [91, 147], 'For': [93], 'this,': [94], 'two': [97], 'datasets:': [98], '(1)': [99], 'A': [100], 'large': [101], 'dataset': [102, 113, 216], '(N=193,311)': [103], 'high': [105], 'quality': [106], 'clinical': [107, 215], 'chest': [108], 'radiographs,': [109], '(2)': [111], '(N=1,625)': [114], '3D': [116], 'abdominal': [117], 'computed': [118], 'tomography': [119], '(CT)': [120], 'images,': [121], 'with': [122, 157, 228], 'task': [124], 'classifying': [126], 'presence': [128], 'pancreatic': [130], 'ductal': [131], 'adenocarcinoma': [132], '(PDAC).': [133], 'Both': [134], 'were': [135], 'retrospectively': [136], 'collected': [137], 'manually': [139], 'labeled': [140], 'by': [141], 'experienced': [142], 'radiologists.': [143], 'We': [144, 181], 'then': [145], 'deep': [148, 223], 'convolutional': [149], 'neural': [150], 'networks': [151], '(CNNs)': [152], 'respect': [158], 'privacy-utility': [160], 'trade-offs': [161], 'measured': [162, 173], 'area': [164], 'under': [165, 207], 'receiver-operator-characteristic': [167], 'curve': [168], '(AUROC),': [169], 'privacy-fairness': [171], 'trade-offs,': [172], ""Pearson's"": [175], 'r': [176], 'or': [177, 200], 'Statistical': [178], 'Parity': [179], 'Difference.': [180], 'found': [182], 'that,': [183], 'while': [184], 'trainings': [187], 'yielded': [188], 'lower': [189], 'accuracy,': [190], 'they': [191], 'did': [192], 'largely': [193], 'not': [194], 'amplify': [195], 'discrimination': [196], 'against': [197], 'age,': [198], 'sex': [199], 'co-morbidity.': [201], 'Our': [202], 'study': [203], 'shows': [204], '--': [206, 217], 'challenging': [209], 'realistic': [210], 'circumstances': [211], 'real-life': [214], 'diagnostic': [222, 230], 'learning': [224], 'possible': [227], 'excellent': [229], 'fairness.': [233]}",2023,"['Scale (ratio)', 'Training (meteorology)', 'Computer science', 'Medical imaging', 'Artificial intelligence', 'Internet privacy', 'Geography', 'Cartography', 'Meteorology']","Artificial intelligence (AI) models are increasingly used in the medical domain. However, as medical data is highly sensitive, special precautions to ensure its protection are required. The gold standard for privacy preservation is the introduction of differential privacy (DP) to model training. Prior work indicates that DP has negative implications on model accuracy and fairness, which are unacceptable in medicine and represent a main barrier to the widespread use of privacy-preserving techniques. In this work, we evaluated the effect of privacy-preserving training of AI models regarding accuracy and fairness compared to non-private training. For this, we used two datasets: (1) A large dataset (N=193,311) of high quality clinical chest radiographs, and (2) a dataset (N=1,625) of 3D abdominal computed tomography (CT) images, with the task of classifying the presence of pancreatic ductal adenocarcinoma (PDAC). Both were retrospectively collected and manually labeled by experienced radiologists. We then compared non-private deep convolutional neural networks (CNNs) and privacy-preserving (DP) models with respect to privacy-utility trade-offs measured as area under the receiver-operator-characteristic curve (AUROC), and privacy-fairness trade-offs, measured as Pearson's r or Statistical Parity Difference. We found that, while the privacy-preserving trainings yielded lower accuracy, they did largely not amplify discrimination against age, sex or co-morbidity. Our study shows that -- under the challenging realistic circumstances of a real-life clinical dataset -- the privacy-preserving training of diagnostic deep learning models is possible with excellent diagnostic accuracy and fairness."
https://openalex.org/W4400051206,"AI, data governance and privacy","{'Recent': [0], 'AI': [1, 19, 70, 85, 113, 128], 'technological': [2], 'advances,': [3], 'particularly': [4], 'the': [5, 62, 74, 78, 83, 103, 106, 111, 120, 125], 'rise': [6], 'of': [7, 89, 105, 127], 'generative': [8], 'AI,': [9], 'have': [10], 'raised': [11], 'many': [12], 'data': [13], 'governance': [14], 'and': [15, 20, 35, 48, 50, 65, 91, 94, 132], 'privacy': [16, 21, 63], 'questions.': [17], 'However,': [18], 'policy': [22], 'communities': [23], 'often': [24], 'address': [25], 'these': [26], 'issues': [27], 'independently,': [28], 'with': [29], 'approaches': [30], 'that': [31, 130], 'vary': [32], 'between': [33, 55], 'jurisdictions': [34], 'legal': [36], 'systems.': [37], 'These': [38], 'silos': [39], 'can': [40], 'generate': [41], 'misunderstandings,': [42], 'add': [43], 'complexities': [44], 'in': [45, 77], 'regulatory': [46], 'compliance': [47], 'enforcement,': [49], 'prevent': [51], 'capitalising': [52], 'on': [53, 61], 'commonalities': [54], 'national': [56, 90], 'frameworks.': [57], 'This': [58], 'report': [59, 101, 121], 'focuses': [60], 'risks': [64], 'opportunities': [66], 'stemming': [67], 'from': [68], 'recent': [69], 'developments.': [71], 'It': [72], 'maps': [73], 'principles': [75], 'set': [76], 'OECD': [79, 84, 107, 112], 'Privacy': [80, 108], 'Guidelines': [81, 109], 'to': [82, 123], 'Principles,': [86], 'takes': [87], 'stock': [88], 'regional': [92], 'initiatives,': [93], 'suggests': [95], 'potential': [96], 'areas': [97], 'for': [98, 117], 'collaboration.': [99], 'The': [100], 'supports': [102], 'implementation': [104], 'alongside': [110], 'Principles.': [114], 'By': [115], 'advocating': [116], 'international': [118], 'co-operation,': [119], 'aims': [122], 'guide': [124], 'development': [126], 'systems': [129], 'respect': [131], 'support': [133], 'privacy.': [134]}",2024,"['Data governance', 'Internet privacy', 'Corporate governance', 'Information privacy', 'Computer security', 'Business', 'Computer science', 'Data quality', 'Marketing', 'Finance', 'Metric (unit)']","Recent AI technological advances, particularly the rise of generative AI, have raised many data governance and privacy questions. However, AI and privacy policy communities often address these issues independently, with approaches that vary between jurisdictions and legal systems. These silos can generate misunderstandings, add complexities in regulatory compliance and enforcement, and prevent capitalising on commonalities between national frameworks. This report focuses on the privacy risks and opportunities stemming from recent AI developments. It maps the principles set in the OECD Privacy Guidelines to the OECD AI Principles, takes stock of national and regional initiatives, and suggests potential areas for collaboration. The report supports the implementation of the OECD Privacy Guidelines alongside the OECD AI Principles. By advocating for international co-operation, the report aims to guide the development of AI systems that respect and support privacy."
https://openalex.org/W4220766463,PrivPAS: A real time Privacy-Preserving AI System and applied ethics,"{'With': [0], '3.78': [1], 'billion': [2, 15], 'social': [3], 'media': [4], 'users': [5, 140], 'worldwide': [6], 'in': [7, 138, 143], '2021': [8], '(48%': [9], 'of': [10, 26, 36, 51, 60, 141, 199, 206, 221], 'the': [11, 21, 61, 122, 192], 'human\\npopulation),': [12], 'almost': [13], '3': [14], 'images': [16], 'are': [17, 75], 'shared': [18], 'daily.': [19], 'At': [20], 'same': [22, 69], 'time,': [23], 'a\\nconsistent': [24], 'evolution': [25], 'smartphone': [27, 139], 'cameras': [28], 'has': [29, 46, 66, 114], 'led': [30], 'to': [31, 85, 100, 106, 127, 132, 161, 171, 183], 'a': [32, 55, 107, 130, 158, 169, 187, 196, 200], 'photography': [33], 'explosion\\nwith': [34], '85%': [35], 'all': [37], 'new': [38], 'pictures': [39], 'being': [40, 63, 70], 'captured': [41], 'using': [42], 'smartphones.': [43], 'However,': [44], 'lately,\\nthere': [45], 'been': [47], 'an': [48, 179, 219], 'increased': [49], 'discussion': [50], 'privacy': [52, 73, 108], 'concerns': [53], 'when': [54], 'person': [56], 'being\\nphotographed': [57], 'is': [58, 181], 'unaware': [59], 'picture': [62], 'taken': [64], 'or': [65], 'reservations': [67], 'about\\nthe': [68], 'shared.': [71], 'These': [72], 'violations': [74], 'amplified': [76], 'for': [77, 111, 135], 'people': [78, 112], 'with\\ndisabilities,': [79], 'who': [80], 'may': [81, 96], 'find': [82], 'it': [83], 'challenging': [84], 'raise': [86], 'dissent': [87], 'even': [88], 'if': [89], 'they': [90], 'are\\naware.': [91], 'Such': [92], 'unauthorized': [93], 'image': [94, 180], 'captures': [95], 'also': [97], 'be': [98], 'misused': [99], 'gain': [101], 'sympathy': [102], 'by\\nthird-party': [103], 'organizations,': [104], 'leading': [105], 'breach.': [109], 'Privacy': [110], 'with\\ndisabilities': [113], 'so': [115], 'far': [116], 'received': [117], 'comparatively': [118], 'less': [119], 'attention': [120], 'from': [121], 'AI\\ncommunity.': [123], 'This': [124], 'motivates': [125], 'us': [126], 'work': [128], 'towards': [129], 'solution': [131], 'generate\\nprivacy-conscious': [133], 'cues': [134], 'raising': [136], 'awareness': [137], 'any\\nsensitivity': [142], 'their': [144], 'viewfinder': [145], 'content.': [146], 'To': [147], 'this': [148], 'end,': [149], 'we': [150, 165], 'introduce': [151], 'PrivPAS': [152], '(A\\nreal': [153], 'time': [154], 'Privacy-Preserving': [155], 'AI': [156], 'System)': [157], 'novel': [159], 'framework': [160], 'identify': [162, 172], 'sensitive\\ncontent.': [163], 'Additionally,': [164], 'curate': [166], 'and': [167, 176], 'annotate': [168], 'dataset': [170], 'and\\nlocalize': [173], 'accessibility': [174], 'markers': [175], 'classify': [177], 'whether': [178], 'sensitive': [182], 'a\\nfeatured': [184], 'subject': [185], 'with': [186, 195], 'disability.': [188], 'We': [189], 'demonstrate': [190], 'that': [191], 'proposed\\nlightweight': [193], 'architecture,': [194], 'memory': [197], 'footprint': [198], 'mere': [201], '8.49MB,': [202], 'achieves': [203, 218], 'a\\nhigh': [204], 'mAP': [205], '89.52%': [207], 'on': [208, 214], 'resource-constrained': [209], 'devices.': [210], 'Furthermore,': [211], 'our': [212], 'pipeline,\\ntrained': [213], 'face': [215], 'anonymized': [216], 'data,': [217], 'F1-score': [220], '73.1%.\\n': [222]}",2022,"['Computer science', 'Information privacy', 'Privacy protection', 'Internet privacy', 'Computer security']","With 3.78 billion social media users worldwide in 2021 (48% of the human\npopulation), almost 3 billion images are shared daily. At the same time, a\nconsistent evolution of smartphone cameras has led to a photography explosion\nwith 85% of all new pictures being captured using smartphones. However, lately,\nthere has been an increased discussion of privacy concerns when a person being\nphotographed is unaware of the picture being taken or has reservations about\nthe same being shared. These privacy violations are amplified for people with\ndisabilities, who may find it challenging to raise dissent even if they are\naware. Such unauthorized image captures may also be misused to gain sympathy by\nthird-party organizations, leading to a privacy breach. Privacy for people with\ndisabilities has so far received comparatively less attention from the AI\ncommunity. This motivates us to work towards a solution to generate\nprivacy-conscious cues for raising awareness in smartphone users of any\nsensitivity in their viewfinder content. To this end, we introduce PrivPAS (A\nreal time Privacy-Preserving AI System) a novel framework to identify sensitive\ncontent. Additionally, we curate and annotate a dataset to identify and\nlocalize accessibility markers and classify whether an image is sensitive to a\nfeatured subject with a disability. We demonstrate that the proposed\nlightweight architecture, with a memory footprint of a mere 8.49MB, achieves a\nhigh mAP of 89.52% on resource-constrained devices. Furthermore, our pipeline,\ntrained on face anonymized data, achieves an F1-score of 73.1%.\n"
https://openalex.org/W4402961330,AI powered privacy protection: A survey of current state and future directions,"{'The': [0, 106, 213], 'research': [1, 217], 'is': [2, 152, 180, 245], 'conducted': [3], 'to': [4, 27, 190, 221, 236], 'investigate': [5], 'how': [6, 62], 'AI': [7, 54, 98, 113, 123, 176, 179, 214, 252], 'transforms': [8], 'the': [9, 17, 28, 58, 74, 95, 110, 144, 159, 164, 173, 188, 198, 228], 'notion': [10], 'of': [11, 13, 31, 35, 53, 97, 112, 122, 146, 161, 175, 200, 205, 230], 'protection': [12, 34, 171], 'privacy': [14, 115, 138, 170, 186, 211, 231, 256], 'through': [15, 246], 'discussing': [16], 'status': [18], 'quo': [19], 'technologies,': [20], 'challenges,': [21], 'and': [22, 70, 84, 103, 126, 135, 150, 166, 203, 241, 249], 'future': [23, 111, 229], 'directions.': [24], 'All': [25], 'due': [26], 'sudden': [29], 'rise': [30], 'digital': [32], 'data,': [33, 66], 'personal': [36], 'information': [37], 'has': [38], 'evolved': [39], 'as': [40, 79, 172], 'a': [41, 223], 'major': [42], 'concern': [43], 'for': [44, 114, 158], 'which': [45, 191], 'AI-enabled': [46], 'solutions': [47], 'are': [48, 55], 'being': [49], 'introduced.': [50], 'Advanced': [51], 'concepts': [52], 'therefore': [56], 'marking': [57], 'paradigm': [59], 'shift': [60], 'in': [61, 137, 154, 184, 215, 226, 258], 'organizations': [63], 'handle': [64], 'sensitive': [65], 'letting': [67], 'more': [68], 'secure': [69], 'privacy-oriented': [71], 'practices': [72], 'lead': [73], 'way': [75], 'with': [76, 117, 124, 208, 233], 'notions': [77], 'such': [78], 'differential': [80], 'privacy,': [81], 'federated': [82], 'learning,': [83], 'anomaly': [85], 'detection.': [86], 'However,': [87], 'despite': [88], 'these': [89], 'advances,': [90], 'formidable': [91], 'challenges': [92], 'remain': [93], 'regarding': [94], 'opacity': [96], 'models,': [99], 'possible': [100], 'algorithmic': [101], 'biases,': [102], 'regulatory': [104, 167], 'compliance.': [105], 'paper': [107, 218], 'further': [108, 141], 'discusses': [109], 'protection,': [116], 'new': [118], 'developments:': [119], 'XAI,': [120], 'integration': [121], 'blockchain,': [125], 'quantum-resistant': [127], 'cryptography.': [128], 'These': [129], 'advances': [130], 'offer': [131], 'great': [132], 'transparency,': [133], 'security,': [134, 240], 'responsibility': [136], 'management.': [139], 'It': [140, 244], 'underlines': [142], 'that': [143, 251], 'collaboration': [145, 250], 'governments,': [147], 'industrial': [148], 'leaders,': [149], 'researchers': [151], 'required': [153], 'providing': [155], 'appropriate': [156], 'frameworks': [157], 'usage': [160], 'AI,': [162], 'given': [163], 'ethical': [165, 242], 'concerns': [168], 'around': [169], 'influence': [174], 'grows.': [177], 'While': [178], 'indeed': [181], 'very': [182], 'promising': [183], 'improving': [185], 'protections,': [187], 'degree': [189], 'it': [192], 'can': [193, 253], 'actually': [194], 'function': [195], 'depends': [196], 'on': [197], 'surmounting': [199], 'present': [201], 'limitations': [202], 'harmonization': [204], 'technological': [206], 'development': [207], 'shifting': [209], 'data': [210], 'criteria.': [212], 'this': [216], 'will': [219], 'continue': [220], 'play': [222], 'leading': [224], 'role': [225], 'shaping': [227], 'preservation,': [232], 'answers': [234], 'continuing': [235], 'emanate': [237], 'from': [238], 'innovation,': [239], 'concerns.': [243], 'continuous': [247], 'improvement': [248], 'ensure': [254], 'effective': [255], 'measures': [257], 'an': [259], 'increasingly': [260], 'data-driven': [261], 'world.': [262]}",2024,"['Current (fluid)', 'State (computer science)', 'Internet privacy', 'Computer security', 'Computer science', 'Engineering', 'Electrical engineering', 'Algorithm']","The research is conducted to investigate how AI transforms the notion of protection of privacy through discussing the status quo technologies, challenges, and future directions. All due to the sudden rise of digital data, protection of personal information has evolved as a major concern for which AI-enabled solutions are being introduced. Advanced concepts of AI are therefore marking the paradigm shift in how organizations handle sensitive data, letting more secure and privacy-oriented practices lead the way with notions such as differential privacy, federated learning, and anomaly detection. However, despite these advances, formidable challenges remain regarding the opacity of AI models, possible algorithmic biases, and regulatory compliance. The paper further discusses the future of AI for privacy protection, with new developments: XAI, integration of AI with blockchain, and quantum-resistant cryptography. These advances offer great transparency, security, and responsibility in privacy management. It further underlines that the collaboration of governments, industrial leaders, and researchers is required in providing appropriate frameworks for the usage of AI, given the ethical and regulatory concerns around privacy protection as the influence of AI grows. While AI is indeed very promising in improving privacy protections, the degree to which it can actually function depends on the surmounting of present limitations and harmonization of technological development with shifting data privacy criteria. The AI in this research paper will continue to play a leading role in shaping the future of privacy preservation, with answers continuing to emanate from innovation, security, and ethical concerns. It is through continuous improvement and collaboration that AI can ensure effective privacy measures in an increasingly data-driven world."
https://openalex.org/W3040344368,“Healthy surveillance”: Designing a concept for privacy-preserving mask recognition AI in the age of pandemics,"{'The': [0], 'obligation': [1], 'to': [2, 31, 40, 148], 'wear': [3, 32], 'masks': [4, 33], 'in': [5, 21, 49, 156], 'times': [6], 'of': [7, 12, 17, 45, 68, 76, 114, 171, 181], 'pandemics': [8], 'reduces': [9], 'the': [10, 18, 43, 66, 166, 169, 179], 'risk': [11], 'spreading': [13], 'viruses.': [14], 'In': [15, 38, 118], 'case': [16], 'COVID-19': [19], 'pandemic': [20], '2020,': [22], 'many': [23], 'governments': [24], 'recommended': [25], 'or': [26, 54], 'even': [27], 'obligated': [28], 'their': [29], 'citizens': [30, 102], 'as': [34, 96], 'an': [35], 'effective': [36], 'countermeasure.': [37], 'order': [39], 'continuously': [41], 'monitor': [42], 'compliance': [44], 'this': [46, 119], 'policy': [47], 'measure': [48], 'public': [50, 58], 'spaces': [51], 'like': [52, 105], 'restaurants': [53], 'tram': [55], 'stations': [56], 'by': [57], 'authorities,': [59], 'one': [60], 'scalable': [61], 'and': [62, 103, 137, 154, 174], 'automatable': [63], 'option': [64], 'depicts': [65], 'application': [67], 'surveillance': [69, 97], 'systems,': [70], 'i.e.,': [71], 'CCTV.': [72], 'However,': [73], 'large-scale': [74], 'monitoring': [75], 'mask': [77, 126], 'recognition': [78, 127], 'does': [79], 'not': [80], 'only': [81], 'require': [82], 'a': [83, 99, 124, 157], 'well-performing': [84], 'Artificial': [85, 144, 175], 'Intelligence,': [86], 'but': [87], 'also': [88], 'ensure': [89], 'that': [90, 161], 'no': [91], 'privacy': [92, 172], 'issues': [93], 'are': [94], 'introduced,': [95], 'is': [98, 146], 'deterrent': [100], 'for': [101, 135], 'regulations': [104, 113], 'General': [106], 'Data': [107], 'Protection': [108], 'Regulation': [109], '(GDPR)': [110], 'demand': [111], 'strict': [112], 'such': [115], 'personal': [116], 'data.': [117], 'work,': [120], 'we': [121, 163], 'show': [122], 'how': [123], 'privacy-preserving': [125], 'artifact': [128], 'could': [129], 'look': [130], 'like,': [131], 'demonstrate': [132], 'different': [133], 'options': [134], 'implementation': [136], 'evaluate': [138], 'performances.': [139], 'Our': [140], 'conceptual': [141], 'deep-learning': [142], 'based': [143], 'Intelligence': [145, 176], 'able': [147], 'achieve': [149], 'detection': [150], 'performances': [151], 'between': [152, 168], '95%': [153], '99%': [155], 'privacy-friendly': [158], 'setting.': [159], 'On': [160], 'basis,': [162], 'elaborate': [164], 'on': [165], 'trade-off': [167], 'level': [170], 'preservation': [173], 'performance,': [177], 'i.e.': [178], '“price': [180], 'privacy”.': [182]}",2021,"['Obligation', 'Computer security', 'Computer science', 'Countermeasure', 'Information privacy', 'Scalability', 'Internet privacy', 'General Data Protection Regulation', 'Pandemic', 'Coronavirus disease 2019 (COVID-19)', 'Artificial intelligence', 'Data Protection Act 1998', 'Engineering', 'Database', 'Law', 'Pathology', 'Political science', 'Aerospace engineering', 'Infectious disease (medical specialty)', 'Medicine', 'Disease']","The obligation to wear masks in times of pandemics reduces the risk of spreading viruses. In case of the COVID-19 pandemic in 2020, many governments recommended or even obligated their citizens to wear masks as an effective countermeasure. In order to continuously monitor the compliance of this policy measure in public spaces like restaurants or tram stations by public authorities, one scalable and automatable option depicts the application of surveillance systems, i.e., CCTV. However, large-scale monitoring of mask recognition does not only require a well-performing Artificial Intelligence, but also ensure that no privacy issues are introduced, as surveillance is a deterrent for citizens and regulations like General Data Protection Regulation (GDPR) demand strict regulations of such personal data. In this work, we show how a privacy-preserving mask recognition artifact could look like, demonstrate different options for implementation and evaluate performances. Our conceptual deep-learning based Artificial Intelligence is able to achieve detection performances between 95% and 99% in a privacy-friendly setting. On that basis, we elaborate on the trade-off between the level of privacy preservation and Artificial Intelligence performance, i.e. the “price of privacy”."
https://openalex.org/W4402349863,"HabitSense: A Privacy-Aware, AI-Enhanced Multimodal Wearable Platform for mHealth Applications","{'Wearable': [0], 'cameras': [1], 'provide': [2], 'an': [3, 61, 229], 'objective': [4], 'method': [5], 'to': [6, 102, 188], 'visually': [7], 'confirm': [8], 'and': [9, 19, 26, 51, 75, 97, 105, 133, 205, 224, 232, 240], 'automate': [10], 'the': [11, 32, 46, 92, 153, 177, 215], 'detection': [12], 'of': [13, 34, 122, 127, 194, 218], 'health-risk': [14, 90, 159, 189, 244], 'behaviors': [15, 190, 245], 'such': [16], 'as': [17], 'smoking': [18, 106, 134], 'overeating,': [20], 'which': [21], 'is': [22, 39, 237], 'critical': [23, 216], 'for': [24, 88, 137, 242], 'developing': [25, 228], 'testing': [27], 'adaptive': [28], 'treatment': [29], 'interventions.': [30], 'Despite': [31], 'potential': [33], 'wearable': [35, 234], 'camera': [36], 'systems,': [37], 'adoption': [38], 'hindered': [40], 'by': [41], 'inadequate': [42], 'clinician': [43, 219], 'input': [44, 68], 'in': [45, 108, 146, 198, 202, 209, 227, 246], 'design,': [47], 'user': [48, 52, 76], 'privacy': [49, 151, 183], 'concerns,': [50, 152], 'burden.': [53], 'To': [54, 149], 'address': [55, 150], 'these': [56], 'barriers,': [57], 'we': [58], 'introduced': [59], 'HabitSense,': [60], 'open-source1,': [62], 'multi-modal': [63], 'neck-worn': [64], 'platform': [65, 93, 154], 'developed': [66], 'with': [67, 72, 131], 'from': [69, 78], 'focus': [70], 'groups': [71], 'clinicians': [73], '(N=36)': [74], 'feedback': [77], 'in-wild': [79], 'studies': [80], 'involving': [81, 115], '105': [82], 'participants': [83], 'over': [84], '35': [85], 'days.': [86], 'Optimized': [87], 'monitoring': [89, 243], 'behaviors,': [91], 'utilizes': [94], 'RGB,': [95], 'thermal,': [96], 'inertial': [98], 'measurement': [99], 'unit': [100], 'sensors': [101], 'detect': [103], 'eating': [104, 132], 'events': [107, 161], 'real': [109], 'time.': [110], 'In': [111], 'a': [112, 143, 164, 199, 206], '7-day': [113], 'study': [114], '15': [116], 'participants,': [117], 'HabitSense': [118, 169], 'recorded': [119], '768': [120], 'hours': [121], 'footage,': [123], 'capturing': [124], '420.91': [125], 'minutes': [126], 'hand-to-mouth': [128], 'gestures': [129, 186], 'associated': [130], 'data': [135], 'crucial': [136], 'training': [138], 'machine': [139], 'learning': [140], 'models,': [141], 'achieving': [142], '92%': [144], 'F1-score': [145], 'gesture': [147], 'recognition.': [148], 'records': [155], 'only': [156], 'during': [157, 179], 'likely': [158], 'behavior': [160], 'using': [162], 'SECURE,': [163], 'smart': [165], 'activation': [166], 'algorithm.': [167], 'Additionally,': [168], 'employs': [170], 'on-device': [171], 'obfuscation': [172], 'algorithms': [173, 226], 'that': [174, 236], 'selectively': [175], 'obfuscate': [176], 'background': [178], 'recording,': [180], 'maintaining': [181], 'individual': [182], 'while': [184], 'leaving': [185], 'related': [187], 'unobfuscated.': [191], 'Our': [192], 'implementation': [193], 'SECURE': [195], 'has': [196], 'resulted': [197], '48%': [200], 'reduction': [201], 'storage': [203], 'needs': [204], '30%': [207], 'increase': [208], 'battery': [210], 'life.': [211], 'This': [212], 'paper': [213], 'highlights': [214], 'roles': [217], 'feedback,': [220], 'extensive': [221], 'field': [222], 'testing,': [223], 'privacy-enhancing': [225], 'unobtrusive,': [230], 'lightweight,': [231], 'reproducible': [233], 'system': [235], 'both': [238], 'feasible': [239], 'acceptable': [241], 'real-world': [247], 'settings.': [248]}",2024,"['mHealth', 'Wearable computer', 'Human–computer interaction', 'Computer science', 'Wearable technology', 'Internet privacy', 'Embedded system', 'Medicine', 'Nursing', 'Psychological intervention']","Wearable cameras provide an objective method to visually confirm and automate the detection of health-risk behaviors such as smoking and overeating, which is critical for developing and testing adaptive treatment interventions. Despite the potential of wearable camera systems, adoption is hindered by inadequate clinician input in the design, user privacy concerns, and user burden. To address these barriers, we introduced HabitSense, an open-source1, multi-modal neck-worn platform developed with input from focus groups with clinicians (N=36) and user feedback from in-wild studies involving 105 participants over 35 days. Optimized for monitoring health-risk behaviors, the platform utilizes RGB, thermal, and inertial measurement unit sensors to detect eating and smoking events in real time. In a 7-day study involving 15 participants, HabitSense recorded 768 hours of footage, capturing 420.91 minutes of hand-to-mouth gestures associated with eating and smoking data crucial for training machine learning models, achieving a 92% F1-score in gesture recognition. To address privacy concerns, the platform records only during likely health-risk behavior events using SECURE, a smart activation algorithm. Additionally, HabitSense employs on-device obfuscation algorithms that selectively obfuscate the background during recording, maintaining individual privacy while leaving gestures related to health-risk behaviors unobfuscated. Our implementation of SECURE has resulted in a 48% reduction in storage needs and a 30% increase in battery life. This paper highlights the critical roles of clinician feedback, extensive field testing, and privacy-enhancing algorithms in developing an unobtrusive, lightweight, and reproducible wearable system that is both feasible and acceptable for monitoring health-risk behaviors in real-world settings."
https://openalex.org/W4400566960,"The Legal Implications of Data Privacy Laws, Cybersecurity Regulations, and AI Ethics in a Digital Society","{'This': [0], 'study': [1], 'explores': [2], 'the': [3, 16, 60, 107, 131], 'legal': [4, 32, 92], 'implications': [5, 112], 'of': [6, 18, 64, 77, 113], 'data': [7, 83, 101, 134, 145, 181], 'privacy': [8, 84, 146], 'laws,': [9], 'cybersecurity': [10, 87], 'regulations,': [11, 88], 'and': [12, 35, 41, 55, 62, 67, 86, 96, 110, 115, 127, 137, 151, 163, 179, 207, 216], 'AI': [13, 138, 195, 203], 'ethics': [14, 196], 'in': [15, 153, 166, 175, 209], 'context': [17], 'an': [19], 'increasingly': [20], 'digital': [21, 37, 154, 169, 177], 'society.': [22, 70], 'The': [23, 44, 71, 140], 'primary': [24], 'objective': [25], 'is': [26, 121], 'to': [27, 58, 123, 130, 187, 225], 'qualitatively': [28], 'assess': [29], 'how': [30], 'these': [31, 65, 117], 'frameworks': [33, 197], 'interact': [34], 'influence': [36], 'governance,': [38], 'individual': [39, 149], 'rights,': [40], 'societal': [42, 111], 'norms.': [43], 'research': [45], 'employs': [46], 'a': [47, 167, 210], 'qualitative': [48, 100], 'methodology,': [49], 'incorporating': [50], 'case': [51, 75], 'studies,': [52], 'expert': [53], 'interviews,': [54], 'thematic': [56], 'analysis': [57, 120], 'examine': [59], 'complexities': [61], 'impacts': [63], 'laws': [66, 85, 147], 'regulations': [68, 172], 'on': [69], 'methodology': [72], 'involves': [73], 'detailed': [74], 'studies': [76], 'countries': [78], 'that': [79, 143, 202, 212], 'have': [80], 'enacted': [81], 'comprehensive': [82], 'alongside': [89], 'interviews': [90], 'with': [91, 190], 'experts,': [93], 'policy': [94], 'makers,': [95], 'technology': [97], 'professionals.': [98], 'These': [99], 'collection': [102], 'methods': [103], 'provide': [104], 'insights': [105], 'into': [106], 'effectiveness,': [108], 'challenges,': [109], 'implementing': [114], 'enforcing': [116], 'laws.': [118], 'Thematic': [119], 'utilized': [122], 'identify': [124], 'key': [125], 'themes': [126], 'patterns': [128], 'related': [129], 'interplay': [132], 'between': [133], 'privacy,': [135], 'cybersecurity,': [136], 'ethics.': [139], 'findings': [141], 'reveal': [142], 'robust': [144], 'enhance': [148], 'rights': [150, 215], 'trust': [152], 'systems,': [155], 'but': [156, 220], 'also': [157], 'pose': [158], 'significant': [159], 'challenges': [160], 'for': [161, 200], 'compliance': [162], 'enforcement,': [164], 'especially': [165], 'globalized': [168], 'landscape.': [170], 'Cybersecurity': [171], 'are': [173, 198, 205], 'critical': [174], 'protecting': [176], 'infrastructure': [178], 'preventing': [180], 'breaches,': [182], 'yet': [183], 'they': [184, 221], 'often': [185], 'struggle': [186], 'keep': [188], 'pace': [189], 'rapidly': [191], 'evolving': [192], 'cyber': [193], 'threats.': [194], 'essential': [199], 'ensuring': [201], 'technologies': [204], 'developed': [206], 'deployed': [208], 'manner': [211], 'respects': [213], 'human': [214], 'promotes': [217], 'social': [218], 'welfare,': [219], 'require': [222], 'continuous': [223], 'updates': [224], 'address': [226], 'emerging': [227], 'ethical': [228], 'dilemmas.': [229]}",2024,"['Law', 'Data breach', 'Privacy laws of the United States', 'Computer security', 'Political science', 'Information privacy', 'Internet privacy', 'Business', 'Computer science']","This study explores the legal implications of data privacy laws, cybersecurity regulations, and AI ethics in the context of an increasingly digital society. The primary objective is to qualitatively assess how these legal frameworks interact and influence digital governance, individual rights, and societal norms. The research employs a qualitative methodology, incorporating case studies, expert interviews, and thematic analysis to examine the complexities and impacts of these laws and regulations on society. The methodology involves detailed case studies of countries that have enacted comprehensive data privacy laws and cybersecurity regulations, alongside interviews with legal experts, policy makers, and technology professionals. These qualitative data collection methods provide insights into the effectiveness, challenges, and societal implications of implementing and enforcing these laws. Thematic analysis is utilized to identify key themes and patterns related to the interplay between data privacy, cybersecurity, and AI ethics. The findings reveal that robust data privacy laws enhance individual rights and trust in digital systems, but also pose significant challenges for compliance and enforcement, especially in a globalized digital landscape. Cybersecurity regulations are critical in protecting digital infrastructure and preventing data breaches, yet they often struggle to keep pace with rapidly evolving cyber threats. AI ethics frameworks are essential for ensuring that AI technologies are developed and deployed in a manner that respects human rights and promotes social welfare, but they require continuous updates to address emerging ethical dilemmas."
https://openalex.org/W3004998268,Privacy Preserving Cyberbullying Prevention with AI Methods in 5G Networks,"{'Children': [0], 'and': [1, 89], 'teenagers': [2], 'that': [3, 69], 'have': [4, 28], 'been': [5, 29], 'a': [6, 17], 'victim': [7], 'of': [8, 22, 62, 102], 'bullying': [9], 'can': [10, 40], 'possibly': [11], 'suffer': [12], 'its': [13], 'psychological': [14], 'effects': [15], 'for': [16], 'lifetime.': [18], 'With': [19], 'the': [20, 70, 79, 82], 'increase': [21], 'online': [23], 'social': [24], 'media,': [25], 'cyberbullying': [26, 42, 63, 103], 'incidents': [27], 'increased': [30], 'as': [31, 54, 86], 'well.': [32], 'In': [33], 'this': [34], 'paper': [35], 'we': [36, 39], 'discuss': [37], 'how': [38], 'detect': [41], 'with': [43], 'AI': [44], 'techniques,': [45], 'using': [46], 'term': [47], 'frequency-inverse': [48], 'document': [49], 'frequency.': [50], 'We': [51, 58], 'label': [52], 'messages': [53, 73], 'benign': [55, 72], 'or': [56], 'bully.': [57], 'want': [59], 'our': [60], 'method': [61], 'detection': [64], 'to': [65, 78, 99], 'be': [66, 76], 'privacy-preserving,': [67], 'such': [68], ""subscribers'"": [71], 'should': [74], 'not': [75], 'revealed': [77], 'operator.': [80], 'Moreover,': [81], 'operator': [83, 92], 'labels': [84], 'subscribers': [85], 'normal,': [87], 'bully': [88], 'victim.': [90], 'The': [91], 'utilizes': [93], 'policy': [94], 'control': [95], 'in': [96], '5G': [97], 'networks,': [98], 'protect': [100], 'victims': [101], 'from': [104], 'harmful': [105], 'traffic.': [106]}",2019,"['Operator (biology)', 'Computer science', 'Internet privacy', 'Control (management)', 'Computer security', 'Social media', 'Term (time)', 'World Wide Web', 'Artificial intelligence', 'Chemistry', 'Transcription factor', 'Gene', 'Physics', 'Quantum mechanics', 'Biochemistry', 'Repressor']","Children and teenagers that have been a victim of bullying can possibly suffer its psychological effects for a lifetime. With the increase of online social media, cyberbullying incidents have been increased as well. In this paper we discuss how we can detect cyberbullying with AI techniques, using term frequency-inverse document frequency. We label messages as benign or bully. We want our method of cyberbullying detection to be privacy-preserving, such that the subscribers' benign messages should not be revealed to the operator. Moreover, the operator labels subscribers as normal, bully and victim. The operator utilizes policy control in 5G networks, to protect victims of cyberbullying from harmful traffic."
https://openalex.org/W4402282711,Ethical Implications of AI in Data Collection: Balancing Innovation with Privacy,"{'Abstract': [0], 'This': [1], 'article': [2, 129], 'examines': [3], 'the': [4, 46, 49, 55, 81, 101, 109, 131, 141, 151], 'ethical': [5, 67, 126], 'and': [6, 30, 52, 74, 96, 115, 120, 125, 136, 156], 'legal': [7, 113, 119], 'implications': [8], 'of': [9, 83, 104, 111, 144, 153], 'artificial': [10], 'intelligence': [11], '(AI)': [12], 'driven': [13], 'data': [14, 34], 'collection,': [15], 'focusing': [16], 'on': [17, 33], 'developments': [18], 'from': [19], '2023': [20], 'to': [21, 99, 139], '2024.': [22], 'It': [23, 107], 'analyzes': [24], 'recent': [25], 'advancements': [26], 'in': [27, 45, 57, 80, 93], 'AI': [28, 64, 86, 105, 145], 'technologies': [29], 'their': [31], 'impact': [32], 'collection': [35], 'practices': [36], 'across': [37], 'various': [38], 'sectors.': [39], 'The': [40, 88, 128], 'study': [41], 'compares': [42], 'regulatory': [43], 'approaches': [44], 'European': [47], 'Union,': [48], 'United': [50], 'States,': [51], 'China,': [53], 'highlighting': [54], 'challenges': [56, 103], 'creating': [58], 'a': [59], 'globally': [60], 'harmonized': [61], 'framework': [62], 'for': [63, 133], 'governance.': [65], 'Key': [66], 'issues,': [68], 'including': [69], 'informed': [70], 'consent,': [71], 'algorithmic': [72], 'bias,': [73], 'privacy': [75], 'protection,': [76], 'are': [77], 'critically': [78], 'assessed': [79], 'context': [82], 'increasingly': [84], 'sophisticated': [85], 'systems.': [87], 'research': [89], 'explores': [90], 'case': [91], 'studies': [92], 'healthcare,': [94], 'finance,': [95], 'smart': [97], 'cities': [98], 'illustrate': [100], 'practical': [102], 'implementation.': [106], 'evaluates': [108], 'effectiveness': [110], 'current': [112], 'frameworks': [114], 'proposes': [116], 'solutions': [117], 'encompassing': [118], 'policy': [121], 'recommendations,': [122], 'technical': [123], 'safeguards,': [124], 'frameworks.': [127], 'emphasizes': [130], 'need': [132], 'adaptive': [134], 'governance': [135], 'international': [137], 'cooperation': [138], 'address': [140], 'global': [142], 'nature': [143], 'development': [146], 'while': [147], 'balancing': [148], 'innovation': [149], 'with': [150], 'protection': [152], 'individual': [154], 'rights': [155], 'societal': [157], 'values.': [158]}",2024,"['Data collection', 'Internet privacy', 'Information privacy', 'Computer science', 'Business', 'Data science', 'Engineering ethics', 'Sociology', 'Engineering', 'Social science']","Abstract This article examines the ethical and legal implications of artificial intelligence (AI) driven data collection, focusing on developments from 2023 to 2024. It analyzes recent advancements in AI technologies and their impact on data collection practices across various sectors. The study compares regulatory approaches in the European Union, the United States, and China, highlighting the challenges in creating a globally harmonized framework for AI governance. Key ethical issues, including informed consent, algorithmic bias, and privacy protection, are critically assessed in the context of increasingly sophisticated AI systems. The research explores case studies in healthcare, finance, and smart cities to illustrate the practical challenges of AI implementation. It evaluates the effectiveness of current legal frameworks and proposes solutions encompassing legal and policy recommendations, technical safeguards, and ethical frameworks. The article emphasizes the need for adaptive governance and international cooperation to address the global nature of AI development while balancing innovation with the protection of individual rights and societal values."
https://openalex.org/W4390529394,Privacy-Preserving Data in IoT-based Cloud Systems: A Comprehensive Survey with AI Integration,"{'As': [0], 'the': [1, 12, 20, 27, 33, 77, 86, 114, 118, 146, 153], 'integration': [2, 79], 'of': [3, 5, 15, 29, 36, 61, 68, 80, 88, 106, 149, 156], 'Internet': [4], 'Things': [6], 'devices': [7], 'with': [8], 'cloud': [9, 39, 128, 159], 'computing': [10, 160], 'proliferates,': [11], 'paramount': [13], 'importance': [14], 'privacy': [16, 30, 56, 150], 'preservation': [17, 151], 'comes': [18], 'to': [19], 'forefront.': [21], 'This': [22], 'survey': [23, 108, 135], 'paper': [24], 'meticulously': [25], 'explores': [26], 'landscape': [28, 155], 'issues': [31], 'in': [32, 55, 122, 152], 'dynamic': [34, 92], 'intersection': [35], 'IoT': [37, 157], 'and': [38, 51, 76, 99, 143, 158], 'systems.': [40, 103], 'The': [41, 59, 104, 130], 'comprehensive': [42], 'literature': [43], 'review': [44], 'synthesizes': [45], 'existing': [46], 'research,': [47], 'illuminating': [48], 'key': [49], 'challenges': [50], 'discerning': [52], 'emerging': [53], 'trends': [54, 84], 'preserving': [57], 'techniques.': [58], 'categorization': [60], 'diverse': [62], 'approaches': [63], 'unveils': [64], 'a': [65, 110, 137], 'nuanced': [66], 'understanding': [67, 117], 'encryption': [69, 95], 'techniques,': [70], 'anonymization': [71], 'strategies,': [72], 'access': [73, 101], 'control': [74, 102], 'mechanisms,': [75], 'burgeoning': [78], 'artificial': [81], 'intelligence.': [82], 'Notable': [83], 'include': [85], 'infusion': [87], 'machine': [89], 'learning': [90], 'for': [91, 96, 116, 140], 'anonymization,': [93], 'homomorphic': [94], 'secure': [97], 'computation,': [98], 'AI-driven': [100], 'culmination': [105], 'this': [107, 134], 'contributes': [109], 'holistic': [111], 'view,': [112], 'laying': [113], 'groundwork': [115], 'multifaceted': [119], 'strategies': [120], 'employed': [121], 'securing': [123], 'sensitive': [124], 'data': [125], 'within': [126], 'IoT-based': [127], 'environments.': [129], 'insights': [131], 'garnered': [132], 'from': [133], 'provide': [136], 'valuable': [138], 'resource': [139], 'researchers,': [141], 'practitioners,': [142], 'policymakers': [144], 'navigating': [145], 'complex': [147], 'terrain': [148], 'evolving': [154]}",2024,"['Cloud computing', 'Computer science', 'Encryption', 'Data science', 'Internet of Things', 'Information privacy', 'Access control', 'Computer security', 'Internet privacy', 'Operating system']","As the integration of Internet of Things devices with cloud computing proliferates, the paramount importance of privacy preservation comes to the forefront. This survey paper meticulously explores the landscape of privacy issues in the dynamic intersection of IoT and cloud systems. The comprehensive literature review synthesizes existing research, illuminating key challenges and discerning emerging trends in privacy preserving techniques. The categorization of diverse approaches unveils a nuanced understanding of encryption techniques, anonymization strategies, access control mechanisms, and the burgeoning integration of artificial intelligence. Notable trends include the infusion of machine learning for dynamic anonymization, homomorphic encryption for secure computation, and AI-driven access control systems. The culmination of this survey contributes a holistic view, laying the groundwork for understanding the multifaceted strategies employed in securing sensitive data within IoT-based cloud environments. The insights garnered from this survey provide a valuable resource for researchers, practitioners, and policymakers navigating the complex terrain of privacy preservation in the evolving landscape of IoT and cloud computing"
https://openalex.org/W4405759532,AI surveillance: Reclaiming privacy through informational control,"{'With': [0], 'the': [1, 6, 14, 57, 78, 84, 90, 97, 114, 139, 147, 155, 165, 188], 'rise': [2], 'of': [3, 8, 59, 65, 81, 100, 116, 123, 138, 149, 154, 158, 164, 168, 191], 'algorithmic': [4, 69], 'management,': [5], 'deployment': [7], 'AI': [9, 17, 109], 'surveillance': [10, 18], 'has': [11], 'proliferated': [12], 'in': [13, 83], 'modern': [15], 'workplace.': [16], 'relies': [19], 'on': [20, 113, 178], 'advanced': [21], 'computational': [22], 'methods': [23], 'to': [24, 40, 102, 130], 'draw': [25], 'statistical': [26, 51], 'inferences': [27, 34], 'about': [28], 'workers': [29, 49, 101], 'from': [30, 96], 'their': [31], 'data.': [32], 'These': [33], 'are': [35, 105], 'subsequently': [36], 'used': [37], 'by': [38, 108], 'employers': [39, 103], 'inform': [41], 'various': [42], 'organisational': [43], 'and': [44, 55, 104, 132, 152, 161, 186], 'managerial': [45], 'decisions.': [46], 'This': [47, 135], 'commodifies': [48], 'into': [50], 'entities,': [52], 'which': [53, 87], 'objectifies': [54], 'instrumentalises': [56], 'value': [58], 'human': [60], 'work': [61], 'as': [62, 126, 144, 146], 'a': [63, 127, 175], 'series': [64], 'data': [66, 133], 'points': [67], 'for': [68], 'analysis.': [70], 'The': [71, 171], 'article': [72, 172], 'explores': [73], 'how': [74], 'this': [75], 'transformation': [76], 'impacts': [77], 'precarious': [79], 'role': [80], 'privacy': [82, 131, 184], 'employment': [85], 'context,': [86], 'already': [88], 'navigates': [89], 'inherent': [91], 'informational': [92, 124, 180], 'imbalances': [93], 'that': [94, 119, 174], 'arise': [95], 'structural': [98], 'subordination': [99], 'further': [106], 'exasperated': [107], 'surveillance.': [110], 'It': [111], 'focuses': [112], 'remedies': [115], 'EU': [117], 'law': [118], 'instantiate': [120], 'specific': [121], 'notions': [122], 'control': [125, 181], 'core': [128], 'ingredient': [129], 'protection.': [134], 'involves': [136], 'consideration': [137], 'General': [140], 'Data': [141], 'Protection': [142], 'Regulation,': [143], 'well': [145], 'jurisprudence': [148], 'Articles': [150], '7': [151], '8': [153, 163], 'European': [156, 166], 'Charter': [157], 'Fundamental': [159], 'Rights,': [160], 'Article': [162], 'Convention': [167], 'Human': [169], 'Rights.': [170], 'argues': [173], 'greater': [176], 'emphasis': [177], 'workers’': [179], 'consolidates': [182], 'existing': [183], 'protections': [185], 'mitigates': [187], 'systemic': [189], 'risks': [190], 'data-driven': [192], 'commodification.': [193]}",2024,"['Context (archaeology)', 'Commodification', 'Charter', 'Data Protection Act 1998', 'Human rights', 'Convention', 'Information privacy', 'Business', 'Law and economics', 'Control (management)', 'General Data Protection Regulation', 'Jurisprudence', 'Political science', 'Law', 'Sociology', 'Economics', 'Biology', 'Market economy', 'Paleontology', 'Management']","With the rise of algorithmic management, the deployment of AI surveillance has proliferated in the modern workplace. AI surveillance relies on advanced computational methods to draw statistical inferences about workers from their data. These inferences are subsequently used by employers to inform various organisational and managerial decisions. This commodifies workers into statistical entities, which objectifies and instrumentalises the value of human work as a series of data points for algorithmic analysis. The article explores how this transformation impacts the precarious role of privacy in the employment context, which already navigates the inherent informational imbalances that arise from the structural subordination of workers to employers and are further exasperated by AI surveillance. It focuses on the remedies of EU law that instantiate specific notions of informational control as a core ingredient to privacy and data protection. This involves consideration of the General Data Protection Regulation, as well as the jurisprudence of Articles 7 and 8 of the European Charter of Fundamental Rights, and Article 8 of the European Convention of Human Rights. The article argues that a greater emphasis on workers’ informational control consolidates existing privacy protections and mitigates the systemic risks of data-driven commodification."
https://openalex.org/W2989817300,AI-Driven Cyber Security Analytics and Privacy Protection,"{'has': [0, 111], 'gone': [1], 'through': [2], 'a': [3], 'rapid': [4], 'development': [5], 'in': [6, 77, 116, 172], ""today's"": [7], 'internet': [8], 'connected': [9], 'world.With': [10], 'the': [11, 15, 20, 26, 37, 45, 55, 70, 74, 84, 117, 123, 139, 148, 151, 158, 165], 'wide': [12], 'application': [13], 'of': [14, 22, 31, 141], 'booming': [16], 'technologies': [17], 'such': [18, 94, 162], 'as': [19, 95, 163], 'Internet': [21], 'ings': [23], '(IoT)': [24], 'and': [25, 35, 58, 105, 136, 154], 'cloud': [27], 'computing,': [28], 'huge': [29], 'amount': [30], 'data': [32, 38, 76, 101], 'are': [33, 89], 'generated': [34], 'collected.While': [36], 'can': [39, 155], 'be': [40], 'used': [41], 'to': [42, 68, 83, 146], 'better': [43], 'serve': [44], 'corresponding': [46], 'business': [47], 'needs,': [48], 'they': [49], 'also': [50], 'pose': [51], 'big': [52, 75, 100], 'challenges': [53], 'for': [54], 'cyber': [56, 85, 108], 'security': [57, 86, 109], 'privacy': [59], 'protection.It': [60], 'becomes': [61], 'very': [62], 'di': [63, 166, 173], 'cult': [64], 'if': [65], 'not': [66], 'impossible': [67], 'discover': [69], 'malicious': [71, 133], 'behavior': [72], 'among': [73], 'real': [78], 'time.us,': [79], 'this': [80], 'gives': [81], 'rise': [82], 'solutions': [87], 'which': [88, 121, 169], 'driven': [90], 'by': [91], 'AI-based': [92], 'technologies,': [93], 'machine': [96], 'learning,': [97, 104], 'statistical': [98], 'inference,': [99], 'analysis,': [102], 'deep': [103], 'so': [106, 137], 'on.AIdriven': [107], 'analytics': [110], 'already': [112], 'found': [113], 'its': [114], 'applications': [115], 'next': [118], 'generation': [119], 'rewall': [120], 'includes': [122], 'automatic': [124], 'intrusion': [125], 'detection': [126], 'system,': [127], 'encrypted': [128], 'tra': [129], 'c': [130], 'classi': [131], 'cation,': [132], 'software': [134], 'detection,': [135], 'on.In': [138], 'area': [140], 'cryptography,': [142], 'AI-driven': [143], 'solution': [144], 'starts': [145], 'help': [147], 'researchers': [149], 'optimize': [150], 'algorithm': [152], 'design': [153], 'largely': [156], 'reduce': [157], 'cryptanalysis': [159], 'e': [160], 'ort': [161], 'searching': [164], 'erential': [167, 174], 'trails': [168], 'is': [170], 'crucial': [171], 'cryptanalysis.': [175]}",2019,"['Computer science', 'Computer security', 'Big data', 'Cloud computing', 'Ransomware', 'Cryptography', 'Malware', 'Analytics', 'The Internet', 'Cryptanalysis', 'Intrusion detection system', 'Hacker', 'Encryption', 'Honeypot', 'Data science', 'World Wide Web', 'Data mining', 'Operating system']","has gone through a rapid development in today's internet connected world.With the wide application of the booming technologies such as the Internet of ings (IoT) and the cloud computing, huge amount of data are generated and collected.While the data can be used to better serve the corresponding business needs, they also pose big challenges for the cyber security and privacy protection.It becomes very di cult if not impossible to discover the malicious behavior among the big data in real time.us, this gives rise to the cyber security solutions which are driven by AI-based technologies, such as machine learning, statistical inference, big data analysis, deep learning, and so on.AIdriven cyber security analytics has already found its applications in the next generation rewall which includes the automatic intrusion detection system, encrypted tra c classi cation, malicious software detection, and so on.In the area of cryptography, AI-driven solution starts to help the researchers optimize the algorithm design and can largely reduce the cryptanalysis e ort such as searching the di erential trails which is crucial in di erential cryptanalysis."
https://openalex.org/W4396833342,"""I know even if you don't tell me"": Understanding Users' Privacy Preferences Regarding AI-based Inferences of Sensitive Information for Personalization","{'Personalization': [0], 'improves': [1], 'user': [2], 'experience': [3], 'by': [4], 'tailoring': [5], 'interactions': [6], 'relevant': [7], 'to': [8, 75, 113, 122], 'each': [9], ""user's"": [10], 'background': [11], 'and': [12, 48, 83, 102, 107, 124], 'preferences.': [13], 'However,': [14], 'personalization': [15], 'requires': [16], 'information': [17], 'about': [18, 64, 105], 'users': [19], 'that': [20, 94, 111], 'platforms': [21], 'often': [22], 'collect': [23], 'without': [24], 'their': [25, 28, 45, 73, 80, 109], 'awareness': [26, 88], 'or': [27], 'enthusiastic': [29], 'consent.': [30], 'Here,': [31], 'we': [32], 'study': [33], 'how': [34], 'the': [35, 77], 'transparency': [36], 'of': [37, 89, 135], 'AI': [38, 138], 'inferences': [39, 104, 123], 'on': [40], ""users'"": [41], 'personal': [42], 'data': [43, 52, 82, 86], 'affects': [44], 'privacy': [46, 120], 'decisions': [47, 99], 'sentiments': [49], 'when': [50], 'sharing': [51], 'for': [53, 66, 100, 108, 128], 'personalization.': [54], 'We': [55], 'conducted': [56], 'two': [57], 'experiments': [58], 'where': [59], 'participants': [60, 95], '(N=877)': [61], 'answered': [62], 'questions': [63], 'themselves': [65], 'personalized': [67], 'public': [68], 'arts': [69], 'recommendations.': [70], 'Participants': [71], 'indicated': [72], 'consent': [74, 98, 131], 'let': [76], 'system': [78], 'use': [79], 'inferred': [81], 'explicitly': [84], 'provided': [85], 'after': [87], 'inferences.': [90, 115, 139], 'Our': [91, 116], 'results': [92], 'show': [93], 'chose': [96], 'restrictive': [97], 'sensitive': [101], 'incorrect': [103], 'them': [106], 'answers': [110], 'led': [112], 'such': [114], 'findings': [117], 'expand': [118], 'existing': [119, 130], 'discourse': [121], 'inform': [125], 'future': [126], 'directions': [127], 'shaping': [129], 'mechanisms': [132], 'in': [133], 'light': [134], 'increasingly': [136], 'pervasive': [137]}",2024,"['Personalization', 'Internet privacy', 'Transparency (behavior)', 'Computer science', 'Information privacy', 'User modeling', 'Personally identifiable information', 'World Wide Web', 'User interface', 'Computer security', 'Operating system']","Personalization improves user experience by tailoring interactions relevant to each user's background and preferences. However, personalization requires information about users that platforms often collect without their awareness or their enthusiastic consent. Here, we study how the transparency of AI inferences on users' personal data affects their privacy decisions and sentiments when sharing data for personalization. We conducted two experiments where participants (N=877) answered questions about themselves for personalized public arts recommendations. Participants indicated their consent to let the system use their inferred data and explicitly provided data after awareness of inferences. Our results show that participants chose restrictive consent decisions for sensitive and incorrect inferences about them and for their answers that led to such inferences. Our findings expand existing privacy discourse to inferences and inform future directions for shaping existing consent mechanisms in light of increasingly pervasive AI inferences."
https://openalex.org/W4389677173,Data Privacy and Ethical Concerns in AI and Computer Science,"{'As': [0], 'Artificial': [1], 'Intelligence': [2], 'and': [3, 9, 25, 46, 51, 58, 64, 69, 86, 97, 109, 114, 124, 137, 155, 162, 179, 211, 217, 225, 229], 'Computer': [4], 'Science': [5], 'continue': [6], 'to': [7, 12, 33, 83, 127, 140, 158, 194, 215], 'grow': [8], 'turn': [10, 31], 'out': [11, 32], 'be': [13, 34, 128], 'a': [14, 72, 205], 'part': [15], 'of': [16, 120, 165, 173, 186, 189, 222], 'our': [17], 'day': [18, 20], 'by': [19], 'lives,': [21], 'the': [22, 55, 79, 103, 125, 134, 166, 171, 175, 187, 219], 'ethical': [23, 80, 135], 'issues': [24, 26, 221], 'about': [27, 78, 102, 106], 'information': [28], 'privateness': [29, 45, 108, 224], 'have': [30], 'extra': [35], 'essential.': [36], 'This': [37], 'evaluation': [38], 'paper': [39, 76, 131, 203], 'thoroughly': [40], 'seems': [41], 'at': [42], 'how': [43, 110], 'statistics': [44], 'ethics': [47, 226], 'join': [48], 'in': [49, 116, 118, 182, 227], 'AI': [50, 63, 84, 113, 228], 'CS.': [52], 'It': [53, 89, 146, 168], 'explores': [54], 'demanding': [56], 'situations': [57], 'possibilities': [59], 'that': [60], 'arise': [61], 'when': [62], 'CS': [65], 'technology': [66], 'acquire,': [67], 'system,': [68], 'observe': [70], 'quite': [71], 'few': [73], 'data.': [74], 'The': [75, 130], 'talks': [77, 101], 'problems': [81], 'due': [82], 'algorithms': [85], 'self-running': [87], 'structures.': [88], 'looks': [90], 'into': [91], 'troubles': [92], 'like': [93, 150], 'bias,': [94], 'transparency,': [95], 'accountability,': [96], 'fairness.': [98], 'Additionally,': [99], 'it': [100], 'converting': [104], 'guidelines': [105, 138], 'facts': [107, 223], 'they': [111], 'affect': [112], 'CS,': [115], 'particular': [117], 'phrases': [119], 'records': [121], 'protection,': [122], 'consent,': [123], 'proper': [126], 'forgotten.': [129], 'also': [132], 'discusses': [133], 'frameworks': [136], 'created': [139], 'cope': [141], 'with': [142, 170], 'those': [143], 'complicated': [144, 220], 'issues.': [145], 'uses': [147], 'numerous': [148], 'resources': [149], 'research': [151], 'articles,': [152], 'case': [153], 'research,': [154], 'coverage': [156], 'files': [157], 'offer': [159], 'an': [160], 'updated': [161], 'multidisciplinary': [163], 'view': [164], 'subject.': [167], 'ends': [169], 'aid': [172], 'citing': [174], 'brand': [176], 'new': [177], 'developments': [178], 'future': [180], 'directions': [181], 'this': [183, 200], 'subject,': [184], 'inclusive': [185], 'importance': [188], 'different': [190], 'professionals': [191], 'working': [192], 'collectively': [193], 'address': [195, 218], 'these': [196], 'challenges.': [197], 'In': [198], 'quick,': [199], 'thorough': [201], 'assessment': [202], 'is': [204], 'beneficial': [206], 'resource': [207], 'for': [208], 'researchers,': [209], 'policymakers,': [210], 'practitioners': [212], 'who': [213], 'need': [214], 'recognize': [216], 'pc': [230], 'technological': [231], 'know-how.': [232]}",2022,"['Transparency (behavior)', 'Engineering ethics', 'Subject (documents)', 'Multidisciplinary approach', 'Accountability', 'Ethical issues', 'Computer science', 'Information ethics', 'Public relations', 'Political science', 'Artificial intelligence', 'Engineering', 'Computer security', 'Law', 'World Wide Web']","As Artificial Intelligence and Computer Science continue to grow and turn out to be a part of our day by day lives, the ethical issues and issues about information privateness have turn out to be extra essential. This evaluation paper thoroughly seems at how statistics privateness and ethics join in AI and CS. It explores the demanding situations and possibilities that arise when AI and CS technology acquire, system, and observe quite a few data. The paper talks about the ethical problems due to AI algorithms and self-running structures. It looks into troubles like bias, transparency, accountability, and fairness. Additionally, it talks about the converting guidelines about facts privateness and how they affect AI and CS, in particular in phrases of records protection, consent, and the proper to be forgotten. The paper also discusses the ethical frameworks and guidelines created to cope with those complicated issues. It uses numerous resources like research articles, case research, and coverage files to offer an updated and multidisciplinary view of the subject. It ends with the aid of citing the brand new developments and future directions in this subject, inclusive of the importance of different professionals working collectively to address these challenges. In quick, this thorough assessment paper is a beneficial resource for researchers, policymakers, and practitioners who need to recognize and address the complicated issues of facts privateness and ethics in AI and pc technological know-how."
https://openalex.org/W3137650920,Problematic Interactions between AI and Health Privacy,"{'The': [0, 106, 129, 155], 'interaction': [1], 'of': [2, 26, 63, 74, 79, 85, 89, 99, 131, 172], 'artificial': [3, 27], 'intelligence': [4, 28], '(AI)': [5], 'and': [6, 41, 77, 96, 116, 144, 165], 'health': [7, 34, 44, 56, 68, 104, 136, 150, 156, 167], 'privacy': [8, 35, 57, 94, 112, 123], 'is': [9, 108, 145], 'a': [10, 82, 160], 'two-way': [11], 'street.': [12], 'Both': [13], 'directions': [14], 'are': [15, 114], 'problematic.': [16], 'This': [17], 'Essay': [18], 'makes': [19], 'two': [20], 'main': [21], 'points.': [22], 'First,': [23], 'the': [24, 30, 51, 61, 67, 87, 97, 166, 170], 'advent': [25], 'weakens': [29], 'legal': [31, 52], 'protections': [32, 113], 'for': [33], 'by': [36, 42, 70, 81], 'rendering': [37], 'deidentification': [38], 'less': [39], 'reliable': [40], 'inferring': [43], 'information': [45], 'from': [46], 'unprotected': [47], 'data': [48, 80, 90, 101], 'sources.': [49], 'Second,': [50], 'rules': [53, 119], 'that': [54], 'protect': [55, 122, 153], 'nonetheless': [58], 'detrimentally': [59], 'impact': [60], 'development': [62], 'AI': [64], 'used': [65], 'in': [66, 135], 'system': [69, 157, 168], 'introducing': [71], 'multiple': [72], 'sources': [73], 'bias:': [75], 'collection': [76, 91], 'sharing': [78], 'small': [83], 'set': [84], 'entities,': [86], 'process': [88], 'while': [92], 'following': [93], 'rules,': [95], 'use': [98], 'non-health': [100], 'to': [102, 121, 147], 'infer': [103], 'information.': [105], 'result': [107], 'an': [109], 'unfortunate': [110], 'anti-synergy:': [111], 'weak': [115], 'illusory,': [117], 'but': [118], 'meant': [120], 'hinder': [124], 'other': [125], 'socially': [126], 'valuable': [127], 'goals.': [128], 'state': [130], 'affairs': [132], 'creates': [133], 'biases': [134], 'AI,': [137], 'privileges': [138], 'commercial': [139], 'research': [140], 'over': [141], 'academic': [142], 'research,': [143], 'ill-suited': [146], 'either': [148], 'improve': [149], 'care': [151], 'or': [152], 'patients.': [154], 'deeply': [158], 'needs': [159], 'new': [161], 'bargain': [162], 'between': [163], 'patients': [164], 'about': [169], 'uses': [171], 'patient': [173], 'data.': [174]}",2021,"['Internet privacy', 'Health care', 'Information privacy', 'Privacy by Design', 'Rendering (computer graphics)', 'Data collection', 'Computer science', 'Process (computing)', 'Computer security', 'Business', 'Data science', 'Public relations', 'Political science', 'Sociology', 'Artificial intelligence', 'Law', 'Social science', 'Operating system']","The interaction of artificial intelligence (AI) and health privacy is a two-way street. Both directions are problematic. This Essay makes two main points. First, the advent of artificial intelligence weakens the legal protections for health privacy by rendering deidentification less reliable and by inferring health information from unprotected data sources. Second, the legal rules that protect health privacy nonetheless detrimentally impact the development of AI used in the health system by introducing multiple sources of bias: collection and sharing of data by a small set of entities, the process of data collection while following privacy rules, and the use of non-health data to infer health information. The result is an unfortunate anti-synergy: privacy protections are weak and illusory, but rules meant to protect privacy hinder other socially valuable goals. The state of affairs creates biases in health AI, privileges commercial research over academic research, and is ill-suited to either improve health care or protect patients. The health system deeply needs a new bargain between patients and the health system about the uses of patient data."
https://openalex.org/W4402191830,"Incorporating Privacy by Design Principles in the Modification of AI Systems in Preventing Breaches across Multiple Environments, Including Public Cloud, Private Cloud, and On-prem","{'The': [0, 85, 204], 'rapid': [1], 'integration': [2], 'of': [3, 28, 53, 96, 112, 169, 198], 'artificial': [4], 'intelligence': [5], '(AI)': [6], 'across': [7, 79], 'various': [8], 'sectors': [9], 'has': [10], 'significantly': [11], 'amplified': [12], 'privacy': [13, 31, 97, 216, 228, 241], 'concerns,': [14], 'particularly': [15, 179], 'with': [16, 176], 'the': [17, 44, 51, 102, 141, 149, 170, 191, 196, 219], 'growing': [18], 'reliance': [19], 'on': [20], 'cloud': [21], 'environments.': [22, 84], 'Existing': [23], 'methods': [24], 'often': [25], 'fall': [26], 'short': [27], 'effectively': [29], 'preventing': [30], 'breaches': [32, 78], 'due': [33], 'to': [34, 69, 76, 92, 164, 189, 239], 'inadequate': [35], 'risk': [36], 'assessment': [37], 'and': [38, 82, 110, 135, 173, 182, 194, 218, 234], 'mitigation': [39], 'strategies.': [40], 'These': [41, 186], 'limitations': [42], 'highlight': [43], 'necessity': [45], 'for': [46, 143, 213], 'more': [47], 'robust': [48, 215], 'solutions,': [49], 'indicating': [50, 140], 'importance': [52], 'Privacy': [54], 'by': [55, 64], 'Design': [56], '(PbD)': [57], 'principles.': [58], 'This': [59], 'study': [60, 153, 205, 220], 'addresses': [61], 'these': [62], 'gaps': [63], 'proposing': [65], 'a': [66, 124, 161, 166], 'comprehensive': [67, 227], 'approach': [68], 'incorporating': [70], 'PbD': [71, 136, 177, 199, 209], 'principles': [72, 210], 'into': [73], 'AI': [74], 'systems': [75], 'prevent': [77], 'public,': [80], 'private,': [81], 'on-prem': [83], 'proposed': [86], 'work': [87], 'utilizes': [88], 'logistic': [89], 'regression': [90], 'analysis': [91, 163], 'identify': [93], 'significant': [94], 'predictors': [95], 'breaches,': [98], 'revealing': [99], 'that': [100, 207], 'both': [101], 'environment': [103], '(B': [104, 114], '=': [105, 115, 129], '-1.142,': [106], 'p': [107, 117], '&lt;': [108, 118], '.001)': [109], 'severity': [111], 'vulnerabilities': [113], '0.932,': [116], '.01)': [119], 'play': [120], 'crucial': [121], 'roles.': [122], 'Additionally,': [123], 'strong': [125], 'positive': [126], 'correlation': [127], '(r': [128], '0.791)': [130], 'between': [131], 'breach': [132, 224], 'detection': [133, 145, 225], 'rates': [134], 'effectiveness': [137, 197], 'is': [138, 211], 'observed,': [139], 'need': [142], 'enhanced': [144], 'mechanisms.': [146], 'To': [147], 'support': [148], 'empirical': [150, 192], 'findings,': [151], 'this': [152], 'also': [154], 'reviews': [155], 'existing': [156, 202], 'case': [157], 'studies.': [158], 'It': [159], 'conducts': [160], 'thematic': [162], 'provide': [165], 'deeper': [167], 'understanding': [168], 'practical': [171], 'challenges': [172], 'solutions': [174], 'associated': [175], 'implementation,': [178], 'in': [180, 236], 'healthcare': [181], 'smart': [183], 'city': [184], 'applications.': [185], 'analyses': [187], 'serve': [188], 'supplement': [190], 'evidence': [193], 'demonstrate': [195], 'over': [200], 'other': [201], 'methods.': [203], 'concludes': [206], 'implementing': [208], 'critical': [212], 'achieving': [214], 'protection,': [217], 'recommends': [221], 'prioritizing': [222], 'advanced': [223], 'mechanisms,': [226], 'impact': [229], 'assessments,': [230], 'continuous': [231], 'stakeholder': [232], 'engagement,': [233], 'investment': [235], 'privacy-enhancing': [237], 'technologies': [238], 'address': [240], 'risks': [242], 'effectively.': [243]}",2024,"['Cloud computing', 'Computer security', 'Internet privacy', 'Computer science', 'Business', 'Operating system']","The rapid integration of artificial intelligence (AI) across various sectors has significantly amplified privacy concerns, particularly with the growing reliance on cloud environments. Existing methods often fall short of effectively preventing privacy breaches due to inadequate risk assessment and mitigation strategies. These limitations highlight the necessity for more robust solutions, indicating the importance of Privacy by Design (PbD) principles. This study addresses these gaps by proposing a comprehensive approach to incorporating PbD principles into AI systems to prevent breaches across public, private, and on-prem environments. The proposed work utilizes logistic regression analysis to identify significant predictors of privacy breaches, revealing that both the environment (B = -1.142, p &lt; .001) and severity of vulnerabilities (B = 0.932, p &lt; .01) play crucial roles. Additionally, a strong positive correlation (r = 0.791) between breach detection rates and PbD effectiveness is observed, indicating the need for enhanced detection mechanisms. To support the empirical findings, this study also reviews existing case studies. It conducts a thematic analysis to provide a deeper understanding of the practical challenges and solutions associated with PbD implementation, particularly in healthcare and smart city applications. These analyses serve to supplement the empirical evidence and demonstrate the effectiveness of PbD over other existing methods. The study concludes that implementing PbD principles is critical for achieving robust privacy protection, and the study recommends prioritizing advanced breach detection mechanisms, comprehensive privacy impact assessments, continuous stakeholder engagement, and investment in privacy-enhancing technologies to address privacy risks effectively."
https://openalex.org/W4327810303,Exploring the Relevance of Data Privacy-Enhancing Technologies for AI Governance Use Cases,"{'The': [0], 'development': [1], 'of': [2, 56, 100], 'privacy-enhancing': [3], 'technologies': [4], 'has': [5], 'made': [6], 'immense': [7], 'progress': [8], 'in': [9, 16, 59, 68, 76, 88, 120], 'reducing': [10], 'trade-offs': [11], 'between': [12, 102], 'privacy': [13], 'and': [14, 19, 40, 65, 132], 'performance': [15], 'data': [17], 'exchange': [18], 'analysis.': [20], 'Similar': [21], 'tools': [22], 'for': [23, 29, 81], 'structured': [24], 'transparency': [25], 'could': [26], 'be': [27, 73], 'useful': [28, 45], 'AI': [30, 50, 83, 105, 121], 'governance': [31, 51, 84, 106, 122], 'by': [32], 'offering': [33], 'capabilities': [34], 'such': [35], 'as': [36, 53, 70, 95, 123], 'external': [37], 'scrutiny,': [38], 'auditing,': [39], 'source': [41], 'verification.': [42], 'It': [43], 'is': [44, 112], 'to': [46, 61, 115], 'view': [47], 'these': [48, 103, 118, 127], 'different': [49, 104], 'objectives': [52], 'a': [54, 96, 124], 'system': [55, 94], 'information': [57], 'flows': [58], 'order': [60], 'avoid': [62], 'partial': [63], 'solutions': [64, 107], 'significant': [66, 74], 'gaps': [67], 'governance,': [69], 'there': [71], 'may': [72], 'overlap': [75], 'the': [77, 82, 93, 98], 'software': [78], 'stacks': [79], 'needed': [80], 'use': [85], 'cases': [86], 'mentioned': [87], 'this': [89], 'text.': [90], 'When': [91], 'viewing': [92], 'whole,': [97], 'importance': [99], 'interoperability': [101], 'becomes': [108], 'clear.': [109], 'Therefore,': [110], 'it': [111], 'imminently': [113], 'important': [114], 'look': [116], 'at': [117], 'problems': [119], 'system,': [125], 'before': [126], 'standards,': [128], 'auditing': [129], 'procedures,': [130], 'software,': [131], 'norms': [133], 'settle': [134], 'into': [135], 'place.': [136]}",2023,"['Corporate governance', 'Transparency (behavior)', 'Scrutiny', 'Audit', 'Interoperability', 'Relevance (law)', 'Order (exchange)', 'Computer science', 'Data governance', 'Software', 'Information governance', 'Knowledge management', 'Business', 'Computer security', 'Process management', 'Accounting', 'Data science', 'Information system', 'Political science', 'World Wide Web', 'Data quality', 'Law', 'Management information systems', 'Metric (unit)', 'Marketing', 'Programming language', 'Finance']","The development of privacy-enhancing technologies has made immense progress in reducing trade-offs between privacy and performance in data exchange and analysis. Similar tools for structured transparency could be useful for AI governance by offering capabilities such as external scrutiny, auditing, and source verification. It is useful to view these different AI governance objectives as a system of information flows in order to avoid partial solutions and significant gaps in governance, as there may be significant overlap in the software stacks needed for the AI governance use cases mentioned in this text. When viewing the system as a whole, the importance of interoperability between these different AI governance solutions becomes clear. Therefore, it is imminently important to look at these problems in AI governance as a system, before these standards, auditing procedures, software, and norms settle into place."
https://openalex.org/W4401035306,AI-driven anonymization: Protecting personal data privacy while leveraging machine learning,"{'AbstractThe': [0], 'development': [1], 'of': [2, 25, 33, 45, 91, 109], 'artificial': [3], 'intelligence': [4, 58], 'has': [5, 12, 52], 'significantly': [6], 'transformed': [7], ""people's"": [8], 'lives.': [9], 'However,': [10], 'it': [11], 'also': [13, 118], 'posed': [14], 'a': [15, 54], 'significant': [16], 'threat': [17], 'to': [18, 41, 64, 126, 140], 'privacy': [19, 86, 102, 113, 127, 145], 'and': [20, 31, 36, 62, 67, 75, 88, 104, 128, 135, 147], 'security,': [21], 'with': [22], 'numerous': [23], 'instances': [24], 'personal': [26, 46, 69, 84, 100, 129, 143], 'information': [27, 47], 'being': [28], 'exposed': [29], 'online': [30], 'reports': [32], 'criminal': [34], 'attacks': [35], 'theft.': [37], 'Consequently,': [38], 'the': [39, 89, 107], 'need': [40], 'achieve': [42], 'intelligent': [43], 'protection': [44, 87, 103, 114], 'through': [48, 106], 'machine': [49, 110, 123], 'learning': [50, 124], 'algorithms': [51, 61], 'become': [53], 'paramount': [55], 'concern.': [56], 'Artificial': [57], 'leverages': [59], 'advanced': [60], 'technologies': [63], 'effectively': [65], 'encrypt': [66], 'anonymize': [68], 'data,': [70], 'enabling': [71], 'valuable': [72], 'data': [73, 85, 101, 130, 144], 'analysis': [74], 'utilization': [76], 'while': [77], 'safeguarding': [78], 'privacy.': [79], 'This': [80], 'paper': [81, 117], 'focuses': [82], 'on': [83], 'promotion': [90], 'anonymity': [92], 'as': [93], 'its': [94], 'core': [95], 'research': [96], 'objectives.': [97], 'It': [98], 'achieves': [99], 'detection': [105, 146], 'use': [108], ""learning's"": [111], 'differential': [112], 'algorithm.': [115], 'The': [116], 'addresses': [119], 'existing': [120], 'challenges': [121], 'in': [122], 'related': [125], 'protection,': [131], 'offers': [132], 'improvement': [133], 'suggestions,': [134], 'analyzes': [136], 'factors': [137], 'impacting': [138], 'datasets': [139], 'enable': [141], 'timely': [142], 'protection.': [148]}",2024,"['Computer science', 'Privacy protection', 'Internet privacy', 'Information privacy', 'Data anonymization', 'Computer security', 'Artificial intelligence', 'Machine learning']","AbstractThe development of artificial intelligence has significantly transformed people's lives. However, it has also posed a significant threat to privacy and security, with numerous instances of personal information being exposed online and reports of criminal attacks and theft. Consequently, the need to achieve intelligent protection of personal information through machine learning algorithms has become a paramount concern. Artificial intelligence leverages advanced algorithms and technologies to effectively encrypt and anonymize personal data, enabling valuable data analysis and utilization while safeguarding privacy. This paper focuses on personal data privacy protection and the promotion of anonymity as its core research objectives. It achieves personal data privacy protection and detection through the use of machine learning's differential privacy protection algorithm. The paper also addresses existing challenges in machine learning related to privacy and personal data protection, offers improvement suggestions, and analyzes factors impacting datasets to enable timely personal data privacy detection and protection."
https://openalex.org/W4409382126,"Ethical and Legal Considerations of AI in IT Project Management: Addressing AI Biases, Data Privacy, and Governance","{'As': [0], 'Artificial': [1], 'Intelligence': [2], '(AI)': [3], 'continues': [4], 'to': [5, 92, 126], 'reshape': [6], 'the': [7, 107, 117, 149], 'IT': [8, 101], 'project': [9, 47, 102, 162], 'management': [10, 48, 163], 'field,': [11], 'ethical': [12], 'and': [13, 29, 42, 59, 86, 97, 121, 135, 156], 'legal': [14, 119], 'issues': [15], 'are': [16, 90], 'emerging': [17], 'as': [18, 83], 'increasingly': [19], 'important.': [20], 'AI-powered': [21, 44], 'tools': [22], 'boost': [23], 'productivity': [24], 'via': [25], 'automation,': [26], 'predictive': [27], 'analytics,': [28], 'decision': [30], 'support;': [31], 'simultaneously,': [32], 'they': [33], 'also': [34], 'introduce': [35], 'risks': [36, 109], 'associated': [37], 'with': [38, 77], 'bias,': [39], 'data': [40, 70, 79, 133], 'privacy,': [41, 134], 'governance.': [43], 'biases': [45, 128], 'in': [46, 52, 75, 100, 113, 130, 159], 'algorithms': [49], 'can': [50, 146], 'result': [51], 'unequal': [53], 'distribution': [54], 'of': [55, 69, 110, 139, 151], 'resources,': [56], 'discriminatory': [57], 'decision-making,': [58], 'unforeseen': [60], 'outcomes.': [61], 'In': [62], 'addition,': [63], ""AI's"": [64], 'reliance': [65], 'on': [66, 124], 'vast': [67], 'volumes': [68], 'raises': [71], 'privacy': [72], 'concerns,': [73], 'particularly': [74], 'complying': [76], 'global': [78], 'protection': [80], 'laws': [81], 'such': [82], 'GDPR,': [84], 'CCPA,': [85], 'HIPAA.': [87], 'Governance': [88], 'frameworks': [89], 'needed': [91], 'render': [93], 'AI': [94, 152], 'transparent,': [95], 'responsible,': [96], 'ethically': [98, 147], 'applied': [99], 'management.': [103], 'This': [104], 'article': [105], 'explores': [106], 'possible': [108], 'artificial': [111], 'intelligence': [112], 'managing': [114], 'projects,': [115], 'examines': [116], 'existing': [118], 'frameworks,': [120], 'provides': [122], 'recommendations': [123], 'how': [125], 'mitigate': [127], 'embedded': [129], 'AI,': [131], 'protect': [132], 'institute': [136], 'effective': [137], 'governance': [138], 'AI.': [140], 'By': [141], 'addressing': [142], 'these': [143], 'issues,': [144], 'organizations': [145], 'leverage': [148], 'power': [150], 'while': [153], 'maintaining': [154], 'compliance': [155], 'fostering': [157], 'trust': [158], 'information': [160], 'technology': [161], 'processes.': [164]}",2025,"['Data governance', 'Corporate governance', 'Business', 'Political science', 'Information privacy', 'Data Protection Act 1998', 'Internet privacy', 'Engineering ethics', 'Public relations', 'Sociology', 'Psychology', 'Knowledge management', 'Computer science', 'Engineering', 'Law', 'Data quality', 'Metric (unit)', 'Finance', 'Marketing']","As Artificial Intelligence (AI) continues to reshape the IT project management field, ethical and legal issues are emerging as increasingly important. AI-powered tools boost productivity via automation, predictive analytics, and decision support; simultaneously, they also introduce risks associated with bias, data privacy, and governance. AI-powered biases in project management algorithms can result in unequal distribution of resources, discriminatory decision-making, and unforeseen outcomes. In addition, AI's reliance on vast volumes of data raises privacy concerns, particularly in complying with global data protection laws such as GDPR, CCPA, and HIPAA. Governance frameworks are needed to render AI transparent, responsible, and ethically applied in IT project management. This article explores the possible risks of artificial intelligence in managing projects, examines the existing legal frameworks, and provides recommendations on how to mitigate biases embedded in AI, protect data privacy, and institute effective governance of AI. By addressing these issues, organizations can ethically leverage the power of AI while maintaining compliance and fostering trust in information technology project management processes."
https://openalex.org/W2949019824,Privacy-preserving Crowd-guided AI Decision-making in Ethical Dilemmas,"{'With': [0], 'the': [1, 57, 70, 86, 119, 161, 164, 175, 184, 189, 223], 'rapid': [2], 'development': [3], 'of': [4, 88, 121, 130, 163, 191, 229], 'artificial': [5], 'intelligence': [6], '(AI),': [7], 'ethical': [8, 41, 59, 78, 115], 'issues\\nsurrounding': [9], 'AI': [10, 79, 112], 'have': [11, 45], 'attracted': [12], 'increasing': [13], 'attention.': [14], 'In': [15, 104], 'particular,': [16], 'autonomous\\nvehicles': [17], 'may': [18], 'face': [19], 'moral': [20, 91], 'dilemmas': [21], 'in': [22, 30, 48, 114, 142, 198], 'accident': [23], 'scenarios,': [24, 61], 'such': [25, 40, 81, 199], 'as': [26], 'staying': [27], 'the\\ncourse': [28], 'resulting': [29, 141], 'hurting': [31], 'pedestrians': [32], 'or': [33], 'swerving': [34], 'leading': [35], 'to': [36, 68, 154, 187], 'hurting\\npassengers.': [37], 'To': [38], 'investigate': [39], 'dilemmas,': [42], 'recent': [43], 'studies': [44], 'adopted\\npreference': [46], 'aggregation,': [47], 'which': [49], 'each': [50, 203], 'voter': [51, 204], 'expresses': [52], 'her/his': [53, 206], 'preferences': [54, 67, 92], 'over\\ndecisions': [55], 'for': [56, 76], 'possible': [58], 'dilemma': [60], 'and': [62, 126, 137, 170, 182, 195, 218], 'a': [63, 74, 108, 178, 200, 210], 'centralized': [64], 'system\\naggregates': [65], 'these': [66, 156], 'obtain': [69], 'winning': [71], 'decision.': [72], 'Although': [73], 'useful\\nmethodology': [75], 'building': [77], 'systems,': [80], 'an': [82], 'approach': [83, 225], 'can': [84, 98, 226], 'potentially\\nviolate': [85], 'privacy': [87, 123, 125, 131, 135, 180, 190, 212], 'voters': [89], 'since': [90], 'are': [93, 172], 'sensitive': [94], 'information\\nand': [95], 'their': [96], 'disclosure': [97], 'be': [99], 'exploited': [100], 'by': [101], 'malicious': [102], 'parties.': [103], 'this': [105], 'paper,': [106], 'we\\nreport': [107], 'first-of-its-kind': [109], 'privacy-preserving': [110], 'crowd-guided': [111], 'decision-making\\napproach': [113], 'dilemmas.': [116], 'We': [117], 'adopt': [118], 'notion': [120], 'differential': [122], 'to\\nquantify': [124], 'consider': [127], 'four': [128, 143], 'granularities': [129], 'protection': [132, 136], 'by\\ntaking': [133], 'voter-/record-level': [134], 'centralized/distributed\\nperturbation': [138], 'into': [139], 'account,': [140], 'approaches': [144], 'VLCP,': [145], 'RLCP,': [146], 'VLDP,': [147], 'and\\nRLDP.': [148], 'Moreover,': [149], 'we': [150], 'propose': [151], 'different': [152], 'algorithms': [153], 'achieve': [155, 227], 'privacy\\nprotection': [157], 'granularities,': [158], 'while': [159, 232], 'retaining': [160], 'accuracy': [162], 'learned': [165], 'moral\\npreference': [166, 208], 'model.': [167], 'Specifically,': [168], 'VLCP': [169], 'RLCP': [171], 'implemented': [173], 'with': [174, 209], 'data\\naggregator': [176], 'setting': [177], 'universal': [179], 'parameter': [181], 'perturbing': [183], 'averaged\\nmoral': [185], 'preference': [186, 230], 'protect': [188], ""voters'"": [192], 'data.': [193], 'VLDP': [194], 'RLDP': [196], 'are\\nimplemented': [197], 'way': [201], 'that': [202, 222], 'perturbs': [205], 'local': [207], 'personalized': [211], 'parameter.': [213], 'Extensive': [214], 'experiments': [215], 'on': [216], 'both\\nsynthetic': [217], 'real': [219], 'data': [220], 'demonstrate': [221], 'proposed': [224], 'high\\naccuracy': [228], 'aggregation': [231], 'protecting': [233], 'individual': [234], ""voter's"": [235], 'privacy.\\n': [236]}",2019,[],"With the rapid development of artificial intelligence (AI), ethical issues\nsurrounding AI have attracted increasing attention. In particular, autonomous\nvehicles may face moral dilemmas in accident scenarios, such as staying the\ncourse resulting in hurting pedestrians or swerving leading to hurting\npassengers. To investigate such ethical dilemmas, recent studies have adopted\npreference aggregation, in which each voter expresses her/his preferences over\ndecisions for the possible ethical dilemma scenarios, and a centralized system\naggregates these preferences to obtain the winning decision. Although a useful\nmethodology for building ethical AI systems, such an approach can potentially\nviolate the privacy of voters since moral preferences are sensitive information\nand their disclosure can be exploited by malicious parties. In this paper, we\nreport a first-of-its-kind privacy-preserving crowd-guided AI decision-making\napproach in ethical dilemmas. We adopt the notion of differential privacy to\nquantify privacy and consider four granularities of privacy protection by\ntaking voter-/record-level privacy protection and centralized/distributed\nperturbation into account, resulting in four approaches VLCP, RLCP, VLDP, and\nRLDP. Moreover, we propose different algorithms to achieve these privacy\nprotection granularities, while retaining the accuracy of the learned moral\npreference model. Specifically, VLCP and RLCP are implemented with the data\naggregator setting a universal privacy parameter and perturbing the averaged\nmoral preference to protect the privacy of voters' data. VLDP and RLDP are\nimplemented in such a way that each voter perturbs her/his local moral\npreference with a personalized privacy parameter. Extensive experiments on both\nsynthetic and real data demonstrate that the proposed approach can achieve high\naccuracy of preference aggregation while protecting individual voter's privacy.\n"
https://openalex.org/W2991703064,"Emergent AI, Social Robots and the Law: Security, Privacy and Policy Issues","{'The': [0], 'rapid': [1], 'growth': [2], 'of': [3, 12, 70, 73, 89, 106, 121, 152, 184, 187, 197, 209, 241], 'AI': [4, 51], 'systems': [5, 38, 52, 133], 'has': [6, 115], 'implications': [7], 'on': [8, 166], 'a': [9, 19, 34, 142, 149, 195, 225, 233], 'wide': [10], 'variety': [11], 'fields.': [13], 'It': [14], 'can': [15, 78], 'prove': [16], 'to': [17, 21, 32, 172, 218], 'be': [18, 95], 'boon': [20], 'disparate': [22], 'fields': [23], 'such': [24], 'as': [25, 230, 232], 'healthcare,': [26], 'education,': [27], 'global': [28], 'logistics': [29], 'and': [30, 48, 55, 67, 81, 126, 177, 212, 214], 'transportation,': [31], 'name': [33], 'few.': [35], 'However,': [36], 'these': [37, 74, 90, 107, 129, 132, 185, 219], 'will': [39], 'also': [40], 'bring': [41], 'forth': [42], 'far-reaching': [43], 'changes': [44], 'in': [45, 155], 'employment,': [46], 'economy': [47], 'security.': [49], 'As': [50], 'gain': [53], 'acceptance': [54], 'become': [56], 'more': [57], 'commonplace,': [58], 'certain': [59], 'critical': [60], 'questions': [61, 146, 154, 169], 'arise:': [62], 'What': [63, 85, 97, 109, 135], 'are': [64, 98, 110, 147], 'the': [65, 71, 87, 99, 104, 111, 118, 137, 167, 173, 198, 206, 228, 242], 'legal': [66, 168, 204], 'security': [68], 'ramifications': [69], 'use': [72, 79, 105], 'new': [75], 'technologies?': [76, 108], 'Who': [77, 114], 'them,': [80], 'under': [82], 'what': [83], 'circumstances?': [84], 'is': [86, 124, 136, 141], 'safety': [88], 'systems?': [91, 130], 'Should': [92], 'their': [93], 'commercialization': [94], 'regulated?': [96], 'privacy': [100, 211], 'issues': [101, 208], 'associated': [102, 207], 'with': [103, 194, 224], 'ethical': [112], 'considerations?': [113], 'responsibility': [116], 'for': [117, 236], 'large': [119], 'amounts': [120], 'data': [122], 'that': [123, 170, 180], 'collected': [125], 'manipulated': [127], 'by': [128], 'Could': [131], 'fail?': [134], 'recourse': [138], 'if': [139], 'there': [140], 'system': [143], 'failure?': [144], 'These': [145], 'but': [148], 'small': [150], 'subset': [151], 'possible': [153], 'this': [156, 161], 'key': [157], 'emerging': [158], 'field.': [159], 'In': [160], 'paper,': [162], 'we': [163, 222], 'focus': [164], 'primarily': [165], 'relate': [171], 'security,': [174, 210], 'privacy,': [175], 'ethical,': [176], 'policy': [178], 'considerations': [179], 'emerge': [181], 'from': [182], 'one': [183], 'types': [186], 'technologies,': [188], 'namely': [189], 'social': [190], 'robots.': [191], 'We': [192], 'begin': [193], 'history': [196], 'field,': [199], 'then': [200], 'go': [201], 'deeper': [202], 'into': [203], 'issues,': [205], 'ethics,': [213], 'consider': [215], 'some': [216, 240], 'solutions': [217], 'issues.': [220], 'Finally,': [221], 'conclude': [223], 'look': [226], 'at': [227], 'future': [229, 237], 'well': [231], 'modest': [234], 'proposal': [235], 'research': [238], 'addressing': [239], 'challenges': [243], 'listed.': [244]}",2017,"['Variety (cybernetics)', 'Commercialization', 'Information privacy', 'Internet privacy', 'Field (mathematics)', 'Privacy by Design', 'Emerging technologies', 'Computer security', 'Privacy law', 'Business', 'Engineering ethics', 'Political science', 'Public relations', 'Computer science', 'Privacy policy', 'Law', 'Engineering', 'Artificial intelligence', 'Pure mathematics', 'Mathematics']","The rapid growth of AI systems has implications on a wide variety of fields. It can prove to be a boon to disparate fields such as healthcare, education, global logistics and transportation, to name a few. However, these systems will also bring forth far-reaching changes in employment, economy and security. As AI systems gain acceptance and become more commonplace, certain critical questions arise: What are the legal and security ramifications of the use of these new technologies? Who can use them, and under what circumstances? What is the safety of these systems? Should their commercialization be regulated? What are the privacy issues associated with the use of these technologies? What are the ethical considerations? Who has responsibility for the large amounts of data that is collected and manipulated by these systems? Could these systems fail? What is the recourse if there is a system failure? These questions are but a small subset of possible questions in this key emerging field. In this paper, we focus primarily on the legal questions that relate to the security, privacy, ethical, and policy considerations that emerge from one of these types of technologies, namely social robots. We begin with a history of the field, then go deeper into legal issues, the associated issues of security, privacy and ethics, and consider some solutions to these issues. Finally, we conclude with a look at the future as well as a modest proposal for future research addressing some of the challenges listed."
https://openalex.org/W4390366811,The Future of AI in IoT: Emerging Trends in Intelligent Data Analysis and Privacy Protection,"{'This': [0], 'paper': [1, 42], 'explores': [2], 'the': [3, 11, 61, 81, 88, 107], 'dynamic': [4], 'intersection': [5], 'of': [6, 13, 63], 'Artificial': [7], 'Intelligence': [8], '(AI)': [9], 'and': [10, 24, 36, 54, 74, 98, 118], 'Internet': [12], 'Things': [14], '(IoT),': [15], 'focusing': [16], 'on': [17], 'emerging': [18], 'trends': [19], 'in': [20, 38, 46, 66, 83, 127], 'intelligent': [21], 'data': [22, 48, 94], 'analysis': [23], 'privacy': [25, 64, 117], 'protection.': [26], 'Employing': [27], 'a': [28, 122], 'systematic': [29], 'literature': [30], 'review,': [31], 'we': [32], 'analyze': [33], 'recent': [34], 'advancements': [35, 115], 'challenges': [37, 82], 'AI-IoT': [39], 'integration.': [40], 'The': [41, 77, 104], 'highlights': [43], 'key': [44], 'developments': [45], 'sensor': [47], 'anomaly': [49], 'detection,': [50], 'AI-driven': [51], 'big-data': [52], 'analytics,': [53], 'IoT-based': [55], 'communication': [56], 'techniques.': [57], 'It': [58], 'delves': [59], 'into': [60], 'complexities': [62], 'protection': [65], 'IoT,': [67, 86], 'examining': [68], 'innovative': [69], 'solutions': [70, 111], 'like': [71, 102], 'federated': [72], 'learning': [73], 'blockchain': [75], 'technologies.': [76], 'study': [78], 'also': [79], 'addresses': [80], 'AI': [84], 'for': [85, 109, 124], 'prioritizing': [87], 'most': [89], 'pressing': [90], 'issues': [91], 'such': [92], 'as': [93], 'security,': [95], 'ethical': [96], 'implementation,': [97], 'compliance': [99], 'with': [100, 116], 'regulations': [101], 'GDPR.': [103], 'research': [105], 'underscores': [106], 'need': [108], 'adaptable': [110], 'that': [112], 'balance': [113], 'technological': [114], 'security': [119], 'considerations,': [120], 'setting': [121], 'path': [123], 'future': [125], 'exploration': [126], 'AI-empowered': [128], 'IoT': [129], 'applications.': [130]}",2023,"['Internet of Things', 'Computer science', 'Big data', 'Computer security', 'Intersection (aeronautics)', 'Analytics', 'Data science', 'Key (lock)', 'Information privacy', 'Engineering', 'Data mining', 'Aerospace engineering']","This paper explores the dynamic intersection of Artificial Intelligence (AI) and the Internet of Things (IoT), focusing on emerging trends in intelligent data analysis and privacy protection. Employing a systematic literature review, we analyze recent advancements and challenges in AI-IoT integration. The paper highlights key developments in sensor data anomaly detection, AI-driven big-data analytics, and IoT-based communication techniques. It delves into the complexities of privacy protection in IoT, examining innovative solutions like federated learning and blockchain technologies. The study also addresses the challenges in AI for IoT, prioritizing the most pressing issues such as data security, ethical implementation, and compliance with regulations like GDPR. The research underscores the need for adaptable solutions that balance technological advancements with privacy and security considerations, setting a path for future exploration in AI-empowered IoT applications."
https://openalex.org/W4408999320,A Privacy-Preserving and Attack-Aware AI Approach for High-Risk Healthcare Systems Under the EU AI Act,"{'Artificial': [0], 'intelligence': [1], '(AI)': [2], 'has': [3], 'significantly': [4], 'driven': [5], 'advancement': [6], 'in': [7, 189], 'the': [8, 13, 53, 67, 85, 158], 'healthcare': [9, 62, 95, 190], 'field': [10], 'by': [11, 194], 'enabling': [12], 'integration': [14], 'of': [15, 42, 69, 84, 160, 199], 'highly': [16], 'advanced': [17], 'algorithms': [18], 'to': [19, 39, 61, 73, 117, 141, 178], 'improve': [20, 143], 'diagnostics,': [21], 'patient': [22], 'surveillance,': [23], 'and': [24, 33, 45, 76, 99, 138, 145, 172, 203], 'treatment': [25], 'planning.': [26], 'Nonetheless,': [27], 'dependence': [28], 'on': [29, 150, 164], 'sensitive': [30], 'health': [31], 'data': [32, 120], 'automated': [34], 'decision-making': [35], 'exposes': [36], 'such': [37], 'systems': [38, 188], 'escalating': [40], 'risks': [41], 'privacy': [43, 87, 201], 'breaches': [44], 'is': [46], 'under': [47, 191], 'rigorous': [48], 'regulatory': [49, 173], 'oversight.': [50], 'In': [51], 'particular,': [52], 'EU': [54, 134], 'AI': [55, 58, 135, 187], 'Act': [56, 136], 'classifies': [57], 'uses': [59], 'pertaining': [60], 'as': [63, 180], '“high-risk”,': [64], 'thus': [65], 'requiring': [66], 'application': [68], 'strict': [70], 'provisions': [71], 'related': [72], 'transparency,': [74], 'safety,': [75], 'privacy.': [77], 'This': [78, 175], 'paper': [79], 'presents': [80], 'a': [81, 105, 181, 205], 'comprehensive': [82], 'overview': [83], 'diverse': [86], 'attacks': [88], 'that': [89, 109, 155], 'can': [90], 'target': [91], 'machine': [92], 'learning': [93, 112], '(ML)-based': [94], 'systems,': [96], 'including': [97], 'data-centric': [98], 'model-centric': [100], 'attacks.': [101], 'We': [102, 126, 147], 'then': [103], 'propose': [104], 'novel': [106], 'privacy-preserving': [107], 'architecture': [108], 'integrates': [110], 'federated': [111], 'with': [113, 133], 'secure': [114], 'computation': [115], 'protocols': [116], 'minimally': [118], 'expose': [119], 'while': [121], 'ensuring': [122], 'strong': [123], 'model': [124], 'performance.': [125], 'outline': [127], 'an': [128, 151, 196], 'ongoing': [129], 'monitoring': [130], 'mechanism': [131], 'compliant': [132], 'specifications': [137], 'GDPR': [139], 'standards': [140], 'further': [142, 148], 'trust': [144], 'compliance.': [146], 'elaborate': [149], 'independent': [152], 'adaptive': [153], 'algorithm': [154], 'automatically': [156], 'tunes': [157], 'level': [159], 'cryptographic': [161], 'protection': [162], 'based': [163], 'contextual': [165], 'factors': [166], 'like': [167], 'risk': [168], 'severity,': [169], 'computational': [170], 'capacity,': [171], 'environment.': [174], 'research': [176], 'aims': [177], 'serve': [179], 'blueprint': [182], 'for': [183], 'designing': [184], 'trustworthy,': [185], 'high-risk': [186], 'emerging': [192], 'regulations': [193], 'providing': [195], 'in-depth': [197], 'review': [198], 'ML-specific': [200], 'threats': [202], 'proposing': [204], 'holistic': [206], 'technical': [207], 'solution.': [208]}",2025,"['Health care', 'Computer science', 'Computer security', 'Internet privacy', 'Political science', 'Law']","Artificial intelligence (AI) has significantly driven advancement in the healthcare field by enabling the integration of highly advanced algorithms to improve diagnostics, patient surveillance, and treatment planning. Nonetheless, dependence on sensitive health data and automated decision-making exposes such systems to escalating risks of privacy breaches and is under rigorous regulatory oversight. In particular, the EU AI Act classifies AI uses pertaining to healthcare as “high-risk”, thus requiring the application of strict provisions related to transparency, safety, and privacy. This paper presents a comprehensive overview of the diverse privacy attacks that can target machine learning (ML)-based healthcare systems, including data-centric and model-centric attacks. We then propose a novel privacy-preserving architecture that integrates federated learning with secure computation protocols to minimally expose data while ensuring strong model performance. We outline an ongoing monitoring mechanism compliant with EU AI Act specifications and GDPR standards to further improve trust and compliance. We further elaborate on an independent adaptive algorithm that automatically tunes the level of cryptographic protection based on contextual factors like risk severity, computational capacity, and regulatory environment. This research aims to serve as a blueprint for designing trustworthy, high-risk AI systems in healthcare under emerging regulations by providing an in-depth review of ML-specific privacy threats and proposing a holistic technical solution."
https://openalex.org/W4362480911,Robust AI: security and privacy issues in machine learning,"{'Machine': [0], 'learning': [1, 51, 126, 259, 410, 1083, 1110, 1193, 1203, 1224, 1255, 1271, 1289, 1332], 'based': [2, 80, 997, 1121], 'decision': [3], 'making': [4, 37, 1330], 'can': [5, 52, 76, 397, 1131, 1162, 1263], 'be': [6, 34, 53, 78, 111, 199, 499, 1116], 'adopted': [7], 'in': [8, 49, 113, 133, 210, 294, 329, 398, 454, 501, 648, 704, 901, 945, 980, 988, 1015, 1066, 1069, 1085, 1101, 1107, 1163, 1247, 1310, 1322, 1342], 'practice': [9], 'as': [10, 30, 55, 486, 505, 869, 916, 918, 925, 982, 1031, 1146], 'a': [11, 56, 463, 770, 834, 852, 877, 920, 966, 1176, 1190, 1286, 1326, 1339], 'driver': [12], 'of': [13, 27, 47, 58, 84, 139, 168, 188, 235, 257, 285, 304, 326, 336, 352, 355, 422, 432, 456, 462, 492, 503, 513, 519, 545, 550, 584, 602, 614, 646, 670, 676, 679, 695, 724, 731, 791, 810, 879, 884, 911, 940, 948, 1004, 1006, 1023, 1038, 1072, 1169, 1200, 1214, 1221, 1237, 1252, 1278, 1280, 1307, 1314, 1345], 'most': [14, 713], 'applications': [15, 1034, 1220], 'only': [16, 480, 987], 'when': [17], 'there': [18], 'are': [19, 98, 484, 605, 1096, 1325], 'strong': [20], 'guarantees': [21], 'on': [22, 81, 357, 406, 629, 642, 833, 1010, 1055, 1098, 1122, 1230, 1244, 1269], 'its': [23], 'reliability.': [24], 'The': [25, 106, 163, 340, 582, 632, 892, 1013, 1058], 'trust': [26], 'those': [28, 85, 239, 481], 'involved': [29], 'stakeholders': [31], 'needs': [32], 'to': [33, 110, 122, 158, 185, 223, 263, 363, 384, 434, 466, 479, 498, 588, 599, 618, 643, 689, 716, 758, 765, 775, 784, 806, 895, 907, 957, 1000, 1019, 1061, 1136, 1150, 1166, 1182, 1294, 1301, 1312], 'established': [35], 'for': [36, 100, 275, 320, 420, 447, 664, 707, 846, 855, 873, 943, 1029, 1205], 'it': [38, 75, 214, 736, 797, 926], 'more': [39, 777, 1334], 'ubiquitous': [40], 'and': [41, 62, 103, 130, 147, 160, 172, 180, 194, 238, 246, 277, 307, 334, 365, 367, 370, 378, 396, 425, 427, 471, 475, 496, 548, 571, 639, 692, 710, 734, 756, 779, 816, 876, 932, 974, 995, 1051, 1088, 1120, 1212, 1226, 1262, 1336], 'acceptable.': [42], 'In': [43, 268, 673, 739], 'general,': [44], 'the': [45, 82, 116, 124, 169, 173, 192, 195, 203, 227, 233, 250, 269, 279, 283, 290, 296, 302, 317, 324, 330, 353, 389, 407, 416, 423, 430, 443, 457, 468, 493, 510, 517, 523, 555, 558, 561, 568, 572, 575, 578, 593, 600, 644, 649, 665, 671, 674, 680, 696, 702, 712, 722, 729, 746, 749, 761, 766, 781, 787, 792, 808, 814, 820, 827, 857, 870, 874, 885, 889, 903, 912, 938, 946, 971, 1002, 1021, 1024, 1036, 1067, 1070, 1081, 1102, 1113, 1123, 1128, 1139, 1147, 1151, 1167, 1170, 1198, 1201, 1228, 1238, 1250, 1253, 1270, 1281, 1295, 1299, 1302, 1315, 1319, 1343], 'idea': [46, 341, 633, 939], 'reliability': [48, 65], 'machine': [50, 125, 258, 409, 1331], 'construed': [54], 'sum': [57], 'two': [59, 541], 'parts,': [60, 543], 'Robustness': [61, 132, 153], 'Resilience.': [63], 'Since': [64], 'is': [66, 93, 108, 154, 191, 215, 265, 382, 557, 563, 574, 617, 634, 721, 804, 867, 894, 915, 985, 1018, 1027, 1044, 1052, 1064, 1105, 1175, 1195, 1337], 'concerned': [67], 'about': [68, 249], 'providing': [69], 'assurances': [70], 'against': [71, 95, 136], 'malfunctions': [72], 'or': [73, 449, 843, 1154], 'errors,': [74], 'also': [77, 401, 936], 'classified': [79], 'types': [83], 'errors.': [86, 105], 'This': [87, 488, 1042, 1174, 1304], 'thesis': [88, 1324], 'deals': [89], 'with': [90, 115, 156, 242, 261, 863, 888, 1047, 1266], 'Robustness,': [91], 'that': [92, 190, 202, 225, 240, 289, 308, 387, 436, 483, 554, 560, 595, 620, 669, 748, 800, 838, 866, 897, 969, 979, 1026, 1142, 1240, 1291], 'robustness': [94, 107], 'attacks,': [96, 140], 'which': [97, 295, 577, 914], 'responsible': [99], 'generating': [101, 856], 'intentional': [102], 'malicious': [104, 1260], 'therefore': [109, 414, 622, 1338], 'studied': [112, 155, 1218], 'conjunction': [114], 'mechanisms': [117], 'an': [118, 392, 403, 898, 1076], 'adversary': [119, 750, 899, 1077], 'may': [120, 198, 1078], 'adopt': [121], 'disrupt': [123], 'application.': [127], '&#13;\\nTo': [128], 'investigate': [129, 728], 'understand': [131], 'ML': [134, 164, 229], 'algorithms': [135], 'various': [137], 'forms': [138], 'we': [141, 177, 272, 459, 508, 536, 652, 660, 685, 744, 831, 1008, 1284], 'break': [142, 735], 'down': [143, 624], 'each': [144, 421], 'into': [145, 540, 1080], 'components': [146, 187], 'consider': [148, 178, 219, 273], 'all': [149, 220], 'possible': [150, 1097], 'combinations.': [151], 'Typically,': [152], 'respect': [157, 262], 'security': [159, 179, 236, 264, 274, 511], 'privacy': [161, 181, 647, 663, 678, 1005, 1022, 1056, 1178], 'aspects.': [162], 'algorithm': [165, 1194], 'itself': [166, 231, 1257], 'comprises': [167], 'trained': [170, 338, 681], 'model': [171, 193, 922, 1114, 1135], 'training': [174, 919, 930, 1152, 1172], 'data.': [175, 196, 524, 672, 1041], 'Therefore,': [176], 'related': [182, 222], 'problems': [183, 209, 221], 'pertaining': [184], 'both': [186], 'ML,': [189], 'It': [197, 381], 'noted': [200], 'here': [201, 386], 'work': [204, 616, 1017], 'touches': [205], 'upon': [206], 'many': [207, 1032, 1108], 'important': [208, 383], 'this': [211, 321, 350, 585, 615, 732, 801, 817, 840, 983, 1016, 1062, 1158, 1184, 1323], 'regard,': [212], 'but': [213, 441, 604], 'not': [216, 597, 1053, 1242], 'exhaustive.': [217], 'We': [218, 287, 314, 347, 413, 525, 700, 727, 768, 935, 1180, 1217], 'attacks': [224, 243, 281, 515, 1095, 1268], 'jeopardize': [226], 'fundamental': [228, 408], 'task': [230, 411, 470, 601], 'under': [232, 252], 'umbrella': [234], 'issues': [237], 'deal': [241], 'leaking': [244], 'secret': [245], 'sensitive': [247, 565, 1040], 'information': [248, 445], 'system': [251, 495], 'privacy.': [253], '&#13;\\nThe': [254], 'primary': [255], 'vulnerability': [256, 626, 818], 'models': [260, 299, 944, 990, 1099, 1239], 'adversarial': [266, 280, 305, 312, 358, 375, 439, 472, 514, 532, 579, 610, 625, 861], 'attacks.': [267], 'first': [270], 'part,': [271, 651], 'models,': [276, 666, 684, 697], 'study': [278, 509], 'through': [282, 636], 'lens': [284], 'dimensionality.': [286], 'assert': [288], 'high': [291, 331], 'dimensional': [292, 332], 'landscape': [293], 'neural': [297, 682, 708, 847, 886, 993], 'network': [298, 683, 887, 904], 'optimize': [300], 'facilitate': [301], 'generation': [303, 360], 'examples': [306, 862], 'dimensionality': [309, 356, 379, 390, 477], 'reduction': [310, 418, 478], 'enhances': [311], 'robustness.': [313], 'have': [315, 348, 402, 526, 537, 1259], 'explored': [316], 'mathematical': [318], 'background': [319], 'proposition,': [322], 'studying': [323], 'properties': [325], 'data': [327, 762, 1025, 1043], 'distributions': [328], 'spaces': [333], 'nature': [335], 'such': [337, 553, 1222, 1274], 'manifolds.': [339], 'has': [342, 391, 751], 'been': [343, 1144], 'empirically': [344], 'justified': [345], 'thereafter.': [346], 'extended': [349, 937], 'notion': [351], 'influence': [354], 'sample': [359, 473], 'from': [361, 516, 760, 813, 923], 'images': [362, 539, 594], 'videos': [364], 'text': [366, 953, 961], 'provided': [368], 'practical': [369, 1033, 1219], 'efficient': [371], 'solutions': [372], 'by': [373, 668, 1127, 1197, 1233, 1298], 'leveraging': [374], 'samples': [376, 482, 759, 778, 783, 931, 973, 976], 'detection': [377, 451, 474], 'reduction.': [380], 'note': [385], 'reducing': [388], 'additional': [393], 'computational': [394], 'cost': [395], 'some': [399, 655], 'cases': [400], 'adverse': [404], 'effect': [405], 'itself.': [412], 'optimise': [415], 'dimension': [417], 'operation': [419], 'tasks': [424], 'use-cases': [426], 'carefully': [428], 'choose': [429], 'amount': [431], 'variability': [433], 'preserve': [435], 'effectively': [437], 'eliminates': [438], 'noise': [440], 'retains': [442], 'meaningful': [444], 'necessary': [446, 1340], 'classification': [448, 569, 603, 630], 'object': [450], 'etc.': [452], 'Additionally,': [453, 1075], 'one': [455, 1130], 'works,': [458], 'make': [460, 745], 'use': [461, 780], 'parallel': [464], 'channel': [465], 'run': [467], 'classifications': [469], 'apply': [476], 'detected': [485], 'adversarial.': [487], 'significantly': [489], 'improves': [490], 'efficiency': [491], 'overall': [494, 1282], 'proves': [497], 'beneficial': [500], 'terms': [502], 'accuracy': [504], 'well.': [506], '&#13;\\nThereafter,': [507], 'flaw': [512], 'perspective': [518], 'vulnerable': [520], 'features': [521], 'within': [522, 531, 592, 960], 'analysed': [527], 'spatially': [528], 'correlated': [529], 'patterns': [530], 'images.': [533], 'Class': [534], 'wise,': [535], 'split': [538], 'key': [542, 872], 'Region': [544, 549], 'Importance': [546], '(RoI)': [547], 'Attack': [551], '(RoA),': [552], 'RoI': [556], 'region': [559, 576], 'classifier': [562], 'particularly': [564, 952], 'to,': [566], 'during': [567], 'task,': [570], 'RoA': [573], 'attack': [580], 'modifies.': [581], 'goal': [583, 893], 'exercise': [586], 'was': [587], 'figure': [589], 'out': [590, 613, 799, 1157], 'areas': [591], 'do': [596, 1241], 'contribute': [598], 'adversarially': [606], 'vulnerable.': [607], 'Our': [608], 'proposed': [609, 1285], 'defence': [611], 'mechanism': [612, 854], 'neutralize': [619], 'region,': [621], 'bringing': [623], 'without': [627], 'compromising': [628], 'accuracy.': [631, 1245], 'demonstrated': [635], 'benchmarking': [637], 'datasets': [638], 'models.': [640, 794, 998], '&#13;\\nMoving': [641], 'aspect': [645, 1003], 'second': [650], 'look': [653, 661], 'at': [654, 662], 'very': [656, 752], 'different': [657, 1048], 'problems.': [658], 'First,': [659], 'followed': [667], 'context': [675], 'preserving': [677], 'direct': [686], 'our': [687, 740], 'attention': [688], 'protecting': [690], 'ownership': [691], 'IP': [693], 'rights': [694], 'using': [698, 719, 737, 849, 963, 1186], 'watermarking.': [699], 'review': [701], 'state-of-the-art': [703], 'watermarking': [705, 836, 845, 942], 'schemes': [706], 'networks': [709, 848, 994], 'select': [711], 'appropriate': [714], 'ones': [715], 'study.': [717], 'Watermarking': [718], 'backdooring': [720], 'scheme': [723, 733, 822, 837, 968], 'choice': [725], 'here.': [726], 'vulnerabilities': [730], 'synthesis.': [738], 'proposition': [741], 'titled': [742], 'Re-Markable,': [743], 'assumption': [747], 'limited': [753], 'compute': [754, 933], 'power': [755], 'access': [757], 'distribution': [763], 'relevant': [764], 'task.': [767], 'train': [769, 1132], 'GAN': [771], '(Generative': [772], 'Adversarial': [773], 'Network)': [774], 'synthesize': [776], 'synthesized': [782], 're-train': [785, 908], 'just': [786], 'fully': [788], 'connected': [789], 'layers': [790], 'watermarked': [793], 'As': [795], 'demonstrated,': [796], 'turns': [798], 'minimal': [802], 'computation': [803], 'sufficient': [805], 'eliminate': [807], 'presence': [809], 'embedded': [811, 890], 'watermarks': [812, 959], 'model,': [815, 913, 1129], 'makes': [819], 'existing': [821], 'extremely': [823], 'unreliable.': [824], 'To': [825], 'solve': [826, 1183], 'problem': [828, 1063, 1185], 'thus': [829], 'discovered,': [830], 'worked': [832], 'robust': [835, 844, 941, 1287, 1335], 'overcomes': [839], 'vulnerability.': [841], 'ROWBACK,': [842], 'backdooring,': [850, 964], 'uses': [851, 965], 'redesigned': [853], 'Trigger': [858, 972], 'Set': [859], '(using': [860], 'explicit': [864], 'labelling)': [865], 'used': [868, 1028, 1196], 'private': [871, 1192], 'watermarking,': [875], 'method': [878], 'explicitly': [880], 'marking': [881, 967], 'every': [882, 909], 'layer': [883, 910], 'watermarks.': [891], 'ensure': [896], 'interested': [900], 'extracting': [902], 'would': [905, 927], 'need': [906], 'good': [917], 'fresh': [921], 'scratch': [924], 'require': [928], 'extensive': [929], 'power.': [934], 'domain': [947], 'natural': [949, 1106], 'language': [950], 'processing,': [951], 'classifiers.': [954], 'TextBack,': [955], 'designed': [956], 'embed': [958], 'classifiers': [962], 'involves': [970], 'clean': [975], 'together,': [977], 'unlike': [978], 'images,': [981], 'property': [984], 'observed': [986], 'sequential': [989], 'like': [991], 'recurrent': [992], 'LSTM': [996], '&#13;\\nFinally,': [999], 'cover': [1001], 'data,': [1007], 'focus': [1009], 'collaborative': [1011, 1223], 'ML.': [1012], 'motivation': [1014], 'protect': [1020], 'training,': [1030, 1208], 'necessitate': [1035], 'usage': [1037], 'highly': [1039], 'decentralised,': [1045], 'resides': [1046], 'non-collocated': [1049], 'entities,': [1050], 'sharable': [1054], 'grounds.': [1057], 'straight-forward': [1059], 'solution': [1060], 'available': [1065], 'literature': [1068], 'form': [1071], 'Federated': [1073], 'Learning.': [1074], 'tap': [1079], 'federated': [1082, 1109, 1202, 1254, 1288], 'infrastructure': [1084, 1204], 'multiple': [1086, 1118, 1160], 'ways': [1087], 'extract': [1089], 'information.': [1090], 'For': [1091], 'example,': [1092], 'Membership': [1093], 'Inference': [1094], 'deployed': [1100, 1227], 'cloud': [1103], '(which': [1104], 'setups),': [1111], 'wherein': [1112], 'could': [1115, 1258], 'queried': [1117], 'times': [1119, 1161], 'output': [1124], 'probabilities': [1125], 'returned': [1126], 'another': [1133, 1248], 'separate': [1134], 'know': [1137], 'if': [1138], 'particular': [1140], 'input': [1141], 'had': [1143], 'sent': [1145, 1297], 'query': [1148], 'belonged': [1149], 'set': [1153], 'not.': [1155], 'Carrying': [1156], 'process': [1159], 'theory': [1164], 'lead': [1165], 'reverse-engineering': [1168], 'entire': [1171], 'set.': [1173], 'serious': [1177], 'violation.': [1179], 'attempted': [1181], 'Differential': [1187], 'Privacy,': [1188], 'where': [1189], 'differentially': [1191], 'participants': [1199, 1251], 'their': [1206], 'local': [1207], 'involving': [1209], 'gradient': [1210], 'trimming': [1211], 'addition': [1213], 'sampled': [1215], 'noise.': [1216], 'systems': [1225, 1333], 'framework': [1229], 'edge': [1231], 'devices,': [1232], 'creating': [1234], 'light-weight': [1235], 'versions': [1236], 'compromise': [1243], 'Similarly,': [1246], 'use-case,': [1249], 'setup': [1256], 'intentions': [1261], 'come': [1264], 'up': [1265, 1311], 'sabotaging': [1267], 'framework.': [1272], 'Considering': [1273], 'potential': [1275], 'single': [1276], 'points': [1277], 'failures': [1279], 'system,': [1283], 'infrastructure,': [1290], 'assigns': [1292], 'coefficients': [1293], 'updates': [1296], 'clients': [1300], 'server.': [1303], 'takes': [1305], 'care': [1306], 'tolerating': [1308], 'faults': [1309], '50%': [1313], 'clients’': [1316], 'failures.': [1317], '&#13;\\nOverall,': [1318], 'ideas': [1320], 'discussed': [1321], 'major': [1327], 'step': [1328, 1341], 'towards': [1329], 'direction': [1344], 'reliable': [1346], 'AI.': [1347]}",2023,"['Computer science', 'Computer security', 'Internet privacy', 'Data science', 'Artificial intelligence']","Machine learning based decision making can be adopted in practice as a driver of most applications only when there are strong guarantees on its reliability. The trust of those involved as stakeholders needs to be established for making it more ubiquitous and acceptable. In general, the idea of reliability in machine learning can be construed as a sum of two parts, Robustness and Resilience. Since reliability is concerned about providing assurances against malfunctions or errors, it can also be classified based on the types of those errors. This thesis deals with Robustness, that is robustness against attacks, which are responsible for generating intentional and malicious errors. The robustness is therefore to be studied in conjunction with the mechanisms an adversary may adopt to disrupt the machine learning application. &#13;\nTo investigate and understand Robustness in ML algorithms against various forms of attacks, we break down each into components and consider all possible combinations. Typically, Robustness is studied with respect to security and privacy aspects. The ML algorithm itself comprises of the trained model and the training data. Therefore, we consider security and privacy related problems pertaining to both components of ML, that is the model and the data. It may be noted here that the work touches upon many important problems in this regard, but it is not exhaustive. We consider all problems related to attacks that jeopardize the fundamental ML task itself under the umbrella of security issues and those that deal with attacks leaking secret and sensitive information about the system under privacy. &#13;\nThe primary vulnerability of machine learning models with respect to security is adversarial attacks. In the first part, we consider security for models, and study the adversarial attacks through the lens of dimensionality. We assert that the high dimensional landscape in which the neural network models optimize facilitate the generation of adversarial examples and that dimensionality reduction enhances adversarial robustness. We have explored the mathematical background for this proposition, studying the properties of data distributions in the high dimensional spaces and nature of such trained manifolds. The idea has been empirically justified thereafter. We have extended this notion of the influence of dimensionality on adversarial sample generation from images to videos and text and provided practical and efficient solutions by leveraging adversarial samples detection and dimensionality reduction. It is important to note here that reducing the dimensionality has an additional computational cost and can in some cases also have an adverse effect on the fundamental machine learning task itself. We therefore optimise the dimension reduction operation for each of the tasks and use-cases and carefully choose the amount of variability to preserve that effectively eliminates adversarial noise but retains the meaningful information necessary for classification or object detection etc. Additionally, in one of the works, we make use of a parallel channel to run the classifications task and adversarial sample detection and apply dimensionality reduction to only those samples that are detected as adversarial. This significantly improves efficiency of the overall system and proves to be beneficial in terms of accuracy as well. &#13;\nThereafter, we study the security flaw of adversarial attacks from the perspective of vulnerable features within the data. We have analysed spatially correlated patterns within adversarial images. Class wise, we have split images into two key parts, Region of Importance (RoI) and Region of Attack (RoA), such that the RoI is the region that the classifier is particularly sensitive to, during the classification task, and the RoA is the region which the adversarial attack modifies. The goal of this exercise was to figure out areas within the images that do not contribute to the task of classification but are adversarially vulnerable. Our proposed adversarial defence mechanism out of this work is to neutralize that region, therefore bringing down adversarial vulnerability without compromising on classification accuracy. The idea is demonstrated through benchmarking datasets and models. &#13;\nMoving on to the aspect of privacy in the second part, we look at some very different problems. First, we look at privacy for the models, followed by that of the data. In the context of preserving privacy of the trained neural network models, we direct our attention to protecting ownership and IP rights of the models, using watermarking. We review the state-of-the-art in watermarking schemes for neural networks and select the most appropriate ones to study. Watermarking using backdooring is the scheme of choice here. We investigate the vulnerabilities of this scheme and break it using synthesis. In our proposition titled Re-Markable, we make the assumption that the adversary has very limited compute power and access to samples from the data distribution relevant to the task. We train a GAN (Generative Adversarial Network) to synthesize more samples and use the synthesized samples to re-train just the fully connected layers of the watermarked models. As demonstrated, it turns out that this minimal computation is sufficient to eliminate the presence of embedded watermarks from the model, and this vulnerability makes the existing scheme extremely unreliable. To solve the problem thus discovered, we worked on a robust watermarking scheme that overcomes this vulnerability. ROWBACK, or robust watermarking for neural networks using backdooring, uses a redesigned mechanism for generating the Trigger Set (using adversarial examples with explicit labelling) that is used as the private key for the watermarking, and a method of explicitly marking every layer of the neural network with the embedded watermarks. The goal is to ensure that an adversary interested in extracting the network would need to re-train every layer of the model, which is as good as training a fresh model from scratch as it would require extensive training samples and compute power. We also extended the idea of robust watermarking for models in the domain of natural language processing, particularly text classifiers. TextBack, designed to embed watermarks within text classifiers using backdooring, uses a marking scheme that involves the Trigger samples and clean samples together, unlike that in images, as this property is observed only in sequential models like recurrent neural networks and LSTM based models. &#13;\nFinally, to cover the aspect of privacy of data, we focus on collaborative ML. The motivation in this work is to protect the privacy of the data that is used for training, as many practical applications necessitate the usage of highly sensitive data. This data is decentralised, resides with different non-collocated entities, and is not sharable on privacy grounds. The straight-forward solution to this problem is available in the literature in the form of Federated Learning. Additionally, an adversary may tap into the federated learning infrastructure in multiple ways and extract information. For example, Membership Inference attacks are possible on models deployed in the cloud (which is natural in many federated learning setups), wherein the model could be queried multiple times and based on the output probabilities returned by the model, one can train another separate model to know if the particular input that had been sent as the query belonged to the training set or not. Carrying out this process multiple times can in theory lead to the reverse-engineering of the entire training set. This is a serious privacy violation. We attempted to solve this problem using Differential Privacy, where a differentially private learning algorithm is used by the participants of the federated learning infrastructure for their local training, involving gradient trimming and addition of sampled noise. We studied practical applications of such collaborative learning systems and deployed the framework on edge devices, by creating light-weight versions of the models that do not compromise on accuracy. Similarly, in another use-case, the participants of the federated learning setup itself could have malicious intentions and can come up with sabotaging attacks on the learning framework. Considering such potential single points of failures of the overall system, we proposed a robust federated learning infrastructure, that assigns coefficients to the updates sent by the clients to the server. This takes care of tolerating faults in up to 50% of the clients’ failures. &#13;\nOverall, the ideas discussed in this thesis are a major step towards making machine learning systems more robust and is therefore a necessary step in the direction of reliable AI."
https://openalex.org/W3170417470,AI-Enabled Automation for Completeness Checking of Privacy Policies,"{'Technological': [0], 'advances': [1], 'in': [2, 84, 175, 252, 257, 261], 'information': [3, 173], 'sharing': [4], 'have': [5], 'raised': [6], 'concerns': [7], 'about': [8, 16], 'data': [9, 20], 'protection.': [10], 'Privacy': [11], 'policies': [12, 43, 81, 177, 195], 'contain': [13], 'privacy-related': [14, 94, 131], 'requirements': [15], 'how': [17], 'the': [18, 49, 65, 75, 113, 130, 171, 183, 197, 213], 'personal': [19], 'of': [21, 67, 77, 116, 133, 142, 153, 160, 203, 212, 215, 218, 234, 238, 255], 'individuals': [22], 'will': [23], 'be': [24], 'handled': [25], 'by': [26, 156], 'an': [27, 38, 148, 253], 'organization': [28, 89], 'or': [29, 37], 'a': [30, 34, 68, 136, 140, 158, 201, 232, 242], 'software': [31, 95], 'system': [32], '(e.g.,': [33], 'web': [35], 'service': [36], 'app).': [39], 'In': [40, 105], 'Europe,': [41], 'privacy': [42, 69, 80, 117, 176, 194, 206], 'are': [44], 'subject': [45], 'to': [46, 62, 74, 128, 241], 'compliance': [47, 59], 'with': [48], 'General': [50], 'Data': [51], 'Protection': [52], 'Regulation': [53], '(GDPR).': [54], 'A': [55], 'prerequisite': [56], 'for': [57, 112], 'GDPR': [58], 'checking': [60, 99, 115], 'is': [61, 71, 100], 'verify': [63], 'whether': [64], 'content': [66, 174], 'policy': [70], 'complete': [72], 'according': [73], 'provisions': [76, 132], 'GDPR.': [78], 'Incomplete': [79], 'might': [82], 'result': [83], 'large': [85], 'fines': [86], 'on': [87, 151], 'violating': [88], 'as': [90, 92], 'well': [91], 'incomplete': [93], 'specifications.': [96], 'Manual': [97], 'completeness': [98, 114, 143, 184, 220], 'both': [101], 'time-consuming': [102], 'and': [103, 139, 164, 178, 236, 259], 'error-prone.': [104], 'this': [106], 'paper,': [107], 'we': [108, 123, 146, 169, 190], 'propose': [109], 'AI-based': [110], 'automation': [111], 'policies.': [118], 'Through': [119], 'systematic': [120], 'qualitative': [121], 'methods,': [122], 'first': [124], 'build': [125], 'two': [126], 'artifacts': [127, 155], 'characterize': [129], 'GDPR,': [134], 'namely': [135], 'conceptual': [137], 'model': [138], 'set': [141, 202], 'criteria.': [144, 185], 'Then,': [145], 'develop': [147], 'automated': [149], 'solution': [150], 'top': [152], 'these': [154], 'leveraging': [157], 'combination': [159], 'natural': [161], 'language': [162], 'processing': [163], 'supervised': [165], 'machine': [166], 'learning.': [167], 'Specifically,': [168], 'identify': [170], 'GDPR-relevant': [172], 'subsequently': [179], 'check': [180], 'them': [181], 'against': [182], 'To': [186], 'evaluate': [187], 'our': [188, 208, 249], 'approach,': [189], 'collected': [191], '234': [192], 'real': [193], 'from': [196], 'fund': [198], 'industry.': [199], 'Over': [200], '48': [204], 'unseen': [205], 'policies,': [207], 'approach': [209, 229, 250], 'detected': [210], '300': [211], 'total': [214], '334': [216], 'violations': [217], 'some': [219], 'criteria': [221], 'correctly,': [222], 'while': [223], 'producing': [224], '23': [225], 'false': [226], 'positives.': [227], 'The': [228], 'thus': [230], 'has': [231], 'precision': [233, 258], '92.9%': [235], 'recall': [237], '89.8%.': [239], 'Compared': [240], 'baseline': [243], 'that': [244], 'applies': [245], 'keyword': [246], 'search': [247], 'only,': [248], 'results': [251], 'improvement': [254], '24.5%': [256], '38%': [260], 'recall.': [262]}",2021,"['Computer science', 'Privacy policy', 'Completeness (order theory)', 'General Data Protection Regulation', 'Information privacy', 'Privacy software', 'Privacy by Design', 'Privacy law', 'Computer security', 'Data Protection Act 1998', 'Mathematical analysis', 'Mathematics']","Technological advances in information sharing have raised concerns about data protection. Privacy policies contain privacy-related requirements about how the personal data of individuals will be handled by an organization or a software system (e.g., a web service or an app). In Europe, privacy policies are subject to compliance with the General Data Protection Regulation (GDPR). A prerequisite for GDPR compliance checking is to verify whether the content of a privacy policy is complete according to the provisions of GDPR. Incomplete privacy policies might result in large fines on violating organization as well as incomplete privacy-related software specifications. Manual completeness checking is both time-consuming and error-prone. In this paper, we propose AI-based automation for the completeness checking of privacy policies. Through systematic qualitative methods, we first build two artifacts to characterize the privacy-related provisions of GDPR, namely a conceptual model and a set of completeness criteria. Then, we develop an automated solution on top of these artifacts by leveraging a combination of natural language processing and supervised machine learning. Specifically, we identify the GDPR-relevant information content in privacy policies and subsequently check them against the completeness criteria. To evaluate our approach, we collected 234 real privacy policies from the fund industry. Over a set of 48 unseen privacy policies, our approach detected 300 of the total of 334 violations of some completeness criteria correctly, while producing 23 false positives. The approach thus has a precision of 92.9% and recall of 89.8%. Compared to a baseline that applies keyword search only, our approach results in an improvement of 24.5% in precision and 38% in recall."
https://openalex.org/W3107908749,Feminist Research Ethics and Student Privacy in the Age of AI,"{'This': [0], 'article': [1, 73], 'examines': [2], 'university': [3, 48, 61, 97], 'researchers’': [4], 'capture': [5], 'of': [6, 70, 77], 'student': [7], 'images': [8], 'on': [9], 'US': [10], 'college': [11], 'campuses': [12], 'for': [13, 41, 59, 64, 85], 'training': [14], 'facial': [15], 'recognition': [16], 'technology,': [17], 'and': [18, 29, 81, 89, 108], 'situates': [19], 'this': [20], 'project': [21], 'within': [22], 'universities’': [23], 'broader': [24], 'historical': [25], 'alignment': [26], 'with': [27, 68], 'militarism': [28], 'racial': [30], 'injustice.': [31], 'It': [32], 'argues': [33], 'that': [34, 47, 100], 'feminist': [35, 94], 'STS': [36], 'ethics': [37, 63, 80, 99], 'provides': [38], 'a': [39, 65], 'framework': [40], 'not': [42], 'only': [43], 'challenging': [44], 'the': [45, 75, 102], 'ways': [46], 'research': [49, 62, 98, 105], 'inquiry': [50], 'actively': [51], 'contributes': [52], 'to': [53, 96], 'oppressive': [54], 'power': [55], 'structures,': [56], 'but': [57], 'also': [58], 'reimagining': [60], 'greater': [66], 'engagement': [67], 'questions': [69], 'justice.': [71], 'The': [72], 'identifies': [74], 'limitations': [76], 'dominant': [78], 'institutional': [79], 'privacy': [82], 'rights': [83], 'discourses': [84], 'centering': [86], 'justice': [87], 'considerations,': [88], 'instead': [90], 'outlines': [91], 'an': [92], 'intersectional': [93], 'approach': [95], 'reimagines': [101], 'relationship': [103], 'between': [104], 'processes,': [106], 'power,': [107], 'social': [109], 'impacts.': [110]}",2020,"['Injustice', 'Sociology', 'Economic Justice', 'Power (physics)', 'Social justice', 'Militarism', 'Feminism', 'Research ethics', 'Engineering ethics', 'Political science', 'Gender studies', 'Social science', 'Law', 'Politics', 'Engineering', 'Physics', 'Quantum mechanics']","This article examines university researchers’ capture of student images on US college campuses for training facial recognition technology, and situates this project within universities’ broader historical alignment with militarism and racial injustice. It argues that feminist STS ethics provides a framework for not only challenging the ways that university research inquiry actively contributes to oppressive power structures, but also for reimagining university research ethics for a greater engagement with questions of justice. The article identifies the limitations of dominant institutional ethics and privacy rights discourses for centering justice considerations, and instead outlines an intersectional feminist approach to university research ethics that reimagines the relationship between research processes, power, and social impacts."
https://openalex.org/W4404342050,Ethical AI in Retail: Consumer Privacy and Fairness,"{'The': [0, 202, 218], 'adoption': [1], 'of': [2, 24, 44, 99, 106, 119, 199], 'artificial': [3], 'intelligence': [4], '(AI)': [5], 'in': [6, 47, 121, 223, 235], 'retail': [7, 112], 'has': [8], 'significantly': [9], 'transformed': [10], 'the': [11, 21, 41, 104], 'industry,': [12], 'enabling': [13], 'more': [14], 'personalized': [15], 'services': [16], 'and': [17, 34, 60, 91, 159, 169, 173, 196, 211, 238], 'efficient': [18], 'operations.': [19], 'However,': [20], 'rapid': [22], 'implementation': [23], 'AI': [25, 45, 54, 65, 137, 154, 200, 216, 224, 236], 'technologies': [26, 55], 'raises': [27], 'ethical': [28, 42, 64, 163], 'concerns,': [29], 'particularly': [30], 'regarding': [31, 103], 'consumer': [32, 233, 240], 'privacy': [33, 168, 172], 'fairness.': [35, 170], 'This': [36], 'study': [37, 203, 219], 'aims': [38], 'to': [39, 73, 183, 229], 'analyze': [40], 'challenges': [43], 'applications': [46], 'retail,': [48], 'explore': [49], 'ways': [50], 'retailers': [51, 181, 206], 'can': [52, 155], 'implement': [53], 'ethically': [56], 'while': [57], 'remaining': [58], 'competitive,': [59], 'provide': [61], 'recommendations': [62], 'on': [63], 'practices.': [66], 'A': [67], 'descriptive': [68, 87], 'survey': [69], 'design': [70], 'was': [71, 150], 'used': [72], 'collect': [74], 'data': [75, 108, 124, 167, 193, 212, 241], 'from': [76], '300': [77], 'respondents': [78], 'across': [79], 'major': [80, 131], 'e-commerce': [81], 'platforms.': [82], 'Data': [83, 171], 'were': [84, 175], 'analyzed': [85], 'using': [86], 'statistics,': [88], 'including': [89], 'percentages': [90], 'mean': [92], 'scores.': [93], 'Findings': [94], 'shows': [95], 'a': [96, 117, 134, 188], 'high': [97], 'level': [98], 'concerns': [100, 145], 'among': [101], 'consumers': [102, 142], 'amount': [105], 'personal': [107], 'collected': [109], 'by': [110], 'AI-driven': [111], 'applications,': [113], 'with': [114], 'many': [115], 'expressing': [116], 'lack': [118], 'trust': [120], 'how': [122], 'their': [123, 185], 'is': [125, 129], 'managed.': [126], 'Also,': [127], 'fairness': [128], 'another': [130], 'issue,': [132], 'as': [133, 166, 177], 'majority': [135], 'believe': [136], 'systems': [138], 'do': [139], 'not': [140], 'treat': [141], 'equally,': [143], 'raising': [144], 'about': [146], 'algorithmic': [147], 'bias.': [148], 'It': [149], 'also': [151], 'found': [152], 'that': [153, 205], 'enhance': [156], 'business': [157], 'competitiveness': [158], 'efficiency': [160], 'without': [161], 'compromising': [162], 'principles,': [164], 'such': [165], 'transparency': [174, 222], 'highlighted': [176], 'critical': [178], 'areas': [179], 'where': [180], 'need': [182], 'focus': [184], 'efforts,': [186], 'indicating': [187], 'strong': [189], 'demand': [190], 'for': [191], 'stricter': [192], 'protection': [194, 213], 'protocols': [195], 'ongoing': [197], 'scrutiny': [198], 'systems.': [201, 217], 'concludes': [204], 'must': [207], 'prioritize': [208], 'transparency,': [209], 'fairness,': [210], 'when': [214], 'deploying': [215], 'recommends': [220], 'ensuring': [221], 'processes,': [225], 'conducting': [226], 'regular': [227], 'audits': [228], 'address': [230], 'biases,': [231], 'incorporating': [232], 'feedback': [234], 'development,': [237], 'emphasizing': [239], 'privacy.': [242]}",2024,"['Business', 'Consumer privacy', 'Internet privacy', 'Marketing', 'Advertising', 'Information privacy', 'Computer science']","The adoption of artificial intelligence (AI) in retail has significantly transformed the industry, enabling more personalized services and efficient operations. However, the rapid implementation of AI technologies raises ethical concerns, particularly regarding consumer privacy and fairness. This study aims to analyze the ethical challenges of AI applications in retail, explore ways retailers can implement AI technologies ethically while remaining competitive, and provide recommendations on ethical AI practices. A descriptive survey design was used to collect data from 300 respondents across major e-commerce platforms. Data were analyzed using descriptive statistics, including percentages and mean scores. Findings shows a high level of concerns among consumers regarding the amount of personal data collected by AI-driven retail applications, with many expressing a lack of trust in how their data is managed. Also, fairness is another major issue, as a majority believe AI systems do not treat consumers equally, raising concerns about algorithmic bias. It was also found that AI can enhance business competitiveness and efficiency without compromising ethical principles, such as data privacy and fairness. Data privacy and transparency were highlighted as critical areas where retailers need to focus their efforts, indicating a strong demand for stricter data protection protocols and ongoing scrutiny of AI systems. The study concludes that retailers must prioritize transparency, fairness, and data protection when deploying AI systems. The study recommends ensuring transparency in AI processes, conducting regular audits to address biases, incorporating consumer feedback in AI development, and emphasizing consumer data privacy."
https://openalex.org/W4387628470,Privacy Strategies for Conversational AI and their Influence on Users' Perceptions and Decision-Making,{'296': [0]},2023,"['Heuristics', 'Usability', 'Computer science', 'Internet privacy', 'Perception', 'Control (management)', 'Information privacy', 'Ask price', 'Debiasing', 'Human–computer interaction', 'Psychology', 'Social psychology', 'Artificial intelligence', 'Economics', 'Operating system', 'Economy', 'Neuroscience']",296
https://openalex.org/W4403110633,User Privacy Preservation in AI-Powered Digital Communication Systems,"{'In': [0, 149, 261], 'an': [1, 303], 'era': [2], 'dominated': [3], 'by': [4], 'AI-powered': [5, 98, 265], 'digital': [6, 99, 266, 306], 'communication': [7, 100, 242, 267], 'systems,': [8, 101, 268], 'concerns': [9], 'about': [10], 'user': [11, 29, 60, 74, 127, 155, 176, 201, 213, 227, 280, 300], 'privacy': [12, 30, 43, 104, 124, 164, 177, 228, 259, 281, 301], 'have': [13], 'taken': [14], 'center': [15], 'stage.': [16], 'This': [17, 78, 217], 'research': [18, 64, 79, 218], 'aims': [19, 65], 'to': [20, 27, 38, 66, 85, 175, 183, 226, 298], 'understand': [21], 'and': [22, 52, 54, 76, 119, 126, 139, 147, 154, 166, 195, 197, 215, 233, 245, 248, 254, 295], 'assess': [23, 67], 'the': [24, 40, 47, 56, 63, 68, 136, 142, 151, 162, 190, 198, 207, 220, 238, 249, 262, 276], 'strategies': [25, 72, 106, 140, 211], 'employed': [26], 'preserve': [28], 'in': [31, 189, 257, 302], 'such': [32], 'a': [33, 81, 158, 223, 286], 'system.': [34], 'Specifically,': [35], 'it': [36], 'seeks': [37], 'identify': [39], 'range': [41], 'of': [42, 49, 70, 123, 144, 161, 192, 209, 222, 251, 264, 279], 'preservation': [44, 105], 'methods,': [45], 'evaluate': [46], 'transparency': [48, 191], 'data': [50, 184, 193], 'collection': [51, 194], 'usage,': [53], 'analyze': [55], 'mechanisms': [57, 199], 'for': [58, 200, 240, 285], 'obtaining': [59], 'consent.': [61, 202], 'Additionally,': [62], 'impact': [69, 208], 'these': [71, 87, 210], 'on': [73, 96, 212, 275], 'trust': [75, 214], 'satisfaction.': [77, 216], 'presents': [80], 'comparative': [82, 91, 270], 'case': [83, 92, 271], 'study': [84, 93, 204, 272], 'achieve': [86], 'objectives.': [88], 'A': [89], 'qualitative': [90], 'methodology': [94], 'focused': [95], 'multiple': [97], 'comparing': [102], 'different': [103], 'across': [107], 'various': [108], 'platforms.': [109], 'Data': [110], 'was': [111], 'collected': [112], 'through': [113], 'in-depth': [114, 131], 'interviews': [115, 132], 'with': [116], 'system': [117, 246], 'developers': [118, 146, 247], 'users,': [120], 'content': [121, 152], 'analysis': [122, 153], 'policies,': [125], 'experience': [128], 'assessments.': [129], 'The': [130, 170, 203], 'provided': [133], 'insights': [134], 'into': [135], 'practical': [137], 'challenges': [138], 'from': [141, 180], 'perspective': [143], 'both': [145, 231], 'users.': [148], 'contrast,': [150], 'assessments': [156], 'offered': [157], 'comprehensive': [159], 'understanding': [160], 'implemented': [163], 'measures': [165, 297], 'their': [167], 'perceived': [168], 'effectiveness.': [169], 'findings': [171], 'reveal': [172], 'diverse': [173], 'approaches': [174], 'preservation,': [178, 229], 'ranging': [179], 'end-to-end': [181], 'encryption': [182], 'anonymization.': [185], 'Variations': [186], 'were': [187], 'observed': [188], 'usage': [196], 'also': [205], 'highlighted': [206], 'underscores': [219], 'importance': [221], 'nuanced': [224], 'approach': [225, 288], 'considering': [230], 'technical': [232, 291], 'ethical': [234, 293], 'dimensions.': [235], 'It': [236, 283], 'emphasizes': [237], 'need': [239], 'transparent': [241], 'between': [243], 'users': [244], 'role': [250], 'legal': [252], 'frameworks': [253], 'industry': [255], 'standards': [256], 'shaping': [258], 'practices.': [260], 'context': [263], 'this': [269], 'sheds': [273], 'light': [274], 'multifaceted': [277], 'landscape': [278], 'preservation.': [282], 'advocates': [284], 'holistic': [287], 'that': [289], 'combines': [290], 'safeguards,': [292], 'considerations,': [294], 'regulatory': [296], 'ensure': [299], 'increasingly': [304], 'interconnected': [305], 'world.': [307]}",2024,"['Internet privacy', 'Computer science', 'Computer security']","In an era dominated by AI-powered digital communication systems, concerns about user privacy have taken center stage. This research aims to understand and assess the strategies employed to preserve user privacy in such a system. Specifically, it seeks to identify the range of privacy preservation methods, evaluate the transparency of data collection and usage, and analyze the mechanisms for obtaining user consent. Additionally, the research aims to assess the impact of these strategies on user trust and satisfaction. This research presents a comparative case study to achieve these objectives. A qualitative comparative case study methodology focused on multiple AI-powered digital communication systems, comparing different privacy preservation strategies across various platforms. Data was collected through in-depth interviews with system developers and users, content analysis of privacy policies, and user experience assessments. The in-depth interviews provided insights into the practical challenges and strategies from the perspective of both developers and users. In contrast, the content analysis and user assessments offered a comprehensive understanding of the implemented privacy measures and their perceived effectiveness. The findings reveal diverse approaches to user privacy preservation, ranging from end-to-end encryption to data anonymization. Variations were observed in the transparency of data collection and usage and the mechanisms for user consent. The study also highlighted the impact of these strategies on user trust and satisfaction. This research underscores the importance of a nuanced approach to user privacy preservation, considering both technical and ethical dimensions. It emphasizes the need for transparent communication between users and system developers and the role of legal frameworks and industry standards in shaping privacy practices. In the context of AI-powered digital communication systems, this comparative case study sheds light on the multifaceted landscape of user privacy preservation. It advocates for a holistic approach that combines technical safeguards, ethical considerations, and regulatory measures to ensure user privacy in an increasingly interconnected digital world."
https://openalex.org/W4399850283,Synthetic and privacy-preserving traffic trace generation using generative AI models for training Network Intrusion Detection Systems,"{'Network': [0], 'Intrusion': [1], 'Detection': [2], 'Systems': [3], '(NIDS)': [4], 'are': [5, 240], 'crucial': [6], 'tools': [7], 'for': [8, 89, 137, 243, 282], 'protecting': [9], 'networked': [10], 'devices': [11], 'from': [12, 111, 170], 'cyberattacks.': [13], 'Recent': [14], 'development': [15], 'in': [16, 27, 38, 96, 187, 259, 276], 'the': [17, 41, 48, 65, 77, 138, 172, 182, 190, 251, 255, 267, 277], 'field': [18, 278], 'of': [19, 51, 58, 62, 67, 79, 106, 140, 174, 177, 184, 192, 269, 279], 'Artificial': [20], 'Intelligence': [21], '(AI)': [22], 'has': [23, 219], 'provided': [24], 'tremendous': [25], 'advantages': [26], 'implementing': [28], 'NIDSs': [29], 'able': [30], 'to': [31, 76, 189, 225, 236, 250, 265], 'monitor': [32], 'network': [33], 'traffic': [34, 84, 109, 142, 203], 'and': [35, 69, 81, 86, 119, 131, 157, 162, 181, 206, 246, 262, 272], 'block': [36], 'cyberattacks': [37], 'real-time.': [39], 'In': [40], 'literature,': [42], 'it': [43], 'is': [44, 123, 167], 'widely': [45], 'recognized': [46], 'that': [47, 239], 'effective': [49, 242], 'training': [50, 226, 245], 'a': [52, 55, 101, 126, 132, 178, 217, 220], 'NIDS': [53, 180, 218, 244], 'requires': [54], 'large': [56], 'quantity': [57], 'labeled': [59], 'traffic,': [60], 'representative': [61], 'attacks.': [63], 'Nonetheless,': [64], 'availability': [66], 'public': [68], 'abundant': [70], 'datasets': [71, 257], 'remains': [72], 'remarkably': [73], 'restricted': [74], 'due': [75], 'cost': [78], 'gathering': [80], 'labeling': [82], 'real': [83, 112, 193, 228], 'traces': [85, 110, 211, 238], 'privacy': [87], 'concerns': [88], 'sharing': [90], 'them.': [91], 'To': [92, 144], 'tackle': [93], 'these': [94], 'challenges,': [95], 'this': [97], 'paper': [98], 'we': [99, 148], 'present': [100], 'generative': [102, 215, 280], 'AI': [103, 281], 'model': [104], 'capable': [105], 'synthesizing': [107], 'anonymized': [108], 'ones,': [113], 'thus': [114], 'dealing': [115], 'with': [116, 199, 210], 'privacy,': [117], 'abundance,': [118], 'representativeness.': [120], 'The': [121, 165], 'proposal': [122], 'based': [124], 'on': [125, 227], 'Conditional': [127], 'Variational': [128], 'Autoencoder': [129], '(CVAE)': [130], 'preprocessing': [133], 'procedure': [134], 'specifically': [135], 'designed': [136], 'generation': [139], 'new': [141], 'traces.': [143], 'validate': [145], 'our': [146, 197, 214, 270], 'solution,': [147], 'conduct': [149], 'an': [150], 'extensive': [151], 'empirical': [152], 'study': [153], 'leveraging': [154], 'three': [155], 'recent': [156], 'publicly-available': [158], 'datasets,': [159], 'containing': [160], 'benign': [161], 'malicious': [163], 'traffic.': [164], 'validation': [166], 'carried': [168], 'out': [169], 'both': [171, 260], 'perspectives': [173], 'classification': [175], 'performance': [176], 'robust': [179], 'quality': [183], 'synthetic': [185, 256], 'data,': [186], 'comparison': [188], 'utilization': [191], 'data.': [194], 'We': [195, 253], 'compare': [196], 'CVAE': [198], 'two': [200], 'state-of-the-art': [201], 'AI-based': [202], 'data': [204], 'generators': [205], 'prove': [207], 'that,': [208], 'trained': [209], 'emitted': [212], 'by': [213], 'model,': [216], 'limited': [221], 'F1-score': [222], 'loss': [223], 'compared': [224], 'data;': [229], 'competing': [230], 'models': [231], 'instead': [232], 'struggle': [233], 'or': [234], 'fail': [235], 'generate': [237], 'as': [241, 247], 'statistically': [248], 'similar': [249], 'original.': [252], 'make': [254], 'available': [258], 'PCAP': [261], 'tabular': [263], 'formats,': [264], 'facilitate': [266], 'reproducibility': [268], 'findings': [271], 'encourage': [273], 'further': [274], 'exploration': [275], 'networking.': [283]}",2024,"['Computer science', 'Autoencoder', 'Data mining', 'Machine learning', 'Artificial intelligence', 'Generative model', 'Synthetic data', 'Artificial neural network', 'Field (mathematics)', 'Generative grammar', 'Pure mathematics', 'Mathematics']","Network Intrusion Detection Systems (NIDS) are crucial tools for protecting networked devices from cyberattacks. Recent development in the field of Artificial Intelligence (AI) has provided tremendous advantages in implementing NIDSs able to monitor network traffic and block cyberattacks in real-time. In the literature, it is widely recognized that the effective training of a NIDS requires a large quantity of labeled traffic, representative of attacks. Nonetheless, the availability of public and abundant datasets remains remarkably restricted due to the cost of gathering and labeling real traffic traces and privacy concerns for sharing them. To tackle these challenges, in this paper we present a generative AI model capable of synthesizing anonymized traffic traces from real ones, thus dealing with privacy, abundance, and representativeness. The proposal is based on a Conditional Variational Autoencoder (CVAE) and a preprocessing procedure specifically designed for the generation of new traffic traces. To validate our solution, we conduct an extensive empirical study leveraging three recent and publicly-available datasets, containing benign and malicious traffic. The validation is carried out from both the perspectives of classification performance of a robust NIDS and the quality of synthetic data, in comparison to the utilization of real data. We compare our CVAE with two state-of-the-art AI-based traffic data generators and prove that, trained with traces emitted by our generative model, a NIDS has a limited F1-score loss compared to training on real data; competing models instead struggle or fail to generate traces that are as effective for NIDS training and as statistically similar to the original. We make the synthetic datasets available in both PCAP and tabular formats, to facilitate the reproducibility of our findings and encourage further exploration in the field of generative AI for networking."
https://openalex.org/W4377294678,"You Are Not Alone: A Serial Mediation of Social Attraction, Privacy Concerns, and Satisfaction in Voice AI Use","{'The': [0], 'popularity': [1], 'of': [2, 54], 'voice-activated': [3], 'artificial': [4], 'intelligence': [5], '(voice': [6], 'AI)': [7], 'has': [8], 'grown': [9], 'rapidly': [10], 'as': [11, 19, 115], 'people': [12, 107], 'continue': [13, 74], 'to': [14, 25, 37, 73, 132], 'use': [15], 'smart': [16], 'speakers': [17], 'such': [18], 'Amazon': [20], 'Alexa': [21], 'and': [22, 62, 71, 121, 134, 139], 'Google': [23], 'Home': [24], 'support': [26], 'everyday': [27], 'tasks.': [28], 'However,': [29], 'little': [30], 'is': [31], 'known': [32], 'about': [33], 'how': [34], 'loneliness': [35, 70], 'relates': [36], 'voice': [38, 76, 88, 113], 'AI': [39, 89, 114], 'use,': [40], 'or': [41], 'the': [42, 51, 65], 'potential': [43], 'mediators': [44], 'in': [45, 64], 'this': [46], 'association.': [47], 'This': [48], 'study': [49], 'investigates': [50], 'mediating': [52], 'roles': [53], 'users’': [55, 68, 93], 'perceptions': [56, 94], '(i.e.,': [57], 'social': [58, 69], 'attraction,': [59], 'privacy': [60, 125], 'concerns,': [61], 'satisfaction)': [63], 'relationship': [66], 'between': [67], 'intentions': [72], 'using': [75], 'AI.': [77], 'A': [78], 'serial': [79, 103], 'mediation': [80], 'model': [81], 'based': [82], 'on': [83], 'survey': [84], 'data': [85], 'from': [86], 'current': [87], 'users': [90], 'showed': [91], 'that': [92], 'were': [95, 105, 129], 'positively': [96], 'associated': [97], 'with': [98], 'behavioral': [99], 'intentions.': [100], 'Several': [101], 'full': [102], 'mediations': [104], 'observed:': [106], 'who': [108], 'felt': [109], 'lonely': [110], 'perceived': [111], '(1)': [112], 'a': [116], 'more': [117], 'socially': [118], 'attractive': [119], 'agent': [120], '(2)': [122], 'had': [123], 'fewer': [124], 'concerns.': [126], 'These': [127], 'aspects': [128], 'each': [130], 'tied': [131], 'satisfaction': [133], 'subsequent': [135], 'usage': [136], 'intention.': [137], 'Theoretical': [138], 'practical': [140], 'implications': [141], 'are': [142], 'discussed.': [143]}",2023,"['Popularity', 'Loneliness', 'Mediation', 'Psychology', 'Perception', 'Internet privacy', 'Attraction', 'Social psychology', 'Computer science', 'Sociology', 'Social science', 'Neuroscience', 'Linguistics', 'Philosophy']","The popularity of voice-activated artificial intelligence (voice AI) has grown rapidly as people continue to use smart speakers such as Amazon Alexa and Google Home to support everyday tasks. However, little is known about how loneliness relates to voice AI use, or the potential mediators in this association. This study investigates the mediating roles of users’ perceptions (i.e., social attraction, privacy concerns, and satisfaction) in the relationship between users’ social loneliness and intentions to continue using voice AI. A serial mediation model based on survey data from current voice AI users showed that users’ perceptions were positively associated with behavioral intentions. Several full serial mediations were observed: people who felt lonely perceived (1) voice AI as a more socially attractive agent and (2) had fewer privacy concerns. These aspects were each tied to satisfaction and subsequent usage intention. Theoretical and practical implications are discussed."
https://openalex.org/W4399634584,AI-Driven Network Security and Privacy,"{'While': [0], 'creating': [1], 'unprecedented': [2, 10], 'opportunities,': [3], 'artificial': [4], 'intelligence': [5], 'is': [6], 'also': [7], 'accompanied': [8], 'by': [9], 'risks': [11], '[...]': [12]}",2024,"['Computer security', 'Computer science', 'Network security', 'Internet privacy']","While creating unprecedented opportunities, artificial intelligence is also accompanied by unprecedented risks [...]"
https://openalex.org/W4390064612,A unified privacy preserving model with AI at the edge for Human-in-the-Loop Cyber-Physical Systems,"{'With': [0], 'the': [1, 16, 54, 69, 89, 131, 144, 147, 163, 171, 200], 'proliferation': [2], 'of': [3, 6, 19, 58, 135, 146, 174, 176], 'personal': [4], 'Internet': [5], 'Things': [7], '(IoT)': [8], 'devices': [9], 'and': [10, 41, 56, 112, 116], 'their': [11, 45], 'wide': [12], 'adoption': [13], 'among': [14], 'society,': [15], 'original': [17], 'notion': [18], 'IoT': [20], 'has': [21, 87], 'been': [22, 64], 'reshaped,': [23], 'giving': [24], 'rise': [25], 'to': [26, 73, 83, 110, 142, 162, 199], 'new': [27], 'IoT-based': [28], 'paradigms': [29], 'like': [30], 'Human-in-the-Loop': [31], 'Cyber-Physical': [32], 'Systems': [33], '(HiTLCPS).': [34], 'While': [35], 'these': [36, 67], 'systems': [37], 'can': [38], 'bring': [39], 'benefits': [40], 'positively': [42], 'influence': [43], 'people,': [44], 'pervasive': [46], 'nature': [47], 'raises': [48], 'significant': [49], 'privacy': [50], 'concerns,': [51], 'especially': [52], 'regarding': [53], 'acquisition': [55, 78, 115], 'processing': [57], 'data.': [59], 'Although': [60], 'privacy-preserving': [61, 100], 'mechanisms': [62], 'have': [63], 'proposed': [65], 'for': [66, 102], 'implementations,': [68], 'existing': [70], 'approaches': [71], 'tend': [72], 'focus': [74], 'on': [75, 167], 'either': [76], 'data': [77, 80, 114], 'or': [79], 'processing.': [81], 'However,': [82], 'date,': [84], 'no': [85], 'solution': [86, 160], 'encompassed': [88], 'entire': [90], 'process.': [91], 'In': [92], 'this': [93, 95, 180], 'regard,': [94], 'paper': [96, 181], 'presents': [97], 'a': [98, 107, 121, 158, 185, 194], 'unified': [99], 'model': [101], 'HiTLCPS.': [103], 'This': [104], 'approach': [105, 156, 165], 'integrates': [106], 'human-centric': [108], 'mechanism': [109], 'control': [111], 'make': [113], 'sharing': [117], 'tasks': [118], 'transparent': [119], 'with': [120], 'state': [122, 195], 'inference': [123, 196], 'process': [124, 197], 'supported': [125], 'by': [126, 183], 'Artificial': [127], 'Intelligence': [128], '(AI)': [129], 'in': [130, 139], 'edge.': [132], 'A': [133], 'set': [134], 'assessments': [136], 'were': [137], 'conducted': [138], 'actual': [140], 'implementation': [141], 'evaluate': [143], 'feasibility': [145], 'model.': [148], 'Our': [149], 'findings': [150], 'reveal': [151], 'that': [152], 'our': [153], 'federated': [154], 'learning': [155, 169], 'is': [157], 'suitable': [159], 'compared': [161], 'traditional': [164], 'based': [166], 'machine': [168], 'at': [170], 'small': [172], 'cost': [173], '3.27%': [175], 'average': [177], 'accuracy.': [178], 'Finally,': [179], 'concludes': [182], 'providing': [184], 'roadmap': [186], 'toward': [187], 'integrating': [188], 'HiTLCPS': [189], 'from': [190], 'diverse': [191], 'contexts,': [192], 'including': [193], 'closer': [198], 'user': [201], 'domain.': [202]}",2023,"['Computer science', 'Cyber-physical system', 'Process (computing)', 'Inference', 'Human-in-the-loop', 'Implementation', 'Artificial intelligence', 'Domain (mathematical analysis)', 'Enhanced Data Rates for GSM Evolution', 'Computer security', 'Data science', 'Human–computer interaction', 'Software engineering', 'Operating system', 'Mathematics', 'Mathematical analysis']","With the proliferation of personal Internet of Things (IoT) devices and their wide adoption among society, the original notion of IoT has been reshaped, giving rise to new IoT-based paradigms like Human-in-the-Loop Cyber-Physical Systems (HiTLCPS). While these systems can bring benefits and positively influence people, their pervasive nature raises significant privacy concerns, especially regarding the acquisition and processing of data. Although privacy-preserving mechanisms have been proposed for these implementations, the existing approaches tend to focus on either data acquisition or data processing. However, to date, no solution has encompassed the entire process. In this regard, this paper presents a unified privacy-preserving model for HiTLCPS. This approach integrates a human-centric mechanism to control and make data acquisition and sharing tasks transparent with a state inference process supported by Artificial Intelligence (AI) in the edge. A set of assessments were conducted in actual implementation to evaluate the feasibility of the model. Our findings reveal that our federated learning approach is a suitable solution compared to the traditional approach based on machine learning at the small cost of 3.27% of average accuracy. Finally, this paper concludes by providing a roadmap toward integrating HiTLCPS from diverse contexts, including a state inference process closer to the user domain."
https://openalex.org/W4401104509,Securing AI: Federated Learning as a Tool for Privacy Preservation,"{'Federated': [0, 150], 'Learning': [1], '(FL)': [2], 'is': [3, 87], 'a': [4], 'technique': [5], 'in': [6, 33, 37, 123], 'the': [7, 26, 52, 67, 84], 'field': [8], 'of': [9, 28, 54], 'machine': [10], 'learning': [11], 'that': [12, 125], 'prioritizes': [13], 'privacy': [14, 36, 129, 147], 'by': [15], 'allowing': [16], 'collaborative': [17], 'model': [18], 'training': [19], 'without': [20, 60], 'revealing': [21], 'data.': [22], 'This': [23, 135], 'article': [24], 'explores': [25], 'basics': [27], 'FL': [29, 50, 70, 86, 106, 124, 140], 'and': [30, 43, 56, 77, 98, 113, 131], 'its': [31], 'importance': [32], 'protecting': [34], 'data': [35, 48, 111], 'sectors': [38], 'such': [39, 89], 'as': [40, 90], 'healthcare,': [41], 'finance,': [42], 'industrial': [44, 100], 'engineering.': [45], 'By': [46], 'using': [47], 'sources': [49], 'enables': [51], 'development': [53], 'strong': [55], 'adaptable': [57], 'AI': [58, 143], 'models': [59], 'centralizing': [61], 'sensitive': [62], 'information.': [63], 'We': [64], 'delve': [65], 'into': [66], 'methodologies': [68], 'behind': [69], 'including': [71], 'secure': [72], 'multiparty': [73], 'computation,': [74], 'differential': [75], 'privacy,': [76], 'homomorphic': [78], 'encryption.': [79], 'Additionally,': [80], 'we': [81, 120], 'look': [82], 'at': [83], 'ways': [85], 'used,': [88], 'speeding': [91], 'up': [92], 'medical': [93], 'research': [94], 'improving': [95], 'financial': [96], 'security': [97], 'streamlining': [99], 'processes.': [101], 'The': [102], 'challenges': [103], 'related': [104], 'to': [105], '-': [107, 115], 'like': [108], 'communication': [109], 'diverse': [110], 'distributions': [112], 'scalability': [114], 'are': [116], 'also': [117], 'addressed.': [118], 'Lastly,': [119], 'discuss': [121], 'trends,': [122], 'focus': [126], 'on': [127], 'enhancing': [128], 'techniques': [130], 'complying': [132], 'with': [133], 'regulations.': [134], 'thorough': [136], 'overview': [137], 'highlights': [138], 'how': [139], 'can': [141], 'revolutionize': [142], 'advancement': [144], 'while': [145], 'upholding': [146], 'standards.': [148], 'Keywords:': [149], 'Learning,': [151, 156], 'Privacy': [152], 'Preservation,': [153], 'Decentralized': [154], 'Machine': [155], 'Secure': [157], 'Multiparty': [158], 'Computation,': [159], 'Differential': [160], 'Privacy,': [161], 'Healthcare': [162], 'AI,': [163], 'Industrial': [164], 'Engineering,': [165], 'Data': [166], 'Silos,': [167], 'Collaborative': [168], 'Learning.': [169]}",2024,"['Computer science', 'Internet privacy', 'Data science', 'Artificial intelligence']","Federated Learning (FL) is a technique in the field of machine learning that prioritizes privacy by allowing collaborative model training without revealing data. This article explores the basics of FL and its importance in protecting data privacy in sectors such as healthcare, finance, and industrial engineering. By using data sources FL enables the development of strong and adaptable AI models without centralizing sensitive information. We delve into the methodologies behind FL including secure multiparty computation, differential privacy, and homomorphic encryption. Additionally, we look at the ways FL is used, such as speeding up medical research improving financial security and streamlining industrial processes. The challenges related to FL - like communication diverse data distributions and scalability - are also addressed. Lastly, we discuss trends, in FL that focus on enhancing privacy techniques and complying with regulations. This thorough overview highlights how FL can revolutionize AI advancement while upholding privacy standards. Keywords: Federated Learning, Privacy Preservation, Decentralized Machine Learning, Secure Multiparty Computation, Differential Privacy, Healthcare AI, Industrial Engineering, Data Silos, Collaborative Learning."
https://openalex.org/W4400020000,GenAIPABench: A Benchmark for Generative AI-based Privacy Assistants,"{'Website': [0], 'privacy': [1, 32, 40, 78, 109, 145], 'policies': [2, 13, 79, 110], 'are': [3], 'often': [4], 'lengthy': [5], 'and': [6, 14, 19, 87, 96, 100, 111, 125, 157], 'intricate.': [7], 'Privacy': [8, 66], 'assistants': [9, 33], 'assist': [10], 'in': [11, 140, 143, 151], 'simplifying': [12], 'making': [15], 'them': [16], 'more': [17], 'accessible': [18], 'user-friendly.': [20], 'The': [21], 'emergence': [22], 'of': [23, 74, 98, 114], 'generative': [24], 'AI': [25], '(genAI)': [26], 'offers': [27], 'new': [28], 'opportunities': [29], 'to': [30, 49, 91, 107, 129], 'build': [31], 'that': [34], 'can': [35], 'answer': [36], 'users’': [37], 'questions': [38, 76], 'about': [39, 77], 'policies.': [41], 'However,': [42], 'genAI’s': [43], 'reliability': [44], 'is': [45], 'a': [46, 60], 'concern': [47], 'due': [48], 'its': [50], 'potential': [51], 'for': [52, 62, 84, 104], 'producing': [53], 'inaccurate': [54], 'information.': [55], 'This': [56], 'study': [57], 'introduces': [58], 'GenAIPABench,': [59], 'benchmark': [61], 'evaluating': [63], 'Generative': [64], 'AI-based': [65], 'Assistants': [67], '(GenAIPAs).': [68], 'GenAIPABench': [69, 128], 'includes:': [70], '1)': [71], 'A': [72, 102], 'set': [73], 'curated': [75, 116], 'along': [80], 'with': [81], 'annotated': [82], 'answers': [83], 'various': [85], 'organizations': [86], 'regulations;': [88], '2)': [89], 'Metrics': [90], 'assess': [92], 'the': [93, 115, 144], 'accuracy,': [94], 'relevance,': [95], 'consistency': [97], 'responses;': [99], '3)': [101], 'tool': [103], 'generating': [105], 'prompts': [106], 'introduce': [108], 'paraphrased': [112], 'variants': [113], 'questions.': [117], 'We': [118], 'evaluated': [119], '3': [120], 'leading': [121], 'genAI': [122, 141], 'systems—ChatGPT-4,': [123], 'Bard,': [124], 'Bing': [126], 'AI—using': [127], 'gauge': [130], 'their': [131], 'effectiveness': [132], 'as': [133], 'GenAIPAs.': [134], 'Our': [135], 'results': [136], 'demonstrate': [137], 'significant': [138], 'promise': [139], 'capabilities': [142], 'domain': [146], 'while': [147], 'also': [148], 'highlighting': [149], 'challenges': [150], 'managing': [152], 'complex': [153], 'queries,': [154], 'ensuring': [155], 'consistency,': [156], 'verifying': [158], 'source': [159], 'accuracy.': [160]}",2024,"['Generative grammar', 'Benchmark (surveying)', 'Computer science', 'Generative model', 'Artificial intelligence', 'Machine learning', 'Geography', 'Cartography']","Website privacy policies are often lengthy and intricate. Privacy assistants assist in simplifying policies and making them more accessible and user-friendly. The emergence of generative AI (genAI) offers new opportunities to build privacy assistants that can answer users’ questions about privacy policies. However, genAI’s reliability is a concern due to its potential for producing inaccurate information. This study introduces GenAIPABench, a benchmark for evaluating Generative AI-based Privacy Assistants (GenAIPAs). GenAIPABench includes: 1) A set of curated questions about privacy policies along with annotated answers for various organizations and regulations; 2) Metrics to assess the accuracy, relevance, and consistency of responses; and 3) A tool for generating prompts to introduce privacy policies and paraphrased variants of the curated questions. We evaluated 3 leading genAI systems—ChatGPT-4, Bard, and Bing AI—using GenAIPABench to gauge their effectiveness as GenAIPAs. Our results demonstrate significant promise in genAI capabilities in the privacy domain while also highlighting challenges in managing complex queries, ensuring consistency, and verifying source accuracy."
https://openalex.org/W3170422531,Legal AI from a Privacy Point of View: Data Protection and Transparency in Focus,"{'A': [0, 27], 'major': [1, 28], 'starting': [2], 'point': [3], 'is': [4, 7, 31, 35, 41, 107], 'that': [5, 46], 'transparency': [6, 62], 'a': [8, 126, 132, 142, 180], 'condition': [9], 'for': [10, 118, 149, 168, 171], 'privacy': [11, 106], 'in': [12, 84, 154, 160, 193], 'the': [13, 44, 77, 155, 161], 'context': [14], 'of': [15, 56, 71, 86, 97, 115, 128], 'personal': [16, 98], 'data': [17, 92, 99, 152], 'processing,': [18], 'especially': [19], 'when': [20, 151], 'based': [21, 101], 'on': [22, 102], 'artificial': [23], 'intelligence': [24], '(AI)': [25], 'methods.': [26], 'keyword': [29], 'here': [30], 'openness,': [32], 'which': [33], 'however': [34], 'not': [36, 60], 'equivalent': [37], 'to': [38, 64, 108, 122, 135, 140, 144, 166, 178, 191], 'transparency.': [39], 'This': [40, 147], 'explained': [42], 'by': [43, 54], 'fact': [45], 'an': [47], 'organization': [48], 'may': [49, 175], 'very': [50], 'well': [51, 158], 'be': [52, 109, 123, 141, 176, 188], 'governed': [53], 'principles': [55], 'openness': [57], 'but': [58], 'still': [59], 'provide': [61], 'due': [63], 'insufficient': [65], 'access': [66], 'rights': [67], 'and': [68, 80, 90, 120, 185], 'lacking': [69], 'implementation': [70], 'those': [72], 'rights.': [73], 'Given': [74], 'these': [75, 112], 'hypotheses,': [76], 'chapter': [78], 'investigates': [79], 'illuminates': [81], 'ways': [82], 'forward': [83], 'recognition': [85], 'algorithms,': [87], 'machine': [88], 'learning,': [89], 'big': [91], 'as': [93, 157, 159, 179], 'critical': [94], 'success': [95], 'factors': [96], 'processing': [100], 'AI—that': [103], 'is,': [104], 'if': [105], 'preserved.': [110], 'In': [111], 'circumstances,': [113], 'autonomy': [114], 'technology': [116], 'calls': [117], 'attention': [119], 'needs': [121], 'challenged': [124], 'from': [125], 'variety': [127], 'perspectives.': [129], 'Not': [130], 'least,': [131], 'legal': [133, 181], 'approach': [134], 'digital': [136], 'human': [137], 'sciences': [138], 'appears': [139], 'resource': [143], 'examine': [145], 'further.': [146], 'applies,': [148], 'instance,': [150], 'subjects': [153], 'public': [156], 'private': [162], 'sphere': [163], 'are': [164], 'exposed': [165], 'AI': [167], 'better': [169], 'or': [170], 'worse.': [172], 'Providing': [173], 'what': [174], 'referred': [177], 'shield': [182], 'between': [183], 'user': [184], 'application': [186], 'might': [187], 'one': [189], 'remedy': [190], 'shortcomings': [192], 'this': [194], 'context.': [195]}",2021,"['Transparency (behavior)', 'Openness to experience', 'Autonomy', 'Data Protection Act 1998', 'Information privacy', 'Context (archaeology)', 'Internet privacy', 'Computer science', 'Variety (cybernetics)', 'Privacy policy', 'Data science', 'Computer security', 'Political science', 'Artificial intelligence', 'Psychology', 'Law', 'Social psychology', 'Biology', 'Paleontology']","A major starting point is that transparency is a condition for privacy in the context of personal data processing, especially when based on artificial intelligence (AI) methods. A major keyword here is openness, which however is not equivalent to transparency. This is explained by the fact that an organization may very well be governed by principles of openness but still not provide transparency due to insufficient access rights and lacking implementation of those rights. Given these hypotheses, the chapter investigates and illuminates ways forward in recognition of algorithms, machine learning, and big data as critical success factors of personal data processing based on AI—that is, if privacy is to be preserved. In these circumstances, autonomy of technology calls for attention and needs to be challenged from a variety of perspectives. Not least, a legal approach to digital human sciences appears to be a resource to examine further. This applies, for instance, when data subjects in the public as well as in the private sphere are exposed to AI for better or for worse. Providing what may be referred to as a legal shield between user and application might be one remedy to shortcomings in this context."
https://openalex.org/W2952911266,"Privacy Concern, Data Quality and Trustworthiness of AI-Analytics","{'The': [0, 41, 65, 74, 91, 118, 159, 175], 'present': [1, 223], 'study': [2, 120, 129, 224], 'investigates': [3], 'the': [4, 12, 22, 30, 38, 44, 53, 57, 82, 88, 95, 106, 122, 128, 143, 156, 171, 185, 188, 199, 216, 222, 226], 'role': [5], 'of': [6, 8, 25, 34, 43, 71, 76, 105, 108, 115, 138, 161, 173, 203, 228], 'trustworthiness': [7, 114, 137, 172, 239], 'data': [9, 13, 35, 58, 72, 83, 111, 140, 168, 204, 217, 229, 236, 241, 254], 'analytics': [10], 'from': [11], 'quality': [14, 36, 112, 169, 242], 'and': [15, 32, 62, 113, 232, 240, 250], 'privacy': [16, 23, 66, 109, 176], 'concern': [17, 24, 67, 177], 'perspectives.': [18], 'In': [19], 'addition': [20], 'to': [21, 37, 48, 56, 81, 87, 100, 131, 155, 165, 184, 194, 198, 247], 'users,': [26], 'we': [27], 'investigated': [28], 'conceptually': [29], 'requirements': [31], 'impacts': [33], 'business': [39, 63, 251], 'processes.': [40], 'goal': [42], 'conceptual': [45, 135, 157], 'analyze': [46], 'was': [47], 'gain': [49], 'more': [50], 'knowledge': [51], 'about': [52], 'factors': [54, 209], 'affecting': [55], 'quality,': [59, 230], 'its': [60], 'accuracy': [61], 'impacts.': [64], 'is': [68, 78, 94, 164, 178, 255], 'a': [69, 102, 133, 150, 179], 'part': [70], 'quality.': [73, 218], 'behavior': [75], 'users': [77], 'closely': [79], 'related': [80], 'that': [84, 98, 167, 181], 'they': [85], 'insert': [86], 'software': [89], 'systems.': [90], 'research': [92, 125, 145], 'approach': [93], 'case': [96, 119], 'study,': [97], 'allowed': [99, 147], 'develop': [101], 'new': [103, 134], 'understanding': [104, 136, 152], 'relationship': [107], 'concern,': [110], 'machine': [116], 'learning.': [117], 'used': [121], 'abductive': [123], 'qualitative': [124], 'method,': [126], 'as': [127], 'aims': [130], 'build': [132], 'AI-based': [139], 'analytics.': [141], 'Using': [142], 'iterative': [144], 'process': [146], 'for': [148], 'developing': [149], 'deeper': [151], 'while': [153], 'contributing': [154], 'models.': [158], 'contribution': [160], 'this': [162, 191], 'paper': [163, 192], 'show': [166], 'affects': [170], 'results.': [174], 'factor': [180], 'influences': [182], 'indirectly': [183], 'trustworthiness.': [186], 'For': [187], 'managerial': [189], 'implication,': [190], 'suggests': [193], 'put': [195], 'special': [196], 'emphasizes': [197], 'very': [200], 'first': [201], 'phases': [202], 'collection': [205], 'processes': [206], 'where': [207, 253], 'human': [208], 'or': [210], 'sensor': [211], 'technological': [212], 'shortages': [213], 'might': [214], 'corrupt': [215], 'To': [219], 'sum': [220], 'up,': [221], 'underlines': [225], 'importance': [227], 'reliability': [231], 'validity': [233], 'in': [234], 'different': [235], 'categories.': [237], 'Data': [238], 'evaluation': [243], 'should': [244], 'be': [245], 'included': [246], 'all': [248], 'marketing': [249], 'operations': [252], 'utilized.': [256]}",2019,"['Trustworthiness', 'Computer science', 'Analytics', 'Data quality', 'Internet privacy', 'Information privacy', 'Quality (philosophy)', 'Data science', 'Data analysis', 'Computer security', 'Business', 'Data mining', 'Metric (unit)', 'Marketing', 'Epistemology', 'Philosophy']","The present study investigates the role of trustworthiness of data analytics from the data quality and privacy concern perspectives. In addition to the privacy concern of users, we investigated conceptually the requirements and impacts of data quality to the business processes. The goal of the conceptual analyze was to gain more knowledge about the factors affecting to the data quality, its accuracy and business impacts. The privacy concern is a part of data quality. The behavior of users is closely related to the data that they insert to the software systems. The research approach is the case study, that allowed to develop a new understanding of the relationship of privacy concern, data quality and trustworthiness of machine learning. The case study used the abductive qualitative research method, as the study aims to build a new conceptual understanding trustworthiness of AI-based data analytics. Using the iterative research process allowed for developing a deeper understanding while contributing to the conceptual models. The contribution of this paper is to show that data quality affects the trustworthiness of results. The privacy concern is a factor that influences indirectly to the trustworthiness. For the managerial implication, this paper suggests to put special emphasizes to the very first phases of data collection processes where human factors or sensor technological shortages might corrupt the data quality. To sum up, the present study underlines the importance of data quality, reliability and validity in different data categories. Data trustworthiness and data quality evaluation should be included to all marketing and business operations where data is utilized."
https://openalex.org/W4390136355,Transparency and Privacy: The Role of Explainable AI and Federated Learning in Financial Fraud Detection,"{'Fraudulent': [0], 'transactions': [1, 60, 79, 171], 'and': [2, 27, 44, 63, 151, 181, 199, 209, 241], 'how': [3], 'to': [4, 24, 99, 110, 115, 155, 163, 168, 211], 'detect': [5, 169], 'them': [6], 'remain': [7], 'a': [8, 49, 117, 144, 166, 205], 'significant': [9, 75], 'problem': [10], 'for': [11, 19, 33], 'financial': [12, 34, 106, 161], 'institutions': [13, 107, 162], 'around': [14], 'the': [15, 40, 56, 88, 93, 100, 124, 137, 184, 190, 194, 212, 223, 245], 'world.': [16], 'The': [17], 'need': [18], 'advanced': [20], 'fraud': [21, 46, 94, 125, 225], 'detection': [22, 47, 95, 126, 226], 'systems': [23, 48], 'safeguard': [25], 'assets': [26], 'maintain': [28], 'customer': [29, 113, 175], 'trust': [30, 210], 'is': [31, 55, 121], 'paramount': [32], 'institutions,': [35], 'but': [36], 'some': [37], 'factors': [38, 54], 'make': [39], 'development': [41], 'of': [42, 52, 77, 92, 186, 207], 'effective': [43, 240], 'efficient': [45], 'challenge.': [50], 'One': [51], 'such': [53], 'fact': [57], 'that': [58, 64, 70, 104, 132, 189, 222], 'fraudulent': [59, 78, 170], 'are': [61, 68, 73, 108], 'rare': [62], 'many': [65], 'transaction': [66, 219], 'datasets': [67], 'imbalanced;': [69], 'is,': [71], 'there': [72], 'fewer': [74], 'samples': [76], 'than': [80], 'legitimate': [81], 'ones.': [82], 'This': [83, 233], 'data': [84, 101, 114, 179], 'imbalance': [85], 'can': [86, 196], 'affect': [87, 136], 'performance': [89, 231], 'or': [90], 'reliability': [91], 'model.': [96], 'Moreover,': [97], 'due': [98], 'privacy': [102, 180], 'laws': [103], 'all': [105], 'subject': [109], 'follow,': [111], 'sharing': [112, 174], 'facilitate': [116], 'higher-performing': [118], 'centralized': [119], 'model': [120, 167, 195], 'impossible.': [122], 'Furthermore,': [123], 'technique': [127], 'should': [128], 'be': [129, 197], 'transparent': [130], 'so': [131], 'it': [133], 'does': [134], 'not': [135], 'user': [138], 'experience.': [139], 'Hence,': [140], 'this': [141], 'research': [142], 'introduces': [143], 'novel': [145], 'approach': [146], 'using': [147], 'Federated': [148], 'Learning': [149], '(FL)': [150], 'Explainable': [152], 'AI': [153], '(XAI)': [154], 'address': [156], 'these': [157], 'challenges.': [158], 'FL': [159], 'enables': [160], 'collaboratively': [164], 'train': [165], 'without': [172], 'directly': [173], 'data,': [176], 'thereby': [177], 'preserving': [178], 'confidentiality.': [182], 'Meanwhile,': [183], 'integration': [185], 'XAI': [187], 'ensures': [188], 'predictions': [191], 'made': [192], 'by': [193, 201], 'understood': [198], 'interpreted': [200], 'human': [202], 'experts,': [203], 'adding': [204], 'layer': [206], 'transparency': [208], 'system.': [213], 'Experimental': [214], 'results,': [215], 'based': [216], 'on': [217], 'realistic': [218], 'datasets,': [220], 'reveal': [221], 'FL-based': [224], 'system': [227], 'consistently': [228], 'demonstrates': [229], 'high': [230], 'metrics.': [232], 'study': [234], 'grounds': [235], ""FL's"": [236], 'potential': [237], 'as': [238], 'an': [239], 'privacy-preserving': [242], 'tool': [243], 'in': [244], 'fight': [246], 'against': [247], 'fraud.': [248]}",2023,"['Transparency (behavior)', 'Database transaction', 'Confidentiality', 'Financial transaction', 'Data sharing', 'Computer science', 'Business', 'Transaction data', 'Computer security', 'Internet privacy', 'Database', 'Alternative medicine', 'Medicine', 'Pathology']","Fraudulent transactions and how to detect them remain a significant problem for financial institutions around the world. The need for advanced fraud detection systems to safeguard assets and maintain customer trust is paramount for financial institutions, but some factors make the development of effective and efficient fraud detection systems a challenge. One of such factors is the fact that fraudulent transactions are rare and that many transaction datasets are imbalanced; that is, there are fewer significant samples of fraudulent transactions than legitimate ones. This data imbalance can affect the performance or reliability of the fraud detection model. Moreover, due to the data privacy laws that all financial institutions are subject to follow, sharing customer data to facilitate a higher-performing centralized model is impossible. Furthermore, the fraud detection technique should be transparent so that it does not affect the user experience. Hence, this research introduces a novel approach using Federated Learning (FL) and Explainable AI (XAI) to address these challenges. FL enables financial institutions to collaboratively train a model to detect fraudulent transactions without directly sharing customer data, thereby preserving data privacy and confidentiality. Meanwhile, the integration of XAI ensures that the predictions made by the model can be understood and interpreted by human experts, adding a layer of transparency and trust to the system. Experimental results, based on realistic transaction datasets, reveal that the FL-based fraud detection system consistently demonstrates high performance metrics. This study grounds FL's potential as an effective and privacy-preserving tool in the fight against fraud."
https://openalex.org/W4401834045,Methods and Algorithms of Ensuring Data Privacy in AI-Based Healthcare Systems and Technologies,"{'This': [0], 'project': [1, 41], 'seeks': [2], 'to': [3, 12, 33, 56], 'devise': [4], 'novel': [5], 'algorithms': [6], 'and': [7, 30], 'techniques': [8], 'leveraged': [9], 'in': [10, 16, 50], 'healthcare': [11, 38, 51], 'guarantee': [13], 'data': [14, 35], 'privacy': [15, 36, 54], 'AI-powered': [17], 'systems.': [18], 'To': [19], 'bolster': [20], 'its': [21], 'credibility,': [22], 'the': [23, 47, 62], 'study': [24, 45], 'review': [25], 'presents': [26], 'various': [27], 'modern': [28], 'approaches': [29], 'technologies': [31], 'used': [32], 'preserve': [34], 'of': [37, 46], 'data.': [39], 'The': [40], 'conducted': [42], 'an': [43], 'empirical': [44], 'current': [48], 'development': [49], 'regarding': [52], 'AI': [53], 'protection': [55], 'compile': [57], 'a': [58], 'steadfast': [59], 'literature': [60], 'on': [61], 'subject.': [63]}",2024,"['Credibility', 'Computer science', 'Health care', 'Data science', 'Information privacy', 'Confidentiality', 'Compiler', 'Big data', 'Computer security', 'Data mining', 'Political science', 'Programming language', 'Law']","This project seeks to devise novel algorithms and techniques leveraged in healthcare to guarantee data privacy in AI-powered systems. To bolster its credibility, the study review presents various modern approaches and technologies used to preserve data privacy of healthcare data. The project conducted an empirical study of the current development in healthcare regarding AI privacy protection to compile a steadfast literature on the subject."
https://openalex.org/W4409148389,"Balancing Security and Privacy: Web Bot Detection, Privacy Challenges, and Regulatory Compliance under the GDPR and AI Act.","{'This': [0], 'paper': [1], 'presents': [2], 'a': [3, 26, 91, 173, 179], 'comprehensive': [4], 'analysis': [5], 'of': [6, 19, 57, 64, 84, 112], 'web': [7, 21, 59], 'bot': [8, 94, 125, 169], 'activity,': [9], 'exploring': [10], 'both': [11], 'offensive': [12], 'and': [13, 34, 45, 96, 120, 145], 'defensive': [14], 'perspectives': [15], 'within': [16], 'the': [17, 54, 68, 78, 82, 110, 118, 128, 132, 138, 146], 'context': [18], 'modern': [20], 'infrastructure.': [22], 'As': [23], 'bots': [24, 47, 60], 'play': [25], 'dual': [27], 'role-enabling': [28], 'malicious': [29], 'activities': [30], 'like': [31], 'credential': [32], 'stuffing': [33], 'scraping': [35], 'while': [36, 108, 166], 'also': [37], 'facilitating': [38], 'benign': [39, 65], 'automation-distinguishing': [40], 'between': [41, 93], 'humans,': [42], 'good': [43], 'bots,': [44], 'bad': [46], 'has': [48], 'become': [49], 'increasingly': [50], 'critical.': [51], 'We': [52], 'examine': [53], 'technical': [55, 129], 'challenges': [56], 'detecting': [58], 'amidst': [61], 'large': [62], 'volumes': [63], 'traffic,': [66], 'highlighting': [67], 'privacy': [69], 'risks': [70], 'involved': [71], 'in': [72, 178], 'monitoring': [73], 'users': [74], 'at': [75], 'scale.': [76], 'Additionally,': [77], 'study': [79], 'dives': [80], 'into': [81, 160], 'use': [83], 'Privacy': [85], 'Enhancing': [86], 'Technologies': [87], '(PETs)': [88], 'to': [89, 104, 131, 176], 'strike': [90], 'balance': [92], 'detection': [95], 'user': [97], 'privacy.': [98], 'These': [99], 'technologies': [100], 'provide': [101, 158], 'innovative': [102], 'approaches': [103], 'minimising': [105], 'data': [106], 'exposure': [107], 'maintaining': [109, 167], 'effectiveness': [111], 'bot-detection': [113], 'mechanisms.': [114], 'Furthermore,': [115], 'we': [116, 157], 'explore': [117], 'legal': [119], 'ethical': [121], 'considerations': [122], 'associated': [123], 'with': [124], 'detection,': [126], 'mapping': [127], 'solutions': [130], 'regulatory': [133, 155], 'frameworks': [134], 'set': [135], 'forth': [136], 'by': [137], 'EU': [139], 'General': [140], 'Data': [141], 'Protection': [142], 'Regulation': [143], '(GDPR)': [144], 'Artificial': [147], 'Intelligence': [148], 'Act': [149], '(AI': [150], 'Act).': [151], 'By': [152], 'analysing': [153], 'these': [154], 'constraints,': [156], 'insights': [159], 'how': [161], 'organisations': [162], 'can': [163], 'ensure': [164], 'compliance': [165], 'robust': [168], 'defence': [170], 'strategies,': [171], 'fostering': [172], 'responsible': [174], 'approach': [175], 'cybersecurity': [177], 'privacy-conscious': [180], 'world.': [181]}",2025,"['Compliance (psychology)', 'Internet privacy', 'Information privacy', 'Privacy policy', 'Computer security', 'Privacy software', 'Privacy by Design', 'Privacy law', 'Privacy protection', 'Business', 'Computer science', 'Psychology', 'Social psychology']","This paper presents a comprehensive analysis of web bot activity, exploring both offensive and defensive perspectives within the context of modern web infrastructure. As bots play a dual role-enabling malicious activities like credential stuffing and scraping while also facilitating benign automation-distinguishing between humans, good bots, and bad bots has become increasingly critical. We examine the technical challenges of detecting web bots amidst large volumes of benign traffic, highlighting the privacy risks involved in monitoring users at scale. Additionally, the study dives into the use of Privacy Enhancing Technologies (PETs) to strike a balance between bot detection and user privacy. These technologies provide innovative approaches to minimising data exposure while maintaining the effectiveness of bot-detection mechanisms. Furthermore, we explore the legal and ethical considerations associated with bot detection, mapping the technical solutions to the regulatory frameworks set forth by the EU General Data Protection Regulation (GDPR) and the Artificial Intelligence Act (AI Act). By analysing these regulatory constraints, we provide insights into how organisations can ensure compliance while maintaining robust bot defence strategies, fostering a responsible approach to cybersecurity in a privacy-conscious world."
https://openalex.org/W4390962139,"Generative AI in EU Law: Liability, Privacy, Intellectual Property, and Cybersecurity","{'The': [0, 115], 'advent': [1], 'of': [2, 43, 62, 74, 86, 136], 'Generative': [3, 63, 107], 'AI,': [4], 'particularly': [5], 'through': [6], 'Large': [7], 'Language': [8], 'Models': [9], '(LLMs)': [10], 'like': [11], 'ChatGPT': [12], 'and': [13, 40, 50, 59, 65, 79, 89, 111, 120, 126, 133, 148], 'its': [14], 'successors,': [15], 'marks': [16], 'a': [17], 'paradigm': [18], 'shift': [19], 'in': [20, 48, 67, 100, 109, 113, 122], 'the': [21, 38, 57, 68, 84, 87, 94, 102, 123, 131, 143], 'AI': [22, 64, 108], 'landscape.': [23], 'Advanced': [24], 'LLMs': [25, 66, 112], 'exhibit': [26], 'multimodality,': [27], 'handling': [28], 'diverse': [29], 'data': [30], 'formats,': [31], 'thereby': [32], 'broadening': [33], 'their': [34], 'application': [35], 'scope.': [36], 'However,': [37], 'complexity': [39], 'emergent': [41], 'autonomy': [42], 'these': [44], 'models': [45], 'introduce': [46], 'challenges': [47, 104], 'predictability': [49], 'legal': [51, 58, 149], 'compliance.': [52], 'This': [53], 'paper': [54, 116], 'delves': [55], 'into': [56], 'regulatory': [60], 'implications': [61], 'European': [69], 'Union': [70], 'context,': [71], 'analyzing': [72], 'aspects': [73], 'liability,': [75], 'privacy,': [76], 'intellectual': [77], 'property,': [78], 'cybersecurity.': [80], 'It': [81], 'critically': [82], 'examines': [83], 'adequacy': [85], 'existing': [88], 'proposed': [90], 'EU': [91], 'legislation,': [92], 'including': [93], 'Artificial': [95], 'Intelligence': [96], 'Act': [97], '(AIA)': [98], 'draft,': [99], 'addressing': [101], 'unique': [103], 'posed': [105], 'by': [106], 'general': [110], 'particular.': [114], 'identifies': [117], 'potential': [118], 'gaps': [119], 'shortcomings': [121], 'legislative': [124], 'framework': [125], 'proposes': [127], 'recommendations': [128], 'to': [129], 'ensure': [130], 'safe': [132], 'compliant': [134], 'deployment': [135], 'generative': [137], 'models,': [138], 'ensuring': [139], 'they': [140], 'align': [141], 'with': [142], ""EU's"": [144], 'evolving': [145], 'digital': [146], 'landscape': [147], 'standards.': [150]}",2024,"['Generative grammar', 'Intellectual property', 'Context (archaeology)', 'Legislation', 'Computer security', 'European union', 'Liability', 'Autonomy', 'Political science', 'Law', 'Law and economics', 'Internet privacy', 'Business', 'Computer science', 'Artificial intelligence', 'Economics', 'International trade', 'Paleontology', 'Biology']","The advent of Generative AI, particularly through Large Language Models (LLMs) like ChatGPT and its successors, marks a paradigm shift in the AI landscape. Advanced LLMs exhibit multimodality, handling diverse data formats, thereby broadening their application scope. However, the complexity and emergent autonomy of these models introduce challenges in predictability and legal compliance. This paper delves into the legal and regulatory implications of Generative AI and LLMs in the European Union context, analyzing aspects of liability, privacy, intellectual property, and cybersecurity. It critically examines the adequacy of the existing and proposed EU legislation, including the Artificial Intelligence Act (AIA) draft, in addressing the unique challenges posed by Generative AI in general and LLMs in particular. The paper identifies potential gaps and shortcomings in the legislative framework and proposes recommendations to ensure the safe and compliant deployment of generative models, ensuring they align with the EU's evolving digital landscape and legal standards."
https://openalex.org/W4391721839,AI -ChatGPT Usage Among Users: Factors Affecting Intentions to Use and the Moderating Effect of Privacy Concerns,"{'ChatGPT': [0, 52, 68, 113, 141, 184, 189, 197, 221], 'is': [1], 'an': [2], 'artificial': [3], 'intelligence': [4], 'model': [5, 76, 102], 'intended': [6, 205], 'for': [7, 235], 'many': [8], 'purposes': [9], 'that': [10, 104, 215], 'has': [11, 148], 'increased': [12], 'in': [13, 15, 18, 140, 183, 222, 228], 'popularity': [14], 'all': [16], 'fields': [17], 'our': [19], 'lives': [20], 'such': [21], 'as': [22], 'education,': [23], 'health,': [24], 'entertainment,': [25], 'marketing,': [26], 'and': [27, 55, 70, 108, 134, 172, 191, 233], 'transportation.': [28], 'This': [29, 201], 'research': [30], 'aims': [31], 'to': [32, 38, 57, 72, 158, 195, 206, 208, 219], 'identify': [33], 'the': [34, 42, 49, 59, 65, 106, 109, 123, 126, 155, 168, 177, 186, 192, 209, 213, 217, 223], 'factors': [35, 54, 69, 214], 'affecting': [36], 'intentions': [37], 'use': [39, 159, 196, 220], 'ChatGPTs,': [40], 'examine': [41, 58], 'moderating': [43], 'effect': [44, 61, 163, 179], 'of': [45, 62, 111, 131, 180], 'privacy': [46, 165], 'concerns': [47, 166], 'on': [48, 64, 137, 167, 185, 212], 'relationship': [50, 66, 127, 169], 'between': [51, 67, 128, 170, 188], 'usage': [53, 190], 'trust,': [56], 'mediating': [60], 'trust': [63, 139, 147, 182], 'intention': [71, 157, 171, 194, 218], 'use.': [73], 'The': [74, 85, 100], 'recommended': [75], 'was': [77, 142, 198], 'empirically': [78], 'tested': [79], 'using': [80, 97], 'Structural': [81], 'Equation': [82], 'Modeling': [83], '(SEM).': [84], 'data': [86], 'were': [87], 'collected': [88], 'electronically': [89], 'from': [90], '410': [91], 'students': [92], 'through': [93], 'social': [94], 'media': [95], 'platforms': [96], 'purposive': [98], 'sampling.': [99], 'structural': [101], 'indicates': [103], 'both': [105], 'expertise': [107], 'responsiveness': [110], 'AI': [112], 'have': [114], 'a': [115, 149], 'significant': [116, 151], 'positive': [117, 152], 'association': [118, 153], 'with': [119, 154], ""consumers'"": [120, 138, 146, 181], 'trust.': [121], 'On': [122], 'other': [124], 'hand,': [125], 'perceived': [129, 135], 'ease': [130], 'use,': [132], 'anthropomorphism,': [133], 'risk': [136], 'rejected.': [143], 'In': [144], 'addition,': [145], 'strong': [150], 'behavioural': [156], 'ChatGPT.': [160], 'No': [161], 'moderation': [162], 'via': [164], 'chat': [173], 'GPT': [174], 'usage.': [175], 'Meanwhile,': [176], 'total': [178], 'relation': [187], 'behavioral': [193], 'not': [199], 'evident.': [200], ""research's"": [202], 'findings': [203], 'are': [204], 'contribute': [207], 'existing': [210], 'literature': [211], 'affect': [216], 'education': [224], 'context': [225], 'among': [226], 'learners': [227], 'various': [229], 'stages': [230], 'providing': [231], 'insights': [232], 'recommendations': [234], 'future': [236], 'research.': [237]}",2024,"['Popularity', 'Moderation', 'Structural equation modeling', 'Psychology', 'Affect (linguistics)', 'Context (archaeology)', 'Social influence', 'Social psychology', 'Nonprobability sampling', 'Association (psychology)', 'Applied psychology', 'Computer science', 'Sociology', 'Machine learning', 'Population', 'Communication', 'Biology', 'Demography', 'Paleontology', 'Psychotherapist']","ChatGPT is an artificial intelligence model intended for many purposes that has increased in popularity in all fields in our lives such as education, health, entertainment, marketing, and transportation. This research aims to identify the factors affecting intentions to use ChatGPTs, examine the moderating effect of privacy concerns on the relationship between ChatGPT usage factors and trust, to examine the mediating effect of trust on the relationship between ChatGPT factors and intention to use. The recommended model was empirically tested using Structural Equation Modeling (SEM). The data were collected electronically from 410 students through social media platforms using purposive sampling. The structural model indicates that both the expertise and the responsiveness of AI ChatGPT have a significant positive association with consumers' trust. On the other hand, the relationship between perceived ease of use, anthropomorphism, and perceived risk on consumers' trust in ChatGPT was rejected. In addition, consumers' trust has a strong significant positive association with the behavioural intention to use ChatGPT. No moderation effect via privacy concerns on the relationship between intention and chat GPT usage. Meanwhile, the total effect of consumers' trust in ChatGPT on the relation between ChatGPT usage and the behavioral intention to use ChatGPT was not evident. This research's findings are intended to contribute to the existing literature on the factors that affect the intention to use ChatGPT in the education context among learners in various stages providing insights and recommendations for future research."
https://openalex.org/W4406411734,Co-designing AI with youth partners: Enabling ideal classroom relationships through a novel AI relational privacy ethical framework,"{'In': [0, 53], 'recent': [1, 109], 'years,': [2], 'the': [3, 26, 78, 182, 185, 192, 194, 213, 227, 243], 'design': [4, 27, 79, 228, 244], 'of': [5, 43, 80, 146, 184, 191, 229, 245], 'AI-based': [6, 248], 'tools': [7, 82], 'for': [8, 94, 136, 207], 'educational': [9], 'spaces': [10], 'have': [11, 60], 'been': [12], 'largely': [13], 'driven': [14], 'by': [15, 236], 'researchers': [16], 'who': [17], 'impart': [18], 'their': [19, 72, 199], 'past': [20], 'expertises,': [21], 'experiences,': [22], 'and': [23, 37, 74, 114, 144, 148, 175, 198, 215, 240, 250], 'perspectives': [24], 'in': [25, 41, 50, 70, 116, 126, 131, 168, 172, 197], 'process.': [28, 52], 'While': [29], 'this': [30, 51, 54], 'typically': [31, 48], 'leads': [32], 'to': [33, 65, 211, 242], 'technically': [34], 'feasible': [35], 'designs': [36], 'are': [38, 129], 'often': [39], 'well-grounded': [40], 'theories': [42], 'learning,': [44], 'youth': [45, 67, 128, 167, 195], 'agency': [46], 'is': [47, 88, 154], 'limited': [49], 'paper,': [55], 'we': [56, 121, 201], 'argue': [57], 'that': [58, 225], 'designers': [59], 'a': [61, 123, 188, 218], 'significant': [62], 'ethical': [63, 209, 223], 'responsibility': [64], 'incorporate': [66], 'voices': [68], '–': [69, 76], 'particular,': [71], 'dreams': [73], 'concerns': [75], 'into': [77, 104], 'AI': [81, 147, 220, 232], 'starting': [83], 'from': [84, 108], 'conception.': [85], 'This': [86, 152], 'need': [87], 'particularly': [89], 'important': [90], 'as': [91, 97], 'new': [92, 101, 230], 'applications': [93, 249], 'AI,': [95, 208], 'such': [96], 'AI-supported': [98], 'collaboration,': [99], 'introduce': [100, 122], 'surveillance': [102], 'vectors': [103], 'classroom': [105], 'spaces.': [106], 'Drawing': [107], 'scholarship': [110], 'which': [111, 127, 161], 'advances': [112], 'ethics': [113], 'relationality': [115], 'participatory': [117], 'co-design': [118, 124], 'with': [119, 170], 'youth,': [120], 'methodology': [125], 'supported': [130], 'imagining': [132], 'expansive': [133, 204], 'technical': [134], 'possibilities': [135, 206], 'K-12': [137], 'public': [138], 'schools,': [139], 'grounded': [140], 'within': [141], 'affordances,': [142], 'limitations,': [143], 'tradeoffs': [145], 'machine': [149], 'learning': [150], 'techniques.': [151], 'approach': [153], 'demonstrated': [155], 'through': [156], 'our': [157], 'Learning': [158], 'Futures': [159], 'Workshop,': [160], 'brought': [162], 'together': [163], '30': [164], 'historically': [165], 'minoritized': [166], 'conversation': [169], 'experts': [171], 'both': [173], 'education': [174], 'technology.': [176], 'Through': [177], 'detailed': [178], 'case': [179], 'study': [180], 'on': [181], 'enactment': [183], 'workshop,': [186], 'including': [187], 'thematic': [189], 'analysis': [190], 'activities': [193], 'engaged': [196], 'outputs,': [200], 'identified': [202], 'new,': [203], 'relational': [205], 'commitments': [210], 'support': [212], 'design,': [214], 'finally,': [216], 'developed': [217], 'novel': [219], 'Relational': [221], 'Privacy': [222], 'framework': [224], 'supports': [226], 'collaborative': [231], 'platforms.': [233], 'We': [234], 'conclude': [235], 'connecting': [237], 'these': [238], 'findings': [239], 'frameworks': [241], 'newly': [246], 'enacted': [247], 'underlying': [251], 'data': [252], 'infrastructures.': [253]}",2025,"['Ideal (ethics)', 'Psychology', 'Computer science', 'Sociology', 'Political science', 'Law']","In recent years, the design of AI-based tools for educational spaces have been largely driven by researchers who impart their past expertises, experiences, and perspectives in the design process. While this typically leads to technically feasible designs and are often well-grounded in theories of learning, youth agency is typically limited in this process. In this paper, we argue that designers have a significant ethical responsibility to incorporate youth voices – in particular, their dreams and concerns – into the design of AI tools starting from conception. This need is particularly important as new applications for AI, such as AI-supported collaboration, introduce new surveillance vectors into classroom spaces. Drawing from recent scholarship which advances ethics and relationality in participatory co-design with youth, we introduce a co-design methodology in which youth are supported in imagining expansive technical possibilities for K-12 public schools, grounded within affordances, limitations, and tradeoffs of AI and machine learning techniques. This approach is demonstrated through our Learning Futures Workshop, which brought together 30 historically minoritized youth in conversation with experts in both education and technology. Through detailed case study on the enactment of the workshop, including a thematic analysis of the activities the youth engaged in and their outputs, we identified new, expansive relational possibilities for AI, ethical commitments to support the design, and finally, developed a novel AI Relational Privacy ethical framework that supports the design of new collaborative AI platforms. We conclude by connecting these findings and frameworks to the design of newly enacted AI-based applications and underlying data infrastructures."
https://openalex.org/W4403721375,Advancing Scholarship Management: A Blockchain-Enhanced Platform With Privacy-Secure Identities and AI-Driven Recommendations,"{'Publisher': [0], 'Copyright:': [1], '©': [2], '2013': [3], 'IEEE.': [4]}",2024,"['Blockchain', 'Scholarship', 'Computer science', 'Computer security', 'Internet privacy', 'Information privacy', 'Political science', 'Law']",Publisher Copyright: © 2013 IEEE.
https://openalex.org/W4393347944,"Privacy-Preserving AI/ML Application Architectures: Techniques, Trade-offs, and Case Studies","{'Given': [0], 'the': [1, 23, 31, 36, 76, 141, 149, 156], 'widespread': [2], 'adoption': [3], 'and': [4, 10, 33, 46, 51, 72, 98, 113, 121, 131, 153, 161], 'fusion': [5, 50], 'of': [6, 25, 35, 44, 54, 83, 106, 143, 151, 168], 'artificial': [7], 'intelligence': [8], '(AI)': [9], 'blockchain': [11], 'technologies,': [12], 'safeguarding': [13, 167], 'privacy': [14, 55, 84, 123, 144], 'has': [15], 'become': [16], 'paramount.': [17], 'These': [18], 'techniques': [19], 'not': [20], 'only': [21], 'ensure': [22], 'confidentiality': [24], ""individuals'"": [26], 'data': [27, 66, 94], 'but': [28], 'also': [29, 119], 'uphold': [30], 'integrity': [32], 'reliability': [34], 'information.': [37], 'This': [38], 'study': [39, 118], 'provides': [40], 'an': [41], 'introductory': [42], 'overview': [43], 'AI': [45, 152], 'blockchain,': [47, 154], 'elucidating': [48], 'their': [49, 110], 'subsequent': [52], 'emergence': [53], 'protection': [56, 85, 124, 145], 'methodologies.': [57], 'It': [58], 'delves': [59], 'into': [60], 'specific': [61], 'application': [62, 129], 'contexts': [63, 130], 'such': [64], 'as': [65], 'encryption,': [67], 'de-identification,': [68], 'multi-tier': [69], 'distributed': [70], 'ledgers,': [71], 'k-anonymity': [73], 'techniques.': [74], 'Furthermore,': [75], 'paper': [77], 'critically': [78], 'assesses': [79], 'five': [80], 'pivotal': [81], 'dimensions': [82], 'systems': [86], 'within': [87], 'AI-blockchain': [88, 128], 'integration:': [89], 'authorization': [90], 'management,': [91], 'access': [92], 'control,': [93], 'security,': [95], 'network': [96], 'integrity,': [97], 'scalability.': [99], 'Additionally,': [100], 'it': [101, 136], 'conducts': [102], 'a': [103, 164], 'thorough': [104], 'analysis': [105], 'existing': [107], 'shortcomings,': [108], 'pinpointing': [109], 'root': [111], 'causes': [112], 'proposing': [114], 'corresponding': [115], 'remedies.': [116], 'The': [117], 'categorizes': [120], 'synthesizes': [122], 'methodologies': [125], 'based': [126], 'on': [127], 'technical': [132], 'frameworks.': [133], 'In': [134], 'conclusion,': [135], 'outlines': [137], 'prospective': [138], 'avenues': [139], 'for': [140, 163], 'evolution': [142], 'technologies': [146], 'stemming': [147], 'from': [148], 'integration': [150], 'emphasizing': [155], 'need': [157], 'to': [158], 'enhance': [159], 'efficiency': [160], 'security': [162], 'more': [165], 'holistic': [166], 'privacy.': [169]}",2023,"['Computer science', 'Computer security']","Given the widespread adoption and fusion of artificial intelligence (AI) and blockchain technologies, safeguarding privacy has become paramount. These techniques not only ensure the confidentiality of individuals' data but also uphold the integrity and reliability of the information. This study provides an introductory overview of AI and blockchain, elucidating their fusion and subsequent emergence of privacy protection methodologies. It delves into specific application contexts such as data encryption, de-identification, multi-tier distributed ledgers, and k-anonymity techniques. Furthermore, the paper critically assesses five pivotal dimensions of privacy protection systems within AI-blockchain integration: authorization management, access control, data security, network integrity, and scalability. Additionally, it conducts a thorough analysis of existing shortcomings, pinpointing their root causes and proposing corresponding remedies. The study also categorizes and synthesizes privacy protection methodologies based on AI-blockchain application contexts and technical frameworks. In conclusion, it outlines prospective avenues for the evolution of privacy protection technologies stemming from the integration of AI and blockchain, emphasizing the need to enhance efficiency and security for a more holistic safeguarding of privacy."
https://openalex.org/W4411606599,"A Review of Ethical Considerations in AI-Driven Marketing Analytics: Privacy, Transparency, and Consumer Trust","{'This': [0], 'paper': [1, 55, 138], 'provides': [2], 'a': [3, 118], 'comprehensive': [4], 'review': [5], 'of': [6, 37, 42, 76, 84, 102], 'the': [7, 35, 40, 45, 57, 69, 74, 82, 100, 112], 'ethical': [8, 60, 106, 128, 157], 'considerations': [9], 'in': [10, 79, 104, 147, 159], 'AI-driven': [11, 160], 'marketing': [12, 31, 65, 125], 'analytics,': [13], 'focusing': [14], 'on': [15, 47, 87], 'three': [16], 'critical': [17], 'aspects:': [18], 'privacy,': [19, 73], 'transparency,': [20], 'and': [21, 44, 59, 81, 90, 99, 126, 134, 145, 156], 'consumer': [22, 38, 48, 72, 88, 132], 'trust.': [23, 136], 'As': [24], 'artificial': [25], 'intelligence': [26], '(AI)': [27], 'technologies': [28], 'increasingly': [29], 'shape': [30], 'strategies,': [32], 'concerns': [33], 'surrounding': [34], 'use': [36], 'data,': [39], 'transparency': [41, 144], 'algorithms,': [43, 80], 'impact': [46], 'trust': [49, 89], 'have': [50], 'gained': [51], 'significant': [52], 'attention.': [53], 'The': [54, 109, 137], 'explores': [56], 'challenges': [58], 'dilemmas': [61], 'associated': [62], 'with': [63, 140], 'AI-powered': [64], 'tools,': [66], 'such': [67], 'as': [68], 'risks': [70], 'to': [71, 116], 'opacity': [75], 'decision-making': [77], 'processes': [78], 'implications': [83], 'these': [85], 'issues': [86], 'business': [91], 'reputation.': [92], 'Additionally,': [93], 'it': [94], 'reviews': [95], 'existing': [96], 'regulatory': [97, 154], 'frameworks': [98], 'role': [101], 'organizations': [103], 'implementing': [105], 'AI': [107, 122, 148], 'practices.': [108], 'study': [110], 'highlights': [111], 'need': [113], 'for': [114, 123, 142, 151], 'businesses': [115], 'strike': [117], 'balance': [119], 'between': [120], 'leveraging': [121], 'data-driven': [124], 'maintaining': [127], 'standards': [129], 'that': [130], 'protect': [131], 'rights': [133], 'promote': [135], 'concludes': [139], 'recommendations': [141], 'improving': [143], 'privacy': [146], 'systems,': [149], 'advocating': [150], 'more': [152], 'robust': [153], 'oversight': [155], 'guidelines': [158], 'marketing.': [161]}",2021,"['Transparency (behavior)', 'Analytics', 'Business', 'Internet privacy', 'Consumer privacy', 'Information privacy', 'Data science', 'Computer science', 'Computer security']","This paper provides a comprehensive review of the ethical considerations in AI-driven marketing analytics, focusing on three critical aspects: privacy, transparency, and consumer trust. As artificial intelligence (AI) technologies increasingly shape marketing strategies, concerns surrounding the use of consumer data, the transparency of algorithms, and the impact on consumer trust have gained significant attention. The paper explores the challenges and ethical dilemmas associated with AI-powered marketing tools, such as the risks to consumer privacy, the opacity of decision-making processes in algorithms, and the implications of these issues on consumer trust and business reputation. Additionally, it reviews existing regulatory frameworks and the role of organizations in implementing ethical AI practices. The study highlights the need for businesses to strike a balance between leveraging AI for data-driven marketing and maintaining ethical standards that protect consumer rights and promote trust. The paper concludes with recommendations for improving transparency and privacy in AI systems, advocating for more robust regulatory oversight and ethical guidelines in AI-driven marketing."
https://openalex.org/W4401880165,"AI-Powered Integrated With Encoding Mechanism Enhancing Privacy, Security, and Performance for IoT Ecosystem","{'The': [0, 160], 'Internet': [1], 'of': [2, 11, 47, 57, 70, 120, 129, 141, 176, 201, 238], 'Things': [3], '(IoT)': [4], 'ecosystem': [5], 'presents': [6], 'substantial': [7], 'challenges': [8], 'in': [9, 33, 72, 92, 242], 'terms': [10], 'privacy': [12, 35, 71, 89, 107, 231], 'and': [13, 36, 53, 90, 127, 150, 178, 185, 203, 236], 'security,': [14], 'rendering': [15], 'it': [16], 'an': [17, 84, 174], 'attractive': [18], 'target': [19], 'for': [20, 88, 180, 205], 'malicious': [21], 'actors.': [22], 'In': [23, 95], 'this': [24, 81, 133], 'context,': [25], 'the': [26, 30, 44, 54, 68, 93, 118, 125, 139, 153, 181, 206, 220], 'literature': [27], 'review': [28], 'highlights': [29], 'ongoing': [31], 'difficulty': [32], 'addressing': [34], 'security': [37, 91], 'through': [38], 'a': [39, 105], 'unified': [40], 'mechanism': [41, 87, 108, 116, 223], 'owing': [42], 'to': [43, 97, 170, 199, 211], 'heterogeneous': [45], 'nature': [46], 'IoT': [48], 'devices,': [49], 'their': [50], 'dynamic': [51], 'behavior,': [52], 'continual': [55], 'advancement': [56], 'intelligent': [58], 'hacking': [59], 'tools.': [60], 'Hence,': [61], 'encoding': [62, 163], 'techniques': [63], 'have': [64], 'been': [65], 'considered': [66], 'from': [67, 152], 'perspective': [69], 'Artificial': [73], 'Intelligence': [74], '(AI)': [75], 'models.': [76, 131, 143, 252], 'To': [77], 'overcome': [78], 'these': [79], 'challenges,': [80], 'study': [82], 'introduces': [83], 'integrated': [85, 166], 'single': [86], 'IoT.': [94], 'order': [96], 'safeguard': [98], 'sensitive': [99, 121, 239], 'data': [100, 234, 241], 'during': [101], 'AI': [102, 142, 168, 251], 'model': [103], 'training,': [104], 'novel': [106], 'called': [109], 'Replacement': [110], 'Encoding': [111], '(RE)': [112], 'is': [113, 165], 'proposed.': [114], 'This': [115], 'ensures': [117], 'camouflage': [119], 'information': [122], 'while': [123], 'preserving': [124], 'integrity': [126], 'utility': [128, 226], 'trained': [130], 'Additionally,': [132], 'approach': [134], 'provides': [135], 'automated': [136, 233], 'preprocessing,': [137, 235], 'enhancing': [138], 'performance': [140], 'Message': [144], 'packet': [145], 'features': [146, 213], 'were': [147], 'derived,': [148], 'extracted,': [149], 'analyzed': [151], 'CICIoT2023': [154], 'dataset': [155], '(PCAP': [156], 'files)': [157], 'using': [158, 214], 'Wireshark.': [159], 'proposed': [161, 221], 'replacement': [162], 'scheme': [164], 'with': [167, 209], 'classifiers': [169], 'detect': [171], 'attacks,': [172], 'achieving': [173], 'accuracy': [175], '88.94%': [177], '86.61%': [179], 'Random': [182], 'Forest': [183], '(RF)': [184], 'Deep': [186], 'Neural': [187], 'Network': [188], '(DNN)': [189], 'models,': [190], 'respectively,': [191], 'utilizing': [192], '100': [193], 'features.': [194, 218], 'These': [195], 'results': [196], 'are': [197], 'compared': [198], 'accuracies': [200], '90.16%': [202], '94.81%': [204], 'same': [207], 'models': [208], 'up': [210], '15': [212], 'genetic': [215], 'algorithm-based': [216], 'correlation': [217], 'Finally,': [219], 'RF': [222], 'demonstrates': [224], 'its': [225], 'across': [227], 'multiple': [228], 'domains,': [229], 'including': [230], 'preservation,': [232], 'protection': [237], 'user': [240], 'Generative': [243], 'Pre-Training': [244], 'Transformer': [245], '(GPT)': [246], 'applications': [247], 'as': [248, 250], 'well': [249]}",2024,"['Computer science', 'Encoding (memory)', 'Mechanism (biology)', 'Internet of Things', 'Computer security', 'Information privacy', 'Ecosystem', 'Internet privacy', 'Artificial intelligence', 'Ecology', 'Biology', 'Philosophy', 'Epistemology']","The Internet of Things (IoT) ecosystem presents substantial challenges in terms of privacy and security, rendering it an attractive target for malicious actors. In this context, the literature review highlights the ongoing difficulty in addressing privacy and security through a unified mechanism owing to the heterogeneous nature of IoT devices, their dynamic behavior, and the continual advancement of intelligent hacking tools. Hence, encoding techniques have been considered from the perspective of privacy in Artificial Intelligence (AI) models. To overcome these challenges, this study introduces an integrated single mechanism for privacy and security in the IoT. In order to safeguard sensitive data during AI model training, a novel privacy mechanism called Replacement Encoding (RE) is proposed. This mechanism ensures the camouflage of sensitive information while preserving the integrity and utility of trained models. Additionally, this approach provides automated preprocessing, enhancing the performance of AI models. Message packet features were derived, extracted, and analyzed from the CICIoT2023 dataset (PCAP files) using Wireshark. The proposed replacement encoding scheme is integrated with AI classifiers to detect attacks, achieving an accuracy of 88.94% and 86.61% for the Random Forest (RF) and Deep Neural Network (DNN) models, respectively, utilizing 100 features. These results are compared to accuracies of 90.16% and 94.81% for the same models with up to 15 features using genetic algorithm-based correlation features. Finally, the proposed RF mechanism demonstrates its utility across multiple domains, including privacy preservation, automated data preprocessing, and protection of sensitive user data in Generative Pre-Training Transformer (GPT) applications as well as AI models."
https://openalex.org/W4376122803,Leveraging Generative AI Models for Synthetic Data Generation in Healthcare: Balancing Research and Privacy,"{'The': [0], 'widespread': [1], 'adoption': [2], 'of': [3], 'electronic': [4], 'health': [5], 'records': [6], 'and': [7, 23, 32, 39, 50, 61, 81, 89, 94, 114], 'digital': [8], 'healthcare': [9, 105], 'data': [10, 29, 42, 59, 78, 85, 99, 110], 'has': [11, 100], 'created': [12], 'a': [13, 53], 'demand': [14], 'for': [15, 73, 79], 'data-driven': [16], 'insights': [17], 'to': [18, 56, 103], 'enhance': [19], 'patient': [20, 28, 62, 77, 109], 'outcomes,': [21], 'diagnostics,': [22], 'treatments.': [24], 'However,': [25], 'using': [26, 44], 'real': [27], 'presents': [30], 'privacy': [31, 63, 113], 'regulatory': [33], 'challenges,': [34, 93], 'including': [35], 'compliance': [36], 'with': [37], 'HIPAA': [38], 'GDPR.': [40], 'Synthetic': [41, 98], 'generation,': [43], 'generative': [45, 70], 'AI': [46, 71], 'models': [47, 72], 'like': [48], 'GANs': [49], 'VAEs': [51], 'offers': [52], 'promising': [54], 'solution': [55], 'balance': [57], 'valuable': [58], 'access': [60], 'protection.': [64], 'In': [65], 'this': [66], 'paper,': [67], 'we': [68], 'examine': [69], 'creating': [74], 'realistic,': [75], 'anonymized': [76, 108], 'research': [80, 96], 'training,': [82], 'explore': [83], 'synthetic': [84], 'applications': [86], 'in': [87], 'healthcare,': [88], 'discuss': [90], 'its': [91], 'benefits,': [92], 'future': [95], 'directions.': [97], 'the': [101], 'potential': [102], 'revolutionize': [104], 'by': [106], 'providing': [107], 'while': [111], 'preserving': [112], 'enabling': [115], 'versatile': [116], 'applications.': [117]}",2023,"['Computer science', 'Data science', 'Health care', 'Generative grammar', 'Generative model', 'Information privacy', 'Synthetic data', 'Health records', 'Internet privacy', 'Artificial intelligence', 'Economics', 'Economic growth']","The widespread adoption of electronic health records and digital healthcare data has created a demand for data-driven insights to enhance patient outcomes, diagnostics, and treatments. However, using real patient data presents privacy and regulatory challenges, including compliance with HIPAA and GDPR. Synthetic data generation, using generative AI models like GANs and VAEs offers a promising solution to balance valuable data access and patient privacy protection. In this paper, we examine generative AI models for creating realistic, anonymized patient data for research and training, explore synthetic data applications in healthcare, and discuss its benefits, challenges, and future research directions. Synthetic data has the potential to revolutionize healthcare by providing anonymized patient data while preserving privacy and enabling versatile applications."
https://openalex.org/W4392830310,A Taxonomy of AI Techniques for Security and Privacy in Cyber–Physical Systems,"{'This': [0, 26, 54, 94], 'research': [1, 118, 162], 'paper': [2, 27, 55], 'addresses': [3], 'the': [4, 17, 62, 77, 117, 120, 153, 164, 176], 'concerns': [5, 66, 133, 171], 'related': [6], 'to': [7, 88, 128, 143, 211, 222], 'security': [8, 34, 63, 90, 130, 144, 168], 'and': [9, 15, 35, 49, 64, 83, 91, 110, 114, 131, 145, 169, 174], 'privacy': [10, 36, 65, 92, 132, 146, 170], 'in': [11, 22, 38, 67, 134, 172, 180, 233], 'cyber–physical': [12], 'systems': [13], '(CPS)': [14], 'explores': [16, 119], 'role': [18, 177], 'ofartificial': [19], 'intelligence': [20], '(AI)': [21], 'addressing': [23, 167], 'these': [24, 157, 182], 'concerns.': [25], 'presents': [28], 'a': [29, 71, 99], 'comprehensive': [30], 'classification': [31], 'of': [32, 44, 80, 138, 156, 166, 178, 199, 209], 'various': [33, 121], 'threats': [37], 'CPS,': [39, 105], 'providing': [40], 'an': [41], 'organized': [42], 'overview': [43], 'potential': [45, 154], 'risks,': [46], 'economic': [47], 'loss,': [48], 'enabling': [50, 106], 'effective': [51], 'risk': [52], 'assessment.': [53], 'highlights': [56, 175], 'how': [57], 'AI': [58, 82, 122, 179], 'can': [59, 125], 'help': [60], 'address': [61, 129], 'CPS': [68, 173], 'by': [69], 'presenting': [70], 'detailed': [72], 'flow': [73], 'chart': [74], 'that': [75, 124, 204], 'illustrates': [76], 'stepby-step': [78], 'process': [79], 'using': [81], 'machine': [84], 'learning': [85], '(ML)': [86], 'techniques': [87, 123, 140], 'detect': [89], 'issues.': [93], 'integrated': [95], 'approach': [96], 'serves': [97], 'as': [98, 225], 'guide': [100], 'for': [101], 'designing': [102], 'ML-based': [103], 'secure': [104], 'proactive': [107], 'defense': [108], 'mechanisms': [109], 'improving': [111], 'incident': [112], 'response': [113], 'recovery.': [115], 'Furthermore,': [116], 'be': [126], 'employed': [127], 'CPS.': [135], 'A': [136], 'taxonomy': [137], 'ML': [139], 'specifically': [141], 'relevant': [142], 'issues': [147], 'is': [148, 219], 'provided,': [149], 'offering': [150], 'insights': [151], 'into': [152], 'applications': [155], 'techniques.': [158], 'In': [159], 'conclusion,': [160], 'this': [161, 212, 223, 234], 'emphasizes': [163], 'significance': [165], 'tackling': [181], 'challenges.': [183], 'Received:': [184], '23': [185], 'August': [186], '2023': [187, 192], '|': [188, 193], 'Revised:': [189], '18': [190], 'December': [191], 'Accepted:': [194], '11': [195], 'January': [196], '2024': [197], 'Conflicts': [198], 'Interest': [200], 'The': [201], 'author': [202], 'declares': [203], 'he': [205], 'has': [206], 'no': [207, 226], 'conflicts': [208], 'interest': [210], 'work.': [213], 'Data': [214, 217], 'Availability': [215], 'Statement': [216], 'sharing': [218], 'not': [220], 'applicable': [221], 'article': [224], 'new': [227], 'data': [228], 'were': [229], 'created': [230], 'or': [231], 'analyzed': [232], 'study.': [235]}",2024,"['Cyber-physical system', 'Computer security', 'Taxonomy (biology)', 'Computer science', 'Internet privacy', 'Information privacy', 'Biology', 'Ecology', 'Operating system']","This research paper addresses the concerns related to security and privacy in cyber–physical systems (CPS) and explores the role ofartificial intelligence (AI) in addressing these concerns. This paper presents a comprehensive classification of various security and privacy threats in CPS, providing an organized overview of potential risks, economic loss, and enabling effective risk assessment. This paper highlights how AI can help address the security and privacy concerns in CPS by presenting a detailed flow chart that illustrates the stepby-step process of using AI and machine learning (ML) techniques to detect security and privacy issues. This integrated approach serves as a guide for designing ML-based secure CPS, enabling proactive defense mechanisms and improving incident response and recovery. Furthermore, the research explores the various AI techniques that can be employed to address security and privacy concerns in CPS. A taxonomy of ML techniques specifically relevant to security and privacy issues is provided, offering insights into the potential applications of these techniques. In conclusion, this research emphasizes the significance of addressing security and privacy concerns in CPS and highlights the role of AI in tackling these challenges. Received: 23 August 2023 | Revised: 18 December 2023 | Accepted: 11 January 2024 Conflicts of Interest The author declares that he has no conflicts of interest to this work. Data Availability Statement Data sharing is not applicable to this article as no new data were created or analyzed in this study."
https://openalex.org/W4405626355,Clio: Privacy-Preserving Insights into Real-World AI Use,"{'How': [0], 'are': [1, 110], 'AI': [2, 53, 235, 245], 'assistants': [3, 54], 'being': [4, 111], 'used': [5, 112], 'in': [6, 13, 99, 113, 165], 'the': [7, 68, 114, 142, 218], 'real': [8, 115], 'world?': [9], 'While': [10], 'model': [11], 'providers': [12], 'theory': [14], 'have': [15, 31], 'a': [16, 48, 84, 239], 'window': [17], 'into': [18], 'this': [19, 34, 79], 'impact': [20], 'via': [21], 'their': [22], ""users'"": [23], 'data,': [24], 'both': [25], 'privacy': [26, 90], 'concerns': [27], 'and': [28, 46, 58, 89, 122, 137, 152, 170, 209, 227, 247], 'practical': [29], 'challenges': [30], 'made': [32], 'analyzing': [33], 'data': [35], 'difficult.': [36], 'To': [37], 'address': [38], 'these': [39], 'issues,': [40], 'we': [41, 104, 177], 'present': [42], 'Clio': [43, 179, 237], '(Claude': [44], 'insights': [45, 106], 'observations),': [47], 'privacy-preserving': [49], 'platform': [50, 241], 'that': [51, 159], 'uses': [52], 'themselves': [55], 'to': [56, 73, 131, 180, 189], 'analyze': [57], 'surface': [59], 'aggregated': [60], 'usage': [61], 'patterns': [62, 158], 'across': [63, 161], 'millions': [64], 'of': [65, 87, 202, 220, 233], 'conversations,': [66, 124], 'without': [67], 'need': [69], 'for': [70, 194, 242], 'human': [71], 'reviewers': [72], 'read': [74], 'raw': [75], 'conversations.': [76], 'We': [77, 95, 139, 215], 'validate': [78], 'can': [80], 'be': [81], 'done': [82], 'with': [83], 'high': [85], 'degree': [86], 'accuracy': [88], 'by': [91, 185], 'conducting': [92], 'extensive': [93], 'evaluations.': [94], 'demonstrate': [96], ""Clio's"": [97], 'usefulness': [98], 'two': [100], 'broad': [101], 'ways.': [102], 'First,': [103], 'share': [105], 'about': [107], 'how': [108], 'models': [109], 'world': [116, 207], 'from': [117, 126], 'one': [118], 'million': [119], 'Claude.ai': [120, 149], 'Free': [121], 'Pro': [123], 'ranging': [125], 'providing': [127, 132], 'advice': [128], 'on': [129, 134, 148], 'hairstyles': [130], 'guidance': [133], 'Git': [135], 'operations': [136], 'concepts.': [138], 'also': [140, 216], 'identify': [141], 'most': [143], 'common': [144], 'high-level': [145], 'use': [146, 178], 'cases': [147], '(coding,': [150], 'writing,': [151], 'research': [153], 'tasks)': [154], 'as': [155, 157, 223, 225], 'well': [156, 224], 'differ': [160], 'languages': [162], '(e.g.,': [163], 'conversations': [164], 'Japanese': [166], 'discuss': [167, 217], 'elder': [168], 'care': [169], 'aging': [171], 'populations': [172], 'at': [173], 'higher-than-typical': [174], 'rates).': [175], 'Second,': [176], 'make': [181], 'our': [182, 191, 211, 221], 'systems': [183], 'safer': [184], 'identifying': [186], 'coordinated': [187], 'attempts': [188], 'abuse': [190], 'systems,': [192], 'monitoring': [193, 213], 'unknown': [195], 'unknowns': [196], 'during': [197], 'critical': [198], 'periods': [199], 'like': [200], 'launches': [201], 'new': [203], 'capabilities': [204], 'or': [205], 'major': [206], 'events,': [208], 'improving': [210], 'existing': [212], 'systems.': [214], 'limitations': [219], 'approach,': [222], 'risks': [226], 'ethical': [228], 'concerns.': [229], 'By': [230], 'enabling': [231], 'analysis': [232], 'real-world': [234], 'usage,': [236], 'provides': [238], 'scalable': [240], 'empirically': [243], 'grounded': [244], 'safety': [246], 'governance.': [248]}",2024,"['Internet privacy', 'Computer science', 'Computer security', 'Data science', 'Business']","How are AI assistants being used in the real world? While model providers in theory have a window into this impact via their users' data, both privacy concerns and practical challenges have made analyzing this data difficult. To address these issues, we present Clio (Claude insights and observations), a privacy-preserving platform that uses AI assistants themselves to analyze and surface aggregated usage patterns across millions of conversations, without the need for human reviewers to read raw conversations. We validate this can be done with a high degree of accuracy and privacy by conducting extensive evaluations. We demonstrate Clio's usefulness in two broad ways. First, we share insights about how models are being used in the real world from one million Claude.ai Free and Pro conversations, ranging from providing advice on hairstyles to providing guidance on Git operations and concepts. We also identify the most common high-level use cases on Claude.ai (coding, writing, and research tasks) as well as patterns that differ across languages (e.g., conversations in Japanese discuss elder care and aging populations at higher-than-typical rates). Second, we use Clio to make our systems safer by identifying coordinated attempts to abuse our systems, monitoring for unknown unknowns during critical periods like launches of new capabilities or major world events, and improving our existing monitoring systems. We also discuss the limitations of our approach, as well as risks and ethical concerns. By enabling analysis of real-world AI usage, Clio provides a scalable platform for empirically grounded AI safety and governance."
https://openalex.org/W4404867402,AI Ethics and Transparency in Operations Management: How Governance Mechanisms Can Reduce Data Bias and Privacy Risks,"{'The': [0], 'use': [1, 47], 'of': [2, 45, 91, 142], 'artificial': [3], 'intelligence': [4], '(AI)': [5], 'in': [6, 17, 37, 48, 97, 123, 186], 'operations': [7, 185], 'management': [8], 'holds': [9], 'the': [10, 42, 67, 72, 88, 98, 111, 140, 168], 'key': [11], 'to': [12, 53, 86, 103, 167, 178, 182], 'efficiency,': [13], 'precision': [14], 'and': [15, 31, 58, 71, 135, 153, 192], 'agility': [16], 'business': [18], 'decision-making,': [19], 'yet': [20], 'it': [21], 'also': [22], 'involves': [23], 'ethical': [24, 43, 172], 'challenges': [25, 90], 'such': [26, 65, 131], 'as': [27, 66, 132, 147, 149], 'fairness,': [28], 'accountability,': [29], 'transparency': [30], 'privacy': [32, 56, 134], 'that': [33, 124, 128, 189], 'can': [34, 109, 138, 154], 'undermine': [35], 'trust': [36], 'AI.': [38], 'This': [39, 164], 'paper': [40, 80, 165], 'examines': [41], 'considerations': [44], 'AI': [46, 69, 173, 184], 'operations,': [49], 'paying': [50], 'particular': [51], 'attention': [52], 'data': [54, 114], 'bias,': [55], 'risks': [57], 'governance.': [59], 'Drawing': [60], 'on': [61, 171, 180], 'major': [62], 'governance': [63, 84], 'frameworks': [64], 'OECD': [68], 'Principles': [70], 'EUs': [73], 'Ethics': [74], 'Guidelines': [75], 'for': [76, 116], 'Trustworthy': [77], 'AI,': [78], 'this': [79], 'proposes': [81], 'a': [82, 187], 'hybrid': [83], 'model': [85], 'address': [87], 'unique': [89], 'operational': [92], 'contexts.': [93], 'A': [94], 'case': [95, 125], 'study': [96], 'financial': [99], 'sector': [100], 'is': [101, 190], 'used': [102], 'further': [104], 'explain': [105], 'how': [106, 181], 'privacy-preserving': [107, 129], 'techniques': [108], 'safeguard': [110], 'sensitive': [112], 'customer': [113, 118, 156], 'needed': [115], 'AI-driven': [117], 'service.': [119], 'Extensive': [120], 'experimentation': [121], 'conducted': [122], 'has': [126], 'shown': [127], 'methods': [130], 'differential': [133], 'federated': [136], 'learning': [137], 'reduce': [139], 'incidence': [141], 'unauthorised': [143], 'data-access': [144], 'events': [145], 'by': [146, 158, 174], 'much': [148], '30': [150], 'per': [151, 162], 'cent': [152], 'improve': [155], 'satisfaction': [157], 'more': [159], 'than': [160], '20': [161], 'cent.': [163], 'contributes': [166], 'dynamic': [169], 'discourse': [170], 'offering': [175], 'practical': [176], 'recommendations': [177], 'organisations': [179], 'conduct': [183], 'way': [188], 'responsible': [191], 'compliant.': [193]}",2024,"['Transparency (behavior)', 'Corporate governance', 'Information privacy', 'Business', 'Data governance', 'Internet privacy', 'Computer security', 'Data Protection Act 1998', 'Computer science', 'Data quality', 'Marketing', 'Finance', 'Metric (unit)']","The use of artificial intelligence (AI) in operations management holds the key to efficiency, precision and agility in business decision-making, yet it also involves ethical challenges such as fairness, accountability, transparency and privacy that can undermine trust in AI. This paper examines the ethical considerations of AI use in operations, paying particular attention to data bias, privacy risks and governance. Drawing on major governance frameworks such as the OECD AI Principles and the EUs Ethics Guidelines for Trustworthy AI, this paper proposes a hybrid governance model to address the unique challenges of operational contexts. A case study in the financial sector is used to further explain how privacy-preserving techniques can safeguard the sensitive customer data needed for AI-driven customer service. Extensive experimentation conducted in that case has shown that privacy-preserving methods such as differential privacy and federated learning can reduce the incidence of unauthorised data-access events by as much as 30 per cent and can improve customer satisfaction by more than 20 per cent. This paper contributes to the dynamic discourse on ethical AI by offering practical recommendations to organisations on how to conduct AI operations in a way that is responsible and compliant."
https://openalex.org/W4390519417,The Future of AI in IoT: Emerging Trends in Intelligent Data Analysis and Privacy Protection,"{'This': [0], 'paper': [1, 42], 'explores': [2], 'the': [3, 11, 61, 81, 88, 107], 'dynamic': [4], 'intersection': [5], 'of': [6, 13, 63], 'Artificial': [7], 'Intelligence': [8], '(AI)': [9], 'and': [10, 24, 36, 54, 74, 98, 118], 'Internet': [12], 'Things': [14], '(IoT),': [15], 'focusing': [16], 'on': [17], 'emerging': [18], 'trends': [19], 'in': [20, 38, 46, 66, 83, 127], 'intelligent': [21], 'data': [22, 48, 94], 'analysis': [23], 'privacy': [25, 64, 117], 'protection.': [26], 'Employing': [27], 'a': [28, 122], 'systematic': [29], 'literature': [30], 'review,': [31], 'we': [32], 'analyze': [33], 'recent': [34], 'advancements': [35, 115], 'challenges': [37, 82], 'AI-IoT': [39], 'integration.': [40], 'The': [41, 77, 104], 'highlights': [43], 'key': [44], 'developments': [45], 'sensor': [47], 'anomaly': [49], 'detection,': [50], 'AI-driven': [51], 'big-data': [52], 'analytics,': [53], 'IoT-based': [55], 'communication': [56], 'techniques.': [57], 'It': [58], 'delves': [59], 'into': [60], 'complexities': [62], 'protection': [65], 'IoT,': [67, 86], 'examining': [68], 'innovative': [69], 'solutions': [70, 111], 'like': [71, 102], 'federated': [72], 'learning': [73], 'blockchain': [75], 'technologies.': [76], 'study': [78], 'also': [79], 'addresses': [80], 'AI': [84], 'for': [85, 109, 124], 'prioritizing': [87], 'most': [89], 'pressing': [90], 'issues': [91], 'such': [92], 'as': [93], 'security,': [95], 'ethical': [96], 'implementation,': [97], 'compliance': [99], 'with': [100, 116], 'regulations': [101], 'GDPR.': [103], 'research': [105], 'underscores': [106], 'need': [108], 'adaptable': [110], 'that': [112], 'balance': [113], 'technological': [114], 'security': [119], 'considerations,': [120], 'setting': [121], 'path': [123], 'future': [125], 'exploration': [126], 'AI-empowered': [128], 'IoT': [129], 'applications.': [130]}",2023,"['Internet of Things', 'Computer science', 'Big data', 'Computer security', 'Intersection (aeronautics)', 'Analytics', 'Key (lock)', 'Data science', 'Information privacy', 'Data Protection Act 1998', 'Engineering', 'Data mining', 'Aerospace engineering']","This paper explores the dynamic intersection of Artificial Intelligence (AI) and the Internet of Things (IoT), focusing on emerging trends in intelligent data analysis and privacy protection. Employing a systematic literature review, we analyze recent advancements and challenges in AI-IoT integration. The paper highlights key developments in sensor data anomaly detection, AI-driven big-data analytics, and IoT-based communication techniques. It delves into the complexities of privacy protection in IoT, examining innovative solutions like federated learning and blockchain technologies. The study also addresses the challenges in AI for IoT, prioritizing the most pressing issues such as data security, ethical implementation, and compliance with regulations like GDPR. The research underscores the need for adaptable solutions that balance technological advancements with privacy and security considerations, setting a path for future exploration in AI-empowered IoT applications."
https://openalex.org/W4411275423,Generative AI risks and resilience: How users adapt to hallucination and privacy challenges,"{'Purpose:': [0], 'This': [1], 'study': [2, 37, 110, 159], 'examines': [3], 'two': [4], 'central': [5], 'risks': [6], 'affecting': [7], 'continued': [8, 168, 184], 'use': [9, 42, 169], 'of': [10, 135, 145, 170], 'generative': [11], 'AI': [12], '(GenAI)—AI': [13], 'hallucinations': [14], 'and': [15, 63, 78, 105, 121, 126, 151, 194], 'privacy': [16], 'concerns—and': [17], 'explores': [18], 'how': [19, 132], 'protective': [20, 80, 176, 181], 'behaviors': [21, 182], 'serve': [22], 'as': [23, 147], 'adaptive': [24], 'mechanisms': [25], 'to': [26, 60, 115], 'mitigate': [27], 'these': [28], 'risks.': [29], 'Design/methodology/approach:': [30], 'Drawing': [31], 'on': [32], 'Protection': [33, 112], 'Motivation': [34, 113], 'Theory,': [35], 'the': [36, 101, 116, 142, 186], 'tests': [38], 'a': [39, 52, 149], 'risk-adaptive': [40], 'GenAI': [41, 117, 154, 171], 'model': [43], 'using': [44], 'survey': [45], 'data': [46], 'from': [47], '789': [48], 'users': [49, 173], 'recruited': [50], 'via': [51], 'Prolific': [53], 'panel.': [54], 'Structural': [55], 'equation': [56], 'modeling': [57], 'is': [58, 84], 'employed': [59], 'analyze': [61], 'direct': [62], 'moderating': [64], 'effects.': [65], 'Findings:': [66], 'Privacy': [67], 'concerns': [68], 'negatively': [69], 'influence': [70], 'user': [71], 'attitudes': [72, 89], 'while': [73], 'positively': [74, 91], 'predicting': [75], 'both': [76, 148], 'personal': [77], 'system-level': [79, 127], 'behaviors.': [81, 129, 177], 'Hallucination': [82], 'risk': [83, 125, 136, 146, 163, 175], 'similarly': [85], 'associated': [86], 'with': [87], 'negative': [88], 'but': [90], 'predicts': [92], 'information': [93, 97], 'verification.': [94], 'Notably,': [95], 'only': [96], 'verification': [98], 'significantly': [99], 'moderates': [100], 'link': [102], 'between': [103], 'attitude': [104], 'continuance': [106], 'intention.': [107], 'Originality:': [108], 'The': [109, 158], 'extends': [111], 'Theory': [114], 'context': [118], 'by': [119], 'developing': [120], 'validating': [122], 'new': [123], 'constructs—hallucination': [124], 'privacy-protective': [128], 'It': [130], 'reveals': [131], 'different': [133], 'types': [134], 'trigger': [137], 'distinct': [138], 'behavioral': [139], 'adaptations,': [140], 'highlighting': [141, 179], 'dual': [143], 'role': [144], 'deterrent': [150], 'catalyst': [152], 'in': [153], 'adoption.': [155], 'Practical': [156], 'implications:': [157], 'offers': [160], 'insights': [161], 'that': [162], 'perceptions': [164], 'may': [165], 'not': [166], 'deter': [167], 'when': [172], 'perform': [174], 'By': [178], 'which': [180], 'enhance': [183], 'use,': [185], 'findings': [187], 'inform': [188], 'risk-mitigation': [189], 'strategies': [190], 'for': [191], 'developers,': [192], 'educators,': [193], 'regulators.': [195]}",2025,"['Resilience (materials science)', 'Generative grammar', 'Computer science', 'Artificial intelligence', 'Physics', 'Thermodynamics']","Purpose: This study examines two central risks affecting continued use of generative AI (GenAI)—AI hallucinations and privacy concerns—and explores how protective behaviors serve as adaptive mechanisms to mitigate these risks. Design/methodology/approach: Drawing on Protection Motivation Theory, the study tests a risk-adaptive GenAI use model using survey data from 789 users recruited via a Prolific panel. Structural equation modeling is employed to analyze direct and moderating effects. Findings: Privacy concerns negatively influence user attitudes while positively predicting both personal and system-level protective behaviors. Hallucination risk is similarly associated with negative attitudes but positively predicts information verification. Notably, only information verification significantly moderates the link between attitude and continuance intention. Originality: The study extends Protection Motivation Theory to the GenAI context by developing and validating new constructs—hallucination risk and system-level privacy-protective behaviors. It reveals how different types of risk trigger distinct behavioral adaptations, highlighting the dual role of risk as both a deterrent and catalyst in GenAI adoption. Practical implications: The study offers insights that risk perceptions may not deter continued use of GenAI when users perform risk protective behaviors. By highlighting which protective behaviors enhance continued use, the findings inform risk-mitigation strategies for developers, educators, and regulators."
https://openalex.org/W4396893786,AI-Driven Privacy in Elderly Care: Developing a Comprehensive Solution for Camera-Based Monitoring of Older Adults,"{'The': [0, 133], 'need': [1], 'for': [2, 50], 'privacy': [3, 38, 144, 171], 'in': [4, 127, 160, 172], 'elderly': [5, 36, 173], 'care': [6, 174], 'is': [7, 81, 138], 'crucial,': [8], 'especially': [9], 'where': [10], 'constant': [11], 'monitoring': [12, 27, 70], 'can': [13], 'intrude': [14], 'on': [15], 'personal': [16], 'dignity.': [17], 'This': [18, 80, 154], 'research': [19], 'introduces': [20], 'the': [21, 32, 44, 67, 72, 84, 98, 128, 136, 157], 'development': [22], 'of': [23, 35, 86, 117, 130, 135], 'a': [24, 77, 102, 108, 131], 'unique': [25], 'camera-based': [26], 'system': [28, 45, 100, 137], 'designed': [29], 'to': [30, 119, 140, 166], 'address': [31], 'dual': [33], 'objectives': [34], 'care:': [37], 'and': [39, 94, 123, 147, 163, 170], 'safety.': [40], 'At': [41], 'its': [42, 142, 164], 'core,': [43], 'employs': [46], 'an': [47], 'AI-driven': [48], 'technique': [49, 146], 'real-time': [51, 91], 'subject': [52, 68], 'anonymization.': [53], 'Unlike': [54], 'traditional': [55], 'methods': [56], 'such': [57], 'as': [58], 'pixelization': [59], 'or': [60], 'blurring,': [61], 'our': [62], 'proposed': [63, 99], 'approach': [64], 'effectively': [65], 'removes': [66], 'under': [69], 'from': [71], 'scene,': [73], 'replacing': [74], 'them': [75], 'with': [76, 114], 'two-dimensional': [78], 'avatar.': [79], 'achieved': [82], 'through': [83], 'use': [85], 'YOLOv8,': [87], 'which': [88], 'facilitates': [89], 'accurate': [90], 'person': [92], 'detection': [93, 104, 149], 'pose': [95], 'estimation.': [96], 'Furthermore,': [97], 'incorporates': [101], 'fall': [103, 148], 'algorithm': [105], 'that': [106], 'utilizes': [107], 'residual': [109], 'causal': [110], 'convolutional': [111], 'network': [112], 'together': [113], 'motion': [115], 'features': [116], 'persons': [118], 'identify': [120], 'emergency': [121], 'situations': [122], 'promptly': [124], 'notify': [125], 'caregivers': [126], 'event': [129], 'fall.': [132], 'effectiveness': [134], 'evaluated': [139], 'emphasize': [141], 'advanced': [143], 'protection': [145], 'capabilities': [150], 'using': [151], 'several': [152], 'metrics.': [153], 'evaluation': [155], 'demonstrates': [156], 'system’s': [158], 'proficiency': [159], 'real-world': [161], 'applications': [162], 'potential': [165], 'enhance': [167], 'both': [168], 'safety': [169], 'environments.': [175]}",2024,"['Computer science', 'Internet privacy', 'Psychology', 'Medicine']","The need for privacy in elderly care is crucial, especially where constant monitoring can intrude on personal dignity. This research introduces the development of a unique camera-based monitoring system designed to address the dual objectives of elderly care: privacy and safety. At its core, the system employs an AI-driven technique for real-time subject anonymization. Unlike traditional methods such as pixelization or blurring, our proposed approach effectively removes the subject under monitoring from the scene, replacing them with a two-dimensional avatar. This is achieved through the use of YOLOv8, which facilitates accurate real-time person detection and pose estimation. Furthermore, the proposed system incorporates a fall detection algorithm that utilizes a residual causal convolutional network together with motion features of persons to identify emergency situations and promptly notify caregivers in the event of a fall. The effectiveness of the system is evaluated to emphasize its advanced privacy protection technique and fall detection capabilities using several metrics. This evaluation demonstrates the system’s proficiency in real-world applications and its potential to enhance both safety and privacy in elderly care environments."
https://openalex.org/W4380551867,Preserving privacy in domain transfer of medical AI models comes at no performance costs: The integral role of differential privacy,"{'Developing': [0], 'robust': [1], 'and': [2, 134, 144, 148, 170], 'effective': [3], 'artificial': [4], 'intelligence': [5], '(AI)': [6], 'models': [7, 22, 68, 75, 219], 'in': [8, 127, 135, 245], 'medicine': [9], 'requires': [10], 'access': [11], 'to': [12, 36, 74, 188, 197, 211], 'large': [13, 26], 'amounts': [14], 'of': [15, 20, 58, 67, 101, 105, 122, 243], 'patient': [16, 47], 'data.': [17], 'The': [18], 'use': [19, 104], 'AI': [21, 106, 249], 'solely': [23], 'trained': [24, 69, 76], 'on': [25, 79, 255], 'multi-institutional': [27], 'datasets': [28], 'can': [29], 'help': [30], 'with': [31, 70, 142, 178], 'this,': [32], 'yet': [33], 'the': [34, 56, 65, 84, 96, 102, 120, 152, 155, 162, 241], 'imperative': [35], 'ensure': [37], 'data': [38, 80], 'privacy': [39, 60, 181], 'remains,': [40], 'particularly': [41], 'as': [42, 72, 161, 165, 167], 'membership': [43], 'inference': [44], 'risks': [45], 'breaching': [46], 'confidentiality.': [48], 'As': [49], 'a': [50], 'proposed': [51], 'remedy,': [52], 'we': [53, 118, 227, 237], 'advocate': [54, 239], 'for': [55, 206, 224, 240], 'integration': [57], 'differential': [59], '(DP).': [61], 'We': [62, 139], 'specifically': [63], 'investigate': [64], 'performance': [66, 222, 231], 'DP': [71, 78, 218, 244], 'compared': [73], 'without': [77], 'from': [81, 115], 'institutions': [82], 'that': [83, 98, 175, 217, 229], 'model': [85], 'had': [86], 'not': [87, 234], 'seen': [88], 'during': [89], 'its': [90, 252], 'training': [91, 246], '(i.e.,': [92], 'external': [93], 'validation)': [94], '-': [95, 201, 205], 'situation': [97], 'is': [99, 232], 'reflective': [100], 'clinical': [103], 'models.': [107], 'By': [108], 'leveraging': [109], 'more': [110], 'than': [111, 203], '590,000': [112], 'chest': [113], 'radiographs': [114], 'five': [116], 'institutions,': [117], 'evaluated': [119], 'efficacy': [121], 'DP-enhanced': [123], 'domain': [124], 'transfer': [125], '(DP-DT)': [126], 'diagnosing': [128], 'cardiomegaly,': [129], 'pleural': [130], 'effusion,': [131], 'pneumonia,': [132], 'atelectasis,': [133], 'identifying': [136], 'healthy': [137], 'subjects.': [138], 'juxtaposed': [140], 'DP-DT': [141, 195], 'non-DP-DT': [143, 189], 'examined': [145], 'diagnostic': [146, 247], 'accuracy': [147], 'demographic': [149], 'fairness': [150], 'using': [151], 'area': [153], 'under': [154], 'receiver': [156], 'operating': [157], 'characteristic': [158], 'curve': [159], '(AUC)': [160], 'main': [163], 'metric,': [164], 'well': [166], 'accuracy,': [168], 'sensitivity,': [169], 'specificity.': [171], 'Our': [172], 'results': [173], 'show': [174, 228], 'DP-DT,': [176], 'even': [177], 'exceptionally': [179], 'high': [180], 'levels': [182], '(epsilon': [183], 'around': [184], '1),': [185], 'performs': [186], 'comparably': [187], '(P&gt;0.119': [190], 'across': [191], 'all': [192, 208], 'domains).': [193], 'Furthermore,': [194], 'led': [196], 'marginal': [198], 'AUC': [199], 'differences': [200], 'less': [202], '1%': [204], 'nearly': [207], 'subgroups,': [209], 'relative': [210], 'non-DP-DT.': [212], 'Despite': [213], 'consistent': [214], 'evidence': [215], 'suggesting': [216], 'induce': [220], 'significant': [221], 'degradation': [223], 'on-domain': [225], 'applications,': [226], 'off-domain': [230], 'almost': [233], 'affected.': [235], 'Therefore,': [236], 'ardently': [238], 'adoption': [242], 'medical': [248], 'models,': [250], 'given': [251], 'minimal': [253], 'impact': [254], 'performance.': [256]}",2023,"['Receiver operating characteristic', 'Computer science', 'Inference', 'Metric (unit)', 'Domain (mathematical analysis)', 'Artificial intelligence', 'Machine learning', 'Confidentiality', 'Data mining', 'Medicine', 'Computer security', 'Mathematics', 'Mathematical analysis', 'Economics', 'Operations management']","Developing robust and effective artificial intelligence (AI) models in medicine requires access to large amounts of patient data. The use of AI models solely trained on large multi-institutional datasets can help with this, yet the imperative to ensure data privacy remains, particularly as membership inference risks breaching patient confidentiality. As a proposed remedy, we advocate for the integration of differential privacy (DP). We specifically investigate the performance of models trained with DP as compared to models trained without DP on data from institutions that the model had not seen during its training (i.e., external validation) - the situation that is reflective of the clinical use of AI models. By leveraging more than 590,000 chest radiographs from five institutions, we evaluated the efficacy of DP-enhanced domain transfer (DP-DT) in diagnosing cardiomegaly, pleural effusion, pneumonia, atelectasis, and in identifying healthy subjects. We juxtaposed DP-DT with non-DP-DT and examined diagnostic accuracy and demographic fairness using the area under the receiver operating characteristic curve (AUC) as the main metric, as well as accuracy, sensitivity, and specificity. Our results show that DP-DT, even with exceptionally high privacy levels (epsilon around 1), performs comparably to non-DP-DT (P&gt;0.119 across all domains). Furthermore, DP-DT led to marginal AUC differences - less than 1% - for nearly all subgroups, relative to non-DP-DT. Despite consistent evidence suggesting that DP models induce significant performance degradation for on-domain applications, we show that off-domain performance is almost not affected. Therefore, we ardently advocate for the adoption of DP in training diagnostic medical AI models, given its minimal impact on performance."
https://openalex.org/W4399245582,Evaluating Privacy Leakage and Memorization Attacks on Large Language Models (LLMs) in Generative AI Applications,"{'The': [0, 103, 125], 'recent': [1], 'interest': [2], 'in': [3], 'the': [4, 19, 25, 65, 84, 98, 146], 'deployment': [5], 'of': [6, 27, 69, 100, 109, 135, 142, 148], 'Generative': [7], 'AI': [8], 'applications': [9], 'that': [10, 38, 71], 'use': [11], 'large': [12], 'language': [13], 'models': [14], '(LLMs)': [15], 'has': [16], 'brought': [17], 'to': [18], 'forefront': [20], 'significant': [21], 'privacy': [22], 'concerns,': [23], 'notably': [24], 'leakage': [26], 'Personally': [28], 'Identifiable': [29], 'Information': [30], '(PII)': [31], 'and': [32, 60, 67, 78, 90, 97, 115, 118, 145], 'other': [33], 'confidential': [34], 'or': [35, 49], 'protected': [36], 'information': [37, 70], 'may': [39, 72], 'have': [40], 'been': [41], 'memorized': [42], 'during': [43, 46], 'training,': [44], 'specifically': [45], 'a': [47, 139], 'fine-tuning': [48], 'customization': [50], 'process.': [51], 'We': [52], 'describe': [53], 'different': [54, 149], 'black-box': [55], 'attacks': [56, 101, 113, 120], 'from': [57, 75, 127], 'potential': [58], 'adversaries': [59], 'study': [61, 104], 'their': [62], 'impact': [63], 'on': [64], 'amount': [66], 'type': [68], 'be': [73], 'recovered': [74], 'commonly': [76], 'used': [77], 'deployed': [79], 'LLMs.': [80], 'Our': [81], 'research': [82], 'investigates': [83], 'relationship': [85], 'between': [86], 'PII': [87, 111], 'leakage,': [88], 'memorization,': [89], 'factors': [91], 'such': [92], 'as': [93], 'model': [94], 'size,': [95], 'architecture,': [96], 'nature': [99], 'employed.': [102], 'utilizes': [105], 'two': [106], 'broad': [107], 'categories': [108], 'attacks:': [110], 'leakage-focused': [112], '(auto-completion': [114], 'extraction': [116], 'attacks)': [117], 'memorization-focused': [119], '(various': [121], 'membership': [122], 'inference': [123], 'attacks).': [124], 'findings': [126], 'these': [128], 'investigations': [129], 'are': [130], 'quantified': [131], 'using': [132], 'an': [133], 'array': [134], 'evaluative': [136], 'metrics,': [137], 'providing': [138], 'detailed': [140], 'understanding': [141], 'LLM': [143], 'vulnerabilities': [144], 'effectiveness': [147], 'attacks.': [150]}",2024,"['Memorization', 'Leakage (economics)', 'Computer security', 'Generative grammar', 'Computer science', 'Internet privacy', 'Artificial intelligence', 'Psychology', 'Cognitive psychology', 'Economics', 'Macroeconomics']","The recent interest in the deployment of Generative AI applications that use large language models (LLMs) has brought to the forefront significant privacy concerns, notably the leakage of Personally Identifiable Information (PII) and other confidential or protected information that may have been memorized during training, specifically during a fine-tuning or customization process. We describe different black-box attacks from potential adversaries and study their impact on the amount and type of information that may be recovered from commonly used and deployed LLMs. Our research investigates the relationship between PII leakage, memorization, and factors such as model size, architecture, and the nature of attacks employed. The study utilizes two broad categories of attacks: PII leakage-focused attacks (auto-completion and extraction attacks) and memorization-focused attacks (various membership inference attacks). The findings from these investigations are quantified using an array of evaluative metrics, providing a detailed understanding of LLM vulnerabilities and the effectiveness of different attacks."
https://openalex.org/W4400656012,Mitigating Chatbots AI Data Privacy Violations in the Banking Sector: A Qualitative Grounded Theory Study,"{'This': [0], 'research': [1, 36, 52], 'study': [2, 115], 'examines': [3], 'the': [4, 48, 54, 89, 97, 109, 130, 139], 'impact': [5, 55, 90], 'of': [6, 44, 56, 76, 99, 132, 142], 'Artificial': [7], 'Intelligence': [8], '(AI)': [9], 'data': [10, 13, 27, 58, 102, 125, 151], 'poisoning': [11, 59, 126], 'on': [12, 91], 'privacy': [14, 153], 'violations': [15], 'in': [16, 25, 47, 135], 'AI-enabled': [17, 133], 'banking': [18, 49], 'chatbots,': [19], 'employing': [20], 'a': [21, 42, 74], 'qualitative': [22, 33], 'approach': [23], 'grounded': [24, 34], 'AI,': [26], 'privacy,': [28], 'and': [29, 85, 128], 'cybersecurity': [30], 'theories.': [31], 'Through': [32], 'theory': [35], 'approach,': [37], 'viewpoints': [38], 'were': [39], 'gathered': [40], 'from': [41, 65, 79, 108], 'group': [43], 'IT': [45], 'professionals': [46], 'sector.': [50], 'The': [51], 'uncovered': [53], 'AI': [57, 112, 124], 'across': [60], 'different': [61], 'professional': [62], 'roles,': [63], 'ranging': [64], 'direct': [66], 'breaches': [67], 'to': [68, 82, 147], 'indirect': [69], 'exposure.': [70], 'Key': [71], 'findings': [72], 'revealed': [73], 'spectrum': [75], 'mitigation': [77], 'strategies,': [78], 'technical': [80], 'solutions': [81], 'basic': [83], 'awareness': [84], 'mixed': [86], 'responses': [87], 'regarding': [88], 'personally': [92], 'identifiable': [93], 'information': [94], '(PII),': [95], 'underscoring': [96], 'complexity': [98], 'safeguarding': [100], 'customer': [101, 150], '[1].': [103], 'Despite': [104], 'potential': [105], 'limitations': [106], 'stemming': [107], 'rapidly': [110], 'evolving': [111], 'landscape,': [113], 'this': [114], 'contributes': [116], 'valuable': [117], 'insights': [118], 'into': [119], 'effective': [120], 'strategies': [121], 'for': [122], 'mitigating': [123], 'risks': [127], 'enhancing': [129], 'security': [131, 145], 'chatbots': [134], 'banking.': [136], 'It': [137], 'highlights': [138], 'critical': [140], 'importance': [141], 'developing': [143], 'robust': [144], 'measures': [146], 'protect': [148], 'sensitive': [149], 'against': [152], 'violations.': [154]}",2024,"['Grounded theory', 'Qualitative research', 'Information privacy', 'Internet privacy', 'Computer science', 'Psychology', 'Sociology', 'Social science']","This research study examines the impact of Artificial Intelligence (AI) data poisoning on data privacy violations in AI-enabled banking chatbots, employing a qualitative approach grounded in AI, data privacy, and cybersecurity theories. Through qualitative grounded theory research approach, viewpoints were gathered from a group of IT professionals in the banking sector. The research uncovered the impact of AI data poisoning across different professional roles, ranging from direct breaches to indirect exposure. Key findings revealed a spectrum of mitigation strategies, from technical solutions to basic awareness and mixed responses regarding the impact on personally identifiable information (PII), underscoring the complexity of safeguarding customer data [1]. Despite potential limitations stemming from the rapidly evolving AI landscape, this study contributes valuable insights into effective strategies for mitigating AI data poisoning risks and enhancing the security of AI-enabled chatbots in banking. It highlights the critical importance of developing robust security measures to protect sensitive customer data against privacy violations."
https://openalex.org/W4400675054,A Real-Time and Privacy-Preserving Facial Expression Recognition System Using an AI-Powered Microcontroller,"{'This': [0], 'study': [1], 'proposes': [2], 'an': [3, 60, 114, 126, 184], 'edge': [4, 115], 'computing-based': [5], 'facial': [6, 36, 44, 50, 85, 95, 121], 'expression': [7, 122], 'recognition': [8], 'system': [9, 25, 136], 'that': [10], 'is': [11, 66, 137], 'low': [12, 14], 'cost,': [13], 'power,': [15], 'and': [16, 30, 82, 103, 120, 165, 198], 'privacy': [17], 'preserving.': [18], 'It': [19], 'utilizes': [20], 'a': [21, 34, 108, 189, 199], 'minimally': [22], 'obtrusive': [23], 'cap-based': [24], 'designed': [26], 'for': [27, 117], 'the': [28, 69, 73, 77, 80, 83, 135, 180], 'continuous': [29], 'real-time': [31], 'monitoring': [32], 'of': [33, 72, 134, 186, 192, 202], 'user’s': [35, 84], 'expressions.': [37, 51], 'The': [38, 88], 'proposed': [39], 'method': [40], 'focuses': [41], 'on': [42], 'detecting': [43], 'skin': [45, 86], 'deformations': [46], 'accompanying': [47], 'changes': [48], 'in': [49], 'A': [52], 'multi-zone': [53], 'time-of-flight': [54], '(ToF)': [55], 'depth': [56, 64], 'sensor': [57, 81], 'VL53L5CX,': [58], 'featuring': [59], '8': [61, 63], '×': [62], 'image,': [65], 'integrated': [67], 'into': [68], 'front': [70], 'brim': [71], 'cap': [74], 'to': [75, 92, 107], 'measure': [76], 'distance': [78, 89], 'between': [79], 'surface.': [87], 'values': [90], 'corresponding': [91], 'seven': [93], 'universal': [94], 'expressions': [96], '(neutral,': [97], 'happy,': [98], 'disgust,': [99], 'anger,': [100], 'surprise,': [101], 'fear,': [102], 'sad)': [104], 'are': [105, 170], 'transmitted': [106], 'low-power': [109], 'STM32F476': [110], 'microcontroller': [111], '(MCU)': [112], 'as': [113], 'device': [116], 'data': [118, 142], 'preprocessing': [119], 'classification': [123], 'tasks': [124], 'utilizing': [125, 141], 'on-device': [127], 'pre-trained': [128], 'deep': [129, 148], 'learning': [130, 149], 'model.': [131], 'Performance': [132], 'evaluation': [133], 'conducted': [138], 'through': [139], 'experiments': [140], 'collected': [143], 'from': [144], '20': [145], 'subjects.': [146], 'Four': [147], 'algorithms,': [150], 'including': [151], 'Convolutional': [152], 'Neural': [153, 157, 167], 'Networks': [154, 158, 168], '(CNN),': [155], 'Recurrent': [156], '(RNN),': [159], 'Long': [160], 'Short-Term': [161], 'Memory': [162], '(LSTM)': [163], 'networks,': [164], 'Deep': [166], '(DNN),': [169], 'assessed.': [171], 'These': [172], 'algorithms': [173], 'demonstrate': [174], 'high': [175], 'accuracy,': [176], 'with': [177], 'CNN': [178], 'yielding': [179], 'best': [181], 'result,': [182], 'achieving': [183], 'accuracy': [185], '89.20%': [187], 'at': [188], 'frame': [190], 'rate': [191], '15': [193], 'frames': [194], 'per': [195], 'second': [196], '(fps)': [197], 'maximum': [200], 'latency': [201], '2': [203], 'ms.': [204]}",2024,"['Microcontroller', 'Computer science', 'Facial expression recognition', 'Facial expression', 'Embedded system', 'Expression (computer science)', 'Artificial intelligence', 'Facial recognition system', 'Computer vision', 'Computer hardware', 'Speech recognition', 'Human–computer interaction', 'Pattern recognition (psychology)', 'Programming language']","This study proposes an edge computing-based facial expression recognition system that is low cost, low power, and privacy preserving. It utilizes a minimally obtrusive cap-based system designed for the continuous and real-time monitoring of a user’s facial expressions. The proposed method focuses on detecting facial skin deformations accompanying changes in facial expressions. A multi-zone time-of-flight (ToF) depth sensor VL53L5CX, featuring an 8 × 8 depth image, is integrated into the front brim of the cap to measure the distance between the sensor and the user’s facial skin surface. The distance values corresponding to seven universal facial expressions (neutral, happy, disgust, anger, surprise, fear, and sad) are transmitted to a low-power STM32F476 microcontroller (MCU) as an edge device for data preprocessing and facial expression classification tasks utilizing an on-device pre-trained deep learning model. Performance evaluation of the system is conducted through experiments utilizing data collected from 20 subjects. Four deep learning algorithms, including Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM) networks, and Deep Neural Networks (DNN), are assessed. These algorithms demonstrate high accuracy, with CNN yielding the best result, achieving an accuracy of 89.20% at a frame rate of 15 frames per second (fps) and a maximum latency of 2 ms."
https://openalex.org/W4403230019,"Technical Innovations and Social Implications: Mapping Global Research Focus in AI, Blockchain, Cybersecurity, and Privacy","{'This': [0, 90], 'study': [1, 106, 185], 'examines': [2], 'the': [3, 25, 97, 119], 'balance': [4], 'between': [5], 'technical': [6, 146], 'and': [7, 15, 43, 72, 85, 153, 175, 191, 198], 'social': [8, 26, 134, 154], 'focus': [9, 42, 117, 143, 178], 'in': [10, 18, 102, 161, 179, 201], 'artificial': [11], 'intelligence,': [12], 'blockchain,': [13], 'cybersecurity,': [14], 'privacy': [16], 'publications': [17], 'Web': [19], 'of': [20, 40, 59, 77, 99, 110, 115, 136, 171], 'Science': [21], 'across': [22, 49, 118], 'countries,': [23, 50], 'exploring': [24], 'factors': [27, 155], 'that': [28, 66, 151], 'influence': [29], 'these': [30, 52], 'research': [31, 41, 61, 78, 100, 116, 163, 177], 'priorities.': [32, 62], 'We': [33], 'use': [34], 'regression': [35], 'analysis': [36, 45], 'to': [37, 46, 54, 132], 'identify': [38], 'predictors': [39, 76], 'cluster': [44], 'reveal': [47, 65], 'patterns': [48, 114], 'combining': [51], 'methods': [53], 'provide': [55], 'a': [56, 158, 169], 'broader': [57], 'view': [58], 'global': [60, 125], 'Our': [63], 'findings': [64, 149], 'liberal': [67], 'democracy': [68], 'index,': [69], 'life': [70], 'expectancy,': [71], 'happiness': [73], 'are': [74], 'significant': [75], 'focus,': [79], 'while': [80, 138], 'traditional': [81], 'indicators': [82], 'like': [83], 'education': [84], 'income': [86], 'show': [87], 'weaker': [88], 'relationships.': [89], 'unexpected': [91], 'result': [92], 'challenges': [93], 'conventional': [94], 'assumptions': [95], 'about': [96], 'drivers': [98], 'priorities': [101], 'digital': [103, 204], 'technologies.': [104], 'The': [105, 184], 'identifies': [107], 'distinct': [108], 'clusters': [109], 'countries': [111, 142], 'with': [112], 'similar': [113], 'four': [120], 'technologies,': [121, 137], 'revealing': [122], 'previously': [123, 166], 'unrecognized': [124], 'typologies.': [126], 'Notably,': [127], 'more': [128, 144], 'democratic': [129], 'societies': [130], 'tend': [131], 'emphasize': [133], 'implications': [135], 'some': [139], 'rapidly': [140, 180], 'developing': [141], 'on': [145], 'aspects.': [147], 'These': [148], 'suggest': [150], 'political': [152], 'may': [156], 'play': [157], 'larger': [159], 'role': [160], 'shaping': [162], 'agendas': [164], 'than': [165], 'thought,': [167], 'necessitating': [168], 're-evaluation': [170], 'how': [172], 'we': [173], 'understand': [174], 'predict': [176], 'evolving': [181], 'technological': [182, 196], 'fields.': [183], 'provides': [186], 'valuable': [187], 'information': [188], 'for': [189, 195], 'policymakers': [190], 'researchers,': [192], 'informing': [193], 'strategies': [194], 'development': [197], 'international': [199], 'collaboration': [200], 'an': [202], 'increasingly': [203], 'world.': [205]}",2024,"['Blockchain', 'Computer security', 'Focus (optics)', 'Internet privacy', 'Privacy protection', 'Information privacy', 'Computer science', 'Business', 'Optics', 'Physics']","This study examines the balance between technical and social focus in artificial intelligence, blockchain, cybersecurity, and privacy publications in Web of Science across countries, exploring the social factors that influence these research priorities. We use regression analysis to identify predictors of research focus and cluster analysis to reveal patterns across countries, combining these methods to provide a broader view of global research priorities. Our findings reveal that liberal democracy index, life expectancy, and happiness are significant predictors of research focus, while traditional indicators like education and income show weaker relationships. This unexpected result challenges conventional assumptions about the drivers of research priorities in digital technologies. The study identifies distinct clusters of countries with similar patterns of research focus across the four technologies, revealing previously unrecognized global typologies. Notably, more democratic societies tend to emphasize social implications of technologies, while some rapidly developing countries focus more on technical aspects. These findings suggest that political and social factors may play a larger role in shaping research agendas than previously thought, necessitating a re-evaluation of how we understand and predict research focus in rapidly evolving technological fields. The study provides valuable information for policymakers and researchers, informing strategies for technological development and international collaboration in an increasingly digital world."
https://openalex.org/W4402677668,Harnessing AI and analytics to enhance cybersecurity and privacy for collective intelligence systems,"{'Collective': [0], 'intelligence': [1, 34], 'systems': [2, 62], 'like': [3], 'Chat': [4], 'Generative': [5], 'Pre-Trained': [6], 'Transformer': [7], '(ChatGPT)': [8], 'have': [9, 12], 'emerged.': [10], 'They': [11], 'brought': [13], 'both': [14], 'promise': [15], 'and': [16, 20, 36, 43, 82, 87, 97, 123, 140, 183, 220, 259, 288, 318], 'peril': [17], 'to': [18, 28, 40, 63, 70, 84, 94, 105, 146, 155, 165, 186, 196, 208, 214, 224, 230, 243, 294, 298, 316], 'cybersecurity': [19], 'privacy': [21, 44, 107], 'protection.': [22], 'This': [23, 126, 190], 'study': [24], 'introduces': [25], 'novel': [26], 'approaches': [27], 'harness': [29], 'the': [30, 129, 132, 194, 264, 307, 328, 335, 343], 'power': [31], 'of': [32, 134, 306, 330, 345], 'artificial': [33], '(AI)': [35], 'big': [37], 'data': [38, 72, 77], 'analytics': [39, 104], 'enhance': [41], 'security': [42], 'in': [45, 60, 99, 108, 120, 268, 322], 'this': [46], 'new': [47], 'era.': [48], 'Contributions': [49], 'could': [50], 'explore': [51], 'topics': [52], 'such': [53], 'as:': [54], 'leveraging': [55], 'natural': [56], 'language': [57], 'processing': [58], '(NLP)': [59], 'ChatGPT-like': [61], 'strengthen': [64], 'information': [65], 'security;': [66], 'evaluating': [67], 'privacy-enhancing': [68], 'technologies': [69], 'maximize': [71], 'utility': [73], 'while': [74, 111], 'minimizing': [75], 'personal': [76], 'exposure;': [78], 'modeling': [79], 'human': [80, 137], 'behavior': [81], 'agency': [83], 'build': [85], 'secure': [86], 'ethical': [88], 'human-centric': [89], 'systems;': [90], 'applying': [91], 'machine': [92], 'learning': [93, 161], 'detect': [95], 'threats': [96], 'vulnerabilities': [98], 'a': [100, 121, 152, 176, 180, 221, 232, 281, 319], 'data-driven': [101], 'manner;': [102], 'using': [103], 'preserve': [106], 'large': [109], 'datasets': [110], 'enabling': [112, 206], 'value': [113], 'creation;': [114], 'crafting': [115], 'AI': [116], 'techniques': [117], 'that': [118, 158, 199, 239, 338], 'operate': [119], 'trustworthy': [122], 'explainable': [124], 'manner.': [125], 'article': [127], 'advances': [128], 'state-of-the-art': [130], 'at': [131], 'intersection': [133], 'cybersecurity,': [135], 'privacy,': [136], 'factors,': [138], 'ethics,': [139], 'cutting-edge': [141], 'AI,': [142], 'providing': [143], 'impactful': [144], 'solutions': [145], 'emerging': [147], 'challenges.': [148], 'Our': [149, 172, 302, 325], 'research': [150, 309], 'presents': [151], 'revolutionary': [153], 'approach': [154, 173], 'malware': [156, 181, 257, 276, 286], 'detection': [157, 311, 323], 'leverages': [159], 'deep': [160], '(DL)': [162], 'based': [163], 'methodologies': [164], 'automatically': [166], 'learn': [167, 215], 'features': [168, 185], 'from': [169, 179, 203, 216, 263, 314], 'raw': [170], 'data.': [171], 'involves': [174], 'constructing': [175], 'grayscale': [177, 218], 'image': [178], 'file': [182], 'extracting': [184], 'minimize': [187], 'its': [188], 'size.': [189], 'process': [191], 'affords': [192], 'us': [193, 207], 'ability': [195], 'discern': [197], 'patterns': [198, 337], 'might': [200], 'remain': [201], 'hidden': [202, 336], 'other': [204, 299], 'techniques,': [205], 'utilize': [209], 'convolutional': [210], 'neural': [211], 'networks': [212], '(CNNs)': [213], 'these': [217], 'images': [219], 'stacking': [222], 'ensemble': [223], 'classify': [225], 'malware.': [226], 'The': [227], 'goal': [228], 'is': [229], 'model': [231, 297, 303], 'highly': [233], 'complex': [234, 340], 'nonlinear': [235], 'function': [236], 'with': [237, 291, 310], 'parameters': [238, 293], 'can': [240], 'be': [241], 'optimized': [242], 'achieve': [244], 'superior': [245], 'performance.': [246, 324], 'To': [247], 'test': [248], 'our': [249, 296, 331], 'approach,': [250, 332], 'we': [251, 279], 'ran': [252], 'it': [253], 'on': [254, 284], 'over': [255], '6,414': [256], 'variants': [258], '2,050': [260], 'benign': [261], 'files': [262], 'MalImg': [265], 'collection,': [266], 'resulting': [267], 'an': [269], 'impressive': [270], '99.86': [271], 'percent': [272], 'validation': [273], 'accuracy': [274, 312], 'for': [275], 'detection.': [277], 'Furthermore,': [278], 'conducted': [280], 'classification': [282], 'experiment': [283], '15': [285], 'families': [287], '13': [289], 'tests': [290], 'varying': [292], 'compare': [295], 'comparable': [300], 'research.': [301], 'outperformed': [304], 'most': [305], 'similar': [308], 'ranging': [313], '47.07%': [315], '99.81%': [317], 'significant': [320], 'increase': [321], 'results': [326], 'demonstrate': [327], 'efficacy': [329], 'which': [333], 'unlocks': [334], 'underlie': [339], 'systems,': [341], 'advancing': [342], 'frontiers': [344], 'computational': [346], 'security.': [347]}",2024,"['Computer science', 'Malware', 'Big data', 'Analytics', 'Artificial intelligence', 'Computer security', 'Convolutional neural network', 'Data science', 'Machine learning', 'Data mining']","Collective intelligence systems like Chat Generative Pre-Trained Transformer (ChatGPT) have emerged. They have brought both promise and peril to cybersecurity and privacy protection. This study introduces novel approaches to harness the power of artificial intelligence (AI) and big data analytics to enhance security and privacy in this new era. Contributions could explore topics such as: leveraging natural language processing (NLP) in ChatGPT-like systems to strengthen information security; evaluating privacy-enhancing technologies to maximize data utility while minimizing personal data exposure; modeling human behavior and agency to build secure and ethical human-centric systems; applying machine learning to detect threats and vulnerabilities in a data-driven manner; using analytics to preserve privacy in large datasets while enabling value creation; crafting AI techniques that operate in a trustworthy and explainable manner. This article advances the state-of-the-art at the intersection of cybersecurity, privacy, human factors, ethics, and cutting-edge AI, providing impactful solutions to emerging challenges. Our research presents a revolutionary approach to malware detection that leverages deep learning (DL) based methodologies to automatically learn features from raw data. Our approach involves constructing a grayscale image from a malware file and extracting features to minimize its size. This process affords us the ability to discern patterns that might remain hidden from other techniques, enabling us to utilize convolutional neural networks (CNNs) to learn from these grayscale images and a stacking ensemble to classify malware. The goal is to model a highly complex nonlinear function with parameters that can be optimized to achieve superior performance. To test our approach, we ran it on over 6,414 malware variants and 2,050 benign files from the MalImg collection, resulting in an impressive 99.86 percent validation accuracy for malware detection. Furthermore, we conducted a classification experiment on 15 malware families and 13 tests with varying parameters to compare our model to other comparable research. Our model outperformed most of the similar research with detection accuracy ranging from 47.07% to 99.81% and a significant increase in detection performance. Our results demonstrate the efficacy of our approach, which unlocks the hidden patterns that underlie complex systems, advancing the frontiers of computational security."
https://openalex.org/W2902762277,Undermining User Privacy on Mobile Devices Using AI,"{'Over': [0], 'the': [1, 10, 20, 34, 71, 74, 148, 166, 222], 'past': [2], 'years,': [3], 'literature': [4], 'has': [5], 'shown': [6], 'that': [7, 51, 186, 210], 'attacks': [8, 54, 193], 'exploiting': [9], 'microarchitecture': [11], 'of': [12, 22, 78, 137, 224], 'modern': [13], 'processors': [14], 'pose': [15], 'a': [16, 83, 115, 126], 'serious': [17], 'threat': [18], 'to': [19, 42, 89, 188, 198], 'privacy': [21, 223], 'mobile': [23, 216], 'phone': [24, 112, 217], 'users.': [25, 226], 'This': [26, 155, 204], 'is': [27, 156], 'because': [28], 'applications': [29, 133], 'leave': [30], 'distinct': [31], 'footprints': [32], 'in': [33, 73, 123, 202], 'processor,': [35], 'which': [36, 93], 'can': [37], 'be': [38], 'used': [39], 'by': [40, 113, 146], 'malware': [41], 'infer': [43], 'user': [44], 'activities.': [45], 'In': [46, 65, 181], 'this': [47], 'work,': [48], 'we': [49, 67, 94], 'show': [50, 185], 'these': [52], 'inference': [53, 192], 'are': [55, 194], 'considerably': [56], 'more': [57, 206], 'practical': [58], 'when': [59], 'combined': [60], 'with': [61, 96, 134], 'advanced': [62, 189], 'AI': [63, 190], 'techniques.': [64], 'particular,': [66], 'focus': [68], 'on': [69, 108], 'profiling': [70], 'activity': [72], 'last-level': [75], 'cache': [76, 91, 173], '(LLC)': [77], 'ARM': [79], 'processors.': [80], 'We': [81, 104], 'employ': [82], 'simple': [84], 'Prime+Probe': [85], 'based': [86], 'monitoring': [87, 147, 170], 'technique': [88], 'obtain': [90], 'traces,': [92], 'classify': [95], 'Deep': [97, 159], 'Learning': [98, 160], 'methods': [99], 'including': [100], 'Convolutional': [101], 'Neural': [102], 'Networks.': [103], 'demonstrate': [105], 'our': [106, 183], 'approach': [107], 'an': [109, 119, 135], 'off-the-shelf': [110], 'Android': [111], 'launching': [114], 'successful': [116], 'attack': [117], 'from': [118, 165], 'unprivileged,': [120], 'zeropermission': [121], 'App': [122, 129], 'well': [124], 'under': [125], 'minute.': [127], 'The': [128], 'thereby': [130], 'detects': [131], 'running': [132], 'accuracy': [136], '98%': [138], 'and': [139, 143, 171, 200, 214], 'reveals': [140], 'opened': [141], 'websites': [142], 'streaming': [144], 'videos': [145], 'LLC': [149, 169], 'for': [150, 208], 'at': [151], 'most': [152], '6': [153], 'seconds.': [154], 'possible,': [157], 'since': [158], 'compensates': [161], 'measurement': [162], 'disturbances': [163], 'stemming': [164], 'inherently': [167], 'noisy': [168], 'unfavorable': [172], 'characteristics': [174], 'such': [175], 'as': [176], 'random': [177], 'line': [178], 'replacement': [179], 'policies.': [180], 'summary,': [182], 'results': [184], 'thanks': [187], 'techniques,': [191], 'becoming': [195], 'alarmingly': [196], 'easy': [197], 'implement': [199], 'execute': [201], 'practice.': [203], 'once': [205], 'calls': [207], 'countermeasures': [209], 'confine': [211], 'microarchitectural': [212], 'leakage': [213], 'protect': [215], 'applications,': [218], 'especially': [219], 'those': [220], 'valuing': [221], 'their': [225]}",2019,"['Computer science', 'Cache', 'Profiling (computer programming)', 'Phone', 'Android (operating system)', 'Mobile device', 'Convolutional neural network', 'Malware', 'Deep learning', 'Inference', 'Computer security', 'Mobile phone', 'Artificial intelligence', 'Embedded system', 'World Wide Web', 'Computer network', 'Operating system', 'Philosophy', 'Linguistics']","Over the past years, literature has shown that attacks exploiting the microarchitecture of modern processors pose a serious threat to the privacy of mobile phone users. This is because applications leave distinct footprints in the processor, which can be used by malware to infer user activities. In this work, we show that these inference attacks are considerably more practical when combined with advanced AI techniques. In particular, we focus on profiling the activity in the last-level cache (LLC) of ARM processors. We employ a simple Prime+Probe based monitoring technique to obtain cache traces, which we classify with Deep Learning methods including Convolutional Neural Networks. We demonstrate our approach on an off-the-shelf Android phone by launching a successful attack from an unprivileged, zeropermission App in well under a minute. The App thereby detects running applications with an accuracy of 98% and reveals opened websites and streaming videos by monitoring the LLC for at most 6 seconds. This is possible, since Deep Learning compensates measurement disturbances stemming from the inherently noisy LLC monitoring and unfavorable cache characteristics such as random line replacement policies. In summary, our results show that thanks to advanced AI techniques, inference attacks are becoming alarmingly easy to implement and execute in practice. This once more calls for countermeasures that confine microarchitectural leakage and protect mobile phone applications, especially those valuing the privacy of their users."
https://openalex.org/W4399695555,"Evaluating Privacy, Security, and Trust Perceptions in Conversational AI: A Systematic Review","{'Conversational': [0], 'AI': [1], '(CAI)': [2], 'systems': [3], 'which': [4, 150], 'encompass': [5], 'voice-': [6], 'and': [7, 14, 33, 49, 51, 57, 80, 92, 106, 109, 115, 127, 132, 163, 191, 204, 212, 215], 'text-based': [8], 'assistants': [9], 'are': [10, 151], 'on': [11, 46, 89, 112, 167, 200], 'the': [12, 39, 52, 61, 72, 84, 96, 125, 140, 158, 168, 173, 218], 'rise': [13], 'have': [15], 'been': [16], 'largely': [17], 'integrated': [18], 'into': [19, 83, 124], ""people's"": [20], 'everyday': [21], 'lives.': [22], 'Despite': [23], 'their': [24, 44], 'widespread': [25], 'adoption,': [26], 'users': [27], 'voice': [28], 'concerns': [29], 'regarding': [30], 'privacy,': [31, 55, 90, 130, 189, 210], 'security': [32, 56, 91, 131, 164, 190, 211], 'trust': [34, 58, 93, 133, 192, 213], 'in': [35, 60, 95], 'these': [36, 42, 180], 'systems.': [37, 100, 223], 'However,': [38], 'composition': [40], 'of': [41, 87, 98, 129, 142, 160, 175, 179, 220], 'perceptions,': [43], 'impact': [45], 'technology': [47], 'adoption': [48], 'usage': [50], 'relationship': [53], 'between': [54], 'perceptions': [59, 94, 159, 193, 214], 'CAI': [62, 99, 222], 'context': [63, 97], 'remain': [64], 'open': [65], 'research': [66, 88, 196], 'challenges.': [67], 'This': [68], 'study': [69], 'contributes': [70], 'to': [71, 198, 202, 217], 'field': [73], 'by': [74], 'conducting': [75], 'a': [76, 183], 'Systematic': [77], 'Literature': [78], 'Review': [79], 'offers': [81], 'insights': [82, 123], 'current': [85], 'state': [86], 'The': [101], 'review': [102], 'covers': [103], 'application': [104], 'fields': [105], 'user': [107], 'groups': [108], 'sheds': [110], 'light': [111], 'empirical': [113], 'methods': [114], 'tools': [116], 'used': [117], 'for': [118, 208], 'assessment.': [119], 'Moreover,': [120], 'it': [121], 'provides': [122], 'reliability': [126], 'validity': [128], 'scales,': [134], 'as': [135, 137, 145, 147], 'well': [136, 146], 'extensively': [138], 'investigating': [139], 'subconstructs': [141, 169], 'each': [143], 'item': [144], 'additional': [148], 'concepts': [149], 'concurrently': [152], 'collected.': [153], 'We': [154], 'point': [155], 'out': [156], 'that': [157], 'trust,': [161], 'privacy': [162], 'overlap': [165], 'based': [166], 'we': [170], 'identified.': [171], 'While': [172], 'majority': [174], 'studies': [176, 185], 'investigate': [177], 'one': [178], 'concepts,': [181], 'only': [182], 'few': [184], 'were': [186], 'found': [187], 'exploring': [188], 'jointly.': [194], 'Our': [195], 'aims': [197], 'inform': [199], 'directions': [201], 'develop': [203], 'use': [205], 'reliable': [206], 'scales': [207], ""users'"": [209], 'contribute': [216], 'development': [219], 'trustworthy': [221]}",2024,"['Internet privacy', 'Perception', 'Computer security', 'Computer science', 'Business', 'Psychology', 'Neuroscience']","Conversational AI (CAI) systems which encompass voice- and text-based assistants are on the rise and have been largely integrated into people's everyday lives. Despite their widespread adoption, users voice concerns regarding privacy, security and trust in these systems. However, the composition of these perceptions, their impact on technology adoption and usage and the relationship between privacy, security and trust perceptions in the CAI context remain open research challenges. This study contributes to the field by conducting a Systematic Literature Review and offers insights into the current state of research on privacy, security and trust perceptions in the context of CAI systems. The review covers application fields and user groups and sheds light on empirical methods and tools used for assessment. Moreover, it provides insights into the reliability and validity of privacy, security and trust scales, as well as extensively investigating the subconstructs of each item as well as additional concepts which are concurrently collected. We point out that the perceptions of trust, privacy and security overlap based on the subconstructs we identified. While the majority of studies investigate one of these concepts, only a few studies were found exploring privacy, security and trust perceptions jointly. Our research aims to inform on directions to develop and use reliable scales for users' privacy, security and trust perceptions and contribute to the development of trustworthy CAI systems."
https://openalex.org/W4400022865,Privacy Implications of Explainable AI in Data-Driven Systems,"{'Machine': [0], 'learning': [1, 171], '(ML)': [2], 'models,': [3, 26, 156], 'demonstrably': [4], 'powerful,': [5], 'suffer': [6], 'from': [7], 'a': [8, 70, 128, 178], 'lack': [9], 'of': [10, 14, 24, 57, 164, 169, 203], 'interpretability.': [11], 'The': [12], 'absence': [13], 'transparency,': [15], 'often': [16], 'referred': [17], 'to': [18, 35, 51, 98, 116, 137, 154, 177, 190], 'as': [19, 124, 158], 'the': [20, 31, 53, 83, 95, 121, 147, 162, 167, 201, 205], 'black': [21], 'box': [22], 'nature': [23], 'ML': [25, 90, 100, 155, 210], 'undermines': [27], 'trust': [28], 'and': [29, 49, 66, 79, 88, 101, 132, 195, 212], 'urges': [30], 'need': [32], 'for': [33, 86, 146], 'efforts': [34], 'enhance': [36], 'their': [37, 138, 159], 'explainability.': [38], 'Explainable': [39], 'AI': [40], '(XAI)': [41], 'techniques': [42, 112, 143], 'address': [43], 'this': [44, 75, 108], 'challenge': [45, 202], 'by': [46], 'providing': [47], 'frameworks': [48], 'methods': [50], 'explain': [52], 'internal': [54], 'decision-making': [55, 211], 'processes': [56], 'these': [58, 188], 'complex': [59], 'models.': [60], 'Techniques': [61], 'like': [62], 'Counterfactual': [63], 'Explanations': [64], '(CF)': [65], 'Feature': [67], 'Importance': [68], 'play': [69], 'crucial': [71], 'role': [72], 'in': [73, 120], 'achieving': [74], 'goal.': [76], 'Furthermore,': [77], 'high-quality': [78], 'diverse': [80], 'data': [81, 96], 'remains': [82], 'foundational': [84], 'element': [85], 'robust': [87], 'trustworthy': [89], 'applications.': [91], 'In': [92, 107], 'many': [93], 'applications,': [94], 'used': [97], 'train': [99], 'XAI': [102, 131, 142], 'explainers': [103], 'contain': [104], 'sensitive': [105, 118], 'information.': [106], 'context,': [109], 'numerous': [110], 'privacy-preserving': [111], 'can': [113, 182], 'be': [114], 'employed': [115], 'safeguard': [117], 'information': [119, 152], 'data,': [122], 'such': [123, 157], 'differential': [125], 'privacy.': [126, 214], 'Subsequently,': [127], 'conflict': [129], 'between': [130, 208], 'privacy': [133, 184], 'solutions': [134], 'emerges': [135], 'due': [136], 'opposing': [139], 'goals.': [140], 'Since': [141], 'provide': [144], 'reasoning': [145], 'model': [148, 192], 'behavior,': [149], 'they': [150], 'reveal': [151], 'relative': [153], 'decision': [160], 'boundaries,': [161], 'values': [163], 'features,': [165], 'or': [166], 'gradients': [168], 'deep': [170], 'models': [172], 'when': [173], 'explanations': [174], 'are': [175], 'exposed': [176], 'third': [179], 'entity.': [180], 'Attackers': [181], 'initiate': [183], 'breaching': [185], 'attacks': [186], 'using': [187], 'explanations,': [189], 'perform': [191], 'extraction,': [193], 'inference,': [194], 'membership': [196], 'attacks.': [197], 'This': [198], 'dilemma': [199], 'underscores': [200], 'finding': [204], 'right': [206], 'equilibrium': [207], 'understanding': [209], 'safeguarding': [213]}",2024,"['Internet privacy', 'Computer science', 'Information privacy', 'Data science', 'Computer security']","Machine learning (ML) models, demonstrably powerful, suffer from a lack of interpretability. The absence of transparency, often referred to as the black box nature of ML models, undermines trust and urges the need for efforts to enhance their explainability. Explainable AI (XAI) techniques address this challenge by providing frameworks and methods to explain the internal decision-making processes of these complex models. Techniques like Counterfactual Explanations (CF) and Feature Importance play a crucial role in achieving this goal. Furthermore, high-quality and diverse data remains the foundational element for robust and trustworthy ML applications. In many applications, the data used to train ML and XAI explainers contain sensitive information. In this context, numerous privacy-preserving techniques can be employed to safeguard sensitive information in the data, such as differential privacy. Subsequently, a conflict between XAI and privacy solutions emerges due to their opposing goals. Since XAI techniques provide reasoning for the model behavior, they reveal information relative to ML models, such as their decision boundaries, the values of features, or the gradients of deep learning models when explanations are exposed to a third entity. Attackers can initiate privacy breaching attacks using these explanations, to perform model extraction, inference, and membership attacks. This dilemma underscores the challenge of finding the right equilibrium between understanding ML decision-making and safeguarding privacy."
https://openalex.org/W4383197555,Translating theory into practice: assessing the privacy implications of concept-based explanations for biomedical AI,"{'Artificial': [0], 'Intelligence': [1], '(AI)': [2], 'has': [3, 60, 105], 'achieved': [4], 'remarkable': [5], 'success': [6, 177], 'in': [7, 20, 37, 64, 101, 142, 198, 219, 228, 240], 'image': [8, 10, 147], 'generation,': [9], 'analysis,': [11], 'and': [12, 27, 43, 51, 126, 169, 171, 188], 'language': [13], 'modeling,': [14], 'making': [15], 'data-driven': [16, 76], 'techniques': [17], 'increasingly': [18], 'relevant': [19], 'practical': [21], 'real-world': [22], 'applications,': [23], 'promising': [24], 'enhanced': [25], 'creativity': [26], 'efficiency': [28], 'for': [29], 'human': [30], 'users.': [31, 97], 'However,': [32, 223], 'the': [33, 72, 121, 128, 134, 143, 205, 220, 233, 249, 258, 265, 277, 287], 'deployment': [34, 251], 'of': [35, 56, 130, 136, 145, 178, 186, 207, 252, 260, 267], 'AI': [36, 58, 140, 210], 'high-stakes': [38], 'domains': [39], 'such': [40], 'as': [41], 'infrastructure': [42], 'healthcare': [44], 'still': [45], 'raises': [46], 'concerns': [47], 'regarding': [48], 'algorithm': [49], 'accountability': [50], 'safety.': [52], 'The': [53, 176, 194], 'emerging': [54], 'field': [55], 'explainable': [57], '(XAI)': [59], 'made': [61, 74], 'significant': [62], 'strides': [63], 'developing': [65], 'interfaces': [66], 'that': [67, 107, 273], 'enable': [68], 'humans': [69], 'to': [70, 86, 89, 96, 117, 124, 214, 217, 247], 'comprehend': [71], 'decisions': [73], 'by': [75, 212, 236], 'models.': [77], 'Among': [78], 'these': [79], 'approaches,': [80], 'concept-based': [81, 131, 189, 200, 253, 268], 'explainability': [82], 'stands': [83], 'out': [84], 'due': [85], 'its': [87], 'ability': [88], 'align': [90], 'explanations': [91, 110, 132, 190, 201, 237, 269], 'with': [92], 'high-level': [93], 'concepts': [94], 'familiar': [95], 'Nonetheless,': [98], 'early': [99], 'research': [100], 'adversarial': [102], 'machine': [103], 'learning': [104], 'unveiled': [106], 'exposing': [108, 183], 'model': [109, 159], 'can': [111, 202, 281], 'render': [112], 'victim': [113], 'models': [114, 141], 'more': [115, 229], 'susceptible': [116], 'attacks.': [118], 'This': [119], 'is': [120, 153, 191, 225, 238, 270], 'first': [122], 'study': [123], 'investigate': [125], 'compare': [127], 'impact': [129, 259], 'on': [133, 155, 165, 264, 286], 'privacy': [135, 151, 262], 'Deep': [137], 'Learning': [138], 'based': [139], 'context': [144], 'biomedical': [146, 167], 'analysis.': [148], 'An': [149], 'extensive': [150], 'benchmark': [152], 'conducted': [154], 'three': [156], 'different': [157], 'state-of-the-art': [158], 'architectures': [160], '(ResNet50,': [161], 'NFNet,': [162], 'ConvNeXt)': [163], 'trained': [164], 'two': [166], '(ISIC': [168], 'EyePACS)': [170], 'one': [172], 'synthetic': [173], 'dataset': [174], '(SCDB).': [175], 'membership': [179], 'inference': [180], 'attacks': [181], 'while': [182, 274], 'varying': [184], 'degrees': [185], 'attribution-based': [187], 'systematically': [192], 'compared.': [193], 'findings': [195], 'indicate': [196], 'that,': [197, 227], 'theory,': [199], 'potentially': [203], 'increase': [204], 'vulnerability': [206], 'a': [208], 'private': [209], 'system': [211], 'up': [213], '16%': [215], 'compared': [216], 'attributions': [218], 'baseline': [221], 'setting.': [222], 'it': [224], 'demonstrated': [226], 'realistic': [230], 'attack': [231], 'scenarios,': [232], 'threat': [234], 'posed': [235], 'negligible': [239], 'practice.': [241], 'Furthermore,': [242], 'actionable': [243], 'recommendations': [244], 'are': [245], 'provided': [246], 'ensure': [248], 'safe': [250], 'XAI': [254], 'systems.': [255], 'In': [256], 'addition,': [257], 'differential': [261], '(DP)': [263], 'quality': [266], 'explored,': [271], 'revealing': [272], 'negatively': [275], 'influencing': [276], 'explanation': [278], 'ability,': [279], 'DP': [280], 'have': [282], 'an': [283], 'adverse': [284], 'effect': [285], 'models’': [288], 'privacy.': [289]}",2023,"['Computer science', 'Context (archaeology)', 'Adversarial system', 'Data science', 'Artificial intelligence', 'Field (mathematics)', 'Attribution', 'Deep learning', 'Software deployment', 'Inference', 'Vulnerability (computing)', 'Computer security', 'Psychology', 'Social psychology', 'Paleontology', 'Biology', 'Mathematics', 'Operating system', 'Pure mathematics']","Artificial Intelligence (AI) has achieved remarkable success in image generation, image analysis, and language modeling, making data-driven techniques increasingly relevant in practical real-world applications, promising enhanced creativity and efficiency for human users. However, the deployment of AI in high-stakes domains such as infrastructure and healthcare still raises concerns regarding algorithm accountability and safety. The emerging field of explainable AI (XAI) has made significant strides in developing interfaces that enable humans to comprehend the decisions made by data-driven models. Among these approaches, concept-based explainability stands out due to its ability to align explanations with high-level concepts familiar to users. Nonetheless, early research in adversarial machine learning has unveiled that exposing model explanations can render victim models more susceptible to attacks. This is the first study to investigate and compare the impact of concept-based explanations on the privacy of Deep Learning based AI models in the context of biomedical image analysis. An extensive privacy benchmark is conducted on three different state-of-the-art model architectures (ResNet50, NFNet, ConvNeXt) trained on two biomedical (ISIC and EyePACS) and one synthetic dataset (SCDB). The success of membership inference attacks while exposing varying degrees of attribution-based and concept-based explanations is systematically compared. The findings indicate that, in theory, concept-based explanations can potentially increase the vulnerability of a private AI system by up to 16% compared to attributions in the baseline setting. However, it is demonstrated that, in more realistic attack scenarios, the threat posed by explanations is negligible in practice. Furthermore, actionable recommendations are provided to ensure the safe deployment of concept-based XAI systems. In addition, the impact of differential privacy (DP) on the quality of concept-based explanations is explored, revealing that while negatively influencing the explanation ability, DP can have an adverse effect on the models’ privacy."
https://openalex.org/W4393067727,Examining Privacy and Trust Issues at the Edge of Isomorphic IoT Architectures: Case Liquid AI,"{'The': [0, 126, 141], 'growing': [1], 'domain': [2], 'of': [3, 26, 60, 72, 121, 138, 147], 'liquidity': [4], 'in': [5, 87], 'computing': [6], 'extends': [7], 'its': [8], 'boundaries': [9], 'to': [10, 30, 81, 131], 'include': [11], 'advancements': [12], 'like': [13], 'liquid': [14, 21], 'artificial': [15], 'intelligence': [16], '(AI).': [17], 'Liquid': [18, 172], 'AI': [19, 173], 'leverages': [20], 'software': [22], 'using': [23], 'isomorphic': [24], 'Internet': [25], 'Things': [27], '(IoT)': [28], 'architecture': [29], 'enhance': [31], 'computation': [32], 'at': [33], 'the': [34, 53, 58, 73, 78, 136, 144, 148, 155], 'edge.': [35], 'This': [36], 'innovation': [37], 'unveils': [38], 'vast': [39], 'opportunities': [40], 'yet': [41], 'also': [42], 'introduces': [43], 'significant': [44], 'challenges,': [45], 'particularly': [46], 'around': [47], 'privacy': [48], 'and': [49, 84, 98, 102, 104, 106, 110, 114, 117, 119, 170], 'trust.': [50, 125], 'We': [51], 'explore': [52], 'vulnerabilities': [54], 'that': [55], 'might': [56], 'hinder': [57], 'progression': [59], 'this': [61, 75, 151], 'technological': [62], 'fusion': [63], 'toward': [64], 'achieving': [65], 'trustworthy': [66, 139, 171], 'AI.': [67, 140], 'Through': [68], 'an': [69], 'intensive': [70], 'examination': [71], 'literature,': [74, 158], 'research': [76, 152], 'highlights': [77], 'heightened': [79], 'threats': [80], 'data': [82], 'integrity': [83], 'stakeholder': [85], 'trust': [86], 'these': [88], 'evolving': [89], 'ecosystems.': [90], 'Four': [91], 'main': [92], 'challenges:': [93], 'Data': [94, 96, 100], 'collection,': [95], 'storage': [97], 'Access,': [99], 'utilization': [101], 'sharing,': [103], 'Surveillance': [105], 'profiling': [107], 'were': [108], 'identified': [109], 'examined': [111], 'under': [112, 124], 'privacy,': [113], 'two,': [115], 'Algorithms': [116], 'decision-making': [118], 'Security': [120], 'IoT': [122], 'infrastructure': [123], 'concerns': [127], 'are': [128], 'further': [129], 'categorized': [130], 'highlight': [132], 'their': [133], 'impact': [134], 'on': [135], 'development': [137], 'study': [142], 'acknowledges': [143], 'early': [145], 'state': [146], 'field.': [149], 'Consequently,': [150], 'navigates': [153], 'through': [154], 'limited': [156], 'available': [157], 'initiating': [159], 'a': [160, 165], 'pioneering': [161], 'discourse': [162], 'emphasizing': [163], 'fostering': [164], 'foundation': [166], 'for': [167], 'developing': [168], 'secure': [169], 'environments.': [174]}",2023,"['Computer science', 'Profiling (computer programming)', 'Computer security', 'Data science', 'Trusted Computing', 'Internet privacy', 'Trustworthiness', 'World Wide Web', 'Operating system']","The growing domain of liquidity in computing extends its boundaries to include advancements like liquid artificial intelligence (AI). Liquid AI leverages liquid software using isomorphic Internet of Things (IoT) architecture to enhance computation at the edge. This innovation unveils vast opportunities yet also introduces significant challenges, particularly around privacy and trust. We explore the vulnerabilities that might hinder the progression of this technological fusion toward achieving trustworthy AI. Through an intensive examination of the literature, this research highlights the heightened threats to data integrity and stakeholder trust in these evolving ecosystems. Four main challenges: Data collection, Data storage and Access, Data utilization and sharing, and Surveillance and profiling were identified and examined under privacy, and two, Algorithms and decision-making and Security of IoT infrastructure under trust. The concerns are further categorized to highlight their impact on the development of trustworthy AI. The study acknowledges the early state of the field. Consequently, this research navigates through the limited available literature, initiating a pioneering discourse emphasizing fostering a foundation for developing secure and trustworthy Liquid AI environments."
https://openalex.org/W4393971166,Perceived Trustworthiness of Human vs. AI Instructors in Digital Privacy Education for Older Adults,"{'Recent': [0], 'work': [1], 'highlights': [2], 'digital': [3, 13, 49, 87, 178], 'privacy': [4, 50, 173], 'education': [5, 31, 51], 'as': [6, 150], 'a': [7, 28, 38, 56, 83, 122], 'crucial': [8], 'component': [9], 'in': [10, 48, 171], 'overcoming': [11], 'the': [12, 43, 61, 108, 115, 119, 128, 133, 136, 143, 181], 'literacy': [14, 179], 'gap': [15], 'among': [16, 132, 180], 'seniors,': [17], 'but': [18], 'also': [19], 'shows': [20], 'that': [21, 105], 'seniors': [22], 'distrust': [23], 'AI': [24, 91, 109, 120], 'systems': [25], 'and': [26, 66, 75, 92, 101, 138, 152, 167, 175], 'prefer': [27], 'more': [29], 'personable': [30], 'experience.': [32], 'To': [33], 'this': [34], 'end,': [35], 'we': [36], 'conducted': [37], 'within-subjects': [39], 'experiment': [40], 'to': [41, 82, 156], 'explore': [42], 'pivotal': [44], 'role': [45], 'of': [46, 64], 'trust': [47, 68, 106, 158], 'for': [52, 164], 'older': [53, 77, 137], 'adults,': [54], 'with': [55, 124], 'specific': [57], 'focus': [58], 'on': [59, 86], 'how': [60], 'physical': [62], 'characteristics': [63], 'instructors—human': [65], 'AI—influence': [67], 'levels.': [69, 159], 'In': [70], 'our': [71], 'study,': [72], '36': [73], 'younger': [74], '27': [76], 'participants': [78], 'evaluated': [79], '9': [80], 'introductions': [81], 'video': [84], 'tutorial': [85], 'privacy,': [88], 'featuring': [89], '3': [90], '6': [93], 'human': [94, 116, 134], 'instructors': [95, 110, 141], '(the': [96], 'latter': [97], 'varying': [98], 'by': [99], 'age': [100], 'gender).': [102], 'Analysis': [103], 'revealed': [104], 'towards': [107, 114], 'was': [111, 127], 'lower': [112], 'than': [113], 'instructors.': [117], 'Among': [118], 'instructors,': [121, 135], 'robot': [123], 'human-like': [125], 'features': [126], 'most': [129, 144], 'trusted,': [130], 'while': [131], 'middle-aged': [139], 'female': [140], 'were': [142, 154], 'trusted.': [145], 'Furthermore,': [146], 'participant': [147], 'demographics': [148], 'such': [149], 'gender': [151], 'rurality': [153], 'found': [155], 'moderate': [157], 'This': [160], 'research': [161], 'has': [162], 'implications': [163], 'instructional': [165], 'design': [166], 'technology': [168], 'acceptance,': [169], 'particularly': [170], 'addressing': [172], 'concerns': [174], 'fostering': [176], 'inclusive': [177], 'senior': [182], 'population.': [183]}",2024,"['Distrust', 'Digital literacy', 'Trustworthiness', 'Demographics', 'Literacy', 'Internet privacy', 'Psychology', 'Medical education', 'Focus group', 'Computer science', 'Pedagogy', 'Medicine', 'Sociology', 'Anthropology', 'Demography', 'Psychotherapist']","Recent work highlights digital privacy education as a crucial component in overcoming the digital literacy gap among seniors, but also shows that seniors distrust AI systems and prefer a more personable education experience. To this end, we conducted a within-subjects experiment to explore the pivotal role of trust in digital privacy education for older adults, with a specific focus on how the physical characteristics of instructors—human and AI—influence trust levels. In our study, 36 younger and 27 older participants evaluated 9 introductions to a video tutorial on digital privacy, featuring 3 AI and 6 human instructors (the latter varying by age and gender). Analysis revealed that trust towards the AI instructors was lower than towards the human instructors. Among the AI instructors, a robot with human-like features was the most trusted, while among the human instructors, the older and middle-aged female instructors were the most trusted. Furthermore, participant demographics such as gender and rurality were found to moderate trust levels. This research has implications for instructional design and technology acceptance, particularly in addressing privacy concerns and fostering inclusive digital literacy among the senior population."
