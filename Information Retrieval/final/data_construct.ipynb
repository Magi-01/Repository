{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0533f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "BASE_URL = \"https://api.openalex.org/works\"\n",
    "# Look-up Terms\n",
    "Query = [\"artificial intelligence\", \"neural networks\", \"supervised learning\", \"Unsupervised learning\", \"AI privacy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6206242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_papers(query, per_page=20, pages=5):\n",
    "    print(query)\n",
    "    papers = []\n",
    "    for page in range(1, pages+1):\n",
    "        # Fetch the papers\n",
    "        url = f\"{BASE_URL}?filter=title.search:{query}&per-page={per_page}&page={page}\"\n",
    "        r = requests.get(url)\n",
    "        data = r.json()\n",
    "        results = data.get(\"results\", [])\n",
    "        if not results:\n",
    "            print(f\"No results found for page {page}\")\n",
    "            break\n",
    "        # Store them \n",
    "        for d in results:\n",
    "            papers.append({\n",
    "                \"id\": d.get(\"id\"),\n",
    "                \"title\": d.get(\"title\"),\n",
    "                \"abstract\": d.get(\"abstract_inverted_index\"),\n",
    "                \"year\": d.get(\"publication_year\"),\n",
    "                \"concepts\": [c[\"display_name\"] for c in d.get(\"concepts\", [])]\n",
    "            })\n",
    "    return papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9382ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_papers = []\n",
    "\n",
    "for q in Query:\n",
    "    papers = fetch_papers(q, per_page=10, pages=1)  # returns list of dicts\n",
    "    all_papers.extend(papers)  # append to the master list\n",
    "\n",
    "# Convert to DataFrame once at the end\n",
    "df = pd.DataFrame(all_papers)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3e6671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_abstract(inverted_index):\n",
    "    if not inverted_index:\n",
    "        return \"\"\n",
    "    \n",
    "    # position_map[pos] = word\n",
    "    position_map = {}\n",
    "    for word, positions in inverted_index.items():\n",
    "        for pos in positions:\n",
    "            position_map[pos] = word\n",
    "    \n",
    "    # Sort positions and join words\n",
    "    words = [position_map[pos] for pos in sorted(position_map.keys())]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535ebeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"abstract_text\"] = df[\"abstract\"].apply(reconstruct_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bda772",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"openalex_papers.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
