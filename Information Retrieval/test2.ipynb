{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "d9103116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mutua\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "from collections import defaultdict, Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "FEEDBACK_FILE2 = \"user_feedback2.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "55d4d216",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_query(query: str) -> str:\n",
    "    # Lowercase, remove stopwords, stem\n",
    "    tokens = [stemmer.stem(t) for t in query.lower().split() if t not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def preprocess_fuzzy(text):\n",
    "    text = re.sub(r'[^a-zA-Z0-9 ]', ' ', text.lower())\n",
    "    tokens = [stemmer.stem(w) for w in text.split() if w not in stop_words]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "abb84117",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------- BM25 Class -----------------\n",
    "class BM25Fuzzy:\n",
    "    def __init__(self, docs, k1=1.5, b=0.75):\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.docs = [preprocess_fuzzy(doc) for doc in docs]\n",
    "        self.N = len(docs)\n",
    "        self.avgdl = sum(len(d) for d in self.docs) / self.N\n",
    "        self.doc_len = [len(d) for d in self.docs]\n",
    "        self.index = defaultdict(dict)\n",
    "        self.build_index()\n",
    "\n",
    "        # Build vocab and document frequencies\n",
    "        self.vocab = set()\n",
    "        self.doc_freqs = defaultdict(int)\n",
    "        for term, postings in self.index.items():\n",
    "            self.vocab.add(term)\n",
    "            self.doc_freqs[term] = len(postings)\n",
    "    \n",
    "    def build_index(self):\n",
    "        for doc_id, doc in enumerate(self.docs):\n",
    "            freqs = Counter(doc)\n",
    "            for term, f in freqs.items():\n",
    "                self.index[term][doc_id] = f\n",
    "\n",
    "    def score_fuzzy(self, query_tokens, doc_id):\n",
    "        score = 0.0\n",
    "        doc_len = len(self.docs[doc_id])\n",
    "\n",
    "        for q in query_tokens:\n",
    "            # Fuzzy match: prefix overlap (or extend to Levenshtein later)\n",
    "            matching_terms = [t for t in self.vocab if t.startswith(q[:3])]\n",
    "            for term in matching_terms:\n",
    "                f = self.index.get(term, {}).get(doc_id, 0)\n",
    "                if f == 0:\n",
    "                    continue\n",
    "                df = self.doc_freqs[term]\n",
    "                idf = math.log((self.N - df + 0.5) / (df + 0.5) + 1)\n",
    "\n",
    "                numerator = f * (self.k1 + 1)\n",
    "                denominator = f + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl)\n",
    "                score += idf * numerator / denominator\n",
    "        return score\n",
    "\n",
    "\n",
    "    def search_fuzzy(self, query, top_k=10):\n",
    "        # normalize query same as when indexing\n",
    "        query_tokens = preprocess_fuzzy(query)\n",
    "        scores = defaultdict(float)\n",
    "\n",
    "        for token in query_tokens:\n",
    "            if token not in self.index:\n",
    "                continue\n",
    "            idf = self.idf(token)\n",
    "            postings = self.index[token]\n",
    "            for doc_id, freq in postings.items():\n",
    "                dl = self.doc_len[doc_id]\n",
    "                score = idf * freq * (self.k1 + 1) / (freq + self.k1 * (1 - self.b + self.b * dl / self.avgdl))\n",
    "                scores[doc_id] += score\n",
    "\n",
    "        # Return top_k\n",
    "        ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        return ranked[:top_k]\n",
    "\n",
    "    def idf(self, term):\n",
    "        df = self.doc_freqs.get(term, 0)\n",
    "        return np.log((self.N - df + 0.5) / (df + 0.5) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "4bd730b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_user_feedback(results, df):\n",
    "    relevant_docs = []\n",
    "    print(\"Mark relevant documents by typing their number (space-separated, e.g., 1 3 5):\")\n",
    "    selected = input(\"Relevant docs: \").strip()\n",
    "    if selected:\n",
    "        try:\n",
    "            indices = [int(x)-1 for x in selected.split()]\n",
    "            for i in indices:\n",
    "                relevant_docs.append(results[i][0])\n",
    "        except:\n",
    "            print(\"Invalid input, no docs marked as relevant.\")\n",
    "    return relevant_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "2a706555",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fuzzy_search(bm25, query, top_k=10):\n",
    "    \"\"\"\n",
    "    Fuzzy search using startswith matching for each query token.\n",
    "    Returns top_k documents with scores.\n",
    "    \"\"\"\n",
    "    query_tokens = preprocess_fuzzy(query)\n",
    "    scores = []\n",
    "\n",
    "    for doc_id, doc_tokens in enumerate(bm25.docs):\n",
    "        score = 0.0\n",
    "        for qtok in query_tokens:\n",
    "            # match doc terms that start with query token\n",
    "            for dtok in doc_tokens:\n",
    "                if dtok.startswith(qtok):\n",
    "                    score += bm25.idf(dtok)\n",
    "        scores.append((doc_id, score))\n",
    "\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return scores[:top_k]\n",
    "\n",
    "def fuzzy_search_display(bm25, query, df, top_k=10):\n",
    "    results = fuzzy_search(bm25, query, top_k=top_k)\n",
    "    for rank, (doc_id, score) in enumerate(results, start=1):\n",
    "        print(f\"{rank}. Doc ID: {doc_id}, Score: {score:.4f}\")\n",
    "        snippet = \" \".join(df.loc[doc_id, 'abstract_text'].split()[:30])\n",
    "        print(f\"   {snippet}...\\n\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "7b4155cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pseudo_relevance_feedback_iterative_fuzzy(bm25, query, relevant_doc_ids, n_iterations=3, expansion_terms=5):\n",
    "    current_query = query\n",
    "    all_expanded_terms = []\n",
    "    for i in range(n_iterations):\n",
    "        term_counter = Counter()\n",
    "        for doc_id in relevant_doc_ids:\n",
    "            term_counter.update(bm25.docs[doc_id])\n",
    "\n",
    "        original_tokens = preprocess_fuzzy(current_query)\n",
    "        for t in original_tokens:\n",
    "            if t in term_counter:\n",
    "                del term_counter[t]\n",
    "\n",
    "        top_terms = [t for t, _ in term_counter.most_common(expansion_terms)]\n",
    "        if not top_terms:\n",
    "            break\n",
    "\n",
    "        all_expanded_terms.extend(top_terms)\n",
    "        current_query = current_query + \" \" + \" \".join(top_terms)\n",
    "\n",
    "        # ðŸ”¹ Use fuzzy search here\n",
    "        print(\"=== Index Tokens ===\")\n",
    "        print(list(bm25.index.keys()))\n",
    "        search_results = bm25.search_fuzzy(current_query, top_k=10)\n",
    "        relevant_doc_ids = [doc_id for doc_id, _ in search_results[:5]]\n",
    "\n",
    "    return current_query, all_expanded_terms, relevant_doc_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "aff4455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_feedback_fuzzy(query, expanded_terms, relevant_docs):\n",
    "    norm_query = normalize_query(query)\n",
    "    try:\n",
    "        with open(FEEDBACK_FILE2, \"r\") as f:\n",
    "            feedback_data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        feedback_data = {}\n",
    "\n",
    "    # Overwrite instead of merging\n",
    "    feedback_data[norm_query] = {\n",
    "        \"expanded_terms\": expanded_terms,\n",
    "        \"relevant_docs\": relevant_docs\n",
    "    }\n",
    "\n",
    "    with open(FEEDBACK_FILE2, \"w\") as f:\n",
    "        json.dump(feedback_data, f, indent=2)\n",
    "\n",
    "def query_feedback_fuzzy(query):\n",
    "    \"\"\"\n",
    "    Returns learned expanded terms and relevant document IDs for a given query.\n",
    "    Does NOT print anything; intended for programmatic access.\n",
    "    \"\"\"\n",
    "    norm_query = normalize_query(query)  # normalize before lookup\n",
    "\n",
    "    try:\n",
    "        with open(FEEDBACK_FILE2, \"r\") as f:\n",
    "            feedback_data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return None  # No feedback data available\n",
    "\n",
    "    if norm_query not in feedback_data:\n",
    "        return None  # No feedback for this query\n",
    "\n",
    "    expanded_terms = feedback_data[norm_query].get(\"expanded_terms\", [])\n",
    "    relevant_docs = feedback_data[norm_query].get(\"relevant_docs\", [])\n",
    "\n",
    "    return {\"expanded_terms\": expanded_terms, \"relevant_docs\": relevant_docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "faddf1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def augment_query_with_feedback_fuzzy(query):\n",
    "    try:\n",
    "        with open(FEEDBACK_FILE2, \"r\") as f:\n",
    "            feedback_data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return query\n",
    "    if query in feedback_data:\n",
    "        expanded_terms = feedback_data[query][\"expanded_terms\"]\n",
    "        return query + \" \" + \" \".join(expanded_terms)\n",
    "    return query\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "5109a1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Evaluation -----------------\n",
    "def precision_at_k(relevant_docs, retrieved_docs, k=10):\n",
    "    retrieved_k = [doc for doc, _ in retrieved_docs[:k]]\n",
    "    return len(set(retrieved_k) & set(relevant_docs)) / k\n",
    "\n",
    "def recall_at_k(relevant_docs, retrieved_docs, k=10):\n",
    "    retrieved_k = [doc for doc, _ in retrieved_docs[:k]]\n",
    "    return len(set(retrieved_k) & set(relevant_docs)) / len(relevant_docs)\n",
    "\n",
    "def average_precision(relevant_docs, retrieved_docs, k=10):\n",
    "    retrieved_k = [doc for doc, _ in retrieved_docs[:k]]\n",
    "    hits = 0\n",
    "    sum_prec = 0\n",
    "    for i, doc_id in enumerate(retrieved_k, start=1):\n",
    "        if doc_id in relevant_docs:\n",
    "            hits += 1\n",
    "            sum_prec += hits / i\n",
    "    if hits == 0:\n",
    "        return 0\n",
    "    return sum_prec / hits\n",
    "\n",
    "\n",
    "def evaluate_all_queries_fuzzy(test_queries, bm25, df, top_k=10):\n",
    "    \"\"\"\n",
    "    Evaluate all queries in test_queries and compute aggregate metrics.\n",
    "    \n",
    "    Returns a dictionary with per-query metrics and overall mean metrics.\n",
    "    \"\"\"\n",
    "    all_precisions = []\n",
    "    all_recalls = []\n",
    "    all_average_precisions = []\n",
    "\n",
    "    per_query_metrics = {}\n",
    "\n",
    "    for query_text, relevant_docs in test_queries.items():\n",
    "        # Augment query with previous feedback if available\n",
    "        query_aug = augment_query_with_feedback_fuzzy(query_text)\n",
    "\n",
    "        # Retrieve top_k results\n",
    "        results = bm25.search_fuzzy(query_aug, top_k=top_k)\n",
    "\n",
    "        # Compute metrics for this query\n",
    "        prec = precision_at_k(relevant_docs, results, k=top_k)\n",
    "        rec = recall_at_k(relevant_docs, results, k=top_k)\n",
    "        ap = average_precision(relevant_docs, results, k=top_k)\n",
    "\n",
    "        per_query_metrics[query_text] = {\n",
    "            'Precision@{}'.format(top_k): prec,\n",
    "            'Recall@{}'.format(top_k): rec,\n",
    "            'AveragePrecision': ap\n",
    "        }\n",
    "\n",
    "        all_precisions.append(prec)\n",
    "        all_recalls.append(rec)\n",
    "        all_average_precisions.append(ap)\n",
    "\n",
    "    # Compute mean metrics\n",
    "    mean_metrics = {\n",
    "        'MeanPrecision@{}'.format(top_k): sum(all_precisions)/len(all_precisions),\n",
    "        'MeanRecall@{}'.format(top_k): sum(all_recalls)/len(all_recalls),\n",
    "        'MAP': sum(all_average_precisions)/len(all_average_precisions)\n",
    "    }\n",
    "\n",
    "    return per_query_metrics, mean_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "efc510cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Main Iterative Feedback Workflow -----------------\n",
    "def run_test_queries_fuzzy(df, bm25, test_queries, n_iterations=3, top_k=10, expansion_terms=5):\n",
    "    for query_text, relevant_docs in test_queries.items():\n",
    "        print(f\"\\n=== Processing Query (FUZZY): '{query_text}' ===\")\n",
    "\n",
    "        query_aug = augment_query_with_feedback_fuzzy(query_text)\n",
    "        print(f\"Augmented query: {query_aug}\")\n",
    "\n",
    "        results = fuzzy_search_display(bm25, query_aug, df, top_k=top_k)\n",
    "\n",
    "        if not relevant_docs:\n",
    "            relevant_docs = get_user_feedback(results, df)\n",
    "\n",
    "        if not relevant_docs:\n",
    "            print(\"No relevant documents marked. Skipping PRF.\\n\")\n",
    "            continue\n",
    "\n",
    "        final_query, learned_terms, final_relevant_docs = pseudo_relevance_feedback_iterative_fuzzy(\n",
    "            bm25,\n",
    "            query_aug,\n",
    "            relevant_doc_ids=relevant_docs,\n",
    "            n_iterations=n_iterations,\n",
    "            expansion_terms=expansion_terms\n",
    "        )\n",
    "        print(f\"Final query after {n_iterations} iterations: {final_query}\")\n",
    "\n",
    "        new_results = fuzzy_search_display(bm25, final_query, df, top_k=top_k)\n",
    "\n",
    "        relevant_docs_filtered = [doc_id for doc_id, score in results if score > 0]\n",
    "\n",
    "        save_feedback_fuzzy(query_text, learned_terms, relevant_docs_filtered)\n",
    "\n",
    "    per_query_metrics, mean_metrics = evaluate_all_queries_fuzzy(test_queries, bm25, df, top_k)\n",
    "    print(\"\\n=== Evaluation Metrics for All Fuzzy Queries ===\")\n",
    "    print(per_query_metrics)\n",
    "    print(mean_metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "92a9fb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_feedback_comparison_fuzzy(query, df, bm25, top_k=10):\n",
    "    \"\"\"\n",
    "    Shows titles from both the original dataset (raw retrieval) and\n",
    "    the learned feedback (JSON) for a given query.\n",
    "    \"\"\"\n",
    "    feedback_info = query_feedback_fuzzy(query)\n",
    "    inferred_doc_ids = feedback_info[\"relevant_docs\"] if feedback_info else []\n",
    "\n",
    "    # Original BM25 retrieval\n",
    "    raw_results = bm25.search_fuzzy(query, top_k=top_k)\n",
    "    raw_doc_ids = [doc_id for doc_id, _ in raw_results]\n",
    "\n",
    "    print(f\"\\nQuery: {query}\\n\")\n",
    "\n",
    "    print(\"Titles from JSON-inferred feedback:\")\n",
    "    if inferred_doc_ids:\n",
    "        for doc_id in inferred_doc_ids:\n",
    "            if doc_id < len(df):\n",
    "                print(f\"- {df.loc[doc_id, 'title']}\")\n",
    "    else:\n",
    "        print(\"- None\")\n",
    "\n",
    "    print(\"\\nTitles from original BM25 retrieval:\")\n",
    "    if raw_doc_ids:\n",
    "        for doc_id in raw_doc_ids:\n",
    "            if doc_id < len(df):\n",
    "                print(f\"- {df.loc[doc_id, 'title']}\")\n",
    "    else:\n",
    "        print(\"- None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "eb8f865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    \"title\": [\n",
    "        \"AI in Healthcare\",\n",
    "        \"Deep Learning Basics\",\n",
    "        \"Machine Learning for AI\",\n",
    "        \"Neural Networks in Practice\",\n",
    "        \"Healthcare and AI Applications\"\n",
    "    ],\n",
    "    \"abstract_text\": [\n",
    "        \"This paper discusses applications of AI in healthcare settings.\",\n",
    "        \"Introduction to deep learning concepts and algorithms.\",\n",
    "        \"A practical guide to machine learning techniques for AI.\",\n",
    "        \"Detailed exploration of neural networks applied in practice.\",\n",
    "        \"Overview of AI applications in healthcare and medicine.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data).fillna('').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "91a0a60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# BM25 search corpus\n",
    "abstracts = df['abstract_text'].tolist()\n",
    "\n",
    "bm25_fuzzy = BM25Fuzzy(abstracts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "5103bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample test queries with expected doc IDs\n",
    "test_queries = {\n",
    "    \"AI in healthcare\": [0, 4],   # Docs 0 and 4 should match\n",
    "    \"Deep learning\": [1],         # Only doc 1\n",
    "    \"Neural networks\": [3],       # Only doc 3\n",
    "    \"AI for healthcare\": [0, 4],  # Should still match docs 0 and 4 despite 'for' vs 'in'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "6f6c4b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Query (FUZZY): 'AI in healthcare' ===\n",
      "Augmented query: AI in healthcare\n",
      "1. Doc ID: 0, Score: 1.4145\n",
      "   This paper discusses applications of AI in healthcare settings....\n",
      "\n",
      "2. Doc ID: 4, Score: 1.4145\n",
      "   Overview of AI applications in healthcare and medicine....\n",
      "\n",
      "3. Doc ID: 2, Score: 0.5390\n",
      "   A practical guide to machine learning techniques for AI....\n",
      "\n",
      "4. Doc ID: 1, Score: 0.0000\n",
      "   Introduction to deep learning concepts and algorithms....\n",
      "\n",
      "5. Doc ID: 3, Score: 0.0000\n",
      "   Detailed exploration of neural networks applied in practice....\n",
      "\n",
      "=== Index Tokens ===\n",
      "['paper', 'discuss', 'applic', 'ai', 'healthcar', 'set', 'introduct', 'deep', 'learn', 'concept', 'algorithm', 'practic', 'guid', 'machin', 'techniqu', 'detail', 'explor', 'neural', 'network', 'appli', 'overview', 'medicin']\n",
      "=== Index Tokens ===\n",
      "['paper', 'discuss', 'applic', 'ai', 'healthcar', 'set', 'introduct', 'deep', 'learn', 'concept', 'algorithm', 'practic', 'guid', 'machin', 'techniqu', 'detail', 'explor', 'neural', 'network', 'appli', 'overview', 'medicin']\n",
      "=== Index Tokens ===\n",
      "['paper', 'discuss', 'applic', 'ai', 'healthcar', 'set', 'introduct', 'deep', 'learn', 'concept', 'algorithm', 'practic', 'guid', 'machin', 'techniqu', 'detail', 'explor', 'neural', 'network', 'appli', 'overview', 'medicin']\n",
      "Final query after 3 iterations: AI in healthcare applic paper discuss set overview medicin practic guid machin learn techniqu introduct deep concept algorithm\n",
      "1. Doc ID: 0, Score: 6.4488\n",
      "   This paper discusses applications of AI in healthcare settings....\n",
      "\n",
      "2. Doc ID: 2, Score: 6.4488\n",
      "   A practical guide to machine learning techniques for AI....\n",
      "\n",
      "3. Doc ID: 1, Score: 6.4206\n",
      "   Introduction to deep learning concepts and algorithms....\n",
      "\n",
      "4. Doc ID: 4, Score: 5.0625\n",
      "   Overview of AI applications in healthcare and medicine....\n",
      "\n",
      "5. Doc ID: 3, Score: 0.8755\n",
      "   Detailed exploration of neural networks applied in practice....\n",
      "\n",
      "\n",
      "=== Processing Query (FUZZY): 'Deep learning' ===\n",
      "Augmented query: Deep learning\n",
      "1. Doc ID: 1, Score: 2.2618\n",
      "   Introduction to deep learning concepts and algorithms....\n",
      "\n",
      "2. Doc ID: 2, Score: 0.8755\n",
      "   A practical guide to machine learning techniques for AI....\n",
      "\n",
      "3. Doc ID: 0, Score: 0.0000\n",
      "   This paper discusses applications of AI in healthcare settings....\n",
      "\n",
      "4. Doc ID: 3, Score: 0.0000\n",
      "   Detailed exploration of neural networks applied in practice....\n",
      "\n",
      "5. Doc ID: 4, Score: 0.0000\n",
      "   Overview of AI applications in healthcare and medicine....\n",
      "\n",
      "=== Index Tokens ===\n",
      "['paper', 'discuss', 'applic', 'ai', 'healthcar', 'set', 'introduct', 'deep', 'learn', 'concept', 'algorithm', 'practic', 'guid', 'machin', 'techniqu', 'detail', 'explor', 'neural', 'network', 'appli', 'overview', 'medicin']\n",
      "=== Index Tokens ===\n",
      "['paper', 'discuss', 'applic', 'ai', 'healthcar', 'set', 'introduct', 'deep', 'learn', 'concept', 'algorithm', 'practic', 'guid', 'machin', 'techniqu', 'detail', 'explor', 'neural', 'network', 'appli', 'overview', 'medicin']\n",
      "=== Index Tokens ===\n",
      "['paper', 'discuss', 'applic', 'ai', 'healthcar', 'set', 'introduct', 'deep', 'learn', 'concept', 'algorithm', 'practic', 'guid', 'machin', 'techniqu', 'detail', 'explor', 'neural', 'network', 'appli', 'overview', 'medicin']\n",
      "Final query after 3 iterations: Deep learning introduct concept algorithm practic guid machin techniqu ai applic healthcar detail explor neural\n",
      "1. Doc ID: 2, Score: 6.4488\n",
      "   A practical guide to machine learning techniques for AI....\n",
      "\n",
      "2. Doc ID: 1, Score: 6.4206\n",
      "   Introduction to deep learning concepts and algorithms....\n",
      "\n",
      "3. Doc ID: 3, Score: 5.0344\n",
      "   Detailed exploration of neural networks applied in practice....\n",
      "\n",
      "4. Doc ID: 0, Score: 2.2899\n",
      "   This paper discusses applications of AI in healthcare settings....\n",
      "\n",
      "5. Doc ID: 4, Score: 2.2899\n",
      "   Overview of AI applications in healthcare and medicine....\n",
      "\n",
      "\n",
      "=== Processing Query (FUZZY): 'Neural networks' ===\n",
      "Augmented query: Neural networks\n",
      "1. Doc ID: 3, Score: 2.7726\n",
      "   Detailed exploration of neural networks applied in practice....\n",
      "\n",
      "2. Doc ID: 0, Score: 0.0000\n",
      "   This paper discusses applications of AI in healthcare settings....\n",
      "\n",
      "3. Doc ID: 1, Score: 0.0000\n",
      "   Introduction to deep learning concepts and algorithms....\n",
      "\n",
      "4. Doc ID: 2, Score: 0.0000\n",
      "   A practical guide to machine learning techniques for AI....\n",
      "\n",
      "5. Doc ID: 4, Score: 0.0000\n",
      "   Overview of AI applications in healthcare and medicine....\n",
      "\n",
      "=== Index Tokens ===\n",
      "['paper', 'discuss', 'applic', 'ai', 'healthcar', 'set', 'introduct', 'deep', 'learn', 'concept', 'algorithm', 'practic', 'guid', 'machin', 'techniqu', 'detail', 'explor', 'neural', 'network', 'appli', 'overview', 'medicin']\n",
      "=== Index Tokens ===\n",
      "['paper', 'discuss', 'applic', 'ai', 'healthcar', 'set', 'introduct', 'deep', 'learn', 'concept', 'algorithm', 'practic', 'guid', 'machin', 'techniqu', 'detail', 'explor', 'neural', 'network', 'appli', 'overview', 'medicin']\n",
      "=== Index Tokens ===\n",
      "['paper', 'discuss', 'applic', 'ai', 'healthcar', 'set', 'introduct', 'deep', 'learn', 'concept', 'algorithm', 'practic', 'guid', 'machin', 'techniqu', 'detail', 'explor', 'neural', 'network', 'appli', 'overview', 'medicin']\n",
      "Final query after 3 iterations: Neural networks detail explor appli practic guid machin learn techniqu ai applic healthcar introduct deep concept\n",
      "1. Doc ID: 3, Score: 7.8069\n",
      "   Detailed exploration of neural networks applied in practice....\n",
      "\n",
      "2. Doc ID: 2, Score: 6.4488\n",
      "   A practical guide to machine learning techniques for AI....\n",
      "\n",
      "3. Doc ID: 1, Score: 5.0344\n",
      "   Introduction to deep learning concepts and algorithms....\n",
      "\n",
      "4. Doc ID: 0, Score: 3.1654\n",
      "   This paper discusses applications of AI in healthcare settings....\n",
      "\n",
      "5. Doc ID: 4, Score: 3.1654\n",
      "   Overview of AI applications in healthcare and medicine....\n",
      "\n",
      "\n",
      "=== Processing Query (FUZZY): 'AI for healthcare' ===\n",
      "Augmented query: AI for healthcare\n",
      "1. Doc ID: 0, Score: 1.4145\n",
      "   This paper discusses applications of AI in healthcare settings....\n",
      "\n",
      "2. Doc ID: 4, Score: 1.4145\n",
      "   Overview of AI applications in healthcare and medicine....\n",
      "\n",
      "3. Doc ID: 2, Score: 0.5390\n",
      "   A practical guide to machine learning techniques for AI....\n",
      "\n",
      "4. Doc ID: 1, Score: 0.0000\n",
      "   Introduction to deep learning concepts and algorithms....\n",
      "\n",
      "5. Doc ID: 3, Score: 0.0000\n",
      "   Detailed exploration of neural networks applied in practice....\n",
      "\n",
      "=== Index Tokens ===\n",
      "['paper', 'discuss', 'applic', 'ai', 'healthcar', 'set', 'introduct', 'deep', 'learn', 'concept', 'algorithm', 'practic', 'guid', 'machin', 'techniqu', 'detail', 'explor', 'neural', 'network', 'appli', 'overview', 'medicin']\n",
      "=== Index Tokens ===\n",
      "['paper', 'discuss', 'applic', 'ai', 'healthcar', 'set', 'introduct', 'deep', 'learn', 'concept', 'algorithm', 'practic', 'guid', 'machin', 'techniqu', 'detail', 'explor', 'neural', 'network', 'appli', 'overview', 'medicin']\n",
      "=== Index Tokens ===\n",
      "['paper', 'discuss', 'applic', 'ai', 'healthcar', 'set', 'introduct', 'deep', 'learn', 'concept', 'algorithm', 'practic', 'guid', 'machin', 'techniqu', 'detail', 'explor', 'neural', 'network', 'appli', 'overview', 'medicin']\n",
      "Final query after 3 iterations: AI for healthcare applic paper discuss set overview medicin practic guid machin learn techniqu introduct deep concept algorithm\n",
      "1. Doc ID: 0, Score: 6.4488\n",
      "   This paper discusses applications of AI in healthcare settings....\n",
      "\n",
      "2. Doc ID: 2, Score: 6.4488\n",
      "   A practical guide to machine learning techniques for AI....\n",
      "\n",
      "3. Doc ID: 1, Score: 6.4206\n",
      "   Introduction to deep learning concepts and algorithms....\n",
      "\n",
      "4. Doc ID: 4, Score: 5.0625\n",
      "   Overview of AI applications in healthcare and medicine....\n",
      "\n",
      "5. Doc ID: 3, Score: 0.8755\n",
      "   Detailed exploration of neural networks applied in practice....\n",
      "\n",
      "\n",
      "=== Evaluation Metrics for All Fuzzy Queries ===\n",
      "{'AI in healthcare': {'Precision@10': 0.2, 'Recall@10': 1.0, 'AveragePrecision': 1.0}, 'Deep learning': {'Precision@10': 0.1, 'Recall@10': 1.0, 'AveragePrecision': 1.0}, 'Neural networks': {'Precision@10': 0.1, 'Recall@10': 1.0, 'AveragePrecision': 1.0}, 'AI for healthcare': {'Precision@10': 0.2, 'Recall@10': 1.0, 'AveragePrecision': 1.0}}\n",
      "{'MeanPrecision@10': 0.15000000000000002, 'MeanRecall@10': 1.0, 'MAP': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_test_queries_fuzzy(df, bm25_fuzzy, test_queries, n_iterations=3, top_k=10, expansion_terms=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6375a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Learning\n",
      "\n",
      "Titles from JSON-inferred feedback:\n",
      "- None\n",
      "\n",
      "Titles from original BM25 retrieval:\n",
      "- Deep Learning Basics\n",
      "- Machine Learning for AI\n"
     ]
    }
   ],
   "source": [
    "\n",
    "show_feedback_comparison_fuzzy(\"Deep Learning\", df, bm25_fuzzy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "d05cbd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query tokens: ['ai', 'healthcar']\n"
     ]
    }
   ],
   "source": [
    "q = \"AI in healthcare\"\n",
    "print(\"Query tokens:\", preprocess_fuzzy(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c5bdab8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedback for query: {'expanded_terms': ['introduct', 'concept', 'algorithm', 'practic', 'guid', 'machin', 'techniqu', 'ai', 'applic', 'healthcar', 'detail', 'explor', 'neural'], 'relevant_docs': [1, 2]}\n"
     ]
    }
   ],
   "source": [
    "query = \"Deep Learning\"\n",
    "feedback = query_feedback_fuzzy(query)\n",
    "print(\"Feedback for query:\", feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "cc1e992b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'expanded_terms': ['ai', 'healthcar'], 'relevant_docs': [0, 4]}\n"
     ]
    }
   ],
   "source": [
    "query = \"AI in Healthcare\"\n",
    "relevant_docs = [0, 4]  # only truly relevant docs\n",
    "expanded_terms = [\"ai\", \"healthcar\"]\n",
    "save_feedback_fuzzy(query, expanded_terms, relevant_docs)\n",
    "feedback = query_feedback_fuzzy(query)\n",
    "print(feedback)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
