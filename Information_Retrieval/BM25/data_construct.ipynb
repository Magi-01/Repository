{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0533f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import os\n",
    "\n",
    "BASE_URL = \"https://api.openalex.org/works\"\n",
    "\n",
    "# Look-up Terms\n",
    "Query = [\n",
    "    # Computer Science / AI\n",
    "    \"machine learning\",\n",
    "    \"artificial intelligence\",\n",
    "    \"neural networks\",\n",
    "    \"deep learning\",\n",
    "    \"computer vision\",\n",
    "    \"reinforcement learning\",\n",
    "    \"natural language processing\",\n",
    "    \"AI ethics\",\n",
    "    \"robotics\",\n",
    "    \"knowledge graphs\",\n",
    "    \n",
    "    # Physics\n",
    "    \"quantum mechanics\",\n",
    "    \"climate modeling\",\n",
    "    \"string theory\",\n",
    "    \"particle physics\",\n",
    "    \"astrophysics\",\n",
    "    \"condensed matter physics\",\n",
    "    \"gravitational waves\",\n",
    "    \"thermodynamics\",\n",
    "    \"optics\",\n",
    "    \"plasma physics\",\n",
    "    \n",
    "    # Biology / Medicine\n",
    "    \"genome sequencing\",\n",
    "    \"cancer immunotherapy\",\n",
    "    \"CRISPR gene editing\",\n",
    "    \"stem cell therapy\",\n",
    "    \"epigenetics\",\n",
    "    \"microbiome research\",\n",
    "    \"protein folding\",\n",
    "    \"neuroscience\",\n",
    "    \"vaccine development\",\n",
    "    \"bioinformatics\",\n",
    "    \n",
    "    # Social Sciences\n",
    "    \"behavioral economics\",\n",
    "    \"urban sociology\",\n",
    "    \"political polarization\",\n",
    "    \"education policy\",\n",
    "    \"social networks\",\n",
    "    \"gender studies\",\n",
    "    \"migration studies\",\n",
    "    \"organizational behavior\",\n",
    "    \"public health policy\",\n",
    "    \"criminology\",\n",
    "    \n",
    "    # Humanities\n",
    "    \"medieval literature\",\n",
    "    \"renaissance art\",\n",
    "    \"philosophy of mind\",\n",
    "    \"linguistics\",\n",
    "    \"cultural anthropology\",\n",
    "    \"classical archaeology\",\n",
    "    \"music theory\",\n",
    "    \"modern literature\",\n",
    "    \"history of science\",\n",
    "    \"religious studies\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53efe4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page(query, page, per_page=20, max_retries=10):\n",
    "    \"\"\"Fetch a single page of OpenAlex results with retries.\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            url = f\"{BASE_URL}?filter=title.search:{query},open_access.is_oa:true&per-page={per_page}&page={page}\"\n",
    "            r = requests.get(url, timeout=10)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            results = data.get(\"results\", [])\n",
    "            papers = []\n",
    "            for d in results:\n",
    "                paper_id = d.get(\"id\")\n",
    "                papers.append({\n",
    "                    \"id\": paper_id,\n",
    "                    \"title\": d.get(\"title\"),\n",
    "                    \"abstract\": d.get(\"abstract_inverted_index\"),\n",
    "                    \"year\": d.get(\"publication_year\"),\n",
    "                    \"concepts\": [c[\"display_name\"] for c in d.get(\"concepts\", [])]\n",
    "                })\n",
    "            return papers\n",
    "        except (requests.exceptions.RequestException, ValueError) as e:\n",
    "            print(f\"Page {page} attempt {attempt+1} failed: {e}\")\n",
    "            sleep(15)\n",
    "    print(f\"Page {page} skipped after {max_retries} retries.\")\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fec824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remaking original description\n",
    "def reconstruct_abstract(inv_index):\n",
    "    \"\"\"Convert abstract inverted index to full text.\"\"\"\n",
    "    if not inv_index:\n",
    "        return \"\"\n",
    "    position_map = {}\n",
    "    for word, positions in inv_index.items():\n",
    "        for pos in positions:\n",
    "            position_map[pos] = word\n",
    "    return \" \".join(position_map[pos] for pos in sorted(position_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6206242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallelise the process for efficiency\n",
    "def fetch_query_parallel(query):\n",
    "    papers_dict = {}\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = {executor.submit(fetch_page, query, page, 20): page for page in range(1, 50+1)}\n",
    "        for future in as_completed(futures):\n",
    "            page_papers = future.result()\n",
    "            for paper in page_papers:\n",
    "                papers_dict[paper[\"id\"]] = paper  # deduplication\n",
    "    return list(papers_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676ab3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(\"openalex_papers5.csv\"):\n",
    "#    os.remove(\"openalex_papers5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9659167a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_paper_ids = set()\n",
    "batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefb7d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing query 1/50: machine learning\n",
      "Fetched 1000 English papers for query 'machine learning'\n",
      "Processing query 2/50: artificial intelligence\n",
      "Fetched 1000 English papers for query 'artificial intelligence'\n",
      "Processing query 3/50: neural networks\n",
      "Fetched 1000 English papers for query 'neural networks'\n",
      "Processing query 4/50: deep learning\n",
      "Fetched 1000 English papers for query 'deep learning'\n",
      "Processing query 5/50: computer vision\n",
      "Fetched 1000 English papers for query 'computer vision'\n",
      "Processing query 6/50: reinforcement learning\n",
      "Fetched 1000 English papers for query 'reinforcement learning'\n",
      "Processing query 7/50: natural language processing\n",
      "Fetched 1000 English papers for query 'natural language processing'\n",
      "Processing query 8/50: AI ethics\n",
      "Fetched 1000 English papers for query 'AI ethics'\n",
      "Processing query 9/50: robotics\n",
      "Fetched 1000 English papers for query 'robotics'\n",
      "Processing query 10/50: knowledge graphs\n",
      "Fetched 1000 English papers for query 'knowledge graphs'\n",
      "Processing query 11/50: quantum mechanics\n",
      "Fetched 1000 English papers for query 'quantum mechanics'\n",
      "Processing query 12/50: climate modeling\n",
      "Fetched 1000 English papers for query 'climate modeling'\n",
      "Processing query 13/50: string theory\n",
      "Fetched 1000 English papers for query 'string theory'\n",
      "Processing query 14/50: particle physics\n",
      "Fetched 1000 English papers for query 'particle physics'\n",
      "Processing query 15/50: astrophysics\n",
      "Fetched 1000 English papers for query 'astrophysics'\n",
      "Processing query 16/50: condensed matter physics\n",
      "Fetched 412 English papers for query 'condensed matter physics'\n",
      "Processing query 17/50: gravitational waves\n",
      "Fetched 1000 English papers for query 'gravitational waves'\n",
      "Processing query 18/50: thermodynamics\n",
      "Fetched 1000 English papers for query 'thermodynamics'\n",
      "Processing query 19/50: optics\n",
      "Fetched 1000 English papers for query 'optics'\n",
      "Processing query 20/50: plasma physics\n",
      "Fetched 1000 English papers for query 'plasma physics'\n",
      "Processing query 21/50: genome sequencing\n",
      "Fetched 1000 English papers for query 'genome sequencing'\n",
      "Processing query 22/50: cancer immunotherapy\n",
      "Fetched 1000 English papers for query 'cancer immunotherapy'\n",
      "Processing query 23/50: CRISPR gene editing\n",
      "Fetched 1000 English papers for query 'CRISPR gene editing'\n",
      "Processing query 24/50: stem cell therapy\n",
      "Fetched 1000 English papers for query 'stem cell therapy'\n",
      "Processing query 25/50: epigenetics\n",
      "Fetched 1000 English papers for query 'epigenetics'\n",
      "Processing query 26/50: microbiome research\n",
      "Fetched 746 English papers for query 'microbiome research'\n",
      "Processing query 27/50: protein folding\n",
      "Fetched 1000 English papers for query 'protein folding'\n",
      "Processing query 28/50: neuroscience\n",
      "Fetched 1000 English papers for query 'neuroscience'\n",
      "Processing query 29/50: vaccine development\n",
      "Fetched 1000 English papers for query 'vaccine development'\n",
      "Processing query 30/50: bioinformatics\n",
      "Fetched 1000 English papers for query 'bioinformatics'\n",
      "Processing query 31/50: behavioral economics\n",
      "Fetched 1000 English papers for query 'behavioral economics'\n",
      "Processing query 32/50: urban sociology\n",
      "Fetched 353 English papers for query 'urban sociology'\n",
      "Processing query 33/50: political polarization\n",
      "Fetched 1000 English papers for query 'political polarization'\n",
      "Processing query 34/50: education policy\n",
      "Fetched 1000 English papers for query 'education policy'\n",
      "Processing query 35/50: social networks\n",
      "Fetched 1000 English papers for query 'social networks'\n",
      "Processing query 36/50: gender studies\n",
      "Fetched 1000 English papers for query 'gender studies'\n",
      "Processing query 37/50: migration studies\n",
      "Fetched 1000 English papers for query 'migration studies'\n",
      "Processing query 38/50: organizational behavior\n",
      "Fetched 1000 English papers for query 'organizational behavior'\n",
      "Processing query 39/50: public health policy\n",
      "Fetched 1000 English papers for query 'public health policy'\n",
      "Processing query 40/50: criminology\n",
      "Fetched 1000 English papers for query 'criminology'\n",
      "Processing query 41/50: medieval literature\n",
      "Fetched 828 English papers for query 'medieval literature'\n",
      "Processing query 42/50: renaissance art\n",
      "Fetched 470 English papers for query 'renaissance art'\n",
      "Processing query 43/50: philosophy of mind\n",
      "Fetched 691 English papers for query 'philosophy of mind'\n",
      "Processing query 44/50: linguistics\n",
      "Fetched 1000 English papers for query 'linguistics'\n",
      "Processing query 45/50: cultural anthropology\n",
      "Fetched 943 English papers for query 'cultural anthropology'\n",
      "Processing query 46/50: classical archaeology\n",
      "Fetched 113 English papers for query 'classical archaeology'\n",
      "Processing query 47/50: music theory\n",
      "Fetched 1000 English papers for query 'music theory'\n",
      "Processing query 48/50: modern literature\n",
      "Fetched 1000 English papers for query 'modern literature'\n",
      "Processing query 49/50: history of science\n",
      "Fetched 1000 English papers for query 'history of science'\n",
      "Processing query 50/50: religious studies\n",
      "Fetched 1000 English papers for query 'religious studies'\n",
      "Finished. Total unique papers saved: 46191\n",
      "CSV file: openalex_papers5.csv\n"
     ]
    }
   ],
   "source": [
    "for q_idx, q in enumerate(Query, 1):\n",
    "    print(f\"Processing query {q_idx}/{len(Query)}: {q}\")\n",
    "    papers = fetch_query_parallel(q)\n",
    "    print(f\"Fetched {len(papers)} papers for query '{q}'\")\n",
    "\n",
    "    for paper in papers:\n",
    "        pid = paper[\"id\"]\n",
    "        if pid in global_paper_ids:\n",
    "            continue  # skip duplicates across queries\n",
    "        global_paper_ids.add(pid)\n",
    "        # reconstruct abstract text\n",
    "        paper[\"abstract_text\"] = reconstruct_abstract(paper.pop(\"abstract\", None))\n",
    "        batch.append(paper)\n",
    "\n",
    "        # Write batch to CSV if reached CHUNK_SIZE\n",
    "        if len(batch) >= 1000:\n",
    "            df_chunk = pd.DataFrame(batch)\n",
    "            df_chunk.to_csv(\"openalex_papers5.csv\", mode='a', index=False, header=not os.path.exists(\"openalex_papers5.csv\"))\n",
    "            batch = []\n",
    "\n",
    "# Write remaining papers\n",
    "if batch:\n",
    "    df_chunk = pd.DataFrame(batch)\n",
    "    df_chunk.to_csv(\"openalex_papers5.csv\", mode='a', index=False, header=not os.path.exists(\"openalex_papers5.csv\"))\n",
    "\n",
    "print(f\"Finished. Total unique papers saved: {len(global_paper_ids)}\")\n",
    "print(f\"CSV file: {\"openalex_papers5.csv\"}\")\n",
    "# Writing directly to memory for efficiency and saving an original copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28f273f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>concepts</th>\n",
       "      <th>abstract_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://openalex.org/W2886899886</td>\n",
       "      <td>Pattern of inter-marriage in Keningau: a preli...</td>\n",
       "      <td>2016</td>\n",
       "      <td>[Faith, Ethnic group, Religious conversion, Is...</td>\n",
       "      <td>This paper seeks to discuss the profiling patt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://openalex.org/W3217800672</td>\n",
       "      <td>Study of expenditure and stay in the segmentat...</td>\n",
       "      <td>2021</td>\n",
       "      <td>[Tourism, Diversification (marketing strategy)...</td>\n",
       "      <td>Tourist expenditure is an element that is gain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://openalex.org/W4312205350</td>\n",
       "      <td>Communication Patterns of Gus Baha' Religious ...</td>\n",
       "      <td>2022</td>\n",
       "      <td>[Clothing, History, Archaeology]</td>\n",
       "      <td>This article aims to describe the communicatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://openalex.org/W2947724033</td>\n",
       "      <td>Pope Francis's Laudato Si': A corpus study of ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>[Encyclical, Relevance (law), Rhetorical quest...</td>\n",
       "      <td>This paper explores aspects of the lexico-gram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://openalex.org/W3035577798</td>\n",
       "      <td>The Dilemma Between Religious Doctrine and Pol...</td>\n",
       "      <td>2020</td>\n",
       "      <td>[Politics, Ideology, Doctrine, Islam, Politica...</td>\n",
       "      <td>This paper aims to examine how Hamas as an Isl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://openalex.org/W3160035937</td>\n",
       "      <td>The Impact of the Church–State Model for an Ef...</td>\n",
       "      <td>2021</td>\n",
       "      <td>[Coronavirus disease 2019 (COVID-19), Interpre...</td>\n",
       "      <td>During the COVID-19 pandemic, many governments...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://openalex.org/W4378232595</td>\n",
       "      <td>The influence of cultural and religious factor...</td>\n",
       "      <td>2023</td>\n",
       "      <td>[Anxiety, Hofstede's cultural dimensions theor...</td>\n",
       "      <td>Introduction Low back pain and neck pain are a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://openalex.org/W3154589232</td>\n",
       "      <td>Religious tourism in Jordan: current situation...</td>\n",
       "      <td>2012</td>\n",
       "      <td>[Tourism, Islam, Religious tourism, State (com...</td>\n",
       "      <td>The purpose of this research study is to analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://openalex.org/W1973500443</td>\n",
       "      <td>Is it still possible to study religion religio...</td>\n",
       "      <td>2013</td>\n",
       "      <td>[Mythology, Variety (cybernetics), Philosophy,...</td>\n",
       "      <td>This article reflects on the question whether ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://openalex.org/W2033397684</td>\n",
       "      <td>A Comparative Study on Cyber Ethics, Religious...</td>\n",
       "      <td>2013</td>\n",
       "      <td>[Honesty, Social psychology, Psychology, Happi...</td>\n",
       "      <td>Throughout the internet's evolution , debates ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  https://openalex.org/W2886899886   \n",
       "1  https://openalex.org/W3217800672   \n",
       "2  https://openalex.org/W4312205350   \n",
       "3  https://openalex.org/W2947724033   \n",
       "4  https://openalex.org/W3035577798   \n",
       "5  https://openalex.org/W3160035937   \n",
       "6  https://openalex.org/W4378232595   \n",
       "7  https://openalex.org/W3154589232   \n",
       "8  https://openalex.org/W1973500443   \n",
       "9  https://openalex.org/W2033397684   \n",
       "\n",
       "                                               title  year  \\\n",
       "0  Pattern of inter-marriage in Keningau: a preli...  2016   \n",
       "1  Study of expenditure and stay in the segmentat...  2021   \n",
       "2  Communication Patterns of Gus Baha' Religious ...  2022   \n",
       "3  Pope Francis's Laudato Si': A corpus study of ...  2019   \n",
       "4  The Dilemma Between Religious Doctrine and Pol...  2020   \n",
       "5  The Impact of the Church–State Model for an Ef...  2021   \n",
       "6  The influence of cultural and religious factor...  2023   \n",
       "7  Religious tourism in Jordan: current situation...  2012   \n",
       "8  Is it still possible to study religion religio...  2013   \n",
       "9  A Comparative Study on Cyber Ethics, Religious...  2013   \n",
       "\n",
       "                                            concepts  \\\n",
       "0  [Faith, Ethnic group, Religious conversion, Is...   \n",
       "1  [Tourism, Diversification (marketing strategy)...   \n",
       "2                   [Clothing, History, Archaeology]   \n",
       "3  [Encyclical, Relevance (law), Rhetorical quest...   \n",
       "4  [Politics, Ideology, Doctrine, Islam, Politica...   \n",
       "5  [Coronavirus disease 2019 (COVID-19), Interpre...   \n",
       "6  [Anxiety, Hofstede's cultural dimensions theor...   \n",
       "7  [Tourism, Islam, Religious tourism, State (com...   \n",
       "8  [Mythology, Variety (cybernetics), Philosophy,...   \n",
       "9  [Honesty, Social psychology, Psychology, Happi...   \n",
       "\n",
       "                                       abstract_text  \n",
       "0  This paper seeks to discuss the profiling patt...  \n",
       "1  Tourist expenditure is an element that is gain...  \n",
       "2  This article aims to describe the communicatio...  \n",
       "3  This paper explores aspects of the lexico-gram...  \n",
       "4  This paper aims to examine how Hamas as an Isl...  \n",
       "5  During the COVID-19 pandemic, many governments...  \n",
       "6  Introduction Low back pain and neck pain are a...  \n",
       "7  The purpose of this research study is to analy...  \n",
       "8  This article reflects on the question whether ...  \n",
       "9  Throughout the internet's evolution , debates ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chunk.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b7453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict, Counter\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7206d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\")) # assuming english lexicon (dropped all other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95d8349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    return [\n",
    "        t for t in tokens\n",
    "        if t.isalpha() and t not in stop_words\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92945ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inverted_index(text):\n",
    "    \"\"\"\n",
    "    Build an inverted index from a string:\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return {}\n",
    "\n",
    "    tokens = tokenize(text)  # lowercase, remove stopwords\n",
    "    inv_index = defaultdict(list)\n",
    "    for pos, token in enumerate(tokens):\n",
    "        inv_index[token].append(pos)\n",
    "    return dict(inv_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329b10ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc8bd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"abstract_text\"].notna() & (df[\"abstract_text\"] != \"\")] # remove all pages with empty descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdf0738",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"abstract_inverted_index\"] = df[\"abstract_text\"].apply(build_inverted_index) # construct inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e19d191",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokens\"] = df[\"abstract_inverted_index\"].apply(\n",
    "    lambda inv: [t.lower() for t, pos_list in inv.items() for _ in pos_list]\n",
    ")\n",
    "# Expand the inverted index into a token list by:\n",
    "# - repeating each term once per occurrence\n",
    "# - converting all tokens to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b84ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokens\"] = df[\"tokens\"].apply(json.dumps) # Have to convert to json as when saving to csv, tokens are converted from list to str (char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f993e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./openalex10.csv\", index=False) # save to csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
