id,title,abstract,year,concepts,abstract_text
https://openalex.org/W2122410182,Artificial intelligence: a modern approach,"{'The': [0], 'long-anticipated': [1], 'revision': [2], 'of': [3, 13, 22], 'this': [4], '#1': [5], 'selling': [6], 'book': [7], 'offers': [8], 'the': [9, 14, 18], 'most': [10], 'comprehensive,': [11], 'state': [12], 'art': [15], 'introduction': [16], 'to': [17], 'theory': [19], 'and': [20, 59, 96], 'practice': [21], 'artificial': [23, 101], 'intelligence': [24], 'for': [25], 'modern': [26], 'applications.': [27], 'Intelligent': [28], 'Agents.': [29], 'Solving': [30], 'Problems': [31], 'by': [32], 'Searching.': [33], 'Informed': [34], 'Search': [35], 'Methods.': [36], 'Game': [37], 'Playing.': [38], 'Agents': [39, 83], 'that': [40, 84], 'Reason': [41], 'Logically.': [42], 'First-order': [43], 'Logic.': [44, 52], 'Building': [45], 'a': [46], 'Knowledge': [47, 80], 'Base.': [48], 'Inference': [49], 'in': [50, 81, 88, 100], 'First-Order': [51], 'Logical': [53], 'Reasoning': [54, 63], 'Systems.': [55, 64], 'Practical': [56, 86], 'Planning.': [57], 'Planning': [58], 'Acting.': [60], 'Uncertainty.': [61], 'Probabilistic': [62], 'Making': [65, 68], 'Simple': [66], 'Decisions.': [67, 70], 'Complex': [69], 'Learning': [71, 74], 'from': [72], 'Observations.': [73], 'with': [75], 'Neural': [76], 'Networks.': [77], 'Reinforcement': [78], 'Learning.': [79, 82], 'Communicate.': [85], 'Communication': [87], 'English.': [89], 'Perception.': [90], 'Robotics.': [91], 'For': [92], 'computer': [93], 'professionals,': [94], 'linguists,': [95], 'cognitive': [97], 'scientists': [98], 'interested': [99], 'intelligence.': [102]}",1995,"['Artificial intelligence', 'Computer science', 'Inference', 'Artificial intelligence, situated approach', 'Probabilistic logic', 'Cognitive robotics', 'Symbolic artificial intelligence', 'Reinforcement learning', 'Cognitive science', 'Robot', 'Psychology']","The long-anticipated revision of this #1 selling book offers the most comprehensive, state of the art introduction to the theory and practice of artificial intelligence for modern applications. Intelligent Agents. Solving Problems by Searching. Informed Search Methods. Game Playing. Agents that Reason Logically. First-order Logic. Building a Knowledge Base. Inference in First-Order Logic. Logical Reasoning Systems. Practical Planning. Planning and Acting. Uncertainty. Probabilistic Reasoning Systems. Making Simple Decisions. Making Complex Decisions. Learning from Observations. Learning with Neural Networks. Reinforcement Learning. Knowledge in Learning. Agents that Communicate. Practical Communication in English. Perception. Robotics. For computer professionals, linguists, and cognitive scientists interested in artificial intelligence."
https://openalex.org/W2664267452,"Artificial intelligence in healthcare: past, present and future","{'Artificial': [0], 'intelligence': [1], '(AI)': [2], 'aims': [3], 'to': [4, 15, 48], 'mimic': [5], 'human': [6], 'cognitive': [7], 'functions.': [8], 'It': [9], 'is': [10], 'bringing': [11], 'a': [12], 'paradigm': [13], 'shift': [14], 'healthcare,': [16], 'powered': [17], 'by': [18], 'increasing': [19], 'availability': [20], 'of': [21, 27, 35, 51, 119, 150], 'healthcare': [22, 39, 52], 'data': [23, 53], 'and': [24, 40, 55, 74, 77, 101, 122, 130, 145], 'rapid': [25], 'progress': [26], 'analytics': [28], 'techniques.': [29], 'We': [30, 103, 133], 'survey': [31], 'the': [32, 69, 78, 109, 115], 'current': [33], 'status': [34], 'AI': [36, 44, 58, 96, 110, 139], 'applications': [37, 111], 'in': [38, 106, 112, 114], 'discuss': [41], 'its': [42], 'future.': [43], 'can': [45], 'be': [46], 'applied': [47], 'various': [49], 'types': [50], '(structured': [54], 'unstructured).': [56], 'Popular': [57], 'techniques': [59], 'include': [60, 98], 'machine': [61, 73], 'learning': [62], 'methods': [63], 'for': [64, 88, 147], 'structured': [65], 'data,': [66], 'such': [67, 141], 'as': [68, 82, 84, 125, 127, 142], 'classical': [70], 'support': [71], 'vector': [72], 'neural': [75], 'network,': [76], 'modern': [79], 'deep': [80], 'learning,': [81], 'well': [83, 126], 'natural': [85], 'language': [86], 'processing': [87], 'unstructured': [89], 'data.': [90], 'Major': [91], 'disease': [92], 'areas': [93, 118], 'that': [94], 'use': [95], 'tools': [97], 'cancer,': [99], 'neurology': [100], 'cardiology.': [102], 'then': [104], 'review': [105], 'more': [107], 'details': [108], 'stroke,': [113], 'three': [116], 'major': [117], 'early': [120], 'detection': [121], 'diagnosis,': [123], 'treatment,': [124], 'outcome': [128], 'prediction': [129], 'prognosis': [131], 'evaluation.': [132], 'conclude': [134], 'with': [135], 'discussion': [136], 'about': [137], 'pioneer': [138], 'systems,': [140], 'IBM': [143], 'Watson,': [144], 'hurdles': [146], 'real-life': [148], 'deployment': [149], 'AI.': [151]}",2017,"['Cognitive computing', 'Health care', 'Data science', 'Artificial intelligence', 'Computer science', 'Software deployment', 'Unstructured data', 'Watson', 'Applications of artificial intelligence', 'Big data', 'Analytics', 'IBM', 'Deep learning', 'Predictive analytics', 'Machine learning', 'Cognition', 'Medicine', 'Software engineering', 'Data mining', 'Materials science', 'Psychiatry', 'Economic growth', 'Economics', 'Nanotechnology']","Artificial intelligence (AI) aims to mimic human cognitive functions. It is bringing a paradigm shift to healthcare, powered by increasing availability of healthcare data and rapid progress of analytics techniques. We survey the current status of AI applications in healthcare and discuss its future. AI can be applied to various types of healthcare data (structured and unstructured). Popular AI techniques include machine learning methods for structured data, such as the classical support vector machine and neural network, and the modern deep learning, as well as natural language processing for unstructured data. Major disease areas that use AI tools include cancer, neurology and cardiology. We then review in more details the AI applications in stroke, in the three major areas of early detection and diagnosis, treatment, as well as outcome prediction and prognosis evaluation. We conclude with discussion about pioneer AI systems, such as IBM Watson, and hurdles for real-life deployment of AI."
https://openalex.org/W2891503716,Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI),"{'At': [0], 'the': [1, 4, 28, 45, 57, 101, 130, 142, 145, 149, 153], 'dawn': [2], 'of': [3, 16, 47, 60, 94, 129, 136, 144], 'fourth': [5], 'industrial': [6], 'revolution,': [7], 'we': [8, 147], 'are': [9], 'witnessing': [10], 'a': [11, 31, 41, 76], 'fast': [12], 'and': [13, 92, 123, 132, 160], 'widespread': [14], 'adoption': [15], 'artificial': [17], 'intelligence': [18], '(AI)': [19], 'in': [20], 'our': [21], 'daily': [22], 'life,': [23], 'which': [24], 'contributes': [25], 'to': [26, 44, 107, 125, 139], 'accelerating': [27], 'shift': [29], 'towards': [30], 'more': [32], 'algorithmic': [33], 'society.': [34], 'However,': [35], 'even': [36], 'with': [37], 'such': [38], 'unprecedented': [39], 'advancements,': [40], 'key': [42, 127], 'impediment': [43], 'use': [46], 'AI-based': [48, 95], 'systems': [49, 62], 'is': [50, 98], 'that': [51], 'they': [52], 'often': [53], 'lack': [54], 'transparency.': [55], 'Indeed,': [56], 'black-box': [58], 'nature': [59], 'these': [61], 'allows': [63], 'powerful': [64], 'predictions,': [65], 'but': [66], 'it': [67], 'cannot': [68], 'be': [69], 'directly': [70], 'explained.': [71], 'This': [72, 114], 'issue': [73], 'has': [74], 'triggered': [75], 'new': [77], 'debate': [78], 'on': [79], 'explainable': [80], 'AI': [81, 106], '(XAI).': [82], 'A': [83], 'research': [84, 137, 163], 'field': [85], 'holds': [86], 'substantial': [87], 'promise': [88], 'for': [89, 105, 120], 'improving': [90], 'trust': [91], 'transparency': [93], 'systems.': [96], 'It': [97], 'recognized': [99], 'as': [100], 'sine': [102], 'qua': [103], 'non': [104], 'continue': [108], 'making': [109], 'steady': [110], 'progress': [111], 'without': [112], 'disruption.': [113], 'survey': [115], 'provides': [116], 'an': [117], 'entry': [118], 'point': [119], 'interested': [121], 'researchers': [122], 'practitioners': [124], 'learn': [126], 'aspects': [128], 'young': [131], 'rapidly': [133], 'growing': [134], 'body': [135], 'related': [138], 'XAI.': [140], 'Through': [141], 'lens': [143], 'literature,': [146], 'review': [148], 'existing': [150], 'approaches': [151], 'regarding': [152], 'topic,': [154], 'discuss': [155], 'trends': [156], 'surrounding': [157], 'its': [158], 'sphere,': [159], 'present': [161], 'major': [162], 'trajectories.': [164]}",2018,"['Transparency (behavior)', 'Sine qua non', 'Computer science', 'Black box', 'Field (mathematics)', 'Data science', 'Key (lock)', 'Artificial intelligence', 'Operations research', 'Political science', 'Computer security', 'Engineering', 'Law', 'Mathematics', 'Pure mathematics']","At the dawn of the fourth industrial revolution, we are witnessing a fast and widespread adoption of artificial intelligence (AI) in our daily life, which contributes to accelerating the shift towards a more algorithmic society. However, even with such unprecedented advancements, a key impediment to the use of AI-based systems is that they often lack transparency. Indeed, the black-box nature of these systems allows powerful predictions, but it cannot be directly explained. This issue has triggered a new debate on explainable AI (XAI). A research field holds substantial promise for improving trust and transparency of AI-based systems. It is recognized as the sine qua non for AI to continue making steady progress without disruption. This survey provides an entry point for interested researchers and practitioners to learn key aspects of the young and rapidly growing body of research related to XAI. Through the lens of the literature, we review the existing approaches regarding the topic, discuss trends surrounding its sphere, and present major research trajectories."
https://openalex.org/W3017131514,Artificial Intelligence in Education: A Review,"{'The': [0, 110], 'purpose': [1], 'of': [2, 10, 32, 42, 56, 72, 81, 135, 154, 164, 249], 'this': [3], 'study': [4, 34, 74, 82, 111], 'was': [5, 35, 65], 'to': [6, 37, 142, 170, 187], 'assess': [7], 'the': [8, 30, 33, 38, 54, 70, 73, 84, 133, 152, 162, 212, 216], 'impact': [9], 'Artificial': [11, 76], 'Intelligence': [12], '(AI)': [13], 'on': [14, 17], 'education.': [15], 'Premised': [16], 'a': [18, 27, 60, 79], 'narrative': [19], 'and': [20, 40, 47, 63, 67, 83, 87, 95, 107, 119, 137, 144, 149, 167, 174, 195, 201, 203, 221, 224, 229, 240, 246], 'framework': [21], 'for': [22], 'assessing': [23], 'AI': [24, 43, 114, 130], 'identified': [25], 'from': [26], 'preliminary': [28], 'analysis,': [29], 'scope': [31], 'limited': [36], 'application': [39], 'effects': [41], 'in': [44, 92, 121, 127, 207, 231], 'administration,': [45], 'instruction,': [46], 'learning.': [48, 250], 'A': [49], 'qualitative': [50], 'research': [51, 61], 'approach,': [52], 'leveraging': [53], 'use': [55, 153, 163], 'literature': [57], 'review': [58], 'as': [59, 193], 'design': [62], 'approach': [64], 'used': [66, 120], 'effectively': [68, 200], 'facilitated': [69], 'realization': [71], 'purpose.': [75], 'intelligence': [77, 100], 'is': [78], 'field': [80], 'resulting': [85], 'innovations': [86], 'developments': [88], 'that': [89, 113], 'have': [90, 184], 'culminated': [91], 'computers,': [93], 'machines,': [94], 'other': [96, 160, 213], 'artifacts': [97], 'having': [98], 'human-like': [99], 'characterized': [101], 'by': [102, 124], 'cognitive': [103], 'abilities,': [104], 'learning,': [105], 'adaptability,': [106, 222], 'decision-making': [108], 'capabilities.': [109], 'ascertained': [112], 'has': [115, 226, 237], 'extensively': [116], 'been': [117, 185, 227], 'adopted': [118], 'education,': [122], 'particularly': [123], 'education': [125, 147], 'institutions,': [126], 'different': [128, 189], 'forms.': [129], 'initially': [131], 'took': [132], 'form': [134], 'computer': [136, 138, 156], 'related': [139], 'technologies,': [140, 161], 'transitioning': [141], 'web-based': [143, 168], 'online': [145], 'intelligent': [146], 'systems,': [148, 157], 'ultimately': [150], 'with': [151, 159, 178, 233], 'embedded': [155], 'together': [158], 'humanoid': [165], 'robots': [166], 'chatbots': [169], 'perform': [171, 188], ""instructors'"": [172], 'duties': [173], 'functions': [175], 'independently': [176], 'or': [177], 'instructors.': [179], 'Using': [180], 'these': [181], 'platforms,': [182], 'instructors': [183], 'able': [186], 'administrative': [190], 'functions,': [191], 'such': [192], 'reviewing': [194], 'grading': [196], ""students'"": [197, 234], 'assignments': [198], 'more': [199], 'efficiently,': [202], 'achieve': [204], 'higher': [205], 'quality': [206, 248], 'their': [208], 'teaching': [209], 'activities.': [210], 'On': [211], 'hand,': [214], 'because': [215], 'systems': [217], 'leverage': [218], 'machine': [219], 'learning': [220], 'curriculum': [223], 'content': [225], 'customized': [228], 'personalized': [230], 'line': [232], 'needs,': [235], 'which': [236], 'fostered': [238], 'uptake': [239], 'retention,': [241], 'thereby': [242], 'improving': [243], 'learners': [244], 'experience': [245], 'overall': [247]}",2020,"['Computer science', 'Adaptability', 'Personalized learning', 'Artificial intelligence', 'Curriculum', 'Knowledge management', 'Multimedia', 'Teaching method', 'Open learning', 'Cooperative learning', 'Mathematics education', 'Psychology', 'Biology', 'Ecology', 'Pedagogy']","The purpose of this study was to assess the impact of Artificial Intelligence (AI) on education. Premised on a narrative and framework for assessing AI identified from a preliminary analysis, the scope of the study was limited to the application and effects of AI in administration, instruction, and learning. A qualitative research approach, leveraging the use of literature review as a research design and approach was used and effectively facilitated the realization of the study purpose. Artificial intelligence is a field of study and the resulting innovations and developments that have culminated in computers, machines, and other artifacts having human-like intelligence characterized by cognitive abilities, learning, adaptability, and decision-making capabilities. The study ascertained that AI has extensively been adopted and used in education, particularly by education institutions, in different forms. AI initially took the form of computer and computer related technologies, transitioning to web-based and online intelligent education systems, and ultimately with the use of embedded computer systems, together with other technologies, the use of humanoid robots and web-based chatbots to perform instructors' duties and functions independently or with instructors. Using these platforms, instructors have been able to perform different administrative functions, such as reviewing and grading students' assignments more effectively and efficiently, and achieve higher quality in their teaching activities. On the other hand, because the systems leverage machine learning and adaptability, curriculum and content has been customized and personalized in line with students' needs, which has fostered uptake and retention, thereby improving learners experience and overall quality of learning."
https://openalex.org/W1543659671,Artificial Intelligence: A Guide to Intelligent Systems,"{'From': [0], 'the': [1, 4, 12, 60, 76, 87, 95, 118, 151, 154], 'Publisher:\r\nVirtually': [2], 'all': [3], 'literature': [5], 'on': [6, 29], 'artificial': [7], 'intelligence': [8], 'is': [9, 137], 'expressed': [10], 'in': [11, 75, 156], 'jargon': [13], 'of': [14, 57, 68, 97, 153], 'commuter': [15], 'science,': [16, 129], 'crowded': [17], 'with': [18, 54, 66], 'complex': [19], 'matrix': [20], 'algebra': [21], 'and': [22, 43, 59, 159, 167], 'differential': [23], 'equations.': [24], 'Unlike': [25], 'many': [26], 'other': [27], 'books': [28], 'computer': [30, 98, 128], 'intelligence,': [31, 99], 'this': [32], 'one': [33], 'demonstrates': [34], 'that': [35], 'most': [36], 'ideas': [37], 'behind': [38], 'intelligent': [39, 111], 'systems': [40, 131, 158], 'are': [41], 'simple': [42], 'straightforward.': [44], 'The': [45, 72, 135], 'book': [46, 77, 90, 119, 136], 'has': [47], 'evolved': [48], 'from': [49], 'lectures': [50], 'given': [51, 85], 'to': [52, 94, 150], 'students': [53], 'little': [55], 'knowledge': [56, 67], 'calculus,': [58], 'reader': [61], 'needs': [62], 'no': [63], 'prerequisites': [64], 'associated': [65], 'any': [69], 'programming': [70], 'language.': [71], 'methods': [73], 'used': [74, 122], 'have': [78], 'been': [79], 'extensively': [80], 'tested': [81], 'through': [82], 'several': [83], 'courses': [84], 'by': [86], 'author.': [88], '\r\n\r\nThe': [89], 'provides': [91], 'an': [92, 124], 'introduction': [93], 'field': [96], 'covering': [100], '\r\n\r\nrule-based': [101], 'expert': [102, 104, 106], 'systems,\r\nfuzzy': [103], 'systems,\r\nframe-based': [105], 'systems,\r\nartificail': [107], 'neural': [108], 'networks,\r\nevolutionary': [109], 'computation,\r\nhybrid': [110], 'systems,\r\nknowledge': [112], 'engineering,\r\ndata': [113], 'mining.\r\n\r\n\r\nIn': [114], 'a': [115, 141], 'university': [116], 'setting': [117], 'can': [120, 174], 'be': [121], 'as': [123, 140], 'introductory': [125], 'course': [126], 'within': [127], 'information': [130], 'or': [132], 'engineering': [133], 'departments.': [134], 'also': [138], 'suitable': [139], 'self-study': [142], 'guide': [143], 'for': [144], 'non-computer': [145], 'science': [146], 'professionals,': [147], 'giving': [148], 'access': [149], 'state': [152], 'art': [155], 'knowledge-based': [157], 'computational': [160], 'intelligence.': [161], 'Everyone': [162], 'who': [163], 'faces': [164], 'challenging': [165], 'problems': [166], 'cannot': [168], 'solve': [169], 'them': [170], 'using': [171], 'traditional': [172], 'approaches': [173], 'benefit': [175]}",2001,"['Computer science', 'Jargon', 'Expert system', 'Intelligent decision support system', 'Computational intelligence', 'Artificial intelligence', 'Applications of artificial intelligence', 'Simple (philosophy)', 'Field (mathematics)', 'Data science', 'Mathematics', 'Epistemology', 'Pure mathematics', 'Linguistics', 'Philosophy']","From the Publisher:
Virtually all the literature on artificial intelligence is expressed in the jargon of commuter science, crowded with complex matrix algebra and differential equations. Unlike many other books on computer intelligence, this one demonstrates that most ideas behind intelligent systems are simple and straightforward. The book has evolved from lectures given to students with little knowledge of calculus, and the reader needs no prerequisites associated with knowledge of any programming language. The methods used in the book have been extensively tested through several courses given by the author. 

The book provides an introduction to the field of computer intelligence, covering 

rule-based expert systems,
fuzzy expert systems,
frame-based expert systems,
artificail neural networks,
evolutionary computation,
hybrid intelligent systems,
knowledge engineering,
data mining.


In a university setting the book can be used as an introductory course within computer science, information systems or engineering departments. The book is also suitable as a self-study guide for non-computer science professionals, giving access to the state of the art in knowledge-based systems and computational intelligence. Everyone who faces challenging problems and cannot solve them using traditional approaches can benefit"
https://openalex.org/W3021909058,Artificial Intelligence: A Modern Approach,"{'&lt;p&gt;Humankind': [0], 'has': [1, 91, 205, 216, 328, 447], 'given': [2], 'itself': [3], 'the': [4, 9, 111, 136, 145, 192, 201, 209, 214, 222, 236, 246, 272, 294, 306, 324, 342, 371, 375, 394, 420, 436, 442, 445, 518, 526], 'scientific': [5], 'name': [6, 247], 'homo': [7], 'sapiens--man': [8], 'wise--because': [10], 'our': [11, 18, 22, 131], 'mental': [12, 382], 'capacities': [13], 'are': [14, 56, 82, 187, 462], 'so': [15], 'important': [16], 'to': [17, 34, 41, 45, 62, 73, 161, 217, 224, 278, 352, 434, 450, 490, 522, 544, 548], 'everyday': [19, 132], 'lives': [20, 133], 'and': [21, 53, 84, 95, 134, 165, 171, 305, 308, 358, 388, 430, 459, 467, 487, 502, 520, 524], 'sense': [23], 'of': [24, 28, 139, 144, 228, 235, 314, 336, 341, 367, 428, 439, 441, 479, 551], 'self.': [25], 'The': [26, 334, 365], 'field': [27], 'artificial': [29, 513], 'intelligence,': [30, 429, 514], 'or': [31, 159, 197, 361], 'AI,': [32, 322], 'attempts': [33], 'understand': [35, 69, 353], 'intelligent': [36, 64, 80, 230, 418], 'entities.': [37], 'Thus,': [38], 'one': [39, 108, 143, 234, 317, 340], 'reason': [40, 72], 'study': [42, 74, 315, 335], 'it': [43, 115, 150, 267, 310, 558], 'is': [44, 76, 116, 149, 211, 219, 233, 268, 338, 559], 'learn': [46], 'more': [47, 172, 452, 465, 468], 'about': [48, 180, 260], 'ourselves.': [49], 'But': [50, 408], 'unlike': [51, 191], 'philosophy': [52], 'psychology,': [54], 'which': [55, 530], 'also': [57, 339], 'concerned': [58], 'with': [59, 120, 183, 264], 'AI': [60, 75, 90, 141, 204, 232, 473, 541], 'strives': [61], 'build': [63], 'entities': [65, 81], 'as': [66, 68, 271, 409, 411, 470, 485, 494], 'well': [67, 410], 'them.': [70], 'Another': [71], 'that': [77, 118, 208, 252, 292, 309, 393], 'these': [78, 381], 'constructed': [79], 'interesting': [83, 469], 'useful': [85], 'in': [86, 103, 113, 203, 221, 243, 282, 287, 370, 507, 540], 'their': [87, 536, 546], 'own': [88], 'right.': [89], 'produced': [92], 'many': [93, 312, 431, 455], 'significant': [94], 'impressive': [96], 'products': [97], 'even': [98], 'at': [99, 251, 456], 'this': [100, 556], 'early': [101, 372], 'stage': [102], 'its': [104], 'development.': [105], 'Although': [106], 'no': [107], 'can': [109, 318, 542], 'predict': [110], 'future': [112, 137], 'detail,': [114], 'clear': [117], 'computers': [119, 369], 'human-level': [121], 'intelligence': [122, 337], '(or': [123], 'better)': [124], 'would': [125, 275], 'have': [126, 297, 350, 532], 'a': [127, 153, 167, 331, 385, 405, 413, 423, 471, 476, 561], 'huge': [128, 477], 'impact': [129], 'on': [130, 135, 323, 529], 'course': [138], 'civilization.': [140], 'addresses': [142], 'ultimate': [146], 'puzzles.': [147], 'How': [148, 176], 'possible': [151], 'for': [152, 194, 259, 330, 400, 415, 425], 'slow,': [154], 'tiny': [155], 'brain{brain},': [156], 'whether': [157], 'biological': [158], 'electronic,': [160], 'perceive,': [162], 'understand,': [163], 'predict,': [164], 'manipulate': [166], 'world': [168], 'far': [169], 'larger': [170], 'complicated': [173], 'than': [174, 454], 'itself?': [175], 'do': [177, 218], 'we': [178], 'go': [179], 'making': [181], 'something': [182], 'those': [184], 'properties?': [185], 'These': [186], 'hard': [188], 'questions,': [189], 'but': [190, 377], 'search': [193], 'faster-than-light': [195], 'travel': [196], 'an': [198, 226, 229], 'antigravity': [199], 'device,': [200], 'researcher': [202, 215], 'solid': [206], 'evidence': [207], 'quest': [210], 'possible.': [212], 'All': [213], 'look': [220], 'mirror': [223], 'see': [225], 'example': [227], 'system.': [231], 'newest': [237], 'disciplines.': [238, 284, 344], 'It': [239], 'was': [240, 248], 'formally': [241], 'initiated': [242], '1956,': [244], 'when': [245], 'coined,': [249], 'although': [250], 'point': [253], 'work': [254], 'had': [255], 'been': [256, 299, 533], 'under': [257], 'way': [258], 'five': [261], 'years.': [262], 'Along': [263], 'modern': [265, 460], 'genetics,': [266], 'regularly': [269], 'cited': [270], '``field': [273], 'I': [274], 'most': [276], 'like': [277], 'be': [279, 363, 451], ""in''by"": [280], 'scientists': [281, 506], 'other': [283, 325, 508], 'A': [285], 'student': [286], 'physics': [288], 'might': [289], 'reasonably': [290], 'feel': [291], 'all': [293, 535], 'good': [295], 'ideas': [296, 461], 'already': [298], 'taken': [300], 'by': [301], 'Galileo,': [302], 'Newton,': [303], 'Einstein,': [304], 'rest,': [307], 'takes': [311], 'years': [313], 'before': [316], 'contribute': [319], 'new': [320, 395], 'ideas.': [321], 'hand,': [326], 'still': [327], 'openings': [329], 'full-time': [332], 'Einstein.': [333], 'oldest': [343], 'For': [345], 'over': [346], '2000': [347], 'years,': [348], 'philosophers': [349], 'tried': [351], 'how': [354], 'seeing,': [355], 'learning,': [356], 'remembering,': [357], 'reasoning': [359], 'could,': [360], 'should,': [362], 'done.': [364], 'advent': [366], 'usable': [368], '1950s': [373], 'turned': [374, 448], 'learned': [376], 'armchair': [378], 'speculation': [379], 'concerning': [380], 'faculties': [383], 'into': [384, 444, 512], 'real': [386], 'experimental': [387], 'theoretical': [389], 'discipline.': [390], 'Many': [391], 'felt': [392], '``Electronic': [396], ""Super-Brains''had"": [397], 'unlimited': [398], 'potential': [399], 'intelligence.': [401], '``Faster': [402], 'Than': [403], ""Einstein''was"": [404], 'typical': [406], 'headline.': [407], 'providing': [412], 'vehicle': [414], 'creating': [416], 'artificially': [417], 'entities,': [419], 'computer': [421], 'provides': [422], 'tool': [424], 'testing': [426], 'theories': [427, 432], 'failed': [433], 'withstand': [435], 'test--a': [437], 'case': [438], '``out': [440], 'armchair,': [443], ""fire.''AI"": [446], 'out': [449], 'difficult': [453], 'first': [457], 'imagined,': [458], 'much': [463], 'richer,': [464], 'subtle,': [466], 'result.': [472], 'currently': [474], 'encompasses': [475], 'variety': [478], 'subfields,': [480], 'from': [481], 'general-purpose': [482], 'areas': [483], 'such': [484, 493], 'perception': [486], 'logical': [488], 'reasoning,': [489], 'specific': [491], 'tasks': [492, 528], 'playing': [495], 'chess,': [496], 'proving': [497], 'mathematical': [498], 'theorems,': [499], 'writing': [500], 'poetry{poetry},': [501], 'diagnosing': [503], 'diseases.': [504], 'Often,': [505], 'fields': [509], 'move': [510], 'gradually': [511], 'where': [515], 'they': [516, 531], 'find': [517], 'tools': [519], 'vocabulary': [521], 'systematize': [523], 'automate': [525], 'intellectual': [527, 553], 'working': [534], 'lives.': [537], 'Similarly,': [538], 'workers': [539], 'choose': [543], 'apply': [545], 'methods': [547], 'any': [549], 'area': [550], 'human': [552], 'endeavor.': [554], 'In': [555], 'sense,': [557], 'truly': [560], 'universal': [562], 'field.': [563], '&lt;/p&gt;': [564]}",1995,"['Artificial general intelligence', 'Cognitive science', 'Computer science', 'Civilization', 'Field (mathematics)', 'Everyday life', 'Artificial intelligence', 'Human intelligence', 'Epistemology', 'Psychology', 'Data science', 'Philosophy', 'History', 'Pure mathematics', 'Archaeology', 'Mathematics']","&lt;p&gt;Humankind has given itself the scientific name homo sapiens--man the wise--because our mental capacities are so important to our everyday lives and our sense of self. The field of artificial intelligence, or AI, attempts to understand intelligent entities. Thus, one reason to study it is to learn more about ourselves. But unlike philosophy and psychology, which are also concerned with AI strives to build intelligent entities as well as understand them. Another reason to study AI is that these constructed intelligent entities are interesting and useful in their own right. AI has produced many significant and impressive products even at this early stage in its development. Although no one can predict the future in detail, it is clear that computers with human-level intelligence (or better) would have a huge impact on our everyday lives and on the future course of civilization. AI addresses one of the ultimate puzzles. How is it possible for a slow, tiny brain{brain}, whether biological or electronic, to perceive, understand, predict, and manipulate a world far larger and more complicated than itself? How do we go about making something with those properties? These are hard questions, but unlike the search for faster-than-light travel or an antigravity device, the researcher in AI has solid evidence that the quest is possible. All the researcher has to do is look in the mirror to see an example of an intelligent system. AI is one of the newest disciplines. It was formally initiated in 1956, when the name was coined, although at that point work had been under way for about five years. Along with modern genetics, it is regularly cited as the ``field I would most like to be in''by scientists in other disciplines. A student in physics might reasonably feel that all the good ideas have already been taken by Galileo, Newton, Einstein, and the rest, and that it takes many years of study before one can contribute new ideas. AI, on the other hand, still has openings for a full-time Einstein. The study of intelligence is also one of the oldest disciplines. For over 2000 years, philosophers have tried to understand how seeing, learning, remembering, and reasoning could, or should, be done. The advent of usable computers in the early 1950s turned the learned but armchair speculation concerning these mental faculties into a real experimental and theoretical discipline. Many felt that the new ``Electronic Super-Brains''had unlimited potential for intelligence. ``Faster Than Einstein''was a typical headline. But as well as providing a vehicle for creating artificially intelligent entities, the computer provides a tool for testing theories of intelligence, and many theories failed to withstand the test--a case of ``out of the armchair, into the fire.''AI has turned out to be more difficult than many at first imagined, and modern ideas are much richer, more subtle, and more interesting as a result. AI currently encompasses a huge variety of subfields, from general-purpose areas such as perception and logical reasoning, to specific tasks such as playing chess, proving mathematical theorems, writing poetry{poetry}, and diagnosing diseases. Often, scientists in other fields move gradually into artificial intelligence, where they find the tools and vocabulary to systematize and automate the intellectual tasks on which they have been working all their lives. Similarly, workers in AI can choose to apply their methods to any area of human intellectual endeavor. In this sense, it is truly a universal field. &lt;/p&gt;"
https://openalex.org/W2979906316,How artificial intelligence will change the future of marketing,"{'Abstract': [0], 'In': [1], 'the': [2, 30, 38, 74, 93, 108], 'future,': [3, 94], 'artificial': [4], 'intelligence': [5, 43], '(AI)': [6], 'is': [7, 50], 'likely': [8], 'to': [9, 102], 'substantially': [10], 'change': [11, 91], 'both': [12], 'marketing': [13, 85], 'strategies': [14, 86], 'and': [15, 47, 87, 105], 'customer': [16, 88], 'behaviors.': [17], 'Building': [18], 'from': [19], 'not': [20, 82], 'only': [21, 83], 'extant': [22], 'research': [23, 56, 78], 'but': [24, 95], 'also': [25, 96], 'extensive': [26], 'interactions': [27], 'with': [28], 'practice,': [29], 'authors': [31, 75, 109], 'propose': [32, 76], 'a': [33, 53, 59, 70, 77], 'multidimensional': [34], 'framework': [35], 'for': [36], 'understanding': [37], 'impact': [39], 'of': [40, 61], 'AI': [41, 49, 111], 'involving': [42], 'levels,': [44], 'task': [45], 'types,': [46], 'whether': [48], 'embedded': [51], 'in': [52, 92], 'robot.': [54], 'Prior': [55], 'typically': [57], 'addresses': [58, 81], 'subset': [60], 'these': [62], 'dimensions;': [63], 'this': [64], 'paper': [65], 'integrates': [66], 'all': [67], 'three': [68], 'into': [69], 'single': [71], 'framework.': [72], 'Next,': [73], 'agenda': [79], 'that': [80], 'how': [84], 'behaviors': [89], 'will': [90, 112], 'highlights': [97], 'important': [98], 'policy': [99], 'questions': [100], 'relating': [101], 'privacy,': [103], 'bias': [104], 'ethics.': [106], 'Finally,': [107], 'suggest': [110], 'be': [113], 'more': [114], 'effective': [115], 'if': [116], 'it': [117], 'augments': [118], '(rather': [119], 'than': [120], 'replaces)': [121], 'human': [122], 'managers.': [123]}",2019,"['Extant taxon', 'Task (project management)', 'Computer science', 'Marketing', 'Marketing research', 'Knowledge management', 'Artificial intelligence', 'Data science', 'Business', 'Management', 'Economics', 'Evolutionary biology', 'Biology']","Abstract In the future, artificial intelligence (AI) is likely to substantially change both marketing strategies and customer behaviors. Building from not only extant research but also extensive interactions with practice, the authors propose a multidimensional framework for understanding the impact of AI involving intelligence levels, task types, and whether AI is embedded in a robot. Prior research typically addresses a subset of these dimensions; this paper integrates all three into a single framework. Next, the authors propose a research agenda that addresses not only how marketing strategies and customer behaviors will change in the future, but also highlights important policy questions relating to privacy, bias and ethics. Finally, the authors suggest AI will be more effective if it augments (rather than replaces) human managers."
https://openalex.org/W4382987554,ARTIFICIAL INTELLIGENCE FOR THE REAL WORLD,"{'Artificial': [0], 'intelligence': [1, 22, 68], '(A.I.)': [2], 'is': [3, 24, 28], 'a': [4, 25, 48], 'multidisciplinary': [5], 'field': [6], 'aimed': [7], 'at': [8], 'automating': [9], 'tasks': [10], 'that': [11, 27], 'currently': [12], 'need': [13], 'human': [14], 'intelligence.Despite': [15], 'its': [16], 'lack': [17], 'of': [18, 32], 'general': [19], 'familiarity,': [20], 'artificial': [21, 67], '(AI)': [23, 69], 'technology': [26], 'revolutionizing': [29], 'every': [30], 'aspect': [31], 'life.This': [33], 'article': [34], 'aims': [35], 'to': [36, 44, 53], 'educate': [37], 'laypeople': [38], 'about': [39], 'AI': [40], 'and': [41, 61, 74], 'encourage': [42], 'them': [43], 'utilize': [45], 'it': [46, 72, 76], 'as': [47], 'tool': [49], 'in': [50, 80, 84], 'many': [51], 'disciplines': [52], 'rethink': [54], 'how': [55, 71, 75], 'we': [56], 'combine': [57], 'data,': [58], 'analyze': [59], 'it,': [60], 'make': [62], 'choices.We': [63], 'quickly': [64], 'covered': [65], 'what': [66], 'is,': [70], 'works,': [73], 'may': [77], 'be': [78], 'applied': [79], 'our': [81], 'daily': [82], 'lives': [83], 'this': [85], 'article.': [86]}",2023,"['Computer science', 'Artificial intelligence']","Artificial intelligence (A.I.) is a multidisciplinary field aimed at automating tasks that currently need human intelligence.Despite its lack of general familiarity, artificial intelligence (AI) is a technology that is revolutionizing every aspect of life.This article aims to educate laypeople about AI and encourage them to utilize it as a tool in many disciplines to rethink how we combine data, analyze it, and make choices.We quickly covered what artificial intelligence (AI) is, how it works, and how it may be applied in our daily lives in this article."
https://openalex.org/W2927351257,Causability and explainability of artificial intelligence in medicine,"{'Explainable': [0, 53], 'artificial': [1], 'intelligence': [2], '(AI)': [3], 'is': [4, 15, 77, 150, 156, 163, 171, 179], 'attracting': [5], 'much': [6], 'interest': [7], 'in': [8, 32, 142, 160], 'medicine.': [9], 'Technically,': [10], 'the': [11, 37, 41, 57, 96, 104, 112, 151], 'problem': [12], 'of': [13, 36, 43, 59, 63, 89, 106, 114, 135, 139, 147, 153, 166, 174, 184], 'explainability': [14, 127, 159, 170], 'as': [16, 18, 130, 132], 'old': [17], 'AI': [19, 23, 54], 'itself': [20], 'and': [21, 61, 128, 138, 186, 191], 'classic': [22], 'represented': [24], 'comprehensible': [25], 'retraceable': [26], 'approaches.': [27], 'However,': [28], 'their': [29], 'weakness': [30], 'was': [31], 'dealing': [33], 'with': [34, 56], 'uncertainties': [35], 'real': [38], 'world.': [39], 'Through': [40], 'introduction': [42], 'probabilistic': [44], 'learning,': [45], 'applications': [46], 'became': [47], 'increasingly': [48, 51], 'successful,': [49], 'but': [50], 'opaque.': [52], 'deals': [55], 'implementation': [58], 'transparency': [60], 'traceability': [62], 'statistical': [64], 'black‐box': [65], 'machine': [66], 'learning': [67, 71], 'methods,': [68], 'particularly': [69], 'deep': [70], '(DL).': [72], 'We': [73], 'argue': [74], 'that': [75, 99, 161], 'there': [76], 'a': [78, 87, 133, 164, 167, 172, 175], 'need': [79, 93], 'to': [80, 124], 'go': [81], 'beyond': [82], 'explainable': [83, 90], 'AI.': [84], 'To': [85], 'reach': [86], 'level': [88], 'medicine': [91], 'we': [92, 119], 'causability.': [94], 'In': [95, 116], 'same': [97], 'way': [98], 'usability': [100], 'encompasses': [101, 109], 'measurements': [102, 110], 'for': [103, 111], 'quality': [105, 113], 'use,': [107], 'causability': [108, 129, 162], 'explanations.': [115], 'this': [117, 148], 'article,': [118], 'provide': [120], 'some': [121], 'necessary': [122], 'definitions': [123], 'discriminate': [125], 'between': [126], 'well': [131], 'use‐case': [134], 'DL': [136], 'interpretation': [137], 'human': [140], 'explanation': [141], 'histopathology.': [143], 'The': [144], 'main': [145], 'contribution': [146], 'article': [149, 178], 'notion': [152], 'causability,': [154], 'which': [155], 'differentiated': [157], 'from': [158], 'property': [165, 173], 'person,': [168], 'while': [169], 'system': [176], 'This': [177], 'categorized': [180], 'under:': [181], 'Fundamental': [182], 'Concepts': [183], 'Data': [185], 'Knowledge': [187], '&gt;': [188], 'Human': [189], 'Centricity': [190], 'User': [192], 'Interaction': [193]}",2019,"['Transparency (behavior)', 'Artificial intelligence', 'Computer science', 'Usability', 'Probabilistic logic', 'Property (philosophy)', 'Quality (philosophy)', 'Traceability', 'Data science', 'Machine learning', 'Human–computer interaction', 'Epistemology', 'Software engineering', 'Computer security', 'Philosophy']","Explainable artificial intelligence (AI) is attracting much interest in medicine. Technically, the problem of explainability is as old as AI itself and classic AI represented comprehensible retraceable approaches. However, their weakness was in dealing with uncertainties of the real world. Through the introduction of probabilistic learning, applications became increasingly successful, but increasingly opaque. Explainable AI deals with the implementation of transparency and traceability of statistical black‐box machine learning methods, particularly deep learning (DL). We argue that there is a need to go beyond explainable AI. To reach a level of explainable medicine we need causability. In the same way that usability encompasses measurements for the quality of use, causability encompasses measurements for the quality of explanations. In this article, we provide some necessary definitions to discriminate between explainability and causability as well as a use‐case of DL interpretation and of human explanation in histopathology. The main contribution of this article is the notion of causability, which is differentiated from explainability in that causability is a property of a person, while explainability is a property of a system This article is categorized under: Fundamental Concepts of Data and Knowledge &gt; Human Centricity and User Interaction"
https://openalex.org/W2950865323,Edge Intelligence: Paving the Last Mile of Artificial Intelligence With Edge Computing,"{'With': [0], 'the': [1, 6, 33, 52, 60, 74, 78, 86, 89, 109, 113, 159, 169, 184, 194, 202, 211, 226], 'breakthroughs': [2], 'in': [3, 149], 'deep': [4, 220], 'learning,': [5], 'recent': [7, 160, 185], 'years': [8], 'have': [9], 'witnessed': [10], 'a': [11, 121, 138, 154, 180], 'booming': [12], 'of': [13, 35, 40, 44, 57, 88, 141, 162, 183, 210], 'artificial': [14], 'intelligence': [15, 132], '(AI)': [16], 'applications': [17], 'and': [18, 38, 46, 106, 153, 172, 196, 215, 249], 'services,': [19], 'spanning': [20], 'from': [21, 108], 'personal': [22], 'assistant': [23], 'to': [24, 27, 51, 72, 77, 83, 112, 136], 'recommendation': [25], 'systems': [26], 'video/audio': [28], 'surveillance.': [29], 'More': [30], 'recently,': [31], 'with': [32], 'proliferation': [34], 'mobile': [36, 45], 'computing': [37, 104], 'Internet': [39], 'Things': [41], '(IoT),': [42], 'billions': [43], 'IoT': [47], 'devices': [48], 'are': [49], 'connected': [50], 'Internet,': [53], 'generating': [54], 'zillions': [55], 'bytes': [56], 'data': [58], 'at': [59, 201, 225], 'network': [61, 79, 110, 114, 203, 227], 'edge.': [62, 204, 228], 'Driving': [63], 'by': [64, 167], 'this': [65, 95, 176, 240], 'trend,': [66], 'there': [67], 'is': [68, 134, 147, 164], 'an': [69, 99, 208], 'urgent': [70], 'need': [71], 'push': [73], 'AI': [75, 129, 173, 199], 'frontiers': [76], 'edge': [80, 90, 97, 128, 131], 'so': [81], 'as': [82, 120], 'fully': [84], 'unleash': [85], 'potential': [87], 'big': [91], 'data.': [92], 'To': [93, 175], 'meet': [94], 'demand,': [96], 'computing,': [98], 'emerging': [100, 216], 'paradigm': [101], 'that': [102, 239], 'pushes': [103], 'tasks': [105], 'services': [107], 'core': [111], 'edge,': [115], 'has': [116], 'been': [117], 'widely': [118], 'recognized': [119], 'promising': [122], 'solution.': [123], 'The': [124], 'resulted': [125], 'new': [126], 'interdiscipline,': [127], 'or': [130], '(EI),': [133], 'beginning': [135], 'receive': [137], 'tremendous': [139], 'amount': [140], 'interest.': [142], 'However,': [143], 'research': [144, 186, 233, 252], 'on': [145, 188, 235, 254], 'EI': [146, 163], 'still': [148], 'its': [150], 'infancy': [151], 'stage,': [152], 'dedicated': [155], 'venue': [156], 'for': [157, 198, 219], 'exchanging': [158], 'advances': [161], 'highly': [165], 'desired': [166], 'both': [168], 'computer': [170], 'system': [171], 'communities.': [174], 'end,': [177], 'we': [178, 191, 230], 'conduct': [179], 'comprehensive': [181], 'survey': [182, 241], 'efforts': [187], 'EI.': [189, 236, 255], 'Specifically,': [190], 'first': [192], 'review': [193], 'background': [195], 'motivation': [197], 'running': [200], 'We': [205, 237], 'then': [206], 'provide': [207], 'overview': [209], 'overarching': [212], 'architectures,': [213], 'frameworks,': [214], 'key': [217], 'technologies': [218], 'learning': [221], 'model': [222], 'toward': [223], 'training/inference': [224], 'Finally,': [229], 'discuss': [231], 'future': [232], 'opportunities': [234], 'believe': [238], 'will': [242], 'elicit': [243], 'escalating': [244], 'attentions,': [245], 'stimulate': [246], 'fruitful': [247], 'discussions,': [248], 'inspire': [250], 'further': [251], 'ideas': [253]}",2019,"['Edge computing', 'Edge device', 'Computer science', 'Enhanced Data Rates for GSM Evolution', 'Data science', 'Deep learning', 'Applications of artificial intelligence', 'Big data', 'The Internet', 'Artificial intelligence', 'Mobile edge computing', 'Multimedia', 'Cloud computing', 'World Wide Web', 'Data mining', 'Operating system']","With the breakthroughs in deep learning, the recent years have witnessed a booming of artificial intelligence (AI) applications and services, spanning from personal assistant to recommendation systems to video/audio surveillance. More recently, with the proliferation of mobile computing and Internet of Things (IoT), billions of mobile and IoT devices are connected to the Internet, generating zillions bytes of data at the network edge. Driving by this trend, there is an urgent need to push the AI frontiers to the network edge so as to fully unleash the potential of the edge big data. To meet this demand, edge computing, an emerging paradigm that pushes computing tasks and services from the network core to the network edge, has been widely recognized as a promising solution. The resulted new interdiscipline, edge AI or edge intelligence (EI), is beginning to receive a tremendous amount of interest. However, research on EI is still in its infancy stage, and a dedicated venue for exchanging the recent advances of EI is highly desired by both the computer system and AI communities. To this end, we conduct a comprehensive survey of the recent research efforts on EI. Specifically, we first review the background and motivation for AI running at the network edge. We then provide an overview of the overarching architectures, frameworks, and emerging key technologies for deep learning model toward training/inference at the network edge. Finally, we discuss future research opportunities on EI. We believe that this survey will elicit escalating attentions, stimulate fruitful discussions, and inspire further research ideas on EI."
https://openalex.org/W2911605224,Artificial intelligence in cancer imaging: Clinical challenges and applications,"{'Abstract': [0], 'Judgement,': [1], 'as': [2, 199], 'one': [3], 'of': [4, 8, 14, 37, 50, 71, 78, 88, 111, 120, 125, 137, 142, 145, 160, 167, 197, 204], 'the': [5, 12, 41, 47, 65, 86, 108, 126, 143, 157, 164, 191, 194, 246], 'core': [6], 'tenets': [7], 'medicine,': [9], 'relies': [10, 82], 'upon': [11, 83], 'integration': [13], 'multilayered': [15], 'data': [16], 'with': [17, 35], 'nuanced': [18], 'decision': [19], 'making.': [20], 'Cancer': [21], 'offers': [22], 'a': [23, 184], 'unique': [24], 'context': [25], 'for': [26, 242], 'medical': [27, 202], 'decisions': [28, 171], 'given': [29], 'not': [30, 175, 238], 'only': [31], 'its': [32, 133], 'variegated': [33], 'forms': [34], 'evolution': [36], 'disease': [38, 79, 146], 'but': [39], 'also': [40], 'need': [42], 'to': [43, 54, 60, 103, 176, 183, 186, 201, 218, 235, 257, 261], 'take': [44], 'into': [45], 'account': [46], 'individual': [48], 'condition': [49], 'patients,': [51], 'their': [52, 58], 'ability': [53], 'receive': [55], 'treatment,': [56], 'and': [57, 69, 129, 140, 147, 162, 180, 206, 216, 244, 260], 'responses': [59], 'treatment.': [61], 'Challenges': [62], 'remain': [63], 'in': [64, 107, 156, 209, 233, 253, 265], 'accurate': [66], 'detection,': [67, 169], 'characterization,': [68], 'monitoring': [70], 'cancers': [72], 'despite': [73], 'improved': [74], 'technologies.': [75], 'Radiographic': [76], 'assessment': [77, 141], 'most': [80, 228], 'commonly': [81], 'visual': [84], 'evaluations,': [85], 'interpretations': [87], 'which': [89], 'may': [90, 153], 'be': [91, 187], 'augmented': [92], 'by': [93, 114], 'advanced': [94], 'computational': [95], 'analyses.': [96], 'In': [97], 'particular,': [98], 'artificial': [99], 'intelligence': [100], '(AI)': [101], 'promises': [102], 'make': [104], 'great': [105], 'strides': [106], 'qualitative': [109], 'interpretation': [110, 159], 'cancer': [112, 205, 266], 'imaging': [113, 203], 'expert': [115], 'clinicians,': [116], 'including': [117], 'volumetric': [118], 'delineation': [119], 'tumors': [121], 'over': [122], 'time,': [123], 'extrapolation': [124], 'tumor': [127, 211], 'genotype': [128], 'biological': [130], 'course': [131], 'from': [132], 'radiographic': [134, 168], 'phenotype,': [135], 'prediction': [136], 'clinical': [138, 165, 222, 258], 'outcome,': [139], 'impact': [144, 262], 'treatment': [148], 'on': [149, 172], 'adjacent': [150], 'organs.': [151], 'AI': [152, 198, 231, 255], 'automate': [154], 'processes': [155], 'initial': [158], 'images': [161], 'shift': [163], 'workflow': [166], 'management': [170], 'whether': [173], 'or': [174], 'administer': [177], 'an': [178], 'intervention,': [179], 'subsequent': [181], 'observation': [182], 'yet': [185], 'envisioned': [188], 'paradigm.': [189], 'Here,': [190], 'authors': [192], 'review': [193], 'current': [195], 'state': [196], 'applied': [200], 'describe': [207], 'advances': [208], '4': [210], 'types': [212], '(lung,': [213], 'brain,': [214], 'breast,': [215], 'prostate)': [217], 'illustrate': [219], 'how': [220], 'common': [221], 'problems': [223], 'are': [224], 'being': [225], 'addressed.': [226], 'Although': [227], 'studies': [229], 'evaluating': [230], 'applications': [232], 'oncology': [234], 'date': [236], 'have': [237], 'been': [239], 'vigorously': [240], 'validated': [241], 'reproducibility': [243], 'generalizability,': [245], 'results': [247], 'do': [248], 'highlight': [249], 'increasingly': [250], 'concerted': [251], 'efforts': [252], 'pushing': [254], 'technology': [256], 'use': [259], 'future': [263], 'directions': [264], 'care.': [267]}",2019,"['Medicine', 'Context (archaeology)', 'Workflow', 'Generalizability theory', 'Medical physics', 'Precision medicine', 'Disease', 'Medical imaging', 'Artificial intelligence', 'Pathology', 'Radiology', 'Computer science', 'Psychology', 'Database', 'Developmental psychology', 'Biology', 'Paleontology']","Abstract Judgement, as one of the core tenets of medicine, relies upon the integration of multilayered data with nuanced decision making. Cancer offers a unique context for medical decisions given not only its variegated forms with evolution of disease but also the need to take into account the individual condition of patients, their ability to receive treatment, and their responses to treatment. Challenges remain in the accurate detection, characterization, and monitoring of cancers despite improved technologies. Radiographic assessment of disease most commonly relies upon visual evaluations, the interpretations of which may be augmented by advanced computational analyses. In particular, artificial intelligence (AI) promises to make great strides in the qualitative interpretation of cancer imaging by expert clinicians, including volumetric delineation of tumors over time, extrapolation of the tumor genotype and biological course from its radiographic phenotype, prediction of clinical outcome, and assessment of the impact of disease and treatment on adjacent organs. AI may automate processes in the initial interpretation of images and shift the clinical workflow of radiographic detection, management decisions on whether or not to administer an intervention, and subsequent observation to a yet to be envisioned paradigm. Here, the authors review the current state of AI as applied to medical imaging of cancer and describe advances in 4 tumor types (lung, brain, breast, and prostate) to illustrate how common clinical problems are being addressed. Although most studies evaluating AI applications in oncology to date have not been vigorously validated for reproducibility and generalizability, the results do highlight increasingly concerted efforts in pushing AI technology to clinical use and to impact future directions in cancer care."
https://openalex.org/W2807593075,Artificial Intelligence in Cardiology,"{'Artificial': [0], 'intelligence': [1, 37, 59], 'and': [2, 16, 38, 51, 79, 95, 101, 112, 126, 130, 143], 'machine': [3, 39], 'learning': [4, 94, 111], 'are': [5], 'poised': [6], 'to': [7, 22, 49, 73, 139], 'influence': [8], 'nearly': [9], 'every': [10], 'aspect': [11], 'of': [12, 35, 44, 109], 'the': [13, 61, 65, 107], 'human': [14], 'condition,': [15], 'cardiology': [17, 48, 74, 100, 142], 'is': [18], 'not': [19], 'an': [20], 'exception': [21], 'this': [23], 'trend.': [24], 'This': [25], 'paper': [26, 66], 'provides': [27, 119], 'a': [28], 'guide': [29], 'for': [30], 'clinicians': [31], 'on': [32], 'relevant': [33, 72], 'aspects': [34], 'artificial': [36, 58], 'learning,': [40, 118], 'reviews': [41, 68, 96], 'selected': [42, 97], 'applications': [43, 98], 'these': [45, 134], 'methods': [46, 114, 135], 'in': [47, 60, 92, 99, 123, 127], 'date,': [50], 'identifies': [52], 'how': [53, 133], 'cardiovascular': [54, 128], 'medicine': [55, 125], 'could': [56, 136], 'incorporate': [57], 'future.': [62], 'In': [63], 'particular,': [64], 'first': [67], 'predictive': [69], 'modeling': [70], 'concepts': [71], 'such': [75, 82], 'as': [76, 83], 'feature': [77], 'selection': [78], 'frequent': [80], 'pitfalls': [81], 'improper': [84], 'dichotomization.': [85], 'Second,': [86], 'it': [87, 105], 'discusses': [88], 'common': [89], 'algorithms': [90], 'used': [91], 'supervised': [93], 'related': [102, 113], 'disciplines.': [103], 'Third,': [104], 'describes': [106], 'advent': [108], 'deep': [110], 'collectively': [115], 'called': [116], 'unsupervised': [117], 'contextual': [120], 'examples': [121], 'both': [122], 'general': [124], 'medicine,': [129], 'then': [131], 'explains': [132], 'be': [137], 'applied': [138], 'enable': [140], 'precision': [141], 'improve': [144], 'patient': [145], 'outcomes.': [146]}",2018,"['Artificial intelligence', 'Medicine', 'Machine learning', 'Internal medicine', 'Cardiology', 'Deep learning', 'Feature selection', 'Precision medicine', 'Clinical cardiology', 'Computer science', 'Pathology']","Artificial intelligence and machine learning are poised to influence nearly every aspect of the human condition, and cardiology is not an exception to this trend. This paper provides a guide for clinicians on relevant aspects of artificial intelligence and machine learning, reviews selected applications of these methods in cardiology to date, and identifies how cardiovascular medicine could incorporate artificial intelligence in the future. In particular, the paper first reviews predictive modeling concepts relevant to cardiology such as feature selection and frequent pitfalls such as improper dichotomization. Second, it discusses common algorithms used in supervised learning and reviews selected applications in cardiology and related disciplines. Third, it describes the advent of deep learning and related methods collectively called unsupervised learning, provides contextual examples both in general medicine and in cardiovascular medicine, and then explains how these methods could be applied to enable precision cardiology and improve patient outcomes."
https://openalex.org/W2958089299,A Survey on Explainable Artificial Intelligence (XAI): Toward Medical XAI,"{'Recently,': [0], 'artificial': [1], 'intelligence': [2], 'and': [3, 41, 51, 63, 98, 117, 158, 180, 189], 'machine': [4, 61, 100], 'learning': [5, 28], 'in': [6, 12, 126, 149], 'general': [7], 'have': [8, 35], 'demonstrated': [9], 'remarkable': [10], 'performances': [11], 'many': [13, 38, 99], 'tasks,': [14], 'from': [15, 129], 'image': [16], 'processing': [17], 'to': [18, 68, 81, 136, 147, 183], 'natural': [19], 'language': [20], 'processing,': [21], 'especially': [22], 'with': [23, 31, 165, 174], 'the': [24, 56, 83, 86, 89, 93, 137, 144], 'advent': [25], 'of': [26, 44, 49, 92, 139], 'deep': [27], '(DL).': [29], 'Along': [30], 'research': [32, 115], 'progress,': [33], 'they': [34], 'encroached': [36], 'upon': [37], 'different': [39, 114, 121, 124], 'fields': [40], 'disciplines.': [42], 'Some': [43], 'them': [45], 'require': [46], 'high': [47], 'level': [48], 'accountability': [50], 'thus': [52, 66], 'transparency,': [53], 'for': [54, 60, 177], 'example,': [55], 'medical': [57, 150, 178, 192], 'sector.': [58], 'Explanations': [59], 'decisions': [62, 101], 'predictions': [64], 'are': [65, 102, 194], 'needed': [67], 'justify': [69], 'their': [70], 'reliability.': [71], 'This': [72], 'requires': [73], 'greater': [74], 'interpretability,': [75], 'which': [76], 'often': [77], 'means': [78], 'we': [79], 'need': [80], 'understand': [82], 'mechanism': [84], 'underlying': [85], 'algorithms.': [87], 'Unfortunately,': [88], 'blackbox': [90], 'nature': [91], 'DL': [94], 'is': [95, 153], 'still': [96, 103], 'unresolved,': [97], 'poorly': [104], 'understood.': [105], 'We': [106], 'provide': [107, 132], 'a': [108], 'review': [109], 'on': [110], 'interpretabilities': [111], 'suggested': [112], 'by': [113], 'works': [116], 'categorize': [118], 'them.': [119], 'The': [120], 'categories': [122], 'show': [123], 'dimensions': [125], 'interpretability': [127, 148, 170], 'research,': [128, 151], 'approaches': [130], 'that': [131], '""obviously""': [133], 'interpretable': [134], 'information': [135], 'studies': [138], 'complex': [140], 'patterns.': [141], 'By': [142], 'applying': [143], 'same': [145], 'categorization': [146], 'it': [152], 'hoped': [154], 'that:': [155], '1)': [156], 'clinicians': [157], 'practitioners': [159], 'can': [160], 'subsequently': [161], 'approach': [162], 'these': [163], 'methods': [164], 'caution;': [166], '2)': [167], 'insight': [168], 'into': [169], 'will': [171], 'be': [172], 'born': [173], 'more': [175], 'considerations': [176], 'practices;': [179], '3)': [181], 'initiatives': [182], 'push': [184], 'forward': [185], 'data-based,': [186], 'mathematically': [187], 'grounded,': [188], 'technically': [190], 'grounded': [191], 'education': [193], 'encouraged.': [195]}",2020,"['Croatian', 'Linguistics', 'Philosophy']","Recently, artificial intelligence and machine learning in general have demonstrated remarkable performances in many tasks, from image processing to natural language processing, especially with the advent of deep learning (DL). Along with research progress, they have encroached upon many different fields and disciplines. Some of them require high level of accountability and thus transparency, for example, the medical sector. Explanations for machine decisions and predictions are thus needed to justify their reliability. This requires greater interpretability, which often means we need to understand the mechanism underlying the algorithms. Unfortunately, the blackbox nature of the DL is still unresolved, and many machine decisions are still poorly understood. We provide a review on interpretabilities suggested by different research works and categorize them. The different categories show different dimensions in interpretability research, from approaches that provide ""obviously"" interpretable information to the studies of complex patterns. By applying the same categorization to interpretability in medical research, it is hoped that: 1) clinicians and practitioners can subsequently approach these methods with caution; 2) insight into interpretability will be born with more considerations for medical practices; and 3) initiatives to push forward data-based, mathematically grounded, and technically grounded medical education are encouraged."
https://openalex.org/W2898192966,Artificial Intelligence and Deep Learning in Ophthalmology,"{'Artificial': [0], 'intelligence': [1], '(AI)': [2], 'based': [3], 'on': [4, 36], 'deep': [5], 'learning': [6], '(DL)': [7], 'has': [8, 17, 41], 'sparked': [9], 'tremendous': [10], 'global': [11], 'interest': [12], 'in': [13, 21, 57, 77, 83, 101, 116, 148, 167], 'recent': [14], 'years.': [15], 'DL': [16, 40, 76, 114, 140, 159], 'been': [18, 42], 'widely': [19], 'adopted': [20], 'image': [22], 'recognition,': [23], 'speech': [24], 'recognition': [25], 'and': [26, 50, 63, 72, 94, 104, 120, 130, 132, 170], 'natural': [27], 'language': [28], 'processing,': [29], 'but': [30], 'is': [31, 146], 'only': [32], 'beginning': [33], 'to': [34, 44, 91], 'impact': [35], 'healthcare.': [37], 'In': [38], 'ophthalmology,': [39, 117], 'applied': [43], 'fundus': [45], 'photographs,': [46], 'optical': [47], 'coherence': [48], 'tomography': [49], 'visual': [51], 'fields,': [52], 'achieving': [53], 'robust': [54], 'classification': [55], 'performance': [56], 'the': [58, 67, 125, 136, 149, 157, 171], 'detection': [59], 'of': [60, 65, 124, 135, 156], 'diabetic': [61], 'retinopathy': [62, 64], 'prematurity,': [66], 'glaucoma-like': [68], 'disc,': [69], 'macular': [70, 74], 'oedema': [71], 'age-related': [73], 'degeneration.': [75], 'ocular': [78], 'imaging': [79], 'may': [80], 'be': [81], 'used': [82], 'conjunction': [84], 'with': [85, 113], 'telemedicine': [86], 'as': [87], 'a': [88, 154], 'possible': [89], 'solution': [90], 'screen,': [92], 'diagnose': [93], 'monitor': [95], 'major': [96], 'eye': [97], 'diseases': [98], 'for': [99, 162], 'patients': [100], 'primary': [102], 'care': [103], 'community': [105], 'settings.': [106], 'Nonetheless,': [107], 'there': [108], 'are': [109], 'also': [110], 'potential': [111, 165], 'challenges': [112, 166], 'application': [115], 'including': [118], 'clinical': [119, 168], 'technical': [121], 'challenges,': [122], 'explainability': [123], 'algorithm': [126], 'results,': [127], 'medicolegal': [128], 'issues,': [129], 'physician': [131], 'patient': [133], 'acceptance': [134], 'AI': [137], '‘black-box’': [138], 'algorithms.': [139], 'could': [141], 'potentially': [142], 'revolutionise': [143], 'how': [144], 'ophthalmology': [145], 'practised': [147], 'future.': [150], 'This': [151], 'review': [152], 'provides': [153], 'summary': [155], 'state-of-the-art': [158], 'systems': [160], 'described': [161], 'ophthalmic': [163], 'applications,': [164], 'deployment': [169], 'path': [172], 'forward.': [173]}",2022,"['Medicine', 'Diabetic retinopathy', 'Optometry', 'Reimbursement', 'Glaucoma', 'Artificial intelligence', 'Macular degeneration', 'Ophthalmology', 'Health care', 'Computer science', 'Diabetes mellitus', 'Political science', 'Law', 'Endocrinology']","Artificial intelligence (AI) based on deep learning (DL) has sparked tremendous global interest in recent years. DL has been widely adopted in image recognition, speech recognition and natural language processing, but is only beginning to impact on healthcare. In ophthalmology, DL has been applied to fundus photographs, optical coherence tomography and visual fields, achieving robust classification performance in the detection of diabetic retinopathy and retinopathy of prematurity, the glaucoma-like disc, macular oedema and age-related macular degeneration. DL in ocular imaging may be used in conjunction with telemedicine as a possible solution to screen, diagnose and monitor major eye diseases for patients in primary care and community settings. Nonetheless, there are also potential challenges with DL application in ophthalmology, including clinical and technical challenges, explainability of the algorithm results, medicolegal issues, and physician and patient acceptance of the AI ‘black-box’ algorithms. DL could potentially revolutionise how ophthalmology is practised in the future. This review provides a summary of the state-of-the-art DL systems described for ophthalmic applications, potential challenges in clinical deployment and the path forward."
https://openalex.org/W3210165781,Artificial intelligence: A powerful paradigm for scientific research,"{'\\n': [0], 'Contains': [1], 'fulltext': [2], ':\\n': [3], '246467.pdf': [4], '(Publisher’s': [5], 'version': [6], ')': [7], '(Open': [8], 'Access)\\n': [9]}",2021,"['Cognitive science', 'Computer science', 'Data science', 'Psychology', 'Artificial intelligence', 'Engineering ethics', 'Management science', 'Engineering']",\n Contains fulltext :\n 246467.pdf (Publisher’s version ) (Open Access)\n
https://openalex.org/W3094793347,A strategic framework for artificial intelligence in marketing,"{'Abstract': [0], 'The': [1], 'authors': [2], 'develop': [3], 'a': [4], 'three-stage': [5], 'framework': [6, 45, 142], 'for': [7, 19, 28, 38, 55, 76, 81, 87, 101, 107, 114, 128, 132, 137], 'strategic': [8, 155], 'marketing': [9, 22, 56, 68, 92, 120, 150], 'planning,': [10], 'incorporating': [11], 'multiple': [12], 'artificial': [13], 'intelligence': [14], '(AI)': [15], 'benefits:': [16], 'mechanical': [17, 71, 96, 123], 'AI': [18, 27, 37, 51, 72, 80, 86, 97, 106, 113, 124, 131, 136], 'automating': [20], 'repetitive': [21], 'functions': [23], 'and': [24, 35, 41, 61, 64, 84, 111, 134], 'activities,': [25], 'thinking': [26, 79, 105, 130], 'processing': [29], 'data': [30, 77], 'to': [31, 143, 152], 'arrive': [32], 'at': [33], 'decisions,': [34], 'feeling': [36, 85, 112, 135], 'analyzing': [39], 'interactions': [40], 'human': [42], 'emotions.': [43], 'This': [44], 'lays': [46], 'out': [47], 'the': [48, 67, 91, 119, 154], 'ways': [49], 'that': [50], 'can': [52, 73, 98, 125], 'be': [53, 74, 99, 126], 'used': [54, 75, 100, 127], 'research,': [57], 'strategy': [58, 93], '(segmentation,': [59], 'targeting,': [60], 'positioning,': [62], 'STP),': [63], 'actions.': [65], 'At': [66, 90, 118], 'research': [69], 'stage,': [70, 95, 122], 'collection,': [78], 'market': [82], 'analysis,': [83], 'customer': [88], 'understanding.': [89], '(STP)': [94], 'segmentation': [102], '(segment': [103, 109, 116], 'recognition),': [104], 'targeting': [108], 'recommendation),': [110], 'positioning': [115], 'resonance).': [117], 'action': [121], 'standardization,': [129], 'personalization,': [133], 'relationalization.': [138], 'We': [139], 'apply': [140], 'this': [141], 'various': [144], 'areas': [145], 'of': [146, 157], 'marketing,': [147], 'organized': [148], 'by': [149], '4Ps/4Cs,': [151], 'illustrate': [153], 'use': [156], 'AI.': [158]}",2020,"['Personalization', 'Feeling', 'Market segmentation', 'Marketing research', 'Marketing and artificial intelligence', 'Marketing', 'Computer science', 'Marketing strategy', 'Artificial intelligence', 'Personalized marketing', 'Marketing management', 'Standardization', 'Knowledge management', 'Business', 'Return on marketing investment', 'Psychology', 'Business-to-government', 'Social psychology', 'Intelligent decision support system', 'Operating system']","Abstract The authors develop a three-stage framework for strategic marketing planning, incorporating multiple artificial intelligence (AI) benefits: mechanical AI for automating repetitive marketing functions and activities, thinking AI for processing data to arrive at decisions, and feeling AI for analyzing interactions and human emotions. This framework lays out the ways that AI can be used for marketing research, strategy (segmentation, targeting, and positioning, STP), and actions. At the marketing research stage, mechanical AI can be used for data collection, thinking AI for market analysis, and feeling AI for customer understanding. At the marketing strategy (STP) stage, mechanical AI can be used for segmentation (segment recognition), thinking AI for targeting (segment recommendation), and feeling AI for positioning (segment resonance). At the marketing action stage, mechanical AI can be used for standardization, thinking AI for personalization, and feeling AI for relationalization. We apply this framework to various areas of marketing, organized by marketing 4Ps/4Cs, to illustrate the strategic use of AI."
https://openalex.org/W1997866278,Artificial intelligence in medicine,"{'Artificial': [0], 'intelligence': [1], 'techniques': [2, 29], 'have': [3], 'the': [4, 33], 'potential': [5], 'to': [6], 'be': [7], 'applied': [8], 'in': [9, 32], 'almost': [10], 'every': [11], 'field': [12], 'of': [13], 'medicine.': [14], 'There': [15], 'is': [16], 'need': [17], 'for': [18], 'further': [19], 'clinical': [20, 35], 'trials': [21], 'which': [22], 'are': [23], 'appropriately': [24], 'designed': [25], 'before': [26], 'these': [27], 'emergent': [28], 'find': [30], 'application': [31], 'real': [34], 'setting.': [36]}",2004,"['Computer science', 'Artificial intelligence', 'Field (mathematics)', 'Artificial neural network', 'Machine learning', 'Intelligent decision support system', 'Expert system', 'Set (abstract data type)', 'Exploit', 'Key (lock)', 'Pure mathematics', 'Programming language', 'Mathematics', 'Computer security']",Artificial intelligence techniques have the potential to be applied in almost every field of medicine. There is need for further clinical trials which are appropriately designed before these emergent techniques find application in the real clinical setting.
https://openalex.org/W2966555834,Overview of artificial intelligence in medicine,"{'AI': [0], 'promises': [1], 'to': [2, 25, 35, 47], 'change': [3], 'the': [4, 48], 'practice': [5], 'of': [6, 14], 'medicine': [7], 'in': [8, 20], 'hitherto': [9], 'unknown': [10], 'ways,': [11], 'but': [12], 'many': [13], 'its': [15], 'practical': [16], 'applications': [17], 'are': [18], 'still': [19], 'their': [21], 'infancy': [22], 'and': [23, 28, 37], 'need': [24, 34], 'be': [26], 'explored': [27], 'developed': [29], 'better.': [30], 'Medical': [31], 'professionals': [32], 'also': [33], 'understand': [36], 'acclimatize': [38], 'themselves': [39], 'with': [40], 'these': [41], 'advances': [42], 'for': [43], 'better': [44], 'healthcare': [45], 'delivery': [46], 'masses.': [49]}",2019,"['Applications of artificial intelligence', 'Artificial intelligence', 'Medicine', 'Field (mathematics)', 'Key (lock)', 'Term (time)', 'Engineering ethics', 'Computer science', 'Data science', 'Pure mathematics', 'Computer security', 'Quantum mechanics', 'Physics', 'Engineering', 'Mathematics']","AI promises to change the practice of medicine in hitherto unknown ways, but many of its practical applications are still in their infancy and need to be explored and developed better. Medical professionals also need to understand and acclimatize themselves with these advances for better healthcare delivery to the masses."
https://openalex.org/W4247155454,Artificial Intelligence and Management: The Automation–Augmentation Paradox,"{'Taking': [0, 46], 'three': [1, 51], 'recent': [2], 'business': [3, 136], 'books': [4, 52], 'on': [5, 140, 154], 'artificial': [6], 'intelligence': [7], '(AI)': [8], 'as': [9], 'a': [10, 31, 44, 47, 65, 96, 117, 165], 'starting': [11], 'point,': [12], 'we': [13, 71, 143], 'explore': [14], 'the': [15, 21, 50, 75, 129, 155], 'automation': [16, 25, 103, 122], 'and': [17, 93, 110, 123, 131, 137, 183], 'augmentation': [18, 34, 78, 101], 'concepts': [19], 'in': [20, 74, 152, 159, 170, 177], 'management': [22, 76, 146], 'domain.': [23], 'Whereas': [24], 'implies': [26], 'that': [27, 36, 134, 145, 164], 'machines': [28, 41], 'take': [29], 'over': [30], 'human': [32], 'task,': [33], 'means': [35], 'humans': [37], 'collaborate': [38], 'closely': [39], 'with': [40, 107, 128, 187], 'to': [42, 55, 61, 149, 179, 184], 'perform': [43], 'task.': [45], 'normative': [48], 'stance,': [49], 'advise': [53], 'organizations': [54, 115], 'prioritize': [56], 'augmentation,': [57, 124], 'which': [58], 'they': [59, 125], 'relate': [60], 'superior': [62], 'performance.': [63], 'Using': [64], 'more': [66], 'comprehensive': [67], 'paradox': [68], 'theory': [69, 182], 'perspective,': [70], 'argue': [72, 163], 'that,': [73], 'domain,': [77], 'cannot': [79], 'be': [80, 150], 'neatly': [81], 'separated': [82], 'from': [83], 'automation.': [84], 'These': [85], 'dual': [86], 'AI': [87, 158, 172], 'applications': [88], 'are': [89], 'interdependent': [90], 'across': [91], 'time': [92], 'space,': [94], 'creating': [95], 'paradoxical': [97], 'tension.': [98], 'Overemphasizing': [99], 'either': [100], 'or': [102], 'fuels': [104], 'reinforcing': [105], 'cycles': [106], 'negative': [108], 'organizational': [109], 'societal': [111], 'outcomes.': [112], 'However,': [113], 'if': [114], 'adopt': [116], 'broader': [118], 'perspective': [119], 'comprising': [120], 'both': [121], 'could': [126], 'deal': [127], 'tension': [130], 'achieve': [132], 'complementarities': [133], 'benefit': [135], 'society.': [138], 'Drawing': [139], 'our': [141], 'insights,': [142], 'conclude': [144], 'scholars': [147], 'need': [148], 'involved': [151], 'research': [153, 173], 'use': [156], 'of': [157], 'organizations.': [160], 'We': [161], 'also': [162], 'substantial': [166], 'change': [167], 'is': [168, 174], 'required': [169], 'how': [171], 'currently': [175], 'conducted': [176], 'order': [178], 'develop': [180], 'meaningful': [181], 'provide': [185], 'practice': [186], 'sound': [188], 'advice.': [189]}",2021,"['Automation', 'Task (project management)', 'Interdependence', 'Normative', 'Knowledge management', 'Perspective (graphical)', 'Computer science', 'Order (exchange)', 'Domain (mathematical analysis)', 'Sociology', 'Management science', 'Management', 'Epistemology', 'Artificial intelligence', 'Business', 'Economics', 'Engineering', 'Social science', 'Mathematics', 'Philosophy', 'Mechanical engineering', 'Finance', 'Mathematical analysis']","Taking three recent business books on artificial intelligence (AI) as a starting point, we explore the automation and augmentation concepts in the management domain. Whereas automation implies that machines take over a human task, augmentation means that humans collaborate closely with machines to perform a task. Taking a normative stance, the three books advise organizations to prioritize augmentation, which they relate to superior performance. Using a more comprehensive paradox theory perspective, we argue that, in the management domain, augmentation cannot be neatly separated from automation. These dual AI applications are interdependent across time and space, creating a paradoxical tension. Overemphasizing either augmentation or automation fuels reinforcing cycles with negative organizational and societal outcomes. However, if organizations adopt a broader perspective comprising both automation and augmentation, they could deal with the tension and achieve complementarities that benefit business and society. Drawing on our insights, we conclude that management scholars need to be involved in research on the use of AI in organizations. We also argue that a substantial change is required in how AI research is currently conducted in order to develop meaningful theory and to provide practice with sound advice."
https://openalex.org/W4365143687,Foundation models for generalist medical artificial intelligence,"{'The': [0], 'exceptionally': [1], 'rapid': [2], 'development': [3], 'of': [4, 43, 49, 72, 116, 160], 'highly': [5], 'flexible,': [6], 'reusable': [7], 'artificial': [8], 'intelligence': [9], '(AI)': [10], 'models': [11, 39], 'is': [12], 'likely': [13], 'to': [14, 32, 132], 'usher': [15], 'in': [16, 19, 91], 'newfound': [17], 'capabilities': [18, 127], 'medicine.': [20], 'We': [21, 135], 'propose': [22], 'a': [23, 46, 114], 'new': [24], 'paradigm': [25], 'for': [26, 120, 144, 150], 'medical': [27, 35, 73, 87, 108, 162], 'AI,': [28], 'which': [29], 'we': [30, 112], 'refer': [31], 'as': [33, 97], 'generalist': [34], 'AI': [36, 148], '(GMAI).': [37], 'GMAI': [38, 66, 121], 'will': [40, 67, 90, 140, 153], 'be': [41], 'capable': [42], 'carrying': [44], 'out': [45, 124], 'diverse': [47, 64], 'set': [48, 115], 'tasks': [50], 'using': [51], 'very': [52], 'little': [53], 'or': [54, 86, 102], 'no': [55], 'task-specific': [56], 'labelled': [57], 'data.': [58], 'Built': [59], 'through': [60], 'self-supervision': [61], 'on': [62], 'large,': [63], 'datasets,': [65], 'flexibly': [68], 'interpret': [69], 'different': [70], 'combinations': [71], 'modalities,': [74], 'including': [75], 'data': [76], 'from': [77], 'imaging,': [78], 'electronic': [79], 'health': [80], 'records,': [81], 'laboratory': [82], 'results,': [83], 'genomics,': [84], 'graphs': [85], 'text.': [88], 'Models': [89], 'turn': [92], 'produce': [93], 'expressive': [94], 'outputs': [95], 'such': [96], 'free-text': [98], 'explanations,': [99], 'spoken': [100], 'recommendations': [101], 'image': [103], 'annotations': [104], 'that': [105, 137], 'demonstrate': [106], 'advanced': [107], 'reasoning': [109], 'abilities.': [110], 'Here': [111], 'identify': [113], 'high-impact': [117], 'potential': [118], 'applications': [119, 139], 'and': [122, 128, 146, 152], 'lay': [123], 'specific': [125], 'technical': [126], 'training': [129], 'datasets': [130], 'necessary': [131], 'enable': [133], 'them.': [134], 'expect': [136], 'GMAI-enabled': [138], 'challenge': [141], 'current': [142], 'strategies': [143], 'regulating': [145], 'validating': [147], 'devices': [149], 'medicine': [151], 'shift': [154], 'practices': [155], 'associated': [156], 'with': [157], 'the': [158], 'collection': [159], 'large': [161], 'datasets.': [163]}",2023,"['Computer science', 'Set (abstract data type)', 'Artificial intelligence', 'Modalities', 'Task (project management)', 'Data science', 'Machine learning', 'Economics', 'Management', 'Social science', 'Programming language', 'Sociology']","The exceptionally rapid development of highly flexible, reusable artificial intelligence (AI) models is likely to usher in newfound capabilities in medicine. We propose a new paradigm for medical AI, which we refer to as generalist medical AI (GMAI). GMAI models will be capable of carrying out a diverse set of tasks using very little or no task-specific labelled data. Built through self-supervision on large, diverse datasets, GMAI will flexibly interpret different combinations of medical modalities, including data from imaging, electronic health records, laboratory results, genomics, graphs or medical text. Models will in turn produce expressive outputs such as free-text explanations, spoken recommendations or image annotations that demonstrate advanced medical reasoning abilities. Here we identify a set of high-impact potential applications for GMAI and lay out specific technical capabilities and training datasets necessary to enable them. We expect that GMAI-enabled applications will challenge current strategies for regulating and validating AI devices for medicine and will shift practices associated with the collection of large medical datasets."
https://openalex.org/W3186209406,Artificial intelligence in healthcare: transforming the practice of medicine,"{'Artificial': [0], 'intelligence': [1], '(AI)': [2], 'is': [3], 'a': [4, 43], 'powerful': [5], 'and': [6, 22, 49, 53], 'disruptive': [7], 'area': [8], 'of': [9, 20, 25, 38, 59], 'computer': [10], 'science,': [11], 'with': [12], 'the': [13, 18, 23, 36, 55], 'potential': [14], 'to': [15, 45], 'fundamentally': [16], 'transform': [17], 'practice': [19], 'medicine': [21], 'delivery': [24], 'healthcare.': [26], 'In': [27], 'this': [28], 'review': [29], 'article,': [30], 'we': [31], 'outline': [32], 'recent': [33], 'breakthroughs': [34], 'in': [35, 40], 'application': [37], 'AI': [39, 51, 60], 'healthcare,': [41], 'describe': [42], 'roadmap': [44], 'building': [46], 'effective,': [47], 'reliable': [48], 'safe': [50], 'systems,': [52], 'discuss': [54], 'possible': [56], 'future': [57], 'direction': [58], 'augmented': [61], 'healthcare': [62], 'systems.': [63]}",2021,"['Health care', 'Medicine', 'Political science', 'Law']","Artificial intelligence (AI) is a powerful and disruptive area of computer science, with the potential to fundamentally transform the practice of medicine and the delivery of healthcare. In this review article, we outline recent breakthroughs in the application of AI in healthcare, describe a roadmap to building effective, reliable and safe AI systems, and discuss the possible future direction of AI augmented healthcare systems."
https://openalex.org/W2770717476,Exploring the impact of artificial intelligence on teaching and learning in higher education,"{'This': [0], 'paper': [1], 'explores': [2], 'the': [3, 6, 9, 29, 43, 59, 74, 92], 'phenomena': [4], 'of': [5, 8, 11, 25, 46, 62, 73, 76, 85, 94], 'emergence': [7], 'use': [10], 'artificial': [12, 69], 'intelligence': [13, 70], 'in': [14, 18, 50, 55, 65, 91], 'teaching': [15], 'and': [16, 33, 37, 42, 88, 102, 104], 'learning': [17, 90], 'higher': [19, 51, 63, 86], 'education.': [20], 'It': [21], 'investigates': [22], 'educational': [23], 'implications': [24], 'emerging': [26], 'technologies': [27, 49, 96], 'on': [28], 'way': [30], 'students': [31], 'learn': [32], 'how': [34], 'institutions': [35, 84], 'teach': [36], 'evolve.': [38], 'Recent': [39], 'technological': [40], 'advancements': [41], 'increasing': [44], 'speed': [45], 'adopting': [47], 'new': [48], 'education': [52, 64, 87], 'are': [53], 'explored': [54], 'order': [56], 'to': [57], 'predict': [58], 'future': [60], 'nature': [61], 'a': [66], 'world': [67], 'where': [68], 'is': [71], 'part': [72], 'fabric': [75], 'our': [77], 'universities.': [78], 'We': [79], 'pinpoint': [80], 'some': [81], 'challenges': [82], 'for': [83, 97, 108], 'student': [89, 100], 'adoption': [93], 'these': [95], 'teaching,': [98], 'learning,': [99], 'support,': [101], 'administration': [103], 'explore': [105], 'further': [106], 'directions': [107], 'research.': [109]}",2017,"['Higher education', 'Educational technology', 'Order (exchange)', 'Emerging technologies', 'Mathematics education', 'Computer science', 'Knowledge management', 'Engineering ethics', 'Psychology', 'Artificial intelligence', 'Engineering', 'Political science', 'Business', 'Finance', 'Law']","This paper explores the phenomena of the emergence of the use of artificial intelligence in teaching and learning in higher education. It investigates educational implications of emerging technologies on the way students learn and how institutions teach and evolve. Recent technological advancements and the increasing speed of adopting new technologies in higher education are explored in order to predict the future nature of higher education in a world where artificial intelligence is part of the fabric of our universities. We pinpoint some challenges for institutions of higher education and student learning in the adoption of these technologies for teaching, learning, student support, and administration and explore further directions for research."
https://openalex.org/W2954503794,DARPA's Explainable Artificial Intelligence Program,"{'Dramatic': [0], 'success': [1], 'in': [2, 155], 'machine': [3], 'learning': [4, 66], 'has': [5], 'led': [6], 'to': [7, 32, 42, 125, 141], 'a': [8, 131, 159], 'new': [9], 'wave': [10], 'of': [11, 123, 151, 161], 'AI': [12, 44], 'applications': [13], '(for': [14], 'example,': [15], 'transportation,': [16], 'security,': [17], 'medicine,': [18], 'finance,': [19], 'defense)': [20], 'that': [21], 'offer': [22], 'tremendous': [23], 'benefits': [24], 'but': [25], 'cannot': [26], 'explain': [27], 'their': [28, 143, 171], 'decisions': [29, 50], 'and': [30, 49, 54, 74, 96, 100, 119, 180], 'actions': [31], 'human': [33], 'users.': [34, 59], ""DARPA's"": [35], 'explainable': [36, 68], 'artificial': [37], 'intelligence': [38], '(XAI)': [39], 'program': [40, 154], 'endeavors': [41], 'create': [43], 'systems': [45], 'whose': [46], 'learned': [47], 'models': [48], 'can': [51], 'be': [52], 'understood': [53], 'appropriately': [55], 'trusted': [56], 'by': [57, 92, 116], 'end': [58], 'Realizing': [60], 'this': [61, 152], 'goal': [62], 'requires': [63], 'methods': [64], 'for': [65, 79, 104], 'more': [67], 'models,': [69], 'designing': [70], 'effective': [71, 80, 106], 'explanation': [72, 124], 'interfaces,': [73], 'understanding': [75], 'the': [76, 88, 113, 127, 136, 149, 164], 'psychologic': [77, 121], 'requirements': [78], 'explanations.': [81, 107], 'The': [82, 145], 'XAI': [83, 109, 128, 146], 'developer': [84, 137, 165], 'teams': [85, 138, 147, 166], 'are': [86, 167], 'addressing': [87, 112], 'first': [89, 150], 'two': [90], 'challenges': [91], 'creating': [93], 'ML': [94], 'techniques': [95, 103], 'developing': [97], 'principles,': [98], 'strategies,': [99], 'human‐computer': [101], 'interaction': [102], 'generating': [105], 'Another': [108], 'team': [110], 'is': [111], 'third': [114], 'challenge': [115], 'summarizing,': [117], 'extending,': [118], 'applying': [120], 'theories': [122], 'help': [126], 'evaluator': [129], 'define': [130], 'suitable': [132], 'evaluation': [133], 'framework,': [134], 'which': [135], 'will': [139], 'use': [140], 'test': [142], 'systems.': [144], 'completed': [148], '4‐year': [153], 'May': [156], '2018.': [157], 'In': [158], 'series': [160], 'ongoing': [162], 'evaluations,': [163], 'assessing': [168], 'how': [169], 'well': [170], 'XAM': [172], ""systems'"": [173], 'explanations': [174], 'improve': [175], 'user': [176, 178, 181], 'understanding,': [177], 'trust,': [179], 'task': [182], 'performance.': [183]}",2019,"['Computer science', 'Task (project management)', 'Artificial intelligence', 'Knowledge management', 'Management science', 'Engineering', 'Systems engineering']","Dramatic success in machine learning has led to a new wave of AI applications (for example, transportation, security, medicine, finance, defense) that offer tremendous benefits but cannot explain their decisions and actions to human users. DARPA's explainable artificial intelligence (XAI) program endeavors to create AI systems whose learned models and decisions can be understood and appropriately trusted by end users. Realizing this goal requires methods for learning more explainable models, designing effective explanation interfaces, and understanding the psychologic requirements for effective explanations. The XAI developer teams are addressing the first two challenges by creating ML techniques and developing principles, strategies, and human‐computer interaction techniques for generating effective explanations. Another XAI team is addressing the third challenge by summarizing, extending, and applying psychologic theories of explanation to help the XAI evaluator define a suitable evaluation framework, which the developer teams will use to test their systems. The XAI teams completed the first of this 4‐year program in May 2018. In a series of ongoing evaluations, the developer teams are assessing how well their XAM systems' explanations improve user understanding, user trust, and user task performance."
https://openalex.org/W3016417837,Artificial Intelligence in Dentistry: Chances and Challenges,"{'The': [0], 'term': [1], '“artificial': [2], 'intelligence”': [3], '(AI)': [4], 'refers': [5], 'to': [6, 32, 136, 185, 212, 222, 243, 262, 280], 'the': [7, 63, 98, 159, 246, 267, 282, 293], 'idea': [8], 'of': [9, 13, 19, 69, 163, 188, 194, 248, 284], 'machines': [10], 'being': [11], 'capable': [12], 'performing': [14], 'human': [15, 250], 'tasks.': [16], 'A': [17], 'subdomain': [18], 'AI': [20, 124, 172, 240, 270, 286], 'is': [21, 41], 'machine': [22], 'learning': [23, 40, 50, 224], '(ML),': [24], 'which': [25], '“learns”': [26], 'intrinsic': [27], 'statistical': [28], 'patterns': [29], 'in': [30, 151, 174, 255, 292], 'data': [31, 55, 139], 'eventually': [33, 115], 'cast': [34], 'predictions': [35], 'on': [36, 53], 'unseen': [37], 'data.': [38], 'Deep': [39], 'a': [42, 111, 218], 'ML': [43], 'technique': [44], 'using': [45], 'multi-layer': [46], 'mathematical': [47], 'operations': [48], 'for': [49, 77, 110, 181], 'and': [51, 66, 75, 90, 114, 120, 143, 149, 155, 161, 169, 186, 192, 197, 209, 216, 231, 236, 252, 265], 'inferring': [52], 'complex': [54], 'like': [56], 'imagery.': [57], 'This': [58], 'succinct': [59], 'narrative': [60], 'review': [61], 'describes': [62], 'application,': [64], 'limitations': [65], 'possible': [67], 'future': [68, 294], 'AI-based': [70, 92], 'dental': [71, 88, 99, 132, 239, 295], 'diagnostics,': [72], 'treatment': [73], 'planning,': [74], 'conduct,': [76], 'example,': [78, 182], 'image': [79], 'analysis,': [80], 'prediction': [81], 'making,': [82], 'record': [83], 'keeping,': [84], 'as': [85, 87], 'well': [86], 'research': [89], 'discovery.': [91], 'applications': [93], 'will': [94, 272, 278], 'streamline': [95], 'care,': [96, 189], 'relieving': [97], 'workforce': [100], 'from': [101, 220], 'laborious': [102], 'routine': [103, 131], 'tasks,': [104], 'increasing': [105, 190, 204], 'health': [106], 'at': [107], 'lower': [108], 'costs': [109], 'broader': [112], 'population,': [113], 'facilitate': [116], 'personalized,': [117], 'predictive,': [118], 'preventive,': [119], 'participatory': [121], 'dentistry.': [122], 'However,': [123], 'solutions': [125, 241, 271, 287], 'have': [126], 'not': [127], 'by': [128, 288], 'large': [129], 'entered': [130], 'practice,': [133], 'mainly': [134], 'due': [135], '1)': [137], 'limited': [138], 'availability,': [140], 'accessibility,': [141], 'structure,': [142], 'comprehensiveness,': [144], '2)': [145], 'lacking': [146], 'methodological': [147], 'rigor': [148], 'standards': [150, 253], 'their': [152], 'development,': [153], '3)': [154], 'practical': [156], 'questions': [157], 'around': [158], 'value': [160, 179], 'usefulness': [162], 'these': [164], 'solutions,': [165], 'but': [166], 'also': [167], 'ethics': [168], 'responsibility.': [170], 'Any': [171], 'application': [173], 'dentistry': [175, 257], 'should': [176, 258], 'demonstrate': [177], 'tangible': [178], 'by,': [180], 'improving': [183, 229], 'access': [184], 'quality': [187], 'efficiency': [191], 'safety': [193], 'services,': [195], 'empowering': [196], 'enabling': [198], 'patients,': [199], 'supporting': [200], 'medical': [201], 'research,': [202], 'or': [203], 'sustainability.': [205], 'Individual': [206], 'privacy,': [207], 'rights,': [208], 'autonomy': [210], 'need': [211, 242, 279], 'be': [213, 244, 259], 'put': [214], 'front': [215], 'center;': [217], 'shift': [219], 'centralized': [221], 'distributed/federated': [223], 'may': [225], 'address': [226], 'this': [227], 'while': [228], 'scalability': [230], 'robustness.': [232], 'Lastly,': [233], 'trustworthiness': [234], 'into,': [235], 'generalizability': [237], 'of,': [238], 'guaranteed;': [245], 'implementation': [247], 'continuous': [249], 'oversight': [251], 'grounded': [254], 'evidence-based': [256], 'expected.': [260], 'Methods': [261], 'visualize,': [263], 'interpret,': [264], 'explain': [266], 'logic': [268], 'behind': [269], 'contribute': [273], '(“explainable': [274], 'AI”).': [275], 'Dental': [276], 'education': [277], 'accompany': [281], 'introduction': [283], 'clinical': [285], 'fostering': [289], 'digital': [290], 'literacy': [291], 'workforce.': [296]}",2020,"['Computer science', 'Artificial intelligence', 'Population', 'Deep learning', 'Health care', 'Generalizability theory', 'Data science', 'Machine learning', 'Medicine', 'Psychology', 'Environmental health', 'Developmental psychology', 'Economics', 'Economic growth']","The term “artificial intelligence” (AI) refers to the idea of machines being capable of performing human tasks. A subdomain of AI is machine learning (ML), which “learns” intrinsic statistical patterns in data to eventually cast predictions on unseen data. Deep learning is a ML technique using multi-layer mathematical operations for learning and inferring on complex data like imagery. This succinct narrative review describes the application, limitations and possible future of AI-based dental diagnostics, treatment planning, and conduct, for example, image analysis, prediction making, record keeping, as well as dental research and discovery. AI-based applications will streamline care, relieving the dental workforce from laborious routine tasks, increasing health at lower costs for a broader population, and eventually facilitate personalized, predictive, preventive, and participatory dentistry. However, AI solutions have not by large entered routine dental practice, mainly due to 1) limited data availability, accessibility, structure, and comprehensiveness, 2) lacking methodological rigor and standards in their development, 3) and practical questions around the value and usefulness of these solutions, but also ethics and responsibility. Any AI application in dentistry should demonstrate tangible value by, for example, improving access to and quality of care, increasing efficiency and safety of services, empowering and enabling patients, supporting medical research, or increasing sustainability. Individual privacy, rights, and autonomy need to be put front and center; a shift from centralized to distributed/federated learning may address this while improving scalability and robustness. Lastly, trustworthiness into, and generalizability of, dental AI solutions need to be guaranteed; the implementation of continuous human oversight and standards grounded in evidence-based dentistry should be expected. Methods to visualize, interpret, and explain the logic behind AI solutions will contribute (“explainable AI”). Dental education will need to accompany the introduction of clinical AI solutions by fostering digital literacy in the future dental workforce."
https://openalex.org/W2886801379,Artificial intelligence in retina,"{'Major': [0], 'advances': [1], 'in': [2, 32, 60, 111, 117, 182], 'diagnostic': [3, 143], 'technologies': [4], 'are': [5, 51, 106], 'offering': [6], 'unprecedented': [7], 'insight': [8], 'into': [9], 'the': [10, 13, 72, 75, 177, 199, 210], 'condition': [11], 'of': [12, 23, 74, 83, 102, 132, 139, 149, 154, 159, 164, 180, 212], 'retina': [14, 183], 'and': [15, 28, 46, 56, 64, 108, 115, 120, 162, 172, 196, 206], 'beyond': [16], 'ocular': [17], 'disease.': [18, 66], 'Digital': [19], 'images': [20], 'providing': [21], 'millions': [22], 'morphological': [24], 'datasets': [25, 119], 'can': [26], 'fast': [27], 'non-invasively': [29], 'be': [30], 'analyzed': [31], 'a': [33], 'comprehensive': [34], 'manner': [35], 'using': [36], 'artificial': [37], 'intelligence': [38], '(AI).': [39], 'Methods': [40], 'based': [41], 'on': [42], 'machine': [43], 'learning': [44, 49, 82], '(ML)': [45], 'particularly': [47], 'deep': [48], '(DL)': [50], 'able': [52], 'to': [53, 201], 'identify,': [54], 'localize': [55], 'quantify': [57], 'pathological': [58, 84], 'features': [59, 85], 'almost': [61], 'every': [62], 'macular': [63], 'retinal': [65, 104], 'Convolutional': [67], 'neural': [68], 'networks': [69], 'thereby': [70], 'mimic': [71], 'path': [73], 'human': [76], 'brain': [77], 'for': [78, 130, 167], 'object': [79], 'recognition': [80], 'through': [81], 'from': [86, 94], 'training': [87], 'sets,': [88], 'supervised': [89], 'ML,': [90], 'or': [91], 'even': [92], 'extrapolation': [93], 'patterns': [95], 'recognized': [96], 'independently,': [97], 'unsupervised': [98], 'ML.': [99], 'The': [100, 136], 'methods': [101], 'AI-based': [103, 124], 'analyses': [105], 'diverse': [107], 'differ': [109], 'widely': [110], 'their': [112], 'applicability,': [113], 'interpretability': [114], 'reliability': [116], 'different': [118], 'diseases.': [121], 'Fully': [122], 'automated': [123, 152], 'systems': [125], 'have': [126], 'recently': [127], 'been': [128], 'approved': [129], 'screening': [131], 'diabetic': [133], 'retinopathy': [134], '(DR).': [135], 'overall': [137], 'potential': [138, 178], 'ML/DL': [140], 'includes': [141], 'screening,': [142], 'grading': [144], 'as': [145, 147, 190, 192], 'well': [146, 191], 'guidance': [148], 'therapy': [150], 'with': [151, 209], 'detection': [153], 'disease': [155], 'activity,': [156], 'recurrences,': [157], 'quantification': [158], 'therapeutic': [160, 169], 'effects': [161], 'identification': [163], 'relevant': [165], 'targets': [166], 'novel': [168], 'approaches.': [170], 'Prediction': [171], 'prognostic': [173], 'conclusions': [174], 'further': [175], 'expand': [176], 'benefit': [179], 'AI': [181], 'which': [184], 'will': [185, 197], 'enable': [186], 'personalized': [187], 'health': [188], 'care': [189], 'large': [193], 'scale': [194], 'management': [195], 'empower': [198], 'ophthalmologist': [200], 'provide': [202], 'high': [203], 'quality': [204], 'diagnosis/therapy': [205], 'successfully': [207], 'deal': [208], 'complexity': [211], '21st': [213], 'century': [214], 'ophthalmology.': [215]}",2018,"['Artificial intelligence', 'Interpretability', 'Computer science', 'Machine learning', 'Convolutional neural network', 'Deep learning', 'Medicine']","Major advances in diagnostic technologies are offering unprecedented insight into the condition of the retina and beyond ocular disease. Digital images providing millions of morphological datasets can fast and non-invasively be analyzed in a comprehensive manner using artificial intelligence (AI). Methods based on machine learning (ML) and particularly deep learning (DL) are able to identify, localize and quantify pathological features in almost every macular and retinal disease. Convolutional neural networks thereby mimic the path of the human brain for object recognition through learning of pathological features from training sets, supervised ML, or even extrapolation from patterns recognized independently, unsupervised ML. The methods of AI-based retinal analyses are diverse and differ widely in their applicability, interpretability and reliability in different datasets and diseases. Fully automated AI-based systems have recently been approved for screening of diabetic retinopathy (DR). The overall potential of ML/DL includes screening, diagnostic grading as well as guidance of therapy with automated detection of disease activity, recurrences, quantification of therapeutic effects and identification of relevant targets for novel therapeutic approaches. Prediction and prognostic conclusions further expand the potential benefit of AI in retina which will enable personalized health care as well as large scale management and will empower the ophthalmologist to provide high quality diagnosis/therapy and successfully deal with the complexity of 21st century ophthalmology."
https://openalex.org/W2971544482,Edge Intelligence: The Confluence of Edge Computing and Artificial Intelligence,"{'Along': [0], 'with': [1, 31, 109], 'the': [2, 9, 11, 32, 38, 49, 110, 118, 125, 137, 152, 156, 161], 'rapid': [3], 'developments': [4], 'in': [5, 23, 34, 106, 168], 'communication': [6], 'technologies': [7], 'and': [8, 37, 57, 69, 89, 114, 134, 155], 'surge\\nin': [10], 'use': [12], 'of': [13, 44, 112], 'mobile': [14], 'devices,': [15], 'a': [16, 62, 148], 'brand-new': [17], 'computation': [18], 'paradigm,': [19], 'Edge': [20, 67, 74, 81, 87, 107, 169], 'Computing,\\nis': [21], 'surging': [22], 'popularity.': [24], 'Meanwhile,': [25], 'Artificial': [26], 'Intelligence': [27, 82], '(AI)': [28], 'applications\\nare': [29], 'thriving': [30], 'breakthroughs': [33], 'deep': [35], 'learning': [36], 'many': [39], 'improvements\\nin': [40], 'hardware': [41], 'architectures.': [42], 'Billions': [43], 'data': [45, 55], 'bytes,': [46], 'generated': [47], 'at': [48], 'network\\nedge,': [50], 'put': [51], 'massive': [52], 'demands': [53], 'on': [54, 91, 94, 99, 136], 'processing': [56], 'structural': [58], 'optimization.': [59], 'Thus,\\nthere': [60], 'exists': [61], 'strong': [63], 'demand': [64], 'to': [65, 73, 122], 'integrate': [66], 'Computing': [68, 108], 'AI,': [70], 'which': [71], 'gives\\nbirth': [72], 'Intelligence.': [75], 'In': [76], 'this': [77, 143], 'paper,': [78], 'we': [79], 'divide': [80], 'into': [83, 142], 'AI\\nfor': [84], 'edge': [85, 92], '(Intelligence-enabled': [86], 'Computing)': [88], 'AI': [90, 129], '(Artificial\\nIntelligence': [93], 'Edge).': [95], 'The': [96], 'former': [97], 'focuses': [98], 'providing': [100], 'more': [101], 'optimal': [102], 'solutions\\nto': [103], 'key': [104], 'problems': [105], 'help': [111], 'popular': [113], 'effective': [115], 'AI\\ntechnologies': [116], 'while': [117], 'latter': [119], 'studies': [120], 'how': [121], 'carry': [123], 'out': [124], 'entire': [126], 'process': [127], 'of\\nbuilding': [128], 'models,': [130], 'i.e.,': [131], 'model': [132], 'training': [133], 'inference,': [135], 'edge.': [138], 'This': [139], 'paper\\nprovides': [140], 'insights': [141], 'new': [144], 'inter-disciplinary': [145], 'field': [146], 'from': [147], 'broader\\nperspective.': [149], 'It': [150], 'discusses': [151], 'core': [153], 'concepts': [154], 'research': [157], 'road-map,': [158], 'which\\nshould': [159], 'provide': [160], 'necessary': [162], 'background': [163], 'for': [164], 'potential': [165], 'future': [166], 'research\\ninitiatives': [167], 'Intelligence.\\n': [170]}",2020,"['Confluence', 'Computer science', 'Enhanced Data Rates for GSM Evolution', 'Artificial intelligence', 'Edge computing', 'Programming language']","Along with the rapid developments in communication technologies and the surge\nin the use of mobile devices, a brand-new computation paradigm, Edge Computing,\nis surging in popularity. Meanwhile, Artificial Intelligence (AI) applications\nare thriving with the breakthroughs in deep learning and the many improvements\nin hardware architectures. Billions of data bytes, generated at the network\nedge, put massive demands on data processing and structural optimization. Thus,\nthere exists a strong demand to integrate Edge Computing and AI, which gives\nbirth to Edge Intelligence. In this paper, we divide Edge Intelligence into AI\nfor edge (Intelligence-enabled Edge Computing) and AI on edge (Artificial\nIntelligence on Edge). The former focuses on providing more optimal solutions\nto key problems in Edge Computing with the help of popular and effective AI\ntechnologies while the latter studies how to carry out the entire process of\nbuilding AI models, i.e., model training and inference, on the edge. This paper\nprovides insights into this new inter-disciplinary field from a broader\nperspective. It discusses the core concepts and the research road-map, which\nshould provide the necessary background for potential future research\ninitiatives in Edge Intelligence.\n"
https://openalex.org/W4367310920,Comparing Physician and Artificial Intelligence Chatbot Responses to Patient Questions Posted to a Public Social Media Forum,"{'Importance': [0], 'The': [1, 141, 297, 363], 'rapid': [2], 'expansion': [3], 'of': [4, 52, 84, 161, 177, 252, 283, 299, 335, 365, 402, 433], 'virtual': [5], 'health': [6, 22, 163], 'care': [7, 23, 164], 'has': [8], 'caused': [9], 'a': [10, 79, 87, 105, 110, 123, 159, 222, 416], 'surge': [11], 'in': [12, 32, 59, 132, 156, 247, 427, 438], 'patient': [13, 36, 69, 424, 470], 'messages': [14], 'concomitant': [15], 'with': [16, 145], 'more': [17, 351], 'work': [18], 'and': [19, 65, 73, 81, 138, 147, 151, 172, 194, 213, 227, 231, 238, 420, 468], 'burnout': [20], 'among': [21], 'professionals.': [24, 165], 'Artificial': [25], 'intelligence': [26], '(AI)': [27], 'assistants': [28, 461], 'could': [29, 42, 450, 455], 'potentially': [30], 'aid': [31], 'creating': [33], 'answers': [34], 'to': [35, 62, 68, 96, 109, 224, 244, 330, 397, 423, 445], 'questions': [37, 85, 128, 237, 425], 'by': [38, 45, 117, 158], 'drafting': [39], 'responses': [40, 67, 114, 153, 243, 246, 259, 265, 280, 289, 300, 341, 346, 355, 366, 407, 422, 447], 'that': [41, 448], 'be': [43], 'reviewed': [44], 'clinicians.': [46], 'Objective': [47], 'To': [48], 'evaluate': [49], 'the': [50, 119, 133, 235, 253, 343, 409], 'ability': [51], 'an': [53, 428], 'AI': [54, 460], 'chatbot': [55, 152, 230, 242, 264, 315, 376, 417, 444], 'assistant': [56], '(ChatGPT),': [57], 'released': [58], 'November': [60], '2022,': [61], 'provide': [63], 'quality': [64, 176, 286, 307, 340, 419], 'empathetic': [66, 203, 206, 209, 211, 215, 352, 368, 371, 403, 406, 421], 'questions.': [70], 'Design,': [71], 'Setting,': [72], 'Participants': [74], 'In': [75, 412], 'this': [76, 413, 434], 'cross-sectional': [77, 414], 'study,': [78, 415], 'public': [80, 88, 111], 'nonidentifiable': [82], 'database': [83], 'from': [86, 101], 'social': [89], 'media': [90], 'forum': [91], '(Reddit’s': [92], 'r/AskDocs)': [93], 'was': [94, 170, 312, 373], 'used': [95], 'randomly': [97, 148], 'draw': [98], '195': [99, 236], 'exchanges': [100], 'October': [102], '2022': [103], 'where': [104], 'verified': [106], 'physician': [107, 150, 245, 258, 288, 354], 'responded': [108], 'question.': [112], 'Chatbot': [113, 279, 345], 'were': [115, 154, 219, 260, 281, 347], 'generated': [116, 418], 'entering': [118], 'original': [120, 142], 'question': [121, 143], 'into': [122], 'fresh': [124], 'session': [125], '(without': [126], 'prior': [127], 'having': [129], 'been': [130], 'asked': [131], 'session)': [134], 'on': [135, 221], 'December': [136], '22': [137], '23,': [139], '2022.': [140], 'along': [144], 'anonymized': [146], 'ordered': [149, 220], 'evaluated': [155], 'triplicate': [157], 'team': [160], 'licensed': [162], 'Evaluators': [166], 'chose': [167], '“which': [168], 'response': [169], 'better”': [171], 'judged': [173], 'both': [174], '“the': [175, 195], 'information': [178], 'provided”': [179, 200], '(': [180, 201, 290, 356], 'very': [181, 191, 214, 305, 338, 370, 405], 'poor': [182, 184], ',': [183, 185, 187, 189, 204, 207, 210, 212], 'acceptable': [186], 'good': [188, 192, 303, 306, 336, 339], 'or': [190, 197, 304, 337, 369, 404], ')': [193], 'empathy': [196], 'bedside': [198], 'manner': [199], 'not': [202], 'slightly': [205], 'moderately': [208], ').': [216], 'Mean': [217, 256], 'outcomes': [218], '1': [223], '5': [225], 'scale': [226], 'compared': [228], 'between': [229], 'physicians.': [232], 'Results': [233], 'Of': [234], 'responses,': [239, 464], 'evaluators': [240], 'preferred': [241], '78.6%': [248], '(95%': [249], 'CI,': [250, 321, 326, 383, 388, 393], '75.0%-81.8%)': [251], '585': [254], 'evaluations.': [255], '(IQR)': [257], 'significantly': [261, 284, 350], 'shorter': [262], 'than': [263, 287, 316, 353, 377], '(52': [266], '[17-62]': [267], 'words': [268], 'vs': [269], '211': [270], '[168-245]': [271], 'words;': [272], 't': [273, 291, 357], '=': [274, 292, 358], '25.4;': [275], 'P': [276, 294, 360], '&amp;amp;lt;': [277, 295, 361], '.001).': [278, 296, 362], 'rated': [282, 301, 349, 367], 'higher': [285, 313, 333, 374, 400], '13.3;': [293], 'proportion': [298, 364], 'as': [302, 442], '(≥': [308], '4),': [309], 'for': [310, 314, 342, 375, 378, 408], 'instance,': [311], 'physicians': [317, 379, 449], '(chatbot:': [318], '78.5%,': [319], '95%': [320, 325, 382, 387, 392], '72.3%-84.1%;': [322], 'physicians:': [323, 390], '22.1%,': [324], '16.4%-28.2%;).': [327], 'This': [328, 395], 'amounted': [329, 396], '3.6': [331], 'times': [332, 399], 'prevalence': [334, 401], 'chatbot.': [344, 410], 'also': [348], '18.9;': [359], '(≥4)': [372], '(physicians:': [380], '4.6%,': [381, 391], '2.1%-7.7%;': [384], 'chatbot:': [385], '45.1%,': [386], '38.5%-51.8%;': [389], '2.1%-7.7%).': [394], '9.8': [398], 'Conclusions': [411], 'posed': [426], 'online': [429], 'forum.': [430], 'Further': [431], 'exploration': [432], 'technology': [435], 'is': [436], 'warranted': [437], 'clinical': [439], 'settings,': [440], 'such': [441], 'using': [443, 459], 'draft': [446], 'then': [451], 'edit.': [452], 'Randomized': [453], 'trials': [454], 'assess': [456], 'further': [457], 'if': [458], 'might': [462], 'improve': [463, 469], 'lower': [465], 'clinician': [466], 'burnout,': [467], 'outcomes.': [471]}",2023,"['Chatbot', 'Medicine', 'Empathy', 'Session (web analytics)', 'Social media', 'Nursing', 'Medical education', 'Family medicine', 'World Wide Web', 'Psychiatry', 'Computer science']","Importance The rapid expansion of virtual health care has caused a surge in patient messages concomitant with more work and burnout among health care professionals. Artificial intelligence (AI) assistants could potentially aid in creating answers to patient questions by drafting responses that could be reviewed by clinicians. Objective To evaluate the ability of an AI chatbot assistant (ChatGPT), released in November 2022, to provide quality and empathetic responses to patient questions. Design, Setting, and Participants In this cross-sectional study, a public and nonidentifiable database of questions from a public social media forum (Reddit’s r/AskDocs) was used to randomly draw 195 exchanges from October 2022 where a verified physician responded to a public question. Chatbot responses were generated by entering the original question into a fresh session (without prior questions having been asked in the session) on December 22 and 23, 2022. The original question along with anonymized and randomly ordered physician and chatbot responses were evaluated in triplicate by a team of licensed health care professionals. Evaluators chose “which response was better” and judged both “the quality of information provided” ( very poor , poor , acceptable , good , or very good ) and “the empathy or bedside manner provided” ( not empathetic , slightly empathetic , moderately empathetic , empathetic , and very empathetic ). Mean outcomes were ordered on a 1 to 5 scale and compared between chatbot and physicians. Results Of the 195 questions and responses, evaluators preferred chatbot responses to physician responses in 78.6% (95% CI, 75.0%-81.8%) of the 585 evaluations. Mean (IQR) physician responses were significantly shorter than chatbot responses (52 [17-62] words vs 211 [168-245] words; t = 25.4; P &amp;amp;lt; .001). Chatbot responses were rated of significantly higher quality than physician responses ( t = 13.3; P &amp;amp;lt; .001). The proportion of responses rated as good or very good quality (≥ 4), for instance, was higher for chatbot than physicians (chatbot: 78.5%, 95% CI, 72.3%-84.1%; physicians: 22.1%, 95% CI, 16.4%-28.2%;). This amounted to 3.6 times higher prevalence of good or very good quality responses for the chatbot. Chatbot responses were also rated significantly more empathetic than physician responses ( t = 18.9; P &amp;amp;lt; .001). The proportion of responses rated empathetic or very empathetic (≥4) was higher for chatbot than for physicians (physicians: 4.6%, 95% CI, 2.1%-7.7%; chatbot: 45.1%, 95% CI, 38.5%-51.8%; physicians: 4.6%, 95% CI, 2.1%-7.7%). This amounted to 9.8 times higher prevalence of empathetic or very empathetic responses for the chatbot. Conclusions In this cross-sectional study, a chatbot generated quality and empathetic responses to patient questions posed in an online forum. Further exploration of this technology is warranted in clinical settings, such as using chatbot to draft responses that physicians could then edit. Randomized trials could assess further if using AI assistants might improve responses, lower clinician burnout, and improve patient outcomes."
https://openalex.org/W3081261125,Consumers and Artificial Intelligence: An Experiential Perspective,"{'Artificial': [0], 'intelligence': [1], '(AI)': [2], 'helps': [3], 'companies': [4], 'offer': [5], 'important': [6], 'benefits': [7], 'to': [8, 44, 71, 94, 110, 151, 157, 166, 175], 'consumers,': [9], 'such': [10], 'as': [11, 40], 'health': [12], 'monitoring': [13], 'with': [14, 18, 24, 30, 121, 134], 'wearable': [15], 'devices,': [16], 'advice': [17], 'recommender': [19], 'systems,': [20], 'peace': [21], 'of': [22, 113, 131], 'mind': [23], 'smart': [25], 'household': [26], 'products,': [27], 'and': [28, 49, 58, 90, 104, 107, 143, 154, 174], 'convenience': [29], 'voice-activated': [31], 'virtual': [32], 'assistants.': [33], 'However,': [34], 'although': [35], 'AI': [36, 65, 86, 173], 'can': [37, 62, 92], 'be': [38, 45], 'seen': [39], 'a': [41], 'neutral': [42], 'tool': [43], 'evaluated': [46], 'on': [47, 76, 103], 'efficiency': [48], 'accuracy,': [50], 'this': [51], 'approach': [52, 147], 'does': [53], 'not': [54], 'consider': [55], 'the': [56, 79, 82, 97, 100, 114, 126, 149, 159], 'social': [57], 'individual': [59], 'challenges': [60], 'that': [61, 84], 'occur': [63], 'when': [64], 'is': [66], 'deployed.': [67], 'This': [68, 146], 'research': [69], 'aims': [70], 'bridge': [72], 'these': [73], 'two': [74], 'perspectives:': [75], 'one': [77], 'side,': [78, 99], 'authors': [80, 101, 127, 150], 'acknowledge': [81], 'value': [83, 168], 'embedding': [85], 'technology': [87], 'into': [88, 172], 'products': [89], 'services': [91], 'provide': [93], 'consumers.': [95], 'On': [96], 'other': [98], 'build': [102], 'integrate': [105], 'sociological': [106], 'psychological': [108], 'scholarship': [109], 'examine': [111], 'some': [112], 'costs': [115], 'consumers': [116, 163], 'experience': [117, 167], 'in': [118, 161, 169], 'their': [119], 'interactions': [120], 'AI.': [122], 'In': [123], 'doing': [124], 'so,': [125], 'identify': [128], 'four': [129], 'types': [130], 'consumer': [132], 'experiences': [133], 'AI:': [135], '(1)': [136], 'data': [137], 'capture,': [138], '(2)': [139], 'classification,': [140], '(3)': [141], 'delegation,': [142], '(4)': [144], 'social.': [145], 'allows': [148], 'discuss': [152], 'policy': [153], 'managerial': [155], 'avenues': [156], 'address': [158], 'ways': [160], 'which': [162], 'may': [164], 'fail': [165], 'organizations’': [170], 'investments': [171], 'lay': [176], 'out': [177], 'an': [178], 'agenda': [179], 'for': [180], 'future': [181], 'research.': [182]}",2020,"['Value (mathematics)', 'Experiential learning', 'Scholarship', 'Perspective (graphical)', 'Bridge (graph theory)', 'Marketing', 'Computer science', 'Knowledge management', 'Sociology', 'Business', 'Artificial intelligence', 'Economics', 'Medicine', 'Machine learning', 'Economic growth', 'Pedagogy', 'Internal medicine']","Artificial intelligence (AI) helps companies offer important benefits to consumers, such as health monitoring with wearable devices, advice with recommender systems, peace of mind with smart household products, and convenience with voice-activated virtual assistants. However, although AI can be seen as a neutral tool to be evaluated on efficiency and accuracy, this approach does not consider the social and individual challenges that can occur when AI is deployed. This research aims to bridge these two perspectives: on one side, the authors acknowledge the value that embedding AI technology into products and services can provide to consumers. On the other side, the authors build on and integrate sociological and psychological scholarship to examine some of the costs consumers experience in their interactions with AI. In doing so, the authors identify four types of consumer experiences with AI: (1) data capture, (2) classification, (3) delegation, and (4) social. This approach allows the authors to discuss policy and managerial avenues to address the ways in which consumers may fail to experience value in organizations’ investments into AI and to lay out an agenda for future research."
https://openalex.org/W2910707576,"Artificial intelligence, bias and clinical safety","{'This': [0], 'is': [1], 'the': [2, 14], 'final': [3], 'version.': [4], 'Available': [5], 'on': [6], 'open': [7], 'access': [8], 'from': [9], 'BMJ': [10], 'Publishing': [11], 'group': [12], 'via': [13], 'DOI': [15], 'in': [16], 'this': [17], 'record': [18]}",2019,"['Medicine', 'Patient safety', 'MEDLINE', 'Medical emergency', 'Data science', 'Health care', 'Computer science', 'Economic growth', 'Economics', 'Law', 'Political science']",This is the final version. Available on open access from BMJ Publishing group via the DOI in this record
https://openalex.org/W4304943299,Ethical principles for artificial intelligence in education,"{'Abstract': [0], 'The': [1, 179], 'advancement': [2], 'of': [3, 21, 30, 40, 52, 76, 145, 182, 203, 214], 'artificial': [4], 'intelligence': [5], 'in': [6, 128, 198, 218], 'education': [7, 129], '(AIED)': [8], 'has': [9, 54], 'the': [10, 14, 19, 28, 50, 73, 83, 87, 123, 199, 219], 'potential': [11, 131], 'to': [12, 36, 56, 96, 139, 187, 192], 'transform': [13], 'educational': [15, 168, 196], 'landscape': [16], 'and': [17, 43, 47, 60, 69, 80, 109, 115, 130, 141, 150, 155, 163, 176, 194, 201, 205], 'influence': [18], 'role': [20], 'all': [22], 'involved': [23], 'stakeholders.': [24], 'In': [25, 117], 'recent': [26, 74], 'years,': [27], 'applications': [29], 'AIED': [31, 53, 106, 207], 'have': [32], 'been': [33], 'gradually': [34], 'adopted': [35], 'progress': [37], 'our': [38], 'understanding': [39], 'students’': [41], 'learning': [42, 45], 'enhance': [44], 'performance': [46], 'experience.': [48], 'However,': [49], 'adoption': [51], 'led': [55], 'increasing': [57], 'ethical': [58, 79, 91, 105, 132, 146, 153, 183, 204], 'risks': [59], 'concerns': [61], 'regarding': [62], 'several': [63], 'aspects': [64], 'such': [65], 'as': [66, 189, 208, 210], 'personal': [67], 'data': [68], 'learner': [70], 'autonomy.': [71], 'Despite': [72], 'announcement': [75], 'guidelines': [77, 156], 'for': [78, 157, 166], 'trustworthy': [81, 206], 'AIED,': [82], 'debate': [84], 'revolves': [85], 'around': [86], 'key': [88], 'principles': [89, 147, 184], 'underpinning': [90], 'AIED.': [92, 158], 'This': [93], 'paper': [94], 'aims': [95], 'explore': [97], 'whether': [98], 'there': [99], 'is': [100, 185], 'a': [101, 143, 190], 'global': [102], 'consensus': [103], 'on': [104], 'by': [107, 126, 148], 'mapping': [108], 'analyzing': [110], 'international': [111], 'organizations’': [112], 'current': [113], 'policies': [114, 154], 'guidelines.': [116], 'this': [118], 'paper,': [119], 'we': [120], 'first': [121], 'introduce': [122], 'opportunities': [124], 'offered': [125], 'AI': [127], 'issues.': [133], 'Then,': [134], 'thematic': [135], 'analysis': [136], 'was': [137], 'conducted': [138], 'conceptualize': [140], 'establish': [142], 'set': [144, 181], 'examining': [149], 'synthesizing': [151], 'relevant': [152, 167], 'We': [159], 'discuss': [160], 'each': [161], 'principle': [162], 'associated': [164], 'implications': [165], 'stakeholders,': [169], 'including': [170], 'students,': [171], 'teachers,': [172], 'technology': [173], 'developers,': [174], 'policymakers,': [175], 'institutional': [177], 'decision-makers.': [178], 'proposed': [180], 'expected': [186], 'serve': [188], 'framework': [191], 'inform': [193], 'guide': [195], 'stakeholders': [197], 'development': [200, 213], 'deployment': [202], 'well': [209], 'catalyze': [211], 'future': [212], 'related': [215], 'impact': [216], 'studies': [217], 'field.': [220]}",2022,"['Autonomy', 'Engineering ethics', 'Underpinning', 'Trustworthiness', 'Set (abstract data type)', 'Thematic analysis', 'Psychology', 'Knowledge management', 'Public relations', 'Political science', 'Sociology', 'Computer science', 'Qualitative research', 'Engineering', 'Social psychology', 'Social science', 'Law', 'Civil engineering', 'Programming language']","Abstract The advancement of artificial intelligence in education (AIED) has the potential to transform the educational landscape and influence the role of all involved stakeholders. In recent years, the applications of AIED have been gradually adopted to progress our understanding of students’ learning and enhance learning performance and experience. However, the adoption of AIED has led to increasing ethical risks and concerns regarding several aspects such as personal data and learner autonomy. Despite the recent announcement of guidelines for ethical and trustworthy AIED, the debate revolves around the key principles underpinning ethical AIED. This paper aims to explore whether there is a global consensus on ethical AIED by mapping and analyzing international organizations’ current policies and guidelines. In this paper, we first introduce the opportunities offered by AI in education and potential ethical issues. Then, thematic analysis was conducted to conceptualize and establish a set of ethical principles by examining and synthesizing relevant ethical policies and guidelines for AIED. We discuss each principle and associated implications for relevant educational stakeholders, including students, teachers, technology developers, policymakers, and institutional decision-makers. The proposed set of ethical principles is expected to serve as a framework to inform and guide educational stakeholders in the development and deployment of ethical and trustworthy AIED as well as catalyze future development of related impact studies in the field."
https://openalex.org/W3011149445,Using Artificial Intelligence to Detect COVID-19 and Community-acquired Pneumonia Based on Pulmonary CT: Evaluation of the Diagnostic Accuracy,"{'Background': [0], 'Coronavirus': [1], 'disease': [2], '2019': [3, 270], '(COVID-19)': [4], 'has': [5], 'widely': [6], 'spread': [7], 'all': [8], 'over': [9], 'the': [10, 13, 61, 79, 97, 100, 120, 123, 179, 210, 229, 250], 'world': [11], 'since': [12], 'beginning': [14], 'of': [15, 26, 81, 85, 99, 136, 192, 202, 215, 236, 242, 255], '2020.': [16, 114], 'It': [17], 'is': [18, 287], 'desirable': [19], 'to': [20, 38, 69, 95], 'develop': [21, 33], 'automatic': [22, 36], 'and': [23, 44, 49, 54, 89, 112, 129, 155, 173, 195, 223, 239, 271, 277], 'accurate': [24], 'detection': [25, 63, 80], 'COVID-19': [27, 40, 62, 177], 'using': [28, 41], 'chest': [29, 42, 75, 138], 'CT.': [30], 'Purpose': [31], 'To': [32], 'a': [34, 57], 'fully': [35], 'framework': [37], 'detect': [39, 268], 'CT': [43, 76, 83, 139], 'evaluate': [45], 'its': [46], 'performance.': [47], 'Materials': [48], 'Methods': [50], 'In': [51], 'this': [52, 290], 'retrospective': [53], 'multicenter': [55], 'study,': [56], 'deep': [58, 263], 'learning': [59, 264], 'model,': [60], 'neural': [64], 'network': [65], '(COVNet),': [66], 'was': [67, 117, 150, 183, 233], 'developed': [68], 'extract': [70], 'visual': [71], 'features': [72], 'from': [73, 106, 141, 274], 'volumetric': [74], 'scans': [77, 84, 140], 'for': [78, 175, 225, 289], 'COVID-19.': [82], 'community-acquired': [86, 275], 'pneumonia': [87, 276], '(CAP)': [88], 'other': [90, 278], 'non-pneumonia': [91], 'abnormalities': [92], 'were': [93, 104, 157], 'included': [94], 'test': [96, 181, 231], 'robustness': [98], 'model.': [101], 'The': [102, 132, 144, 170, 220], 'datasets': [103], 'collected': [105, 133], 'six': [107], 'hospitals': [108], 'between': [109], 'August': [110], '2016': [111], 'February': [113], 'Diagnostic': [115], 'performance': [116], 'assessed': [118], 'with': [119, 206, 246], 'area': [121, 208, 248], 'under': [122, 209, 249], 'receiver': [124, 211, 251], 'operating': [125, 212, 252], 'characteristic': [126, 213, 253], 'curve,': [127], 'sensitivity,': [128], 'specificity.': [130], 'Results': [131], 'dataset': [134], 'consisted': [135], '4352': [137], '3322': [142], 'patients.': [143], 'average': [145], 'patient': [146], 'age': [147], '(±standard': [148], 'deviation)': [149], '49': [151], 'years': [152], '±': [153], '15,': [154], 'there': [156], 'slightly': [158], 'more': [159], 'men': [160], 'than': [161], 'women': [162], '(1838': [163], 'vs': [164], '1484,': [165], 'respectively;': [166], '<i>P</i>': [167], '=': [168], '.29).': [169], 'per-scan': [171, 221], 'sensitivity': [172, 222], 'specificity': [174, 224], 'detecting': [176, 226], 'in': [178, 228], 'independent': [180, 230], 'set': [182, 232], '90%': [184], '(95%': [185, 197, 257], 'confidence': [186], 'interval': [187], '[CI]:': [188], '83%,': [189], '94%;': [190], '114': [191], '127': [193], 'scans)': [194, 238], '96%': [196], 'CI:': [198, 258], '93%,': [199], '98%;': [200], '294': [201], '307': [203], 'scans),': [204, 244], 'respectively,': [205, 245], 'an': [207, 247], 'curve': [214, 254], '0.96': [216], '(<i>P</i>': [217], '<': [218], '.001).': [219], 'CAP': [227], '87%': [234], '(152': [235], '175': [237], '92%': [240], '(239': [241], '259': [243], '0.95': [256], '0.93,': [259], '0.97).': [260], 'Conclusion': [261], 'A': [262], 'model': [265], 'can': [266], 'accurately': [267], 'coronavirus': [269], 'differentiate': [272], 'it': [273], 'lung': [279], 'conditions.': [280], '©': [281], 'RSNA,': [282], '2020': [283], '<i>Online': [284], 'supplemental': [285], 'material': [286], 'available': [288], 'article.</i>': [291]}",2020,"['Medicine', 'Receiver operating characteristic', 'Coronavirus disease 2019 (COVID-19)', 'Pneumonia', 'Confidence interval', 'Radiology', 'Community-acquired pneumonia', 'Area under the curve', 'Nuclear medicine', 'Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)', 'Area under curve', 'Computed tomography', 'Internal medicine', 'Disease', 'Infectious disease (medical specialty)', 'Pharmacokinetics']","Background Coronavirus disease 2019 (COVID-19) has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performance. Materials and Methods In this retrospective and multicenter study, a deep learning model, the COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT scans for the detection of COVID-19. CT scans of community-acquired pneumonia (CAP) and other non-pneumonia abnormalities were included to test the robustness of the model. The datasets were collected from six hospitals between August 2016 and February 2020. Diagnostic performance was assessed with the area under the receiver operating characteristic curve, sensitivity, and specificity. Results The collected dataset consisted of 4352 chest CT scans from 3322 patients. The average patient age (±standard deviation) was 49 years ± 15, and there were slightly more men than women (1838 vs 1484, respectively; <i>P</i> = .29). The per-scan sensitivity and specificity for detecting COVID-19 in the independent test set was 90% (95% confidence interval [CI]: 83%, 94%; 114 of 127 scans) and 96% (95% CI: 93%, 98%; 294 of 307 scans), respectively, with an area under the receiver operating characteristic curve of 0.96 (<i>P</i> < .001). The per-scan sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175 scans) and 92% (239 of 259 scans), respectively, with an area under the receiver operating characteristic curve of 0.95 (95% CI: 0.93, 0.97). Conclusion A deep learning model can accurately detect coronavirus 2019 and differentiate it from community-acquired pneumonia and other lung conditions. © RSNA, 2020 <i>Online supplemental material is available for this article.</i>"
https://openalex.org/W2969912247,On Defining Artificial Intelligence,"{'Abstract': [0], 'This': [1], 'article': [2], 'systematically': [3], 'analyzes': [4], 'the': [5, 20, 23, 60, 64, 96, 108, 120], 'problem': [6], 'of': [7, 22, 29, 34, 86, 110], 'defining': [8], '“artificial': [9], 'intelligence.”': [10], 'It': [11, 99], 'starts': [12], 'by': [13], 'pointing': [14], 'out': [15], 'that': [16, 102], 'a': [17, 30, 35, 44, 116], 'definition': [18, 33, 70, 88, 104], 'influences': [19], 'path': [21], 'research,': [24, 50], 'then': [25], 'establishes': [26], 'four': [27], 'criteria': [28], 'good': [31], 'working': [32], 'notion:': [36], 'being': [37], 'similar': [38], 'to': [39, 48, 57, 74], 'its': [40], 'common': [41], 'usage,': [42], 'drawing': [43], 'sharp': [45], 'boundary,': [46], 'leading': [47], 'fruitful': [49], 'and': [51, 82, 91, 114], 'as': [52, 54], 'simple': [53], 'possible.': [55], 'According': [56], 'these': [58], 'criteria,': [59], 'representative': [61], 'definitions': [62], 'in': [63], 'field': [65], 'are': [66, 89], 'analyzed.': [67], 'A': [68], 'new': [69], 'is': [71, 93, 100], 'proposed,': [72], 'according': [73], 'it': [75, 92], 'intelligence': [76], 'means': [77], '“adaptation': [78], 'with': [79, 95], 'insufficient': [80], 'knowledge': [81], 'resources.”': [83], 'The': [84], 'implications': [85], 'this': [87, 103], 'discussed,': [90], 'compared': [94], 'other': [97], 'definitions.': [98], 'claimed': [101], 'sheds': [105], 'light': [106], 'on': [107], 'solution': [109], 'many': [111], 'existing': [112], 'problems': [113], 'sets': [115], 'sound': [117], 'foundation': [118], 'for': [119], 'field.': [121]}",2019,"['Adaptation (eye)', 'Field (mathematics)', 'Computer science', 'Simple (philosophy)', 'Foundation (evidence)', 'Path (computing)', 'Management science', 'Artificial intelligence', 'Boundary (topology)', 'Data science', 'Cognitive science', 'Epistemology', 'Mathematics', 'Psychology', 'Engineering', 'Political science', 'Philosophy', 'Law', 'Programming language', 'Pure mathematics', 'Mathematical analysis', 'Neuroscience']","Abstract This article systematically analyzes the problem of defining “artificial intelligence.” It starts by pointing out that a definition influences the path of the research, then establishes four criteria of a good working definition of a notion: being similar to its common usage, drawing a sharp boundary, leading to fruitful research, and as simple as possible. According to these criteria, the representative definitions in the field are analyzed. A new definition is proposed, according to it intelligence means “adaptation with insufficient knowledge and resources.” The implications of this definition are discussed, and it is compared with the other definitions. It is claimed that this definition sheds light on the solution of many existing problems and sets a sound foundation for the field."
https://openalex.org/W2959938226,Concepts of Artificial Intelligence for Computer-Assisted Drug Discovery,"{'Artificial': [0], 'intelligence': [1], '(AI),': [2], 'and,': [3], 'in': [4, 65, 95], 'particular,': [5], 'deep': [6], 'learning': [7, 25, 59, 81], 'as': [8], 'a': [9, 53, 127], 'subcategory': [10], 'of': [11, 20, 31, 37, 56, 62, 77, 87, 120], 'AI,': [12], 'provides': [13, 52], 'opportunities': [14], 'for': [15, 45, 133], 'the': [16, 70, 78, 83, 121], 'discovery': [17, 47, 90, 136], 'and': [18, 48, 61, 97, 106, 112, 118, 137], 'development': [19], 'innovative': [21], 'drugs.': [22], 'Various': [23], 'machine': [24, 58, 80], 'approaches': [26], 'have': [27, 41], 'recently': [28], '(re)emerged,': [29], 'some': [30, 74], 'which': [32, 40], 'may': [33], 'be': [34], 'considered': [35], 'instances': [36], 'domain-specific': [38], 'AI': [39], 'been': [42], 'successfully': [43], 'employed': [44], 'drug': [46, 103, 110, 135], 'design.': [49, 138], 'This': [50], 'review': [51], 'comprehensive': [54], 'portrayal': [55], 'these': [57], 'techniques': [60], 'their': [63], 'applications': [64, 94], 'medicinal': [66], 'chemistry.': [67], 'After': [68], 'introducing': [69], 'basic': [71], 'principles,': [72], 'alongside': [73], 'application': [75], 'notes,': [76], 'various': [79], 'algorithms,': [82], 'current': [84, 122], 'state-of-the': [85], 'art': [86], 'AI-assisted': [88, 134], 'pharmaceutical': [89], 'is': [91], 'discussed,': [92], 'including': [93], 'structure-': [96], 'ligand-based': [98], 'virtual': [99], 'screening,': [100], 'de': [101], 'novo': [102], 'design,': [104], 'physicochemical': [105], 'pharmacokinetic': [107], 'property': [108], 'prediction,': [109], 'repurposing,': [111], 'related': [113], 'aspects.': [114], 'Finally,': [115], 'several': [116], 'challenges': [117], 'limitations': [119], 'methods': [123], 'are': [124], 'summarized,': [125], 'with': [126], 'view': [128], 'to': [129], 'potential': [130], 'future': [131], 'directions': [132]}",2019,"['Drug discovery', 'Artificial intelligence', 'Virtual screening', 'Computer science', 'Repurposing', 'Chemistry', 'Data science', 'Machine learning', 'Engineering', 'Waste management', 'Biochemistry']","Artificial intelligence (AI), and, in particular, deep learning as a subcategory of AI, provides opportunities for the discovery and development of innovative drugs. Various machine learning approaches have recently (re)emerged, some of which may be considered instances of domain-specific AI which have been successfully employed for drug discovery and design. This review provides a comprehensive portrayal of these machine learning techniques and of their applications in medicinal chemistry. After introducing the basic principles, alongside some application notes, of the various machine learning algorithms, the current state-of-the art of AI-assisted pharmaceutical discovery is discussed, including applications in structure- and ligand-based virtual screening, de novo drug design, physicochemical and pharmacokinetic property prediction, drug repurposing, and related aspects. Finally, several challenges and limitations of the current methods are summarized, with a view to potential future directions for AI-assisted drug discovery and design."
https://openalex.org/W2950944546,A comprehensive review on automation in agriculture using artificial intelligence,"{'Agriculture': [0], 'automation': [1, 85, 204], 'is': [2, 15, 141], 'the': [3, 27, 43, 52, 64, 71, 73, 105, 147, 174, 177, 183, 189, 200], 'main': [4], 'concern': [5], 'and': [6, 22, 46, 69, 93, 124, 127, 159, 179, 223, 226], 'emerging': [7], 'subject': [8], 'for': [9, 29, 221], 'every': [10], 'country.': [11], 'The': [12, 207], 'world': [13], 'population': [14, 26], 'increasing': [16, 44], 'at': [17], 'a': [18, 67, 196, 211], 'very': [19], 'fast': [20], 'rate': [21], 'with': [23, 77], 'increase': [24, 173], 'in': [25, 58, 70, 163, 205, 218], 'need': [28, 144], 'food': [30], 'increases': [31], 'briskly.': [32], 'Traditional': [33], 'methods': [34], 'used': [35], 'by': [36, 54, 134], 'farmers': [37], ""aren't"": [38], 'sufficient': [39], 'enough': [40], 'to': [41, 50, 107, 145, 172, 194], 'serve': [42], 'demand': [45], 'so': [47], 'they': [48], 'have': [49], 'hamper': [51], 'soil': [53, 178, 184], 'using': [55, 228], 'harmful': [56, 152], 'pesticides': [57], 'an': [59, 142], 'intensified': [60], 'manner.': [61], 'This': [62, 80, 186], 'affects': [63], 'agricultural': [65, 164], 'practice': [66], 'lot': [68], 'end': [72], 'land': [74], 'remains': [75], 'barren': [76], 'no': [78], 'fertility.': [79, 185], 'paper': [81, 187, 208], 'talks': [82], 'about': [83, 199], 'different': [84, 137], 'practices': [86, 169], 'like': [87, 110, 149], 'IOT,': [88], 'Wireless': [89], 'Communications,': [90], 'Machine': [91, 235], 'learning': [92, 236], 'Artificial': [94], 'Intelligence,': [95], 'Deep': [96], 'learning.': [97], 'There': [98], 'are': [99, 103], 'some': [100], 'areas': [101], 'which': [102, 214], 'causing': [104], 'problems': [106, 130], 'agriculture': [108], 'field': [109], 'crop': [111], 'diseases,': [112], 'lack': [113, 121], 'of': [114, 122, 151, 161, 167, 191, 203], 'storage': [115], 'management,': [116, 120], 'pesticide': [117], 'control,': [118], 'weed': [119], 'irrigation': [123], 'water': [125], 'management': [126], 'all': [128], 'this': [129], 'can': [131, 215], 'be': [132, 216], 'solved': [133], 'above': [135], 'mentioned': [136], 'techniques.': [138], 'Today,': [139], 'there': [140], 'urgent': [143], 'decipher': [146], 'issues': [148], 'use': [150], 'pesticides,': [153], 'controlled': [154], 'irrigation,': [155], 'control': [156], 'on': [157], 'pollution': [158], 'effects': [160], 'environment': [162], 'practice.': [165], 'Automation': [166, 231], 'farming': [168], 'has': [170, 181], 'proved': [171], 'gain': [175], 'from': [176], 'also': [180, 209], 'strengthened': [182], 'surveys': [188], 'work': [190], 'many': [192], 'researchers': [193], 'get': [195], 'brief': [197], 'overview': [198], 'current': [201], 'implementation': [202], 'agriculture.': [206], 'discusses': [210], 'proposed': [212], 'system': [213], 'implemented': [217], 'botanical': [219], 'farm': [220], 'flower': [222], 'leaf': [224], 'identification': [225], 'watering': [227], 'IOT.': [229], 'Keywords:': [230], 'artificial': [232], 'intelligence,': [233], 'Irrigation,': [234]}",2019,"['Agriculture', 'Automation', 'Population', 'Agricultural engineering', 'Precision agriculture', 'Computer science', 'Business', 'Environmental planning', 'Engineering', 'Environmental science', 'Ecology', 'Biology', 'Medicine', 'Environmental health', 'Mechanical engineering']","Agriculture automation is the main concern and emerging subject for every country. The world population is increasing at a very fast rate and with increase in population the need for food increases briskly. Traditional methods used by farmers aren't sufficient enough to serve the increasing demand and so they have to hamper the soil by using harmful pesticides in an intensified manner. This affects the agricultural practice a lot and in the end the land remains barren with no fertility. This paper talks about different automation practices like IOT, Wireless Communications, Machine learning and Artificial Intelligence, Deep learning. There are some areas which are causing the problems to agriculture field like crop diseases, lack of storage management, pesticide control, weed management, lack of irrigation and water management and all this problems can be solved by above mentioned different techniques. Today, there is an urgent need to decipher the issues like use of harmful pesticides, controlled irrigation, control on pollution and effects of environment in agricultural practice. Automation of farming practices has proved to increase the gain from the soil and also has strengthened the soil fertility. This paper surveys the work of many researchers to get a brief overview about the current implementation of automation in agriculture. The paper also discusses a proposed system which can be implemented in botanical farm for flower and leaf identification and watering using IOT. Keywords: Automation artificial intelligence, Irrigation, Machine learning"
https://openalex.org/W2942193471,Artificial intelligence in education : challenges and opportunities for sustainable development,"{'Artificial': [0], 'Intelligence': [1], 'is': [2, 106, 206, 359, 421, 449, 623, 683, 740, 797, 825], 'a': [3, 67, 101, 284, 371, 567, 702, 715, 844], 'booming': [4], 'technological': [5, 582, 659], 'domain': [6], 'capable': [7], 'of': [8, 12, 42, 50, 61, 84, 104, 117, 135, 142, 152, 168, 184, 343, 348, 382, 417, 476, 534, 545, 570, 580, 593, 614, 640, 651, 676, 755, 759, 789, 840, 890, 923], 'altering': [9], 'every': [10], 'aspect': [11], 'our': [13, 763], 'social': [14, 80, 646], 'interactions.': [15], 'In': [16, 90], 'education,': [17, 232, 696, 756], 'AI': [18, 35, 65, 119, 173, 186, 217, 227, 344, 374, 454, 547, 574, 615, 630, 677, 693, 713, 721, 779, 802, 815, 865, 894, 924], 'has': [19, 120, 835], 'begun': [20], 'producing': [21], 'new': [22, 368, 425, 642, 671, 708, 915], 'teaching': [23], 'and': [24, 39, 79, 108, 137, 148, 198, 214, 221, 235, 255, 266, 297, 308, 327, 332, 373, 390, 406, 409, 444, 459, 497, 507, 510, 513, 518, 527, 537, 543, 550, 596, 607, 627, 645, 717, 720, 728, 744, 777, 850, 857, 863, 888, 905, 921], 'learning': [25, 179, 223, 520], 'solutions': [26, 260, 730], 'that': [27, 211, 530, 616, 673, 731, 812, 831], 'are': [28, 82, 330, 395, 485, 559, 637, 732, 750], 'now': [29], 'undergoing': [30], 'testing': [31], 'in': [32, 123, 127, 139, 200, 272, 316, 345, 384, 431, 548, 565, 587, 603, 631, 714, 734, 791, 803, 816, 820, 837, 843, 859, 925], 'different': [33, 322, 355], 'contexts.': [34], 'requires': [36], 'advanced': [37, 479], 'infrastructures': [38], 'an': [40, 317, 469, 554, 612, 688, 783, 910], 'ecosystem': [41, 613], 'thriving': [43], 'innovators,': [44], 'but': [45], 'what': [46, 105, 109], 'about': [47], 'the': [48, 59, 77, 85, 133, 140, 143, 153, 201, 321, 340, 357, 380, 399, 412, 418, 436, 466, 477, 505, 525, 535, 541, 581, 591, 649, 666, 753, 757, 787, 821, 829, 832, 918], 'urgencies': [49], 'developing': [51, 128, 202, 428, 566], 'countries?': [52], 'Will': [53], 'they': [54], 'have': [55, 600], 'to': [56, 69, 75, 156, 177, 194, 218, 231, 239, 287, 314, 336, 402, 423, 489, 585, 601, 610, 624, 664, 678, 684, 694, 711, 741, 769, 773, 785, 798, 872, 876, 913], 'wait': [57], 'for': [58, 282, 339, 370, 388, 427, 468, 553, 575, 629, 669, 687, 848, 927], '“luxury”': [60], 'AI?': [62], 'Or': [63], 'should': [64, 96, 531, 761, 781], 'be': [66, 97, 111, 175, 532, 662, 701, 762, 782, 809], 'priority': [68], 'tackle': [70, 490], 'as': [71, 73, 150, 249, 257, 398, 657], 'soon': [72], 'possible': [74], 'reduce': [76], 'digital': [78, 372, 385, 709], 'divide?These': [81], 'some': [83, 475, 502, 514], 'questions': [86], 'guiding': [87], 'this': [88, 91, 93, 169, 491, 588, 698], 'document.': [89], 'regard,': [92], 'urgent': [94], 'discussion': [95, 416, 900], 'taken': [98], 'up': [99], 'with': [100, 433, 648, 855, 909], 'clear': [102], 'picture': [103], 'happening': [107], 'can': [110, 174, 188, 228, 462, 808], 'done.': [112], 'This': [113], 'document': [114, 170, 907], 'gathers': [115], 'examples': [116, 183, 258, 353, 434], 'how': [118, 172, 185, 226, 725], 'been': [121], 'introduced': [122], 'education': [124, 190, 458, 509, 549, 690, 804, 817, 833, 873, 926], 'worldwide,': [125], 'particularly': [126], 'countries.': [129], 'It': [130, 181, 766], 'also': [131, 360, 500], 'sows': [132], 'seeds': [134], 'debates': [136], 'discussions': [138, 916], 'context': [141], '2019': [144], 'Mobile': [145], 'Learning': [146], 'Week': [147], 'beyond,': [149], 'part': [151, 448, 533], 'multiple': [154, 594], 'ways': [155], 'accomplish': [157], 'Sustainable': [158], 'Development': [159], 'Goal': [160], '4,': [161], 'which': [162, 325], 'targets': [163], 'education.': [164, 632], 'The': [165, 204, 415, 446, 561, 578, 620, 633, 737], 'first': [166, 562], 'section': [167, 205, 311, 358, 523], 'analyses': [171], 'used': [176], 'improve': [178, 195, 679, 774], 'outcomes.': [180], 'presents': [182], 'technology': [187], 'help': [189], 'systems': [191, 238, 291], 'use': [192, 712, 862], 'data': [193, 294, 746, 760, 775, 790, 860, 880, 886, 891], 'educational': [196, 290, 328, 334, 792, 841], 'equity': [197, 628], 'quality': [199, 743, 758], 'world.': [203], 'divided': [207, 361], 'into': [208, 362], 'two': [209, 363], 'topics': [210], 'address': [212], 'pedagogical': [213, 716], 'system-wide': [215], 'solutions:i)': [216], 'promote': [219], 'personalisation': [220], 'better': [222], 'outcomes,': [224], 'exploring': [225], 'favour': [229], 'access': [230, 871], 'collaborative': [233], 'environments': [234], 'intelligent': [236], 'tutoring': [237], 'support': [240], 'teachers.': [241], 'We': [242, 499], 'briefly': [243], 'introduce': [244], 'cases': [245, 300, 480, 503], 'from': [246, 262, 295, 301, 354, 411, 435, 481, 504, 516], 'countries': [247, 483, 636], 'such': [248, 397, 656], 'China,': [250], 'Uruguay,': [251], 'Brazil,': [252], 'South': [253, 495], 'Africa': [254], 'Kenya': [256], 'experimental': [259], 'conceived': [261], 'public': [263, 571, 899], 'policies,': [264], 'philanthropic': [265], 'private': [267], 'organisations.': [268], 'ii)': [269], 'Data': [270], 'analytics': [271], 'Education': [273], 'Management': [274], 'Information': [275], 'Systems': [276], '(EMIS).': [277], 'Here': [278, 472], 'we': [279, 473, 749], 'present': [280, 474, 501], 'opportunities': [281, 515], 'improving': [283], 'state’s': [285], 'capacity': [286], 'manage': [288], 'large-scale': [289], 'by': [292, 324], 'increasing': [293, 341], 'schools': [296, 432], 'learning,': [298], 'presenting': [299], 'United': [302, 439], 'Arab': [303], 'Emirates,': [304], 'Kenya,': [305], 'Bhutan,': [306], 'Kyrgyzstan': [307], 'Chile.The': [309], 'second': [310, 447, 621], '“Preparing': [312], 'learners': [313, 338], 'thrive': [315], 'AI-saturated': [318], 'future”': [319], 'explores': [320], 'means': [323], 'governments': [326], 'institutions': [329], 'rethinking': [331], 'reworking': [333], 'programmes': [335], 'prepare': [337, 465, 685], 'presence': [342], 'all': [346], 'aspects': [347], 'human': [349], 'activity.': [350], 'Based': [351], 'on': [352, 379, 452, 573, 801, 814, 884, 901], 'contexts,': [356], 'main': [364, 654], 'parts:': [365], 'i)': [366], '“A': [367], 'curriculum': [369], 'powered': [375], 'world”': [376], 'elaborates': [377], 'further': [378], 'importance': [381, 788], 'advancing': [383], 'competency': [386], 'frameworks': [387], 'teachers': [389, 686, 705, 726], 'students.': [391], 'Some': [392, 653], 'current': [393], 'initiatives': [394], 'presented': [396], '“Global': [400], 'Framework': [401], 'Measure': [403], 'Digital': [404], 'Literacy”': [405], '“ICT': [407], 'Competencies': [408], 'Standards': [410], 'Pedagogical': [413], 'Dimension”.': [414], 'curricular': [419], 'dimension': [420], 'broadened': [422], 'include': [424], 'experiences': [426], 'computational': [429], 'thinking': [430], 'European': [437], 'Union,': [438], 'Kingdom,': [440], 'Estonia,': [441], 'Argentina,': [442], 'Singapore': [443], 'Malaysia.ii)': [445], 'more': [450], 'focused': [451], 'strengthening': [453], 'capacities': [455], 'through': [456], 'post-basic': [457], 'training.': [460], 'How': [461], 'each': [463], 'country': [464], 'conditions': [467, 583, 668], 'AI-powered': [470, 555, 689], 'world?': [471], 'most': [478], 'developed': [482, 635], 'who': [484], 'generating': [486], 'comprehensive': [487, 568], 'plans': [488], 'question,': [492], 'namely': [493], 'France,': [494], 'Korea': [496], 'China.': [498], 'technical': [506], 'vocational': [508], 'training': [511], 'sector': [512, 834], 'non-formal': [517], 'informal': [519], 'scenarios.The': [521], 'last': [522], 'addresses': [524], 'challenges': [526, 558], 'policy': [528, 572], 'implications': [529], 'global': [536], 'local': [538], 'conversations': [539], 'regarding': [540, 870], 'possibilities': [542, 920], 'risks': [544, 922], 'introducing': [546], 'preparing': [551, 692], 'students': [552], 'context.': [556], 'Six': [557], 'presented:': [560], 'challenge': [563, 622, 682, 739, 796, 853], 'lies': [564], 'view': [569], 'sustainable': [576, 618, 733, 928], 'development.': [577, 619, 929], 'complexity': [579], 'needed': [584], 'advance': [586], 'field': [589], 'require': [590, 898], 'alignment': [592], 'factors': [595], 'institutions.': [597], 'Public': [598], 'policies': [599], 'work': [602, 727], 'partnership': [604], 'at': [605, 638], 'international': [606], 'national': [608], 'levels': [609], 'create': [611, 729, 914], 'serves': [617], 'ensure': [625], 'inclusion': [626], 'least': [634], 'risk': [639], 'suffering': [641], 'technological,': [643], 'economic': [644], 'divides': [647], 'development': [650], 'AI.': [652], 'obstacles': [655], 'basic': [658, 667], 'infrastructure': [660], 'must': [661, 699, 706, 723], 'faced': [663], 'establish': [665], 'implementing': [670], 'strategies': [672], 'take': [674], 'advantage': [675], 'learning.The': [680], 'third': [681], 'while': [691], 'understand': [695], 'though': [697], 'nevertheless': [700, 826], 'two-way': [703], 'road:': [704], 'learn': [707, 724], 'skills': [710], 'meaningful': [718], 'way': [719, 846], 'developers': [722], 'real-life': [735], 'environments.': [736], 'fourth': [738], 'develop': [742, 770], 'inclusive': [745], 'systems.': [747], 'If': [748], 'headed': [751], 'towards': [752], 'datafication': [754], 'chief': [764], 'concern.': [765], '́s': [767], 'essential': [768], 'state': [771], 'capabilities': [772], 'collection': [776], 'systematisation.': [778], 'developments': [780], 'opportunity': [784], 'increase': [786, 819], 'system': [793], 'management.The': [794], 'fifth': [795], 'make': [799], 'research': [800, 813, 842], 'significant.': [805], 'While': [806], 'it': [807, 824], 'reasonably': [810], 'expected': [811], 'will': [818, 896], 'coming': [822], 'years,': [823], 'worth': [827], 'recalling': [828], 'difficulties': [830], 'had': [836], 'taking': [838], 'stock': [839], 'significant': [845], 'both': [847], 'practice': [849], 'policy-making.The': [851], 'sixth': [852], 'deals': [854], 'ethics': [856], 'transparency': [858, 904], 'collection,': [861], 'dissemination.': [864], 'opens': [866], 'many': [867], 'ethical': [868], 'concerns': [869], 'system,': [874], 'recommendations': [875], 'individual': [877], 'students,': [878], 'personal': [879], 'concentration,': [881], 'liability,': [882], 'impact': [883], 'work,': [885], 'privacy': [887], 'ownership': [889], 'feeding': [892], 'algorithms.': [893], 'regulation': [895], 'thus': [897], 'ethics,': [902], 'accountability,': [903], 'security.The': [906], 'ends': [908], 'open': [911], 'invitation': [912], 'around': [917], 'uses,': [919]}",2019,"['Sustainable development', 'Engineering ethics', 'Business', 'Political science', 'Engineering', 'Law']","Artificial Intelligence is a booming technological domain capable of altering every aspect of our social interactions. In education, AI has begun producing new teaching and learning solutions that are now undergoing testing in different contexts. AI requires advanced infrastructures and an ecosystem of thriving innovators, but what about the urgencies of developing countries? Will they have to wait for the “luxury” of AI? Or should AI be a priority to tackle as soon as possible to reduce the digital and social divide?These are some of the questions guiding this document. In this regard, this urgent discussion should be taken up with a clear picture of what is happening and what can be done. This document gathers examples of how AI has been introduced in education worldwide, particularly in developing countries. It also sows the seeds of debates and discussions in the context of the 2019 Mobile Learning Week and beyond, as part of the multiple ways to accomplish Sustainable Development Goal 4, which targets education. The first section of this document analyses how AI can be used to improve learning outcomes. It presents examples of how AI technology can help education systems use data to improve educational equity and quality in the developing world. The section is divided into two topics that address pedagogical and system-wide solutions:i) AI to promote personalisation and better learning outcomes, exploring how AI can favour access to education, collaborative environments and intelligent tutoring systems to support teachers. We briefly introduce cases from countries such as China, Uruguay, Brazil, South Africa and Kenya as examples experimental solutions conceived from public policies, philanthropic and private organisations. ii) Data analytics in Education Management Information Systems (EMIS). Here we present opportunities for improving a state’s capacity to manage large-scale educational systems by increasing data from schools and learning, presenting cases from United Arab Emirates, Kenya, Bhutan, Kyrgyzstan and Chile.The second section “Preparing learners to thrive in an AI-saturated future” explores the different means by which governments and educational institutions are rethinking and reworking educational programmes to prepare learners for the increasing presence of AI in all aspects of human activity. Based on examples from different contexts, the section is also divided into two main parts: i) “A new curriculum for a digital and AI powered world” elaborates further on the importance of advancing in digital competency frameworks for teachers and students. Some current initiatives are presented such as the “Global Framework to Measure Digital Literacy” and “ICT Competencies and Standards from the Pedagogical Dimension”. The discussion of the curricular dimension is broadened to include new experiences for developing computational thinking in schools with examples from the European Union, United Kingdom, Estonia, Argentina, Singapore and Malaysia.ii) The second part is more focused on strengthening AI capacities through post-basic education and training. How can each country prepare the conditions for an AI-powered world? Here we present some of the most advanced cases from developed countries who are generating comprehensive plans to tackle this question, namely France, South Korea and China. We also present some cases from the technical and vocational education and training sector and some opportunities from non-formal and informal learning scenarios.The last section addresses the challenges and policy implications that should be part of the global and local conversations regarding the possibilities and risks of introducing AI in education and preparing students for an AI-powered context. Six challenges are presented: The first challenge lies in developing a comprehensive view of public policy on AI for sustainable development. The complexity of the technological conditions needed to advance in this field require the alignment of multiple factors and institutions. Public policies have to work in partnership at international and national levels to create an ecosystem of AI that serves sustainable development. The second challenge is to ensure inclusion and equity for AI in education. The least developed countries are at risk of suffering new technological, economic and social divides with the development of AI. Some main obstacles such as basic technological infrastructure must be faced to establish the basic conditions for implementing new strategies that take advantage of AI to improve learning.The third challenge is to prepare teachers for an AI-powered education while preparing AI to understand education, though this must nevertheless be a two-way road: teachers must learn new digital skills to use AI in a pedagogical and meaningful way and AI developers must learn how teachers work and create solutions that are sustainable in real-life environments. The fourth challenge is to develop quality and inclusive data systems. If we are headed towards the datafication of education, the quality of data should be our chief concern. It ́s essential to develop state capabilities to improve data collection and systematisation. AI developments should be an opportunity to increase the importance of data in educational system management.The fifth challenge is to make research on AI in education significant. While it can be reasonably expected that research on AI in education will increase in the coming years, it is nevertheless worth recalling the difficulties that the education sector has had in taking stock of educational research in a significant way both for practice and policy-making.The sixth challenge deals with ethics and transparency in data collection, use and dissemination. AI opens many ethical concerns regarding access to education system, recommendations to individual students, personal data concentration, liability, impact on work, data privacy and ownership of data feeding algorithms. AI regulation will thus require public discussion on ethics, accountability, transparency and security.The document ends with an open invitation to create new discussions around the uses, possibilities and risks of AI in education for sustainable development."
https://openalex.org/W3148271110,The role of artificial intelligence in healthcare: a structured literature review,"{'Abstract': [0], 'Background/Introduction': [1], 'Artificial': [2], 'intelligence': [3], '(AI)': [4], 'in': [5, 94, 136, 200], 'the': [6, 51, 78, 82, 92, 119, 123, 141, 201], 'healthcare': [7, 202], 'sector': [8], 'is': [9, 97], 'receiving': [10], 'attention': [11], 'from': [12, 24, 58, 81], 'researchers': [13, 52, 189], 'and': [14, 31, 35, 46, 64, 72, 109, 111, 118, 145, 159, 176, 183, 190, 194], 'health': [15, 36, 102, 157, 191], 'professionals.': [16], 'Few': [17], 'previous': [18], 'studies': [19], 'have': [20], 'investigated': [21], 'this': [22, 95], 'topic': [23], 'a': [25, 138, 160], 'multi-disciplinary': [26], 'perspective,': [27], 'including': [28], 'accounting,': [29], 'business': [30], 'management,': [32, 104], 'decision': [33], 'sciences': [34], 'professions.': [37], 'Methods': [38], 'The': [39, 60, 88, 114, 150], 'structured': [40], 'literature': [41, 93, 151], 'review': [42], 'with': [43], 'its': [44], 'reliable': [45], 'replicable': [47], 'research': [48, 163, 197], 'protocol': [49], 'allowed': [50], 'to': [53, 67], 'extract': [54], '288': [55], 'peer-reviewed': [56], 'papers': [57], 'Scopus.': [59], 'authors': [61], 'used': [62], 'qualitative': [63], 'quantitative': [65], 'variables': [66], 'analyse': [68], 'authors,': [69], 'journals,': [70], 'keywords,': [71], 'collaboration': [73], 'networks': [74], 'among': [75], 'researchers.': [76], 'Additionally,': [77], 'paper': [79], 'benefited': [80], 'Bibliometrix': [83], 'R': [84], 'software': [85], 'package.': [86], 'Results': [87], 'investigation': [89], 'showed': [90], 'that': [91, 131, 164], 'field': [96], 'emerging.': [98], 'It': [99], 'focuses': [100], 'on': [101, 198], 'services': [103, 158], 'predictive': [105], 'medicine,': [106], 'patient': [107], 'data': [108, 177], 'diagnostics,': [110], 'clinical': [112], 'decision-making.': [113], 'United': [115, 120], 'States,': [116], 'China,': [117], 'Kingdom': [121], 'contributed': [122], 'highest': [124], 'number': [125], 'of': [126, 143, 162], 'studies.': [127], 'Keyword': [128], 'analysis': [129, 182], 'revealed': [130], 'AI': [132, 154, 172, 199], 'can': [133, 187], 'support': [134], 'physicians': [135], 'making': [137], 'diagnosis,': [139], 'predicting': [140], 'spread': [142], 'diseases': [144], 'customising': [146], 'treatment': [147], 'paths.': [148], 'Conclusions': [149], 'reveals': [152], 'several': [153], 'applications': [155], 'for': [156, 180], 'stream': [161], 'has': [165], 'not': [166], 'fully': [167], 'been': [168], 'covered.': [169], 'For': [170], 'instance,': [171], 'projects': [173], 'require': [174], 'skills': [175], 'quality': [178], 'awareness': [179], 'data-intensive': [181], 'knowledge-based': [184], 'management.': [185], 'Insights': [186], 'help': [188], 'professionals': [192], 'understand': [193], 'address': [195], 'future': [196], 'field.': [203]}",2021,"['Health informatics', 'Health care', 'Knowledge management', 'Data science', 'Protocol (science)', 'Scopus', 'Field (mathematics)', 'Peer review', 'Systematic review', 'Computer science', 'Medical education', 'MEDLINE', 'Medicine', 'Nursing', 'Alternative medicine', 'Public health', 'Pure mathematics', 'Political science', 'Law', 'Pathology', 'Economics', 'Mathematics', 'Economic growth']","Abstract Background/Introduction Artificial intelligence (AI) in the healthcare sector is receiving attention from researchers and health professionals. Few previous studies have investigated this topic from a multi-disciplinary perspective, including accounting, business and management, decision sciences and health professions. Methods The structured literature review with its reliable and replicable research protocol allowed the researchers to extract 288 peer-reviewed papers from Scopus. The authors used qualitative and quantitative variables to analyse authors, journals, keywords, and collaboration networks among researchers. Additionally, the paper benefited from the Bibliometrix R software package. Results The investigation showed that the literature in this field is emerging. It focuses on health services management, predictive medicine, patient data and diagnostics, and clinical decision-making. The United States, China, and the United Kingdom contributed the highest number of studies. Keyword analysis revealed that AI can support physicians in making a diagnosis, predicting the spread of diseases and customising treatment paths. Conclusions The literature reveals several AI applications for health services and a stream of research that has not fully been covered. For instance, AI projects require skills and data quality awareness for data-intensive analysis and knowledge-based management. Insights can help researchers and health professionals understand and address future research on AI in the healthcare field."
https://openalex.org/W3013294478,Checklist for Artificial Intelligence in Medical Imaging (CLAIM): A Guide for Authors and Reviewers,"{'T': [0], 'he': [1], 'advent': [2], 'of': [3, 20, 28, 37, 69, 80, 94, 103, 113, 128, 153, 191, 227], 'deep': [4], 'neural': [5], 'networks': [6], 'as': [7, 248], 'a': [8, 17, 48, 167, 170, 249], 'new': [9], 'artifi-': [10], 'cial': [11], 'intelligence': [12], '(AI)': [13], 'technique': [14], 'has': [15, 121, 221], 'engendered': [16], 'large': [18], 'number': [19, 79], 'medical': [21, 25, 132, 195, 230], 'applications,': [22], 'particularly': [23], 'in': [24, 33, 56, 106, 140, 169, 194, 204, 229, 255], 'imaging.Such': [26], 'applications': [27, 226], 'AI': [29, 141, 192, 203, 228], 'must': [30, 44, 51], 'remain': [31], 'grounded': [32], 'the': [34, 53, 64, 70, 76, 90, 101, 126, 174, 200, 217, 262], 'fundamental': [35], 'tenets': [36], 'science': [38], 'and': [39, 47, 67, 72, 110, 189, 209, 220, 239], 'scientific': [40, 49], 'publication': [41, 50], '(1).Scientific': [42], 'results': [43], 'be': [45, 246], 'reproducible,': [46], 'describe': [52], ""authors'"": [54], 'work': [55], 'sufficient': [57], 'detail': [58], 'to': [59, 62, 74, 124, 137, 142, 163, 224, 252], 'enable': [60], 'readers': [61], 'determine': [63], 'rigor,': [65], 'quality,': [66], 'generalizability': [68], 'work,': [71], 'potentially': [73], 'reproduce': [75], ""work's"": [77], 'results.A': [78], 'valuable': [81], 'manuscript': [82, 183], 'checklists': [83], 'have': [84, 134, 157, 161], 'come': [85], 'into': [86, 166], 'widespread': [87], 'use,': [88], 'including': [89], 'Standards': [91, 112], 'for': [92, 150, 202], 'Reporting': [93, 102, 114], 'Diagnostic': [95], 'Accuracy': [96], 'Studies': [97], '(STARD)': [98], '(2-5),': [99], 'Strengthening': [100], 'Observational': [104], 'studies': [105, 130], 'Epidemiology': [107], '(STROBE)': [108], '(6),': [109], 'Consolidated': [111], 'Trials': [115], '(CONSORT)': [116], '(7,8).A': [117], 'radiomics': [118, 129], 'quality': [119, 127], 'score': [120], 'been': [122, 158, 222], 'proposed': [123, 159], 'assess': [125], '(9).Peer-reviewed': [131], 'journals': [133], 'an': [135], 'opportunity': [136], 'connect': [138], 'innovations': [139], 'clinical': [143], 'practice': [144], 'through': [145], 'rigorous': [146], 'validation': [147], '(10).Various': [148], 'guidelines': [149, 177], 'reporting': [151], 'evaluation': [152], 'machine': [154], 'learning': [155], 'models': [156], '(11)(12)(13)(14).We': [160], 'sought': [162], 'codify': [164], 'these': [165], 'checklist': [168, 263], 'format': [171], 'concordant': [172], 'with': [173, 264], 'EQUATOR': [175], 'Network': [176], '(15,16)': [178], 'that': [179, 232], 'also': [180], 'incorporates': [181], 'general': [182], 'review': [184], 'criteria': [185], '(17,18).To': [186], 'aid': [187], 'authors': [188, 254], 'reviewers': [190], 'manuscripts': [193], 'imaging,': [196], 'we': [197], 'propose': [198], 'CLAIM,': [199], 'Checklist': [201], 'Medical': [205], 'Imaging': [206], '(see': [207], 'Table': [208], 'downloadable': [210], 'Word': [211], 'document': [212], '[supplement]).CLAIM': [213], 'is': [214], 'modeled': [215], 'after': [216], 'STARD': [218], 'guideline': [219], 'extended': [223], 'address': [225], 'imaging': [231], 'include': [233], 'classification,': [234], 'image': [235], 'reconstruction,': [236], 'text': [237, 259], 'analysis,': [238], 'workflow': [240], 'optimization.The': [241], 'elements': [242], 'described': [243], 'here': [244], 'should': [245], 'viewed': [247], '""best': [250], 'practice""': [251], 'guide': [253], 'presenting': [256], 'their': [257], 'research.The': [258], 'below': [260], 'amplifies': [261], 'greater': [265], 'detail.': [266]}",2020,"['Checklist', 'Generalizability theory', 'Guideline', 'Computer science', 'Observational study', 'Quality (philosophy)', 'Medical physics', 'Medical imaging', 'Artificial intelligence', 'Medical education', 'Medicine', 'Psychology', 'Pathology', 'Epistemology', 'Philosophy', 'Developmental psychology', 'Cognitive psychology']","T he advent of deep neural networks as a new artifi- cial intelligence (AI) technique has engendered a large number of medical applications, particularly in medical imaging.Such applications of AI must remain grounded in the fundamental tenets of science and scientific publication (1).Scientific results must be reproducible, and a scientific publication must describe the authors' work in sufficient detail to enable readers to determine the rigor, quality, and generalizability of the work, and potentially to reproduce the work's results.A number of valuable manuscript checklists have come into widespread use, including the Standards for Reporting of Diagnostic Accuracy Studies (STARD) (2-5), Strengthening the Reporting of Observational studies in Epidemiology (STROBE) (6), and Consolidated Standards of Reporting Trials (CONSORT) (7,8).A radiomics quality score has been proposed to assess the quality of radiomics studies (9).Peer-reviewed medical journals have an opportunity to connect innovations in AI to clinical practice through rigorous validation (10).Various guidelines for reporting evaluation of machine learning models have been proposed (11)(12)(13)(14).We have sought to codify these into a checklist in a format concordant with the EQUATOR Network guidelines (15,16) that also incorporates general manuscript review criteria (17,18).To aid authors and reviewers of AI manuscripts in medical imaging, we propose CLAIM, the Checklist for AI in Medical Imaging (see Table and downloadable Word document [supplement]).CLAIM is modeled after the STARD guideline and has been extended to address applications of AI in medical imaging that include classification, image reconstruction, text analysis, and workflow optimization.The elements described here should be viewed as a ""best practice"" to guide authors in presenting their research.The text below amplifies the checklist with greater detail."
https://openalex.org/W3034344071,Human Compatible: Artificial Intelligence and the Problem of Control,"{'""In': [0], 'the': [1, 61, 68, 79, 96, 113, 130, 181, 235, 246, 249, 261], 'popular': [2], 'imagination,': [3], 'superhuman': [4, 107, 135], 'artificial': [5], 'intelligence': [6, 71], 'is': [7, 28, 255, 260], 'an': [8], 'approaching': [9], 'tidal': [10], 'wave': [11], 'that': [12, 48, 99, 161, 212, 263], 'threatens': [13], 'not': [14, 201, 256], 'just': [15, 257], 'jobs': [16], 'and': [17, 26, 32, 74, 94, 134, 195, 216], 'human': [18, 182, 239], 'relationships,': [19], 'but': [20, 54], 'civilization': [21], 'itself.': [22], 'Conflict': [23], 'between': [24], 'humans': [25, 73, 115], 'machines': [27, 173, 190, 211], 'seen': [29], 'as': [30], 'inevitable': [31], 'its': [33], 'outcome': [34], 'all': [35], 'too': [36], 'predictable.': [37], 'In': [38, 219], 'this': [39, 49], 'groundbreaking': [40], 'book,': [41], 'distinguished': [42], 'AI': [43, 59, 97, 136, 165, 232, 254], 'researcher': [44], 'Stuart': [45], 'Russell': [46, 64, 159, 227], 'argues': [47], 'scenario': [50], 'can': [51, 83, 149, 163], 'be': [52, 177, 192, 234, 245], 'avoided,': [53], 'only': [55], 'if': [56], 'we': [57, 82, 105, 138, 150, 162], 'rethink': [58], 'from': [60, 85, 122], 'ground': [62], 'up.': [63], 'begins': [65], 'by': [66], 'exploring': [67], 'idea': [69], 'of': [70, 251, 267], 'in': [72, 75, 230, 238], 'machines.': [76], 'He': [77, 109], 'describes': [78], 'near-term': [80], 'benefits': [81], 'expect,': [84], 'intelligent': [86], 'personal': [87], 'assistants': [88], 'to': [89, 102, 119, 126, 171, 176, 187, 197, 209], 'vastly': [90], 'accelerated': [91], 'scientific': [92], 'research,': [93], 'outlines': [95], 'breakthroughs': [98, 132], 'still': [100], 'have': [101, 140, 155], 'happen': [103], 'before': [104], 'reach': [106], 'AI.': [108], 'also': [110, 244], 'spells': [111], 'out': [112], 'ways': [114], 'are': [116, 174, 185, 213], 'already': [117], 'finding': [118], 'misuse': [120], 'AI,': [121], 'lethal': [123], 'autonomous': [124], 'weapons': [125], 'viral': [127], 'sabotage.': [128], 'If': [129], 'predicted': [131], 'occur': [133], 'emerges,': [137], 'will': [139], 'created': [141], 'entities': [142], 'far': [143], 'more': [144], 'powerful': [145], 'than': [146], 'ourselves.': [147], 'How': [148], 'ensure': [151], 'they': [152, 184], 'never,': [153], 'ever,': [154], 'power': [156], 'over': [157, 253], 'us?': [158], 'suggests': [160], 'rebuild': [164], 'on': [166], 'a': [167, 220, 265], 'new': [168, 204], 'foundation,': [169], 'according': [170], 'which': [172], 'designed': [175], 'inherently': [178], 'uncertain': [179], 'about': [180], 'preferences': [183], 'required': [186], 'satisfy.': [188], 'Such': [189], 'would': [191, 206, 233], 'humble,': [193], 'altruistic,': [194], 'committed': [196], 'pursue': [198], 'our': [199], 'objectives,': [200], 'theirs.': [202], 'This': [203], 'foundation': [205], 'allow': [207], 'us': [208], 'create': [210], 'provably': [214, 217], 'deferential': [215], 'beneficial.': [218], '2014': [221], 'editorial': [222], 'co-authored': [223], 'with': [224], 'Stephen': [225], 'Hawking,': [226], 'wrote,': [228], '""Success': [229], 'creating': [231], 'biggest': [236], 'event': [237], 'history.': [240], 'Unfortunately,': [241], 'it': [242, 259], 'might': [243], 'last.""': [247], 'Solving': [248], 'problem': [250], 'control': [252], 'possible;': [258], 'key': [262], 'unlocks': [264], 'future': [266], 'unlimited': [268], 'promise""--': [269]}",2019,"['Humanity', 'Dream', 'Control (management)', 'Existentialism', 'Artificial intelligence', 'Event (particle physics)', 'Computer science', 'Operations research', 'Environmental ethics', 'Political science', 'Psychology', 'Law', 'Engineering', 'Philosophy', 'Neuroscience', 'Physics', 'Quantum mechanics']","""In the popular imagination, superhuman artificial intelligence is an approaching tidal wave that threatens not just jobs and human relationships, but civilization itself. Conflict between humans and machines is seen as inevitable and its outcome all too predictable. In this groundbreaking book, distinguished AI researcher Stuart Russell argues that this scenario can be avoided, but only if we rethink AI from the ground up. Russell begins by exploring the idea of intelligence in humans and in machines. He describes the near-term benefits we can expect, from intelligent personal assistants to vastly accelerated scientific research, and outlines the AI breakthroughs that still have to happen before we reach superhuman AI. He also spells out the ways humans are already finding to misuse AI, from lethal autonomous weapons to viral sabotage. If the predicted breakthroughs occur and superhuman AI emerges, we will have created entities far more powerful than ourselves. How can we ensure they never, ever, have power over us? Russell suggests that we can rebuild AI on a new foundation, according to which machines are designed to be inherently uncertain about the human preferences they are required to satisfy. Such machines would be humble, altruistic, and committed to pursue our objectives, not theirs. This new foundation would allow us to create machines that are provably deferential and provably beneficial. In a 2014 editorial co-authored with Stephen Hawking, Russell wrote, ""Success in creating AI would be the biggest event in human history. Unfortunately, it might also be the last."" Solving the problem of control over AI is not just possible; it is the key that unlocks a future of unlimited promise""--"
https://openalex.org/W2894468641,Artificial Intelligence trends in education: a narrative overview,"{'Digital': [0], 'technologies': [1, 51], 'have': [2], 'already': [3], 'become': [4], 'an': [5], 'internal': [6], 'part': [7], 'of': [8, 41, 49, 98], 'our': [9], 'life.': [10], 'They': [11], 'change': [12], 'the': [13, 53, 90, 100], 'way': [14], 'we': [15, 21, 28, 68, 92], 'are': [16], 'looking': [17], 'for': [18], 'information,': [19], 'how': [20, 27, 99], 'communicate': [22], 'with': [23], 'each': [24], 'other,': [25], 'even': [26], 'behave.': [29], 'This': [30], 'transformation': [31], 'applies': [32], 'to': [33, 45, 52, 57], 'many': [34], 'areas,': [35], 'including': [36], 'education.': [37], 'The': [38], 'main': [39], 'objective': [40], 'this': [42], 'article': [43], 'is': [44], 'identify': [46], 'prospective': [47], 'impact': [48], 'artificial': [50], 'study': [54], 'process': [55], 'and': [56, 84], 'predict': [58], 'possible': [59, 96], 'changes': [60], 'in': [61], 'educational': [62, 73], 'landscape.': [63, 107], 'In': [64], 'presented': [65], 'literature': [66], 'review': [67], 'considered': [69], 'four': [70], 'categories:': [71], 'customized': [72], 'content,': [74], 'innovative': [75], 'teaching': [76], 'methods,': [77], 'technology': [78], 'enhanced': [79], 'assessment,': [80], 'communication': [81], 'between': [82], 'student': [83], 'lecturer.': [85], 'Having': [86], 'reviewed': [87], 'publications': [88], 'on': [89], 'subject': [91], 'present': [93], 'here': [94], 'a': [95], 'picture': [97], 'Artificial': [101], 'Intelligence': [102], '(AI)': [103], 'will': [104], 'reshape': [105], 'education': [106]}",2018,"['Computer science', 'Process (computing)', 'Narrative', 'Digital transformation', 'Subject (documents)', 'Information and Communications Technology', 'Data science', 'Artificial intelligence', 'World Wide Web', 'Linguistics', 'Operating system', 'Philosophy']","Digital technologies have already become an internal part of our life. They change the way we are looking for information, how we communicate with each other, even how we behave. This transformation applies to many areas, including education. The main objective of this article is to identify prospective impact of artificial technologies to the study process and to predict possible changes in educational landscape. In presented literature review we considered four categories: customized educational content, innovative teaching methods, technology enhanced assessment, communication between student and lecturer. Having reviewed publications on the subject we present here a possible picture of how the Artificial Intelligence (AI) will reshape education landscape."
https://openalex.org/W3182546273,Explainable artificial intelligence: an analytical review,"{'Abstract': [0], 'This': [1, 85], 'paper': [2, 33], 'provides': [3], 'a': [4, 36, 41], 'brief': [5, 37], 'analytical': [6], 'review': [7], 'of': [8, 17, 23, 50, 59, 63, 96], 'the': [9, 15, 21, 45, 54, 70], 'current': [10], 'state‐of‐the‐art': [11], 'in': [12, 20, 26, 48], 'relation': [13], 'to': [14, 69], 'explainability': [16, 51], 'artificial': [18], 'intelligence': [19], 'context': [22], 'recent': [24], 'advances': [25], 'machine': [27], 'learning': [28], 'and': [29, 40, 43, 76, 98], 'deep': [30], 'learning.': [31], 'The': [32], 'starts': [34], 'with': [35], 'historical': [38], 'introduction': [39], 'taxonomy,': [42], 'formulates': [44], 'main': [46], 'challenges': [47], 'terms': [49], 'building': [52], 'on': [53], 'recently': [55], 'formulated': [56], 'National': [57], 'Institute': [58], 'Standards': [60], 'four': [61], 'principles': [62], 'explainability.': [64], 'Recently': [65], 'published': [66], 'methods': [67], 'related': [68], 'topic': [71], 'are': [72, 83], 'then': [73], 'critically': [74], 'reviewed': [75], 'analyzed.': [77], 'Finally,': [78], 'future': [79], 'directions': [80], 'for': [81], 'research': [82], 'suggested.': [84], 'article': [86], 'is': [87], 'categorized': [88], 'under:': [89], 'Technologies': [90], '&gt;': [91, 100], 'Artificial': [92], 'Intelligence': [93], 'Fundamental': [94], 'Concepts': [95], 'Data': [97], 'Knowledge': [99], 'Explainable': [101], 'AI': [102]}",2021,"['Artificial intelligence', 'Computer science', 'Context (archaeology)', 'Taxonomy (biology)', 'Relation (database)', 'Applications of artificial intelligence', 'Management science', 'Engineering', 'Data mining', 'Botany', 'Paleontology', 'Biology']","Abstract This paper provides a brief analytical review of the current state‐of‐the‐art in relation to the explainability of artificial intelligence in the context of recent advances in machine learning and deep learning. The paper starts with a brief historical introduction and a taxonomy, and formulates the main challenges in terms of explainability building on the recently formulated National Institute of Standards four principles of explainability. Recently published methods related to the topic are then critically reviewed and analyzed. Finally, future directions for research are suggested. This article is categorized under: Technologies &gt; Artificial Intelligence Fundamental Concepts of Data and Knowledge &gt; Explainable AI"
https://openalex.org/W2583955450,Applications of artificial intelligence in intelligent manufacturing: a review,"{'Based': [0], 'on': [1, 79], 'research': [2], 'into': [3], 'the': [4, 12, 20, 27, 41, 47, 54, 80, 95, 106, 117], 'applications': [5], 'of': [6, 23, 30, 46, 56, 66, 82, 97, 119], 'artificial': [7], 'intelligence': [8], '(AI)': [9], 'technology': [10, 76, 84], 'in': [11, 15, 26, 40, 53, 109, 121, 124], 'manufacturing': [13, 48, 70, 75, 99, 111, 123], 'industry': [14], 'recent': [16], 'years,': [17], 'we': [18], 'analyze': [19], 'rapid': [21], 'development': [22, 55, 108], 'core': [24], 'technologies': [25], 'new': [28, 61], 'era': [29], ""'Internet"": [31], 'plus': [32], ""AI',"": [33], 'which': [34], 'is': [35, 112], 'triggering': [36], 'a': [37], 'great': [38], 'change': [39], 'models,': [42, 62], 'means,': [43, 63], 'and': [44, 64, 73, 89, 103], 'ecosystems': [45], 'industry,': [49, 102], 'as': [50, 52], 'well': [51], 'AI.': [57], 'We': [58], 'then': [59], 'propose': [60], 'forms': [65], 'intelligent': [67, 69, 74, 98, 110, 122], 'manufacturing,': [68, 88], 'system': [71], 'architecture,': [72], 'system,': [77], 'based': [78], 'integration': [81], 'AI': [83, 120], 'with': [85], 'information': [86], 'communications,': [87], 'related': [90], 'product': [91], 'technology.': [92], 'Moreover,': [93], 'from': [94], 'perspectives': [96], 'application': [100, 104, 118], 'technology,': [101], 'demonstration,': [105], 'current': [107], 'discussed.': [113], 'Finally,': [114], 'suggestions': [115], 'for': [116], 'China': [125], 'are': [126], 'presented.': [127]}",2017,"['Manufacturing engineering', 'Computer-integrated manufacturing', 'Manufacturing', 'Process development execution system', 'Advanced manufacturing', 'Integrated Computer-Aided Manufacturing', 'Smart manufacturing', 'Computer science', 'Industry 4.0', 'Engineering', 'Systems engineering', 'Business', 'Embedded system', 'Marketing']","Based on research into the applications of artificial intelligence (AI) technology in the manufacturing industry in recent years, we analyze the rapid development of core technologies in the new era of 'Internet plus AI', which is triggering a great change in the models, means, and ecosystems of the manufacturing industry, as well as in the development of AI. We then propose new models, means, and forms of intelligent manufacturing, intelligent manufacturing system architecture, and intelligent manufacturing technology system, based on the integration of AI technology with information communications, manufacturing, and related product technology. Moreover, from the perspectives of intelligent manufacturing application technology, industry, and application demonstration, the current development in intelligent manufacturing is discussed. Finally, suggestions for the application of AI in intelligent manufacturing in China are presented."
https://openalex.org/W3033928040,An Overview of Artificial Intelligence Applications for Power Electronics,"{'This': [0, 90], 'article': [1, 91], 'gives': [2], 'an': [3, 95], 'overview': [4], 'of': [5, 46, 49, 85], 'the': [6, 73, 83, 99], 'artificial': [7], 'intelligence': [8], '(AI)': [9], 'applications': [10, 45], 'for': [11, 87, 102], 'power': [12, 88], 'electronic': [13], 'systems.': [14], 'The': [15, 44], 'three': [16], 'distinctive': [17], 'life-cycle': [18], 'phases,': [19], 'design,': [20], 'control,': [21], 'and': [22, 40, 61, 79], 'maintenance': [23], 'are': [24, 51, 54], 'correlated': [25], 'with': [26], 'one': [27], 'or': [28], 'more': [29], 'tasks': [30], 'to': [31, 71], 'be': [32], 'addressed': [33], 'by': [34, 94], 'AI,': [35], 'including': [36], 'optimization,': [37], 'classification,': [38], 'regression,': [39], 'data': [41], 'structure': [42], 'exploration.': [43], 'four': [47], 'categories': [48], 'AI': [50, 86], 'discussed,': [52], 'which': [53], 'expert': [55], 'system,': [56], 'fuzzy': [57], 'logic,': [58], 'metaheuristic': [59], 'method,': [60], 'machine': [62], 'learning.': [63], 'More': [64], 'than': [65], '500': [66], 'publications': [67, 101], 'have': [68], 'been': [69], 'reviewed': [70], 'identify': [72], 'common': [74], 'understandings,': [75], 'practical': [76], 'implementation': [77], 'challenges,': [78], 'research': [80], 'opportunities': [81], 'in': [82], 'application': [84], 'electronics.': [89], 'is': [92], 'accompanied': [93], 'Excel': [96], 'file': [97], 'listing': [98], 'relevant': [100], 'statistical': [103], 'analytics.': [104]}",2020,"['Computer science', 'Listing (finance)', 'Artificial intelligence', 'Fuzzy logic', 'Expert system', 'Power electronics', 'Electronics', 'Machine learning', 'Analytics', 'Metaheuristic', 'Data science', 'Engineering', 'Electrical engineering', 'Economics', 'Finance', 'Voltage']","This article gives an overview of the artificial intelligence (AI) applications for power electronic systems. The three distinctive life-cycle phases, design, control, and maintenance are correlated with one or more tasks to be addressed by AI, including optimization, classification, regression, and data structure exploration. The applications of four categories of AI are discussed, which are expert system, fuzzy logic, metaheuristic method, and machine learning. More than 500 publications have been reviewed to identify the common understandings, practical implementation challenges, and research opportunities in the application of AI for power electronics. This article is accompanied by an Excel file listing the relevant publications for statistical analytics."
https://openalex.org/W2908162093,Applications of Artificial Intelligence in Transport: An Overview,"{'The': [0, 26, 44, 146, 242], 'rapid': [1, 193], 'pace': [2], 'of': [3, 17, 46, 58, 72, 75, 79, 105, 149, 155, 212, 221, 251], 'developments': [4], 'in': [5, 48, 86, 93, 195, 232, 254], 'Artificial': [6, 118, 128], 'Intelligence': [7], '(AI)': [8], 'is': [9, 52, 177], 'providing': [10], 'unprecedented': [11], 'opportunities': [12], 'to': [13, 113, 182, 186, 190, 203, 227], 'enhance': [14], 'the': [15, 23, 38, 40, 49, 56, 73, 114, 156, 172, 184, 208, 222, 247], 'performance': [16], 'different': [18], 'industries': [19], 'and': [20, 67, 81, 84, 97, 136, 141, 160, 165, 169, 206, 210, 239, 249], 'businesses,': [21], 'including': [22], 'transport': [24, 50, 115, 180], 'sector.': [25], 'innovations': [27], 'introduced': [28], 'by': [29, 245], 'AI': [30, 47, 85, 106, 150, 159, 223, 252], 'include': [31, 117], 'highly': [32], 'advanced': [33], 'computational': [34], 'methods': [35, 107], 'that': [36, 108], 'mimic': [37], 'way': [39, 112, 185], 'human': [41], 'brain': [42], 'works.': [43], 'application': [45, 148], 'field': [51, 116], 'aimed': [53], 'at': [54], 'overcoming': [55], 'challenges': [57, 248], 'an': [59, 219], 'increasing': [60], 'travel': [61, 199], 'demand,': [62], 'CO2': [63], 'emissions,': [64], 'safety': [65], 'concerns,': [66], 'environmental': [68], 'degradation.': [69], 'In': [70], 'light': [71], 'availability': [74], 'a': [76, 94, 152, 192], 'huge': [77], 'amount': [78], 'quantitative': [80], 'qualitative': [82], 'data': [83, 161], 'this': [87], 'digital': [88], 'age,': [89], 'addressing': [90, 246], 'these': [91, 188], 'concerns': [92], 'more': [95, 102, 201], 'efficient': [96], 'effective': [98], 'fashion': [99], 'has': [100], 'become': [101], 'plausible.': [103], 'Examples': [104], 'are': [109], 'finding': [110], 'their': [111, 204, 213], 'Neural': [119], 'Networks': [120], '(ANN),': [121], 'Genetic': [122], 'algorithms': [123], '(GA),': [124], 'Simulated': [125], 'Annealing': [126], '(SA),': [127], 'Immune': [129], 'system': [130, 167], '(AIS),': [131], 'Ant': [132], 'Colony': [133, 138], 'Optimiser': [134], '(ACO)': [135], 'Bee': [137], 'Optimization': [139], '(BCO)': [140], 'Fuzzy': [142], 'Logic': [143], 'Model': [144], '(FLM)': [145], 'successful': [147], 'requires': [151], 'good': [153], 'understanding': [154], 'relationships': [157], 'between': [158], 'on': [162, 171], 'one': [163], 'hand,': [164], 'transportation': [166, 229], 'characteristics': [168], 'variables': [170], 'other': [173], 'hand.': [174], 'Moreover,': [175], 'it': [176], 'promising': [178], 'for': [179], 'authorities': [181], 'determine': [183], 'use': [187], 'technologies': [189], 'create': [191], 'improvement': [194], 'relieving': [196], 'congestion,': [197], 'making': [198], 'time': [200], 'reliable': [202], 'customers': [205], 'improve': [207], 'economics': [209], 'productivity': [211], 'vital': [214], 'assets.': [215], 'This': [216], 'paper': [217], 'provides': [218], 'overview': [220, 243], 'techniques': [224], 'applied': [225], 'worldwide': [226], 'address': [228], 'problems': [230], 'mainly': [231], 'traffic': [233, 235], 'management,': [234], 'safety,': [236], 'public': [237], 'transportation,': [238], 'urban': [240], 'mobility.': [241], 'concludes': [244], 'limitations': [250], 'applications': [253], 'transport.': [255]}",2019,"['Computer science', 'Traffic congestion', 'Public transport', 'Artificial intelligence', 'Applications of artificial intelligence', 'Field (mathematics)', 'Artificial neural network', 'Pace', 'Operations research', 'Risk analysis (engineering)', 'Transport engineering', 'Engineering', 'Business', 'Geodesy', 'Geography', 'Pure mathematics', 'Mathematics']","The rapid pace of developments in Artificial Intelligence (AI) is providing unprecedented opportunities to enhance the performance of different industries and businesses, including the transport sector. The innovations introduced by AI include highly advanced computational methods that mimic the way the human brain works. The application of AI in the transport field is aimed at overcoming the challenges of an increasing travel demand, CO2 emissions, safety concerns, and environmental degradation. In light of the availability of a huge amount of quantitative and qualitative data and AI in this digital age, addressing these concerns in a more efficient and effective fashion has become more plausible. Examples of AI methods that are finding their way to the transport field include Artificial Neural Networks (ANN), Genetic algorithms (GA), Simulated Annealing (SA), Artificial Immune system (AIS), Ant Colony Optimiser (ACO) and Bee Colony Optimization (BCO) and Fuzzy Logic Model (FLM) The successful application of AI requires a good understanding of the relationships between AI and data on one hand, and transportation system characteristics and variables on the other hand. Moreover, it is promising for transport authorities to determine the way to use these technologies to create a rapid improvement in relieving congestion, making travel time more reliable to their customers and improve the economics and productivity of their vital assets. This paper provides an overview of the AI techniques applied worldwide to address transportation problems mainly in traffic management, traffic safety, public transportation, and urban mobility. The overview concludes by addressing the challenges and limitations of AI applications in transport."
https://openalex.org/W2783386352,"Artificial Intelligence, Automation and Work","{'We': [0], 'summarize': [1], 'a': [2, 59, 192], 'framework': [3, 23, 162], 'for': [4, 17, 51, 74, 103], 'the': [5, 8, 15, 25, 49, 64, 72, 88, 101, 123, 137, 153, 158, 165, 172, 175, 178, 185, 195, 202, 215], 'study': [6], 'of': [7, 10, 90, 93, 97, 125, 139, 160, 174, 198, 217], 'implications': [9], 'automation': [11, 29, 91, 113, 135, 182, 205], 'and': [12, 20, 33, 53, 87, 121, 149, 167, 177, 183, 201], 'AI': [13, 34], 'on': [14], 'demand': [16, 50, 73, 102], 'labor,': [18], 'wages,': [19], 'employment.Our': [21], 'task-based': [22], 'emphasizes': [24], 'displacement': [26, 44], 'effect': [27, 45, 80], 'that': [28, 39, 169, 204], 'creates': [30], 'as': [31], 'machines': [32], 'replace': [35], 'labor': [36, 52, 75, 126, 145, 154, 179], 'in': [37, 76, 127, 146], 'tasks': [38], 'it': [40, 55], 'used': [41], 'to': [42, 47, 151, 156, 181], 'perform.This': [43], 'tends': [46, 150], 'reduce': [48, 122], 'wages.But': [54], 'is': [56, 81, 136, 206], 'counteracted': [57], 'by': [58, 68, 83], 'productivity': [60, 79, 187], 'effect,': [61], 'resulting': [62, 186], 'from': [63, 189], 'cost': [65], 'savings': [66], 'generated': [67], 'automation,': [69], 'which': [70, 98, 143], 'increase': [71, 100, 152], 'non-automated': [77], 'tasks.The': [78], 'complemented': [82], 'additional': [84], 'capital': [85], 'accumulation': [86], 'deepening': [89], '(improvements': [92], 'existing': [94], 'machinery),': [95], 'both': [96], 'further': [99], 'labor.These': [104], 'countervailing': [105, 132], 'effects': [106], 'are': [107, 111], 'incomplete.Even': [108], 'when': [109], 'they': [110], 'strong,': [112], 'in-creases': [114], 'output': [115], 'per': [116], 'worker': [117], 'more': [118, 130], 'than': [119], 'wages': [120], 'share': [124, 155], 'national': [128], 'income.The': [129], 'powerful': [131], 'force': [133], 'against': [134], 'creation': [138], 'new': [140, 147, 199], 'labor-intensive': [141], 'tasks,': [142], 'reinstates': [144], 'activities': [148], 'counterbalance': [157], 'impact': [159], 'automation.Our': [161], 'also': [163], 'highlights': [164], 'constraints': [166], 'imperfections': [168], 'slow': [170], 'down': [171], 'adjustment': [173], 'economy': [176], 'market': [180], 'weaken': [184], 'gains': [188], 'this': [190], 'transformation:': [191], 'mismatch': [193], 'between': [194], 'skill': [196], 'requirements': [197], 'technologies,': [200], 'possibility': [203], 'being': [207], 'introduced': [208], 'at': [209, 214], 'an': [210], 'excessive': [211], 'rate,': [212], 'possibly': [213], 'expense': [216], 'other': [218], 'productivity-enhancing': [219], 'technologies.': [220]}",2018,"['Automation', 'Work (physics)', 'Computer science', 'Artificial intelligence', 'Engineering', 'Mechanical engineering']","We summarize a framework for the study of the implications of automation and AI on the demand for labor, wages, and employment.Our task-based framework emphasizes the displacement effect that automation creates as machines and AI replace labor in tasks that it used to perform.This displacement effect tends to reduce the demand for labor and wages.But it is counteracted by a productivity effect, resulting from the cost savings generated by automation, which increase the demand for labor in non-automated tasks.The productivity effect is complemented by additional capital accumulation and the deepening of automation (improvements of existing machinery), both of which further increase the demand for labor.These countervailing effects are incomplete.Even when they are strong, automation in-creases output per worker more than wages and reduce the share of labor in national income.The more powerful countervailing force against automation is the creation of new labor-intensive tasks, which reinstates labor in new activities and tends to increase the labor share to counterbalance the impact of automation.Our framework also highlights the constraints and imperfections that slow down the adjustment of the economy and the labor market to automation and weaken the resulting productivity gains from this transformation: a mismatch between the skill requirements of new technologies, and the possibility that automation is being introduced at an excessive rate, possibly at the expense of other productivity-enhancing technologies."
https://openalex.org/W3004493409,Bias in data‐driven artificial intelligence systems—An introductory survey,"{'Abstract': [0], 'Artificial': [1], 'Intelligence': [2], '(AI)‐based': [3], 'systems': [4], 'are': [5], 'widely': [6], 'employed': [7], 'nowadays': [8, 133], 'to': [9, 39, 61, 82, 105, 152, 156], 'make': [10], 'decisions': [11, 21, 168], 'that': [12, 163], 'have': [13], 'far‐reaching': [14], 'impact': [15], 'on': [16, 97, 122, 169], 'individuals': [17], 'and': [18, 26, 49, 52, 59, 100, 137, 179, 189, 199, 207], 'society.': [19], 'Their': [20], 'might': [22, 164], 'affect': [23], 'everyone,': [24], 'everywhere,': [25], 'anytime,': [27], 'entailing': [28], 'concerns': [29], 'about': [30], 'potential': [31, 71], 'human': [32], 'rights': [33], 'issues.': [34], 'Therefore,': [35], 'it': [36], 'is': [37, 81, 131, 184], 'necessary': [38], 'move': [40], 'beyond': [41], 'traditional': [42], 'AI': [43, 74, 94, 130], 'algorithms': [44], 'optimized': [45], 'for': [46], 'predictive': [47], 'performance': [48], 'embed': [50], 'ethical': [51], 'legal': [53, 115], 'principles': [54], 'in': [55, 93, 113, 166, 194], 'their': [56], 'design,': [57], 'training,': [58], 'deployment': [60], 'ensure': [62], 'social': [63], 'good': [64], 'while': [65], 'still': [66], 'benefiting': [67], 'from': [68], 'the': [69, 73, 89, 148, 157, 170], 'huge': [70], 'of': [72, 78, 88, 91, 129, 161, 172], 'technology.': [75], 'The': [76], 'goal': [77], 'this': [79, 118], 'survey': [80], 'provide': [83], 'a': [84, 114, 126], 'broad': [85], 'multidisciplinary': [86], 'overview': [87], 'area': [90], 'bias': [92, 151], 'systems,': [95], 'focusing': [96], 'technical': [98], 'challenges': [99], 'solutions': [101], 'as': [102, 104, 125, 176], 'well': [103], 'suggest': [106], 'new': [107], 'research': [108], 'directions': [109], 'towards': [110], 'approaches': [111], 'well‐grounded': [112], 'frame.': [116], 'In': [117], 'survey,': [119], 'we': [120, 146], 'focus': [121], 'data‐driven': [123], 'AI,': [124], 'large': [127], 'part': [128], 'powered': [132], 'by': [134], '(big)': [135], 'data': [136, 162], 'powerful': [138], 'machine': [139], 'learning': [140], 'algorithms.': [141], 'If': [142], 'otherwise': [143], 'not': [144], 'specified,': [145], 'use': [147], 'general': [149], 'term': [150], 'describe': [153], 'problems': [154], 'related': [155], 'gathering': [158], 'or': [159], 'processing': [160], 'result': [165], 'prejudiced': [167], 'bases': [171], 'demographic': [173], 'features': [174], 'such': [175], 'race,': [177], 'sex,': [178], 'so': [180], 'forth.': [181], 'This': [182], 'article': [183], 'categorized': [185], 'under:': [186], 'Commercial,': [187, 197, 205], 'Legal,': [188, 198, 206], 'Ethical': [190, 200, 203, 208], 'Issues': [191, 201, 209, 212], '&gt;': [192, 202, 210], 'Fairness': [193], 'Data': [195], 'Mining': [196], 'Considerations': [204], 'Legal': [211]}",2020,"['Computer science', 'Big data', 'Artificial intelligence', 'Software deployment', 'Ethical issues', 'Multidisciplinary approach', 'Data science', 'Engineering ethics', 'Political science', 'Law', 'Data mining', 'Engineering', 'Operating system']","Abstract Artificial Intelligence (AI)‐based systems are widely employed nowadays to make decisions that have far‐reaching impact on individuals and society. Their decisions might affect everyone, everywhere, and anytime, entailing concerns about potential human rights issues. Therefore, it is necessary to move beyond traditional AI algorithms optimized for predictive performance and embed ethical and legal principles in their design, training, and deployment to ensure social good while still benefiting from the huge potential of the AI technology. The goal of this survey is to provide a broad multidisciplinary overview of the area of bias in AI systems, focusing on technical challenges and solutions as well as to suggest new research directions towards approaches well‐grounded in a legal frame. In this survey, we focus on data‐driven AI, as a large part of AI is powered nowadays by (big) data and powerful machine learning algorithms. If otherwise not specified, we use the general term bias to describe problems related to the gathering or processing of data that might result in prejudiced decisions on the bases of demographic features such as race, sex, and so forth. This article is categorized under: Commercial, Legal, and Ethical Issues &gt; Fairness in Data Mining Commercial, Legal, and Ethical Issues &gt; Ethical Considerations Commercial, Legal, and Ethical Issues &gt; Legal Issues"
https://openalex.org/W3156614709,A Review of Artificial Intelligence (AI) in Education from 2010 to 2020,"{'This': [0], 'study': [1], 'provided': [2], 'a': [3, 194], 'content': [4, 69], 'analysis': [5, 70], 'of': [6, 30, 36, 58, 111, 124, 151, 156, 174, 188], 'studies': [7], 'aiming': [8], 'to': [9, 18, 66, 148, 183, 202], 'disclose': [10], 'how': [11], 'artificial': [12], 'intelligence': [13], '(AI)': [14], 'has': [15], 'been': [16], 'applied': [17], 'the': [19, 24, 52, 73, 137, 175, 185], 'education': [20, 53, 140, 179, 191], 'sector': [21], 'and': [22, 28, 45, 54, 85, 92, 95, 103, 117, 158, 164, 192, 199], 'explore': [23], 'potential': [25], 'research': [26, 56, 74, 107], 'trends': [27], 'challenges': [29, 138], 'AI': [31, 125, 145, 152, 176, 189, 200], 'in': [32, 126, 139, 190], 'education.': [33], 'A': [34], 'total': [35], '100': [37], 'papers': [38, 42, 48], 'including': [39, 109], '63': [40], 'empirical': [41], '(74': [43], 'studies)': [44], '37': [46], 'analytic': [47], 'were': [49, 128], 'selected': [50], 'from': [51, 64], 'educational': [55], 'category': [57], 'Social': [59], 'Sciences': [60], 'Citation': [61], 'Index': [62], 'database': [63], '2010': [65], '2020.': [67], 'The': [68, 167], 'showed': [71], 'that': [72], 'questions': [75], 'could': [76], 'be': [77, 142], 'classified': [78], 'into': [79, 171], 'development': [80], 'layer': [81, 89, 97], '(classification,': [82], 'matching,': [83], 'recommendation,': [84], 'deep': [86, 115], 'learning),': [87, 94], 'application': [88], '(feedback,': [90], 'reasoning,': [91], 'adaptive': [93], 'integration': [96], '(affection': [98], 'computing,': [99], 'role‐playing,': [100], 'immersive': [101], 'learning,': [102, 116], 'gamification).': [104], 'Moreover,': [105], 'four': [106], 'trends,': [108], 'Internet': [110], 'Things,': [112], 'swarm': [113], 'intelligence,': [114], 'neuroscience,': [118], 'as': [119, 121, 160, 162], 'well': [120, 161], 'an': [122, 172], 'assessment': [123], 'education,': [127], 'suggested': [129], 'for': [130, 178, 197], 'further': [131, 205], 'investigation.': [132], 'However,': [133], 'we': [134], 'also': [135], 'proposed': [136], 'may': [141], 'caused': [143], 'by': [144], 'with': [146], 'regard': [147], 'inappropriate': [149], 'use': [150], 'techniques,': [153], 'changing': [154], 'roles': [155], 'teachers': [157], 'students,': [159], 'social': [163], 'ethical': [165], 'issues.': [166], 'results': [168], 'provide': [169], 'insights': [170], 'overview': [173], 'used': [177], 'domain,': [180], 'which': [181], 'helps': [182], 'strengthen': [184], 'theoretical': [186], 'foundation': [187], 'provides': [193], 'promising': [195], 'channel': [196], 'educators': [198], 'engineers': [201], 'carry': [203], 'out': [204], 'collaborative': [206], 'research.': [207]}",2021,"['Artificial intelligence', 'Computer science', 'Applications of artificial intelligence', 'Machine learning']","This study provided a content analysis of studies aiming to disclose how artificial intelligence (AI) has been applied to the education sector and explore the potential research trends and challenges of AI in education. A total of 100 papers including 63 empirical papers (74 studies) and 37 analytic papers were selected from the education and educational research category of Social Sciences Citation Index database from 2010 to 2020. The content analysis showed that the research questions could be classified into development layer (classification, matching, recommendation, and deep learning), application layer (feedback, reasoning, and adaptive learning), and integration layer (affection computing, role‐playing, immersive learning, and gamification). Moreover, four research trends, including Internet of Things, swarm intelligence, deep learning, and neuroscience, as well as an assessment of AI in education, were suggested for further investigation. However, we also proposed the challenges in education may be caused by AI with regard to inappropriate use of AI techniques, changing roles of teachers and students, as well as social and ethical issues. The results provide insights into an overview of the AI used for education domain, which helps to strengthen the theoretical foundation of AI in education and provides a promising channel for educators and AI engineers to carry out further collaborative research."
https://openalex.org/W2753415590,"Explainable Artificial Intelligence: Understanding, Visualizing and Interpreting Deep Learning Models","{'With': [0], 'the': [1, 13, 23, 107, 158, 161, 168, 176, 181], 'availability': [2], 'of': [3, 15, 30, 35, 57, 96, 109, 150, 160, 180], 'large': [4], 'databases': [5], 'and': [6, 67, 114, 132, 170], 'recent': [7, 127], 'improvements': [8], 'in': [9, 41, 74, 104, 129, 139, 167, 178], 'deep': [10, 116, 151], 'learning': [11, 66, 117, 152], 'methodology,': [12], 'performance': [14], 'AI': [16], 'systems': [17], 'is': [18, 82], 'reaching': [19], 'or': [20, 51], 'even': [21], 'exceeding': [22], 'human': [24], 'level': [25], 'on': [26, 188], 'an': [27], 'increasing': [28, 122], 'number': [29], 'complex': [31], 'tasks.': [32, 191], 'Impressive': [33], 'examples': [34], 'this': [36, 94, 130], 'development': [37, 108], 'can': [38, 98], 'be': [39, 99], 'found': [40], 'domains': [42], 'such': [43], 'as': [44], 'image': [45], 'classification,': [46], 'sentiment': [47], 'analysis,': [48], 'speech': [49], 'understanding': [50], 'strategic': [52], 'game': [53], 'playing.': [54], 'However,': [55], 'because': [56], 'their': [58, 91], 'nested': [59], 'non-linear': [60], 'structure,': [61], 'these': [62], 'highly': [63], 'successful': [64], 'machine': [65], 'artificial': [68, 140], 'intelligence': [69], 'models': [70, 118], 'are': [71, 186], 'usually': [72], 'applied': [73], 'a': [75, 100, 134], 'black': [76], 'box': [77], 'manner,': [78], 'i.e.,': [79], 'no': [80], 'information': [81], 'provided': [83], 'about': [84], 'what': [85], 'exactly': [86], 'makes': [87, 133], 'them': [88], 'arrive': [89], 'at': [90], 'predictions.': [92], 'Since': [93], 'lack': [95], 'transparency': [97], 'major': [101], 'drawback,': [102], 'e.g.,': [103], 'medical': [105], 'applications,': [106], 'methods': [110, 185], 'for': [111, 136], 'visualizing,': [112], 'explaining': [113, 148], 'interpreting': [115], 'has': [119], 'recently': [120], 'attracted': [121], 'attention.': [123], 'This': [124], 'paper': [125], 'summarizes': [126], 'developments': [128], 'field': [131], 'plea': [135], 'more': [137], 'interpretability': [138], 'intelligence.': [141], 'Furthermore,': [142], 'it': [143], 'presents': [144], 'two': [145], 'approaches': [146], 'to': [147, 165], 'predictions': [149], 'models,': [153], 'one': [154, 171], 'method': [155], 'which': [156, 173], 'computes': [157], 'sensitivity': [159], 'prediction': [162], 'with': [163], 'respect': [164], 'changes': [166], 'input': [169, 182], 'approach': [172], 'meaningfully': [174], 'decomposes': [175], 'decision': [177], 'terms': [179], 'variables.': [183], 'These': [184], 'evaluated': [187], 'three': [189], 'classification': [190]}",2017,"['Interpretability', 'Artificial intelligence', 'Computer science', 'Deep learning', 'Machine learning', 'Field (mathematics)', 'Transparency (behavior)', 'Black box', 'Computer security', 'Pure mathematics', 'Mathematics']","With the availability of large databases and recent improvements in deep learning methodology, the performance of AI systems is reaching or even exceeding the human level on an increasing number of complex tasks. Impressive examples of this development can be found in domains such as image classification, sentiment analysis, speech understanding or strategic game playing. However, because of their nested non-linear structure, these highly successful machine learning and artificial intelligence models are usually applied in a black box manner, i.e., no information is provided about what exactly makes them arrive at their predictions. Since this lack of transparency can be a major drawback, e.g., in medical applications, the development of methods for visualizing, explaining and interpreting deep learning models has recently attracted increasing attention. This paper summarizes recent developments in this field and makes a plea for more interpretability in artificial intelligence. Furthermore, it presents two approaches to explaining predictions of deep learning models, one method which computes the sensitivity of the prediction with respect to changes in the input and one approach which meaningfully decomposes the decision in terms of the input variables. These methods are evaluated on three classification tasks."
https://openalex.org/W4360980141,Examining Science Education in ChatGPT: An Exploratory Study of Generative Artificial Intelligence,"{'Abstract': [0], 'The': [1, 16, 215], 'advent': [2], 'of': [3, 14, 98, 142, 154, 217, 233], 'generative': [4, 234], 'artificial': [5], 'intelligence': [6], '(AI)': [7], 'offers': [8], 'transformative': [9], 'potential': [10, 131], 'in': [11, 41, 52, 86, 116, 236], 'the': [12, 76, 87, 96, 102, 140, 211, 218, 231], 'field': [13], 'education.': [15, 238], 'study': [17], 'explores': [18], 'three': [19], 'main': [20], 'areas:': [21], '(1)': [22], 'How': [23, 47], 'did': [24], 'ChatGPT': [25, 40, 49, 94, 164, 195], 'answer': [26], 'questions': [27], 'related': [28, 135], 'to': [29, 74, 136, 150, 167, 190, 207, 221], 'science': [30, 43, 175, 237], 'education?': [31], '(2)': [32], 'What': [33], 'are': [34, 57], 'some': [35], 'ways': [36], 'educators': [37, 149, 173], 'could': [38], 'utilise': [39], 'their': [42, 191], 'pedagogy?': [44], 'and': [45, 55, 139, 159, 178, 187, 206], '(3)': [46], 'has': [48], 'been': [50], 'utilised': [51], 'this': [53], 'study,': [54], 'what': [56], 'my': [58], 'reflections': [59], 'about': [60, 162, 230], 'its': [61, 130], 'use': [62, 153, 232], 'as': [63, 90, 101, 198, 223], 'a': [64, 71, 107, 113, 169, 199, 224, 227], 'research': [65, 69, 200, 212], 'tool?': [66], 'This': [67], 'exploratory': [68], 'applies': [70], 'self-study': [72], 'methodology': [73], 'investigate': [75], 'technology.': [77], 'Impressively,': [78], 'ChatGPT’s': [79], 'output': [80], 'often': [81], 'aligned': [82], 'with': [83, 120, 127, 204, 209], 'key': [84], 'themes': [85], 'research.': [88], 'However,': [89], 'it': [91, 189], 'currently': [92], 'stands,': [93], 'runs': [95], 'risk': [97, 141], 'positioning': [99], 'itself': [100], 'ultimate': [103], 'epistemic': [104], 'authority,': [105], 'where': [106], 'single': [108], 'truth': [109], 'is': [110, 146, 165, 220], 'assumed': [111], 'without': [112], 'proper': [114], 'grounding': [115], 'evidence': [117], 'or': [118], 'presented': [119], 'sufficient': [121], 'qualifications.': [122], 'Key': [123], 'ethical': [124], 'concerns': [125], 'associated': [126], 'AI': [128, 235], 'include': [129], 'environmental': [132], 'impact,': [133], 'issues': [134], 'content': [137], 'moderation,': [138], 'copyright': [143], 'infringement.': [144], 'It': [145], 'important': [147], 'for': [148, 172, 202, 226], 'model': [151], 'responsible': [152], 'ChatGPT,': [155], 'prioritise': [156], 'critical': [157], 'thinking,': [158], 'be': [160, 168], 'clear': [161], 'expectations.': [163], 'likely': [166], 'useful': [170], 'tool': [171, 201], 'designing': [174], 'units,': [176], 'rubrics,': [177], 'quizzes.': [179], 'Educators': [180], 'should': [181], 'critically': [182], 'evaluate': [183], 'any': [184], 'AI-generated': [185], 'resource': [186], 'adapt': [188], 'specific': [192], 'teaching': [193], 'contexts.': [194], 'was': [196], 'used': [197], 'assistance': [203], 'editing': [205], 'experiment': [208], 'making': [210], 'narrative': [213], 'clearer.': [214], 'intention': [216], 'paper': [219], 'act': [222], 'catalyst': [225], 'broader': [228], 'conversation': [229]}",2023,"['Transformative learning', 'Science education', 'Rubric', 'Engineering ethics', 'Narrative', 'Generative grammar', 'Computer science', 'Sociology', 'Psychology', 'Pedagogy', 'Artificial intelligence', 'Engineering', 'Philosophy', 'Linguistics']","Abstract The advent of generative artificial intelligence (AI) offers transformative potential in the field of education. The study explores three main areas: (1) How did ChatGPT answer questions related to science education? (2) What are some ways educators could utilise ChatGPT in their science pedagogy? and (3) How has ChatGPT been utilised in this study, and what are my reflections about its use as a research tool? This exploratory research applies a self-study methodology to investigate the technology. Impressively, ChatGPT’s output often aligned with key themes in the research. However, as it currently stands, ChatGPT runs the risk of positioning itself as the ultimate epistemic authority, where a single truth is assumed without a proper grounding in evidence or presented with sufficient qualifications. Key ethical concerns associated with AI include its potential environmental impact, issues related to content moderation, and the risk of copyright infringement. It is important for educators to model responsible use of ChatGPT, prioritise critical thinking, and be clear about expectations. ChatGPT is likely to be a useful tool for educators designing science units, rubrics, and quizzes. Educators should critically evaluate any AI-generated resource and adapt it to their specific teaching contexts. ChatGPT was used as a research tool for assistance with editing and to experiment with making the research narrative clearer. The intention of the paper is to act as a catalyst for a broader conversation about the use of generative AI in science education."
https://openalex.org/W4322008312,Can artificial intelligence help for scientific writing?,"{'Abstract': [0], 'This': [1], 'paper': [2], 'discusses': [3], 'the': [4, 24, 72, 89, 105, 133, 154, 167], 'use': [5, 168], 'of': [6, 17, 74, 135, 169], 'Artificial': [7], 'Intelligence': [8], 'Chatbot': [9], 'in': [10, 43, 50, 57, 65, 71, 88, 116, 145, 171], 'scientific': [11, 51, 172], 'writing.': [12], 'ChatGPT': [13, 42, 92], 'is': [14, 68], 'a': [15, 86, 99, 142, 161], 'type': [16], 'chatbot,': [18], 'developed': [19], 'by': [20, 111], 'OpenAI,': [21], 'that': [22], 'uses': [23], 'Generative': [25], 'Pre-trained': [26], 'Transformer': [27], '(GPT)': [28], 'language': [29, 37], 'model': [30], 'to': [31, 35, 46, 165], 'understand': [32], 'and': [33, 41, 55, 104, 137, 150], 'respond': [34], 'natural': [36], 'inputs.': [38], 'AI': [39], 'chatbot': [40], 'particular': [44], 'appear': [45], 'be': [47, 85, 96, 109, 176], 'useful': [48], 'tools': [49], 'writing,': [52], 'assisting': [53], 'researchers': [54], 'scientists': [56], 'organizing': [58], 'material,': [59], 'generating': [60], 'an': [61], 'initial': [62], 'draft': [63], 'and/or': [64], 'proofreading.': [66], 'There': [67], 'no': [69], 'publication': [70], 'field': [73], 'critical': [75, 118], 'care': [76], 'medicine': [77], 'prepared': [78], 'using': [79, 128], 'this': [80, 83, 159], 'approach;': [81], 'however,': [82], 'will': [84, 174], 'possibility': [87], 'next': [90], 'future.': [91], 'work': [93], 'should': [94, 107], 'not': [95], 'used': [97, 115], 'as': [98, 132, 139, 141], 'replacement': [100], 'for': [101], 'human': [102], 'judgment': [103], 'output': [106], 'always': [108], 'reviewed': [110], 'experts': [112], 'before': [113], 'being': [114], 'any': [117], 'decision-making': [119], 'or': [120], 'application.': [121], 'Moreover,': [122], 'several': [123], 'ethical': [124], 'issues': [125], 'arise': [126], 'about': [127], 'these': [129], 'tools,': [130], 'such': [131], 'risk': [134], 'plagiarism': [136], 'inaccuracies,': [138], 'well': [140], 'potential': [143], 'imbalance': [144], 'its': [146], 'accessibility': [147], 'between': [148], 'high-': [149], 'low-income': [151], 'countries,': [152], 'if': [153], 'software': [155], 'becomes': [156], 'paying.': [157], 'For': [158], 'reason,': [160], 'consensus': [162], 'on': [163], 'how': [164], 'regulate': [166], 'chatbots': [170], 'writing': [173], 'soon': [175], 'required.': [177]}",2023,"['Chatbot', 'Generative grammar', 'Engineering ethics', 'Computer science', 'Scientific writing', 'Transformer', 'Data science', 'Artificial intelligence', 'Engineering', 'Linguistics', 'Electrical engineering', 'Philosophy', 'Voltage']","Abstract This paper discusses the use of Artificial Intelligence Chatbot in scientific writing. ChatGPT is a type of chatbot, developed by OpenAI, that uses the Generative Pre-trained Transformer (GPT) language model to understand and respond to natural language inputs. AI chatbot and ChatGPT in particular appear to be useful tools in scientific writing, assisting researchers and scientists in organizing material, generating an initial draft and/or in proofreading. There is no publication in the field of critical care medicine prepared using this approach; however, this will be a possibility in the next future. ChatGPT work should not be used as a replacement for human judgment and the output should always be reviewed by experts before being used in any critical decision-making or application. Moreover, several ethical issues arise about using these tools, such as the risk of plagiarism and inaccuracies, as well as a potential imbalance in its accessibility between high- and low-income countries, if the software becomes paying. For this reason, a consensus on how to regulate the use of chatbots in scientific writing will soon be required."
https://openalex.org/W3195625625,Artificial Intelligence and Business Value: a Literature Review,"{'Abstract': [0], 'Artificial': [1], 'Intelligence': [2], '(AI)': [3], 'are': [4, 28, 53], 'a': [5, 40, 45, 67, 87, 93, 167], 'wide-ranging': [6], 'set': [7], 'of': [8, 42, 66, 70, 80, 129, 137, 151, 159], 'technologies': [9, 73, 106], 'that': [10, 97, 170, 173], 'promise': [11], 'several': [12], 'advantages': [13], 'for': [14], 'organizations': [15, 27, 52, 102], 'in': [16, 33, 48, 61, 107, 140, 162], 'terms': [17], 'off': [18], 'added': [19], 'business': [20, 37, 75, 81], 'value.': [21], 'Over': [22], 'the': [23, 112, 118, 124, 135, 141, 146, 160, 163], 'past': [24], 'few': [25], 'years,': [26], 'increasingly': [29], 'turning': [30], 'to': [31, 35, 56, 99, 175], 'AI': [32, 60, 72, 105, 130, 138], 'order': [34], 'gain': [36], 'value': [38, 82], 'following': [39], 'deluge': [41], 'data': [43], 'and': [44, 58, 77, 110, 121, 127, 132, 144, 148, 165], 'strong': [46], 'increase': [47], 'computational': [49], 'capacity.': [50], 'Nevertheless,': [51], 'still': [54], 'struggling': [55], 'adopt': [57], 'leverage': [59, 104], 'their': [62, 108], 'operations.': [63], 'The': [64, 153], 'lack': [65], 'coherent': [68], 'understanding': [69], 'how': [71, 101], 'create': [74], 'value,': [76], 'what': [78], 'type': [79], 'is': [83], 'expected,': [84], 'therefore': [85], 'necessitates': [86], 'holistic': [88], 'understanding.': [89], 'This': [90], 'study': [91], 'provides': [92], 'systematic': [94], 'literature': [95, 120, 164], 'review': [96], 'attempts': [98], 'explain': [100], 'can': [103], 'operations': [109], 'elucidate': [111], 'value-generating': [113], 'mechanisms.': [114], 'Our': [115], 'analysis': [116], 'synthesizes': [117], 'current': [119], 'highlights:': [122], '(1)': [123], 'key': [125], 'enablers': [126], 'inhibitors': [128], 'adoption': [131], 'use;': [133], '(2)': [134], 'typologies': [136], 'use': [139], 'organizational': [142], 'setting;': [143], '(3)': [145], 'first-': [147], 'second-order': [149], 'effects': [150], 'AI.': [152], 'paper': [154], 'concludes': [155], 'with': [156], 'an': [157], 'identification': [158], 'gaps': [161], 'develops': [166], 'research': [168], 'agenda': [169], 'identifies': [171], 'areas': [172], 'need': [174], 'be': [176], 'addressed': [177], 'by': [178], 'future': [179], 'studies.': [180]}",2021,"['Leverage (statistics)', 'Knowledge management', 'Business value', 'Business intelligence', 'Value (mathematics)', 'Computer science', 'Ambidexterity', 'Order (exchange)', 'Value creation', 'Data science', 'Management science', 'Business', 'Artificial intelligence', 'Engineering', 'Economics', 'Machine learning', 'Human capital', 'Finance', 'Economic growth']","Abstract Artificial Intelligence (AI) are a wide-ranging set of technologies that promise several advantages for organizations in terms off added business value. Over the past few years, organizations are increasingly turning to AI in order to gain business value following a deluge of data and a strong increase in computational capacity. Nevertheless, organizations are still struggling to adopt and leverage AI in their operations. The lack of a coherent understanding of how AI technologies create business value, and what type of business value is expected, therefore necessitates a holistic understanding. This study provides a systematic literature review that attempts to explain how organizations can leverage AI technologies in their operations and elucidate the value-generating mechanisms. Our analysis synthesizes the current literature and highlights: (1) the key enablers and inhibitors of AI adoption and use; (2) the typologies of AI use in the organizational setting; and (3) the first- and second-order effects of AI. The paper concludes with an identification of the gaps in the literature and develops a research agenda that identifies areas that need to be addressed by future studies."
https://openalex.org/W4379470483,A Review of the Role of Artificial Intelligence in Healthcare,"{'Artificial': [0], 'intelligence': [1], '(AI)': [2], 'applications': [3, 165], 'have': [4], 'transformed': [5], 'healthcare.': [6, 160], 'This': [7], 'study': [8], 'is': [9, 61, 166, 188], 'based': [10], 'on': [11, 25], 'a': [12, 189, 220], 'general': [13], 'literature': [14], 'review': [15], 'uncovering': [16], 'the': [17, 26, 74, 101, 105, 143, 201, 210, 214], 'role': [18], 'of': [19, 59, 76, 108, 163, 205, 216], 'AI': [20, 60, 158, 164, 217], 'in': [21, 63, 67, 178, 222], 'healthcare': [22, 109, 236], 'and': [23, 33, 42, 48, 52, 70, 98, 115, 124, 126, 137, 147, 151, 154, 171, 173, 181, 196, 203, 224], 'focuses': [24], 'following': [27], 'key': [28], 'aspects:': [29], '(i)': [30], 'medical': [31, 40, 68, 118], 'imaging': [32, 69], 'diagnostics,': [34], '(ii)': [35], 'virtual': [36, 85], 'patient': [37, 46, 86, 96, 169], 'care,': [38], '(iii)': [39], 'research': [41], 'drug': [43], 'discovery,': [44], '(iv)': [45], 'engagement': [47, 97], 'compliance,': [49], '(v)': [50], 'rehabilitation,': [51], '(vi)': [53], 'other': [54], 'administrative': [55, 106], 'applications.': [56], 'The': [57, 161], 'impact': [58], 'observed': [62], 'detecting': [64], 'clinical': [65], 'conditions': [66], 'diagnostic': [71], 'services,': [72], 'controlling': [73], 'outbreak': [75], 'coronavirus': [77], 'disease': [78], '2019': [79], '(COVID-19)': [80], 'with': [81, 100], 'early': [82], 'diagnosis,': [83], 'providing': [84], 'care': [87], 'using': [88], 'AI-powered': [89], 'tools,': [90], 'managing': [91], 'electronic': [92], 'health': [93, 184, 212], 'records,': [94], 'augmenting': [95], 'compliance': [99], 'treatment': [102], 'plan,': [103], 'reducing': [104], 'workload': [107], 'professionals': [110], '(HCPs),': [111], 'discovering': [112], 'new': [113], 'drugs': [114], 'vaccines,': [116], 'spotting': [117], 'prescription': [119], 'errors,': [120], 'extensive': [121], 'data': [122], 'storage': [123], 'analysis,': [125], 'technology-assisted': [127], 'rehabilitation.': [128], 'Nevertheless,': [129], 'this': [130], 'science': [131], 'pitch': [132], 'meets': [133], 'several': [134], 'technical,': [135], 'ethical,': [136, 195], 'social': [138], 'challenges,': [139], 'including': [140], 'privacy,': [141], 'safety,': [142], 'right': [144], 'to': [145, 191, 233], 'decide': [146], 'try,': [148], 'costs,': [149], 'information': [150], 'consent,': [152], 'access,': [153], 'efficacy,': [155], 'while': [156, 199], 'integrating': [157], 'into': [159], 'governance': [162, 187], 'crucial': [167], 'for': [168, 174], 'safety': [170], 'accountability': [172], 'raising': [175], 'HCPs’': [176], 'belief': [177], 'enhancing': [179], 'acceptance': [180, 202], 'boosting': [182], 'significant': [183], 'consequences.': [185], 'Effective': [186], 'prerequisite': [190], 'precisely': [192], 'address': [193], 'regulatory,': [194], 'trust': [197], 'issues': [198], 'advancing': [200], 'implementation': [204], 'AI.': [206], 'Since': [207], 'COVID-19': [208], 'hit': [209], 'global': [211], 'system,': [213], 'concept': [215], 'has': [218], 'created': [219], 'revolution': [221], 'healthcare,': [223], 'such': [225], 'an': [226], 'uprising': [227], 'could': [228], 'be': [229], 'another': [230], 'step': [231], 'forward': [232], 'meet': [234], 'future': [235], 'needs.': [237]}",2023,"['Health care', 'Corporate governance', 'Medicine', 'Accountability', 'Knowledge management', 'Business', 'Computer science', 'Political science', 'Finance', 'Law']","Artificial intelligence (AI) applications have transformed healthcare. This study is based on a general literature review uncovering the role of AI in healthcare and focuses on the following key aspects: (i) medical imaging and diagnostics, (ii) virtual patient care, (iii) medical research and drug discovery, (iv) patient engagement and compliance, (v) rehabilitation, and (vi) other administrative applications. The impact of AI is observed in detecting clinical conditions in medical imaging and diagnostic services, controlling the outbreak of coronavirus disease 2019 (COVID-19) with early diagnosis, providing virtual patient care using AI-powered tools, managing electronic health records, augmenting patient engagement and compliance with the treatment plan, reducing the administrative workload of healthcare professionals (HCPs), discovering new drugs and vaccines, spotting medical prescription errors, extensive data storage and analysis, and technology-assisted rehabilitation. Nevertheless, this science pitch meets several technical, ethical, and social challenges, including privacy, safety, the right to decide and try, costs, information and consent, access, and efficacy, while integrating AI into healthcare. The governance of AI applications is crucial for patient safety and accountability and for raising HCPs’ belief in enhancing acceptance and boosting significant health consequences. Effective governance is a prerequisite to precisely address regulatory, ethical, and trust issues while advancing the acceptance and implementation of AI. Since COVID-19 hit the global health system, the concept of AI has created a revolution in healthcare, and such an uprising could be another step forward to meet future healthcare needs."
https://openalex.org/W3011186445,Innovation and Design in the Age of Artificial Intelligence,"{'At': [0], 'the': [1, 11, 62, 65, 70, 124, 129, 135, 179, 206, 224, 248, 251, 268, 293, 308, 347, 359, 367, 409, 432], 'heart': [2], 'of': [3, 23, 64, 72, 75, 80, 131, 160, 193, 208, 215, 226, 242, 250, 295, 310, 326, 362, 369, 388, 434], 'any': [4], 'innovation': [5, 24, 36, 66, 127, 140, 229, 440], 'process': [6], 'lies': [7], 'a': [8, 120, 400, 405, 414], 'fundamental': [9], 'practice:': [10], 'way': [12, 403], 'people': [13], 'create': [14, 107], 'ideas': [15], 'and': [16, 28, 59, 82, 126, 139, 182, 200, 210, 217, 228, 259, 265, 271, 302, 338, 390, 439, 443], 'solve': [17], 'problems.': [18], 'This': [19, 117, 173, 429], '“decision': [20], 'making”': [21], 'side': [22], 'is': [25, 149], 'what': [26, 99], 'scholars': [27, 442], 'practitioners': [29], 'refer': [30], 'to': [31, 61, 92, 186, 220, 237, 263, 282, 322], 'as': [32, 146], '“design.”': [33], 'Decisions': [34], 'in': [35, 109, 128, 175, 230, 395, 399], 'processes': [37], 'have': [38], 'so': [39], 'far': [40], 'been': [41], 'taken': [42], 'by': [43, 52, 152, 246, 376], 'humans.': [44], 'What': [45, 68], 'happens': [46], 'when': [47], 'they': [48], 'can': [49], 'be': [50, 171], 'substituted': [51], 'machines?': [53], 'Artificial': [54], 'Intelligence': [55], '(AI)': [56], 'brings': [57, 183], 'data': [58], 'algorithms': [60, 393], 'core': [63], 'processes.': [67], 'are': [69, 197, 313, 334, 340, 378, 426], 'implications': [71, 136, 433], 'this': [73], 'diffusion': [74], 'AI': [76, 85, 233, 279, 290, 306, 355], 'for': [77, 122, 137, 178, 223, 329, 437], 'our': [78], 'understanding': [79, 123, 165], 'design': [81, 110, 125, 138, 155, 184, 227, 244, 287, 438], 'innovation?': [83], 'Is': [84], 'just': [86], 'another': [87], 'digital': [88], 'technology': [89], 'that,': [90, 145], 'akin': [91], 'many': [93, 239], 'others,': [94], 'will': [95, 105], 'not': [96, 357], 'significantly': [97, 150], 'question': [98], 'we': [100, 143], 'know': [101], 'about': [102], 'design?': [103], 'Or': [104], 'it': [106, 364], 'transformations': [108], 'that': [111, 163, 312, 333, 339, 384], 'current': [112], 'theoretical': [113], 'frameworks': [114], 'cannot': [115], 'capture?': [116], 'paper': [118, 430], 'proposes': [119], 'framework': [121], 'age': [130], 'AI.': [132], 'We': [133], 'discuss': [134], 'theory.': [141], 'Specifically,': [142], 'observe': [144], 'creative': [147], 'problem‐solving': [148], 'conducted': [151], 'algorithms,': [153], 'human': [154], 'increasingly': [156], 'becomes': [157], 'an': [158, 191, 235, 323], 'activity': [159, 192], 'sensemaking': [161], ',': [162], 'is,': [164, 189], 'which': [166, 188, 425], 'problems': [167, 411], 'should': [168], 'or': [169], 'could': [170], 'addressed.': [172], 'shift': [174], 'focus': [176], 'calls': [177], 'new': [180], 'theories': [181], 'closer': [185], 'leadership,': [187], 'inherently,': [190], 'sensemaking.': [194], 'Our': [195], 'insights': [196, 436], 'derived': [198], 'from': [199], 'illustrated': [201], 'with': [202, 213, 413], 'two': [203, 221], 'cases': [204], 'at': [205], 'frontier': [207], 'AI—Netflix': [209], 'Airbnb': [211], '(complemented': [212], 'analyses': [214], 'Microsoft': [216], 'Tesla)—which': [218], 'point': [219], 'directions': [222], 'evolution': [225], 'firms.': [231], 'First,': [232], 'enables': [234, 307], 'organization': [236], 'overcome': [238], 'past': [240], 'limitations': [241, 387], 'human‐intensive': [243], 'processes,': [245], 'improving': [247], 'scalability': [249], 'process,': [252], 'broadening': [253], 'its': [254, 261], 'scope': [255], 'across': [256, 346], 'traditional': [257], 'boundaries,': [258], 'enhancing': [260], 'ability': [262], 'learn': [264], 'adapt': [266], 'on': [267], 'fly.': [269], 'Second,': [270], 'maybe': [272], 'more': [273, 314, 336], 'surprising,': [274], 'while': [275, 354], 'removing': [276], 'these': [277, 396, 435], 'limitations,': [278], 'also': [280], 'appears': [281], 'deeply': [283], 'enact': [284], 'several': [285], 'popular': [286], 'principles': [288, 294, 361], '.': [289], 'thus': [291], 'reinforces': [292], 'Design': [296], 'Thinking,': [297], 'namely:': [298], 'being': [299], 'people‐centered,': [300], 'abductive,': [301], 'iterative.': [303], 'In': [304, 352], 'fact,': [305], 'creation': [309], 'solutions': [311], 'highly': [315], 'user': [316], 'centered': [317], 'than': [318, 404], 'human‐based': [319], 'approaches': [320], '(i.e.,': [321], 'extreme': [324], 'level': [325], 'granularity,': [327], 'designed': [328], 'every': [330], 'single': [331], 'person);': [332], 'potentially': [335], 'creative;': [337], 'continuously': [341], 'updated': [342], 'through': [343, 421], 'learning': [344, 382], 'iterations': [345], 'entire': [348], 'product': [349], 'life': [350], 'cycle.': [351], 'sum,': [353], 'does': [356], 'undermine': [358], 'basic': [360], 'design,': [363], 'profoundly': [365], 'changes': [366], 'practice': [368], 'design.': [370], 'Problem‐solving': [371], 'tasks,': [372, 424], 'traditionally': [373], 'carried': [374], 'out': [375], 'designers,': [377], 'now': [379], 'automated': [380], 'into': [381], 'loops': [383, 397], 'operate': [385], 'without': [386], 'volume': [389], 'speed.': [391], 'The': [392], 'embedded': [394], 'think': [398], 'radically': [401], 'different': [402], 'designer': [406], 'who': [407], 'handles': [408], 'complex': [410], 'holistically': [412], 'systemic': [415], 'perspective.': [416], 'Algorithms': [417], 'instead': [418], 'handle': [419], 'complexity': [420], 'very': [422], 'simple': [423], 'iterated': [427], 'continuously.': [428], 'discusses': [431], 'management': [441], 'practitioners.': [444]}",2020,"['Sensemaking', 'Computer science', 'Knowledge management', 'Process (computing)', 'Data science', 'Management science', 'Artificial intelligence', 'Engineering', 'Operating system']","At the heart of any innovation process lies a fundamental practice: the way people create ideas and solve problems. This “decision making” side of innovation is what scholars and practitioners refer to as “design.” Decisions in innovation processes have so far been taken by humans. What happens when they can be substituted by machines? Artificial Intelligence (AI) brings data and algorithms to the core of the innovation processes. What are the implications of this diffusion of AI for our understanding of design and innovation? Is AI just another digital technology that, akin to many others, will not significantly question what we know about design? Or will it create transformations in design that current theoretical frameworks cannot capture? This paper proposes a framework for understanding the design and innovation in the age of AI. We discuss the implications for design and innovation theory. Specifically, we observe that, as creative problem‐solving is significantly conducted by algorithms, human design increasingly becomes an activity of sensemaking , that is, understanding which problems should or could be addressed. This shift in focus calls for the new theories and brings design closer to leadership, which is, inherently, an activity of sensemaking. Our insights are derived from and illustrated with two cases at the frontier of AI—Netflix and Airbnb (complemented with analyses of Microsoft and Tesla)—which point to two directions for the evolution of design and innovation in firms. First, AI enables an organization to overcome many past limitations of human‐intensive design processes, by improving the scalability of the process, broadening its scope across traditional boundaries, and enhancing its ability to learn and adapt on the fly. Second, and maybe more surprising, while removing these limitations, AI also appears to deeply enact several popular design principles . AI thus reinforces the principles of Design Thinking, namely: being people‐centered, abductive, and iterative. In fact, AI enables the creation of solutions that are more highly user centered than human‐based approaches (i.e., to an extreme level of granularity, designed for every single person); that are potentially more creative; and that are continuously updated through learning iterations across the entire product life cycle. In sum, while AI does not undermine the basic principles of design, it profoundly changes the practice of design. Problem‐solving tasks, traditionally carried out by designers, are now automated into learning loops that operate without limitations of volume and speed. The algorithms embedded in these loops think in a radically different way than a designer who handles the complex problems holistically with a systemic perspective. Algorithms instead handle complexity through very simple tasks, which are iterated continuously. This paper discusses the implications of these insights for design and innovation management scholars and practitioners."
https://openalex.org/W3005335661,Artificial Intelligence in Medicine: Today and Tomorrow,"{'Artificial': [0], 'intelligence-powered': [1], 'medical': [2, 73, 136, 187], 'technologies': [3], 'are': [4], 'rapidly': [5], 'evolving': [6], 'into': [7], 'applicable': [8], 'solutions': [9], 'for': [10, 87, 108], 'clinical': [11, 43, 113, 128, 181], 'practice.': [12, 114], 'Deep': [13], 'learning': [14], 'algorithms': [15], 'can': [16], 'deal': [17], 'with': [18, 100, 126], 'increasing': [19], 'amounts': [20], 'of': [21, 35, 49, 56, 66, 77, 112, 134, 140, 148, 155, 175], 'data': [22], 'provided': [23], 'by': [24, 82], 'wearables,': [25], 'smartphones,': [26], 'and': [27, 61, 91, 164, 173, 189], 'other': [28], 'mobile': [29], 'monitoring': [30], 'sensors': [31], 'in': [32, 42, 138, 180], 'different': [33], 'areas': [34], 'medicine.': [36], 'Currently,': [37], 'only': [38], 'very': [39], 'specific': [40], 'settings': [41], 'practice': [44, 182], 'benefit': [45], 'from': [46, 102], 'the': [47, 54, 64, 119, 131, 135, 149, 169], 'application': [48], 'artificial': [50, 177], 'intelligence,': [51], 'such': [52, 109], 'as': [53, 143, 145], 'detection': [55], 'atrial': [57], 'fibrillation,': [58], 'epilepsy': [59], 'seizures,': [60], 'hypoglycemia,': [62], 'or': [63, 72], 'diagnosis': [65], 'disease': [67], 'based': [68], 'on': [69, 168, 183], 'histopathological': [70], 'examination': [71], 'imaging.': [74], 'The': [75, 153], 'implementation': [76], 'augmented': [78], 'medicine': [79, 142], 'is': [80, 98, 158], 'long-awaited': [81], 'patients': [83], 'because': [84], 'it': [85, 97], 'allows': [86], 'a': [88, 92, 166], 'greater': [89], 'autonomy': [90], 'more': [93], 'personalized': [94], 'treatment,': [95], 'however,': [96], 'met': [99], 'resistance': [101], 'physicians': [103], 'which': [104], 'were': [105], 'not': [106], 'prepared': [107], 'an': [110], 'evolution': [111], 'This': [115], 'phenomenon': [116], 'also': [117], 'creates': [118], 'need': [120], 'to': [121, 159], 'validate': [122], 'these': [123], 'modern': [124], 'tools': [125], 'traditional': [127], 'trials,': [129], 'debate': [130], 'educational': [132], 'upgrade': [133], 'curriculum': [137], 'light': [139], 'digital': [141], 'well': [144], 'ethical': [146], 'consideration': [147], 'ongoing': [150], 'connected': [151], 'monitoring.': [152], 'aim': [154], 'this': [156], 'paper': [157], 'discuss': [160], 'recent': [161], 'scientific': [162], 'literature': [163], 'provide': [165], 'perspective': [167], 'benefits,': [170], 'future': [171], 'opportunities': [172], 'risks': [174], 'established': [176], 'intelligence': [178], 'applications': [179], 'physicians,': [184], 'healthcare': [185], 'institutions,': [186], 'education,': [188], 'bioethics.': [190]}",2020,"['Clinical Practice', 'Curriculum', 'Autonomy', 'Bioethics', 'Health care', 'Medicine', 'Engineering ethics', 'Medical education', 'Artificial intelligence', 'Computer science', 'Psychology', 'Engineering', 'Nursing', 'Political science', 'Law', 'Pedagogy']","Artificial intelligence-powered medical technologies are rapidly evolving into applicable solutions for clinical practice. Deep learning algorithms can deal with increasing amounts of data provided by wearables, smartphones, and other mobile monitoring sensors in different areas of medicine. Currently, only very specific settings in clinical practice benefit from the application of artificial intelligence, such as the detection of atrial fibrillation, epilepsy seizures, and hypoglycemia, or the diagnosis of disease based on histopathological examination or medical imaging. The implementation of augmented medicine is long-awaited by patients because it allows for a greater autonomy and a more personalized treatment, however, it is met with resistance from physicians which were not prepared for such an evolution of clinical practice. This phenomenon also creates the need to validate these modern tools with traditional clinical trials, debate the educational upgrade of the medical curriculum in light of digital medicine as well as ethical consideration of the ongoing connected monitoring. The aim of this paper is to discuss recent scientific literature and provide a perspective on the benefits, future opportunities and risks of established artificial intelligence applications in clinical practice on physicians, healthcare institutions, medical education, and bioethics."
https://openalex.org/W4225597912,On evaluation metrics for medical applications of artificial intelligence,"{'Abstract': [0], 'Clinicians': [1], 'and': [2, 64, 104, 144], 'software': [3], 'developers': [4], 'need': [5], 'to': [6, 37, 68, 128], 'understand': [7], 'how': [8, 110], 'proposed': [9], 'machine': [10], 'learning': [11], '(ML)': [12], 'models': [13, 55, 70], 'could': [14], 'improve': [15], 'patient': [16], 'care.': [17], 'No': [18], 'single': [19], 'metric': [20], 'captures': [21], 'all': [22], 'the': [23, 72, 95, 101, 132], 'desirable': [24], 'properties': [25], 'of': [26, 54, 89, 97, 109], 'a': [27, 39, 106], 'model,': [28], 'which': [29], 'is': [30, 62], 'why': [31], 'several': [32], 'metrics': [33, 92, 112, 135], 'are': [34, 45], 'typically': [35], 'reported': [36], 'summarize': [38], 'model’s': [40], 'performance.': [41], 'Unfortunately,': [42], 'these': [43], 'measures': [44], 'not': [46], 'easily': [47, 147], 'understandable': [48], 'by': [49], 'many': [50], 'clinicians.': [51], 'Moreover,': [52], 'comparison': [53], 'across': [56], 'studies': [57, 82], 'in': [58, 84, 94, 100, 130, 137], 'an': [59, 87, 119], 'objective': [60], 'manner': [61], 'challenging,': [63], 'no': [65], 'tool': [66, 123], 'exists': [67], 'compare': [69], 'using': [71], 'same': [73], 'performance': [74], 'metrics.': [75], 'This': [76], 'paper': [77, 139], 'looks': [78], 'at': [79], 'previous': [80], 'ML': [81], 'done': [83], 'gastroenterology,': [85], 'provides': [86], 'explanation': [88, 108], 'what': [90], 'different': [91, 111], 'mean': [93], 'context': [96], 'binary': [98], 'classification': [99], 'presented': [102, 136], 'studies,': [103], 'gives': [105], 'thorough': [107], 'should': [113], 'be': [114, 126], 'interpreted.': [115], 'We': [116], 'also': [117], 'release': [118], 'open': [120], 'source': [121], 'web-based': [122], 'that': [124, 141], 'may': [125, 146], 'used': [127], 'aid': [129], 'calculating': [131], 'most': [133], 'relevant': [134], 'this': [138], 'so': [140], 'other': [142], 'researchers': [143], 'clinicians': [145], 'incorporate': [148], 'them': [149], 'into': [150], 'their': [151], 'research.': [152]}",2022,"['Computer science', 'Metric (unit)', 'Context (archaeology)', 'Machine learning', 'Data science', 'Software', 'Data mining', 'Binary classification', 'Open source', 'Artificial intelligence', 'Information retrieval', 'Support vector machine', 'Paleontology', 'Operations management', 'Biology', 'Programming language', 'Economics']","Abstract Clinicians and software developers need to understand how proposed machine learning (ML) models could improve patient care. No single metric captures all the desirable properties of a model, which is why several metrics are typically reported to summarize a model’s performance. Unfortunately, these measures are not easily understandable by many clinicians. Moreover, comparison of models across studies in an objective manner is challenging, and no tool exists to compare models using the same performance metrics. This paper looks at previous ML studies done in gastroenterology, provides an explanation of what different metrics mean in the context of binary classification in the presented studies, and gives a thorough explanation of how different metrics should be interpreted. We also release an open source web-based tool that may be used to aid in calculating the most relevant metrics presented in this paper so that other researchers and clinicians may easily incorporate them into their research."
https://openalex.org/W4226065182,Explainable Artificial Intelligence (XAI),"{'Complex': [0], 'machine': [1, 73], 'learning': [2, 74], 'models': [3, 10], 'perform': [4], 'better.': [5], 'However,': [6], 'we': [7, 161], 'consider': [8, 134], 'these': [9], 'as': [11, 32, 34], 'black': [12], 'boxes.': [13], 'That’s': [14], 'where': [15], 'Explainable': [16], 'AI': [17, 52], '(XAI)': [18], 'comes': [19], 'into': [20], 'play.': [21], 'Understanding': [22], 'why': [23], 'a': [24, 27, 104, 141, 146, 149, 167], 'model': [25], 'makes': [26], 'specific': [28, 163], 'prediction': [29, 106, 147], 'can': [30, 107], 'be': [31], 'crucial': [33], 'its': [35], 'accuracy': [36], 'for': [37, 116, 172], 'many': [38, 44, 101], 'applications,': [39, 46], 'researchers,': [40], 'and': [41, 49, 59, 67, 93, 103, 156], 'decision-makers.': [42], 'In': [43], 'real-world': [45], 'the': [47, 96, 120, 127, 154], 'explainability': [48, 66], 'transparency': [50], 'of': [51, 110, 136, 158], 'systems': [53], 'are': [54, 61, 85], 'indispensable.': [55], 'The': [56], 'research': [57], 'community': [58], 'industry': [60], 'giving': [62], 'growing': [63], 'attention': [64], 'to': [65, 71, 118, 126, 133, 144], 'explainable': [68], 'AI.': [69], 'Compared': [70], 'traditional': [72], 'methods,': [75], 'deep': [76], 'neural': [77, 150, 159], 'networks': [78], '(DNNs)': [79], 'have': [80, 132], 'been': [81], 'very': [82], 'successful.': [83], 'DNNs': [84], 'comparably': [86], 'weak': [87], 'in': [88, 140], 'explaining': [89], 'their': [90], 'inference': [91], 'processes': [92], 'results': [94], 'because': [95], 'data': [97, 124], 'input': [98, 125], 'passes': [99], 'through': [100], 'layers,': [102], 'single': [105], 'involve': [108], 'millions': [109, 135], 'mathematical': [111], 'operations.': [112], 'It': [113], 'is': [114, 170], 'difficult': [115], 'humans': [117], 'follow': [119], 'exact': [121], 'mapping': [122], 'from': [123], 'predicted': [128], 'result.': [129], 'We': [130], 'would': [131], 'weights': [137], 'that': [138], 'interact': [139], 'complex': [142], 'way': [143], 'understand': [145], 'by': [148], 'network.': [151], 'To': [152], 'interpret': [153], 'behavior': [155], 'predictions': [157], 'networks,': [160], 'need': [162], 'interpretation': [164], 'methods.': [165], 'Thus,': [166], 'new': [168], 'frontier': [169], 'opening': [171], 'researchers.': [173]}",2021,"['Artificial intelligence', 'Computer science', 'Geography']","Complex machine learning models perform better. However, we consider these models as black boxes. That’s where Explainable AI (XAI) comes into play. Understanding why a model makes a specific prediction can be as crucial as its accuracy for many applications, researchers, and decision-makers. In many real-world applications, the explainability and transparency of AI systems are indispensable. The research community and industry are giving growing attention to explainability and explainable AI. Compared to traditional machine learning methods, deep neural networks (DNNs) have been very successful. DNNs are comparably weak in explaining their inference processes and results because the data input passes through many layers, and a single prediction can involve millions of mathematical operations. It is difficult for humans to follow the exact mapping from data input to the predicted result. We would have to consider millions of weights that interact in a complex way to understand a prediction by a neural network. To interpret the behavior and predictions of neural networks, we need specific interpretation methods. Thus, a new frontier is opening for researchers."
https://openalex.org/W4388962306,"Artificial intelligence, firm growth, and product innovation","{'We': [0, 10], 'study': [1], 'the': [2], 'use': [3], 'and': [4, 41, 75, 94], 'economic': [5], 'impact': [6], 'of': [7, 15, 66], 'AI': [8, 17, 29, 58, 67, 89], 'technologies.': [9], 'propose': [11], 'a': [12, 25], 'new': [13, 86], 'measure': [14, 23], 'firm-level': [16], 'investments': [18, 30, 59], 'using': [19, 60], 'employee': [20], 'resumes.': [21], 'Our': [22, 52, 82], 'reveals': [24], 'stark': [26], 'increase': [27], 'in': [28, 38], 'across': [31], 'sectors.': [32], 'AI-investing': [33], 'firms': [34, 74, 96], 'experience': [35], 'higher': [36, 79], 'growth': [37, 45, 70, 93], 'sales,': [39], 'employment,': [40], 'market': [42], 'valuations.': [43], 'This': [44], 'comes': [46], 'primarily': [47], 'through': [48, 97], 'increased': [49], 'product': [50, 98], 'innovation.': [51, 99], 'results': [53, 83], 'are': [54], 'robust': [55], 'to': [56, 63, 92], 'instrumenting': [57], ""firms'"": [61], 'exposure': [62], ""universities'"": [64], 'supply': [65], 'graduates.': [68], 'AI-powered': [69], 'concentrates': [71], 'among': [72], 'larger': [73], 'is': [76], 'associated': [77], 'with': [78], 'industry': [80], 'concentration.': [81], 'highlight': [84], 'that': [85], 'technologies': [87], 'like': [88], 'can': [90], 'contribute': [91], 'superstar': [95]}",2023,"['Superstar', 'Product (mathematics)', 'Industrial organization', 'Product market', 'New product development', 'Business', 'Product innovation', 'Economics', 'Marketing', 'Microeconomics', 'Incentive', 'Geometry', 'Mathematics', 'Advertising']","We study the use and economic impact of AI technologies. We propose a new measure of firm-level AI investments using employee resumes. Our measure reveals a stark increase in AI investments across sectors. AI-investing firms experience higher growth in sales, employment, and market valuations. This growth comes primarily through increased product innovation. Our results are robust to instrumenting AI investments using firms' exposure to universities' supply of AI graduates. AI-powered growth concentrates among larger firms and is associated with higher industry concentration. Our results highlight that new technologies like AI can contribute to growth and superstar firms through product innovation."
https://openalex.org/W2977373448,The impact of artificial intelligence in medicine on the future role of the physician,"{'The': [0, 42], 'practice': [1], 'of': [2, 9, 15, 35, 45, 67, 83, 117], 'medicine': [3], 'is': [4, 106], 'changing': [5], 'with': [6, 19], 'the': [7, 31, 65, 81, 91, 115, 145], 'development': [8], 'new': [10], 'Artificial': [11], 'Intelligence': [12], '(AI)': [13], 'methods': [14], 'machine': [16], 'learning.': [17], 'Coupled': [18], 'rapid': [20], 'improvements': [21], 'in': [22, 47, 75, 120, 124], 'computer': [23], 'processing,': [24], 'these': [25], 'AI-based': [26, 69, 118, 135], 'systems': [27, 70, 119, 136], 'are': [28, 141], 'already': [29], 'improving': [30], 'accuracy': [32], 'and': [33, 37, 103, 130, 140], 'efficiency': [34], 'diagnosis': [36], 'treatment': [38], 'across': [39], 'various': [40], 'specializations.': [41], 'increasing': [43], 'focus': [44], 'AI': [46, 57], 'radiology': [48], 'has': [49], 'led': [50], 'to': [51, 98, 143], 'some': [52, 76], 'experts': [53], 'suggesting': [54], 'that': [55, 110, 134], 'someday': [56], 'may': [58], 'even': [59], 'replace': [60, 73, 144], 'radiologists.': [61], 'These': [62], 'suggestions': [63], 'raise': [64], 'question': [66], 'whether': [68], 'will': [71, 79, 137], 'eventually': [72], 'physicians': [74, 84, 94, 139], 'specializations': [77, 125], 'or': [78], 'augment': [80, 138], 'role': [82, 116], 'without': [85], 'actually': [86], 'replacing': [87], 'them.': [88], 'To': [89, 109], 'assess': [90], 'impact': [92], 'on': [93], 'this': [95, 101, 112], 'research': [96], 'seeks': [97], 'better': [99], 'understand': [100], 'technology': [102], 'how': [104], 'it': [105], 'transforming': [107], 'medicine.': [108], 'end': [111], 'paper': [113], 'researches': [114], 'performing': [121], 'medical': [122], 'work': [123], 'including': [126], 'radiology,': [127], 'pathology,': [128], 'ophthalmology,': [129], 'cardiology.': [131], 'It': [132], 'concludes': [133], 'unlikely': [142], 'traditional': [146], 'physician–patient': [147], 'relationship.': [148]}",2019,"['Artificial intelligence', 'Applications of artificial intelligence', 'Medicine', 'Work (physics)', 'Computer science', 'Engineering', 'Mechanical engineering']","The practice of medicine is changing with the development of new Artificial Intelligence (AI) methods of machine learning. Coupled with rapid improvements in computer processing, these AI-based systems are already improving the accuracy and efficiency of diagnosis and treatment across various specializations. The increasing focus of AI in radiology has led to some experts suggesting that someday AI may even replace radiologists. These suggestions raise the question of whether AI-based systems will eventually replace physicians in some specializations or will augment the role of physicians without actually replacing them. To assess the impact on physicians this research seeks to better understand this technology and how it is transforming medicine. To that end this paper researches the role of AI-based systems in performing medical work in specializations including radiology, pathology, ophthalmology, and cardiology. It concludes that AI-based systems will augment physicians and are unlikely to replace the traditional physician–patient relationship."
https://openalex.org/W4280651558,Explainable Artificial Intelligence in education,"{'There': [0], 'are': [1], 'emerging': [2, 27], 'concerns': [3], 'about': [4], 'the': [5, 17, 26, 43, 59, 74, 116, 132, 152, 174], 'Fairness,': [6], 'Accountability,': [7], 'Transparency,': [8], 'and': [9, 51, 106, 135, 169], 'Ethics': [10], '(FATE)': [11], 'of': [12, 19, 25, 45, 77, 126, 131, 138, 154, 177], 'educational': [13, 108, 159], 'interventions': [14], 'supported': [15], 'by': [16, 165], 'use': [18, 37, 44, 76], 'Artificial': [20], 'Intelligence': [21], '(AI)': [22], 'algorithms.': [23], 'One': [24], 'methods': [28, 46], 'for': [29, 53, 103, 120, 173], 'increasing': [30], 'trust': [31], 'in': [32, 69, 99, 156, 179], 'AI': [33, 39, 55, 78, 109, 127, 133, 160], 'systems': [34, 56], 'is': [35], 'to': [36, 91, 101], 'eXplainable': [38], '(XAI),': [40], 'which': [41], 'promotes': [42], 'that': [47, 67, 94, 150], 'produce': [48], 'transparent': [49], 'explanations': [50, 140], 'reasons': [52], 'decisions': [54], 'make.': [57], 'Considering': [58], 'existing': [60], 'literature': [61], 'on': [62, 115], 'XAI,': [63], 'this': [64], 'paper': [65, 163], 'argues': [66], 'XAI': [68, 178], 'education': [70], 'has': [71, 81], 'commonalities': [72], 'with': [73], 'broader': [75], 'but': [79], 'also': [80], 'distinctive': [82], 'needs.': [83], 'Accordingly,': [84], 'we': [85], 'first': [86], 'present': [87, 145], 'a': [88], 'framework,': [89], 'referred': [90], 'as': [92], 'XAI-ED,': [93], 'considers': [95], 'six': [96], 'key': [97, 112], 'aspects': [98, 113], 'relation': [100], 'explainability': [102], 'studying,': [104], 'designing': [105], 'developing': [107], 'tools.': [110, 161], 'These': [111], 'focus': [114], 'stakeholders,': [117], 'benefits,': [118], 'approaches': [119], 'presenting': [121], 'explanations,': [122], 'widely': [123], 'used': [124], 'classes': [125], 'models,': [128], 'human-centred': [129], 'designs': [130], 'interfaces': [134], 'potential': [136], 'pitfalls': [137], 'providing': [139], 'within': [141], 'education.': [142, 180], 'We': [143], 'then': [144], 'four': [146, 157], 'comprehensive': [147], 'case': [148], 'studies': [149], 'illustrate': [151], 'application': [153], 'XAI-ED': [155], 'different': [158], 'The': [162], 'concludes': [164], 'discussing': [166], 'opportunities,': [167], 'challenges': [168], 'future': [170], 'research': [171], 'needs': [172], 'effective': [175], 'incorporation': [176]}",2022,"['Transparency (behavior)', 'Accountability', 'Relation (database)', 'Computer science', 'Key (lock)', 'Knowledge management', 'Engineering ethics', 'Management science', 'Artificial intelligence', 'Political science', 'Engineering', 'Data mining', 'Law', 'Computer security']","There are emerging concerns about the Fairness, Accountability, Transparency, and Ethics (FATE) of educational interventions supported by the use of Artificial Intelligence (AI) algorithms. One of the emerging methods for increasing trust in AI systems is to use eXplainable AI (XAI), which promotes the use of methods that produce transparent explanations and reasons for decisions AI systems make. Considering the existing literature on XAI, this paper argues that XAI in education has commonalities with the broader use of AI but also has distinctive needs. Accordingly, we first present a framework, referred to as XAI-ED, that considers six key aspects in relation to explainability for studying, designing and developing educational AI tools. These key aspects focus on the stakeholders, benefits, approaches for presenting explanations, widely used classes of AI models, human-centred designs of the AI interfaces and potential pitfalls of providing explanations within education. We then present four comprehensive case studies that illustrate the application of XAI-ED in four different educational AI tools. The paper concludes by discussing opportunities, challenges and future research needs for the effective incorporation of XAI in education."
https://openalex.org/W2972320421,Artificial Intelligence in Anesthesiology,"{'Abstract': [0], 'Artificial': [1, 140], 'intelligence': [2, 18, 31, 70, 88, 114, 134, 141], 'has': [3, 142], 'been': [4], 'advancing': [5], 'in': [6, 32, 63, 86, 107, 130, 137, 151], 'fields': [7, 106], 'including': [8], 'anesthesiology.': [9], 'This': [10], 'scoping': [11], 'review': [12], 'of': [13, 16, 27, 29, 36, 41, 112, 128, 149], 'the': [14, 64, 116, 126, 143, 147], 'intersection': [15], 'artificial': [17, 30, 69, 87, 108, 113, 133], 'and': [19, 23, 45, 54, 73, 81, 97, 102, 125], 'anesthesia': [20, 37], 'research': [21], 'identified': [22, 62], 'summarized': [24], 'six': [25], 'themes': [26], 'applications': [28], 'anesthesiology:': [33], '(1)': [34, 75], 'depth': [35], 'monitoring,': [38], '(2)': [39, 84], 'control': [40], 'anesthesia,': [42], '(3)': [43, 103], 'event': [44], 'risk': [46], 'prediction,': [47], '(4)': [48], 'ultrasound': [49], 'guidance,': [50], '(5)': [51], 'pain': [52, 163], 'management,': [53], '(6)': [55], 'operating': [56], 'room': [57], 'logistics.': [58], 'Based': [59], 'on': [60], 'papers': [61], 'review,': [65], 'several': [66], 'topics': [67], 'within': [68], 'were': [71], 'described': [72], 'summarized:': [74], 'machine': [76, 93], 'learning': [77], '(including': [78], 'supervised,': [79], 'unsupervised,': [80], 'reinforcement': [82], 'learning),': [83], 'techniques': [85], '(': [89], 'e.g.': [90], ',': [91], 'classical': [92], 'learning,': [94, 99], 'neural': [95], 'networks': [96], 'deep': [98], 'Bayesian': [100], 'methods),': [101], 'major': [104], 'applied': [105], 'intelligence.': [109], 'The': [110], 'implications': [111], 'for': [115, 135], 'practicing': [117], 'anesthesiologist': [118], 'are': [119, 122], 'discussed': [120], 'as': [121], 'its': [123], 'limitations': [124], 'role': [127], 'clinicians': [129], 'further': [131], 'developing': [132], 'use': [136], 'clinical': [138], 'care.': [139], 'potential': [144], 'to': [145, 157, 161], 'impact': [146], 'practice': [148], 'anesthesiology': [150], 'aspects': [152], 'ranging': [153], 'from': [154], 'perioperative': [155], 'support': [156], 'critical': [158], 'care': [159], 'delivery': [160], 'outpatient': [162], 'management.': [164]}",2019,"['Anesthesiology', 'Medicine', 'Artificial intelligence', 'Artificial neural network', 'Machine learning', 'Computer science', 'Anesthesia']","Abstract Artificial intelligence has been advancing in fields including anesthesiology. This scoping review of the intersection of artificial intelligence and anesthesia research identified and summarized six themes of applications of artificial intelligence in anesthesiology: (1) depth of anesthesia monitoring, (2) control of anesthesia, (3) event and risk prediction, (4) ultrasound guidance, (5) pain management, and (6) operating room logistics. Based on papers identified in the review, several topics within artificial intelligence were described and summarized: (1) machine learning (including supervised, unsupervised, and reinforcement learning), (2) techniques in artificial intelligence ( e.g. , classical machine learning, neural networks and deep learning, Bayesian methods), and (3) major applied fields in artificial intelligence. The implications of artificial intelligence for the practicing anesthesiologist are discussed as are its limitations and the role of clinicians in further developing artificial intelligence for use in clinical care. Artificial intelligence has the potential to impact the practice of anesthesiology in aspects ranging from perioperative support to critical care delivery to outpatient pain management."
https://openalex.org/W4389437528,Education in the Era of Generative Artificial Intelligence (AI): Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning,"{'Since': [0], 'its': [1], 'maiden': [2], 'release': [3], 'into': [4], 'the': [5, 28, 52, 136], 'public': [6], 'domain': [7], 'on': [8, 159, 183], 'November': [9], '30,': [10], '2022,': [11], 'ChatGPT': [12, 46, 91, 99, 137, 161], 'garnered': [13], 'more': [14], 'than': [15], 'one': [16], 'million': [17], 'subscribers': [18], 'within': [19, 51], 'a': [20], 'week.': [21], 'The': [22, 42, 128, 155], 'generative': [23, 187], 'AI': [24, 66, 188], 'tool': [25], '⎼ChatGPT': [26], 'took': [27], 'world': [29], 'by': [30], 'surprise': [31], 'with': [32], 'it': [33], 'sophisticated': [34], 'capacity': [35], 'to': [36, 47, 68, 83, 105, 122, 165, 196], 'carry': [37], 'out': [38], 'remarkably': [39], 'complex': [40, 49], 'tasks.': [41], 'extraordinary': [43], 'abilities': [44], 'of': [45, 54, 90, 98, 107], 'perform': [48], 'tasks': [50], 'field': [53], 'education': [55, 198], 'has': [56], 'caused': [57], 'mixed': [58], 'feelings': [59], 'among': [60], 'educators,': [61], 'as': [62, 139], 'this': [63], 'advancement': [64], 'in': [65, 92, 135, 144], 'seems': [67], 'revolutionize': [69], 'existing': [70, 150], 'educational': [71], 'praxis.': [72], 'This': [73], 'is': [74], 'an': [75], 'exploratory': [76], 'study': [77, 156], 'that': [78, 118], 'synthesizes': [79], 'recent': [80], 'extant': [81], 'literature': [82], 'offer': [84], 'some': [85, 132], 'potential': [86], 'benefits': [87], 'and': [88, 95, 109, 125, 168, 174, 180, 194, 199], 'drawbacks': [89], 'promoting': [93], 'teaching': [94, 124, 167], 'learning.': [96, 169, 202], 'Benefits': [97], 'include': [100], 'but': [101], 'are': [102], 'not': [103], 'limited': [104], 'promotion': [106], 'personalized': [108], 'interactive': [110], 'learning,': [111], 'generating': [112, 140], 'prompts': [113], 'for': [114], 'formative': [115], 'assessment': [116], 'activities': [117], 'provide': [119], 'ongoing': [120], 'feedback': [121], 'inform': [123], 'learning': [126], 'etc.': [127, 154], 'paper': [129], 'also': [130], 'highlights': [131], 'inherent': [133], 'limitations': [134], 'such': [138], 'wrong': [141], 'information,': [142], 'biases': [143], 'data': [145], 'training,': [146], 'which': [147], 'may': [148], 'augment': [149], 'biases,': [151], 'privacy': [152], 'issues': [153], 'offers': [157], 'recommendations': [158], 'how': [160, 184], 'could': [162, 177, 190], 'be': [163, 191], 'leveraged': [164], 'maximize': [166], 'Policy': [170], 'makers,': [171], 'researchers,': [172], 'educators': [173], 'technology': [175], 'experts': [176], 'work': [178], 'together': [179], 'start': [181], 'conversations': [182], 'these': [185], 'evolving': [186], 'tools': [189], 'used': [192], 'safely': [193], 'constructively': [195], 'improve': [197], 'support': [200], 'students’': [201]}",2023,"['Surprise', 'Formative assessment', 'Generative grammar', 'Promotion (chess)', 'Computer science', 'Praxis', 'Field (mathematics)', 'Extant taxon', 'Artificial intelligence', 'Knowledge management', 'Psychology', 'Mathematics education', 'Political science', 'Social psychology', 'Pure mathematics', 'Law', 'Politics', 'Biology', 'Mathematics', 'Evolutionary biology']","Since its maiden release into the public domain on November 30, 2022, ChatGPT garnered more than one million subscribers within a week. The generative AI tool ⎼ChatGPT took the world by surprise with it sophisticated capacity to carry out remarkably complex tasks. The extraordinary abilities of ChatGPT to perform complex tasks within the field of education has caused mixed feelings among educators, as this advancement in AI seems to revolutionize existing educational praxis. This is an exploratory study that synthesizes recent extant literature to offer some potential benefits and drawbacks of ChatGPT in promoting teaching and learning. Benefits of ChatGPT include but are not limited to promotion of personalized and interactive learning, generating prompts for formative assessment activities that provide ongoing feedback to inform teaching and learning etc. The paper also highlights some inherent limitations in the ChatGPT such as generating wrong information, biases in data training, which may augment existing biases, privacy issues etc. The study offers recommendations on how ChatGPT could be leveraged to maximize teaching and learning. Policy makers, researchers, educators and technology experts could work together and start conversations on how these evolving generative AI tools could be used safely and constructively to improve education and support students’ learning."
https://openalex.org/W4383912288,Artificial Intelligence in Pharmaceutical Technology and Drug Delivery Design,"{'Artificial': [0], 'intelligence': [1], '(AI)': [2], 'has': [3], 'emerged': [4], 'as': [5], 'a': [6, 29, 71], 'powerful': [7], 'tool': [8], 'that': [9, 47, 147], 'harnesses': [10], 'anthropomorphic': [11], 'knowledge': [12], 'and': [13, 25, 37, 54, 61, 74, 99, 109, 114, 124, 134, 158, 182, 202, 209, 225], 'provides': [14, 188], 'expedited': [15], 'solutions': [16], 'to': [17, 77, 92, 153], 'complex': [18], 'challenges.': [19], 'Remarkable': [20], 'advancements': [21], 'in': [22, 32, 106, 171, 196, 208, 213], 'AI': [23, 45, 89, 145, 170, 212], 'technology': [24], 'machine': [26], 'learning': [27, 103], 'present': [28], 'transformative': [30], 'opportunity': [31], 'the': [33, 82, 112, 122, 130, 166, 205, 214], 'drug': [34, 67, 78, 86, 117, 172, 174, 222], 'discovery,': [35, 79, 173], 'formulation,': [36], 'testing': [38], 'of': [39, 84, 116, 126, 169, 191, 211], 'pharmaceutical': [40, 197, 215], 'dosage': [41, 176], 'forms.': [42], 'By': [43], 'utilizing': [44], 'algorithms': [46, 104, 146], 'analyze': [48, 148], 'extensive': [49, 133], 'biological': [50], 'data,': [51, 151], 'including': [52], 'genomics': [53], 'proteomics,': [55], 'researchers': [56], 'can': [57, 90, 110, 141], 'identify': [58], 'disease-associated': [59], 'targets': [60], 'predict': [62, 111], 'their': [63, 200], 'interactions': [64], 'with': [65], 'potential': [66], 'candidates.': [68, 118], 'This': [69, 119, 162, 186], 'enables': [70, 121], 'more': [72, 154], 'efficient': [73], 'targeted': [75], 'approach': [76], 'thereby': [80], 'increasing': [81], 'likelihood': [83], 'successful': [85], 'approvals.': [87], 'Furthermore,': [88], 'contribute': [91], 'reducing': [93, 129], 'development': [94, 100, 223], 'costs': [95], 'by': [96], 'optimizing': [97], 'research': [98], 'processes.': [101], 'Machine': [102], 'assist': [105], 'experimental': [107], 'design': [108], 'pharmacokinetics': [113], 'toxicity': [115], 'capability': [120], 'prioritization': [123], 'optimization': [125], 'lead': [127], 'compounds,': [128], 'need': [131], 'for': [132, 220], 'costly': [135], 'animal': [136], 'testing.': [137], 'Personalized': [138], 'medicine': [139], 'approaches': [140, 194], 'be': [142], 'facilitated': [143], 'through': [144], 'real-world': [149], 'patient': [150, 160, 226], 'leading': [152], 'effective': [155], 'treatment': [156], 'outcomes': [157], 'improved': [159], 'adherence.': [161], 'comprehensive': [163], 'review': [164, 187], 'explores': [165], 'wide-ranging': [167], 'applications': [168], 'delivery': [175], 'form': [177], 'designs,': [178], 'process': [179], 'optimization,': [180], 'testing,': [181], 'pharmacokinetics/pharmacodynamics': [183], '(PK/PD)': [184], 'studies.': [185], 'an': [189], 'overview': [190], 'various': [192], 'AI-based': [193], 'utilized': [195], 'technology,': [198], 'highlighting': [199], 'benefits': [201], 'drawbacks.': [203], 'Nevertheless,': [204], 'continued': [206], 'investment': [207], 'exploration': [210], 'industry': [216], 'offer': [217], 'exciting': [218], 'prospects': [219], 'enhancing': [221], 'processes': [224], 'care.': [227]}",2023,"['Computer science', 'Drug discovery', 'Drug development', 'Pharmaceutical industry', 'Risk analysis (engineering)', 'Artificial intelligence', 'Drug', 'Data science', 'Medicine', 'Pharmacology', 'Bioinformatics', 'Biology']","Artificial intelligence (AI) has emerged as a powerful tool that harnesses anthropomorphic knowledge and provides expedited solutions to complex challenges. Remarkable advancements in AI technology and machine learning present a transformative opportunity in the drug discovery, formulation, and testing of pharmaceutical dosage forms. By utilizing AI algorithms that analyze extensive biological data, including genomics and proteomics, researchers can identify disease-associated targets and predict their interactions with potential drug candidates. This enables a more efficient and targeted approach to drug discovery, thereby increasing the likelihood of successful drug approvals. Furthermore, AI can contribute to reducing development costs by optimizing research and development processes. Machine learning algorithms assist in experimental design and can predict the pharmacokinetics and toxicity of drug candidates. This capability enables the prioritization and optimization of lead compounds, reducing the need for extensive and costly animal testing. Personalized medicine approaches can be facilitated through AI algorithms that analyze real-world patient data, leading to more effective treatment outcomes and improved patient adherence. This comprehensive review explores the wide-ranging applications of AI in drug discovery, drug delivery dosage form designs, process optimization, testing, and pharmacokinetics/pharmacodynamics (PK/PD) studies. This review provides an overview of various AI-based approaches utilized in pharmaceutical technology, highlighting their benefits and drawbacks. Nevertheless, the continued investment in and exploration of AI in the pharmaceutical industry offer exciting prospects for enhancing drug development processes and patient care."
https://openalex.org/W3146345129,Artificial Intelligence in Cancer Research and Precision Medicine,"{'Abstract': [0], 'Artificial': [1], 'intelligence': [2], '(AI)': [3], 'is': [4], 'rapidly': [5], 'reshaping': [6], 'cancer': [7, 85, 143], 'research': [8], 'and': [9, 49, 58, 64, 110, 131, 133], 'personalized': [10], 'clinical': [11], 'care.': [12], 'Availability': [13], 'of': [14, 35, 41, 51, 56, 103, 125, 139], 'high-dimensionality': [15], 'datasets': [16], 'coupled': [17], 'with': [18], 'advances': [19, 74], 'in': [20, 38, 84, 122, 141], 'high-performance': [21], 'computing,': [22], 'as': [23, 25], 'well': [24], 'innovative': [26], 'deep': [27], 'learning': [28], 'architectures,': [29], 'has': [30, 94], 'led': [31], 'to': [32, 53, 61, 66, 97, 107, 127], 'an': [33], 'explosion': [34], 'AI': [36, 93, 126, 140], 'use': [37], 'various': [39], 'aspects': [40, 102], 'oncology': [42], 'research.': [43], 'These': [44], 'applications': [45], 'range': [46], 'from': [47], 'detection': [48], 'classification': [50], 'cancer,': [52], 'molecular': [54], 'characterization': [55], 'tumors': [57], 'their': [59], 'microenvironment,': [60], 'drug': [62], 'discovery': [63], 'repurposing,': [65], 'predicting': [67], 'treatment': [68, 109], 'outcomes': [69], 'for': [70, 137], 'patients.': [71], 'As': [72], 'these': [73], 'start': [75], 'penetrating': [76], 'the': [77, 95, 118, 123, 142], 'clinic,': [78], 'we': [79, 116], 'foresee': [80], 'a': [81, 135], 'shifting': [82], 'paradigm': [83], 'care': [86], 'becoming': [87], 'strongly': [88], 'driven': [89], 'by': [90], 'AI.': [91], 'Significance:': [92], 'potential': [96], 'dramatically': [98], 'affect': [99], 'nearly': [100], 'all': [101], 'oncology—from': [104], 'enhancing': [105], 'diagnosis': [106], 'personalizing': [108], 'discovering': [111], 'novel': [112], 'anticancer': [113], 'drugs.': [114], 'Here,': [115], 'review': [117], 'recent': [119], 'enormous': [120], 'progress': [121], 'application': [124], 'oncology,': [128], 'highlight': [129], 'limitations': [130], 'pitfalls,': [132], 'chart': [134], 'path': [136], 'adoption': [138], 'clinic.': [144]}",2021,"['Repurposing', 'Precision medicine', 'Artificial intelligence', 'Cancer', 'Drug repositioning', 'Personalized medicine', 'Computer science', 'Drug discovery', 'Deep learning', 'Cancer Medicine', 'Medicine', 'Data science', 'Bioinformatics', 'Drug', 'Internal medicine', 'Pathology', 'Pharmacology', 'Biology', 'Ecology']","Abstract Artificial intelligence (AI) is rapidly reshaping cancer research and personalized clinical care. Availability of high-dimensionality datasets coupled with advances in high-performance computing, as well as innovative deep learning architectures, has led to an explosion of AI use in various aspects of oncology research. These applications range from detection and classification of cancer, to molecular characterization of tumors and their microenvironment, to drug discovery and repurposing, to predicting treatment outcomes for patients. As these advances start penetrating the clinic, we foresee a shifting paradigm in cancer care becoming strongly driven by AI. Significance: AI has the potential to dramatically affect nearly all aspects of oncology—from enhancing diagnosis to personalizing treatment and discovering novel anticancer drugs. Here, we review the recent enormous progress in the application of AI to oncology, highlight limitations and pitfalls, and chart a path for adoption of AI in the cancer clinic."
https://openalex.org/W2163605009,ImageNet classification with deep convolutional neural networks,"{'We': [0, 124], 'trained': [1], 'a': [2, 79, 92, 111, 127, 138], 'large,': [3], 'deep': [4], 'convolutional': [5, 63], 'neural': [6, 50], 'network': [7], 'to': [8, 120, 147], 'classify': [9], 'the': [10, 16, 21, 26, 46, 98, 105, 133, 151], '1.2': [11], 'million': [12, 55], 'high-resolution': [13], 'images': [14], 'in': [15, 104, 132], 'ImageNet': [17], 'LSVRC-2010': [18], 'contest': [19], 'into': [20], '1000': [22], 'different': [23], 'classes.': [24], 'On': [25], 'test': [27, 141], 'data,': [28], 'we': [29, 87, 109], 'achieved': [30, 137, 149], 'top-1': [31], 'and': [32, 38, 57, 73, 91, 136], 'top-5': [33, 140], 'error': [34, 142], 'rates': [35], 'of': [36, 61, 66, 97, 129, 144], '37.5%': [37], '17.0%,': [39], 'respectively,': [40], 'which': [41, 52, 67], 'is': [42], 'considerably': [43], 'better': [44], 'than': [45], 'previous': [47], 'state-of-the-art.': [48], 'The': [49], 'network,': [51], 'has': [53], '60': [54], 'parameters': [56], '650,000': [58], 'neurons,': [59], 'consists': [60], 'five': [62], 'layers,': [64, 72], 'some': [65], 'are': [68], 'followed': [69], 'by': [70, 150], 'max-pooling': [71], 'three': [74], 'fully': [75, 106], 'connected': [76, 107], 'layers': [77, 108], 'with': [78], 'final': [80], '1000-way': [81], 'softmax.': [82], 'To': [83, 101], 'make': [84], 'training': [85], 'faster,': [86], 'used': [88], 'non-saturating': [89], 'neurons': [90], 'very': [93, 122], 'efficient': [94], 'GPU': [95], 'implementation': [96], 'convolution': [99], 'operation.': [100], 'reduce': [102], 'overfitting': [103], 'employed': [110], 'recently': [112], 'developed': [113], 'regularization': [114], 'method': [115], 'called': [116], '""dropout""': [117], 'that': [118], 'proved': [119], 'be': [121], 'effective.': [123], 'also': [125], 'entered': [126], 'variant': [128], 'this': [130], 'model': [131], 'ILSVRC-2012': [134], 'competition': [135], 'winning': [139], 'rate': [143], '15.3%,': [145], 'compared': [146], '26.2%': [148], 'second-best': [152], 'entry.': [153]}",2017,"['Softmax function', 'Convolutional neural network', 'Computer science', 'Pooling', 'Dropout (neural networks)', 'Artificial intelligence', 'Convolution (computer science)', 'Regularization (linguistics)', 'Pattern recognition (psychology)', 'Deep neural networks', 'Word error rate', 'Normalization (sociology)', 'Artificial neural network', 'Machine learning', 'Sociology', 'Anthropology']","We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called ""dropout"" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry."
https://openalex.org/W2124776405,Neural Networks: A Comprehensive Foundation,"{'From': [0], 'the': [1, 5, 27, 35, 72], 'Publisher:\r\nThis': [2], 'book': [3, 77], 'represents': [4], 'most': [6], 'comprehensive': [7], 'treatment': [8], 'available': [9], 'of': [10, 30, 54], 'neural': [11, 55], 'networks': [12], 'from': [13], 'an': [14], 'engineering': [15, 67], 'perspective.': [16], 'Thorough,': [17], 'well-organized,': [18], 'and': [19, 49, 51, 61, 83, 98], 'completely': [20], 'up': [21], 'to': [22, 70], 'date,': [23], 'it': [24], 'examines': [25], 'all': [26], 'important': [28], 'aspects': [29], 'this': [31, 76, 87], 'emerging': [32], 'technology,': [33], 'including': [34], 'learning': [36], 'process,': [37], 'back-propagation': [38], 'learning,': [39], 'radial-basis': [40], 'function': [41], 'networks,': [42, 46], 'self-organizing': [43], 'systems,': [44], 'modular': [45], 'temporal': [47], 'processing': [48], 'neurodynamics,': [50], 'VLSI': [52], 'implementation': [53], 'networks.': [56], 'Written': [57], 'in': [58], 'a': [59, 65, 95], 'concise': [60], 'fluid': [62], 'manner,': [63], 'by': [64], 'foremost': [66], 'textbook': [68], 'author,': [69], 'make': [71], 'material': [73], 'more': [74], 'accessible,': [75], 'is': [78], 'ideal': [79], 'for': [80], 'professional': [81], 'engineers': [82], 'graduate': [84], 'students': [85], 'entering': [86], 'exciting': [88], 'field.': [89], 'Computer': [90], 'experiments,': [91], 'problems,': [92], 'worked': [93], 'examples,': [94], 'bibliography,': [96], 'photographs,': [97], 'illustrations': [99], 'reinforce': [100], 'key': [101], 'concepts.': [102]}",1998,"['Modular design', 'Computer science', 'Field (mathematics)', 'Artificial neural network', 'Process (computing)', 'Function (biology)', 'Ideal (ethics)', 'Key (lock)', 'Perspective (graphical)', 'Artificial intelligence', 'Foundation (evidence)', 'Engineering', 'Geography', 'Epistemology', 'Mathematics', 'Pure mathematics', 'Computer security', 'Biology', 'Philosophy', 'Operating system', 'Archaeology', 'Evolutionary biology']","From the Publisher:
This book represents the most comprehensive treatment available of neural networks from an engineering perspective. Thorough, well-organized, and completely up to date, it examines all the important aspects of this emerging technology, including the learning process, back-propagation learning, radial-basis function networks, self-organizing systems, modular networks, temporal processing and neurodynamics, and VLSI implementation of neural networks. Written in a concise and fluid manner, by a foremost engineering textbook author, to make the material more accessible, this book is ideal for professional engineers and graduate students entering this exciting field. Computer experiments, problems, worked examples, a bibliography, photographs, and illustrations reinforce key concepts."
https://openalex.org/W1821462560,Distilling the Knowledge in a Neural Network,"{'A': [0], 'very': [1], 'simple': [2], 'way': [3], 'to': [4, 15, 26, 47, 50, 75, 90, 161], 'improve': [5, 117], 'the': [6, 21, 58, 77, 118, 129, 166], 'performance': [7], 'of': [8, 37, 54, 121, 134, 146, 149, 173], 'almost': [9], 'any': [10], 'machine': [11], 'learning': [12], 'algorithm': [13], 'is': [14, 39, 73, 87], 'train': [16], 'many': [17, 156], 'different': [18, 100], 'models': [19, 38, 60, 135, 154, 158, 168, 177], 'on': [20, 108], 'same': [22], 'data': [23], 'and': [24, 41, 66, 92, 110, 155, 182], 'then': [25], 'average': [27], 'their': [28], 'predictions.': [29], 'Unfortunately,': [30], 'making': [31], 'predictions': [32], 'using': [33, 98], 'a': [34, 51, 83, 99, 122, 137, 143, 171], 'whole': [35], 'ensemble': [36, 81, 133, 147], 'cumbersome': [40], 'may': [42], 'be': [43, 179], 'too': [44], 'computationally': [45], 'expensive': [46], 'allow': [48], 'deployment': [49], 'large': [52, 62], 'number': [53], 'users,': [55], 'especially': [56], 'if': [57], 'individual': [59], 'are': [61], 'neural': [63], 'nets.': [64], 'Caruana': [65], 'his': [67], 'collaborators': [68], 'have': [69], 'shown': [70], 'that': [71, 113, 165], 'it': [72], 'possible': [74], 'compress': [76], 'knowledge': [78, 130], 'in': [79, 131, 183], 'an': [80, 132], 'into': [82, 136], 'single': [84, 138], 'model': [85, 120], 'which': [86, 159], 'much': [88], 'easier': [89], 'deploy': [91], 'we': [93, 111, 114], 'develop': [94], 'this': [95], 'approach': [96], 'further': [97], 'compression': [101], 'technique.': [102], 'We': [103, 140], 'achieve': [104], 'some': [105], 'surprising': [106], 'results': [107], 'MNIST': [109], 'show': [112], 'can': [115, 178], 'significantly': [116], 'acoustic': [119], 'heavily': [123], 'used': [124], 'commercial': [125], 'system': [126], 'by': [127], 'distilling': [128], 'model.': [139], 'also': [141], 'introduce': [142], 'new': [144], 'type': [145], 'composed': [148], 'one': [150], 'or': [151], 'more': [152], 'full': [153, 167], 'specialist': [157, 176], 'learn': [160], 'distinguish': [162], 'fine-grained': [163], 'classes': [164], 'confuse.': [169], 'Unlike': [170], 'mixture': [172], 'experts,': [174], 'these': [175], 'trained': [180], 'rapidly': [181], 'parallel.': [184]}",2015,"['Artificial neural network', 'Computer science', 'Artificial intelligence']","A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel."
https://openalex.org/W2130942839,Sequence to Sequence Learning with Neural Networks,"{'Deep': [0], 'Neural': [1], 'Networks': [2], '(DNNs)': [3], 'are': [4, 25, 202, 208], 'powerful': [5], 'models': [6], 'that': [7, 48, 94, 201, 221], 'have': [8, 138], 'achieved': [9], 'excellent': [10], 'performance': [11, 239], 'on': [12, 52, 95, 118, 130, 140, 155, 189], 'difficult': [13], 'learning': [14, 47], 'tasks.': [15], 'Although': [16], 'DNNs': [17], 'work': [18], 'well': [19], 'whenever': [20], 'large': [21], 'labeled': [22], 'training': [23], 'sets': [24], 'available,': [26], 'they': [27], 'cannot': [28], 'be': [29], 'used': [30, 161], 'to': [31, 34, 45, 65, 70, 82, 98, 164, 179, 184, 204, 211], 'map': [32, 66], 'sequences': [33], 'sequences.': [35], 'In': [36], 'this': [37, 190], 'paper,': [38], 'we': [39, 160, 219], 'present': [40], 'a': [41, 59, 71, 74, 113, 145, 150], 'general': [42], 'end-to-end': [43], 'approach': [44], 'sequence': [46, 54, 69, 86], 'makes': [49], 'minimal': [50], 'assumptions': [51], 'the': [53, 67, 84, 88, 103, 106, 110, 119, 124, 134, 156, 162, 166, 171, 185, 212, 215, 223, 226, 237, 250, 253, 258], 'structure.': [55], 'Our': [56, 90], 'method': [57], 'uses': [58], 'multilayered': [60], 'Long': [61], 'Short-Term': [62], 'Memory': [63], '(LSTM)': [64], 'input': [68], 'vector': [72], 'of': [73, 116, 153, 225], 'fixed': [75], 'dimensionality,': [76], 'and': [77, 198, 207, 214, 252], 'then': [78], 'another': [79], 'deep': [80], 'LSTM': [81, 111, 135, 163, 193], 'decode': [83], 'target': [85, 234, 254], 'from': [87, 102], 'vector.': [89], 'main': [91], 'result': [92, 188], 'is': [93, 182], 'an': [96], 'English': [97], 'French': [99], 'translation': [100], 'task': [101], ""WMT'14"": [104], 'dataset,': [105], 'translations': [107], 'produced': [108, 169], 'by': [109, 170], 'achieve': [112], 'BLEU': [114, 126, 151, 176], 'score': [115, 127, 152, 177], '34.8': [117], 'entire': [120], 'test': [121], 'set,': [122], 'where': [123], ""LSTM's"": [125, 238], 'was': [128], 'penalized': [129], 'out-of-vocabulary': [131], 'words.': [132], 'Additionally,': [133], 'did': [136], 'not': [137, 233], 'difficulty': [139], 'long': [141], 'sentences.': [142], 'For': [143], 'comparison,': [144], 'phrase-based': [146], 'SMT': [147, 173], 'system': [148], 'achieves': [149], '33.3': [154], 'same': [157], 'dataset.': [158], 'When': [159], 'rerank': [165], '1000': [167], 'hypotheses': [168], 'aforementioned': [172], 'system,': [174], 'its': [175], 'increases': [178], '36.5,': [180], 'which': [181, 256], 'close': [183], 'previous': [186], 'best': [187], 'task.': [191], 'The': [192], 'also': [194], 'learned': [195], 'sensible': [196], 'phrase': [197], 'sentence': [199, 255], 'representations': [200], 'sensitive': [203], 'word': [205], 'order': [206, 224], 'relatively': [209], 'invariant': [210], 'active': [213], 'passive': [216], 'voice.': [217], 'Finally,': [218], 'found': [220], 'reversing': [222], 'words': [227], 'in': [228], 'all': [229], 'source': [230, 251], 'sentences': [231], '(but': [232], 'sentences)': [235], 'improved': [236], 'markedly,': [240], 'because': [241], 'doing': [242], 'so': [243], 'introduced': [244], 'many': [245], 'short': [246], 'term': [247], 'dependencies': [248], 'between': [249], 'made': [257], 'optimization': [259], 'problem': [260], 'easier.': [261]}",2014,"['Computer science', 'Artificial intelligence', 'Sentence', 'Phrase', 'Sequence (biology)', 'Natural language processing', 'Word (group theory)', 'Task (project management)', 'Speech recognition', 'Recurrent neural network', 'Artificial neural network', 'Machine translation', 'Vocabulary', 'Deep learning', 'Mathematics', 'Genetics', 'Geometry', 'Management', 'Economics', 'Philosophy', 'Biology', 'Linguistics']","Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT'14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous best result on this task. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier."
https://openalex.org/W1832693441,Convolutional Neural Networks for Sentence Classification,"{'We': [0], 'report': [1], 'on': [2, 13, 38, 80], 'a': [3, 25, 52], 'series': [4], 'of': [5, 15, 63, 77, 83], 'experiments': [6], 'with': [7, 28], 'convolutional': [8], 'neural': [9], 'networks': [10], '(CNN)': [11], 'trained': [12], 'top': [14], 'pre-trained': [16], 'word': [17], 'vectors': [18, 34, 42], 'for': [19, 60], 'sentence-level': [20], 'classification': [21], 'tasks.We': [22], 'show': [23], 'that': [24], 'simple': [26, 53], 'CNN': [27, 69], 'little': [29], 'hyperparameter': [30], 'tuning': [31], 'and': [32, 66, 90], 'static': [33, 67], 'achieves': [35], 'excellent': [36], 'results': [37], 'multiple': [39], 'benchmarks.Learning': [40], 'task-specific': [41, 65], 'through': [43], 'fine-tuning': [44], 'offers': [45], 'further': [46], 'gains': [47], 'in': [48], 'performance.We': [49], 'additionally': [50], 'propose': [51], 'modification': [54], 'to': [55, 58], 'the': [56, 61, 75, 78], 'architecture': [57], 'allow': [59], 'use': [62], 'both': [64], 'vectors.The': [68], 'models': [70], 'discussed': [71], 'herein': [72], 'improve': [73], 'upon': [74], 'state': [76], 'art': [79], '4': [81], 'out': [82], '7': [84], 'tasks,': [85], 'which': [86], 'include': [87], 'sentiment': [88], 'analysis': [89], 'question': [91], 'classification.': [92]}",2014,"['Convolutional neural network', 'Computer science', 'Sentence', 'Artificial intelligence', 'Natural language processing', 'Speech recognition']","We report on a series of experiments with convolutional neural networks (CNN) trained on top of pre-trained word vectors for sentence-level classification tasks.We show that a simple CNN with little hyperparameter tuning and static vectors achieves excellent results on multiple benchmarks.Learning task-specific vectors through fine-tuning offers further gains in performance.We additionally propose a simple modification to the architecture to allow for the use of both task-specific and static vectors.The CNN models discussed herein improve upon the state of the art on 4 out of 7 tasks, which include sentiment analysis and question classification."
https://openalex.org/W1924770834,Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling,"{'In': [0], 'this': [1], 'paper': [2], 'we': [3, 16, 80], 'compare': [4], 'different': [5], 'types': [6], 'of': [7, 51], 'recurrent': [8, 11, 40, 46, 65, 73], 'units': [9, 21, 47, 66, 74], 'in': [10], 'neural': [12], 'networks': [13], '(RNNs).': [14], 'Especially,': [15], 'focus': [17], 'on': [18, 48], 'more': [19, 71], 'sophisticated': [20], 'that': [22, 62], 'implement': [23], 'a': [24, 29, 36], 'gating': [25], 'mechanism,': [26], 'such': [27, 75], 'as': [28, 76], 'long': [30], 'short-term': [31], 'memory': [32], '(LSTM)': [33], 'unit': [34, 41], 'and': [35, 55], 'recently': [37], 'proposed': [38], 'gated': [39], '(GRU).': [42], 'We': [43], 'evaluate': [44], 'these': [45, 63], 'the': [49], 'tasks': [50], 'polyphonic': [52], 'music': [53], 'modeling': [54], 'speech': [56], 'signal': [57], 'modeling.': [58], 'Our': [59], 'experiments': [60], 'revealed': [61], 'advanced': [64], 'are': [67], 'indeed': [68], 'better': [69], 'than': [70], 'traditional': [72], 'tanh': [77], 'units.': [78], 'Also,': [79], 'found': [81], 'GRU': [82], 'to': [83, 86], 'be': [84], 'comparable': [85], 'LSTM.': [87]}",2014,"['Recurrent neural network', 'Computer science', 'Focus (optics)', 'Speech recognition', 'Long short term memory', 'Sequence (biology)', 'Artificial intelligence', 'Polyphony', 'Artificial neural network', 'Psychology', 'Biology', 'Pedagogy', 'Optics', 'Physics', 'Genetics']","In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM."
https://openalex.org/W2907492528,A Comprehensive Survey on Graph Neural Networks,"{'Deep': [0], 'learning': [1, 6, 77, 85, 110], 'has': [2, 69], 'revolutionized': [3], 'many': [4, 80], 'machine': [5, 76, 109], 'tasks': [7, 29], 'in': [8, 27, 33, 105, 164], 'recent': [9], 'years,': [10], 'ranging': [11], 'from': [12, 49], 'image': [13], 'classification': [14], 'and': [15, 21, 52, 60, 108, 132, 145, 153], 'video': [16], 'processing': [17], 'to': [18, 117], 'speech': [19], 'recognition': [20], 'natural': [22], 'language': [23], 'understanding.': [24], 'The': [25, 64], 'data': [26, 46, 68, 89, 106, 151], 'these': [28], 'are': [30, 47, 53], 'typically': [31], 'represented': [32, 54], 'the': [34, 74, 119, 138, 147], 'Euclidean': [35], 'space.': [36], 'However,': [37], 'there': [38], 'is': [39], 'an': [40], 'increasing': [41], 'number': [42], 'of': [43, 66, 100, 140, 156], 'applications,': [44], 'where': [45], 'generated': [48], 'non-Euclidean': [50], 'domains': [51, 144], 'as': [55], 'graphs': [56], 'with': [57], 'complex': [58], 'relationships': [59], 'interdependency': [61], 'between': [62], 'objects.': [63], 'complexity': [65], 'graph': [67, 88, 101, 130], 'imposed': [70], 'significant': [71], 'challenges': [72], 'on': [73, 82], 'existing': [75], 'algorithms.': [78], 'Recently,': [79], 'studies': [81], 'extending': [83], 'deep': [84], 'approaches': [86], 'for': [87], 'have': [90], 'emerged.': [91], 'In': [92], 'this': [93, 165], 'article,': [94], 'we': [95, 159], 'provide': [96], 'a': [97, 114], 'comprehensive': [98], 'overview': [99], 'neural': [102], 'networks': [103], '(GNNs)': [104], 'mining': [107], 'fields.': [111], 'We': [112, 135], 'propose': [113, 160], 'new': [115], 'taxonomy': [116], 'divide': [118], 'state-of-the-art': [120], 'GNNs': [121, 141], 'into': [122], 'four': [123], 'categories,': [124], 'namely,': [125], 'recurrent': [126], 'GNNs,': [127, 129], 'convolutional': [128], 'autoencoders,': [131], 'spatial-temporal': [133], 'GNNs.': [134, 157], 'further': [136], 'discuss': [137], 'applications': [139], 'across': [142], 'various': [143], 'summarize': [146], 'open-source': [148], 'codes,': [149], 'benchmark': [150], 'sets,': [152], 'model': [154], 'evaluation': [155], 'Finally,': [158], 'potential': [161], 'research': [162], 'directions': [163], 'rapidly': [166], 'growing': [167], 'field.': [168]}",2020,[],"Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications, where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on the existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this article, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art GNNs into four categories, namely, recurrent GNNs, convolutional GNNs, graph autoencoders, and spatial-temporal GNNs. We further discuss the applications of GNNs across various domains and summarize the open-source codes, benchmark data sets, and model evaluation of GNNs. Finally, we propose potential research directions in this rapidly growing field."
https://openalex.org/W2612445135,MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications,"{'We': [0, 34, 70, 91], 'present': [1, 71], 'a': [2, 19, 99], 'class': [3], 'of': [4, 67, 96, 102], 'efficient': [5], 'models': [6, 87], 'called': [7], 'MobileNets': [8, 15, 97], 'for': [9, 60], 'mobile': [10], 'and': [11, 46, 76, 79, 104, 114], 'embedded': [12], 'vision': [13], 'applications.': [14], 'are': [16], 'based': [17, 63], 'on': [18, 64, 74, 88], 'streamlined': [20], 'architecture': [21], 'that': [22, 40], 'uses': [23], 'depth-wise': [24], 'separable': [25], 'convolutions': [26], 'to': [27, 54, 84], 'build': [28], 'light': [29], 'weight': [30], 'deep': [31], 'neural': [32], 'networks.': [33], 'introduce': [35], 'two': [36], 'simple': [37], 'global': [38], 'hyper-parameters': [39, 49], 'efficiently': [41], 'trade': [42], 'off': [43], 'between': [44], 'latency': [45], 'accuracy.': [47], 'These': [48], 'allow': [50], 'the': [51, 56, 65, 68, 94], 'model': [52, 59], 'builder': [53], 'choose': [55], 'right': [57], 'sized': [58], 'their': [61], 'application': [62], 'constraints': [66], 'problem.': [69], 'extensive': [72], 'experiments': [73], 'resource': [75], 'accuracy': [77], 'tradeoffs': [78], 'show': [80], 'strong': [81], 'performance': [82], 'compared': [83], 'other': [85], 'popular': [86], 'ImageNet': [89], 'classification.': [90], 'then': [92], 'demonstrate': [93], 'effectiveness': [95], 'across': [98], 'wide': [100], 'range': [101], 'applications': [103], 'use': [105], 'cases': [106], 'including': [107], 'object': [108], 'detection,': [109], 'finegrain': [110], 'classification,': [111], 'face': [112], 'attributes': [113], 'large': [115], 'scale': [116], 'geo-localization.': [117]}",2017,"['Computer science', 'Convolutional neural network', 'Latency (audio)', 'Artificial intelligence', 'Deep neural networks', 'Face (sociological concept)', 'Architecture', 'Deep learning', 'Mobile device', 'Object detection', 'Class (philosophy)', 'Simple (philosophy)', 'Range (aeronautics)', 'Artificial neural network', 'Scale (ratio)', 'Machine learning', 'Pattern recognition (psychology)', 'Engineering', 'Telecommunications', 'Visual arts', 'Physics', 'Aerospace engineering', 'Social science', 'Sociology', 'Epistemology', 'Philosophy', 'Operating system', 'Art', 'Quantum mechanics']","We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization."
https://openalex.org/W1673923490,Intriguing properties of neural networks,"{'Deep': [0], 'neural': [1, 102, 109], 'networks': [2, 110], 'are': [3, 115], 'highly': [4], 'expressive': [5], 'models': [6], 'that': [7, 38, 54, 81, 91, 107, 114, 169], 'have': [8, 40], 'recently': [9], 'achieved': [10], 'state': [11], 'of': [12, 68, 76, 93, 101, 151, 159, 176], 'the': [13, 26, 84, 88, 94, 98, 125, 142, 148, 161, 177, 181], 'art': [14], 'performance': [15], 'on': [16, 172], 'speech': [17], 'and': [18, 64], 'visual': [19], 'recognition': [20], 'tasks.': [21], 'While': [22], 'their': [23], 'expressiveness': [24], 'is': [25, 56, 83, 138, 154], 'reason': [27], 'they': [28], 'succeed,': [29], 'it': [30, 82], 'also': [31], 'causes': [32], 'them': [33], 'to': [34, 73, 118, 127, 179], 'learn': [35, 111], 'uninterpretable': [36], 'solutions': [37], 'could': [39], 'counter-intuitive': [41], 'properties.': [42, 50], 'In': [43, 146], 'this': [44], 'paper': [45], 'we': [46, 52, 105], 'report': [47], 'two': [48], 'such': [49], 'First,': [51], 'find': [53, 106], 'there': [55], 'no': [57], 'distinction': [58], 'between': [59], 'individual': [60, 89], 'high': [61, 69, 99], 'level': [62, 70], 'units': [63], 'random': [65, 157], 'linear': [66], 'combinations': [67], 'units,': [71, 90], 'according': [72], 'various': [74], 'methods': [75], 'unit': [77], 'analysis.': [78], 'It': [79], 'suggests': [80], 'space,': [85], 'rather': [86], 'than': [87], 'contains': [92], 'semantic': [95], 'information': [96], 'in': [97], 'layers': [100], 'networks.': [103], 'Second,': [104], 'deep': [108], 'input-output': [112], 'mappings': [113], 'fairly': [116], 'discontinuous': [117], 'a': [119, 133, 156, 166, 173], 'significant': [120], 'extend.': [121], 'We': [122], 'can': [123, 164], 'cause': [124, 165], 'network': [126], 'misclassify': [128, 180], 'an': [129], 'image': [130], 'by': [131, 140], 'applying': [132], 'certain': [134], 'imperceptible': [135], 'perturbation,': [136], 'which': [137], 'found': [139], 'maximizing': [141], ""network's"": [143], 'prediction': [144], 'error.': [145], 'addition,': [147], 'specific': [149], 'nature': [150], 'these': [152], 'perturbations': [153], 'not': [155], 'artifact': [158], 'learning:': [160], 'same': [162, 182], 'perturbation': [163], 'different': [167, 174], 'network,': [168], 'was': [170], 'trained': [171], 'subset': [175], 'dataset,': [178], 'input.': [183]}",2013,"['Computer science', 'Artificial neural network', 'Artifact (error)', 'Perturbation (astronomy)', 'Artificial intelligence', 'Deep neural networks', 'Machine learning', 'Physics', 'Quantum mechanics']","Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties. First, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains of the semantic information in the high layers of neural networks. Second, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extend. We can cause the network to misclassify an image by applying a certain imperceptible perturbation, which is found by maximizing the network's prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input."
https://openalex.org/W2560647685,Overcoming catastrophic forgetting in neural networks,"{'Significance': [0], 'Deep': [1], 'neural': [2], 'networks': [3], 'are': [4, 35], 'currently': [5], 'the': [6, 57, 74], 'most': [7], 'successful': [8], 'machine-learning': [9], 'technique': [10], 'for': [11, 60], 'solving': [12], 'a': [13, 47], 'variety': [14], 'of': [15, 27, 73], 'tasks,': [16], 'including': [17], 'language': [18], 'translation,': [19], 'image': [20, 23], 'classification,': [21], 'and': [22], 'generation.': [24], 'One': [25], 'weakness': [26], 'such': [28, 52], 'models': [29, 53], 'is': [30], 'that,': [31], 'unlike': [32], 'humans,': [33], 'they': [34], 'unable': [36], 'to': [37, 50], 'learn': [38], 'multiple': [39, 78], 'tasks': [40], 'sequentially.': [41, 83], 'In': [42], 'this': [43], 'work': [44], 'we': [45], 'propose': [46], 'practical': [48], 'solution': [49], 'train': [51], 'sequentially': [54], 'by': [55, 66], 'protecting': [56], 'weights': [58], 'important': [59], 'previous': [61], 'tasks.': [62], 'This': [63], 'approach,': [64], 'inspired': [65], 'synaptic': [67], 'consolidation': [68], 'in': [69], 'neuroscience,': [70], 'enables': [71], 'state': [72], 'art': [75], 'results': [76], 'on': [77], 'reinforcement': [79], 'learning': [80], 'problems': [81], 'experienced': [82]}",2017,"['Forgetting', 'Artificial neural network', 'Computer science', 'Psychology', 'Artificial intelligence', 'Cognitive psychology']","Significance Deep neural networks are currently the most successful machine-learning technique for solving a variety of tasks, including language translation, image classification, and image generation. One weakness of such models is that, unlike humans, they are unable to learn multiple tasks sequentially. In this work we propose a practical solution to train such models sequentially by protecting the weights important for previous tasks. This approach, inspired by synaptic consolidation in neuroscience, enables state of the art results on multiple reinforcement learning problems experienced sequentially."
https://openalex.org/W1904365287,Improving neural networks by preventing co-adaptation of feature detectors,"{'When': [0], 'a': [1, 9, 44, 65], 'large': [2, 79], 'feedforward': [3], 'neural': [4], 'network': [5], 'is': [6, 23, 47, 68], 'trained': [7], 'on': [8, 17, 34, 94], 'small': [10], 'training': [11, 36], 'set,': [12], 'it': [13, 86], 'typically': [14], 'performs': [15], 'poorly': [16], 'held-out': [18], 'test': [19], 'data.': [20], 'This': [21, 38], '""overfitting""': [22], 'greatly': [24], 'reduced': [25], 'by': [26], 'randomly': [27], 'omitting': [28], 'half': [29], 'of': [30, 53, 81], 'the': [31, 51, 73, 77], 'feature': [32, 45, 57, 66], 'detectors': [33], 'each': [35, 60], 'case.': [37], 'prevents': [39], 'complex': [40], 'co-adaptations': [41], 'in': [42, 50, 84], 'which': [43, 85], 'detector': [46], 'only': [48], 'helpful': [49, 70], 'context': [52], 'several': [54], 'other': [55], 'specific': [56], 'detectors.': [58], 'Instead,': [59], 'neuron': [61], 'learns': [62], 'to': [63], 'detect': [64], 'that': [67], 'generally': [69], 'for': [71, 102], 'producing': [72], 'correct': [74], 'answer': [75], 'given': [76], 'combinatorially': [78], 'variety': [80], 'internal': [82], 'contexts': [83], 'must': [87], 'operate.': [88], 'Random': [89], '""dropout""': [90], 'gives': [91], 'big': [92], 'improvements': [93], 'many': [95], 'benchmark': [96], 'tasks': [97], 'and': [98, 104], 'sets': [99], 'new': [100], 'records': [101], 'speech': [103], 'object': [105], 'recognition.': [106]}",2012,"['Overfitting', 'Feature (linguistics)', 'Dropout (neural networks)', 'Computer science', 'Benchmark (surveying)', 'Adaptation (eye)', 'Context (archaeology)', 'Detector', 'Set (abstract data type)', 'Artificial intelligence', 'Artificial neural network', 'Pattern recognition (psychology)', 'Variety (cybernetics)', 'Feed forward', 'Feedforward neural network', 'Machine learning', 'Engineering', 'Psychology', 'Geodesy', 'Programming language', 'Linguistics', 'Telecommunications', 'Paleontology', 'Neuroscience', 'Geography', 'Control engineering', 'Philosophy', 'Biology']","When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This ""overfitting"" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random ""dropout"" gives big improvements on many benchmark tasks and sets new records for speech and object recognition."
https://openalex.org/W2946948417,EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,"{'Convolutional': [0], 'Neural': [1], 'Networks': [2], '(ConvNets)': [3], 'are': [4, 22], 'commonly': [5], 'developed': [6], 'at': [7, 177], 'a': [8, 53, 65, 96, 106], 'fixed': [9], 'resource': [10], 'budget,': [11], 'and': [12, 32, 40, 83, 100, 117, 137, 152, 161], 'then': [13], 'scaled': [14], 'up': [15, 81, 103], 'for': [16], 'better': [17, 45, 115], 'accuracy': [18, 116, 130, 155], 'if': [19], 'more': [20], 'resources': [21], 'available.': [23], 'In': [24, 122], 'this': [25, 49, 77], 'paper,': [26], 'we': [27, 51, 89], 'systematically': [28], 'study': [29], 'model': [30], 'scaling': [31, 55, 80], 'identify': [33], 'that': [34, 57], 'carefully': [35], 'balancing': [36], 'network': [37, 99], 'depth,': [38], 'width,': [39], 'resolution': [41], 'can': [42], 'lead': [43], 'to': [44, 94, 104], 'performance.': [46], 'Based': [47], 'on': [48, 79, 131, 140, 156], 'observation,': [50], 'propose': [52], 'new': [54, 97], 'method': [56, 78], 'uniformly': [58], 'scales': [59], 'all': [60], 'dimensions': [61], 'of': [62, 76, 108, 170], 'depth/width/resolution': [63], 'using': [64], 'simple': [66], 'yet': [67], 'highly': [68], 'effective': [69], 'compound': [70], 'coefficient.': [71], 'We': [72], 'demonstrate': [73], 'the': [74, 143], 'effectiveness': [75], 'MobileNets': [82], 'ResNet.': [84], 'To': [85], 'go': [86], 'even': [87], 'further,': [88], 'use': [90], 'neural': [91], 'architecture': [92], 'search': [93], 'design': [95], 'baseline': [98], 'scale': [101], 'it': [102], 'obtain': [105], 'family': [107], 'models,': [109], 'called': [110], 'EfficientNets,': [111], 'which': [112], 'achieve': [113, 153], 'much': [114], 'efficiency': [118], 'than': [119, 142], 'previous': [120], 'ConvNets.': [121], 'particular,': [123], 'our': [124], 'EfficientNet-B7': [125], 'achieves': [126], 'state-of-the-art': [127, 154], '84.3%': [128], 'top-1': [129], 'ImageNet,': [132], 'while': [133], 'being': [134], '8.4x': [135], 'smaller': [136], '6.1x': [138], 'faster': [139], 'inference': [141], 'best': [144], 'existing': [145], 'ConvNet.': [146], 'Our': [147], 'EfficientNets': [148], 'also': [149], 'transfer': [150, 164], 'well': [151], 'CIFAR-100': [157], '(91.7%),': [158], 'Flowers': [159], '(98.8%),': [160], '3': [162], 'other': [163], 'learning': [165], 'datasets,': [166], 'with': [167], 'an': [168], 'order': [169], 'magnitude': [171], 'fewer': [172], 'parameters.': [173], 'Source': [174], 'code': [175], 'is': [176], 'https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet.': [178]}",2019,"['Scaling', 'Computer science', 'Inference', 'Convolutional neural network', 'Code (set theory)', 'Transfer of learning', 'Scale (ratio)', 'Algorithm', 'Artificial neural network', 'Resolution (logic)', 'Artificial intelligence', 'Machine learning', 'Pattern recognition (psychology)', 'Mathematics', 'Physics', 'Set (abstract data type)', 'Geometry', 'Quantum mechanics', 'Programming language']","Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.3% top-1 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet. Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7%), Flowers (98.8%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters. Source code is at https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet."
https://openalex.org/W1815076433,On the difficulty of training Recurrent Neural Networks,"{'There': [0], 'are': [1], 'two': [2], 'widely': [3], 'known': [4], 'issues': [5, 37], 'with': [6, 72], 'properly': [7], 'training': [8], 'Recurrent': [9], 'Neural': [10], 'Networks,': [11], 'the': [12, 15, 32, 35, 80, 93], 'vanishing': [13, 81], 'and': [14, 47, 75, 89], 'exploding': [16, 73], 'gradient': [17, 66], 'problems': [18, 41], 'detailed': [19], 'in': [20, 92], 'Bengio': [21], 'et': [22], 'al.': [23], '(1994).': [24], 'In': [25], 'this': [26], 'paper': [27], 'we': [28], 'attempt': [29], 'to': [30, 56, 70], 'improve': [31], 'understanding': [33], 'of': [34], 'underlying': [36], 'by': [38], 'exploring': [39], 'these': [40], 'from': [42], 'an': [43], 'analytical,': [44], 'a': [45, 48, 58, 65, 76], 'geometric': [46], 'dynamical': [49], 'systems': [50], 'perspective.': [51], 'Our': [52], 'analysis': [53], 'is': [54], 'used': [55], 'justify': [57], 'simple': [59], 'yet': [60], 'effective': [61], 'solution.': [62], 'We': [63, 84], 'propose': [64], 'norm': [67], 'clipping': [68], 'strategy': [69], 'deal': [71], 'gradients': [74, 82], 'soft': [77], 'constraint': [78], 'for': [79], 'problem.': [83], 'validate': [85], 'empirically': [86], 'our': [87], 'hypothesis': [88], 'proposed': [90], 'solutions': [91], 'experimental': [94], 'section.': [95]}",2012,"['Constraint (computer-aided design)', 'Perspective (graphical)', 'Computer science', 'Artificial neural network', 'Simple (philosophy)', 'Norm (philosophy)', 'Artificial intelligence', 'Gradient descent', 'Algorithm', 'Mathematical optimization', 'Mathematics', 'Geometry', 'Epistemology', 'Philosophy']","There are two widely known issues with properly training Recurrent Neural Networks, the vanishing and the exploding gradient problems detailed in Bengio et al. (1994). In this paper we attempt to improve the understanding of the underlying issues by exploring these problems from an analytical, a geometric and a dynamical systems perspective. Our analysis is used to justify a simple yet effective solution. We propose a gradient norm clipping strategy to deal with exploding gradients and a soft constraint for the vanishing gradients problem. We validate empirically our hypothesis and proposed solutions in the experimental section."
https://openalex.org/W2243397390,DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks,"{'State-of-the-art': [0], 'deep': [1, 50, 76], 'neural': [2], 'networks': [3], 'have': [4, 17, 40], 'achieved': [5], 'impressive': [6], 'results': [7, 89], 'on': [8, 55], 'many': [9], 'image': [10], 'classification': [11], 'tasks.': [12], 'However,': [13], 'these': [14, 85], 'same': [15], 'architectures': [16], 'been': [18, 41], 'shown': [19], 'to': [20, 23, 43, 52, 70], 'be': [21], 'unstable': [22], 'small,': [24], 'well': [25], 'sought,': [26], 'perturbations': [27, 54, 73, 103], 'of': [28, 34, 48, 84, 100], 'the': [29, 32, 46, 67, 82, 98], 'images.': [30], 'Despite': [31], 'importance': [33], 'this': [35, 59, 63], 'phenomenon,': [36], 'no': [37], 'effective': [38], 'methods': [39, 96], 'proposed': [42], 'accurately': [44], 'compute': [45, 72], 'robustness': [47, 83], 'state-of-the-art': [49], 'classifiers': [51, 106], 'such': [53], 'large-scale': [56], 'datasets.': [57], 'In': [58], 'paper,': [60], 'we': [61], 'fill': [62], 'gap': [64], 'and': [65, 78, 104], 'propose': [66], 'DeepFool': [68], 'algorithm': [69], 'efficiently': [71], 'that': [74, 91], 'fool': [75], 'networks,': [77], 'thus': [79], 'reliably': [80], 'quantify': [81], 'classifiers.': [86], 'Extensive': [87], 'experimental': [88], 'show': [90], 'our': [92], 'approach': [93], 'outperforms': [94], 'recent': [95], 'in': [97], 'task': [99], 'computing': [101], 'adversarial': [102], 'making': [105], 'more': [107], 'robust.': [108]}",2016,"['Simple (philosophy)', 'Computer science', 'Artificial neural network', 'Deep neural networks', 'Artificial intelligence', 'Philosophy', 'Epistemology']","State-of-the-art deep neural networks have achieved impressive results on many image classification tasks. However, these same architectures have been shown to be unstable to small, well sought, perturbations of the images. Despite the importance of this phenomenon, no effective methods have been proposed to accurately compute the robustness of state-of-the-art deep classifiers to such perturbations on large-scale datasets. In this paper, we fill this gap and propose the DeepFool algorithm to efficiently compute perturbations that fool deep networks, and thus reliably quantify the robustness of these classifiers. Extensive experimental results show that our approach outperforms recent methods in the task of computing adversarial perturbations and making classifiers more robust."
https://openalex.org/W2949888546,Sequence to Sequence Learning with Neural Networks,"{'Deep': [0], 'Neural': [1], 'Networks': [2], '(DNNs)': [3], 'are': [4, 25, 200, 206], 'powerful': [5], 'models': [6], 'that': [7, 48, 93, 199, 219], 'have': [8, 137], 'achieved': [9], 'excel-lent': [10], 'performance': [11, 237], 'on': [12, 52, 94, 117, 129, 139, 154], 'difficult': [13], 'learning': [14, 47], 'tasks.': [15], 'Although': [16], 'DNNs': [17], 'work': [18], 'well': [19], 'whenever': [20], 'large': [21], 'labeled': [22], 'training': [23], 'sets': [24], 'available,': [26], 'they': [27], 'cannot': [28], 'be': [29], 'used': [30, 160], 'to': [31, 34, 45, 64, 69, 81, 97, 163, 178, 183, 202, 209], 'map': [32, 65], 'sequences': [33], 'sequences.': [35], 'In': [36], 'this': [37], 'paper,': [38], 'we': [39, 159, 217], 'present': [40], 'a': [41, 59, 70, 73, 112, 144, 149], 'general': [42], 'end-to-end': [43], 'approach': [44], 'sequence': [46, 54, 68, 85], 'makes': [49], 'minimal': [50], 'assumptions': [51], 'the': [53, 66, 83, 87, 102, 105, 109, 118, 123, 133, 155, 161, 165, 170, 184, 188, 210, 213, 221, 224, 235, 248, 251, 256], 'structure.': [55], 'Our': [56, 89], 'method': [57], 'uses': [58], 'multilayered': [60], 'Long': [61], 'Short-TermMemory': [62], '(LSTM)': [63], 'input': [67], 'vector': [71], 'of': [72, 115, 152, 187, 223], 'fixed': [74], 'dimensionality,': [75], 'and': [76, 196, 205, 212, 250], 'then': [77], 'another': [78], 'deep': [79], 'LSTM': [80, 110, 134, 162, 191], 'decode': [82], 'target': [84, 232, 252], 'from': [86, 101], 'vector.': [88], 'main': [90], 'result': [91], 'is': [92, 181], 'an': [95], 'English': [96], 'French': [98], 'translation': [99], 'task': [100], 'WMT-14': [103], 'dataset,': [104], 'translations': [106], 'produced': [107, 168], 'by': [108, 169], 'achieve': [111], 'BLEU': [113, 125, 150, 175], 'score': [114, 126, 151, 176], '34.8': [116], 'entire': [119], 'test': [120], 'set,': [121], 'where': [122], 'LSTM’s': [124, 236], 'was': [127], 'penalized': [128], 'out-of-vocabulary': [130], 'words.': [131], 'Additionally,': [132], 'did': [135], 'not': [136, 231], 'difficulty': [138], 'long': [140], 'sentences.': [141], 'For': [142], 'comparison,': [143], 'phrase-based': [145], 'SMT': [146, 172], 'system': [147], 'achieves': [148], '33.3': [153], 'same': [156], 'dataset.': [157], 'When': [158], 'rerank': [164], '1000': [166], 'hypotheses': [167], 'aforementioned': [171], 'system,': [173], 'its': [174], 'increases': [177], '36.5,': [179], 'which': [180, 254], 'close': [182], 'previous': [185], 'state': [186], 'art.': [189], 'The': [190], 'also': [192], 'learned': [193], 'sensible': [194], 'phrase': [195], 'sentence': [197, 253], 'representations': [198], 'sensitive': [201], 'word': [203], 'order': [204, 222], 'relatively': [207], 'invariant': [208], 'active': [211], 'passive': [214], 'voice.': [215], 'Fi-nally,': [216], 'found': [218], 'reversing': [220], 'words': [225], 'in': [226], 'all': [227], 'source': [228, 249], 'sentences': [229], '(but': [230], 'sentences)': [233], 'improved': [234], 'markedly,': [238], 'because': [239], 'doing': [240], 'so': [241], 'introduced': [242], 'many': [243], 'short': [244], 'term': [245], 'dependencies': [246], 'between': [247], 'made': [255], 'optimization': [257], 'problem': [258], 'easier.': [259], '1': [260]}",2014,"['Computer science', 'Artificial intelligence', 'Sentence', 'Phrase', 'Sequence (biology)', 'Natural language processing', 'Word (group theory)', 'Task (project management)', 'Speech recognition', 'Recurrent neural network', 'Artificial neural network', 'Machine translation', 'Sequence learning', 'Mathematics', 'Biology', 'Genetics', 'Economics', 'Management', 'Geometry']","Deep Neural Networks (DNNs) are powerful models that have achieved excel-lent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-TermMemory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT-14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM’s BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous state of the art. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Fi-nally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM’s performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier. 1"
https://openalex.org/W2120615054,A Convolutional Neural Network for Modelling Sentences,"{'The': [0, 32, 45, 71, 111], 'ability': [1], 'to': [2, 8, 84, 134], 'accurately': [3], 'represent': [4], 'sentences': [5, 49], 'is': [6, 62, 81], 'central': [7], 'language': [9], 'understanding.': [10], 'We': [11, 87], 'describe': [12], 'a': [13, 38, 55, 77, 122], 'convolutional': [14], 'architecture': [15], 'dubbed': [16], 'the': [17, 27, 59, 89, 117, 129, 135], 'Dynamic': [18, 35], 'Convolutional': [19], 'Neural': [20], 'Network': [21], '(DCNN)': [22], 'that': [23, 61], 'we': [24], 'adopt': [25], 'for': [26], 'semantic': [28], 'modelling': [29], 'of': [30, 50, 64], 'sentences.': [31], 'network': [33, 46, 72, 112], 'uses': [34], 'k-Max': [36], 'Pooling,': [37], 'global': [39], 'pooling': [40], 'operation': [41], 'over': [42, 58], 'linear': [43], 'sequences.': [44], 'handles': [47], 'input': [48], 'varying': [51], 'length': [52], 'and': [53, 68, 80, 97, 104, 121], 'induces': [54], 'feature': [56], 'graph': [57], 'sentence': [60], 'capable': [63], 'explicitly': [65], 'capturing': [66], 'short': [67], 'long-range': [69], 'relations.': [70], 'does': [73], 'not': [74], 'rely': [75], 'on': [76], 'parse': [78], 'tree': [79], 'easily': [82], 'applicable': [83], 'any': [85], 'language.': [86], 'test': [88], 'DCNN': [90], 'in': [91, 116, 128], 'four': [92], 'experiments:': [93], 'small': [94], 'scale': [95], 'binary': [96], 'multi-class': [98], 'sentiment': [99, 106], 'prediction,': [100], 'six-way': [101], 'question': [102], 'classification': [103], 'Twitter': [105], 'prediction': [107], 'by': [108], 'distant': [109], 'supervision.': [110], 'achieves': [113], 'excellent': [114], 'performance': [115], 'first': [118], 'three': [119], 'tasks': [120], 'greater': [123], 'than': [124], '25%': [125], 'error': [126], 'reduction': [127], 'last': [130], 'task': [131], 'with': [132], 'respect': [133], 'strongest': [136], 'baseline.': [137]}",2014,"['Computer science', 'Convolutional neural network', 'Artificial intelligence', 'Natural language processing', 'Speech recognition']","The ability to accurately represent sentences is central to language understanding. We describe a convolutional architecture dubbed the Dynamic Convolutional Neural Network (DCNN) that we adopt for the semantic modelling of sentences. The network uses Dynamic k-Max Pooling, a global pooling operation over linear sequences. The network handles input sentences of varying length and induces a feature graph over the sentence that is capable of explicitly capturing short and long-range relations. The network does not rely on a parse tree and is easily applicable to any language. We test the DCNN in four experiments: small scale binary and multi-class sentiment prediction, six-way question classification and Twitter sentiment prediction by distant supervision. The network achieves excellent performance in the first three tasks and a greater than 25% error reduction in the last task with respect to the strongest baseline."
https://openalex.org/W3168997536,"A Survey of Convolutional Neural Networks: Analysis, Applications, and Prospects","{'A': [0], 'convolutional': [1], 'neural': [2], 'network': [3], '(CNN)': [4], 'is': [5], 'one': [6], 'of': [7, 112, 119, 152, 162], 'the': [8, 13, 46, 110, 160], 'most': [9], 'significant': [10], 'networks': [11], 'in': [12, 22, 45, 58, 89], 'deep': [14], 'learning': [15], 'field.': [16, 92], 'Since': [17], 'CNN': [18, 63, 127, 178], 'made': [19], 'impressive': [20], 'achievements': [21], 'many': [23], 'areas,': [24], 'including': [25], 'but': [26, 98], 'not': [27, 75, 94], 'limited': [28], 'to': [29, 82], 'computer': [30], 'vision': [31], 'and': [32, 43, 68, 87, 101, 125, 148, 156, 165, 174], 'natural': [33], 'language': [34], 'processing,': [35], 'it': [36], 'attracted': [37], 'much': [38], 'attention': [39], 'from': [40, 64], 'both': [41], 'industry': [42], 'academia': [44], 'past': [47], 'few': [48], 'years.': [49], 'The': [50], 'existing': [51], 'reviews': [52], 'mainly': [53], 'focus': [54], 'on': [55], ""CNN's"": [56], 'applications': [57, 161], 'different': [59], 'scenarios': [60], 'without': [61], 'considering': [62], 'a': [65], 'general': [66], 'perspective,': [67], 'some': [69, 84, 123, 146, 171], 'novel': [70, 85], 'ideas': [71, 86], 'proposed': [72], 'recently': [73], 'are': [74, 104, 129, 168, 179], 'covered.': [76, 169], 'In': [77], 'this': [78, 90, 107], 'review,': [79], 'we': [80, 115, 144], 'aim': [81], 'provide': [83, 116, 149], 'prospects': [88], 'fast-growing': [91], 'Besides,': [93], 'only': [95], '2-D': [96], 'convolution': [97, 167], 'also': [99], '1-D': [100], 'multidimensional': [102, 166], 'ones': [103], 'involved.': [105], 'First,': [106], 'review': [108], 'introduces': [109], 'history': [111], 'CNN.': [113], 'Second,': [114], 'an': [117], 'overview': [118], 'various': [120], 'convolutions.': [121], 'Third,': [122], 'classic': [124], 'advanced': [126], 'models': [128], 'introduced;': [130], 'especially': [131], 'those': [132], 'key': [133], 'points': [134], 'making': [135], 'them': [136], 'reach': [137], 'state-of-the-art': [138], 'results.': [139], 'Fourth,': [140], 'through': [141], 'experimental': [142], 'analysis,': [143], 'draw': [145], 'conclusions': [147], 'several': [150], 'rules': [151], 'thumb': [153], 'for': [154, 177, 183], 'functions': [155], 'hyperparameter': [157], 'selection.': [158], 'Fifth,': [159], '1-D,': [163], '2-D,': [164], 'Finally,': [170], 'open': [172], 'issues': [173], 'promising': [175], 'directions': [176], 'discussed': [180], 'as': [181], 'guidelines': [182], 'future': [184], 'work.': [185]}",2021,"['Convolutional neural network', 'Computer science', 'Data science', 'Artificial intelligence']","A convolutional neural network (CNN) is one of the most significant networks in the deep learning field. Since CNN made impressive achievements in many areas, including but not limited to computer vision and natural language processing, it attracted much attention from both industry and academia in the past few years. The existing reviews mainly focus on CNN's applications in different scenarios without considering CNN from a general perspective, and some novel ideas proposed recently are not covered. In this review, we aim to provide some novel ideas and prospects in this fast-growing field. Besides, not only 2-D convolution but also 1-D and multidimensional ones are involved. First, this review introduces the history of CNN. Second, we provide an overview of various convolutions. Third, some classic and advanced CNN models are introduced; especially those key points making them reach state-of-the-art results. Fourth, through experimental analysis, we draw some conclusions and provide several rules of thumb for functions and hyperparameter selection. Fifth, the applications of 1-D, 2-D, and multidimensional convolution are covered. Finally, some open issues and promising directions for CNN are discussed as guidelines for future work."
https://openalex.org/W2512971201,Deep Neural Networks for YouTube Recommendations,"{'YouTube': [0], 'represents': [1], 'one': [2], 'of': [3], 'the': [4, 20, 29, 43], 'largest': [5], 'scale': [6], 'and': [7, 26, 57, 70, 76], 'most': [8], 'sophisticated': [9], 'industrial': [10], 'recommendation': [11, 80], 'systems': [12], 'in': [13], 'existence.': [14], 'In': [15], 'this': [16], 'paper,': [17], 'we': [18, 50], 'describe': [19, 59], 'system': [21, 81], 'at': [22], 'a': [23, 52, 60, 78], 'high': [24], 'level': [25], 'focus': [27], 'on': [28], 'dramatic': [30], 'performance': [31], 'improvements': [32], 'brought': [33], 'by': [34], 'deep': [35, 53, 62], 'learning.': [36], 'The': [37], 'paper': [38], 'is': [39], 'split': [40], 'according': [41], 'to': [42], 'classic': [44], 'two-stage': [45], 'information': [46], 'retrieval': [47], 'dichotomy:': [48], 'first,': [49], 'detail': [51], 'candidate': [54], 'generation': [55], 'model': [56], 'then': [58], 'separate': [61], 'ranking': [63], 'model.': [64], 'We': [65], 'also': [66], 'provide': [67], 'practical': [68], 'lessons': [69], 'insights': [71], 'derived': [72], 'from': [73], 'designing,': [74], 'iterating': [75], 'maintaining': [77], 'massive': [79], 'with': [82], 'enormous': [83], 'user-facing': [84], 'impact.': [85]}",2016,"['Deep learning', 'Computer science', 'Ranking (information retrieval)', 'Focus (optics)', 'Deep neural networks', 'Artificial intelligence', 'Recommender system', 'Artificial neural network', 'Scale (ratio)', 'Data science', 'Information retrieval', 'Machine learning', 'Geography', 'Cartography', 'Optics', 'Physics']","YouTube represents one of the largest scale and most sophisticated industrial recommendation systems in existence. In this paper, we describe the system at a high level and focus on the dramatic performance improvements brought by deep learning. The paper is split according to the classic two-stage information retrieval dichotomy: first, we detail a deep candidate generation model and then describe a separate deep ranking model. We also provide practical lessons and insights derived from designing, iterating and maintaining a massive recommendation system with enormous user-facing impact."
https://openalex.org/W3186179742,Accurate prediction of protein structures and interactions using a three-track neural network,"{'Deep': [0, 43], 'learning': [1, 44], 'takes': [2], 'on': [3, 65], 'protein': [4], 'folding': [5], 'In': [6], '1972,': [7], 'Anfinsen': [8], 'won': [9], 'a': [10, 15, 18, 71], 'Nobel': [11], 'prize': [12], 'for': [13], 'demonstrating': [14], 'connection': [16], 'between': [17], 'protein’s': [19], 'amino': [20], 'acid': [21], 'sequence': [22], 'and': [23, 78, 82, 98, 103], 'its': [24], 'three-dimensional': [25], 'structure.': [26], 'Since': [27], '1994,': [28], 'scientists': [29], 'have': [30], 'competed': [31], 'in': [32], 'the': [33, 66], 'biannual': [34], 'Critical': [35], 'Assessment': [36], 'of': [37, 87, 107], 'Structure': [38], 'Prediction': [39], '(CASP)': [40], 'protein-folding': [41], 'challenge.': [42], 'methods': [45], 'took': [46], 'center': [47], 'stage': [48], 'at': [49], 'CASP14,': [50], 'with': [51], 'DeepMind’s': [52], 'Alphafold2': [53], 'achieving': [54], 'remarkable': [55], 'accuracy.': [56], 'Baek': [57], 'et': [58], 'al': [59], '.': [60], 'explored': [61], 'network': [62, 73], 'architectures': [63], 'based': [64], 'DeepMind': [67], 'framework.': [68], 'They': [69], 'used': [70], 'three-track': [72], 'to': [74], 'process': [75], 'sequence,': [76], 'distance,': [77], 'coordinate': [79], 'information': [80], 'simultaneously': [81], 'achieved': [83], 'accuracies': [84], 'approaching': [85], 'those': [86], 'DeepMind.': [88], 'The': [89], 'method,': [90], 'RoseTTA': [91], 'fold,': [92], 'can': [93], 'solve': [94], 'challenging': [95], 'x-ray': [96], 'crystallography': [97], 'cryo–electron': [99], 'microscopy': [100], 'modeling': [101], 'problems': [102], 'generate': [104], 'accurate': [105], 'models': [106], 'protein-protein': [108], 'complexes.': [109], '—VV': [110]}",2021,"['CASP', 'Protein structure prediction', 'Artificial neural network', 'Computer science', 'Folding (DSP implementation)', 'Artificial intelligence', 'Sequence (biology)', 'Protein folding', 'Deep learning', 'Protein structure', 'Computational biology', 'Machine learning', 'Chemistry', 'Biology', 'Engineering', 'Biochemistry', 'Electrical engineering']","Deep learning takes on protein folding In 1972, Anfinsen won a Nobel prize for demonstrating a connection between a protein’s amino acid sequence and its three-dimensional structure. Since 1994, scientists have competed in the biannual Critical Assessment of Structure Prediction (CASP) protein-folding challenge. Deep learning methods took center stage at CASP14, with DeepMind’s Alphafold2 achieving remarkable accuracy. Baek et al . explored network architectures based on the DeepMind framework. They used a three-track network to process sequence, distance, and coordinate information simultaneously and achieved accuracies approaching those of DeepMind. The method, RoseTTA fold, can solve challenging x-ray crystallography and cryo–electron microscopy modeling problems and generate accurate models of protein-protein complexes. —VV"
https://openalex.org/W2149933564,How transferable are features in deep neural networks?,"{'Many': [0], 'deep': [1, 94], 'neural': [2, 96], 'networks': [3, 142], 'trained': [4, 154], 'on': [5, 14, 128, 155, 168], 'natural': [6], 'images': [7], 'exhibit': [8], 'a': [9, 37, 93, 100, 224, 237], 'curious': [10], 'phenomenon': [11], 'in': [12, 44, 89], 'common:': [13], 'the': [15, 63, 67, 83, 113, 124, 129, 174, 180, 186, 192, 195, 247], 'first': [16], 'layer': [17, 65, 91, 117], 'they': [18, 46], 'learn': [19], 'features': [20, 30, 170, 189, 205, 228], 'similar': [21], 'to': [22, 33, 36, 49, 60, 119, 140, 239, 246], 'Gabor': [23], 'filters': [24], 'and': [25, 52, 98, 135, 198], 'color': [26], 'blobs.': [27], 'Such': [28], 'first-layer': [29], 'appear': [31], 'not': [32, 73, 148], 'be': [34, 211], 'specific': [35, 61], 'particular': [38], 'dataset': [39], 'or': [40, 177], 'task,': [41, 131], 'but': [42, 69, 202], 'general': [43, 59], 'that': [45, 159, 185, 203, 222, 241], 'are': [47, 171], 'applicable': [48], 'many': [50], 'datasets': [51], 'tasks.': [53], 'Features': [54], 'must': [55], 'eventually': [56], 'transition': [57, 71], 'from': [58, 173, 207, 229], 'by': [62, 108], 'last': [64], 'of': [66, 87, 92, 115, 126, 161, 179, 188, 233], 'network,': [68], 'this': [70, 78], 'has': [72], 'been': [74], 'studied': [75], 'extensively.': [76], 'In': [77, 150], 'paper': [79], 'we': [80, 157], 'experimentally': [81], 'quantify': [82], 'generality': [84], 'versus': [85], 'specificity': [86], 'neurons': [88, 118], 'each': [90], 'convolutional': [95], 'network': [97, 153, 225], 'report': [99], 'few': [101], 'surprising': [102, 219], 'results.': [103], 'Transferability': [104], 'is': [105, 221], 'negatively': [106], 'affected': [107], 'two': [109, 163], 'distinct': [110], 'issues:': [111], '(1)': [112], 'specialization': [114], 'higher': [116], 'their': [120], 'original': [121], 'task': [122, 197, 200], 'at': [123], 'expense': [125], 'performance': [127], 'target': [130, 199, 248], 'which': [132, 146], 'was': [133, 147], 'expected,': [134], '(2)': [136], 'optimization': [137], 'difficulties': [138], 'related': [139], 'splitting': [141], 'between': [143, 194], 'co-adapted': [144], 'neurons,': [145], 'expected.': [149], 'an': [151], 'example': [152], 'ImageNet,': [156], 'demonstrate': [158], 'either': [160], 'these': [162], 'issues': [164], 'may': [165], 'dominate,': [166], 'depending': [167], 'whether': [169], 'transferred': [172, 227], 'bottom,': [175], 'middle,': [176], 'top': [178], 'network.': [181], 'We': [182], 'also': [183], 'document': [184], 'transferability': [187], 'decreases': [190], 'as': [191], 'distance': [193], 'base': [196], 'increases,': [201], 'transferring': [204], 'even': [206, 243], 'distant': [208], 'tasks': [209], 'can': [210, 235], 'better': [212], 'than': [213], 'using': [214], 'random': [215], 'features.': [216], 'A': [217], 'final': [218], 'result': [220], 'initializing': [223], 'with': [226], 'almost': [230], 'any': [231], 'number': [232], 'layers': [234], 'produce': [236], 'boost': [238], 'generalization': [240], 'lingers': [242], 'after': [244], 'fine-tuning': [245], 'dataset.': [249]}",2014,"['Computer science', 'Initialization', 'Generality', 'Artificial intelligence', 'Task (project management)', 'Artificial neural network', 'Generalization', 'Layer (electronics)', 'Transferability', 'Convolutional neural network', 'Deep learning', 'Pattern recognition (psychology)', 'Machine learning', 'Mathematics', 'Economics', 'Mathematical analysis', 'Psychology', 'Management', 'Organic chemistry', 'Logit', 'Psychotherapist', 'Programming language', 'Chemistry']","Many deep neural networks trained on natural images exhibit a curious phenomenon in common: on the first layer they learn features similar to Gabor filters and color blobs. Such first-layer features appear not to be specific to a particular dataset or task, but general in that they are applicable to many datasets and tasks. Features must eventually transition from general to specific by the last layer of the network, but this transition has not been studied extensively. In this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results. Transferability is negatively affected by two distinct issues: (1) the specialization of higher layer neurons to their original task at the expense of performance on the target task, which was expected, and (2) optimization difficulties related to splitting networks between co-adapted neurons, which was not expected. In an example network trained on ImageNet, we demonstrate that either of these two issues may dominate, depending on whether features are transferred from the bottom, middle, or top of the network. We also document that the transferability of features decreases as the distance between the base task and target task increases, but that transferring features even from distant tasks can be better than using random features. A final surprising result is that initializing a network with transferred features from almost any number of layers can produce a boost to generalization that lingers even after fine-tuning to the target dataset."
https://openalex.org/W2253429366,"Deep Convolutional Neural Networks for Computer-Aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning","{'Remarkable': [0], 'progress': [1], 'has': [2], 'been': [3], 'made': [4], 'in': [5, 44, 144], 'image': [6, 30, 64, 97, 101, 158], 'recognition,': [7], 'primarily': [8], 'due': [9], 'to': [10, 62, 99, 120, 138, 237], 'the': [11, 45, 67, 151, 200, 204, 210, 238], 'availability': [12], 'of': [13, 114, 146, 153, 240], 'large-scale': [14], 'annotated': [15, 41], 'datasets': [16, 38], 'and': [17, 76, 127, 142, 156, 166, 192, 208, 231], 'deep': [18, 116], 'convolutional': [19, 117], 'neural': [20, 118], 'networks': [21, 119], '(CNNs).': [22], 'CNNs': [23, 61], 'enable': [24], 'learning': [25, 169], 'data-driven,': [26], 'highly': [27], 'representative,': [28], 'hierarchical': [29], 'features': [31], 'from': [32, 69, 95, 170], 'sufficient': [33], 'training': [34, 66], 'data.': [35], 'However,': [36], 'obtaining': [37], 'as': [39, 42], 'comprehensively': [40], 'ImageNet': [43, 172], 'medical': [46, 63, 100, 247], 'imaging': [47, 248], 'domain': [48], 'remains': [49], 'a': [50], 'challenge.': [51], 'There': [52], 'are': [53], 'currently': [54], 'three': [55, 108], 'major': [56], 'techniques': [57], 'that': [58], 'successfully': [59], 'employ': [60], 'classification:': [65], 'CNN': [68, 74, 79, 92, 130, 228], 'scratch,': [70], 'using': [71], 'off-the-shelf': [72], 'pre-trained': [73, 94, 171], 'features,': [75], 'conducting': [77], 'unsupervised': [78], 'pre-training': [80], 'with': [81, 221], 'supervised': [82], 'fine-tuning.': [83], 'Another': [84], 'effective': [85], 'method': [86], 'is': [87], 'transfer': [88, 168], 'learning,': [89], 'i.e.,': [90], 'fine-tuning': [91], 'models': [93, 134], 'natural': [96], 'dataset': [98, 154], 'tasks.': [102, 249], 'In': [103], 'this': [104], 'paper,': [105], 'we': [106, 163], 'exploit': [107], 'important,': [109], 'but': [110], 'previously': [111], 'understudied': [112], 'factors': [113], 'employing': [115], 'computer-aided': [121, 182], 'detection': [122, 183, 191], 'problems.': [123], 'We': [124, 148, 178, 198], 'first': [125, 211], 'explore': [126], 'evaluate': [128, 150], 'different': [129], 'architectures.': [131], 'The': [132], 'studied': [133], 'contain': [135], '5': [136], 'thousand': [137], '160': [139], 'million': [140], 'parameters,': [141], 'vary': [143], 'numbers': [145], 'layers.': [147], 'then': [149], 'influence': [152], 'scale': [155], 'spatial': [157], 'context': [159], 'on': [160, 203, 216], 'performance.': [161], 'Finally,': [162], 'examine': [164], 'when': [165], 'why': [167], '(via': [173], 'fine-tuning)': [174], 'can': [175, 234], 'be': [176, 235], 'useful.': [177], 'study': [179], 'two': [180], 'specific': [181], '(CADe)': [184], 'problems,': [185], 'namely': [186], 'thoraco-abdominal': [187], 'lymph': [188], 'node': [189], '(LN)': [190], 'interstitial': [193], 'lung': [194], 'disease': [195], '(ILD)': [196], 'classification.': [197], 'achieve': [199], 'state-of-the-art': [201], 'performance': [202, 242], 'mediastinal': [205], 'LN': [206], 'detection,': [207], 'report': [209], 'five-fold': [212], 'cross-validation': [213], 'classification': [214], 'results': [215], 'predicting': [217], 'axial': [218], 'CT': [219], 'slices': [220], 'ILD': [222], 'categories.': [223], 'Our': [224], 'extensive': [225], 'empirical': [226], 'evaluation,': [227], 'model': [229], 'analysis': [230], 'valuable': [232], 'insights': [233], 'extended': [236], 'design': [239], 'high': [241], 'CAD': [243], 'systems': [244], 'for': [245], 'other': [246]}",2016,"['Convolutional neural network', 'Computer science', 'Transfer of learning', 'Artificial intelligence', 'Deep learning', 'Contextual image classification', 'Pattern recognition (psychology)', 'Context (archaeology)', 'Medical imaging', 'Machine learning', 'Object detection', 'Feature extraction', 'Image (mathematics)', 'Paleontology', 'Biology']","Remarkable progress has been made in image recognition, primarily due to the availability of large-scale annotated datasets and deep convolutional neural networks (CNNs). CNNs enable learning data-driven, highly representative, hierarchical image features from sufficient training data. However, obtaining datasets as comprehensively annotated as ImageNet in the medical imaging domain remains a challenge. There are currently three major techniques that successfully employ CNNs to medical image classification: training the CNN from scratch, using off-the-shelf pre-trained CNN features, and conducting unsupervised CNN pre-training with supervised fine-tuning. Another effective method is transfer learning, i.e., fine-tuning CNN models pre-trained from natural image dataset to medical image tasks. In this paper, we exploit three important, but previously understudied factors of employing deep convolutional neural networks to computer-aided detection problems. We first explore and evaluate different CNN architectures. The studied models contain 5 thousand to 160 million parameters, and vary in numbers of layers. We then evaluate the influence of dataset scale and spatial image context on performance. Finally, we examine when and why transfer learning from pre-trained ImageNet (via fine-tuning) can be useful. We study two specific computer-aided detection (CADe) problems, namely thoraco-abdominal lymph node (LN) detection and interstitial lung disease (ILD) classification. We achieve the state-of-the-art performance on the mediastinal LN detection, and report the first five-fold cross-validation classification results on predicting axial CT slices with ILD categories. Our extensive empirical evaluation, CNN model analysis and valuable insights can be extended to the design of high performance CAD systems for other medical imaging tasks."
https://openalex.org/W2963285578,Convergence Results for Neural Networks via Electrodynamics,"{'We': [0], 'study': [1], 'whether': [2, 28, 70], 'a': [3, 18, 85, 159], 'depth': [4, 11], 'two': [5, 12], 'neural': [6], 'network': [7, 13, 155], 'can': [8, 148], 'learn': [9, 152], 'another': [10], 'using': [14], 'gradient': [15, 29, 128, 146], 'descent.': [16], 'Assuming': [17], 'linear': [19], 'output': [20], 'node,': [21], 'we': [22, 118, 143], 'show': [23, 144], 'that': [24, 127, 145], 'the': [25, 33, 39, 57, 61, 67, 74, 81, 88, 95, 102, 107, 111, 120, 135, 139, 153], 'question': [26, 41], 'of': [27, 122, 134], 'descent': [30, 129, 147], 'converges': [31], 'to': [32, 38, 56, 84, 151], 'target': [34, 140], 'function': [35, 109, 125], 'is': [36, 104], 'equivalent': [37], 'following': [40], 'in': [42, 48, 138], 'electrodynamics:': [43], 'Given': [44], 'k': [45, 51], 'fixed': [46], 'protons': [47, 62], 'R^d,': [49], 'and': [50, 63, 110], 'electrons,': [52, 69], 'each': [53], 'moving': [54], 'due': [55], 'attractive': [58], 'force': [59, 65, 103], 'from': [60, 66, 94], 'repulsive': [64], 'remaining': [68], 'at': [71, 131, 158], 'equilibrium': [72], 'all': [73], 'electrons': [75], 'will': [76], 'be': [77, 149], 'matched': [78], 'up': [79, 83], 'with': [80], 'protons,': [82], 'permutation.': [86], 'Under': [87], 'standard': [89], 'electrical': [90], 'force,': [91], 'this': [92, 116], 'follows': [93], 'classic': [96], ""Earnshaw's"": [97], 'theorem.': [98], 'In': [99], 'our': [100], 'setting,': [101], 'determined': [105], 'by': [106], 'activation': [108, 124], 'input': [112], 'distribution.': [113], 'Building': [114], 'on': [115], 'equivalence,': [117], 'prove': [119], 'existence': [121], 'an': [123], 'such': [126], 'learns': [130], 'least': [132], 'one': [133, 156], 'hidden': [136], 'nodes': [137], 'network.': [141], 'Iterating,': [142], 'used': [150], 'entire': [154], 'node': [157], 'time.': [160]}",2018,"['Computer science', 'Exponential function', 'Artificial intelligence', 'Mathematics', 'Mathematical analysis']","We study whether a depth two neural network can learn another depth two network using gradient descent. Assuming a linear output node, we show that the question of whether gradient descent converges to the target function is equivalent to the following question in electrodynamics: Given k fixed protons in R^d, and k electrons, each moving due to the attractive force from the protons and repulsive force from the remaining electrons, whether at equilibrium all the electrons will be matched up with the protons, up to a permutation. Under the standard electrical force, this follows from the classic Earnshaw's theorem. In our setting, the force is determined by the activation function and the input distribution. Building on this equivalence, we prove the existence of an activation function such that gradient descent learns at least one of the hidden nodes in the target network. Iterating, we show that gradient descent can be used to learn the entire network one node at a time."
https://openalex.org/W1591801644,Recurrent Neural Network Regularization,"{'We': [0], 'present': [1], 'a': [2, 54], 'simple': [3], 'regularization': [4], 'technique': [5, 21], 'for': [6, 22], 'Recurrent': [7], 'Neural': [8], 'Networks': [9], '(RNNs)': [10], 'with': [11, 30], 'Long': [12], 'Short-Term': [13], 'Memory': [14], '(LSTM)': [15], 'units.': [16], 'Dropout,': [17], 'the': [18], 'most': [19], 'successful': [20], 'regularizing': [23], 'neural': [24], 'networks,': [25], 'does': [26], 'not': [27], 'work': [28], 'well': [29], 'RNNs': [31], 'and': [32, 46, 68], 'LSTMs.': [33], 'In': [34], 'this': [35], 'paper,': [36], 'we': [37], 'show': [38, 47], 'how': [39], 'to': [40, 44], 'correctly': [41], 'apply': [42], 'dropout': [43], 'LSTMs,': [45], 'that': [48], 'it': [49], 'substantially': [50], 'reduces': [51], 'overfitting': [52], 'on': [53], 'variety': [55], 'of': [56], 'tasks.': [57], 'These': [58], 'tasks': [59], 'include': [60], 'language': [61], 'modeling,': [62], 'speech': [63], 'recognition,': [64], 'image': [65], 'caption': [66], 'generation,': [67], 'machine': [69], 'translation.': [70]}",2014,"['Regularization (linguistics)', 'Artificial neural network', 'Computer science', 'Artificial intelligence']","We present a simple regularization technique for Recurrent Neural Networks (RNNs) with Long Short-Term Memory (LSTM) units. Dropout, the most successful technique for regularizing neural networks, does not work well with RNNs and LSTMs. In this paper, we show how to correctly apply dropout to LSTMs, and show that it substantially reduces overfitting on a variety of tasks. These tasks include language modeling, speech recognition, image caption generation, and machine translation."
https://openalex.org/W2746314669,Improved Regularization of Convolutional Neural Networks with Cutout,"{'Convolutional': [0], 'neural': [1, 81], 'networks': [2], 'are': [3, 11, 30], 'capable': [4], 'of': [5, 55, 61, 79, 106, 139], 'learning': [6, 16], 'powerful': [7], 'representational': [8], 'spaces,': [9], 'which': [10, 65], 'necessary': [12], 'for': [13], 'tackling': [14], 'complex': [15], 'tasks.': [17], 'However,': [18], 'due': [19], 'to': [20, 25, 33, 42, 72, 90, 112, 124], 'the': [21, 51, 74, 129], 'model': [22, 115], 'capacity': [23], 'required': [24], 'capture': [26], 'such': [27], 'representations,': [28], 'they': [29], 'often': [31], 'susceptible': [32], 'overfitting': [34], 'and': [35, 76, 109, 132, 142], 'therefore': [36], 'require': [37], 'proper': [38], 'regularization': [39, 53], 'in': [40, 101], 'order': [41], 'generalize': [43], 'well.': [44], 'In': [45], 'this': [46, 86, 119], 'paper,': [47], 'we': [48, 66, 93], 'show': [49], 'that': [50, 96], 'simple': [52], 'technique': [54], 'randomly': [56], 'masking': [57], 'out': [58], 'square': [59], 'regions': [60], 'input': [62], 'during': [63], 'training,': [64], 'call': [67], 'cutout,': [68], 'can': [69, 98], 'be': [70, 99], 'used': [71, 100], 'improve': [73, 114], 'robustness': [75], 'overall': [77], 'performance': [78], 'convolutional': [80], 'networks.': [82], 'Not': [83], 'only': [84], 'is': [85, 148], 'method': [87, 120], 'extremely': [88], 'easy': [89], 'implement,': [91], 'but': [92], 'also': [94], 'demonstrate': [95], 'it': [97, 123], 'conjunction': [102], 'with': [103], 'existing': [104], 'forms': [105], 'data': [107], 'augmentation': [108], 'other': [110], 'regularizers': [111], 'further': [113], 'performance.': [116], 'We': [117], 'evaluate': [118], 'by': [121], 'applying': [122], 'current': [125], 'state-of-the-art': [126, 137], 'architectures': [127], 'on': [128], 'CIFAR-10,': [130], 'CIFAR-100,': [131], 'SVHN': [133], 'datasets,': [134], 'yielding': [135], 'new': [136], 'results': [138], '2.56%,': [140], '15.20%,': [141], '1.30%': [143], 'test': [144], 'error': [145], 'respectively.': [146], 'Code': [147], 'available': [149], 'at': [150], 'https://github.com/uoguelph-mlrg/Cutout': [151]}",2017,"['Convolutional neural network', 'Regularization (linguistics)', 'Computer science', 'Artificial intelligence']","Convolutional neural networks are capable of learning powerful representational spaces, which are necessary for tackling complex learning tasks. However, due to the model capacity required to capture such representations, they are often susceptible to overfitting and therefore require proper regularization in order to generalize well. In this paper, we show that the simple regularization technique of randomly masking out square regions of input during training, which we call cutout, can be used to improve the robustness and overall performance of convolutional neural networks. Not only is this method extremely easy to implement, but we also demonstrate that it can be used in conjunction with existing forms of data augmentation and other regularizers to further improve model performance. We evaluate this method by applying it to current state-of-the-art architectures on the CIFAR-10, CIFAR-100, and SVHN datasets, yielding new state-of-the-art results of 2.56%, 15.20%, and 1.30% test error respectively. Code is available at https://github.com/uoguelph-mlrg/Cutout"
https://openalex.org/W2319920447,Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1,"{'We': [0], 'introduce': [1], 'a': [2, 98], 'method': [3], 'to': [4, 56, 109], 'train': [5], 'Binarized': [6], 'Neural': [7], 'Networks': [8], '(BNNs)': [9], '-': [10], 'neural': [11], 'networks': [12], 'with': [13, 50, 104, 118], 'binary': [14, 23, 99], 'weights': [15, 24], 'and': [16, 25, 43, 45, 75, 89, 134], 'activations': [17, 26], 'at': [18], 'run-time.': [19], 'At': [20], 'training-time': [21], 'the': [22, 31, 35, 62, 73, 86], 'are': [27], 'used': [28], 'for': [29, 132], 'computing': [30], 'parameters': [32], 'gradients.': [33], 'During': [34], 'forward': [36], 'pass,': [37], 'BNNs': [38, 65, 80, 137], 'drastically': [39], 'reduce': [40], 'memory': [41], 'size': [42], 'accesses,': [44], 'replace': [46], 'most': [47], 'arithmetic': [48], 'operations': [49], 'bit-wise': [51], 'operations,': [52], 'which': [53, 105], 'is': [54, 107, 138], 'expected': [55], 'substantially': [57], 'improve': [58], 'power-efficiency.': [59], 'To': [60], 'validate': [61], 'effectiveness': [63], 'of': [64, 70], 'we': [66, 96], 'conduct': [67], 'two': [68], 'sets': [69], 'experiments': [71], 'on': [72], 'Torch7': [74], 'Theano': [76], 'frameworks.': [77], 'On': [78], 'both,': [79], 'achieved': [81], 'nearly': [82], 'state-of-the-art': [83], 'results': [84], 'over': [85], 'MNIST,': [87], 'CIFAR-10': [88], 'SVHN': [90], 'datasets.': [91], 'Last': [92], 'but': [93], 'not': [94], 'least,': [95], 'wrote': [97], 'matrix': [100], 'multiplication': [101], 'GPU': [102, 121], 'kernel': [103], 'it': [106], 'possible': [108], 'run': [110], 'our': [111, 136], 'MNIST': [112], 'BNN': [113], '7': [114], 'times': [115], 'faster': [116], 'than': [117], 'an': [119], 'unoptimized': [120], 'kernel,': [122], 'without': [123], 'suffering': [124], 'any': [125], 'loss': [126], 'in': [127], 'classification': [128], 'accuracy.': [129], 'The': [130], 'code': [131], 'training': [133], 'running': [135], 'available': [139], 'on-line.': [140]}",2016,"['MNIST database', 'Computer science', 'Artificial neural network', 'Multiplication (music)', 'Binary number', 'Kernel (algebra)', 'Code (set theory)', 'Deep neural networks', 'Artificial intelligence', 'Machine learning', 'Deep learning', 'Matrix multiplication', 'Pattern recognition (psychology)', 'Arithmetic', 'Mathematics', 'Physics', 'Quantum mechanics', 'Quantum', 'Programming language', 'Set (abstract data type)', 'Combinatorics']","We introduce a method to train Binarized Neural Networks (BNNs) - neural networks with binary weights and activations at run-time. At training-time the binary weights and activations are used for computing the parameters gradients. During the forward pass, BNNs drastically reduce memory size and accesses, and replace most arithmetic operations with bit-wise operations, which is expected to substantially improve power-efficiency. To validate the effectiveness of BNNs we conduct two sets of experiments on the Torch7 and Theano frameworks. On both, BNNs achieved nearly state-of-the-art results over the MNIST, CIFAR-10 and SVHN datasets. Last but not least, we wrote a binary matrix multiplication GPU kernel with which it is possible to run our MNIST BNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy. The code for training and running our BNNs is available on-line."
https://openalex.org/W2113325037,DeepPose: Human Pose Estimation via Deep Neural Networks,"{'We': [0, 27, 71], 'propose': [1], 'a': [2, 20, 29, 52, 57, 73], 'method': [3], 'for': [4], 'human': [5], 'pose': [6, 15, 40, 50], 'estimation': [7, 16], 'based': [8], 'on': [9, 65, 82], 'Deep': [10, 69], 'Neural': [11], 'Networks': [12], '(DNNs).': [13], 'The': [14, 42], 'is': [17], 'formulated': [18], 'as': [19], 'DNN-based': [21], 'regression': [22], 'problem': [23], 'towards': [24], 'body': [25], 'joints.': [26], 'present': [28, 72], 'cascade': [30], 'of': [31, 47, 86], 'such': [32], 'DNN': [33], 'regressors': [34], 'which': [35, 63], 'results': [36], 'in': [37, 51, 68], 'high': [38], 'precision': [39], 'estimates.': [41], 'approach': [43], 'has': [44, 56], 'the': [45], 'advantage': [46], 'reasoning': [48], 'about': [49], 'holistic': [53], 'fashion': [54], 'and': [55], 'simple': [58], 'but': [59], 'yet': [60], 'powerful': [61], 'formulation': [62], 'capitalizes': [64], 'recent': [66], 'advances': [67], 'Learning.': [70], 'detailed': [74], 'empirical': [75], 'analysis': [76], 'with': [77], 'state-of-art': [78], 'or': [79], 'better': [80], 'performance': [81], 'four': [83], 'academic': [84], 'benchmarks': [85], 'diverse': [87], 'real-world': [88], 'images.': [89]}",2014,"['Computer science', 'Artificial intelligence', 'Pose', 'Artificial neural network', 'Estimation', 'Deep neural networks', 'Computer vision', 'Pattern recognition (psychology)', 'Machine learning', 'Engineering', 'Systems engineering']",We propose a method for human pose estimation based on Deep Neural Networks (DNNs). The pose estimation is formulated as a DNN-based regression problem towards body joints. We present a cascade of such DNN regressors which results in high precision pose estimates. The approach has the advantage of reasoning about pose in a holistic fashion and has a simple but yet powerful formulation which capitalizes on recent advances in Deep Learning. We present a detailed empirical analysis with state-of-art or better performance on four academic benchmarks of diverse real-world images.
https://openalex.org/W2901312569,State-of-the-art in artificial neural network applications: A survey,"{'This': [0], 'is': [1], 'a': [2, 14, 152], 'survey': [3], 'of': [4, 16, 27, 38, 60, 150], 'neural': [5, 18, 105], 'network': [6], 'applications': [7, 34, 59], 'in': [8, 32, 63, 110], 'the': [9, 23, 43], 'real-world': [10], 'scenario.': [11], 'It': [12], 'provides': [13], 'taxonomy': [15], 'artificial': [17, 104], 'networks': [19, 106], '(ANNs)': [20], 'and': [21, 29, 36, 52, 79, 89, 101, 120, 143], 'furnish': [22], 'reader': [24], 'with': [25], 'knowledge': [26], 'current': [28], 'emerging': [30], 'trends': [31], 'ANN': [33, 46, 61, 85, 123, 161], 'research': [35, 126, 156], 'area': [37], 'focus': [39, 127, 158], 'for': [40, 125], 'researchers.': [41], 'Additionally,': [42], 'study': [44, 56, 83, 93], 'presents': [45], 'application': [47, 112], 'challenges,': [48], 'contributions,': [49, 86], 'compare': [50, 87], 'performances': [51, 88], 'critiques': [53, 90], 'methods.': [54, 91], 'The': [55, 82, 92], 'covers': [57], 'many': [58], 'techniques': [62], 'various': [64], 'disciplines': [65], 'which': [66], 'include': [67], 'computing,': [68], 'science,': [69], 'engineering,': [70], 'medicine,': [71], 'environmental,': [72], 'agriculture,': [73], 'mining,': [74], 'technology,': [75], 'climate,': [76], 'business,': [77], 'arts,': [78], 'nanotechnology,': [80], 'etc.': [81], 'assesses': [84], 'found': [94], 'that': [95, 148], 'neural-network': [96], 'models': [97, 124, 162], 'such': [98], 'as': [99], 'feedforward': [100, 119], 'feedback': [102, 121], 'propagation': [103, 122], 'are': [107], 'performing': [108], 'better': [109], 'its': [111], 'to': [113], 'human': [114], 'problems.': [115], 'Therefore,': [116], 'we': [117, 146], 'proposed': [118], 'based': [128], 'on': [129, 159], 'data': [130], 'analysis': [131], 'factors': [132], 'like': [133], 'accuracy,': [134], 'processing': [135], 'speed,': [136], 'latency,': [137], 'fault': [138], 'tolerance,': [139], 'volume,': [140], 'scalability,': [141], 'convergence,': [142], 'performance.': [144], 'Moreover,': [145], 'recommend': [147], 'instead': [149], 'applying': [151], 'single': [153], 'method,': [154], 'future': [155], 'can': [157], 'combining': [160], 'into': [163], 'one': [164], 'network-wide': [165], 'application.': [166]}",2018,"['Artificial neural network', 'State (computer science)', 'Artificial intelligence', 'Computer science', 'Data science', 'Engineering', 'Algorithm']","This is a survey of neural network applications in the real-world scenario. It provides a taxonomy of artificial neural networks (ANNs) and furnish the reader with knowledge of current and emerging trends in ANN applications research and area of focus for researchers. Additionally, the study presents ANN application challenges, contributions, compare performances and critiques methods. The study covers many applications of ANN techniques in various disciplines which include computing, science, engineering, medicine, environmental, agriculture, mining, technology, climate, business, arts, and nanotechnology, etc. The study assesses ANN contributions, compare performances and critiques methods. The study found that neural-network models such as feedforward and feedback propagation artificial neural networks are performing better in its application to human problems. Therefore, we proposed feedforward and feedback propagation ANN models for research focus based on data analysis factors like accuracy, processing speed, latency, fault tolerance, volume, scalability, convergence, and performance. Moreover, we recommend that instead of applying a single method, future research can focus on combining ANN models into one network-wide application."
https://openalex.org/W2950993016,Performance of neural network basecalling tools for Oxford Nanopore sequencing,"{'Basecalling': [0], 'accuracy': [1, 23, 29], 'has': [2], 'seen': [3], 'significant': [4], 'improvements': [5], 'over': [6], 'the': [7, 48], 'last': [8], '2': [9], 'years.': [10], 'The': [11], 'current': [12], 'version': [13], 'of': [14], ""ONT's"": [15], 'Guppy': [16], 'basecaller': [17], 'performs': [18], 'well': [19], 'overall,': [20], 'with': [21], 'good': [22], 'and': [24], 'fast': [25], 'performance.': [26], 'If': [27], 'higher': [28], 'is': [30], 'required,': [31], 'users': [32], 'should': [33], 'consider': [34], 'producing': [35], 'a': [36, 40], 'custom': [37], 'model': [38], 'using': [39], 'larger': [41], 'neural': [42], 'network': [43], 'and/or': [44], 'training': [45], 'data': [46], 'from': [47], 'same': [49], 'species.': [50]}",2019,"['Biology', 'Nanopore sequencing', 'Genome Biology', 'Human genetics', 'Computational biology', 'Artificial neural network', 'DNA sequencing', 'Nanopore', 'Evolutionary biology', 'Genomics', 'Artificial intelligence', 'Genetics', 'Computer science', 'Genome', 'Nanotechnology', 'Gene', 'Materials science']","Basecalling accuracy has seen significant improvements over the last 2 years. The current version of ONT's Guppy basecaller performs well overall, with good accuracy and fast performance. If higher accuracy is required, users should consider producing a custom model using a larger neural network and/or training data from the same species."
https://openalex.org/W2741907166,Deep learning with convolutional neural networks for EEG decoding and visualization,"{'Abstract': [0], 'Deep': [1], 'learning': [2, 18, 94], 'with': [3, 69, 104, 241], 'convolutional': [4], 'neural': [5], 'networks': [6], '(deep': [7], 'ConvNets)': [8], 'has': [9], 'revolutionized': [10], 'computer': [11], 'vision': [12], 'through': [13], 'end‐to‐end': [14, 32, 47], 'learning,': [15], 'that': [16, 88, 168], 'is,': [17], 'from': [19, 82, 91, 226], 'the': [20, 54, 58, 92, 110, 122, 149, 164, 178, 191, 196, 199, 209, 227, 235], 'raw': [21, 83, 228], 'data.': [22], 'There': [23], 'is': [24, 61, 142], 'increasing': [25], 'interest': [26], 'in': [27, 177, 204], 'using': [28], 'deep': [29, 67, 111, 138, 238], 'ConvNets': [30, 45, 59, 68, 112, 153, 169, 221, 239], 'for': [31, 46, 76, 162, 188, 245], 'EEG': [33, 48, 56, 229], 'analysis,': [34], 'but': [35], 'a': [36, 70, 105, 157], 'better': [37], 'understanding': [38], 'of': [39, 72, 198, 202, 237], 'how': [40, 51, 216], 'to': [41, 52, 144, 172, 208, 217, 222], 'design': [42, 218], 'and': [43, 50, 99, 181, 185, 219, 233], 'train': [44, 220], 'decoding': [49, 77, 113, 133, 210], 'visualize': [53], 'informative': [55], 'features': [57, 150, 166, 193, 203, 232], 'learn': [60], 'still': [62], 'needed.': [63], 'Here,': [64], 'we': [65], 'studied': [66], 'range': [71], 'different': [73, 205], 'architectures,': [74], 'designed': [75, 143], 'imagined': [78], 'or': [79], 'executed': [80], 'tasks': [81], 'EEG.': [84], 'Our': [85, 159, 212], 'results': [86], 'show': [87], 'recent': [89], 'advances': [90], 'machine': [93], 'field,': [95], 'including': [96], 'batch': [97], 'normalization': [98], 'exponential': [100], 'linear': [101], 'units,': [102], 'together': [103], 'cropped': [106], 'training': [107], 'strategy,': [108], 'boosted': [109], 'performance,': [114], 'reaching': [115], 'at': [116], 'least': [117], 'as': [118, 121], 'good': [119], 'performance': [120], 'widely': [123], 'used': [124, 151], 'filter': [125], 'bank': [126], 'common': [127], 'spatial': [128], 'patterns': [129], '(FBCSP)': [130], 'algorithm': [131], '(mean': [132], 'accuracies': [134], '82.1%': [135], 'FBCSP,': [136], '84.0%': [137], 'ConvNets).': [139], 'While': [140], 'FBCSP': [141], 'use': [145, 173], 'spectral': [146, 174], 'power': [147, 175], 'modulations,': [148], 'by': [152, 194], 'are': [154], 'not': [155], 'fixed': [156], 'priori.': [158], 'novel': [160], 'methods': [161], 'visualizing': [163], 'learned': [165, 171, 192], 'demonstrated': [167], 'indeed': [170], 'modulations': [176], 'alpha,': [179], 'beta,': [180], 'high': [182], 'gamma': [183], 'frequencies,': [184], 'proved': [186], 'useful': [187], 'spatially': [189], 'mapping': [190], 'revealing': [195], 'topography': [197], 'causal': [200], 'contributions': [201], 'frequency': [206], 'bands': [207], 'decision.': [211], 'study': [213], 'thus': [214], 'shows': [215], 'decode': [223], 'task‐related': [224], 'information': [225], 'without': [230], 'handcrafted': [231], 'highlights': [234], 'potential': [236], 'combined': [240], 'advanced': [242], 'visualization': [243], 'techniques': [244], 'EEG‐based': [246], 'brain': [247], 'mapping.': [248], 'Hum': [249], 'Brain': [250], 'Mapp': [251], '38:5391–5420,': [252], '2017': [253, 256], '.': [254], '©': [255], 'Wiley': [257], 'Periodicals,': [258], 'Inc.': [259]}",2017,"['Artificial intelligence', 'Deep learning', 'Computer science', 'Decoding methods', 'Convolutional neural network', 'Pattern recognition (psychology)', 'Visualization', 'Electroencephalography', 'Normalization (sociology)', 'Machine learning', 'Algorithm', 'Anthropology', 'Psychology', 'Psychiatry', 'Sociology']","Abstract Deep learning with convolutional neural networks (deep ConvNets) has revolutionized computer vision through end‐to‐end learning, that is, learning from the raw data. There is increasing interest in using deep ConvNets for end‐to‐end EEG analysis, but a better understanding of how to design and train ConvNets for end‐to‐end EEG decoding and how to visualize the informative EEG features the ConvNets learn is still needed. Here, we studied deep ConvNets with a range of different architectures, designed for decoding imagined or executed tasks from raw EEG. Our results show that recent advances from the machine learning field, including batch normalization and exponential linear units, together with a cropped training strategy, boosted the deep ConvNets decoding performance, reaching at least as good performance as the widely used filter bank common spatial patterns (FBCSP) algorithm (mean decoding accuracies 82.1% FBCSP, 84.0% deep ConvNets). While FBCSP is designed to use spectral power modulations, the features used by ConvNets are not fixed a priori. Our novel methods for visualizing the learned features demonstrated that ConvNets indeed learned to use spectral power modulations in the alpha, beta, and high gamma frequencies, and proved useful for spatially mapping the learned features by revealing the topography of the causal contributions of features in different frequency bands to the decoding decision. Our study thus shows how to design and train ConvNets to decode task‐related information from the raw EEG without handcrafted features and highlights the potential of deep ConvNets combined with advanced visualization techniques for EEG‐based brain mapping. Hum Brain Mapp 38:5391–5420, 2017 . © 2017 Wiley Periodicals, Inc."
https://openalex.org/W2124592697,Conditional Random Fields as Recurrent Neural Networks,"{'Pixel-level': [0], 'labelling': [1, 32], 'tasks,': [2], 'such': [3], 'as': [4, 99, 111], 'semantic': [5, 171], 'segmentation,': [6, 173], 'play': [7], 'a': [8, 58, 112, 115, 119], 'central': [9, 35], 'role': [10], 'in': [11, 37, 110], 'image': [12, 27, 172], 'understanding.': [13], 'Recent': [14], 'approaches': [15], 'have': [16], 'attempted': [17], 'to': [18, 29, 48, 117, 143, 167], 'harness': [19], 'the': [20, 41, 67, 91, 145, 151, 164, 168, 178], 'capabilities': [21], 'of': [22, 44, 61, 69, 114, 126, 170], 'deep': [23, 45, 120, 147], 'learning': [24, 46], 'techniques': [25, 47], 'for': [26, 90, 159], 'recognition': [28], 'tackle': [30], 'pixel-level': [31], 'tasks.': [33], 'One': [34], 'issue': [36], 'this': [38, 54, 83], 'methodology': [39], 'is': [40, 107], 'limited': [42], 'capacity': [43], 'delineate': [49], 'visual': [50], 'objects.': [51], 'To': [52, 82], 'solve': [53], 'problem,': [55], 'we': [56, 85], 'introduce': [57], 'new': [59], 'form': [60], 'convolutional': [62], 'neural': [63], 'network': [64, 121, 148], 'that': [65, 122], 'combines': [66], 'strengths': [68], 'Convolutional': [70], 'Neural': [71, 101], 'Networks': [72], '(CNNs)': [73], 'and': [74, 129], 'Conditional': [75, 92], 'Random': [76, 93], 'Fields': [77, 94], '(CRFs)-based': [78], 'probabilistic': [79], 'graphical': [80], 'modelling.': [81], 'end,': [84], 'formulate': [86], 'mean-field': [87], 'approximate': [88], 'inference': [89], 'with': [95, 138, 150], 'Gaussian': [96], 'pairwise': [97], 'potentials': [98], 'Recurrent': [100], 'Networks.': [102], 'This': [103], 'network,': [104], 'called': [105], 'CRF-RNN,': [106], 'then': [108], 'plugged': [109], 'part': [113], 'CNN': [116], 'obtain': [118], 'has': [123], 'desirable': [124], 'properties': [125], 'both': [127], 'CNNs': [128], 'CRFs.': [130], 'Importantly,': [131], 'our': [132], 'system': [133], 'fully': [134], 'integrates': [135], 'CRF': [136], 'modelling': [137], 'CNNs,': [139], 'making': [140], 'it': [141], 'possible': [142], 'train': [144], 'whole': [146], 'end-to-end': [149], 'usual': [152], 'back-propagation': [153], 'algorithm,': [154], 'avoiding': [155], 'offline': [156], 'post-processing': [157], 'methods': [158], 'object': [160], 'delineation.': [161], 'We': [162], 'apply': [163], 'proposed': [165], 'method': [166], 'problem': [169], 'obtaining': [174], 'top': [175], 'results': [176], 'on': [177], 'challenging': [179], 'Pascal': [180], 'VOC': [181], '2012': [182], 'segmentation': [183], 'benchmark.': [184]}",2015,"['Conditional random field', 'Computer science', 'Artificial neural network', 'Recurrent neural network', 'Artificial intelligence']","Pixel-level labelling tasks, such as semantic segmentation, play a central role in image understanding. Recent approaches have attempted to harness the capabilities of deep learning techniques for image recognition to tackle pixel-level labelling tasks. One central issue in this methodology is the limited capacity of deep learning techniques to delineate visual objects. To solve this problem, we introduce a new form of convolutional neural network that combines the strengths of Convolutional Neural Networks (CNNs) and Conditional Random Fields (CRFs)-based probabilistic graphical modelling. To this end, we formulate mean-field approximate inference for the Conditional Random Fields with Gaussian pairwise potentials as Recurrent Neural Networks. This network, called CRF-RNN, is then plugged in as a part of a CNN to obtain a deep network that has desirable properties of both CNNs and CRFs. Importantly, our system fully integrates CRF modelling with CNNs, making it possible to train the whole deep network end-to-end with the usual back-propagation algorithm, avoiding offline post-processing methods for object delineation. We apply the proposed method to the problem of semantic image segmentation, obtaining top results on the challenging Pascal VOC 2012 segmentation benchmark."
https://openalex.org/W2559463885,EEGNet: a compact convolutional neural network for EEG-based brain–computer interfaces,"{'Our': [0, 22], 'results': [1], 'suggest': [2], 'that': [3], 'EEGNet': [4], 'is': [5], 'robust': [6], 'enough': [7], 'to': [8], 'learn': [9], 'a': [10, 17], 'wide': [11], 'variety': [12], 'of': [13, 19], 'interpretable': [14], 'features': [15], 'over': [16], 'range': [18], 'BCI': [20], 'tasks.': [21], 'models': [23], 'can': [24], 'be': [25], 'found': [26], 'at:': [27], 'https://github.com/vlawhern/arl-eegmodels.': [28]}",2018,[],Our results suggest that EEGNet is robust enough to learn a wide variety of interpretable features over a range of BCI tasks. Our models can be found at: https://github.com/vlawhern/arl-eegmodels.
https://openalex.org/W2265846598,Recurrent Convolutional Neural Networks for Text Classification,"{'Text': [0], 'classification': [1, 42, 94], 'is': [2], 'a': [3, 35, 51, 81], 'foundational': [4], 'task': [5], 'in': [6, 92, 100], 'many': [7, 16], 'NLP': [8], 'applications.': [9], 'Traditional': [10], 'text': [11, 41, 93], 'classifiers': [12], 'often': [13], 'rely': [14], 'on': [15, 105, 122, 126], 'human-designed': [17, 44], 'features,': [18], 'such': [19], 'as': [20, 58, 60], 'dictionaries,': [21], 'knowledge': [22], 'bases': [23], 'and': [24], 'special': [25], 'tree': [26], 'kernels.': [27], 'In': [28, 46], 'contrast': [29], 'to': [30, 54, 73, 95], 'traditional': [31, 74], 'methods,': [32], 'we': [33, 49], 'introduce': [34, 68], 'recurrent': [36, 52], 'convolutional': [37], 'neural': [38, 76], 'network': [39], 'for': [40], 'without': [43], 'features.': [45], 'our': [47], 'model,': [48], 'apply': [50], 'structure': [53], 'capture': [55, 96], 'contextual': [56], 'information': [57], 'far': [59], 'possible': [61], 'when': [62], 'learning': [63], 'word': [64], 'representations,': [65], 'which': [66, 87], 'may': [67], 'considerably': [69], 'less': [70], 'noise': [71], 'compared': [72], 'window-based': [75], 'networks.': [77], 'We': [78, 102], 'also': [79], 'employ': [80], 'max-pooling': [82], 'layer': [83], 'that': [84, 114], 'automatically': [85], 'judges': [86], 'words': [88], 'play': [89], 'key': [90, 98], 'roles': [91], 'the': [97, 115, 119], 'components': [99], 'texts.': [101], 'conduct': [103], 'experiments': [104], 'four': [106], 'commonly': [107], 'used': [108], 'datasets.': [109, 128], 'The': [110], 'experimental': [111], 'results': [112], 'show': [113], 'proposed': [116], 'method': [117], 'outperforms': [118], 'state-of-the-art': [120], 'methods': [121], 'several': [123], 'datasets,': [124], 'particularly': [125], 'document-level': [127]}",2015,"['Computer science', 'Artificial intelligence', 'Pooling', 'Convolutional neural network', 'Key (lock)', 'Task (project management)', 'Natural language processing', 'Word (group theory)', 'Recurrent neural network', 'Contrast (vision)', 'Machine learning', 'Tree (set theory)', 'Artificial neural network', 'Pattern recognition (psychology)', 'Mathematics', 'Management', 'Linguistics', 'Philosophy', 'Mathematical analysis', 'Economics', 'Computer security']","Text classification is a foundational task in many NLP applications. Traditional text classifiers often rely on many human-designed features, such as dictionaries, knowledge bases and special tree kernels. In contrast to traditional methods, we introduce a recurrent convolutional neural network for text classification without human-designed features. In our model, we apply a recurrent structure to capture contextual information as far as possible when learning word representations, which may introduce considerably less noise compared to traditional window-based neural networks. We also employ a max-pooling layer that automatically judges which words play key roles in text classification to capture the key components in texts. We conduct experiments on four commonly used datasets. The experimental results show that the proposed method outperforms the state-of-the-art methods on several datasets, particularly on document-level datasets."
https://openalex.org/W2119144962,"Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding","{'Neural': [0], 'networks': [1, 49, 193], 'are': [2, 203], 'both': [3], 'computationally': [4], 'intensive': [5], 'and': [6, 36, 99, 200, 209, 220], 'memory': [7], 'intensive,': [8], 'making': [9], 'them': [10], 'difficult': [11], 'to': [12, 42, 52, 75, 93, 111, 126, 144, 161, 216, 222], 'deploy': [13], 'on': [14, 206], 'embedded': [15], 'systems': [16], 'with': [17, 164], 'limited': [18], 'hardware': [19], 'resources.': [20], 'To': [21], 'address': [22], 'this': [23], 'limitation,': [24], 'we': [25, 71, 80, 89], 'introduce': [26], '""deep': [27], 'compression"",': [28], 'a': [29], 'three': [30], 'stage': [31], 'pipeline:': [32], 'pruning,': [33], 'trained': [34], 'quantization': [35], 'Huffman': [37, 82], 'coding,': [38], 'that': [39, 120], 'work': [40], 'together': [41], 'reduce': [43], 'the': [44, 62, 67, 73, 85, 91, 96, 100, 105, 116, 129, 135, 153, 172, 188], 'storage': [45, 136], 'requirement': [46], 'of': [47, 107, 118, 148, 155, 167, 190], 'neural': [48, 192], 'by': [50, 64, 109, 138, 140, 157], '35x': [51], '49x': [53, 158], 'without': [54, 146], 'affecting': [55], 'their': [56], 'accuracy.': [57, 149, 168], 'Our': [58, 150, 183], 'method': [59, 133, 151, 185], 'first': [60, 86], 'prunes': [61], 'network': [63, 92, 213], 'learning': [65], 'only': [66], 'important': [68], 'connections.': [69], 'Next,': [70], 'quantize': [72], 'weights': [74], 'enforce': [76], 'weight': [77], 'sharing,': [78], 'finally,': [79], 'apply': [81], 'coding.': [83], 'After': [84], 'two': [87], 'steps': [88], 'retrain': [90], 'fine': [94], 'tune': [95], 'remaining': [97], 'connections': [98, 108], 'quantized': [101], 'centroids.': [102], 'Pruning,': [103], 'reduces': [104, 115], 'number': [106, 117], '9x': [110], '13x;': [112], 'Quantization': [113], 'then': [114], 'bits': [119], 'represent': [121], 'each': [122], 'connection': [123], 'from': [124, 142, 159], '32': [125], '5.': [127], 'On': [128], 'ImageNet': [130], 'dataset,': [131], 'our': [132], 'reduced': [134, 152], 'required': [137], 'AlexNet': [139], '35x,': [141], '240MB': [143], '6.9MB,': [145], 'loss': [147, 166], 'size': [154, 199], 'VGG-16': [156], '552MB': [160], '11.3MB,': [162], 'again': [163], 'no': [165], 'This': [169], 'allows': [170], 'fitting': [171], 'model': [173], 'into': [174], 'on-chip': [175], 'SRAM': [176], 'cache': [177], 'rather': [178], 'than': [179], 'off-chip': [180], 'DRAM': [181], 'memory.': [182], 'compression': [184], 'also': [186], 'facilitates': [187], 'use': [189], 'complex': [191], 'in': [194], 'mobile': [195, 210], 'applications': [196], 'where': [197], 'application': [198], 'download': [201], 'bandwidth': [202], 'constrained.': [204], 'Benchmarked': [205], 'CPU,': [207], 'GPU': [208], 'GPU,': [211], 'compressed': [212], 'has': [214], '3x': [215, 221], '4x': [217], 'layerwise': [218], 'speedup': [219], '7x': [223], 'better': [224], 'energy': [225], 'efficiency.': [226]}",2015,"['Huffman coding', 'Computer science', 'Quantization (signal processing)', 'Artificial neural network', 'Speedup', 'Parallel computing', 'Coding (social sciences)', 'Cache', 'SIMD', 'CPU cache', 'Computer engineering', 'Artificial intelligence', 'Data compression', 'Algorithm', 'Mathematics', 'Statistics']","Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems with limited hardware resources. To address this limitation, we introduce ""deep compression"", a three stage pipeline: pruning, trained quantization and Huffman coding, that work together to reduce the storage requirement of neural networks by 35x to 49x without affecting their accuracy. Our method first prunes the network by learning only the important connections. Next, we quantize the weights to enforce weight sharing, finally, we apply Huffman coding. After the first two steps we retrain the network to fine tune the remaining connections and the quantized centroids. Pruning, reduces the number of connections by 9x to 13x; Quantization then reduces the number of bits that represent each connection from 32 to 5. On the ImageNet dataset, our method reduced the storage required by AlexNet by 35x, from 240MB to 6.9MB, without loss of accuracy. Our method reduced the size of VGG-16 by 49x from 552MB to 11.3MB, again with no loss of accuracy. This allows fitting the model into on-chip SRAM cache rather than off-chip DRAM memory. Our compression method also facilitates the use of complex neural networks in mobile applications where application size and download bandwidth are constrained. Benchmarked on CPU, GPU and mobile GPU, compressed network has 3x to 4x layerwise speedup and 3x to 7x better energy efficiency."
https://openalex.org/W2624871570,An Overview of Multi-Task Learning in Deep Neural Networks,"{'Multi-task': [0], 'learning': [1], '(MTL)': [2], 'has': [3], 'led': [4], 'to': [5, 20, 29, 67], 'successes': [6], 'in': [7, 37, 50], 'many': [8], 'applications': [9], 'of': [10, 34, 56], 'machine': [11], 'learning,': [12], 'from': [13], 'natural': [14], 'language': [15], 'processing': [16], 'and': [17, 23, 59, 80], 'speech': [18], 'recognition': [19], 'computer': [21], 'vision': [22], 'drug': [24], 'discovery.': [25], 'This': [26], 'article': [27], 'aims': [28], 'give': [30], 'a': [31], 'general': [32], 'overview': [33, 55], 'MTL,': [35], 'particularly': [36], 'deep': [38], 'neural': [39], 'networks.': [40], 'It': [41], 'introduces': [42], 'the': [43, 57], 'two': [44], 'most': [45], 'common': [46], 'methods': [47], 'for': [48, 83], 'MTL': [49, 72, 78], 'Deep': [51], 'Learning,': [52], 'gives': [53], 'an': [54], 'literature,': [58], 'discusses': [60], 'recent': [61], 'advances.': [62], 'In': [63], 'particular,': [64], 'it': [65], 'seeks': [66], 'help': [68], 'ML': [69], 'practitioners': [70], 'apply': [71], 'by': [73], 'shedding': [74], 'light': [75], 'on': [76], 'how': [77], 'works': [79], 'providing': [81], 'guidelines': [82], 'choosing': [84], 'appropriate': [85], 'auxiliary': [86], 'tasks.': [87]}",2017,"['Computer science', 'Deep learning', 'Task (project management)', 'Artificial intelligence', 'Deep neural networks', 'Artificial neural network', 'Machine learning', 'Cognitive science', 'Psychology', 'Engineering', 'Systems engineering']","Multi-task learning (MTL) has led to successes in many applications of machine learning, from natural language processing and speech recognition to computer vision and drug discovery. This article aims to give a general overview of MTL, particularly in deep neural networks. It introduces the two most common methods for MTL in Deep Learning, gives an overview of the literature, and discusses recent advances. In particular, it seeks to help ML practitioners apply MTL by shedding light on how MTL works and providing guidelines for choosing appropriate auxiliary tasks."
https://openalex.org/W2574952845,Deep Convolutional Neural Network for Inverse Problems in Imaging,"{'In': [0], 'this': [1, 73, 118], 'paper,': [2], 'we': [3, 120], 'propose': [4, 121], 'a': [5, 86, 114, 127, 222, 226], 'novel': [6], 'deep': [7], 'convolutional': [8], 'neural': [9], 'network': [10, 181, 207], '(CNN)-based': [11], 'algorithm': [12], 'for': [13, 213], 'solving': [14], 'ill-posed': [15, 28], 'inverse': [16, 29, 132], 'problems.': [17, 133], 'Regularized': [18], 'iterative': [19, 80, 211], 'algorithms': [20], 'have': [21, 82], 'emerged': [22], 'as': [23, 198, 200], 'the': [24, 32, 53, 58, 64, 76, 83, 94, 101, 104, 110, 138, 142, 149, 154, 176, 179, 214, 232], 'standard': [25], 'approach': [26], 'to': [27, 45, 50, 129, 146, 164, 166, 186, 224], 'problems': [30], 'in': [31, 47, 162, 182, 195, 201], 'past': [33], 'few': [34], 'decades.': [35], 'These': [36], 'methods': [37, 81], 'produce': [38], 'excellent': [39], 'results,': [40], 'but': [41, 144], 'can': [42], 'be': [43], 'challenging': [44], 'deploy': [46], 'practice': [48], 'due': [49], 'factors': [51], 'including': [52], 'high': [54], 'computational': [55], 'cost': [56], 'of': [57, 66, 72, 85, 103, 109, 141, 178], 'forward': [59, 105, 111], 'and': [60, 63, 159, 218], 'adjoint': [61, 102], 'operators': [62], 'difficulty': [65], 'hyperparameter': [67], 'selection.': [68], 'The': [69, 134, 205], 'starting': [70], 'point': [71], 'paper': [74], 'is': [75, 100, 113, 151], 'observation': [77], 'that': [78], 'unrolled': [79], 'form': [84], 'CNN': [87, 128, 155], '(filtering': [88], 'followed': [89, 125], 'by': [90, 126], 'pointwise': [91], 'nonlinearity)': [92], 'when': [93, 148], 'normal': [95], 'operator': [96], '(H*H,': [97], 'where': [98], 'H*': [99], 'imaging': [106], 'operator,': [107], 'H)': [108], 'model': [112, 140], 'convolution.': [115], 'Based': [116], 'on': [117, 189, 231], 'observation,': [119], 'using': [122], 'direct': [123, 135], 'inversion': [124, 136], 'solve': [130], 'normal-convolutional': [131], 'encapsulates': [137], 'physical': [139], 'system,': [143], 'leads': [145], 'artifacts': [147, 169], 'problem': [150], 'ill': [152], 'posed;': [153], 'combines': [156], 'multiresolution': [157], 'decomposition': [158], 'residual': [160], 'learning': [161], 'order': [163], 'learn': [165], 'remove': [167], 'these': [168], 'while': [170], 'preserving': [171], 'image': [172, 230], 'structure.': [173], 'We': [174], 'demonstrate': [175], 'performance': [177], 'proposed': [180, 206], 'sparse-view': [183], 'reconstruction': [184, 212], '(down': [185], '50': [187], 'views)': [188], 'parallel': [190], 'beam': [191], 'X-ray': [192], 'computed': [193], 'tomography': [194], 'synthetic': [196], 'phantoms': [197, 217], 'well': [199], 'real': [202], 'experimental': [203], 'sinograms.': [204], 'outperforms': [208], 'total': [209], 'variation-regularized': [210], 'more': [215], 'realistic': [216], 'requires': [219], 'less': [220], 'than': [221], 'second': [223], 'reconstruct': [225], '512': [227, 229], '×': [228], 'GPU.': [233]}",2017,"['Convolutional neural network', 'Computer science', 'Artificial intelligence', 'Inverse problem', 'Pattern recognition (psychology)', 'Artificial neural network', 'Medical imaging', 'Image processing', 'Image (mathematics)', 'Mathematics', 'Mathematical analysis']","In this paper, we propose a novel deep convolutional neural network (CNN)-based algorithm for solving ill-posed inverse problems. Regularized iterative algorithms have emerged as the standard approach to ill-posed inverse problems in the past few decades. These methods produce excellent results, but can be challenging to deploy in practice due to factors including the high computational cost of the forward and adjoint operators and the difficulty of hyperparameter selection. The starting point of this paper is the observation that unrolled iterative methods have the form of a CNN (filtering followed by pointwise nonlinearity) when the normal operator (H*H, where H* is the adjoint of the forward imaging operator, H) of the forward model is a convolution. Based on this observation, we propose using direct inversion followed by a CNN to solve normal-convolutional inverse problems. The direct inversion encapsulates the physical model of the system, but leads to artifacts when the problem is ill posed; the CNN combines multiresolution decomposition and residual learning in order to learn to remove these artifacts while preserving image structure. We demonstrate the performance of the proposed network in sparse-view reconstruction (down to 50 views) on parallel beam X-ray computed tomography in synthetic phantoms as well as in real experimental sinograms. The proposed network outperforms total variation-regularized iterative reconstruction for the more realistic phantoms and requires less than a second to reconstruct a 512 × 512 image on the GPU."
https://openalex.org/W2626967530,On Calibration of Modern Neural Networks,"{'Confidence': [0], 'calibration': [1, 64], '--': [2, 15, 103, 110], 'the': [3, 11, 59], 'problem': [4], 'of': [5, 10, 61, 107], 'predicting': [6], 'probability': [7], 'estimates': [8], 'representative': [9], 'true': [12], 'correctness': [13], 'likelihood': [14], 'is': [16, 111], 'important': [17, 53], 'for': [18, 95], 'classification': [19, 73], 'models': [20], 'in': [21], 'many': [22], 'applications.': [23], 'We': [24, 57], 'discover': [25], 'that': [26, 44], 'modern': [27], 'neural': [28, 84], 'networks,': [29], 'unlike': [30], 'those': [31], 'from': [32], 'a': [33, 90, 104], 'decade': [34], 'ago,': [35], 'are': [36, 52], 'poorly': [37], 'calibrated.': [38], 'Through': [39], 'extensive': [40], 'experiments,': [41], 'we': [42], 'observe': [43], 'depth,': [45], 'width,': [46], 'weight': [47], 'decay,': [48], 'and': [49, 71, 77, 92], 'Batch': [50], 'Normalization': [51], 'factors': [54], 'influencing': [55], 'calibration.': [56], 'evaluate': [58], 'performance': [60], 'various': [62], 'post-processing': [63], 'methods': [65], 'on': [66, 98], 'state-of-the-art': [67], 'architectures': [68], 'with': [69], 'image': [70], 'document': [72], 'datasets.': [74], 'Our': [75], 'analysis': [76], 'experiments': [78], 'not': [79], 'only': [80], 'offer': [81], 'insights': [82], 'into': [83], 'network': [85], 'learning,': [86], 'but': [87], 'also': [88], 'provide': [89], 'simple': [91], 'straightforward': [93], 'recipe': [94], 'practical': [96], 'settings:': [97], 'most': [99], 'datasets,': [100], 'temperature': [101], 'scaling': [102], 'single-parameter': [105], 'variant': [106], 'Platt': [108], 'Scaling': [109], 'surprisingly': [112], 'effective': [113], 'at': [114], 'calibrating': [115], 'predictions.': [116]}",2017,"['Normalization (sociology)', 'Artificial neural network', 'Correctness', 'Scaling', 'Computer science', 'Calibration', 'Deep neural networks', 'Artificial intelligence', 'Machine learning', 'Simple (philosophy)', 'Pattern recognition (psychology)', 'Data mining', 'Algorithm', 'Mathematics', 'Statistics', 'Epistemology', 'Philosophy', 'Anthropology', 'Geometry', 'Sociology']","Confidence calibration -- the problem of predicting probability estimates representative of the true correctness likelihood -- is important for classification models in many applications. We discover that modern neural networks, unlike those from a decade ago, are poorly calibrated. Through extensive experiments, we observe that depth, width, weight decay, and Batch Normalization are important factors influencing calibration. We evaluate the performance of various post-processing calibration methods on state-of-the-art architectures with image and document classification datasets. Our analysis and experiments not only offer insights into neural network learning, but also provide a simple and straightforward recipe for practical settings: on most datasets, temperature scaling -- a single-parameter variant of Platt Scaling -- is surprisingly effective at calibrating predictions."
https://openalex.org/W2807021761,Graph Convolutional Neural Networks for Web-Scale Recommender Systems,"{'Recent': [0], 'advancements': [1], 'in': [2], 'deep': [3, 43, 174, 187], 'neural': [4], 'networks': [5], 'for': [6], 'graph-structured': [7], 'data': [8], 'have\\nled': [9], 'to': [10, 23, 68, 86, 114, 162, 190], 'state-of-the-art': [11], 'performance': [12], 'on': [13, 95, 143, 147, 204], 'recommender': [14, 201], 'system': [15], 'benchmarks.': [16], 'However,\\nmaking': [17], 'these': [18], 'methods': [19], 'practical': [20], 'and': [21, 30, 66, 103, 117, 155, 157, 166, 176, 192], 'scalable': [22], 'web-scale': [24, 200], 'recommendation': [25, 44], 'tasks\\nwith': [26], 'billions': [27], 'of': [28, 32, 34, 71, 186, 199], 'items': [29], 'hundreds': [31], 'millions': [33], 'users': [35], 'remains': [36], 'a': [37, 41, 54, 91, 105, 133, 148, 196], 'challenge.\\nHere': [38], 'we': [39, 47, 89], 'describe': [40], 'large-scale': [42], 'engine': [45], 'that': [46, 75, 109], 'developed': [48], 'and\\ndeployed': [49], 'at': [50, 139], 'Pinterest.': [51], 'We': [52, 121, 136], 'develop': [53, 90, 123], 'data-efficient': [55], 'Graph': [56], 'Convolutional': [57], 'Network\\n(GCN)': [58], 'algorithm': [59, 129], 'PinSage,': [60], 'which': [61], 'combines': [62], 'efficient': [63, 97, 125], 'random': [64, 98], 'walks': [65, 99], 'graph\\nconvolutions': [67], 'generate': [69], 'embeddings': [70, 131, 189], 'nodes': [72, 153], '(i.e.,': [73], 'items)': [74], 'incorporate\\nboth': [76], 'graph': [77, 149, 188], 'structure': [78], 'as': [79, 81], 'well': [80], 'node': [82], 'feature': [83], 'information.': [84], 'Compared': [85], 'prior': [87], 'GCN\\napproaches,': [88], 'novel': [92, 106], 'method': [93], 'based': [94, 203], 'highly': [96], 'to\\nstructure': [100], 'the': [101, 183, 194], 'convolutions': [102], 'design': [104], 'training': [107, 112], 'strategy': [108], 'relies': [110], 'on\\nharder-and-harder': [111], 'examples': [113, 146], 'improve': [115], 'robustness': [116], 'convergence': [118], 'of\\nthe': [119], 'model.': [120, 135], 'also': [122], 'an': [124], 'MapReduce': [126], 'model': [127], 'inference': [128], 'to\\ngenerate': [130], 'using': [132], 'trained': [134], 'deploy': [137], 'PinSage': [138, 169], 'Pinterest': [140], 'and\\ntrain': [141], 'it': [142], '7.5': [144], 'billion': [145, 152, 159], 'with': [150], '3': [151], 'representing\\npins': [154], 'boards,': [156], '18': [158], 'edges.': [160], 'According': [161], 'offline': [163], 'metrics,': [164], 'user\\nstudies': [165], 'A/B': [167], 'tests,': [168], 'generates': [170], 'higher-quality': [171], 'recommendations': [172], 'than\\ncomparable': [173], 'learning': [175], 'graph-based': [177], 'alternatives.': [178], 'To': [179], 'our': [180], 'knowledge,': [181], 'this\\nis': [182], 'largest': [184], 'application': [185], 'date': [191], 'paves': [193], 'way\\nfor': [195], 'new': [197], 'generation': [198], 'systems': [202], 'graph\\nconvolutional': [205], 'architectures.\\n': [206]}",2018,[],"Recent advancements in deep neural networks for graph-structured data have\nled to state-of-the-art performance on recommender system benchmarks. However,\nmaking these methods practical and scalable to web-scale recommendation tasks\nwith billions of items and hundreds of millions of users remains a challenge.\nHere we describe a large-scale deep recommendation engine that we developed and\ndeployed at Pinterest. We develop a data-efficient Graph Convolutional Network\n(GCN) algorithm PinSage, which combines efficient random walks and graph\nconvolutions to generate embeddings of nodes (i.e., items) that incorporate\nboth graph structure as well as node feature information. Compared to prior GCN\napproaches, we develop a novel method based on highly efficient random walks to\nstructure the convolutions and design a novel training strategy that relies on\nharder-and-harder training examples to improve robustness and convergence of\nthe model. We also develop an efficient MapReduce model inference algorithm to\ngenerate embeddings using a trained model. We deploy PinSage at Pinterest and\ntrain it on 7.5 billion examples on a graph with 3 billion nodes representing\npins and boards, and 18 billion edges. According to offline metrics, user\nstudies and A/B tests, PinSage generates higher-quality recommendations than\ncomparable deep learning and graph-based alternatives. To our knowledge, this\nis the largest application of deep graph embeddings to date and paves the way\nfor a new generation of web-scale recommender systems based on graph\nconvolutional architectures.\n"
https://openalex.org/W2892880750,Hypergraph Neural Networks,"{'In': [0, 60, 77], 'this': [1, 61, 78], 'paper,': [2], 'we': [3, 37], 'present': [4], 'a': [5, 22, 45, 63, 108], 'hypergraph': [6, 23, 81], 'neural': [7], 'networks': [8, 135], '(HGNN)': [9], 'framework': [10, 110], 'for': [11, 31], 'data': [12, 19, 33, 42, 52, 72, 104, 114, 169], 'representation': [13, 30, 75, 100], 'learning,': [14], 'which': [15, 47, 106], 'can': [16, 84, 153], 'encode': [17], 'high-order': [18, 103], 'correlation': [20, 73], 'in': [21, 34, 44], 'structure.': [24], 'Confronting': [25], 'the': [26, 71, 97, 102, 112, 144, 157, 160], 'challenges': [27], 'of': [28], 'learning': [29, 82], 'complex': [32, 58, 113], 'real': [35], 'practice,': [36], 'propose': [38], 'to': [39, 69, 95], 'incorporate': [40], 'such': [41], 'structure': [43], 'hypergraph,': [46], 'is': [48, 67, 93, 107, 163], 'more': [49], 'flexible': [50], 'on': [51, 120], 'modeling,': [53], 'especially': [54], 'when': [55, 165], 'dealing': [56, 166], 'with': [57, 132, 167, 171], 'data.': [59], 'method,': [62], 'hyperedge': [64, 88], 'convolution': [65, 89], 'operation': [66], 'designed': [68], 'handle': [70], 'during': [74], 'learning.': [76], 'way,': [79], 'traditional': [80, 138], 'procedure': [83], 'be': [85], 'conducted': [86, 118], 'using': [87], 'operations': [90], 'efficiently.': [91], 'HGNN': [92, 131, 146, 162], 'able': [94], 'learn': [96], 'hidden': [98], 'layer': [99], 'considering': [101, 111], 'structure,': [105], 'general': [109], 'correlations.': [115], 'We': [116, 152], 'have': [117], 'experiments': [119], 'citation': [121], 'network': [122], 'classification': [123], 'and': [124, 129, 136], 'visual': [125], 'object': [126], 'recognition': [127], 'tasks': [128], 'compared': [130, 170], 'graph': [133], 'convolutional': [134], 'other': [137], 'methods.': [139, 151, 173], 'Experimental': [140], 'results': [141, 158], 'demonstrate': [142], 'that': [143, 159], 'proposed': [145, 161], 'method': [147], 'outperforms': [148], 'recent': [149], 'state-of-theart': [150], 'also': [154], 'reveal': [155], 'from': [156], 'superior': [164], 'multi-modal': [168], 'existing': [172]}",2019,"['Hypergraph', 'Computer science', 'Representation (politics)', 'Artificial intelligence', 'Theoretical computer science', 'Graph', 'Convolutional neural network', 'External Data Representation', 'ENCODE', 'Pattern recognition (psychology)', 'Data mining', 'Machine learning', 'Mathematics', 'Political science', 'Chemistry', 'Politics', 'Gene', 'Biochemistry', 'Law', 'Discrete mathematics']","In this paper, we present a hypergraph neural networks (HGNN) framework for data representation learning, which can encode high-order data correlation in a hypergraph structure. Confronting the challenges of learning representation for complex data in real practice, we propose to incorporate such data structure in a hypergraph, which is more flexible on data modeling, especially when dealing with complex data. In this method, a hyperedge convolution operation is designed to handle the data correlation during representation learning. In this way, traditional hypergraph learning procedure can be conducted using hyperedge convolution operations efficiently. HGNN is able to learn the hidden layer representation considering the high-order data structure, which is a general framework considering the complex data correlations. We have conducted experiments on citation network classification and visual object recognition tasks and compared HGNN with graph convolutional networks and other traditional methods. Experimental results demonstrate that the proposed HGNN method outperforms recent state-of-theart methods. We can also reveal from the results that the proposed HGNN is superior when dealing with multi-modal data compared with existing methods."
https://openalex.org/W2346062110,Convolutional Neural Networks for Medical Image Analysis: Full Training or Fine Tuning?,"{'Training': [0], 'a': [1, 14, 22, 37, 46, 101, 152, 164, 180, 214, 225], 'deep': [2, 91, 102, 140, 207], 'convolutional': [3], 'neural': [4], 'network': [5], '(CNN)': [6], 'from': [7, 104, 129, 143, 183, 200], 'scratch': [8, 144], 'is': [9, 34], 'difficult': [10], 'because': [11], 'it': [12], 'requires': [13], 'large': [15, 47], 'amount': [16, 241], 'of': [17, 25, 49, 82, 89, 139, 163, 194, 242], 'labeled': [18, 50], 'training': [19, 100, 195], 'data': [20], 'and': [21, 59, 122, 127, 134, 217], 'great': [23], 'deal': [24], 'expertise': [26], 'to': [27, 35, 73, 191, 228], 'ensure': [28], 'proper': [29], 'convergence.': [30], 'A': [31], 'promising': [32], 'alternative': [33], 'fine-tune': [36], 'CNN': [38, 103, 166, 181], 'that': [39, 159], 'has': [40], 'been': [41], 'pre-trained': [42, 90, 148, 165], 'using,': [43], 'for': [44, 99, 213, 233], 'instance,': [45], 'set': [48], 'natural': [51, 58], 'images.': [52], 'However,': [53], 'the': [54, 75, 80, 87, 97, 137, 147, 161, 173, 192, 210, 230, 234, 240], 'substantial': [55], 'differences': [56], 'between': [57], 'medical': [60, 83, 114], 'images': [61], 'may': [62], 'advise': [63], 'against': [64], 'such': [65], 'knowledge': [66], 'transfer.': [67], 'In': [68], 'this': [69, 108], 'paper,': [70], 'we': [71, 110], 'seek': [72], 'answer': [74], 'following': [76], 'central': [77], 'question': [78], 'in': [79, 117, 151, 172], 'context': [81], 'image': [84], 'analysis:': [85], 'Can': [86], 'use': [88, 162], 'CNNs': [92, 141, 149, 187, 198], 'with': [93, 146, 167], 'sufficient': [94], 'fine-tuning': [95, 169, 221], 'eliminate': [96], 'need': [98], 'scratch?': [105], 'To': [106], 'address': [107], 'question,': [109], 'considered': [111], 'four': [112], 'distinct': [113], 'imaging': [115, 132], 'applications': [116], 'three': [118, 130], 'specialties': [119], '(radiology,': [120], 'cardiology,': [121], 'gastroenterology)': [123], 'involving': [124], 'classification,': [125], 'detection,': [126], 'segmentation': [128], 'different': [131], 'modalities,': [133], 'investigated': [135], 'how': [136], 'performance': [138, 232], 'trained': [142, 182, 199], 'compared': [145], 'fine-tuned': [150, 186], 'layer-wise': [153, 220], 'manner.': [154], 'Our': [155], 'experiments': [156], 'consistently': [157], 'demonstrated': [158], '1)': [160], 'adequate': [168], 'outperformed': [170], 'or,': [171], 'worst': [174], 'case,': [175], 'performed': [176], 'as': [177, 179], 'well': [178], 'scratch;': [184, 201], '2)': [185], 'were': [188], 'more': [189], 'robust': [190], 'size': [193], 'sets': [196], 'than': [197], '3)': [202], 'neither': [203], 'shallow': [204], 'tuning': [205, 208], 'nor': [206], 'was': [209], 'optimal': [211], 'choice': [212], 'particular': [215], 'application;': [216], '4)': [218], 'our': [219], 'scheme': [222], 'could': [223], 'offer': [224], 'practical': [226], 'way': [227], 'reach': [229], 'best': [231], 'application': [235], 'at': [236], 'hand': [237], 'based': [238], 'on': [239], 'available': [243], 'data.': [244]}",2016,"['Convolutional neural network', 'Computer science', 'Artificial intelligence', 'Deep learning', 'Scratch', 'Fine-tuning', 'Medical imaging', 'Context (archaeology)', 'Contextual image classification', 'Segmentation', 'Pattern recognition (psychology)', 'Transfer of learning', 'Image (mathematics)', 'Image segmentation', 'Machine learning', 'Biology', 'Physics', 'Operating system', 'Paleontology', 'Quantum mechanics']","Training a deep convolutional neural network (CNN) from scratch is difficult because it requires a large amount of labeled training data and a great deal of expertise to ensure proper convergence. A promising alternative is to fine-tune a CNN that has been pre-trained using, for instance, a large set of labeled natural images. However, the substantial differences between natural and medical images may advise against such knowledge transfer. In this paper, we seek to answer the following central question in the context of medical image analysis: Can the use of pre-trained deep CNNs with sufficient fine-tuning eliminate the need for training a deep CNN from scratch? To address this question, we considered four distinct medical imaging applications in three specialties (radiology, cardiology, and gastroenterology) involving classification, detection, and segmentation from three different imaging modalities, and investigated how the performance of deep CNNs trained from scratch compared with the pre-trained CNNs fine-tuned in a layer-wise manner. Our experiments consistently demonstrated that 1) the use of a pre-trained CNN with adequate fine-tuning outperformed or, in the worst case, performed as well as a CNN trained from scratch; 2) fine-tuned CNNs were more robust to the size of training sets than CNNs trained from scratch; 3) neither shallow tuning nor deep tuning was the optimal choice for a particular application; and 4) our layer-wise fine-tuning scheme could offer a practical way to reach the best performance for the application at hand based on the amount of available data."
https://openalex.org/W2598457882,Deep Learning‐Based Crack Damage Detection Using Convolutional Neural Networks,"{'Abstract': [0], 'A': [1], 'number': [2], 'of': [3, 61, 77, 95, 107, 121, 160, 169, 209], 'image': [4, 97, 147], 'processing': [5], 'techniques': [6], '(IPTs)': [7], 'have': [8], 'been': [9], 'implemented': [10], 'for': [11, 82, 109, 184], 'detecting': [12, 83], 'civil': [13], 'infrastructure': [14], 'defects': [15], 'to': [16, 27, 30, 55, 57, 144, 205], 'partially': [17], 'replace': [18], 'human‐conducted': [19], 'onsite': [20], 'inspections.': [21], 'These': [22], 'IPTs': [23, 108], 'are': [24, 93, 164, 203], 'primarily': [25], 'used': [26, 183], 'manipulate': [28], 'images': [29, 120, 168], 'extract': [31], 'defect': [32, 89], 'features,': [33], 'such': [34], 'as': [35], 'cracks': [36, 85, 237], 'in': [37, 238], 'concrete': [38, 84, 236], 'and': [39, 50, 158, 186, 197, 216, 232], 'steel': [40], 'surfaces.': [41], 'However,': [42], 'the': [43, 58, 88, 100, 105, 161, 207, 210, 225], 'extensively': [44], 'varying': [45], 'real‐world': [46], 'situations': [47], '(e.g.,': [48, 192], 'lighting': [49], 'shadow': [51], 'changes)': [52], 'can': [53, 233], 'lead': [54], 'challenges': [56], 'wide': [59], 'adoption': [60], 'IPTs.': [62], 'To': [63], 'overcome': [64], 'these': [65], 'challenges,': [66], 'this': [67], 'article': [68], 'proposes': [69], 'a': [70, 74, 140, 177], 'vision‐based': [71], 'method': [72, 102, 227], 'using': [73, 213], 'deep': [75], 'architecture': [76], 'convolutional': [78], 'neural': [79], 'networks': [80], '(CNNs)': [81], 'without': [86, 104], 'calculating': [87], 'features.': [90, 111], 'As': [91], 'CNNs': [92], 'capable': [94], 'learning': [96], 'features': [98], 'automatically,': [99], 'proposed': [101, 162, 211, 226], 'works': [103], 'conjugation': [106], 'extracting': [110], 'The': [112, 134, 156, 221], 'designed': [113], 'CNN': [114, 136, 212], 'is': [115, 137, 181], 'trained': [116, 135], 'on': [117, 166], '40': [118], 'K': [119], '256': [122, 124, 151, 153], '×': [123, 152, 171], 'pixel': [125, 154, 173], 'resolutions': [126, 174], 'and,': [127], 'consequently,': [128], 'records': [129], 'with': [130, 139], 'about': [131], '98%': [132], 'accuracy.': [133], 'combined': [138], 'sliding': [141], 'window': [142], 'technique': [143], 'scan': [145], 'any': [146], 'size': [148], 'larger': [149], 'than': [150], 'resolutions.': [155], 'robustness': [157], 'adaptability': [159], 'approach': [163], 'tested': [165], '55': [167], '5,888': [170], '3,584': [172], 'taken': [175], 'from': [176], 'different': [178], 'structure': [179], 'which': [180], 'not': [182], 'training': [185], 'validation': [187], 'processes': [188], 'under': [189], 'various': [190], 'conditions': [191], 'strong': [193], 'light': [194], 'spot,': [195], 'shadows,': [196], 'very': [198], 'thin': [199], 'cracks).': [200], 'Comparative': [201], 'studies': [202], 'conducted': [204], 'examine': [206], 'performance': [208], 'traditional': [214], 'Canny': [215], 'Sobel': [217], 'edge': [218], 'detection': [219], 'methods.': [220], 'results': [222], 'show': [223], 'that': [224], 'shows': [228], 'quite': [229], 'better': [230], 'performances': [231], 'indeed': [234], 'find': [235], 'realistic': [239], 'situations.': [240]}",2017,"['Convolutional neural network', 'Sobel operator', 'Computer science', 'Artificial intelligence', 'Robustness (evolution)', 'Pixel', 'Computer vision', 'Canny edge detector', 'Shadow (psychology)', 'Deep learning', 'Pattern recognition (psychology)', 'Adaptability', 'Image (mathematics)', 'Edge detection', 'Image processing', 'Psychology', 'Chemistry', 'Biochemistry', 'Ecology', 'Psychotherapist', 'Biology', 'Gene']","Abstract A number of image processing techniques (IPTs) have been implemented for detecting civil infrastructure defects to partially replace human‐conducted onsite inspections. These IPTs are primarily used to manipulate images to extract defect features, such as cracks in concrete and steel surfaces. However, the extensively varying real‐world situations (e.g., lighting and shadow changes) can lead to challenges to the wide adoption of IPTs. To overcome these challenges, this article proposes a vision‐based method using a deep architecture of convolutional neural networks (CNNs) for detecting concrete cracks without calculating the defect features. As CNNs are capable of learning image features automatically, the proposed method works without the conjugation of IPTs for extracting features. The designed CNN is trained on 40 K images of 256 × 256 pixel resolutions and, consequently, records with about 98% accuracy. The trained CNN is combined with a sliding window technique to scan any image size larger than 256 × 256 pixel resolutions. The robustness and adaptability of the proposed approach are tested on 55 images of 5,888 × 3,584 pixel resolutions taken from a different structure which is not used for training and validation processes under various conditions (e.g., strong light spot, shadows, and very thin cracks). Comparative studies are conducted to examine the performance of the proposed CNN using traditional Canny and Sobel edge detection methods. The results show that the proposed method shows quite better performances and can indeed find concrete cracks in realistic situations."
https://openalex.org/W2914721378,Graph Neural Networks for Social Recommendation,"{'In': [0, 128], 'recent': [1], 'years,': [2], 'Graph': [3], 'Neural': [4], 'Networks': [5], '(GNNs),': [6], 'which': [7, 150], 'can': [8, 44], 'naturally': [9], 'integrate': [10], 'node': [11], 'information': [12], 'and': [13, 51, 54, 60, 83, 102, 139, 145, 155], 'topological': [14], 'structure,': [15], 'have': [16, 89], 'been': [17], 'demonstrated': [18], 'to': [19, 34, 135], 'be': [20, 45], 'powerful': [21], 'in': [22, 40, 94, 113, 141], 'learning': [23, 55], 'on': [24, 71, 160], 'graph': [25, 50, 79, 101, 120, 144], 'data.': [26], 'These': [27], 'advantages': [28], 'of': [29, 58, 167], 'GNNs': [30, 72], 'provide': [31, 131], 'great': [32], 'potential': [33], 'advance': [35], 'social': [36, 41, 49, 67, 87, 100, 126], 'recommendation': [37], 'since': [38], 'data': [39], 'recommender': [42, 68], 'systems': [43, 69], 'represented': [46], 'as': [47], 'user-user': [48, 99], 'user-item': [52, 78, 104, 143], 'graph;': [53], 'latent': [56], 'factors': [57], 'users': [59, 92], 'items': [61], 'is': [62], 'the': [63, 77, 98, 103, 108, 142, 147, 165, 168], 'key.': [64], 'However,': [65], 'building': [66], 'based': [70], 'faces': [73], 'challenges.': [74], 'For': [75], 'example,': [76], 'encodes': [80], 'both': [81], 'interactions': [82, 138], 'their': [84], 'associated': [85], 'opinions;': [86], 'relations': [88], 'heterogeneous': [90, 156], 'strengths;': [91], 'involve': [93], 'two': [95, 153, 161], 'graphs': [96, 154], '(e.g.,': [97], 'graph).': [105], 'To': [106], 'address': [107], 'three': [109], 'aforementioned': [110], 'challenges': [111], 'simultaneously,': [112], 'this': [114], 'paper,': [115], 'we': [116, 130], 'present': [117], 'a': [118, 132], 'novel': [119], 'neural': [121], 'network': [122], 'framework': [123, 148, 170], '(GraphRec)': [124], 'for': [125], 'recommendations.': [127], 'particular,': [129], 'principled': [133], 'approach': [134], 'jointly': [136], 'capture': [137], 'opinions': [140], 'propose': [146], 'GraphRec,': [149], 'coherently': [151], 'models': [152], 'strengths.': [157], 'Extensive': [158], 'experiments': [159], 'real-world': [162], 'datasets': [163], 'demonstrate': [164], 'effectiveness': [166], 'proposed': [169], 'GraphRec.': [171]}",2019,"['Computer science', 'Recommender system', 'Social graph', 'Graph', 'Graph database', 'Theoretical computer science', 'Artificial intelligence', 'Machine learning', 'Information retrieval', 'Data science', 'World Wide Web', 'Social media']","In recent years, Graph Neural Networks (GNNs), which can naturally integrate node information and topological structure, have been demonstrated to be powerful in learning on graph data. These advantages of GNNs provide great potential to advance social recommendation since data in social recommender systems can be represented as user-user social graph and user-item graph; and learning latent factors of users and items is the key. However, building social recommender systems based on GNNs faces challenges. For example, the user-item graph encodes both interactions and their associated opinions; social relations have heterogeneous strengths; users involve in two graphs (e.g., the user-user social graph and the user-item graph). To address the three aforementioned challenges simultaneously, in this paper, we present a novel graph neural network framework (GraphRec) for social recommendations. In particular, we provide a principled approach to jointly capture interactions and opinions in the user-item graph and propose the framework GraphRec, which coherently models two graphs and heterogeneous strengths. Extensive experiments on two real-world datasets demonstrate the effectiveness of the proposed framework GraphRec."
https://openalex.org/W2524428287,Quantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations,"{'We': [0, 68], 'introduce': [1], 'a': [2, 58, 153], 'method': [3], 'to': [4, 64, 86, 113, 164], 'train': [5], 'Quantized': [6, 125], 'Neural': [7], 'Networks': [8], '(QNNs)': [9], '---': [10], 'neural': [11, 127], 'networks': [12, 128], 'with': [13, 54, 97, 159, 173], 'extremely': [14], 'low': [15], 'precision': [16], '(e.g.,': [17], '1-bit)': [18], 'weights': [19, 28, 99], 'and': [20, 29, 47, 49, 76, 100, 136], 'activations,': [21], 'at': [22], 'run-time.': [23], 'At': [24], 'train-time': [25], 'the': [26, 35, 39, 72, 110, 132], 'quantized': [27, 93], 'activations': [30, 102], 'are': [31], 'used': [32], 'for': [33], 'computing': [34], 'parameter': [36, 111], 'gradients.': [37], 'During': [38], 'forward': [40], 'pass,': [41], 'QNNs': [42, 70, 81], 'drastically': [43, 66], 'reduce': [44], 'memory': [45], 'size': [46], 'accesses,': [48], 'replace': [50], 'most': [51], 'arithmetic': [52], 'operations': [53], 'bit-wise': [55, 123], 'operations.': [56], 'As': [57], 'result,': [59], 'power': [60], 'consumption': [61], 'is': [62, 162, 188], 'expected': [63], 'be': [65], 'reduced.': [67], 'trained': [69], 'over': [71, 131], 'MNIST,': [73], 'CIFAR-10,': [74], 'SVHN': [75], 'ImageNet': [77], 'datasets.': [78], 'The': [79, 185], 'resulting': [80], 'achieve': [82], 'prediction': [83], 'accuracy': [84, 139], 'comparable': [85, 138], 'their': [87, 141], '32-bit': [88, 142], 'counterparts.': [89], 'For': [90], 'example,': [91], 'our': [92, 166], 'version': [94], 'of': [95], 'AlexNet': [96], '1-bit': [98], '2-bit': [101], 'achieves': [103], '$51\\%$': [104], 'top-1': [105], 'accuracy.': [106, 184], 'Moreover,': [107], 'we': [108, 151], 'quantize': [109], 'gradients': [112, 119], '6-bits': [114], 'as': [115, 140], 'well': [116], 'which': [117, 160], 'enables': [118], 'computation': [120], 'using': [121, 144], 'only': [122, 145], 'operation.': [124], 'recurrent': [126], 'were': [129], 'tested': [130], 'Penn': [133], 'Treebank': [134], 'dataset,': [135], 'achieved': [137], 'counterparts': [143], '4-bits.': [146], 'Last': [147], 'but': [148], 'not': [149], 'least,': [150], 'programmed': [152], 'binary': [154], 'matrix': [155], 'multiplication': [156], 'GPU': [157, 176], 'kernel': [158], 'it': [161], 'possible': [163], 'run': [165], 'MNIST': [167], 'QNN': [168, 186], '7': [169], 'times': [170], 'faster': [171], 'than': [172], 'an': [174], 'unoptimized': [175], 'kernel,': [177], 'without': [178], 'suffering': [179], 'any': [180], 'loss': [181], 'in': [182], 'classification': [183], 'code': [187], 'available': [189], 'online.': [190]}",2016,"['Artificial neural network', 'Computer science', 'Artificial intelligence', 'Training (meteorology)', 'Deep neural networks', 'Machine learning', 'Pattern recognition (psychology)', 'Physics', 'Meteorology']","We introduce a method to train Quantized Neural Networks (QNNs) --- neural networks with extremely low precision (e.g., 1-bit) weights and activations, at run-time. At train-time the quantized weights and activations are used for computing the parameter gradients. During the forward pass, QNNs drastically reduce memory size and accesses, and replace most arithmetic operations with bit-wise operations. As a result, power consumption is expected to be drastically reduced. We trained QNNs over the MNIST, CIFAR-10, SVHN and ImageNet datasets. The resulting QNNs achieve prediction accuracy comparable to their 32-bit counterparts. For example, our quantized version of AlexNet with 1-bit weights and 2-bit activations achieves $51\%$ top-1 accuracy. Moreover, we quantize the parameter gradients to 6-bits as well which enables gradients computation using only bit-wise operation. Quantized recurrent neural networks were tested over the Penn Treebank dataset, and achieved comparable accuracy as their 32-bit counterparts using only 4-bits. Last but not least, we programmed a binary matrix multiplication GPU kernel with which it is possible to run our MNIST QNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy. The QNN code is available online."
https://openalex.org/W1598796236,A Critical Review of Recurrent Neural Networks for Sequence Learning,"{'Countless': [0], 'learning': [1, 136, 192], 'tasks': [2, 158], 'require': [3, 16], 'dealing': [4], 'with': [5, 137, 217], 'sequential': [6], 'data.': [7], 'Image': [8], 'captioning,': [9, 163], 'speech': [10], 'synthesis,': [11], 'and': [12, 35, 58, 116, 129, 149, 166, 174, 186, 200, 221], 'music': [13], 'generation': [14], 'all': [15], 'that': [17, 22, 45, 73, 96, 178], 'a': [18, 39, 60, 94, 207, 218], 'model': [19, 40], 'produce': [20], 'outputs': [21], 'are': [23, 46, 70], 'sequences.': [24, 47], 'In': [25, 139, 169], 'other': [26], 'domains,': [27], 'such': [28, 50], 'as': [29, 51, 159, 161], 'time': [30], 'series': [31], 'prediction,': [32], 'video': [33], 'analysis,': [34], 'musical': [36], 'information': [37, 99], 'retrieval,': [38], 'must': [41], 'learn': [42], 'from': [43, 100], 'inputs': [44], 'Interactive': [48], 'tasks,': [49], 'translating': [52], 'natural': [53], 'language,': [54], 'engaging': [55], 'in': [56, 81, 124], 'dialogue,': [57], 'controlling': [59], 'robot,': [61], 'often': [62, 117], 'demand': [63], 'both': [64], 'capabilities.': [65], 'Recurrent': [66], 'neural': [67, 89, 108], 'networks': [68, 92, 109], '(RNNs)': [69], 'connectionist': [71], 'models': [72], 'capture': [74], 'the': [75, 82, 176, 180, 211, 214], 'dynamics': [76], 'of': [77, 84, 120, 210, 213], 'sequences': [78], 'via': [79], 'cycles': [80], 'network': [83, 125], 'nodes.': [85], 'Unlike': [86], 'standard': [87], 'feedforward': [88], 'networks,': [90], 'recurrent': [91, 107], 'retain': [93], 'state': [95, 212], 'can': [97], 'represent': [98], 'an': [101], 'arbitrarily': [102], 'long': [103, 145], 'context': [104], 'window.': [105], 'Although': [106], 'have': [110, 132, 153], 'traditionally': [111], 'been': [112], 'difficult': [113], 'to': [114, 205, 223], 'train,': [115], 'contain': [118], 'millions': [119], 'parameters,': [121], 'recent': [122, 140], 'advances': [123], 'architectures,': [126], 'optimization': [127], 'techniques,': [128], 'parallel': [130], 'computation': [131], 'enabled': [133], 'successful': [134], 'large-scale': [135], 'them.': [138], 'years,': [141], 'systems': [142], 'based': [143], 'on': [144, 157], 'short-term': [146], 'memory': [147], '(LSTM)': [148], 'bidirectional': [150], '(BRNN)': [151], 'architectures': [152], 'demonstrated': [154], 'ground-breaking': [155], 'performance': [156], 'varied': [160], 'image': [162], 'language': [164], 'translation,': [165], 'handwriting': [167], 'recognition.': [168], 'this': [170], 'survey,': [171], 'we': [172, 196], 'review': [173], 'synthesize': [175], 'research': [177], 'over': [179], 'past': [181], 'three': [182], 'decades': [183], 'first': [184], 'yielded': [185], 'then': [187], 'made': [188], 'practical': [189], 'these': [190], 'powerful': [191], 'models.': [193], 'When': [194], 'appropriate,': [195], 'reconcile': [197], 'conflicting': [198], 'notation': [199], 'nomenclature.': [201], 'Our': [202], 'goal': [203], 'is': [204], 'provide': [206], 'self-contained': [208], 'explication': [209], 'art': [215], 'together': [216], 'historical': [219], 'perspective': [220], 'references': [222], 'primary': [224], 'research.': [225]}",2015,"['Computer science', 'Recurrent neural network', 'Closed captioning', 'Artificial intelligence', 'Connectionism', 'Context (archaeology)', 'Language model', 'Deep learning', 'Artificial neural network', 'Natural language', 'Machine learning', 'Biology', 'Image (mathematics)', 'Paleontology']","Countless learning tasks require dealing with sequential data. Image captioning, speech synthesis, and music generation all require that a model produce outputs that are sequences. In other domains, such as time series prediction, video analysis, and musical information retrieval, a model must learn from inputs that are sequences. Interactive tasks, such as translating natural language, engaging in dialogue, and controlling a robot, often demand both capabilities. Recurrent neural networks (RNNs) are connectionist models that capture the dynamics of sequences via cycles in the network of nodes. Unlike standard feedforward neural networks, recurrent networks retain a state that can represent information from an arbitrarily long context window. Although recurrent neural networks have traditionally been difficult to train, and often contain millions of parameters, recent advances in network architectures, optimization techniques, and parallel computation have enabled successful large-scale learning with them. In recent years, systems based on long short-term memory (LSTM) and bidirectional (BRNN) architectures have demonstrated ground-breaking performance on tasks as varied as image captioning, language translation, and handwriting recognition. In this survey, we review and synthesize the research that over the past three decades first yielded and then made practical these powerful learning models. When appropriate, we reconcile conflicting notation and nomenclature. Our goal is to provide a self-contained explication of the state of the art together with a historical perspective and references to primary research."
https://openalex.org/W2604662567,DeepFM: A Factorization-Machine based Neural Network for CTR Prediction,"{'Learning': [0], 'sophisticated': [1], 'feature': [2, 34, 57, 75, 108], 'interactions': [3], 'behind': [4], 'user': [5], 'behaviors': [6], 'is': [7, 43], 'critical': [8], 'in': [9, 77], 'maximizing': [10], 'CTR': [11, 130], 'for': [12, 69, 74, 129], 'recommender': [13], 'systems.': [14], 'Despite': [15], 'great': [16], 'progress,': [17], 'existing': [18, 127], 'methods': [19], 'seem': [20], 'to': [21, 45, 84, 98, 117], 'have': [22], 'a': [23, 78, 95], 'strong': [24], 'bias': [25], 'towards': [26], 'low-': [27, 54], 'or': [28, 31], 'high-order': [29, 56], 'interactions,': [30], 'require': [32], 'expertise': [33], 'engineering.': [35], 'In': [36], 'this': [37], 'paper,': [38], 'we': [39], 'show': [40], 'that': [41, 51], 'it': [42], 'possible': [44], 'derive': [46], 'an': [47], 'end-to-end': [48], 'learning': [49, 73, 76], 'model': [50, 90], 'emphasizes': [52], 'both': [53, 133], 'and': [55, 71, 101, 121, 136], 'interactions.': [58], 'The': [59], 'proposed': [60], 'model,': [61], 'DeepFM,': [62], 'combines': [63], 'the': [64, 85, 119, 126], 'power': [65], 'of': [66, 107, 123], 'factorization': [67], 'machines': [68], 'recommendation': [70], 'deep': [72], 'new': [79], 'neural': [80], 'network': [81], 'architecture.': [82], 'Compared': [83], 'latest': [86], 'Wide': [87], '&amp;': [88], 'Deep': [89], 'from': [91], 'Google,': [92], 'DeepFM': [93, 124], 'has': [94], 'shared': [96], 'input': [97], 'its': [99], '""wide""': [100], '""deep""': [102], 'parts,': [103], 'with': [104], 'no': [105], 'need': [106], 'engineering': [109], 'besides': [110], 'raw': [111], 'features.': [112], 'Comprehensive': [113], 'experiments': [114], 'are': [115], 'conducted': [116], 'demonstrate': [118], 'effectiveness': [120], 'efficiency': [122], 'over': [125], 'models': [128], 'prediction,': [131], 'on': [132], 'benchmark': [134], 'data': [135], 'commercial': [137], 'data.': [138]}",2017,"['Feature engineering', 'Computer science', 'Benchmark (surveying)', 'Feature (linguistics)', 'Artificial intelligence', 'Deep learning', 'Machine learning', 'Recommender system', 'Artificial neural network', 'Deep neural networks', 'Factorization', 'Feature learning', 'Raw data', 'Algorithm', 'Linguistics', 'Geodesy', 'Programming language', 'Geography', 'Philosophy']","Learning sophisticated feature interactions behind user behaviors is critical in maximizing CTR for recommender systems. Despite great progress, existing methods seem to have a strong bias towards low- or high-order interactions, or require expertise feature engineering. In this paper, we show that it is possible to derive an end-to-end learning model that emphasizes both low- and high-order feature interactions. The proposed model, DeepFM, combines the power of factorization machines for recommendation and deep learning for feature learning in a new neural network architecture. Compared to the latest Wide &amp; Deep model from Google, DeepFM has a shared input to its ""wide"" and ""deep"" parts, with no need of feature engineering besides raw features. Comprehensive experiments are conducted to demonstrate the effectiveness and efficiency of DeepFM over the existing models for CTR prediction, on both benchmark data and commercial data."
https://openalex.org/W2965857891,Heterogeneous Graph Neural Network,"{'Representation': [0], 'learning': [1], 'in': [2, 247, 263], 'heterogeneous': [3, 43, 63, 105, 112, 126, 153, 192], 'graphs': [4], 'aims': [5], 'to': [6, 17, 41, 58, 84, 131, 145, 175, 224, 243], 'pursue': [7], 'a': [8, 76, 125, 139, 147, 168, 233, 238], 'meaningful': [9], 'vector': [10], 'representation': [11], 'for': [12, 61, 155, 198], 'each': [13, 73, 116, 156, 199], 'node': [14, 27, 117, 157, 163, 228, 272, 278], 'so': [15], 'as': [16, 22, 93, 95, 109, 111], 'facilitate': [18], 'downstream': [19], 'applications': [20], 'such': [21], 'link': [23, 269], 'prediction,': [24, 270], 'personalized': [25], 'recommendation,': [26, 271], 'classification,': [28], 'etc.': [29], 'This': [30], 'task,': [31], 'however,': [32], 'is': [33], 'challenging': [34], 'not': [35], 'only': [36], 'because': [37], 'of': [38, 48, 51, 79, 100, 115, 150, 179, 191, 208, 221], 'the': [39, 59, 219, 226, 245], 'demand': [40], 'incorporate': [42], 'structural': [44, 106], '(graph)': [45, 107], 'information': [46, 108, 114, 178], 'consisting': [47], 'multiple': [49], 'types': [50], 'nodes': [52], 'and': [53, 158, 194, 213, 237, 276], 'edges,': [54], 'but': [55], 'also': [56], 'due': [57], 'need': [60], 'considering': [62, 218], 'attributes': [64], 'or': [65, 69], 'contents': [66, 113, 193], '(e.g.,': [67], 'text': [68], 'image)': [70], 'associated': [71], 'with': [72, 142, 172], 'node.': [74, 200], 'Despite': [75], 'substantial': [77], 'amount': [78], 'effort': [80], 'has': [81], 'been': [82], 'made': [83], 'homogeneous': [85], '(or': [86], 'heterogeneous)': [87], 'graph': [88, 91, 96, 127, 234, 265], 'embedding,': [89], 'attributed': [90], 'embedding': [92, 197], 'well': [94, 110], 'neural': [97, 128, 169], 'networks,': [98], 'few': [99], 'them': [101, 160, 216], 'can': [102, 259], 'jointly': [103], 'consider': [104], 'effectively.': [118], 'In': [119], 'this': [120, 133], 'paper,': [121], 'we': [122, 136, 166, 231], 'propose': [123], 'HetGNN,': [124], 'network': [129, 170], 'model,': [130], 'resolve': [132], 'issue.': [134], 'Specifically,': [135], 'first': [137, 185], 'introduce': [138], 'random': [140], 'walk': [141], 'restart': [143], 'strategy': [144], 'sample': [146], 'fixed': [148], 'size': [149], 'strongly': [151], 'correlated': [152], 'neighbors': [154], 'group': [159], 'based': [161], 'upon': [162], 'types.': [164], 'Next,': [165], 'design': [167], 'architecture': [171], 'two': [173], 'modules': [174], 'aggregate': [176], 'feature': [177, 189], 'those': [180], 'sampled': [181], 'neighboring': [182, 210], 'nodes.': [183], 'The': [184, 201], 'module': [186, 203], 'encodes': [187], '""deep""': [188], 'interactions': [190], 'generates': [195], 'content': [196, 205], 'second': [202], 'aggregates': [204], '(attribute)': [206], 'embeddings': [207], 'different': [209, 222], 'groups': [211, 223], '(types)': [212], 'further': [214], 'combines': [215], 'by': [217], 'impacts': [220], 'obtain': [225], 'ultimate': [227], 'embedding.': [229], 'Finally,': [230], 'leverage': [232], 'context': [235], 'loss': [236], 'mini-batch': [239], 'gradient': [240], 'descent': [241], 'procedure': [242], 'train': [244], 'model': [246], 'an': [248], 'end-to-end': [249], 'manner.': [250], 'Extensive': [251], 'experiments': [252], 'on': [253], 'several': [254], 'datasets': [255], 'demonstrate': [256], 'that': [257], 'HetGNN': [258], 'outperform': [260], 'state-of-the-art': [261], 'baselines': [262], 'various': [264], 'mining': [266], 'tasks,': [267], 'i.e.,': [268], 'classification': [273, 279], '&': [274, 280], 'clustering': [275], 'inductive': [277], 'clustering.': [281]}",2019,"['Computer science', 'Theoretical computer science', 'Stochastic gradient descent', 'Graph embedding', 'Embedding', 'Graph', 'Feature learning', 'Heterogeneous network', 'Leverage (statistics)', 'Node (physics)', 'Artificial neural network', 'Artificial intelligence', 'Telecommunications', 'Structural engineering', 'Engineering', 'Wireless network', 'Wireless']","Representation learning in heterogeneous graphs aims to pursue a meaningful vector representation for each node so as to facilitate downstream applications such as link prediction, personalized recommendation, node classification, etc. This task, however, is challenging not only because of the demand to incorporate heterogeneous structural (graph) information consisting of multiple types of nodes and edges, but also due to the need for considering heterogeneous attributes or contents (e.g., text or image) associated with each node. Despite a substantial amount of effort has been made to homogeneous (or heterogeneous) graph embedding, attributed graph embedding as well as graph neural networks, few of them can jointly consider heterogeneous structural (graph) information as well as heterogeneous contents information of each node effectively. In this paper, we propose HetGNN, a heterogeneous graph neural network model, to resolve this issue. Specifically, we first introduce a random walk with restart strategy to sample a fixed size of strongly correlated heterogeneous neighbors for each node and group them based upon node types. Next, we design a neural network architecture with two modules to aggregate feature information of those sampled neighboring nodes. The first module encodes ""deep"" feature interactions of heterogeneous contents and generates content embedding for each node. The second module aggregates content (attribute) embeddings of different neighboring groups (types) and further combines them by considering the impacts of different groups to obtain the ultimate node embedding. Finally, we leverage a graph context loss and a mini-batch gradient descent procedure to train the model in an end-to-end manner. Extensive experiments on several datasets demonstrate that HetGNN can outperform state-of-the-art baselines in various graph mining tasks, i.e., link prediction, recommendation, node classification & clustering and inductive node classification & clustering."
https://openalex.org/W2419175238,Solving the quantum many-body problem with artificial neural networks,"{'Machine': [0], 'learning': [1, 47], 'and': [2, 40], 'quantum': [3, 9, 55, 93], 'physics': [4], 'Elucidating': [5], 'the': [6, 18, 32, 43, 54, 59, 92], 'behavior': [7], 'of': [8, 12, 17, 31, 45], 'interacting': [10], 'systems': [11], 'many': [13], 'particles': [14], 'remains': [15], 'one': [16], 'biggest': [19], 'challenges': [20], 'in': [21, 91], 'physics.': [22], 'Traditional': [23], 'numerical': [24], 'methods': [25], 'often': [26], 'work': [27], 'well,': [28], 'but': [29], 'some': [30], 'most': [33], 'interesting': [34], 'problems': [35], 'leave': [36], 'them': [37], 'stumped.': [38], 'Carleo': [39], 'Troyer': [41], 'harnessed': [42], 'power': [44], 'machine': [46], 'to': [48, 53], 'develop': [49], 'a': [50, 74, 77, 88], 'variational': [51], 'approach': [52], 'many-body': [56], 'problem': [57], '(see': [58], 'Perspective': [60], 'by': [61], 'Hush).': [62], 'The': [63], 'method': [64], 'performed': [65], 'at': [66], 'least': [67], 'as': [68, 70], 'well': [69, 86], 'state-of-the-art': [71], 'approaches,': [72], 'setting': [73], 'benchmark': [75], 'for': [76], 'prototypical': [78], 'two-dimensional': [79], 'problem.': [80], 'With': [81], 'further': [82], 'development,': [83], 'it': [84], 'may': [85], 'prove': [87], 'valuable': [89], 'piece': [90], 'toolbox.': [94], 'Science': [95], ',': [96], 'this': [97], 'issue': [98], 'p.': [99, 104], '602': [100], ';': [101], 'see': [102], 'also': [103], '580': [105]}",2017,"['Unitary state', 'Quantum', 'Quantum machine learning', 'Computer science', 'Artificial neural network', 'Reinforcement learning', 'Wave function', 'Spins', 'Representation (politics)', 'Function (biology)', 'Hidden variable theory', 'Quantum state', 'Statistical physics', 'Theoretical computer science', 'Quantum computer', 'Artificial intelligence', 'Physics', 'Quantum mechanics', 'Politics', 'Biology', 'Evolutionary biology', 'Condensed matter physics', 'Political science', 'Law']","Machine learning and quantum physics Elucidating the behavior of quantum interacting systems of many particles remains one of the biggest challenges in physics. Traditional numerical methods often work well, but some of the most interesting problems leave them stumped. Carleo and Troyer harnessed the power of machine learning to develop a variational approach to the quantum many-body problem (see the Perspective by Hush). The method performed at least as well as state-of-the-art approaches, setting a benchmark for a prototypical two-dimensional problem. With further development, it may well prove a valuable piece in the quantum toolbox. Science , this issue p. 602 ; see also p. 580"
https://openalex.org/W2250861254,A Fast and Accurate Dependency Parser using Neural Networks,"{'Almost': [0], 'all': [1], 'current': [2], 'dependency': [3, 48], 'parsers': [4], 'classify': [5], 'based': [6], 'on': [7, 79, 102], 'millions': [8], 'of': [9, 22, 36, 59], 'sparse': [10], 'indicator': [11], 'features.Not': [12], 'only': [13], 'do': [14], 'these': [15], 'features': [16], 'generalize': [17], 'poorly,': [18], 'but': [19], 'the': [20, 103], 'cost': [21], 'feature': [23], 'computation': [24], 'restricts': [25], 'parsing': [26], 'speed': [27], 'significantly.In': [28], 'this': [29, 50], 'work,': [30], 'we': [31], 'propose': [32], 'a': [33, 38, 45, 56], 'novel': [34], 'way': [35], 'learning': [37], 'neural': [39], 'network': [40], 'classifier': [41, 51], 'for': [42], 'use': [43], 'in': [44, 73], 'greedy,': [46], 'transition-based': [47], 'parser.Because': [49], 'learns': [52], 'and': [53, 75, 82], 'uses': [54], 'just': [55], 'small': [57], 'number': [58], 'dense': [60], 'features,': [61], 'it': [62], 'can': [63], 'work': [64], 'very': [65], 'fast,': [66], 'while': [67], 'achieving': [68], 'an': [69], 'about': [70], '2%': [71], 'improvement': [72], 'unlabeled': [74, 99], 'labeled': [76], 'attachment': [77, 100], 'scores': [78], 'both': [80], 'English': [81, 104], 'Chinese': [83], 'datasets.Concretely,': [84], 'our': [85], 'parser': [86], 'is': [87], 'able': [88], 'to': [89], 'parse': [90], 'more': [91], 'than': [92], '1000': [93], 'sentences': [94], 'per': [95], 'second': [96], 'at': [97], '92.2%': [98], 'score': [101], 'Penn': [105], 'Treebank.': [106]}",2014,"['Computer science', 'Parsing', 'Dependency (UML)', 'Dependency grammar', 'Artificial intelligence', 'Natural language processing', 'Artificial neural network', 'Speech recognition']","Almost all current dependency parsers classify based on millions of sparse indicator features.Not only do these features generalize poorly, but the cost of feature computation restricts parsing speed significantly.In this work, we propose a novel way of learning a neural network classifier for use in a greedy, transition-based dependency parser.Because this classifier learns and uses just a small number of dense features, it can work very fast, while achieving an about 2% improvement in unlabeled and labeled attachment scores on both English and Chinese datasets.Concretely, our parser is able to parse more than 1000 sentences per second at 92.2% unlabeled attachment score on the English Penn Treebank."
https://openalex.org/W2270470215,Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition,"{'Human': [0], 'activity': [1, 75, 133], 'recognition': [2, 76, 134], '(HAR)': [3], 'tasks': [4], 'have': [5], 'traditionally': [6], 'been': [7, 128], 'solved': [8], 'using': [9], 'engineered': [10], 'features': [11], 'obtained': [12], 'by': [13, 151, 162], 'heuristic': [14], 'processes.': [15], 'Current': [16], 'research': [17], 'suggests': [18], 'that': [19, 139, 169], 'deep': [20, 72, 144], 'convolutional': [21, 79], 'neural': [22, 62], 'networks': [23, 63, 146], 'are': [24, 37], 'suited': [25], 'to': [26, 164, 175, 185, 196], 'automate': [27], 'feature': [28, 115], 'extraction': [29], 'from': [30], 'raw': [31], 'sensor': [32, 95, 177], 'inputs.': [33], 'However,': [34], 'human': [35], 'activities': [36], 'made': [38], 'of': [39, 42, 60, 114, 125, 157], 'complex': [40], 'sequences': [41], 'motor': [43], 'movements,': [44], 'and': [45, 80, 107], 'capturing': [46], 'this': [47], 'temporal': [48, 112], 'dynamics': [49, 113], 'is': [50, 86], 'fundamental': [51], 'for': [52, 64, 74, 88], 'successful': [53], 'HAR.': [54], 'Based': [55], 'on': [56, 78, 121, 147, 153, 194], 'the': [57, 111, 148, 158, 170], 'recent': [58], 'success': [59], 'recurrent': [61, 82], 'time': [65], 'series': [66], 'domains,': [67], 'we': [68], 'propose': [69], 'a': [70, 131], 'generic': [71], 'framework': [73, 120, 141, 171], 'based': [77], 'LSTM': [81], 'units,': [83], 'which:': [84], '(i)': [85], 'suitable': [87], 'multimodal': [89, 183], 'wearable': [90], 'sensors;': [91], '(ii)': [92], 'can': [93, 172, 180], 'perform': [94], 'fusion': [96], 'naturally;': [97], '(iii)': [98], 'does': [99], 'not': [100], 'require': [101], 'expert': [102], 'knowledge': [103], 'in': [104, 130], 'designing': [105], 'features;': [106], '(iv)': [108], 'explicitly': [109], 'models': [110], 'activations.': [116], 'We': [117, 188], 'evaluate': [118], 'our': [119, 140], 'two': [122], 'datasets,': [123], 'one': [124], 'which': [126], 'has': [127], 'used': [129], 'public': [132], 'challenge.': [135], 'Our': [136, 166], 'results': [137, 161, 167], 'show': [138, 168], 'outperforms': [142], 'competing': [143], 'non-recurrent': [145], 'challenge': [149], 'dataset': [150], '4%': [152], 'average;': [154], 'outperforming': [155], 'some': [156], 'previous': [159], 'reported': [160], 'up': [163], '9%.': [165], 'be': [173], 'applied': [174], 'homogeneous': [176], 'modalities,': [178], 'but': [179], 'also': [181], 'fuse': [182], 'sensors': [184], 'improve': [186], 'performance.': [187], 'characterise': [189], 'key': [190], 'architectural': [191], 'hyperparameters’': [192], 'influence': [193], 'performance': [195], 'provide': [197], 'insights': [198], 'about': [199], 'their': [200], 'optimisation.': [201]}",2016,"['Convolutional neural network', 'Computer science', 'Wearable computer', 'Deep learning', 'Recurrent neural network', 'Artificial intelligence', 'Activity recognition', 'Speech recognition', 'Pattern recognition (psychology)', 'Artificial neural network', 'Embedded system']","Human activity recognition (HAR) tasks have traditionally been solved using engineered features obtained by heuristic processes. Current research suggests that deep convolutional neural networks are suited to automate feature extraction from raw sensor inputs. However, human activities are made of complex sequences of motor movements, and capturing this temporal dynamics is fundamental for successful HAR. Based on the recent success of recurrent neural networks for time series domains, we propose a generic deep framework for activity recognition based on convolutional and LSTM recurrent units, which: (i) is suitable for multimodal wearable sensors; (ii) can perform sensor fusion naturally; (iii) does not require expert knowledge in designing features; and (iv) explicitly models the temporal dynamics of feature activations. We evaluate our framework on two datasets, one of which has been used in a public activity recognition challenge. Our results show that our framework outperforms competing deep non-recurrent networks on the challenge dataset by 4% on average; outperforming some of the previous reported results by up to 9%. Our results show that the framework can be applied to homogeneous sensor modalities, but can also fuse multimodal sensors to improve performance. We characterise key architectural hyperparameters’ influence on performance to provide insights about their optimisation."
https://openalex.org/W2953318193,Pixel Recurrent Neural Networks,"{'Modeling': [0], 'the': [1, 36, 42, 49, 53, 59, 65, 97, 101, 110, 117], 'distribution': [2], 'of': [3, 52, 62, 78, 100], 'natural': [4, 90], 'images': [5, 91], 'is': [6, 20], 'a': [7, 29], 'landmark': [8], 'problem': [9], 'in': [10, 38, 64, 81], 'unsupervised': [11], 'learning.': [12], 'This': [13], 'task': [14], 'requires': [15], 'an': [16, 39, 75], 'image': [17, 40], 'model': [18, 118], 'that': [19, 33, 92], 'at': [21], 'once': [22], 'expressive,': [23], 'tractable': [24], 'and': [25, 57, 74, 122], 'scalable.': [26], 'We': [27, 85], 'present': [28], 'deep': [30, 82], 'neural': [31], 'network': [32], 'sequentially': [34], 'predicts': [35], 'pixels': [37], 'along': [41], 'two': [43], 'spatial': [44], 'dimensions.': [45], 'Our': [46, 103], 'method': [47], 'models': [48], 'discrete': [50], 'probability': [51], 'raw': [54], 'pixel': [55], 'values': [56], 'encodes': [58], 'complete': [60], 'set': [61], 'dependencies': [63], 'image.': [66], 'Architectural': [67], 'novelties': [68], 'include': [69], 'fast': [70], 'two-dimensional': [71], 'recurrent': [72, 83], 'layers': [73], 'effective': [76], 'use': [77], 'residual': [79], 'connections': [80], 'networks.': [84], 'achieve': [86], 'log-likelihood': [87], 'scores': [88], 'on': [89, 109], 'are': [93], 'considerably': [94], 'better': [95], 'than': [96], 'previous': [98], 'state': [99], 'art.': [102], 'main': [104], 'results': [105], 'also': [106], 'provide': [107], 'benchmarks': [108], 'diverse': [111], 'ImageNet': [112], 'dataset.': [113], 'Samples': [114], 'generated': [115], 'from': [116], 'appear': [119], 'crisp,': [120], 'varied': [121], 'globally': [123], 'coherent.': [124]}",2016,"['Pixel', 'Computer science', 'Landmark', 'Artificial intelligence', 'Image (mathematics)', 'Scalability', 'Residual', 'Set (abstract data type)', 'Pattern recognition (psychology)', 'Artificial neural network', 'Deep learning', 'Task (project management)', 'Deep neural networks', 'Machine learning', 'Algorithm', 'Management', 'Economics', 'Database', 'Programming language']","Modeling the distribution of natural images is a landmark problem in unsupervised learning. This task requires an image model that is at once expressive, tractable and scalable. We present a deep neural network that sequentially predicts the pixels in an image along the two spatial dimensions. Our method models the discrete probability of the raw pixel values and encodes the complete set of dependencies in the image. Architectural novelties include fast two-dimensional recurrent layers and an effective use of residual connections in deep recurrent networks. We achieve log-likelihood scores on natural images that are considerably better than the previous state of the art. Our main results also provide benchmarks on the diverse ImageNet dataset. Samples generated from the model appear crisp, varied and globally coherent."
https://openalex.org/W2158985775,Artificial neural networks for solving ordinary and partial differential equations,"{'We': [0], 'present': [1, 124], 'a': [2, 25, 58, 118], 'method': [3, 115, 134, 152], 'to': [4, 50, 80, 97, 104, 157], 'solve': [5], 'initial': [6], 'and': [7, 37, 75, 102, 123, 147], 'boundary': [8], 'value': [9], 'problems': [10, 122], 'using': [11, 129], 'artificial': [12], 'neural': [13, 60], 'networks.': [14], 'A': [15], 'trial': [16], 'solution': [17], 'of': [18, 27, 87, 99, 120, 138, 145], 'the': [19, 34, 52, 70, 76, 82, 114, 130, 143, 151, 158, 163], 'differential': [20, 83, 94, 106, 140], 'equation': [21], 'is': [22, 45, 78], 'written': [23], 'as': [24, 48], 'sum': [26], 'two': [28], 'parts.': [29], 'The': [30, 42, 85], 'first': [31], 'part': [32, 44, 56], 'satisfies': [33], 'initial/boundary': [35, 53, 71], 'conditions': [36, 72], 'contains': [38], 'no': [39], 'adjustable': [40, 63], 'parameters.': [41], 'second': [43], 'constructed': [46], 'so': [47], 'not': [49], 'affect': [51], 'conditions.': [54], 'This': [55], 'involves': [57], 'feedforward': [59], 'network': [61, 77], 'containing': [62], 'parameters': [64], '(the': [65], 'weights).': [66], 'Hence': [67], 'by': [68, 116], 'construction': [69], 'are': [73], 'satisfied': [74], 'trained': [79], 'satisfy': [81], 'equation.': [84], 'applicability': [86], 'this': [88, 110], 'approach': [89], 'ranges': [90], 'from': [91], 'single': [92], 'ordinary': [93], 'equations': [95, 107], ""(ODE's),"": [96], 'systems': [98], 'coupled': [100], ""ODE's"": [101], 'also': [103], 'partial': [105, 139], ""(PDE's)."": [108], 'In': [109], 'article,': [111], 'we': [112], 'illustrate': [113], 'solving': [117], 'variety': [119], 'model': [121], 'comparisons': [125], 'with': [126], 'solutions': [127], 'obtained': [128], 'Galekrkin': [131], 'finite': [132], 'element': [133], 'for': [135], 'several': [136], 'cases': [137], 'equations.': [141], 'With': [142], 'advent': [144], 'neuroprocessors': [146], 'digital': [148], 'signal': [149], 'processors': [150], 'becomes': [153], 'particularly': [154], 'interesting': [155], 'due': [156], 'expected': [159], 'essential': [160], 'gains': [161], 'in': [162], 'execution': [164], 'speed.': [165]}",1998,[],"We present a method to solve initial and boundary value problems using artificial neural networks. A trial solution of the differential equation is written as a sum of two parts. The first part satisfies the initial/boundary conditions and contains no adjustable parameters. The second part is constructed so as not to affect the initial/boundary conditions. This part involves a feedforward neural network containing adjustable parameters (the weights). Hence by construction the initial/boundary conditions are satisfied and the network is trained to satisfy the differential equation. The applicability of this approach ranges from single ordinary differential equations (ODE's), to systems of coupled ODE's and also to partial differential equations (PDE's). In this article, we illustrate the method by solving a variety of model problems and present comparisons with solutions obtained using the Galekrkin finite element method for several cases of partial differential equations. With the advent of neuroprocessors and digital signal processors the method becomes particularly interesting due to the expected essential gains in the execution speed."
https://openalex.org/W1521436688,Deep Convolutional Neural Networks for Hyperspectral Image Classification,"{'Recently,': [0], 'convolutional': [1, 23, 55], 'neural': [2, 24], 'networks': [3, 25], 'have': [4], 'demonstrated': [5], 'excellent': [6], 'performance': [7, 100], 'on': [8, 74, 85], 'various': [9], 'visual': [10], 'tasks,': [11], 'including': [12], 'the': [13, 38, 41, 51, 54, 57, 61, 66, 93, 111], 'classification': [14, 99], 'of': [15, 40], 'common': [16], 'two-dimensional': [17], 'images.': [18], 'In': [19], 'this': [20], 'paper,': [21], 'deep': [22, 113], 'are': [26, 50, 72], 'employed': [27], 'to': [28, 78], 'classify': [29], 'hyperspectral': [30, 87], 'images': [31], 'directly': [32], 'in': [33], 'spectral': [34, 76], 'domain.': [35], 'More': [36], 'specifically,': [37], 'architecture': [39], 'proposed': [42, 94], 'classifier': [43], 'contains': [44], 'five': [45, 70], 'layers': [46, 71], 'with': [47], 'weights': [48], 'which': [49], 'input': [52], 'layer,': [53, 56, 60, 64], 'max': [58], 'pooling': [59], 'full': [62], 'connection': [63], 'and': [65, 110], 'output': [67], 'layer.': [68], 'These': [69], 'implemented': [73], 'each': [75], 'signature': [77], 'discriminate': [79], 'against': [80], 'others.': [81], 'Experimental': [82], 'results': [83], 'based': [84], 'several': [86], 'image': [88], 'data': [89], 'sets': [90], 'demonstrate': [91], 'that': [92], 'method': [95], 'can': [96], 'achieve': [97], 'better': [98], 'than': [101], 'some': [102], 'traditional': [103], 'methods,': [104], 'such': [105], 'as': [106], 'support': [107], 'vector': [108], 'machines': [109], 'conventional': [112], 'learning-based': [114], 'methods.': [115]}",2015,"['Hyperspectral imaging', 'Convolutional neural network', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Computer science', 'Classifier (UML)', 'Pooling', 'Deep learning', 'Layer (electronics)', 'Contextual image classification', 'Support vector machine', 'Image (mathematics)', 'Materials science', 'Composite material']","Recently, convolutional neural networks have demonstrated excellent performance on various visual tasks, including the classification of common two-dimensional images. In this paper, deep convolutional neural networks are employed to classify hyperspectral images directly in spectral domain. More specifically, the architecture of the proposed classifier contains five layers with weights which are the input layer, the convolutional layer, the max pooling layer, the full connection layer, and the output layer. These five layers are implemented on each spectral signature to discriminate against others. Experimental results based on several hyperspectral image data sets demonstrate that the proposed method can achieve better classification performance than some traditional methods, such as support vector machines and the conventional deep learning-based methods."
https://openalex.org/W4319988532,Progressive Neural Networks,"{'Learning': [0], 'to': [1, 17, 35, 45], 'solve': [2], 'complex': [3], 'sequences': [4], 'of': [5, 58, 97], 'tasks--while': [6], 'both': [7, 90], 'leveraging': [8], 'transfer': [9, 87], 'and': [10, 37, 63, 67, 77, 93], 'avoiding': [11], 'catastrophic': [12], 'forgetting--remains': [13], 'a': [14, 26, 55, 80], 'key': [15], 'obstacle': [16], 'achieving': [18], 'human-level': [19], 'intelligence.': [20], 'The': [21], 'progressive': [22], 'networks': [23], 'approach': [24], 'represents': [25], 'step': [27], 'forward': [28], 'in': [29], 'this': [30, 51], 'direction:': [31], 'they': [32], 'are': [33], 'immune': [34], 'forgetting': [36], 'can': [38], 'leverage': [39], 'prior': [40], 'knowledge': [41], 'via': [42], 'lateral': [43], 'connections': [44], 'previously': [46], 'learned': [47, 99], 'features.': [48], 'We': [49], 'evaluate': [50], 'architecture': [52], 'extensively': [53], 'on': [54, 75], 'wide': [56], 'variety': [57], 'reinforcement': [59], 'learning': [60], 'tasks': [61], '(Atari': [62], '3D': [64], 'maze': [65], 'games),': [66], 'show': [68], 'that': [69, 86], 'it': [70], 'outperforms': [71], 'common': [72], 'baselines': [73], 'based': [74], 'pretraining': [76], 'finetuning.': [78], 'Using': [79], 'novel': [81], 'sensitivity': [82], 'measure,': [83], 'we': [84], 'demonstrate': [85], 'occurs': [88], 'at': [89], 'low-level': [91], 'sensory': [92], 'high-level': [94], 'control': [95], 'layers': [96], 'the': [98], 'policy.': [100]}",2016,"['Forgetting', 'Leverage (statistics)', 'Computer science', 'Reinforcement learning', 'Artificial intelligence', 'Transfer of learning', 'Machine learning', 'Artificial neural network', 'Key (lock)', 'Cognitive psychology', 'Psychology', 'Computer security']","Learning to solve complex sequences of tasks--while both leveraging transfer and avoiding catastrophic forgetting--remains a key obstacle to achieving human-level intelligence. The progressive networks approach represents a step forward in this direction: they are immune to forgetting and can leverage prior knowledge via lateral connections to previously learned features. We evaluate this architecture extensively on a wide variety of reinforcement learning tasks (Atari and 3D maze games), and show that it outperforms common baselines based on pretraining and finetuning. Using a novel sensitivity measure, we demonstrate that transfer occurs at both low-level sensory and high-level control layers of the learned policy."
https://openalex.org/W2951266961,Weight Uncertainty in Neural Networks,"{'We': [0, 49, 65], 'introduce': [1], 'a': [2, 11, 18, 31], 'new,': [3], 'efficient,': [4], 'principled': [5, 53], 'and': [6, 85], 'backpropagation-compatible': [7], 'algorithm': [8], 'for': [9], 'learning': [10], 'probability': [12], 'distribution': [13], 'on': [14, 45, 62], 'the': [15, 27, 36, 41, 46, 69, 73, 95], 'weights': [16, 28, 74], 'of': [17, 55], 'neural': [19], 'network,': [20], 'called': [21], 'Bayes': [22], 'by': [23, 29], 'Backprop.': [24], 'It': [25], 'regularises': [26], 'minimising': [30], 'compression': [32], 'cost,': [33], 'known': [34], 'as': [35], 'variational': [37], 'free': [38], 'energy': [39], 'or': [40], 'expected': [42], 'lower': [43], 'bound': [44], 'marginal': [47], 'likelihood.': [48], 'show': [50], 'that': [51], 'this': [52, 87], 'kind': [54], 'regularisation': [56], 'yields': [57], 'comparable': [58], 'performance': [59], 'to': [60, 78, 93], 'dropout': [61], 'MNIST': [63], 'classification.': [64], 'then': [66], 'demonstrate': [67], 'how': [68, 86], 'learnt': [70], 'uncertainty': [71, 89], 'in': [72, 81, 98], 'can': [75, 90], 'be': [76, 91], 'used': [77, 92], 'improve': [79], 'generalisation': [80], 'non-linear': [82], 'regression': [83], 'problems,': [84], 'weight': [88], 'drive': [94], 'exploration-exploitation': [96], 'trade-off': [97], 'reinforcement': [99], 'learning.': [100]}",2015,"['MNIST database', 'Dropout (neural networks)', 'Backpropagation', 'Artificial neural network', 'Computer science', 'Artificial intelligence', 'Reinforcement learning', 'Upper and lower bounds', ""Bayes' theorem"", 'Energy (signal processing)', 'Machine learning', 'Mathematical optimization', 'Bayesian probability', 'Mathematics', 'Statistics', 'Mathematical analysis']","We introduce a new, efficient, principled and backpropagation-compatible algorithm for learning a probability distribution on the weights of a neural network, called Bayes by Backprop. It regularises the weights by minimising a compression cost, known as the variational free energy or the expected lower bound on the marginal likelihood. We show that this principled kind of regularisation yields comparable performance to dropout on MNIST classification. We then demonstrate how the learnt uncertainty in the weights can be used to improve generalisation in non-linear regression problems, and how this weight uncertainty can be used to drive the exploration-exploitation trade-off in reinforcement learning."
https://openalex.org/W2798701005,All-optical machine learning using diffractive deep neural networks,"{'All-optical': [0], 'deep': [1], 'learning': [2, 4, 42], 'Deep': [3], 'uses': [5, 44], 'multilayered': [6, 27], 'artificial': [7, 69], 'neural': [8, 28, 70], 'networks': [9, 29], 'to': [10, 67, 76], 'learn': [11], 'digitally': [12], 'from': [13], 'large': [14], 'datasets.': [15], 'It': [16], 'then': [17], 'performs': [18], 'advanced': [19], 'identification': [20], 'and': [21, 52], 'classification': [22], 'tasks.': [23], 'To': [24], 'date,': [25], 'these': [26], 'have': [30], 'been': [31], 'implemented': [32], 'on': [33], 'a': [34], 'computer.': [35], 'Lin': [36], 'et': [37], 'al.': [38], 'demonstrate': [39], 'all-optical': [40], 'machine': [41], 'that': [43, 48, 72], 'passive': [45], 'optical': [46, 64], 'components': [47], 'can': [49, 73], 'be': [50, 74], 'patterned': [51], 'fabricated': [53], 'with': [54], '3D-printing.': [55], 'Their': [56], 'hardware': [57], 'approach': [58], 'comprises': [59], 'stacked': [60], 'layers': [61], 'of': [62, 83], 'diffractive': [63], 'elements': [65], 'analogous': [66], 'an': [68], 'network': [71], 'trained': [75], 'execute': [77], 'complex': [78], 'functions': [79], 'at': [80], 'the': [81], 'speed': [82], 'light.': [84], 'Science': [85], ',': [86], 'this': [87], 'issue': [88], 'p.': [89], '1004': [90]}",2018,"['Computer science', 'Deep learning', 'Artificial intelligence', 'Artificial neural network', 'Feature (linguistics)', 'Lithography', 'Deep neural networks', 'Pattern recognition (psychology)', 'Computer architecture', 'Computer vision', 'Materials science', 'Optoelectronics', 'Linguistics', 'Philosophy']","All-optical deep learning Deep learning uses multilayered artificial neural networks to learn digitally from large datasets. It then performs advanced identification and classification tasks. To date, these multilayered neural networks have been implemented on a computer. Lin et al. demonstrate all-optical machine learning that uses passive optical components that can be patterned and fabricated with 3D-printing. Their hardware approach comprises stacked layers of diffractive optical elements analogous to an artificial neural network that can be trained to execute complex functions at the speed of light. Science , this issue p. 1004"
https://openalex.org/W2766856748,Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties,"{'The': [0], 'use': [1], 'of': [2, 10, 22, 65, 76, 86, 96, 132], 'machine': [3], 'learning': [4], 'methods': [5], 'for': [6, 92, 146], 'accelerating': [7], 'the': [8, 27, 33, 63, 68, 120], 'design': [9], 'crystalline': [11, 77], 'materials': [12, 147], 'usually': [13], 'requires': [14], 'manually': [15], 'constructed': [16], 'feature': [17], 'vectors': [18], 'or': [19, 39], 'complex': [20], 'transformation': [21], 'atom': [23], 'coordinates': [24], 'to': [25, 35, 43, 57, 126, 142], 'input': [26], 'crystal': [28, 37, 51], 'structure,': [29], 'which': [30], 'either': [31], 'constrains': [32], 'model': [34], 'certain': [36], 'types': [38, 101], 'makes': [40], 'it': [41], 'difficult': [42], 'provide': [44], 'chemical': [45, 124], 'insights.': [46], 'Here,': [47], 'we': [48, 134], 'develop': [49], 'a': [50, 71, 82], 'graph': [52], 'convolutional': [53], 'neural': [54], 'networks': [55], 'framework': [56, 113], 'directly': [58], 'learn': [59], 'material': [60], 'properties': [61, 91, 95], 'from': [62, 122], 'connection': [64], 'atoms': [66], 'in': [67], 'crystal,': [69], 'providing': [70], 'universal': [72], 'and': [73, 102], 'interpretable': [74, 115], 'representation': [75], 'materials.': [78], 'Our': [79], 'method': [80], 'provides': [81], 'highly': [83], 'accurate': [84], 'prediction': [85], 'density': [87], 'functional': [88], 'theory': [89], 'calculated': [90], 'eight': [93], 'different': [94], 'crystals': [97], 'with': [98, 107], 'various': [99], 'structure': [100], 'compositions': [103], 'after': [104], 'being': [105], 'trained': [106], '10^{4}': [108], 'data': [109], 'points.': [110], 'Further,': [111], 'our': [112], 'is': [114], 'because': [116], 'one': [117], 'can': [118, 139], 'extract': [119], 'contributions': [121], 'local': [123], 'environments': [125], 'global': [127], 'properties.': [128], 'Using': [129], 'an': [130], 'example': [131], 'perovskites,': [133], 'show': [135], 'how': [136], 'this': [137], 'information': [138], 'be': [140], 'utilized': [141], 'discover': [143], 'empirical': [144], 'rules': [145], 'design.': [148]}",2018,"['Computer science', 'Convolutional neural network', 'Crystal (programming language)', 'Representation (politics)', 'Graph', 'Crystal structure', 'Graph rewriting', 'Artificial neural network', 'Crystal structure prediction', 'Atom (system on chip)', 'Transformation (genetics)', 'Artificial intelligence', 'Theoretical computer science', 'Algorithm', 'Chemistry', 'Crystallography', 'Gene', 'Biochemistry', 'Politics', 'Embedded system', 'Programming language', 'Political science', 'Law']","The use of machine learning methods for accelerating the design of crystalline materials usually requires manually constructed feature vectors or complex transformation of atom coordinates to input the crystal structure, which either constrains the model to certain crystal types or makes it difficult to provide chemical insights. Here, we develop a crystal graph convolutional neural networks framework to directly learn material properties from the connection of atoms in the crystal, providing a universal and interpretable representation of crystalline materials. Our method provides a highly accurate prediction of density functional theory calculated properties for eight different properties of crystals with various structure types and compositions after being trained with 10^{4} data points. Further, our framework is interpretable because one can extract the contributions from local chemical environments to global properties. Using an example of perovskites, we show how this information can be utilized to discover empirical rules for materials design."
https://openalex.org/W2809090039,Neural Tangent Kernel: Convergence and Generalization in Neural Networks,"{'At': [0], 'initialization,': [1], 'artificial': [2], 'neural': [3], 'networks': [4], '(ANNs)': [5], 'are': [6], 'equivalent': [7], 'to': [8, 18, 55, 71, 88, 112, 127, 148, 219, 245], 'Gaussian': [9], 'processes': [10], 'in': [11, 69, 106, 133, 188], 'the': [12, 24, 42, 47, 59, 63, 72, 79, 90, 96, 107, 129, 142, 149, 152, 157, 160, 164, 169, 172, 180, 189, 192, 208, 214, 220, 233, 246], 'infinite-width': [13, 108, 190, 247], 'limit,': [14, 191], 'thus': [15], 'connecting': [16], 'them': [17], 'kernel': [19, 60, 85, 116, 210], 'methods.': [20], 'We': [21, 155, 176], 'prove': [22, 156], 'that': [23, 187], 'evolution': [25], 'of': [26, 44, 62, 93, 131, 137, 141, 151, 159, 182, 213], 'an': [27, 45, 113], 'ANN': [28], 'during': [29, 38, 104, 121, 201], 'training': [30, 130, 143], 'can': [31, 144], 'also': [32], 'be': [33, 146], 'described': [34], 'by': [35], 'a': [36, 76, 197, 224], 'kernel:': [37, 78], 'gradient': [39, 61], 'descent': [40], 'on': [41, 168, 179], 'parameters': [43], 'ANN,': [46], 'network': [48, 193], 'function': [49, 134, 194], '$f_θ$': [50, 195], '(which': [51, 66], 'maps': [52], 'input': [53, 215], 'vectors': [54], 'output': [56], 'vectors)': [57], 'follows': [58, 196], 'functional': [64], 'cost': [65], 'is': [67, 86, 98, 166, 174, 205], 'convex,': [68], 'contrast': [70], 'parameter': [73, 138], 'cost)': [74], 'w.r.t.': [75], 'new': [77], 'Neural': [80], 'Tangent': [81], 'Kernel': [82], '(NTK).': [83], 'This': [84, 123], 'central': [87], 'describe': [89], 'generalization': [91], 'features': [92], 'ANNs.': [94], 'While': [95], 'NTK': [97, 162, 234], 'random': [99], 'at': [100], 'initialization': [101], 'and': [102, 117, 171, 185, 242], 'varies': [103], 'training,': [105], 'limit': [109], 'it': [110, 118, 125, 244], 'converges': [111], 'explicit': [114], 'limiting': [115, 153, 161], 'stays': [119], 'constant': [120], 'training.': [122, 202], 'makes': [124], 'possible': [126], 'study': [128, 232], 'ANNs': [132], 'space': [135], 'instead': [136], 'space.': [139], 'Convergence': [140], 'then': [145, 177], 'related': [147], 'positive-definiteness': [150, 158], 'NTK.': [154], 'when': [163], 'data': [165, 216], 'supported': [167], 'sphere': [170], 'non-linearity': [173], 'non-polynomial.': [175], 'focus': [178], 'setting': [181], 'least-squares': [183], 'regression': [184], 'show': [186], 'linear': [198], 'differential': [199], 'equation': [200], 'The': [203], 'convergence': [204], 'fastest': [206], 'along': [207], 'largest': [209], 'principal': [211], 'components': [212], 'with': [217], 'respect': [218], 'NTK,': [221], 'hence': [222], 'suggesting': [223], 'theoretical': [225], 'motivation': [226], 'for': [227, 239], 'early': [228], 'stopping.': [229], 'Finally': [230], 'we': [231], 'numerically,': [235], 'observe': [236], 'its': [237], 'behavior': [238], 'wide': [240], 'networks,': [241], 'compare': [243], 'limit.': [248]}",2018,"['Mathematics', 'Kernel (algebra)', 'Artificial neural network', 'Gradient descent', 'Initialization', 'Applied mathematics', 'Variable kernel density estimation', 'Kernel method', 'Limit (mathematics)', 'Overfitting', 'Mathematical analysis', 'Computer science', 'Artificial intelligence', 'Combinatorics', 'Support vector machine', 'Programming language']","At initialization, artificial neural networks (ANNs) are equivalent to Gaussian processes in the infinite-width limit, thus connecting them to kernel methods. We prove that the evolution of an ANN during training can also be described by a kernel: during gradient descent on the parameters of an ANN, the network function $f_θ$ (which maps input vectors to output vectors) follows the kernel gradient of the functional cost (which is convex, in contrast to the parameter cost) w.r.t. a new kernel: the Neural Tangent Kernel (NTK). This kernel is central to describe the generalization features of ANNs. While the NTK is random at initialization and varies during training, in the infinite-width limit it converges to an explicit limiting kernel and it stays constant during training. This makes it possible to study the training of ANNs in function space instead of parameter space. Convergence of the training can then be related to the positive-definiteness of the limiting NTK. We prove the positive-definiteness of the limiting NTK when the data is supported on the sphere and the non-linearity is non-polynomial. We then focus on the setting of least-squares regression and show that in the infinite-width limit, the network function $f_θ$ follows a linear differential equation during training. The convergence is fastest along the largest kernel principal components of the input data with respect to the NTK, hence suggesting a theoretical motivation for early stopping. Finally we study the NTK numerically, observe its behavior for wide networks, and compare it to the infinite-width limit."
https://openalex.org/W2016415759,"Fuzzy logic, neural networks, and soft computing","{'article': [0], 'Free': [1], 'Access': [2], 'Share': [3], 'on': [4, 81], 'Fuzzy': [5], 'logic,': [6], 'neural': [7], 'networks,': [8], 'and': [9, 58], 'soft': [10], 'computing': [11], 'Author:': [12], 'Lotfi': [13], 'A.': [14], 'Zadeh': [15], 'Univ.': [16, 20], 'of': [17, 21, 30], 'California,': [18, 22], 'Berkeley': [19], 'BerkeleyView': [23], 'Profile': [24], 'Authors': [25], 'Info': [26], '&': [27], 'Claims': [28], 'Communications': [29], 'the': [31, 82], 'ACMVolume': [32], '37Issue': [33], '3March': [34], '1994pp': [35], '77–84https://doi.org/10.1145/175247.175255Published:01': [36], 'March': [37], '1994Publication': [38], 'History': [39], '1,090citation7,848DownloadsMetricsTotal': [40], 'Citations1,090Total': [41], 'Downloads7,848Last': [42], '12': [43], 'Months265Last': [44], '6': [45], 'weeks18': [46], 'Get': [47], 'Citation': [48, 50, 87], 'AlertsNew': [49, 86], 'Alert': [51], 'added!This': [52], 'alert': [53, 78], 'has': [54, 73], 'been': [55, 74], 'successfully': [56], 'added': [57], 'will': [59, 63], 'be': [60, 64], 'sent': [61], 'to:You': [62], 'notified': [65], 'whenever': [66], 'a': [67, 99], 'record': [68], 'that': [69], 'you': [70], 'have': [71], 'chosen': [72], 'cited.To': [75], 'manage': [76], 'your': [77, 92], 'preferences,': [79], 'click': [80], 'button': [83], 'below.Manage': [84], 'my': [85], 'Alert!Please': [88], 'log': [89], 'in': [90], 'to': [91, 95, 97], 'account': [93], 'Save': [94], 'BinderSave': [96], 'BinderCreate': [98], 'New': [100], 'BinderNameCancelCreateExport': [101], 'CitationPublisher': [102], 'SiteeReaderPDF': [103]}",1994,"['Soft computing', 'Citation', 'Computer science', 'Fuzzy logic', 'Artificial neural network', 'Artificial intelligence', 'World Wide Web']","article Free Access Share on Fuzzy logic, neural networks, and soft computing Author: Lotfi A. Zadeh Univ. of California, Berkeley Univ. of California, BerkeleyView Profile Authors Info & Claims Communications of the ACMVolume 37Issue 3March 1994pp 77–84https://doi.org/10.1145/175247.175255Published:01 March 1994Publication History 1,090citation7,848DownloadsMetricsTotal Citations1,090Total Downloads7,848Last 12 Months265Last 6 weeks18 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF"
https://openalex.org/W1825675169,Understanding Neural Networks Through Deep Visualization,"{'Recent': [0], 'years': [1], 'have': [2, 101], 'produced': [3, 80, 147], 'great': [4], 'advances': [5], 'in': [6, 16, 46, 110, 138], 'training': [7, 17], 'large,': [8], 'deep': [9], 'neural': [10, 19, 63], 'networks': [11, 20], '(DNNs),': [12], 'including': [13], 'notable': [14], 'successes': [15], 'convolutional': [18], '(convnets)': [21], 'to': [22, 112, 160], 'recognize': [23], 'natural': [24], 'images.': [25], 'However,': [26], 'our': [27], 'understanding': [28], 'of': [29, 56, 84, 132, 144], 'how': [30, 120], 'these': [31], 'models': [32], 'work,': [33], 'especially': [34], 'what': [35], 'computations': [36], 'they': [37], 'perform': [38], 'at': [39, 105, 129], 'intermediate': [40], 'layers,': [41], 'has': [42], 'lagged': [43], 'behind.': [44], 'Progress': [45], 'the': [47, 54, 78], 'field': [48], 'will': [49], 'be': [50], 'further': [51], 'accelerated': [52], 'by': [53], 'development': [55], 'better': [57], 'tools': [58, 69, 168], 'for': [59], 'visualizing': [60, 127], 'and': [61, 172], 'interpreting': [62], 'nets.': [64], 'We': [65, 100], 'introduce': [66, 153], 'two': [67], 'such': [68], 'here.': [70], 'The': [71, 123], 'first': [72], 'is': [73], 'a': [74, 85, 96, 133, 175], 'tool': [75, 125], 'that': [76, 103, 108, 158], 'visualizes': [77], 'activations': [79, 107], 'on': [81, 174], 'each': [82, 130], 'layer': [83, 131], 'trained': [86], 'convnet': [87, 177], 'as': [88], 'it': [89], 'processes': [90], 'an': [91], 'image': [92, 139], 'or': [93], 'video': [94], '(e.g.': [95], 'live': [97, 106], 'webcam': [98], 'stream).': [99], 'found': [102], 'looking': [104], 'change': [109], 'response': [111], 'user': [113], 'input': [114], 'helps': [115], 'build': [116], 'valuable': [117], 'intuitions': [118], 'about': [119], 'convnets': [121], 'work.': [122], 'second': [124], 'enables': [126], 'features': [128], 'DNN': [134], 'via': [135], 'regularized': [136], 'optimization': [137], 'space.': [140], 'Because': [141], 'previous': [142], 'versions': [143], 'this': [145], 'idea': [146], 'less': [148], 'recognizable': [149], 'images,': [150], 'here': [151], 'we': [152], 'several': [154], 'new': [155], 'regularization': [156], 'methods': [157], 'combine': [159], 'produce': [161], 'qualitatively': [162], 'clearer,': [163], 'more': [164], 'interpretable': [165], 'visualizations.': [166], 'Both': [167], 'are': [169], 'open': [170], 'source': [171], 'work': [173], 'pre-trained': [176], 'with': [178], 'minimal': [179], 'setup.': [180]}",2015,"['Visualization', 'Artificial neural network', 'Computer science', 'Deep neural networks', 'Artificial intelligence', 'Data science']","Recent years have produced great advances in training large, deep neural networks (DNNs), including notable successes in training convolutional neural networks (convnets) to recognize natural images. However, our understanding of how these models work, especially what computations they perform at intermediate layers, has lagged behind. Progress in the field will be further accelerated by the development of better tools for visualizing and interpreting neural nets. We introduce two such tools here. The first is a tool that visualizes the activations produced on each layer of a trained convnet as it processes an image or video (e.g. a live webcam stream). We have found that looking at live activations that change in response to user input helps build valuable intuitions about how convnets work. The second tool enables visualizing features at each layer of a DNN via regularized optimization in image space. Because previous versions of this idea produced less recognizable images, here we introduce several new regularization methods that combine to produce qualitatively clearer, more interpretable visualizations. Both tools are open source and work on a pre-trained convnet with minimal setup."
https://openalex.org/W1828163288,Sequence Transduction with Recurrent Neural Networks,"{'Many': [0], 'machine': [1, 18], 'learning': [2, 40, 72, 79], 'tasks': [3], 'can': [4], 'be': [5], 'expressed': [6], 'as': [7, 59], 'the': [8, 33, 44, 90, 105, 108, 120, 123, 166], 'transformation---or': [9], '\\emph{transduction}---of': [10], 'input': [11, 45, 91, 150], 'sequences': [12, 48, 94], 'into': [13, 152], 'output': [14, 47, 93, 124, 156], 'sequences:': [15], 'speech': [16, 168], 'recognition,': [17], 'translation,': [19], 'protein': [20], 'secondary': [21], 'structure': [22], 'prediction': [23], 'and': [24, 46, 62, 92], 'text-to-speech': [25], 'to': [26, 41, 55, 95, 147], 'name': [27], 'but': [28], 'a': [29, 50, 69, 86, 100], 'few.': [30], 'One': [31], 'of': [32, 78, 112, 122], 'key': [34], 'challenges': [35], 'in': [36, 49, 144], 'sequence': [37, 71, 114, 125, 135, 151], 'transduction': [38, 115, 136], 'is': [39, 53, 99, 107, 126, 143], 'represent': [42], 'both': [43], 'way': [51], 'that': [52, 74, 142], 'invariant': [54], 'sequential': [56], 'distortions': [57], 'such': [58, 80], 'shrinking,': [60], 'stretching': [61], 'translating.': [63], 'Recurrent': [64], 'neural': [65], 'networks': [66], '(RNNs)': [67], 'are': [68, 163], 'powerful': [70], 'architecture': [73], 'has': [75], 'proven': [76], 'capable': [77], 'representations.': [81], 'However': [82], 'RNNs': [83], 'traditionally': [84], 'require': [85], 'pre-defined': [87], 'alignment': [88, 106], 'between': [89], 'perform': [96], 'transduction.': [97], 'This': [98, 129], 'severe': [101], 'limitation': [102], 'since': [103], '\\emph{finding}': [104], 'most': [109], 'difficult': [110], 'aspect': [111], 'many': [113], 'problems.': [116], 'Indeed,': [117], 'even': [118], 'determining': [119], 'length': [121], 'often': [127], 'challenging.': [128], 'paper': [130], 'introduces': [131], 'an': [132], 'end-to-end,': [133], 'probabilistic': [134], 'system,': [137], 'based': [138], 'entirely': [139], 'on': [140, 165], 'RNNs,': [141], 'principle': [145], 'able': [146], 'transform': [148], 'any': [149, 153], 'finite,': [154], 'discrete': [155], 'sequence.': [157], 'Experimental': [158], 'results': [159], 'for': [160], 'phoneme': [161], 'recognition': [162], 'provided': [164], 'TIMIT': [167], 'corpus.': [169]}",2012,"['Transduction (biophysics)', 'TIMIT', 'Sequence (biology)', 'Recurrent neural network', 'Sequence learning', 'Computer science', 'Artificial intelligence', 'Speech recognition', 'Artificial neural network', 'Hidden Markov model', 'Biology', 'Genetics', 'Biochemistry']","Many machine learning tasks can be expressed as the transformation---or \emph{transduction}---of input sequences into output sequences: speech recognition, machine translation, protein secondary structure prediction and text-to-speech to name but a few. One of the key challenges in sequence transduction is learning to represent both the input and output sequences in a way that is invariant to sequential distortions such as shrinking, stretching and translating. Recurrent neural networks (RNNs) are a powerful sequence learning architecture that has proven capable of learning such representations. However RNNs traditionally require a pre-defined alignment between the input and output sequences to perform transduction. This is a severe limitation since \emph{finding} the alignment is the most difficult aspect of many sequence transduction problems. Indeed, even determining the length of the output sequence is often challenging. This paper introduces an end-to-end, probabilistic sequence transduction system, based entirely on RNNs, that is in principle able to transform any input sequence into any finite, discrete output sequence. Experimental results for phoneme recognition are provided on the TIMIT speech corpus."
https://openalex.org/W2905224888,Graph Neural Networks: A Review of Methods and Applications,"{'Lots': [0], 'of': [1, 57, 63, 87, 95, 101, 142], 'learning': [2, 19, 41, 124], 'tasks': [3], 'require': [4], 'dealing': [5], 'with': [6], 'graph': [7, 34, 73, 105, 109, 113], 'data': [8, 44], 'which': [9, 70], 'contains': [10], 'rich': [11], 'relation': [12], 'information': [13], 'among': [14], 'elements.': [15], 'Modeling': [16], 'physics': [17], 'systems,': [18], 'molecular': [20], 'fingerprints,': [21], 'predicting': [22], 'protein': [23], 'interface,': [24], 'and': [25, 47, 59, 138, 149], 'classifying': [26], 'diseases': [27], 'demand': [28], 'a': [29, 131], 'model': [30], 'to': [31], 'learn': [32], 'from': [33, 42], 'inputs.': [35], 'In': [36, 97, 126], 'other': [37], 'domains': [38], 'such': [39, 103], 'as': [40, 104], 'non-structural': [43], 'like': [45], 'texts': [46], 'images,': [48], 'reasoning': [49, 74], 'on': [50, 121], 'extracted': [51], 'structures': [52], '(like': [53], 'the': [54, 60, 85, 93, 140, 147], 'dependency': [55], 'trees': [56], 'sentences': [58], 'scene': [61], 'graphs': [62, 88], 'images)': [64], 'is': [65], 'an': [66], 'important': [67], 'research': [68], 'topic': [69], 'also': [71], 'needs': [72], 'models.': [75], 'Graph': [76], 'neural': [77, 81], 'networks': [78], '(GNNs)': [79], 'are': [80], 'models': [82, 137], 'that': [83], 'capture': [84], 'dependence': [86], 'via': [89], 'message': [90], 'passing': [91], 'between': [92], 'nodes': [94], 'graphs.': [96], 'recent': [98], 'years,': [99], 'variants': [100, 141], 'GNNs': [102], 'convolutional': [106], 'network': [107, 111, 115], '(GCN),': [108], 'attention': [110], '(GAT),': [112], 'recurrent': [114], '(GRN)': [116], 'have': [117], 'demonstrated': [118], 'ground-breaking': [119], 'performances': [120], 'many': [122], 'deep': [123], 'tasks.': [125], 'this': [127], 'survey,': [128], 'we': [129], 'propose': [130, 150], 'general': [132], 'design': [133], 'pipeline': [134], 'for': [135, 154], 'GNN': [136], 'discuss': [139], 'each': [143], 'component,': [144], 'systematically': [145], 'categorize': [146], 'applications,': [148], 'four': [151], 'open': [152], 'problems': [153], 'future': [155], 'research.': [156]}",2018,"['Computer science', 'Graph', 'Categorization', 'Artificial intelligence', 'Deep learning', 'Graph database', 'Theoretical computer science', 'Convolutional neural network', 'Machine learning']","Lots of learning tasks require dealing with graph data which contains rich relation information among elements. Modeling physics systems, learning molecular fingerprints, predicting protein interface, and classifying diseases demand a model to learn from graph inputs. In other domains such as learning from non-structural data like texts and images, reasoning on extracted structures (like the dependency trees of sentences and the scene graphs of images) is an important research topic which also needs graph reasoning models. Graph neural networks (GNNs) are neural models that capture the dependence of graphs via message passing between the nodes of graphs. In recent years, variants of GNNs such as graph convolutional network (GCN), graph attention network (GAT), graph recurrent network (GRN) have demonstrated ground-breaking performances on many deep learning tasks. In this survey, we propose a general design pipeline for GNN models and discuss the variants of each component, systematically categorize the applications, and propose four open problems for future research."
https://openalex.org/W2167224731,"ALVINN, an autonomous land vehicle in a neural network","{'Computer': [0], 'Science': [1], 'Department': [2]}",1990,"['Computer science', 'Task (project management)', 'Artificial neural network', 'Artificial intelligence', 'Computer vision', 'Real-time computing', 'Representation (politics)', 'Field (mathematics)', 'Simulation', 'Engineering', 'Pure mathematics', 'Political science', 'Mathematics', 'Systems engineering', 'Politics', 'Law']",Computer Science Department
https://openalex.org/W2607219512,Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks,"{'Although': [0], 'deep': [1], 'neural': [2], 'networks': [3], '(DNNs)': [4], 'have': [5, 43], 'achieved': [6], 'great': [7], 'success': [8, 47], 'in': [9, 87, 148], 'many\\ntasks,': [10], 'they': [11], 'can': [12, 58, 145], 'often': [13], 'be': [14, 59, 146], 'fooled': [15], 'by': [16, 21, 65], '\\\\emph{adversarial': [17], 'examples}': [18], 'that': [19, 80, 104], 'are\\ngenerated': [20], 'adding': [22], 'small': [23], 'but': [24, 42], 'purposeful': [25], 'distortions': [26], 'to': [27, 31, 61, 75, 82, 141, 152], 'natural': [28], 'examples.\\nPrevious': [29], 'studies': [30], 'defend': [32], 'against': [33, 157], 'adversarial': [34, 67], 'examples': [35, 111], 'mostly': [36], 'focused': [37], 'on\\nrefining': [38], 'the': [39, 71, 126], 'DNN': [40, 63, 97], 'models,': [41], 'either': [44], 'shown': [45], 'limited': [46], 'or': [48], 'required\\nexpensive': [49], 'computation.': [50], 'We': [51], 'propose': [52], 'a': [53, 91, 96, 149], 'new': [54], 'strategy,': [55], '\\\\emph{feature': [56], 'squeezing},\\nthat': [57], 'used': [60], 'harden': [62], 'models': [64], 'detecting': [66], 'examples.\\nFeature': [68], 'squeezing': [69, 109, 123], 'reduces': [70], 'search': [72], 'space': [73, 89], 'available': [74], 'an': [76], 'adversary': [77], 'by\\ncoalescing': [78], 'samples': [79], 'correspond': [81], 'many': [83], 'different': [84], 'feature': [85, 108, 122], 'vectors': [86], 'the\\noriginal': [88], 'into': [90], 'single': [92], 'sample.': [93], 'By': [94], 'comparing': [95], ""model's"": [98], 'prediction': [99], 'on\\nthe': [100], 'original': [101], 'input': [102], 'with': [103, 112], 'on': [105], 'squeezed': [106], 'inputs,': [107], 'detects\\nadversarial': [110], 'high': [113, 154], 'accuracy': [114], 'and': [115, 132, 144], 'few': [116], 'false': [117], 'positives.': [118], 'This': [119], 'paper\\nexplores': [120], 'two': [121], 'methods:': [124], 'reducing': [125], 'color': [127], 'bit': [128], 'depth': [129], 'of': [130], 'each\\npixel': [131], 'spatial': [133], 'smoothing.': [134], 'These': [135], 'simple': [136], 'strategies': [137], 'are': [138], 'inexpensive': [139], 'and\\ncomplementary': [140], 'other': [142], 'defenses,': [143], 'combined': [147], 'joint': [150], 'detection\\nframework': [151], 'achieve': [153], 'detection': [155], 'rates': [156], 'state-of-the-art': [158], 'attacks.\\n': [159]}",2018,"['Adversarial system', 'Feature (linguistics)', 'Computer science', 'Artificial intelligence', 'Smoothing', 'Feature vector', 'Artificial neural network', 'Deep neural networks', 'False positive paradox', 'Computation', 'Pattern recognition (psychology)', 'Pixel', 'Deep learning', 'Machine learning', 'Algorithm', 'Computer vision', 'Linguistics', 'Philosophy']","Although deep neural networks (DNNs) have achieved great success in many\ntasks, they can often be fooled by \\emph{adversarial examples} that are\ngenerated by adding small but purposeful distortions to natural examples.\nPrevious studies to defend against adversarial examples mostly focused on\nrefining the DNN models, but have either shown limited success or required\nexpensive computation. We propose a new strategy, \\emph{feature squeezing},\nthat can be used to harden DNN models by detecting adversarial examples.\nFeature squeezing reduces the search space available to an adversary by\ncoalescing samples that correspond to many different feature vectors in the\noriginal space into a single sample. By comparing a DNN model's prediction on\nthe original input with that on squeezed inputs, feature squeezing detects\nadversarial examples with high accuracy and few false positives. This paper\nexplores two feature squeezing methods: reducing the color bit depth of each\npixel and spatial smoothing. These simple strategies are inexpensive and\ncomplementary to other defenses, and can be combined in a joint detection\nframework to achieve high detection rates against state-of-the-art attacks.\n"
https://openalex.org/W3035035250,ACTIVATION FUNCTIONS IN NEURAL NETWORKS,"{'Artificial': [0, 95], 'Neural': [1, 96], 'Networks': [2], 'are': [3, 38, 58, 100], 'inspired': [4], 'from': [5, 24, 50], 'the': [6, 10, 16, 51, 55, 62, 68, 73, 77, 117], 'human': [7], 'brain': [8], 'and': [9, 21, 44, 65, 108, 113, 119], 'network': [11, 57], 'of': [12, 41, 54, 111], 'neurons': [13], 'present': [14], 'in': [15, 33, 106], 'brain.The': [17], 'information': [18], 'is': [19, 80], 'processed': [20], 'passed': [22, 59], 'on': [23, 60], 'one': [25], 'neuron': [26], 'to': [27, 46, 61, 67, 76, 83], 'another': [28], 'through': [29], 'neuro': [30], 'synaptic': [31], 'junctions.Similarly,': [32], 'artificial': [34], 'neural': [35, 56], 'networks': [36], 'there': [37], 'different': [39], 'layers': [40, 53, 64], 'cells': [42], 'arranged': [43], 'connected': [45], 'each': [47], 'other.The': [48], 'output/information': [49], 'inner': [52, 84], 'next': [63], 'finally': [66], 'outermost': [69], 'layer': [70, 79], 'which': [71], 'gives': [72], 'output.The': [74], 'input': [75], 'outer': [78], 'provided': [81], 'nonlinearity': [82], ""layers'"": [85], 'output': [86], 'so': [87], 'that': [88], 'it': [89], 'can': [90], 'be': [91], 'further': [92], 'processed.In': [93], 'an': [94], 'Network,': [97], 'activation': [98], 'functions': [99], 'very': [101], 'important': [102], 'as': [103], 'they': [104], 'help': [105], 'learning': [107], 'making': [109], 'sense': [110], 'non-linear': [112], 'complicated': [114], 'mappings': [115], 'between': [116], 'inputs': [118], 'corresponding': [120], 'outputs.': [121]}",2020,"['Artificial neural network', 'Physical neural network', 'Computer science', 'Types of artificial neural networks', 'Layer (electronics)', 'Nonlinear system', 'Artificial intelligence', 'Nervous system network models', 'Time delay neural network', 'Stochastic neural network', 'Topology (electrical circuits)', 'Mathematics', 'Physics', 'Materials science', 'Nanotechnology', 'Combinatorics', 'Quantum mechanics']","Artificial Neural Networks are inspired from the human brain and the network of neurons present in the brain.The information is processed and passed on from one neuron to another through neuro synaptic junctions.Similarly, in artificial neural networks there are different layers of cells arranged and connected to each other.The output/information from the inner layers of the neural network are passed on to the next layers and finally to the outermost layer which gives the output.The input to the outer layer is provided nonlinearity to inner layers' output so that it can be further processed.In an Artificial Neural Network, activation functions are very important as they help in learning and making sense of non-linear and complicated mappings between the inputs and corresponding outputs."
https://openalex.org/W2765424254,One Pixel Attack for Fooling Deep Neural Networks,"{'Recent': [0], 'research': [1], 'has': [2], 'revealed': [3], 'that': [4, 45, 86, 156, 190], 'the': [5, 22, 78, 89, 100, 130, 134, 139, 182], 'output': [6], 'of': [7, 74, 81, 88, 99, 174, 184], 'Deep': [8], 'Neural': [9], 'Networks': [10], '(DNN)': [11], 'can': [12, 41, 70, 106, 191], 'be': [13, 42, 107], 'easily': [14], 'altered': [15], 'by': [16, 115], 'adding': [17], 'relatively': [18], 'small': [19], 'perturbations': [20, 55], 'to': [21, 77, 109, 162], 'input': [23], 'vector.': [24], 'In': [25], 'this': [26], 'paper,': [27], 'we': [28, 46, 168], 'analyze': [29], 'an': [30, 33, 151, 171], 'attack': [31, 141], 'in': [32, 92, 150, 181], 'extremely': [34], 'limited': [35, 153], 'scenario': [36], 'where': [37], 'only': [38], 'one': [39, 112, 118], 'pixel': [40, 119], 'modified.': [43], 'For': [44], 'propose': [47], 'a': [48, 143], 'novel': [49], 'method': [50], 'for': [51, 200], 'generating': [52], 'one-pixel': [53], 'adversarial': [54, 64, 147, 185, 195], 'based': [56], 'on': [57, 125, 133, 146], 'differential': [58], 'evolution': [59], '(DE).': [60], 'It': [61], 'requires': [62], 'less': [63], 'information': [65], '(a': [66], 'black-box': [67], 'attack)': [68], 'and': [69, 97, 122], 'fool': [71], 'more': [72], 'types': [73], 'networks': [75, 199], 'due': [76], 'inherent': [79], 'features': [80], 'DE.': [82], 'The': [83], 'results': [84], 'show': [85, 129], '67.97%': [87], 'natural': [90], 'images': [91, 105], 'Kaggle': [93], 'CIFAR-10': [94, 136], 'test': [95, 104], 'dataset': [96], '16.04%': [98], 'ImageNet': [101], '(ILSVRC': [102], '2012)': [103], 'perturbed': [108], 'at': [110], 'least': [111], 'target': [113], 'class': [114], 'modifying': [116], 'just': [117], 'with': [120], '74.03%': [121], '22.91%': [123], 'confidence': [124], 'average.': [126], 'We': [127], 'also': [128, 160, 169], 'same': [131], 'vulnerability': [132], 'original': [135], 'dataset.': [137], 'Thus,': [138], 'proposed': [140], 'explores': [142], 'different': [144], 'take': [145], 'machine': [148, 186], 'learning': [149], 'extreme': [152], 'scenario,': [154], 'showing': [155], 'current': [157], 'DNNs': [158], 'are': [159], 'vulnerable': [161], 'such': [163], 'low': [164], 'dimension': [165], 'attacks.': [166], 'Besides,': [167], 'illustrate': [170], 'important': [172], 'application': [173], 'DE': [175], '(or': [176], 'broadly': [177], 'speaking,': [178], 'evolutionary': [179], 'computation)': [180], 'domain': [183], 'learning:': [187], 'creating': [188], 'tools': [189], 'effectively': [192], 'generate': [193], 'low-cost': [194], 'attacks': [196], 'against': [197], 'neural': [198], 'evaluating': [201], 'robustness.': [202]}",2019,[],"Recent research has revealed that the output of Deep Neural Networks (DNN) can be easily altered by adding relatively small perturbations to the input vector. In this paper, we analyze an attack in an extremely limited scenario where only one pixel can be modified. For that we propose a novel method for generating one-pixel adversarial perturbations based on differential evolution (DE). It requires less adversarial information (a black-box attack) and can fool more types of networks due to the inherent features of DE. The results show that 67.97% of the natural images in Kaggle CIFAR-10 test dataset and 16.04% of the ImageNet (ILSVRC 2012) test images can be perturbed to at least one target class by modifying just one pixel with 74.03% and 22.91% confidence on average. We also show the same vulnerability on the original CIFAR-10 dataset. Thus, the proposed attack explores a different take on adversarial machine learning in an extreme limited scenario, showing that current DNNs are also vulnerable to such low dimension attacks. Besides, we also illustrate an important application of DE (or broadly speaking, evolutionary computation) in the domain of adversarial machine learning: creating tools that can effectively generate low-cost adversarial attacks against neural networks for evaluating robustness."
https://openalex.org/W2753783305,Trojaning Attack on Neural Networks,"{'With': [0], 'the': [1, 33, 42, 64, 76, 88, 99, 111, 134, 141, 144, 162, 173, 178, 231], 'fast': [2], 'spread': [3], 'of': [4, 164, 222], 'machine': [5, 12], 'learning': [6, 13], 'techniques,': [7], 'sharing': [8], 'and': [9, 73, 167, 188, 208], 'adopting': [10], 'public': [11, 214], 'models': [14, 34, 47], 'become': [15], 'very': [16], 'popular.This': [17], 'gives': [18], 'attackers': [19], 'many': [20], 'new': [21], 'opportunities.In': [22], 'this': [23], 'paper,': [24], 'we': [25, 104, 130, 233], 'propose': [26], 'a': [27, 69, 169, 219, 226], 'trojaning': [28], 'attack': [29, 43, 184, 225], 'on': [30, 172, 213], 'neural': [31, 65], 'networks.As': [32], 'are': [35, 92, 137, 146], 'not': [36, 106, 132, 148], 'intuitive': [37], 'for': [38, 205], 'human': [39, 55], 'to': [40, 67, 83, 87, 108, 119, 124, 126, 139, 151, 160, 224], 'understand,': [41], 'features': [44], 'stealthiness.Deploying': [45], 'trojaned': [46, 190], 'can': [48, 192], 'cause': [49], 'various': [50], 'severe': [51], 'consequences': [52], 'including': [53], 'endangering': [54], 'lives': [56], '(in': [57], 'applications': [58, 159], 'like': [59], 'autonomous': [60], 'driving).We': [61], 'first': [62], 'inverse': [63], 'network': [66, 229], 'generate': [68], 'general': [70], 'trojan': [71, 100], 'trigger,': [72], 'then': [74], 'retrain': [75], 'model': [77], 'with': [78, 98, 110, 210], 'reversed': [79], 'engineered': [80], 'training': [81, 113], 'data': [82], 'inject': [84], 'malicious': [85, 90], 'behaviors': [86, 91, 191], 'model.The': [89], 'only': [93, 217], 'activated': [94], 'by': [95], 'inputs': [96], 'stamped': [97], 'trigger.In': [101], 'our': [102, 128, 165, 183], 'attack,': [103, 166], 'do': [105, 131], 'need': [107], 'tamper': [109], 'original': [112], 'process,': [114], 'which': [115], 'usually': [116, 147], 'takes': [117, 122, 218], 'weeks': [118], 'months.Instead,': [120], 'it': [121, 216], 'minutes': [123], 'hours': [125], 'apply': [127], 'attack.Also,': [129], 'require': [133], 'datasets': [135, 145], 'that': [136, 176, 182], 'used': [138], 'train': [140], 'model.In': [142, 230], 'practice,': [143], 'shared': [149], 'due': [150], 'privacy': [152], 'or': [153], 'copyright': [154], 'concerns.We': [155], 'use': [156], 'five': [157], 'different': [158], 'demonstrate': [161], 'power': [163], 'perform': [168], 'deep': [170], 'analysis': [171], 'possible': [174, 236], 'factors': [175], 'affect': [177], 'attack.The': [179], 'results': [180], 'show': [181], 'is': [185], 'highly': [186], 'effective': [187], 'efficient.The': [189], 'be': [193], 'successfully': [194], 'triggered': [195], '(with': [196], 'nearly': [197], '100%': [198], 'possibility)': [199], 'without': [200], 'affecting': [201], 'its': [202], 'test': [203], 'accuracy': [204, 212], 'normal': [206], 'input': [207], 'even': [209], 'better': [211], 'dataset.Also,': [215], 'small': [220], 'amount': [221], 'time': [223], 'complex': [227], 'neuron': [228], 'end,': [232], 'also': [234], 'discuss': [235], 'defense': [237], 'against': [238], 'such': [239], 'attacks.': [240]}",2018,"['Computer science', 'Trojan', 'Artificial neural network', 'Process (computing)', 'Computer security', 'Artificial intelligence', 'Machine learning', 'Deep learning', 'Operating system']","With the fast spread of machine learning techniques, sharing and adopting public machine learning models become very popular.This gives attackers many new opportunities.In this paper, we propose a trojaning attack on neural networks.As the models are not intuitive for human to understand, the attack features stealthiness.Deploying trojaned models can cause various severe consequences including endangering human lives (in applications like autonomous driving).We first inverse the neural network to generate a general trojan trigger, and then retrain the model with reversed engineered training data to inject malicious behaviors to the model.The malicious behaviors are only activated by inputs stamped with the trojan trigger.In our attack, we do not need to tamper with the original training process, which usually takes weeks to months.Instead, it takes minutes to hours to apply our attack.Also, we do not require the datasets that are used to train the model.In practice, the datasets are usually not shared due to privacy or copyright concerns.We use five different applications to demonstrate the power of our attack, and perform a deep analysis on the possible factors that affect the attack.The results show that our attack is highly effective and efficient.The trojaned behaviors can be successfully triggered (with nearly 100% possibility) without affecting its test accuracy for normal input and even with better accuracy on public dataset.Also, it only takes a small amount of time to attack a complex neuron network model.In the end, we also discuss possible defense against such attacks."
https://openalex.org/W2468907370,Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering,"{'In': [0], 'this': [1, 103], 'work,': [2], 'we': [3], 'are': [4, 21], 'interested': [5], 'in': [6, 45], 'generalizing': [7], 'convolutional': [8, 66], 'neural': [9], 'networks': [10], '(CNNs)': [11], 'from': [12], 'low-dimensional': [13], 'regular': [14], 'grids,': [15], 'where': [16], 'image,': [17], 'video': [18], 'and': [19, 58, 80, 97, 112], 'speech': [20], 'represented,': [22], 'to': [23, 62, 90, 108], 'high-dimensional': [24], 'irregular': [25], 'domains,': [26], 'such': [27], 'as': [28, 84], 'social': [29], 'networks,': [30], 'brain': [31], 'connectomes': [32], 'or': [33], ""words'"": [34], 'embedding,': [35], 'represented': [36], 'by': [37], 'graphs.': [38, 69, 116], 'We': [39], 'present': [40], 'a': [41], 'formulation': [42], 'of': [43, 48, 102], 'CNNs': [44], 'the': [46, 54, 71, 75, 100], 'context': [47], 'spectral': [49], 'graph': [50, 92], 'theory,': [51], 'which': [52], 'provides': [53], 'necessary': [55], 'mathematical': [56], 'background': [57], 'efficient': [59], 'numerical': [60], 'schemes': [61], 'design': [63], 'fast': [64], 'localized': [65], 'filters': [67], 'on': [68, 95, 115], 'Importantly,': [70], 'proposed': [72], 'technique': [73], 'offers': [74], 'same': [76], 'linear': [77], 'computational': [78], 'complexity': [79, 83], 'constant': [81], 'learning': [82, 106], 'classical': [85], 'CNNs,': [86], 'while': [87], 'being': [88], 'universal': [89], 'any': [91], 'structure.': [93], 'Experiments': [94], 'MNIST': [96], '20NEWS': [98], 'demonstrate': [99], 'ability': [101], 'novel': [104], 'deep': [105], 'system': [107], 'learn': [109], 'local,': [110], 'stationary,': [111], 'compositional': [113], 'features': [114]}",2016,"['MNIST database', 'Convolutional neural network', 'Computer science', 'Embedding', 'Theoretical computer science', 'Graph', 'Spectral graph theory', 'Context (archaeology)', 'Artificial intelligence', 'Deep learning', 'Algorithm', 'Line graph', 'Graph power', 'Paleontology', 'Biology']","In this work, we are interested in generalizing convolutional neural networks (CNNs) from low-dimensional regular grids, where image, video and speech are represented, to high-dimensional irregular domains, such as social networks, brain connectomes or words' embedding, represented by graphs. We present a formulation of CNNs in the context of spectral graph theory, which provides the necessary mathematical background and efficient numerical schemes to design fast localized convolutional filters on graphs. Importantly, the proposed technique offers the same linear computational complexity and constant learning complexity as classical CNNs, while being universal to any graph structure. Experiments on MNIST and 20NEWS demonstrate the ability of this novel deep learning system to learn local, stationary, and compositional features on graphs."
https://openalex.org/W1902934009,BinaryConnect: Training Deep Neural Networks with binary weights during propagations,"{'Deep': [0, 80], 'Neural': [1], 'Networks': [2], '(DNN)': [3], 'have': [4], 'achieved': [5], 'state-of-the-art': [6, 178], 'results': [7, 17, 179], 'in': [8, 72, 138, 158], 'a': [9, 66, 134, 140], 'wide': [10], 'range': [11], 'of': [12, 34, 76, 124, 128, 154], 'tasks,': [13], 'with': [14, 19, 142, 180], 'the': [15, 27, 40, 118, 125, 146, 155, 183], 'best': [16], 'obtained': [18], 'large': [20, 24], 'training': [21, 46, 139], 'sets': [22], 'and': [23, 47, 58, 74, 121, 148, 174, 187], 'models.': [25], 'In': [26, 39], 'past,': [28], 'GPUs': [29], 'enabled': [30], 'these': [31], 'breakthroughs': [32], 'because': [33], 'their': [35], 'greater': [36], 'computational': [37], 'speed.': [38], 'future,': [41], 'faster': [42], 'computation': [43], 'at': [44], 'both': [45], 'test': [48], 'time': [49], 'is': [50, 69], 'likely': [51], 'to': [52, 90, 103], 'be': [53], 'crucial': [54], 'for': [55, 59, 79], 'further': [56], 'progress': [57], 'consumer': [60], 'applications': [61], 'on': [62, 182], 'low-power': [63], 'devices.': [64], 'As': [65], 'result,': [67], 'there': [68], 'much': [70], 'interest': [71], 'research': [73], 'development': [75], 'dedicated': [77], 'hardware': [78, 106], 'Learning': [81], '(DL).': [82], 'Binary': [83], 'weights,': [84], 'i.e.,': [85], 'weights': [86, 144, 157], 'which': [87, 136, 159], 'are': [88, 117, 161], 'constrained': [89], 'only': [91], 'two': [92], 'possible': [93], 'values': [94], '(e.g.': [95], '-1': [96], 'or': [97], '1),': [98], 'would': [99], 'bring': [100], 'great': [101], 'benefits': [102], 'specialized': [104], 'DL': [105], 'by': [107, 112], 'replacing': [108], 'many': [109], 'multiply-accumulate': [110], 'operations': [111], 'simple': [113], 'accumulations,': [114], 'as': [115, 172], 'multipliers': [116], 'most': [119], 'space': [120], 'power-hungry': [122], 'components': [123], 'digital': [126], 'implementation': [127], 'neural': [129], 'networks.': [130], 'We': [131], 'introduce': [132], 'BinaryConnect,': [133], 'method': [135], 'consists': [137], 'DNN': [141], 'binary': [143], 'during': [145], 'forward': [147], 'backward': [149], 'propagations,': [150], 'while': [151], 'retaining': [152], 'precision': [153], 'stored': [156], 'gradients': [160], 'accumulated.': [162], 'Like': [163], 'other': [164], 'dropout': [165], 'schemes,': [166], 'we': [167, 175], 'show': [168], 'that': [169], 'BinaryConnect': [170, 181], 'acts': [171], 'regularizer': [173], 'obtain': [176], 'near': [177], 'permutation-invariant': [184], 'MNIST,': [185], 'CIFAR-10': [186], 'SVHN.': [188]}",2015,"['MNIST database', 'Computer science', 'Dropout (neural networks)', 'Artificial neural network', 'Deep neural networks', 'Binary number', 'Invariant (physics)', 'Computation', 'Range (aeronautics)', 'Artificial intelligence', 'Permutation (music)', 'Computer engineering', 'Simple (philosophy)', 'Deep learning', 'Algorithm', 'Machine learning', 'Arithmetic', 'Mathematics', 'Mathematical physics', 'Acoustics', 'Epistemology', 'Physics', 'Philosophy', 'Materials science', 'Composite material']","Deep Neural Networks (DNN) have achieved state-of-the-art results in a wide range of tasks, with the best results obtained with large training sets and large models. In the past, GPUs enabled these breakthroughs because of their greater computational speed. In the future, faster computation at both training and test time is likely to be crucial for further progress and for consumer applications on low-power devices. As a result, there is much interest in research and development of dedicated hardware for Deep Learning (DL). Binary weights, i.e., weights which are constrained to only two possible values (e.g. -1 or 1), would bring great benefits to specialized DL hardware by replacing many multiply-accumulate operations by simple accumulations, as multipliers are the most space and power-hungry components of the digital implementation of neural networks. We introduce BinaryConnect, a method which consists in training a DNN with binary weights during the forward and backward propagations, while retaining precision of the stored weights in which gradients are accumulated. Like other dropout schemes, we show that BinaryConnect acts as regularizer and we obtain near state-of-the-art results with BinaryConnect on the permutation-invariant MNIST, CIFAR-10 and SVHN."
https://openalex.org/W2899457523,Session-Based Recommendation with Graph Neural Networks,"{'The': [0], 'problem': [1], 'of': [2, 50, 61, 101, 122, 130], 'session-based': [3, 151], 'recommendation': [4, 152], 'aims': [5], 'to': [6, 29, 39, 106], 'predict': [7], 'user': [8, 24, 42], 'actions': [9], 'based': [10], 'on': [11, 92, 140], 'anonymous': [12], 'sessions.': [13], 'Previous': [14], 'methods': [15, 153], 'model': [16], 'a': [17, 20, 67], 'session': [18, 84, 94, 115, 132], 'as': [19, 88, 119], 'sequence': [21], 'and': [22, 46, 57, 126], 'estimate': [23], 'representations': [25, 28], 'besides': [26], 'item': [27, 55], 'make': [30], 'recommendations.': [31], 'Though': [32], 'achieved': [33], 'promising': [34], 'results,': [35], 'they': [36], 'are': [37, 86, 104], 'insufficient': [38], 'obtain': [40, 53], 'accurate': [41, 54], 'vectors': [43], 'in': [44], 'sessions': [45], 'neglect': [47], 'complex': [48, 59, 99], 'transitions': [49, 60, 100], 'items.': [51], 'To': [52], 'embedding': [56], 'take': [58], 'items': [62], 'into': [63], 'account,': [64], 'we': [65], 'propose': [66], 'novel': [68], 'method,': [69, 83], 'i.e.': [70], 'Session-based': [71], 'Recommendation': [72], 'with': [73], 'Graph': [74], 'Neural': [75], 'Networks,': [76], 'SR-GNN': [77, 146], 'for': [78], 'brevity.': [79], 'In': [80], 'the': [81, 93, 120, 123, 127, 149], 'proposed': [82], 'sequences': [85], 'modeled': [87], 'graphstructured': [89], 'data.': [90], 'Based': [91], 'graph,': [95], 'GNN': [96], 'can': [97], 'capture': [98], 'items,': [102], 'which': [103], 'difficult': [105], 'be': [107], 'revealed': [108], 'by': [109], 'previous': [110], 'conventional': [111], 'sequential': [112], 'methods.': [113], 'Each': [114], 'is': [116], 'then': [117], 'represented': [118], 'composition': [121], 'global': [124], 'preference': [125], 'current': [128], 'interest': [129], 'that': [131, 145], 'using': [133], 'an': [134], 'attention': [135], 'network.': [136], 'Extensive': [137], 'experiments': [138], 'conducted': [139], 'two': [141], 'real': [142], 'datasets': [143], 'show': [144], 'evidently': [147], 'outperforms': [148], 'state-of-the-art': [150], 'consistently.': [154]}",2019,[],"The problem of session-based recommendation aims to predict user actions based on anonymous sessions. Previous methods model a session as a sequence and estimate user representations besides item representations to make recommendations. Though achieved promising results, they are insufficient to obtain accurate user vectors in sessions and neglect complex transitions of items. To obtain accurate item embedding and take complex transitions of items into account, we propose a novel method, i.e. Session-based Recommendation with Graph Neural Networks, SR-GNN for brevity. In the proposed method, session sequences are modeled as graphstructured data. Based on the session graph, GNN can capture complex transitions of items, which are difficult to be revealed by previous conventional sequential methods. Each session is then represented as the composition of the global preference and the current interest of that session using an attention network. Extensive experiments conducted on two real datasets show that SR-GNN evidently outperforms the state-of-the-art session-based recommendation methods consistently."
https://openalex.org/W2963188159,PoseCNN: A Convolutional Neural Network for 6D Object Pose Estimation in Cluttered Scenes,"{'Estimating': [0], 'the': [1, 14, 22, 29, 57, 68, 75, 80, 117, 129, 147, 180, 188], '6D': [2, 52, 112, 123], 'pose': [3, 54, 114, 166], 'of': [4, 24, 31, 60, 79, 125], 'known': [5], 'objects': [6, 25, 127], 'is': [7, 18, 82, 154], 'important': [8], 'for': [9, 51, 111], 'robots': [10], 'to': [11, 21, 86, 99, 150, 157, 177], 'interact': [12], 'with': [13, 136], 'real': [15], 'world.The': [16], 'problem': [17], 'challenging': [19, 189], 'due': [20], 'variety': [23], 'as': [26, 28, 172], 'well': [27], 'complexity': [30], 'a': [32, 46, 87, 92, 106], 'scene': [33], 'caused': [34], 'by': [35, 63, 84], 'clutter': [36], 'and': [37, 70, 146, 163], 'occlusions': [38], 'between': [39], 'objects.In': [40, 102], 'this': [41], 'work,': [42], 'we': [43, 104], 'introduce': [44, 91], 'PoseCNN,': [45], 'new': [47], 'Convolutional': [48], 'Neural': [49], 'Network': [50], 'object': [53, 62, 81, 113], 'estimation.PoseCNN': [55], 'estimates': [56], '3D': [58, 77], 'translation': [59], 'an': [61], 'localizing': [64], 'its': [65, 72], 'center': [66], 'in': [67, 133], 'image': [69], 'predicting': [71], 'distance': [73], 'from': [74, 128], 'camera.The': [76], 'rotation': [78], 'estimated': [83], 'regressing': [85], 'quaternion': [88], 'representation.We': [89], 'also': [90], 'novel': [93], 'loss': [94], 'function': [95], 'that': [96, 152], 'enables': [97], 'PoseCNN': [98, 153], 'handle': [100, 160], 'symmetric': [101, 161], 'addition,': [103], 'contribute': [105], 'large': [107], 'scale': [108], 'video': [109], 'dataset': [110, 120, 131, 145, 149], 'estimation': [115, 167], 'named': [116], 'YCB-Video': [118, 144], 'dataset.Our': [119], 'provides': [121], 'accurate': [122, 165], 'poses': [124], '21': [126], 'YCB': [130], 'observed': [132], '92': [134], 'videos': [135], '133,827': [137], 'frames.We': [138], 'conduct': [139], 'extensive': [140], 'experiments': [141], 'on': [142, 187], 'our': [143, 182], 'OccludedLINEMOD': [148, 190], 'show': [151], 'highly': [155], 'robust': [156], 'occlusions,': [158], 'can': [159], 'objects,': [162], 'provide': [164], 'using': [168, 174], 'only': [169], 'color': [170], 'images': [171], 'input.When': [173], 'depth': [175], 'data': [176], 'further': [178], 'refine': [179], 'poses,': [181], 'approach': [183], 'achieves': [184], 'state-of-the-art': [185], 'results': [186], 'dataset.': [191]}",2018,"['Artificial intelligence', 'Computer science', 'Pose', 'Computer vision', 'Convolutional neural network', 'Clutter', 'Object (grammar)', 'Quaternion', 'Representation (politics)', 'Translation (biology)', 'Object detection', 'Rotation (mathematics)', 'Pattern recognition (psychology)', '3D pose estimation', 'Mathematics', 'Gene', 'Geometry', 'Messenger RNA', 'Biochemistry', 'Law', 'Telecommunications', 'Radar', 'Politics', 'Chemistry', 'Political science']","Estimating the 6D pose of known objects is important for robots to interact with the real world.The problem is challenging due to the variety of objects as well as the complexity of a scene caused by clutter and occlusions between objects.In this work, we introduce PoseCNN, a new Convolutional Neural Network for 6D object pose estimation.PoseCNN estimates the 3D translation of an object by localizing its center in the image and predicting its distance from the camera.The 3D rotation of the object is estimated by regressing to a quaternion representation.We also introduce a novel loss function that enables PoseCNN to handle symmetric objects.In addition, we contribute a large scale video dataset for 6D object pose estimation named the YCB-Video dataset.Our dataset provides accurate 6D poses of 21 objects from the YCB dataset observed in 92 videos with 133,827 frames.We conduct extensive experiments on our YCB-Video dataset and the OccludedLINEMOD dataset to show that PoseCNN is highly robust to occlusions, can handle symmetric objects, and provide accurate pose estimation using only color images as input.When using depth data to further refine the poses, our approach achieves state-of-the-art results on the challenging OccludedLINEMOD dataset."
https://openalex.org/W2762776925,A Deep Learning Approach for Intrusion Detection Using Recurrent Neural Networks,"{'Intrusion': [0], 'detection': [1, 33, 48, 160], 'plays': [2], 'an': [3, 31], 'important': [4], 'role': [5], 'in': [6, 20, 62, 145], 'ensuring': [7], 'information': [8], 'security,': [9], 'and': [10, 39, 65, 68, 73, 100, 131, 148, 161], 'the': [11, 21, 57, 60, 69, 79, 82, 110, 155, 158], 'key': [12], 'technology': [13], 'is': [14, 120, 135], 'to': [15, 29, 137], 'accurately': [16], 'identify': [17], 'various': [18], 'attacks': [19], 'network.': [22], 'In': [23], 'this': [24], 'paper,': [25], 'we': [26, 40, 55], 'explore': [27], 'how': [28], 'model': [30, 61, 127, 153], 'intrusion': [32, 47, 159, 168], 'system': [34], 'based': [35], 'on': [36, 78, 109], 'deep': [37, 43], 'learning,': [38], 'propose': [41], 'a': [42, 125, 163], 'learning': [44, 75, 103, 142], 'approach': [45], 'for': [46, 123, 167], 'using': [49], 'recurrent': [50], 'neural': [51, 93], 'networks': [52], '(RNN-IDS).': [53], 'Moreover,': [54], 'study': [56], 'performance': [58, 80, 134], 'of': [59, 71, 81, 90, 139, 157], 'binary': [63, 147], 'classification': [64, 126, 143], 'multiclass': [66, 149], 'classification,': [67], 'number': [70], 'neurons': [72], 'different': [74], 'rate': [76], 'impacts': [77], 'proposed': [83, 105], 'model.': [84], 'We': [85], 'compare': [86], 'it': [87], 'with': [88, 128], 'those': [89], 'J48,': [91], 'artificial': [92], 'network,': [94], 'random': [95], 'forest,': [96], 'support': [97], 'vector': [98], 'machine,': [99], 'other': [101], 'machine': [102, 141], 'methods': [104, 144], 'by': [106], 'previous': [107], 'researchers': [108], 'benchmark': [111], 'data': [112], 'set.': [113], 'The': [114, 151], 'experimental': [115], 'results': [116], 'show': [117], 'that': [118, 132, 138], 'RNN-IDS': [119, 152], 'very': [121], 'suitable': [122], 'modeling': [124], 'high': [129], 'accuracy': [130, 156], 'its': [133], 'superior': [136], 'traditional': [140], 'both': [146], 'classification.': [150], 'improves': [154], 'provides': [162], 'new': [164], 'research': [165], 'method': [166], 'detection.': [169]}",2017,"['Computer science', 'Artificial intelligence', 'Intrusion detection system', 'Machine learning', 'Recurrent neural network', 'Deep learning', 'Multiclass classification', 'Benchmark (surveying)', 'Support vector machine', 'Random forest', 'C4.5 algorithm', 'Artificial neural network', 'Binary classification', 'Data mining', 'Naive Bayes classifier', 'Geodesy', 'Geography']","Intrusion detection plays an important role in ensuring information security, and the key technology is to accurately identify various attacks in the network. In this paper, we explore how to model an intrusion detection system based on deep learning, and we propose a deep learning approach for intrusion detection using recurrent neural networks (RNN-IDS). Moreover, we study the performance of the model in binary classification and multiclass classification, and the number of neurons and different learning rate impacts on the performance of the proposed model. We compare it with those of J48, artificial neural network, random forest, support vector machine, and other machine learning methods proposed by previous researchers on the benchmark data set. The experimental results show that RNN-IDS is very suitable for modeling a classification model with high accuracy and that its performance is superior to that of traditional machine learning classification methods in both binary and multiclass classification. The RNN-IDS model improves the accuracy of the intrusion detection and provides a new research method for intrusion detection."
https://openalex.org/W2462592242,Pansharpening by Convolutional Neural Networks,"{'A': [0], 'new': [1], 'pansharpening': [2, 25], 'method': [3, 58], 'is': [4], 'proposed,': [5], 'based': [6], 'on': [7, 51], 'convolutional': [8], 'neural': [9], 'networks.': [10], 'We': [11], 'adapt': [12], 'a': [13, 84], 'simple': [14], 'and': [15, 78, 81], 'effective': [16], 'three-layer': [17], 'architecture': [18], 'recently': [19], 'proposed': [20, 57], 'for': [21], 'super-resolution': [22], 'to': [23, 28, 59], 'the': [24, 36, 56, 67, 71], 'problem.': [26], 'Moreover,': [27], 'improve': [29], 'performance': [30], 'without': [31], 'increasing': [32], 'complexity,': [33], 'we': [34], 'augment': [35], 'input': [37], 'by': [38], 'including': [39], 'several': [40], 'maps': [41], 'of': [42, 47, 70, 75], 'nonlinear': [43], 'radiometric': [44], 'indices': [45], 'typical': [46], 'remote': [48], 'sensing.': [49], 'Experiments': [50], 'three': [52], 'representative': [53], 'datasets': [54], 'show': [55], 'provide': [60], 'very': [61], 'promising': [62], 'results,': [63], 'largely': [64], 'competitive': [65], 'with': [66], 'current': [68], 'state': [69], 'art': [72], 'in': [73], 'terms': [74], 'both': [76], 'full-reference': [77], 'no-reference': [79], 'metrics,': [80], 'also': [82], 'at': [83], 'visual': [85], 'inspection.': [86]}",2016,"['Computer science', 'Convolutional neural network', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Remote sensing', 'Geology']","A new pansharpening method is proposed, based on convolutional neural networks. We adapt a simple and effective three-layer architecture recently proposed for super-resolution to the pansharpening problem. Moreover, to improve performance without increasing complexity, we augment the input by including several maps of nonlinear radiometric indices typical of remote sensing. Experiments on three representative datasets show the proposed method to provide very promising results, largely competitive with the current state of the art in terms of both full-reference and no-reference metrics, and also at a visual inspection."
https://openalex.org/W2267635276,Binarized Neural Networks,"{'We': [0, 28], 'introduce': [1], 'a': [2, 37, 81, 92], 'method': [3], 'to': [4, 80, 103], 'train': [5, 46], 'Binarized': [6], 'Neural': [7], 'Networks': [8], '(BNNs)': [9], '-': [10], 'neural': [11], 'networks': [12], 'with': [13, 74, 98, 112], 'binary': [14, 93], 'weights': [15], 'and': [16, 20, 42, 51, 53, 67, 69, 128], 'activations': [17], 'at': [18, 26], 'run-time': [19], 'when': [21], 'computing': [22], 'the': [23, 59], ""parameters'"": [24], 'gradient': [25], 'train-time.': [27], 'conduct': [29], 'two': [30], 'sets': [31], 'of': [32], 'experiments,': [33], 'each': [34], 'based': [35], 'on': [36, 48], 'different': [38], 'framework,': [39], 'namely': [40], 'Torch7': [41], 'Theano,': [43], 'where': [44], 'we': [45, 90], 'BNNs': [47, 62, 131], 'MNIST,': [49], 'CIFAR-10': [50], 'SVHN,': [52], 'achieve': [54], 'nearly': [55], 'state-of-the-art': [56], 'results.': [57], 'During': [58], 'forward': [60], 'pass,': [61], 'drastically': [63], 'reduce': [64], 'memory': [65], 'size': [66], 'accesses,': [68], 'replace': [70], 'most': [71], 'arithmetic': [72], 'operations': [73], 'bit-wise': [75], 'operations,': [76], 'which': [77, 99], 'might': [78], 'lead': [79], 'great': [82], 'increase': [83], 'in': [84, 121], 'power-efficiency.': [85], 'Last': [86], 'but': [87], 'not': [88], 'least,': [89], 'wrote': [91], 'matrix': [94], 'multiplication': [95], 'GPU': [96, 115], 'kernel': [97], 'it': [100], 'is': [101, 132], 'possible': [102], 'run': [104], 'our': [105, 130], 'MNIST': [106], 'BNN': [107], '7': [108], 'times': [109], 'faster': [110], 'than': [111], 'an': [113], 'unoptimized': [114], 'kernel,': [116], 'without': [117], 'suffering': [118], 'any': [119], 'loss': [120], 'classification': [122], 'accuracy.': [123], 'The': [124], 'code': [125], 'for': [126], 'training': [127], 'running': [129], 'available.': [133]}",2016,"['MNIST database', 'Computer science', 'Kernel (algebra)', 'Artificial neural network', 'Multiplication (music)', 'Binary number', 'Code (set theory)', 'Artificial intelligence', 'Deep neural networks', 'Matrix multiplication', 'Binary code', 'Deep learning', 'Machine learning', 'Pattern recognition (psychology)', 'Arithmetic', 'Mathematics', 'Set (abstract data type)', 'Physics', 'Quantum mechanics', 'Quantum', 'Combinatorics', 'Programming language']","We introduce a method to train Binarized Neural Networks (BNNs) - neural networks with binary weights and activations at run-time and when computing the parameters' gradient at train-time. We conduct two sets of experiments, each based on a different framework, namely Torch7 and Theano, where we train BNNs on MNIST, CIFAR-10 and SVHN, and achieve nearly state-of-the-art results. During the forward pass, BNNs drastically reduce memory size and accesses, and replace most arithmetic operations with bit-wise operations, which might lead to a great increase in power-efficiency. Last but not least, we wrote a binary matrix multiplication GPU kernel with which it is possible to run our MNIST BNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy. The code for training and running our BNNs is available."
https://openalex.org/W2531327146,A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks,"{'We': [0, 15, 46, 71], 'consider': [1], 'the': [2, 64, 74, 81], 'two': [3], 'related': [4], 'problems': [5], 'of': [6, 66], 'detecting': [7], 'if': [8], 'an': [9], 'example': [10], 'is': [11], 'misclassified': [12], 'or': [13], 'out-of-distribution.': [14], 'present': [16], 'a': [17], 'simple': [18], 'baseline': [19, 68, 75], 'that': [20], 'utilizes': [21], 'probabilities': [22, 35], 'from': [23], 'softmax': [24, 34], 'distributions.': [25], 'Correctly': [26], 'classified': [27, 38], 'examples': [28], 'tend': [29], 'to': [30], 'have': [31], 'greater': [32], 'maximum': [33], 'than': [36], 'erroneously': [37], 'and': [39, 59], 'out-of-distribution': [40], 'examples,': [41], 'allowing': [42], 'for': [43, 83], 'their': [44], 'detection.': [45], 'assess': [47], 'performance': [48], 'by': [49], 'defining': [50], 'several': [51], 'tasks': [52], 'in': [53], 'computer': [54], 'vision,': [55], 'natural': [56], 'language': [57], 'processing,': [58], 'automatic': [60], 'speech': [61], 'recognition,': [62], 'showing': [63], 'effectiveness': [65], 'this': [67], 'across': [69], 'all.': [70], 'then': [72], 'show': [73], 'can': [76], 'sometimes': [77], 'be': [78], 'surpassed,': [79], 'demonstrating': [80], 'room': [82], 'future': [84], 'research': [85], 'on': [86], 'these': [87], 'underexplored': [88], 'detection': [89], 'tasks.': [90]}",2016,"['Baseline (sea)', 'Artificial neural network', 'Computer science', 'Distribution (mathematics)', 'Artificial intelligence', 'Mathematics', 'Geology', 'Mathematical analysis', 'Oceanography']","We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks."
https://openalex.org/W2584483805,Low-Dose CT With a Residual Encoder-Decoder Convolutional Neural Network,"{'Given': [0], 'the': [1, 8, 18, 23, 55, 59, 63, 66, 86, 94, 102, 116], 'potential': [2], 'risk': [3], 'of': [4, 57, 88, 142], 'X-ray': [5], 'radiation': [6], 'to': [7, 41, 50, 54, 124], 'patient,': [9], 'low-dose': [10, 26, 110], 'CT': [11, 27, 111], 'has': [12, 136], 'attracted': [13], 'a': [14, 120], 'considerable': [15], 'interest': [16], 'in': [17, 62, 127, 140], 'medical': [19], 'imaging': [20], 'field.': [21], 'Currently,': [22], 'main': [24], 'stream': [25], 'methods': [28, 68, 126], 'include': [29], 'vendor-specific': [30], 'sinogram': [31], 'domain': [32], 'filtration': [33], 'and': [34, 98, 130, 147], 'iterative': [35], 'reconstruction': [36], 'algorithms,': [37], 'but': [38], 'they': [39], 'need': [40], 'access': [42], 'raw': [43], 'data,': [44], 'whose': [45], 'formats': [46], 'are': [47], 'not': [48], 'transparent': [49], 'most': [51], 'users.': [52], 'Due': [53], 'difficulty': [56], 'modeling': [58], 'statistical': [60], 'characteristics': [61], 'image': [64, 76], 'domain,': [65], 'existing': [67], 'for': [69, 109], 'directly': [70], 'processing': [71], 'reconstructed': [72], 'images': [73], 'cannot': [74], 'eliminate': [75], 'noise': [77, 143], 'very': [78], 'well': [79], 'while': [80], 'keeping': [81], 'structural': [82, 145], 'details.': [83], 'Inspired': [84], 'by': [85], 'idea': [87], 'deep': [89], 'learning,': [90], 'here': [91], 'we': [92], 'combine': [93], 'autoencoder,': [95], 'deconvolution': [96], 'network,': [97], 'shortcut': [99], 'connections': [100], 'into': [101], 'residual': [103], 'encoder-decoder': [104], 'convolutional': [105], 'neural': [106], 'network': [107], '(RED-CNN)': [108], 'imaging.': [112], 'After': [113], 'patch-based': [114], 'training,': [115], 'proposed': [117], 'RED-CNN': [118], 'achieves': [119], 'competitive': [121], 'performance': [122], 'relative': [123], 'the-state-of-art': [125], 'both': [128], 'simulated': [129], 'clinical': [131], 'cases.': [132], 'Especially,': [133], 'our': [134], 'method': [135], 'been': [137], 'favorably': [138], 'evaluated': [139], 'terms': [141], 'suppression,': [144], 'preservation,': [146], 'lesion': [148], 'detection.': [149]}",2017,"['Convolutional neural network', 'Residual', 'Encoder', 'Computer science', 'Convolutional code', 'Artificial intelligence', 'Decoding methods', 'Computer vision', 'Pattern recognition (psychology)', 'Algorithm', 'Operating system']","Given the potential risk of X-ray radiation to the patient, low-dose CT has attracted a considerable interest in the medical imaging field. Currently, the main stream low-dose CT methods include vendor-specific sinogram domain filtration and iterative reconstruction algorithms, but they need to access raw data, whose formats are not transparent to most users. Due to the difficulty of modeling the statistical characteristics in the image domain, the existing methods for directly processing reconstructed images cannot eliminate image noise very well while keeping structural details. Inspired by the idea of deep learning, here we combine the autoencoder, deconvolution network, and shortcut connections into the residual encoder-decoder convolutional neural network (RED-CNN) for low-dose CT imaging. After patch-based training, the proposed RED-CNN achieves a competitive performance relative to the-state-of-art methods in both simulated and clinical cases. Especially, our method has been favorably evaluated in terms of noise suppression, structural preservation, and lesion detection."
https://openalex.org/W2949541494,Convolutional Neural Networks for Sentence Classification,"{'We': [0, 23, 52], 'report': [1], 'on': [2, 13, 39, 84], 'a': [3, 26, 55], 'series': [4], 'of': [5, 15, 66, 81, 87], 'experiments': [6], 'with': [7, 29], 'convolutional': [8], 'neural': [9], 'networks': [10], '(CNN)': [11], 'trained': [12], 'top': [14], 'pre-trained': [16], 'word': [17], 'vectors': [18, 35, 44], 'for': [19, 63], 'sentence-level': [20], 'classification': [21], 'tasks.': [22], 'show': [24], 'that': [25], 'simple': [27, 56], 'CNN': [28, 73], 'little': [30], 'hyperparameter': [31], 'tuning': [32], 'and': [33, 69, 94], 'static': [34, 70], 'achieves': [36], 'excellent': [37], 'results': [38], 'multiple': [40], 'benchmarks.': [41], 'Learning': [42], 'task-specific': [43, 68], 'through': [45], 'fine-tuning': [46], 'offers': [47], 'further': [48], 'gains': [49], 'in': [50], 'performance.': [51], 'additionally': [53], 'propose': [54], 'modification': [57], 'to': [58, 61], 'the': [59, 64, 79, 82], 'architecture': [60], 'allow': [62], 'use': [65], 'both': [67], 'vectors.': [71], 'The': [72], 'models': [74], 'discussed': [75], 'herein': [76], 'improve': [77], 'upon': [78], 'state': [80], 'art': [83], '4': [85], 'out': [86], '7': [88], 'tasks,': [89], 'which': [90], 'include': [91], 'sentiment': [92], 'analysis': [93], 'question': [95], 'classification.': [96]}",2014,"['Hyperparameter', 'Computer science', 'Convolutional neural network', 'Sentence', 'Artificial intelligence', 'Task (project management)', 'Word (group theory)', 'Simple (philosophy)', 'Machine learning', 'Natural language processing', 'Pattern recognition (psychology)', 'Mathematics', 'Engineering', 'Geometry', 'Epistemology', 'Philosophy', 'Systems engineering']","We report on a series of experiments with convolutional neural networks (CNN) trained on top of pre-trained word vectors for sentence-level classification tasks. We show that a simple CNN with little hyperparameter tuning and static vectors achieves excellent results on multiple benchmarks. Learning task-specific vectors through fine-tuning offers further gains in performance. We additionally propose a simple modification to the architecture to allow for the use of both task-specific and static vectors. The CNN models discussed herein improve upon the state of the art on 4 out of 7 tasks, which include sentiment analysis and question classification."
https://openalex.org/W2250966211,Document Modeling with Gated Recurrent Neural Network for Sentiment Classification,"{'Document': [0], 'level': [1, 74], 'sentiment': [2, 75, 118], 'classification': [3, 76], 'remains': [4], 'a': [5, 18, 25, 35], 'challenge:': [6], 'encoding': [7], 'the': [8, 14], 'intrinsic': [9], 'relations': [10, 59], 'between': [11], 'sentences': [12, 56], 'in': [13, 34, 63, 114], 'semantic': [15], 'meaning': [16], 'of': [17, 55], 'document.': [19], 'To': [20], 'address': [21], 'this,': [22], 'we': [23], 'introduce': [24], 'neural': [26, 47, 69, 94, 106, 112], 'network': [27, 48, 107, 113], 'model': [28, 40, 95], 'to': [29], 'learn': [30], 'vector-based': [31], 'document': [32, 64, 73, 115], 'representation': [33, 44, 65], 'unified,': [36], 'bottom-up': [37], 'fashion.': [38], 'The': [39], 'first': [41], 'learns': [42], 'sentence': [43], 'with': [45, 66], 'convolutional': [46], 'or': [49], 'long': [50], 'short-term': [51], 'memory.': [52], 'Afterwards,': [53], 'semantics': [54], 'and': [57, 84], 'their': [58], 'are': [60], 'adaptively': [61], 'encoded': [62], 'gated': [67, 104], 'recurrent': [68, 105, 111], 'network.': [70], 'We': [71], 'conduct': [72], 'on': [77], 'four': [78], 'large-scale': [79], 'review': [80], 'datasets': [81], 'from': [82], 'IMDB': [83], 'Yelp': [85], 'Dataset': [86], 'Challenge.': [87], 'Experimental': [88], 'results': [89], 'show': [90], 'that:': [91], '(1)': [92], 'our': [93], 'shows': [96], 'superior': [97], 'performances': [98], 'over': [99], 'several': [100], 'state-of-the-art': [101], 'algorithms;': [102], '(2)': [103], 'dramatically': [108], 'outperforms': [109], 'standard': [110], 'modeling': [116], 'for': [117], 'classification.': [119], '1': [120]}",2015,"['Computer science', 'Artificial intelligence', 'Artificial neural network', 'Natural language processing']","Document level sentiment classification remains a challenge: encoding the intrinsic relations between sentences in the semantic meaning of a document. To address this, we introduce a neural network model to learn vector-based document representation in a unified, bottom-up fashion. The model first learns sentence representation with convolutional neural network or long short-term memory. Afterwards, semantics of sentences and their relations are adaptively encoded in document representation with gated recurrent neural network. We conduct document level sentiment classification on four large-scale review datasets from IMDB and Yelp Dataset Challenge. Experimental results show that: (1) our neural model shows superior performances over several state-of-the-art algorithms; (2) gated recurrent neural network dramatically outperforms standard recurrent neural network in document modeling for sentiment classification. 1"
https://openalex.org/W2963358464,Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic\n Forecasting,"{'Spatiotemporal': [0], 'forecasting': [1, 11, 75], 'has': [2], 'various': [3], 'applications': [4], 'in': [5, 82], 'neuroscience,': [6], 'climate\\nand': [7], 'transportation': [8], 'domain.': [9], 'Traffic': [10], 'is': [12, 21], 'one': [13], 'canonical': [14], 'example': [15], 'of': [16, 42, 123], 'such\\nlearning': [17], 'task.': [18], 'The': [19], 'task': [20], 'challenging': [22], 'due': [23], 'to': [24, 50], '(1)': [25], 'complex': [26], 'spatial': [27, 78, 89], 'dependency': [28, 81, 90, 100], 'on\\nroad': [29], 'networks,': [30], '(2)': [31], 'non-linear': [32], 'temporal': [33, 80, 99], 'dynamics': [34], 'with': [35], 'changing': [36], 'road': [37], 'conditions\\nand': [38], '(3)': [39], 'inherent': [40], 'difficulty': [41], 'long-term': [43], 'forecasting.': [44], 'To': [45], 'address': [46], 'these\\nchallenges,': [47], 'we': [48], 'propose': [49], 'model': [51], 'the': [52, 83, 88, 96, 98, 102, 109], 'traffic': [53, 74, 84, 117], 'flow': [54], 'as': [55], 'a': [56, 69], 'diffusion': [57], 'process': [58], 'on': [59, 95, 111], 'a\\ndirected': [60], 'graph': [61], 'and': [62, 79, 119], 'introduce': [63], 'Diffusion': [64], 'Convolutional': [65], 'Recurrent': [66], 'Neural': [67], 'Network\\n(DCRNN),': [68], 'deep': [70], 'learning': [71], 'framework': [72, 110], 'for': [73], 'that': [76], 'incorporates\\nboth': [77], 'flow.': [85], 'Specifically,': [86], 'DCRNN\\ncaptures': [87], 'using': [91, 101], 'bidirectional': [92], 'random': [93], 'walks': [94], 'graph,\\nand': [97], 'encoder-decoder': [103], 'architecture': [104], 'with\\nscheduled': [105], 'sampling.': [106], 'We': [107], 'evaluate': [108], 'two': [112], 'real-world': [113], 'large': [114], 'scale\\nroad': [115], 'network': [116], 'datasets': [118], 'observe': [120], 'consistent': [121], 'improvement': [122], '12%': [124], '-': [125], '15%\\nover': [126], 'state-of-the-art': [127], 'baselines.\\n': [128]}",2017,"['Convolutional neural network', 'Computer science', 'Diffusion', 'Artificial intelligence', 'Artificial neural network', 'Data mining', 'Physics', 'Thermodynamics']","Spatiotemporal forecasting has various applications in neuroscience, climate\nand transportation domain. Traffic forecasting is one canonical example of such\nlearning task. The task is challenging due to (1) complex spatial dependency on\nroad networks, (2) non-linear temporal dynamics with changing road conditions\nand (3) inherent difficulty of long-term forecasting. To address these\nchallenges, we propose to model the traffic flow as a diffusion process on a\ndirected graph and introduce Diffusion Convolutional Recurrent Neural Network\n(DCRNN), a deep learning framework for traffic forecasting that incorporates\nboth spatial and temporal dependency in the traffic flow. Specifically, DCRNN\ncaptures the spatial dependency using bidirectional random walks on the graph,\nand the temporal dependency using the encoder-decoder architecture with\nscheduled sampling. We evaluate the framework on two real-world large scale\nroad network traffic datasets and observe consistent improvement of 12% - 15%\nover state-of-the-art baselines.\n"
https://openalex.org/W1479807131,Semi-Supervised Learning,"{'A': [0], 'comprehensive': [1, 95], 'review': [2], 'of': [3, 6, 14, 24, 38, 78, 97, 104, 140, 146, 157, 194, 214], 'an': [4, 155], 'area': [5], 'machine': [7, 39], 'learning': [8, 42, 50, 60, 219], 'that': [9, 164, 174], 'deals': [10], 'with': [11, 211], 'the': [12, 25, 36, 45, 105, 121, 127, 141, 144, 160, 166, 192, 199, 215], 'use': [13], 'unlabeled': [15, 83], 'data': [16, 65, 84], 'in': [17, 69, 73, 81], 'classification': [18], 'problems:': [19], 'state-of-the-art': [20, 100], 'algorithms,': [21, 101], 'a': [22, 102, 212], 'taxonomy': [23, 103], 'field,': [26, 106], 'applications,': [27, 108], 'benchmark': [28, 109, 196], 'experiments,': [29, 110], 'and': [30, 58, 91, 111, 115, 124, 136, 172, 184, 220], 'directions': [31, 204], 'for': [32, 187, 205], 'future': [33, 116], 'research.': [34, 207], 'In': [35], 'field': [37], 'learning,': [40], 'semi-supervised': [41, 218], '(SSL)': [43], 'occupies': [44], 'middle': [46], 'ground,': [47], 'between': [48, 217], 'supervised': [49], '(in': [51, 61], 'which': [52, 62, 82], 'all': [53], 'training': [54], 'examples': [55], 'are': [56, 66, 85], 'labeled)': [57], 'unsupervised': [59], 'no': [63], 'label': [64], 'given).': [67], 'Interest': [68], 'SSL': [70, 98, 147, 182, 188, 206], 'has': [71], 'increased': [72], 'recent': [74], 'years,': [75], 'particularly': [76], 'because': [77], 'application': [79], 'domains': [80], 'plentiful,': [86], 'such': [87], 'as': [88], 'images,': [89], 'text,': [90], 'bioinformatics.': [92], 'This': [93], 'first': [94, 119], 'overview': [96], 'presents': [99, 120], 'selected': [107], 'perspectives': [112], 'on': [113], 'ongoing': [114], 'research.Semi-Supervised': [117], 'Learning': [118], 'key': [122], 'assumptions': [123], 'ideas': [125], 'underlying': [126], 'field:': [128], 'smoothness,': [129], 'cluster': [130], 'or': [131], 'low-density': [132, 167], 'separation,': [133], 'manifold': [134], 'structure,': [135], 'transduction.': [137, 221], 'The': [138, 178, 208], 'core': [139], 'book': [142, 161, 179, 200, 209], 'is': [143], 'presentation': [145], 'methods,': [148, 171], 'organized': [149], 'according': [150], 'to': [151], 'algorithmic': [152], 'strategies.': [153], 'After': [154], 'examination': [156], 'generative': [158], 'models,': [159], 'describes': [162], 'algorithms': [163, 173], 'implement': [165], 'separation': [168], 'assumption,': [169], 'graph-based': [170], 'perform': [175], 'two-step': [176], 'learning.': [177], 'then': [180], 'discusses': [181], 'applications': [183], 'offers': [185], 'guidelines': [186], 'practitioners': [189], 'by': [190], 'analyzing': [191], 'results': [193], 'extensive': [195], 'experiments.': [197], 'Finally,': [198], 'looks': [201], 'at': [202], 'interesting': [203], 'closes': [210], 'discussion': [213], 'relationship': [216]}",2006,"['Computer science', 'Artificial intelligence', 'Machine learning', 'Benchmark (surveying)', 'Field (mathematics)', 'Unsupervised learning', 'Semi-supervised learning', 'Graph', 'Taxonomy (biology)', 'Theoretical computer science', 'Mathematics', 'Pure mathematics', 'Biology', 'Geodesy', 'Botany', 'Geography']","A comprehensive review of an area of machine learning that deals with the use of unlabeled data in classification problems: state-of-the-art algorithms, a taxonomy of the field, applications, benchmark experiments, and directions for future research. In the field of machine learning, semi-supervised learning (SSL) occupies the middle ground, between supervised learning (in which all training examples are labeled) and unsupervised learning (in which no label data are given). Interest in SSL has increased in recent years, particularly because of application domains in which unlabeled data are plentiful, such as images, text, and bioinformatics. This first comprehensive overview of SSL presents state-of-the-art algorithms, a taxonomy of the field, selected applications, benchmark experiments, and perspectives on ongoing and future research.Semi-Supervised Learning first presents the key assumptions and ideas underlying the field: smoothness, cluster or low-density separation, manifold structure, and transduction. The core of the book is the presentation of SSL methods, organized according to algorithmic strategies. After an examination of generative models, the book describes algorithms that implement the low-density separation assumption, graph-based methods, and algorithms that perform two-step learning. The book then discusses SSL applications and offers guidelines for SSL practitioners by analyzing the results of extensive benchmark experiments. Finally, the book looks at interesting directions for SSL research. The book closes with a discussion of the relationship between semi-supervised learning and transduction."
https://openalex.org/W2136504847,Semi-Supervised Learning Literature Survey,"{'We': [0], 'review': [1], 'the': [2, 47, 53, 58, 64, 68, 72], 'literature': [3], 'on': [4, 27], 'semi-supervised': [5, 38], 'learning,': [6], 'which': [7], 'is': [8, 42], 'an': [9], 'area': [10], 'in': [11, 67], 'machine': [12], 'learning': [13], 'and': [14, 34], 'more': [15], 'generally,': [16], 'artificial': [17], 'intelligence.': [18], 'There': [19], 'has': [20], 'been': [21], 'a': [22, 43], 'whole&#13;\\nspectrum': [23], 'of': [24], 'interesting': [25], 'ideas': [26], 'how': [28], 'to': [29, 56, 62], 'learn': [30], 'from': [31, 46], 'both': [32], 'labeled': [33], 'unlabeled': [35], 'data,': [36], 'i.e.': [37], 'learning.': [39], 'This': [40], 'document': [41], 'chapter': [44], 'excerpt': [45], 'author’s&#13;\\ndoctoral': [48], 'thesis': [49], '(Zhu,': [50], '2005).': [51], 'However': [52], 'author': [54], 'plans': [55], 'update': [57], 'online': [59], 'version': [60], 'frequently': [61], 'incorporate': [63], 'latest': [65], 'development': [66], 'field.': [69], 'Please': [70], 'obtain': [71], 'latest&#13;\\nversion': [73], 'at': [74], 'http://www.cs.wisc.edu/~jerryzhu/pub/ssl_survey.pdf': [75]}",2005,"['Computer science', 'Artificial intelligence']","We review the literature on semi-supervised learning, which is an area in machine learning and more generally, artificial intelligence. There has been a whole&#13;\nspectrum of interesting ideas on how to learn from both labeled and unlabeled data, i.e. semi-supervised learning. This document is a chapter excerpt from the author’s&#13;\ndoctoral thesis (Zhu, 2005). However the author plans to update the online version frequently to incorporate the latest development in the field. Please obtain the latest&#13;\nversion at http://www.cs.wisc.edu/~jerryzhu/pub/ssl_survey.pdf"
https://openalex.org/W2996428491,ALBERT: A Lite BERT for Self-supervised Learning of Language\n Representations,"{'Increasing': [0], 'model': [1, 19, 92], 'size': [2], 'when': [3], 'pretraining': [4], 'natural': [5], 'language': [6], 'representations': [7], 'often\\nresults': [8], 'in': [9], 'improved': [10], 'performance': [11], 'on': [12, 75, 96], 'downstream': [13, 83], 'tasks.': [14], 'However,': [15], 'at': [16, 116], 'some': [17], 'point\\nfurther': [18], 'increases': [20], 'become': [21], 'harder': [22], 'due': [23], 'to': [24, 39, 57, 64, 107], 'GPU/TPU': [25], 'memory': [26, 41], 'limitations': [27], 'and\\nlonger': [28], 'training': [29], 'times.': [30], 'To': [31], 'address': [32], 'these': [33], 'problems,': [34], 'we': [35], 'present': [36], 'two\\nparameter-reduction': [37], 'techniques': [38], 'lower': [40], 'consumption': [42], 'and': [43, 78, 100, 111], 'increase': [44], 'the\\ntraining': [45], 'speed': [46], 'of': [47], 'BERT.': [48], 'Comprehensive': [49], 'empirical': [50], 'evidence': [51], 'shows': [52], 'that': [53, 59, 73], 'our\\nproposed': [54], 'methods': [55], 'lead': [56], 'models': [58, 114], 'scale': [60], 'much': [61], 'better': [62], 'compared': [63, 106], 'the': [65, 97, 112], 'original\\nBERT.': [66], 'We': [67], 'also': [68], 'use': [69], 'a': [70, 88], 'self-supervised': [71], 'loss': [72], 'focuses': [74], 'modeling\\ninter-sentence': [76], 'coherence,': [77], 'show': [79], 'it': [80], 'consistently': [81], 'helps': [82], 'tasks': [84], 'with\\nmulti-sentence': [85], 'inputs.': [86], 'As': [87], 'result,': [89], 'our': [90], 'best': [91], 'establishes': [93], 'new\\nstate-of-the-art': [94], 'results': [95], 'GLUE,': [98], 'RACE,': [99], '\\\\squad': [101], 'benchmarks': [102], 'while': [103], 'having\\nfewer': [104], 'parameters': [105], 'BERT-large.': [108], 'The': [109], 'code': [110], 'pretrained': [113], 'are\\navailable': [115], 'https://github.com/google-research/ALBERT.\\n': [117]}",2019,"['Computer science', 'Sentence', 'Language model', 'Artificial intelligence', 'Code (set theory)', 'Natural language processing', 'Point (geometry)', 'Coherence (philosophical gambling strategy)', 'Machine learning', 'Programming language', 'Set (abstract data type)', 'Physics', 'Geometry', 'Mathematics', 'Quantum mechanics']","Increasing model size when pretraining natural language representations often\nresults in improved performance on downstream tasks. However, at some point\nfurther model increases become harder due to GPU/TPU memory limitations and\nlonger training times. To address these problems, we present two\nparameter-reduction techniques to lower memory consumption and increase the\ntraining speed of BERT. Comprehensive empirical evidence shows that our\nproposed methods lead to models that scale much better compared to the original\nBERT. We also use a self-supervised loss that focuses on modeling\ninter-sentence coherence, and show it consistently helps downstream tasks with\nmulti-sentence inputs. As a result, our best model establishes new\nstate-of-the-art results on the GLUE, RACE, and \\squad benchmarks while having\nfewer parameters compared to BERT-large. The code and the pretrained models are\navailable at https://github.com/google-research/ALBERT.\n"
https://openalex.org/W2984353870,A survey on semi-supervised learning,"{'Abstract': [0], 'Semi-supervised': [1], 'learning': [2, 8, 21, 134, 157, 244], 'is': [3], 'the': [4, 33, 62, 83, 114, 152, 171, 184, 191, 199, 220, 231, 238, 257], 'branch': [5], 'of': [6, 36, 50, 97, 116, 132, 155, 183, 212], 'machine': [7, 67], 'concerned': [9], 'with': [10, 46, 69, 179, 195], 'using': [11], 'labelled': [12, 51], 'as': [13, 15, 139, 141, 173, 175], 'well': [14, 140, 174], 'unlabelled': [16, 37, 228], 'data': [17, 38, 229], 'to': [18, 107, 121, 164, 170, 249, 256], 'perform': [19], 'certain': [20], 'tasks.': [22], 'Conceptually': [23], 'situated': [24], 'between': [25], 'supervised': [26], 'and': [27, 77, 90, 100, 109, 118, 167, 187, 202, 223, 252], 'unsupervised': [28], 'learning,': [29, 68], 'it': [30], 'permits': [31], 'harnessing': [32], 'large': [34, 153], 'amounts': [35], 'available': [39], 'in': [40, 44, 57, 66, 88], 'many': [41], 'use': [42], 'cases': [43], 'combination': [45], 'typically': [47], 'smaller': [48], 'sets': [49], 'data.': [52], 'In': [53], 'recent': [54, 104, 143], 'years,': [55], 'research': [56, 158], 'this': [58, 111, 125], 'area': [59], 'has': [60, 85], 'followed': [61], 'general': [63], 'trends': [64], 'observed': [65], 'much': [70], 'attention': [71], 'directed': [72], 'at': [73], 'neural': [74], 'network-based': [75], 'models': [76], 'generative': [78], 'learning.': [79], 'The': [80], 'literature': [81], 'on': [82, 148, 198, 219], 'topic': [84], 'also': [86], 'expanded': [87], 'volume': [89], 'scope,': [91], 'now': [92], 'encompassing': [93], 'a': [94, 180, 209], 'broad': [95], 'spectrum': [96], 'theory,': [98], 'algorithms': [99, 188, 245], 'applications.': [101], 'However,': [102], 'no': [103], 'surveys': [105], 'exist': [106], 'collect': [108], 'organize': [110], 'knowledge,': [112], 'impeding': [113], 'ability': [115], 'researchers': [117, 166], 'engineers': [119], 'alike': [120], 'utilize': [122], 'it.': [123], 'Filling': [124], 'void,': [126], 'we': [127, 207, 235], 'present': [128], 'an': [129, 196], 'up-to-date': [130], 'overview': [131], 'semi-supervised': [133, 149, 156, 213, 243, 259], 'methods,': [135], 'covering': [136], 'earlier': [137], 'work': [138], 'more': [142, 176], 'advances.': [144], 'We': [145], 'focus': [146], 'primarily': [147], 'classification,': [150], 'where': [151], 'majority': [154], 'takes': [159], 'place.': [160], 'Our': [161], 'survey': [162], 'aims': [163], 'provide': [165], 'practitioners': [168], 'new': [169, 210], 'field': [172], 'advanced': [177], 'readers': [178], 'solid': [181], 'understanding': [182], 'main': [185], 'approaches': [186, 225], 'developed': [189], 'over': [190], 'past': [192], 'two': [193], 'decades,': [194], 'emphasis': [197], 'most': [200, 242], 'prominent': [201], 'currently': [203], 'relevant': [204], 'work.': [205], 'Furthermore,': [206], 'propose': [208], 'taxonomy': [211], 'classification': [214], 'algorithms,': [215], 'which': [216], 'sheds': [217], 'light': [218], 'different': [221], 'conceptual': [222], 'methodological': [224], 'for': [226], 'incorporating': [227], 'into': [230], 'training': [232], 'process.': [233], 'Lastly,': [234], 'show': [236], 'how': [237, 253], 'fundamental': [239], 'assumptions': [240], 'underlying': [241], 'are': [246], 'closely': [247], 'connected': [248], 'each': [250], 'other,': [251], 'they': [254], 'relate': [255], 'well-known': [258], 'clustering': [260], 'assumption.': [261]}",2019,"['Artificial intelligence', 'Machine learning', 'Computer science', 'Supervised learning', 'Unsupervised learning', 'Scope (computer science)', 'Semi-supervised learning', 'Artificial neural network', 'Field (mathematics)', 'Data science', 'Mathematics', 'Programming language', 'Pure mathematics']","Abstract Semi-supervised learning is the branch of machine learning concerned with using labelled as well as unlabelled data to perform certain learning tasks. Conceptually situated between supervised and unsupervised learning, it permits harnessing the large amounts of unlabelled data available in many use cases in combination with typically smaller sets of labelled data. In recent years, research in this area has followed the general trends observed in machine learning, with much attention directed at neural network-based models and generative learning. The literature on the topic has also expanded in volume and scope, now encompassing a broad spectrum of theory, algorithms and applications. However, no recent surveys exist to collect and organize this knowledge, impeding the ability of researchers and engineers alike to utilize it. Filling this void, we present an up-to-date overview of semi-supervised learning methods, covering earlier work as well as more recent advances. We focus primarily on semi-supervised classification, where the large majority of semi-supervised learning research takes place. Our survey aims to provide researchers and practitioners new to the field as well as more advanced readers with a solid understanding of the main approaches and algorithms developed over the past two decades, with an emphasis on the most prominent and currently relevant work. Furthermore, we propose a new taxonomy of semi-supervised classification algorithms, which sheds light on the different conceptual and methodological approaches for incorporating unlabelled data into the training process. Lastly, we show how the fundamental assumptions underlying most semi-supervised learning algorithms are closely connected to each other, and how they relate to the well-known semi-supervised clustering assumption."
https://openalex.org/W3035060554,Bootstrap your own latent: A new approach to self-supervised Learning,"{'We': [0, 119], 'introduce': [1], 'Bootstrap': [2], 'Your': [3], 'Own': [4], 'Latent': [5], '(BYOL),': [6], 'a': [7, 58, 72, 89, 106, 110, 116], 'new': [8, 90], 'approach': [9], 'to': [10, 22, 47], 'self-supervised': [11], 'image': [12, 56], 'representation': [13, 52], 'learning.': [14], 'BYOL': [15, 87, 97, 122], 'relies': [16], 'on': [17, 84, 103, 124, 135, 148], 'two': [18], 'neural': [19], 'networks,': [20, 27], 'referred': [21], 'as': [23], 'online': [24, 45, 77], 'and': [25, 30, 113, 138, 143], 'target': [26, 50, 69], 'that': [28, 121], 'interact': [29], 'learn': [31], 'from': [32], 'each': [33], 'other.': [34], 'From': [35], 'an': [36, 40], 'augmented': [37, 60], 'view': [38], 'of': [39, 53, 75, 92, 132], 'image,': [41], 'we': [42, 66], 'train': [43], 'the': [44, 49, 54, 63, 68, 76, 93, 129, 133], 'network': [46, 51, 70], 'predict': [48], 'same': [55, 64], 'under': [57], 'different': [59], 'view.': [61], 'At': [62], 'time,': [65], 'update': [67], 'with': [71, 109, 115], 'slow-moving': [73], 'average': [74], 'network.': [78], 'While': [79], 'state-of-the': [80], 'art': [81, 94, 134], 'methods': [82], 'rely': [83], 'negative': [85], 'pairs,': [86], 'achieves': [88], 'state': [91, 131], 'without': [95], 'them.': [96], 'reaches': [98], '$74.3\\%$': [99], 'top-1': [100], 'classification': [101], 'accuracy': [102], 'ImageNet': [104], 'using': [105], 'linear': [107], 'evaluation': [108], 'ResNet-50': [111], 'architecture': [112], '$79.6\\%$': [114], 'larger': [117], 'ResNet.': [118], 'show': [120], 'performs': [123], 'par': [125], 'or': [126], 'better': [127], 'than': [128], 'current': [130], 'both': [136], 'transfer': [137], 'semi-supervised': [139], 'benchmarks.': [140], 'Our': [141], 'implementation': [142], 'pretrained': [144], 'models': [145], 'are': [146], 'given': [147], 'GitHub.': [149]}",2020,"['Computer science', 'Artificial intelligence', 'Machine learning', 'Econometrics', 'Psychology', 'Mathematics']","We introduce Bootstrap Your Own Latent (BYOL), a new approach to self-supervised image representation learning. BYOL relies on two neural networks, referred to as online and target networks, that interact and learn from each other. From an augmented view of an image, we train the online network to predict the target network representation of the same image under a different augmented view. At the same time, we update the target network with a slow-moving average of the online network. While state-of-the art methods rely on negative pairs, BYOL achieves a new state of the art without them. BYOL reaches $74.3\%$ top-1 classification accuracy on ImageNet using a linear evaluation with a ResNet-50 architecture and $79.6\%$ with a larger ResNet. We show that BYOL performs on par or better than the current state of the art on both transfer and semi-supervised benchmarks. Our implementation and pretrained models are given on GitHub."
https://openalex.org/W2530395818,Equality of Opportunity in Supervised Learning,"{'We': [0, 116, 142], 'propose': [1], 'a': [2, 7, 147], 'criterion': [3], 'for': [4], 'discrimination': [5, 53], 'against': [6], 'specified': [8], 'sensitive': [9], 'attribute': [10], 'in': [11, 34], 'supervised': [12], 'learning,': [13], 'where': [14], 'the': [15, 29, 35, 65, 74, 82, 98, 102, 104, 107, 118], 'goal': [16], 'is': [17, 92], 'to': [18, 43, 51, 55, 73], 'predict': [19], 'some': [20], 'target': [21, 105], 'based': [22, 126], 'on': [23, 97, 112, 127], 'available': [24], 'features.': [25], 'Assuming': [26], 'data': [27], 'about': [28], 'predictor,': [30, 103], 'target,': [31], 'and': [32, 106, 123, 134], 'membership': [33], 'protected': [36, 108], 'group': [37], 'are': [38], 'available,': [39], 'we': [40], 'show': [41], 'how': [42], 'optimally': [44], 'adjust': [45], 'any': [46], 'learned': [47], 'predictor': [48], 'so': [49], 'as': [50], 'remove': [52], 'according': [54], 'our': [56, 90, 144], 'definition.': [57], 'Our': [58], 'framework': [59], 'also': [60], 'improves': [61], 'incentives': [62], 'by': [63, 80], 'shifting': [64], 'cost': [66], 'of': [67, 101, 114, 121, 150], 'poor': [68], 'classification': [69, 83], 'from': [70, 138], 'disadvantaged': [71], 'groups': [72], 'decision': [75], 'maker,': [76], 'who': [77], 'can': [78, 133], 'respond': [79], 'improving': [81], 'accuracy.': [84], 'In': [85], 'line': [86], 'with': [87], 'other': [88], 'studies,': [89], 'notion': [91, 145], 'oblivious:': [93], 'it': [94], 'depends': [95], 'only': [96], 'joint': [99], 'statistics': [100], 'attribute,': [109], 'but': [110], 'not': [111], 'interpretation': [113], 'individualfeatures.': [115], 'study': [117, 149], 'inherent': [119], 'limits': [120], 'defining': [122], 'identifying': [124], 'biases': [125], 'such': [128], 'oblivious': [129, 140], 'measures,': [130], 'outlining': [131], 'what': [132], 'cannot': [135], 'be': [136], 'inferred': [137], 'different': [139], 'tests.': [141], 'illustrate': [143], 'using': [146], 'case': [148], 'FICO': [151], 'credit': [152], 'scores.': [153]}",2016,"['Computer science', 'Interpretation (philosophy)', 'Disadvantaged', 'Machine learning', 'Artificial intelligence', 'Incentive', 'Decision maker', 'Line (geometry)', 'Mathematics', 'Microeconomics', 'Operations research', 'Economics', 'Programming language', 'Economic growth', 'Geometry']","We propose a criterion for discrimination against a specified sensitive attribute in supervised learning, where the goal is to predict some target based on available features. Assuming data about the predictor, target, and membership in the protected group are available, we show how to optimally adjust any learned predictor so as to remove discrimination according to our definition. Our framework also improves incentives by shifting the cost of poor classification from disadvantaged groups to the decision maker, who can respond by improving the classification accuracy. In line with other studies, our notion is oblivious: it depends only on the joint statistics of the predictor, the target and the protected attribute, but not on interpretation of individualfeatures. We study the inherent limits of defining and identifying biases based on such oblivious measures, outlining what can and cannot be inferred from different oblivious tests. We illustrate our notion using a case study of FICO credit scores."
https://openalex.org/W3001197829,FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence,"{'Semi-supervised': [0], 'learning': [1, 100], '(SSL)': [2], 'provides': [3], 'an': [4, 137], 'effective': [5], 'means': [6], 'of': [7, 23, 27, 80, 97], 'leveraging': [8], 'unlabeled': [9, 48], 'data': [10], 'to': [11, 71, 126, 141, 151], 'improve': [12], 'a': [13, 24, 51, 63, 77, 95], ""model's"": [14, 44], 'performance.': [15], 'In': [16], 'this': [17], 'paper,': [18], 'we': [19, 87, 134], 'demonstrate': [20], 'the': [21, 43, 54, 60, 73, 81, 144], 'power': [22], 'simple': [25], 'combination': [26], 'two': [28], 'common': [29], 'SSL': [30, 128], 'methods:': [31], 'consistency': [32], 'regularization': [33], 'and': [34, 110], 'pseudo-labeling.': [35], 'Our': [36], 'algorithm,': [37], 'FixMatch,': [38], 'first': [39], 'generates': [40], 'pseudo-labels': [41], 'using': [42], 'predictions': [45], 'on': [46, 105], 'weakly-augmented': [47], 'images.': [49], 'For': [50], 'given': [52], 'image,': [53], 'pseudo-label': [55, 74], 'is': [56, 68], 'only': [57], 'retained': [58], 'if': [59], 'model': [61, 67], 'produces': [62], 'high-confidence': [64], 'prediction.': [65], 'The': [66], 'then': [69], 'trained': [70], 'predict': [72], 'when': [75], 'fed': [76], 'strongly-augmented': [78], 'version': [79], 'same': [82], 'image.': [83], 'Despite': [84], 'its': [85], 'simplicity,': [86], 'show': [88], 'that': [89, 130, 147], 'FixMatch': [90, 122], 'achieves': [91], 'state-of-the-art': [92], 'performance': [93], 'across': [94], 'variety': [96], 'standard': [98], 'semi-supervised': [99], 'benchmarks,': [101], 'including': [102], '94.93%': [103], 'accuracy': [104, 112], 'CIFAR-10': [106], 'with': [107, 113], '250': [108], 'labels': [109, 118], '88.61%': [111], '40': [114], '--': [115], 'just': [116], '4': [117], 'per': [119], 'class.': [120], 'Since': [121], 'bears': [123], 'many': [124], 'similarities': [125], 'existing': [127], 'methods': [129], 'achieve': [131], 'worse': [132], 'performance,': [133], 'carry': [135], 'out': [136], 'extensive': [138], 'ablation': [139], 'study': [140], 'tease': [142], 'apart': [143], 'experimental': [145], 'factors': [146], 'are': [148], 'most': [149], 'important': [150], ""FixMatch's"": [152], 'success.': [153], 'We': [154], 'make': [155], 'our': [156], 'code': [157], 'available': [158], 'at': [159], 'https://github.com/google-research/fixmatch.': [160]}",2020,"['Computer science', 'Consistency (knowledge bases)', 'Regularization (linguistics)', 'Code (set theory)', 'Artificial intelligence', 'Class (philosophy)', 'Machine learning', 'Simplicity', 'Semi-supervised learning', 'Image (mathematics)', 'Pattern recognition (psychology)', 'Simple (philosophy)', 'Programming language', 'Philosophy', 'Set (abstract data type)', 'Epistemology']","Semi-supervised learning (SSL) provides an effective means of leveraging unlabeled data to improve a model's performance. In this paper, we demonstrate the power of a simple combination of two common SSL methods: consistency regularization and pseudo-labeling. Our algorithm, FixMatch, first generates pseudo-labels using the model's predictions on weakly-augmented unlabeled images. For a given image, the pseudo-label is only retained if the model produces a high-confidence prediction. The model is then trained to predict the pseudo-label when fed a strongly-augmented version of the same image. Despite its simplicity, we show that FixMatch achieves state-of-the-art performance across a variety of standard semi-supervised learning benchmarks, including 94.93% accuracy on CIFAR-10 with 250 labels and 88.61% accuracy with 40 -- just 4 labels per class. Since FixMatch bears many similarities to existing SSL methods that achieve worse performance, we carry out an extensive ablation study to tease apart the experimental factors that are most important to FixMatch's success. We make our code available at https://github.com/google-research/fixmatch."
https://openalex.org/W3036601975,wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations,"{'We': [0], 'show': [1], 'for': [2], 'the': [3, 22, 33, 37, 50, 68, 74, 85, 89, 92, 124], 'first': [4], 'time': [5], 'that': [6], 'learning': [7], 'powerful': [8], 'representations': [9, 52], 'from': [10], 'speech': [11, 19, 34, 127], 'audio': [12], 'alone': [13], 'followed': [14], 'by': [15], 'fine-tuning': [16], 'on': [17, 67, 91, 112], 'transcribed': [18], 'can': [20], 'outperform': [21], 'best': [23], 'semi-supervised': [24], 'methods': [25], 'while': [26, 96], 'being': [27], 'conceptually': [28], 'simpler.': [29], 'wav2vec': [30, 82], '2.0': [31, 83], 'masks': [32], 'input': [35], 'in': [36], 'latent': [38, 51], 'space': [39], 'and': [40, 110], 'solves': [41], 'a': [42, 47], 'contrastive': [43], 'task': [44], 'defined': [45], 'over': [46], 'quantization': [48], 'of': [49, 62, 76, 88, 107, 115, 126, 132], 'which': [53], 'are': [54], 'jointly': [55], 'learned.': [56], 'Experiments': [57], 'using': [58, 97], 'all': [59], 'labeled': [60, 77, 101, 108, 133], 'data': [61, 78, 109, 117], 'Librispeech': [63], 'achieve': [64], '1.8/3.3': [65], 'WER': [66], 'clean/other': [69], 'test': [70], 'sets.': [71], 'When': [72], 'lowering': [73], 'amount': [75], 'to': [79], 'one': [80], 'hour,': [81], 'outperforms': [84], 'previous': [86], 'state': [87], 'art': [90], '100': [93, 98], 'hour': [94], 'subset': [95], 'times': [99], 'less': [100], 'data.': [102, 134], 'Using': [103], 'just': [104], 'ten': [105], 'minutes': [106], 'pre-training': [111], '53k': [113], 'hours': [114], 'unlabeled': [116], 'still': [118], 'achieves': [119], '4.8/8.2': [120], 'WER.': [121], 'This': [122], 'demonstrates': [123], 'feasibility': [125], 'recognition': [128], 'with': [129], 'limited': [130], 'amounts': [131]}",2020,"['Computer science', 'Natural language processing', 'Self representation', 'Artificial intelligence', 'Speech recognition', 'Art', 'Humanities']","We show for the first time that learning powerful representations from speech audio alone followed by fine-tuning on transcribed speech can outperform the best semi-supervised methods while being conceptually simpler. wav2vec 2.0 masks the speech input in the latent space and solves a contrastive task defined over a quantization of the latent representations which are jointly learned. Experiments using all labeled data of Librispeech achieve 1.8/3.3 WER on the clean/other test sets. When lowering the amount of labeled data to one hour, wav2vec 2.0 outperforms the previous state of the art on the 100 hour subset while using 100 times less labeled data. Using just ten minutes of labeled data and pre-training on 53k hours of unlabeled data still achieves 4.8/8.2 WER. This demonstrates the feasibility of speech recognition with limited amounts of labeled data."
https://openalex.org/W2964051675,Deeper Insights Into Graph Convolutional Networks for Semi-Supervised Learning,"{'Many': [0], 'interesting': [1], 'problems': [2], 'in': [3, 36, 151], 'machine': [4], 'learning': [5, 12, 152], 'are': [6, 52], 'being': [7], 'revisited': [8], 'with': [9, 46, 120, 133, 153], 'new': [10], 'deep': [11], 'tools.': [13], 'For': [14], 'graph-based': [15], 'semi-supervised': [16], 'learning,': [17], 'a': [18, 98], 'recent': [19], 'important': [20], 'development': [21], 'is': [22, 96, 105], 'graph': [23, 34, 90], 'convolutional': [24, 38, 122], 'networks': [25], '(GCNs),': [26], 'which': [27, 104], 'nicely': [28], 'integrate': [29], 'local': [30], 'vertex': [31], 'features': [32], 'and': [33, 55, 66, 80, 140, 157, 174], 'topology': [35], 'the': [37, 41, 77, 89, 93, 106, 127, 130], 'layers.': [39, 123], 'Although': [40], 'GCN': [42, 78, 94, 131], 'model': [43, 67, 79, 95, 132], 'compares': [44], 'favorably': [45], 'other': [47], 'state-of-the-art': [48], 'methods,': [49], 'its': [50, 82], 'mechanisms': [51], 'not': [53], 'clear': [54], 'it': [56, 113], 'still': [57], 'requires': [58], 'considerable': [59], 'amount': [60], 'of': [61, 92, 101, 118, 129], 'labeled': [62], 'data': [63], 'for': [64, 164], 'validation': [65], 'selection.': [68], 'In': [69], 'this': [70], 'paper,': [71], 'we': [72, 86, 136], 'develop': [73], 'deeper': [74], 'insights': [75], 'into': [76], 'address': [81], 'fundamental': [83], 'limits.': [84], 'First,': [85], 'show': [87], 'that': [88], 'convolution': [91], 'actually': [97], 'special': [99], 'form': [100], 'Laplacian': [102], 'smoothing,': [103], 'key': [107], 'reason': [108], 'why': [109], 'GCNs': [110, 150], 'work,': [111], 'but': [112], 'also': [114], 'brings': [115], 'potential': [116], 'concerns': [117], 'over-smoothing': [119], 'many': [121], 'Second,': [124], 'to': [125, 143], 'overcome': [126], 'limits': [128], 'shallow': [134], 'architectures,': [135], 'propose': [137], 'both': [138], 'co-training': [139], 'self-training': [141], 'approaches': [142, 147], 'train': [144], 'GCNs.': [145], 'Our': [146], 'significantly': [148], 'improve': [149], 'very': [154], 'few': [155], 'labels,': [156], 'exempt': [158], 'them': [159], 'from': [160], 'requiring': [161], 'additional': [162], 'labels': [163], 'validation.': [165], 'Extensive': [166], 'experiments': [167], 'on': [168], 'benchmarks': [169], 'have': [170], 'verified': [171], 'our': [172], 'theory': [173], 'proposals.': [175]}",2018,"['Computer science', 'Graph', 'Machine learning', 'Artificial intelligence', 'Deep learning', 'Smoothing', 'Convolutional neural network', 'Theoretical computer science', 'Laplacian matrix', 'Computer vision']","Many interesting problems in machine learning are being revisited with new deep learning tools. For graph-based semi-supervised learning, a recent important development is graph convolutional networks (GCNs), which nicely integrate local vertex features and graph topology in the convolutional layers. Although the GCN model compares favorably with other state-of-the-art methods, its mechanisms are not clear and it still requires considerable amount of labeled data for validation and model selection. In this paper, we develop deeper insights into the GCN model and address its fundamental limits. First, we show that the graph convolution of the GCN model is actually a special form of Laplacian smoothing, which is the key reason why GCNs work, but it also brings potential concerns of over-smoothing with many convolutional layers. Second, to overcome the limits of the GCN model with shallow architectures, we propose both co-training and self-training approaches to train GCNs. Our approaches significantly improve GCNs in learning with very few labels, and exempt them from requiring additional labels for validation. Extensive experiments on benchmarks have verified our theory and proposals."
https://openalex.org/W2746791238,A brief introduction to weakly supervised learning,"{'Supervised': [0], 'learning': [1, 7], 'techniques': [2, 28, 67], 'construct': [3], 'predictive': [4], 'models': [5], 'by': [6], 'from': [8], 'a': [9, 20, 95], 'large': [10], 'number': [11], 'of': [12, 57, 79, 88, 97], 'training': [13, 17, 98, 108], 'examples,': [14], 'where': [15, 93, 106, 119], 'each': [16], 'example': [18], 'has': [19], 'label': [21], 'indicating': [22], 'its': [23], 'ground-truth': [24, 50], 'output.': [25], 'Though': [26], 'current': [27], 'have': [29], 'achieved': [30], 'great': [31], 'success,': [32], 'it': [33, 40, 62], 'is': [34, 41, 63, 100], 'noteworthy': [35], 'that': [36], 'in': [37], 'many': [38], 'tasks': [39], 'difficult': [42], 'to': [43, 53, 68], 'get': [44], 'strong': [45], 'supervision': [46], 'information': [47], 'like': [48], 'fully': [49], 'labels': [51, 122], 'due': [52], 'the': [54, 58, 107, 120], 'high': [55], 'cost': [56], 'data-labeling': [59], 'process.': [60], 'Thus,': [61], 'desirable': [64], 'for': [65], 'machine-learning': [66], 'work': [69], 'with': [70, 102, 112], 'weak': [71, 89], 'supervision.': [72], 'This': [73], 'article': [74], 'reviews': [75], 'some': [76], 'research': [77], 'progress': [78], 'weakly': [80], 'supervised': [81], 'learning,': [82], 'focusing': [83], 'on': [84], 'three': [85], 'typical': [86], 'types': [87], 'supervision:': [90], 'incomplete': [91], 'supervision,': [92, 105, 118], 'only': [94, 113], 'subset': [96], 'data': [99, 109], 'given': [101, 111, 121], 'labels;': [103, 115], 'inexact': [104], 'are': [110, 123], 'coarse-grained': [114], 'and': [116], 'inaccurate': [117], 'not': [124], 'always': [125], 'ground-truth.': [126]}",2017,"['Ground truth', 'Computer science', 'Construct (python library)', 'Process (computing)', 'Training set', 'Machine learning', 'Artificial intelligence', 'Labeled data', 'Supervised learning', 'Common ground', 'Semi-supervised learning', 'Training (meteorology)', 'Psychology', 'Artificial neural network', 'Social psychology', 'Physics', 'Meteorology', 'Operating system', 'Programming language']","Supervised learning techniques construct predictive models by learning from a large number of training examples, where each training example has a label indicating its ground-truth output. Though current techniques have achieved great success, it is noteworthy that in many tasks it is difficult to get strong supervision information like fully ground-truth labels due to the high cost of the data-labeling process. Thus, it is desirable for machine-learning techniques to work with weak supervision. This article reviews some research progress of weakly supervised learning, focusing on three typical types of weak supervision: incomplete supervision, where only a subset of training data is given with labels; inexact supervision, where the training data are given with only coarse-grained labels; and inaccurate supervision, where the given labels are not always ground-truth."
https://openalex.org/W2951970475,Temporal Ensembling for Semi-Supervised Learning,"{'In': [0], 'this': [1], 'paper,': [2], 'we': [3, 33, 101, 173], 'present': [4], 'a': [5, 16, 21, 35, 69, 94, 150], 'simple': [6], 'and': [7, 51, 57, 88, 126, 136, 140], 'efficient': [8], 'method': [9], 'for': [10, 72, 96, 105], 'training': [11, 25, 86], 'deep': [12], 'neural': [13], 'networks': [14], 'in': [15, 121, 131, 153], 'semi-supervised': [17, 108], 'setting': [18], 'where': [19, 32], 'only': [20], 'small': [22], 'portion': [23], 'of': [24, 38, 45, 79], 'data': [26], 'is': [27], 'labeled.': [28], 'We': [29, 147], 'introduce': [30], 'self-ensembling,': [31], 'form': [34], 'consensus': [36], 'prediction': [37, 63], 'the': [39, 43, 46, 73, 77, 80, 83, 112, 144, 162], 'unknown': [40, 74], 'labels': [41, 75, 125], 'using': [42, 158], 'outputs': [44], 'network-in-training': [47], 'on': [48], 'different': [49, 55], 'epochs,': [50], 'most': [52, 84], 'importantly,': [53], 'under': [54], 'regularization': [56], 'input': [58], 'augmentation': [59], 'conditions.': [60], 'This': [61], 'ensemble': [62], 'can': [64, 89], 'be': [65, 68, 91], 'expected': [66], 'to': [67, 119, 129, 138, 177], 'better': [70], 'predictor': [71], 'than': [76], 'output': [78], 'network': [81], 'at': [82], 'recent': [85], 'epoch,': [87], 'thus': [90], 'used': [92], 'as': [93, 166], 'target': [95], 'training.': [97, 171], 'Using': [98], 'our': [99], 'method,': [100], 'set': [102], 'new': [103], 'records': [104], 'two': [106], 'standard': [107, 145], 'learning': [109], 'benchmarks,': [110], 'reducing': [111], '(non-augmented)': [113], 'classification': [114, 155], 'error': [115], 'rate': [116], 'from': [117, 127, 161], '18.44%': [118], '7.05%': [120], 'SVHN': [122], 'with': [123, 133], '500': [124], '18.63%': [128], '16.55%': [130], 'CIFAR-10': [132], '4000': [134], 'labels,': [135], 'further': [137], '5.12%': [139], '12.16%': [141], 'by': [142, 157], 'enabling': [143], 'augmentations.': [146], 'additionally': [148], 'obtain': [149], 'clear': [151], 'improvement': [152], 'CIFAR-100': [154], 'accuracy': [156], 'random': [159], 'images': [160], 'Tiny': [163], 'Images': [164], 'dataset': [165], 'unlabeled': [167], 'extra': [168], 'inputs': [169], 'during': [170], 'Finally,': [172], 'demonstrate': [174], 'good': [175], 'tolerance': [176], 'incorrect': [178], 'labels.': [179]}",2016,"['Computer science', 'Regularization (linguistics)', 'Artificial intelligence', 'Machine learning', 'Training set', 'Artificial neural network', 'Set (abstract data type)', 'Deep neural networks', 'Supervised learning', 'Labeled data', 'Pattern recognition (psychology)', 'Programming language']","In this paper, we present a simple and efficient method for training deep neural networks in a semi-supervised setting where only a small portion of training data is labeled. We introduce self-ensembling, where we form a consensus prediction of the unknown labels using the outputs of the network-in-training on different epochs, and most importantly, under different regularization and input augmentation conditions. This ensemble prediction can be expected to be a better predictor for the unknown labels than the output of the network at the most recent training epoch, and can thus be used as a target for training. Using our method, we set new records for two standard semi-supervised learning benchmarks, reducing the (non-augmented) classification error rate from 18.44% to 7.05% in SVHN with 500 labels and from 18.63% to 16.55% in CIFAR-10 with 4000 labels, and further to 5.12% and 12.16% by enabling the standard augmentations. We additionally obtain a clear improvement in CIFAR-100 classification accuracy by using random images from the Tiny Images dataset as unlabeled extra inputs during training. Finally, we demonstrate good tolerance to incorrect labels."
https://openalex.org/W3114632476,A Survey on Contrastive Self-Supervised Learning,"{'Self-supervised': [0], 'learning': [1, 37, 46, 104], 'has': [2, 38], 'gained': [3], 'popularity': [4], 'because': [5], 'of': [6, 13, 20, 63, 86, 122, 144], 'its': [7], 'ability': [8], 'to': [9, 68, 73, 157], 'avoid': [10], 'the': [11, 28, 64, 91, 142, 145, 149], 'cost': [12], 'annotating': [14], 'large-scale': [15], 'datasets.': [16], 'It': [17, 57], 'is': [18], 'capable': [19], 'adopting': [21], 'self-defined': [22], 'pseudolabels': [23], 'as': [24, 130], 'supervision': [25], 'and': [26, 54, 135, 148, 154], 'use': [27], 'learned': [29], 'representations': [30], 'for': [31, 47, 125, 151], 'several': [32], 'downstream': [33, 127], 'tasks.': [34], 'Specifically,': [35], 'contrastive': [36, 92, 103], 'recently': [39], 'become': [40], 'a': [41, 102, 119], 'dominant': [42], 'component': [43], 'in': [44, 101], 'self-supervised': [45, 87], 'computer': [48], 'vision,': [49], 'natural': [50], 'language': [51], 'processing': [52], '(NLP),': [53], 'other': [55, 70], 'domains.': [56], 'aims': [58], 'at': [59], 'embedding': [60], 'augmented': [61], 'versions': [62], 'same': [65], 'sample': [66], 'close': [67], 'each': [69], 'while': [71], 'trying': [72], 'push': [74], 'away': [75], 'embeddings': [76], 'from': [77], 'different': [78, 108, 123], 'samples.': [79], 'This': [80], 'paper': [81], 'provides': [82], 'an': [83], 'extensive': [84], 'review': [85], 'methods': [88, 124, 147], 'that': [89, 110], 'follow': [90], 'approach.': [93], 'The': [94], 'work': [95], 'explains': [96], 'commonly': [97], 'used': [98], 'pretext': [99], 'tasks': [100, 128], 'setup,': [105], 'followed': [106], 'by': [107], 'architectures': [109], 'have': [111], 'been': [112], 'proposed': [113], 'so': [114], 'far.': [115], 'Next,': [116], 'we': [117, 139], 'present': [118], 'performance': [120], 'comparison': [121], 'multiple': [126], 'such': [129], 'image': [131], 'classification,': [132], 'object': [133], 'detection,': [134], 'action': [136], 'recognition.': [137], 'Finally,': [138], 'conclude': [140], 'with': [141], 'limitations': [143], 'current': [146], 'need': [150], 'further': [152], 'techniques': [153], 'future': [155], 'directions': [156], 'make': [158], 'meaningful': [159], 'progress.': [160]}",2020,"['Computer science', 'Artificial intelligence', 'Pretext', 'Machine learning', 'Embedding', 'Popularity', 'Supervised learning', 'Sample (material)', 'Natural language processing', 'Artificial neural network', 'Psychology', 'Politics', 'Chemistry', 'Political science', 'Chromatography', 'Law', 'Social psychology']","Self-supervised learning has gained popularity because of its ability to avoid the cost of annotating large-scale datasets. It is capable of adopting self-defined pseudolabels as supervision and use the learned representations for several downstream tasks. Specifically, contrastive learning has recently become a dominant component in self-supervised learning for computer vision, natural language processing (NLP), and other domains. It aims at embedding augmented versions of the same sample close to each other while trying to push away embeddings from different samples. This paper provides an extensive review of self-supervised methods that follow the contrastive approach. The work explains commonly used pretext tasks in a contrastive learning setup, followed by different architectures that have been proposed so far. Next, we present a performance comparison of different methods for multiple downstream tasks such as image classification, object detection, and action recognition. Finally, we conclude with the limitations of the current methods and the need for further techniques and future directions to make meaningful progress."
https://openalex.org/W2108501770,Semi-Supervised Learning with Deep Generative Models,"{'The': [0], 'ever-increasing': [1], 'size': [2], 'of': [3, 11, 20, 23], 'modern': [4, 28], 'data': [5, 29, 53], 'sets': [6, 54], 'combined': [7], 'with': [8, 38], 'the': [9, 21, 33], 'difficulty': [10], 'obtaining': [12], 'label': [13], 'information': [14], 'has': [15], 'made': [16], 'semi-supervised': [17, 36, 99], 'learning': [18, 37], 'one': [19], 'problems': [22], 'significant': [24, 91], 'practical': [25], 'importance': [26], 'in': [27, 83], 'analysis.': [30], 'We': [31, 70], 'revisit': [32], 'approach': [34], 'to': [35, 55, 89], 'generative': [39, 74, 94], 'models': [40, 44, 75], 'and': [41, 76], 'develop': [42], 'new': [43], 'that': [45, 72], 'allow': [46], 'for': [47, 98], 'effective': [48], 'generalisation': [49], 'from': [50], 'small': [51], 'labelled': [52], 'large': [56], 'unlabelled': [57], 'ones.': [58], 'Generative': [59], 'approaches': [60, 95], 'have': [61], 'thus': [62], 'far': [63], 'been': [64], 'either': [65], 'inflexible,': [66], 'inefficient': [67], 'or': [68], 'non-scalable.': [69], 'show': [71], 'deep': [73], 'approximate': [77], 'Bayesian': [78], 'inference': [79], 'exploiting': [80], 'recent': [81], 'advances': [82], 'variational': [84], 'methods': [85], 'can': [86], 'be': [87], 'used': [88], 'provide': [90], 'improvements,': [92], 'making': [93], 'highly': [96], 'competitive': [97], 'learning.': [100]}",2014,"['Generative grammar', 'Artificial intelligence', 'Machine learning', 'Computer science', 'Inference', 'Generative model', 'Scalability', 'Deep learning', 'Semi-supervised learning', 'Supervised learning', 'Bayesian probability', 'Bayesian inference', 'Artificial neural network', 'Database']","The ever-increasing size of modern data sets combined with the difficulty of obtaining label information has made semi-supervised learning one of the problems of significant practical importance in modern data analysis. We revisit the approach to semi-supervised learning with generative models and develop new models that allow for effective generalisation from small labelled data sets to large unlabelled ones. Generative approaches have thus far been either inflexible, inefficient or non-scalable. We show that deep generative models and approximate Bayesian inference exploiting recent advances in variational methods can be used to provide significant improvements, making generative approaches highly competitive for semi-supervised learning."
https://openalex.org/W3177500196,ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning,"{'Computational': [0], 'biology': [1], 'and': [2, 41, 53, 75, 136], 'bioinformatics': [3], 'provide': [4], 'vast': [5], 'data': [6, 50, 90], 'gold-mines': [7], 'from': [8, 17, 51, 88], 'protein': [9, 63, 96, 119, 130], 'sequences,': [10], 'ideal': [11], 'for': [12, 25, 109, 151], 'Language': [13, 19], 'Models': [14], '(LMs)': [15], 'taken': [16], 'Natural': [18], 'Processing': [20], '(NLP).': [21], 'These': [22], 'LMs': [23, 64], 'reach': [24], 'new': [26], 'prediction': [27, 117], 'frontiers': [28], 'at': [29], 'low': [30], 'inference': [31], 'costs.': [32], 'Here,': [33], 'we': [34], 'trained': [35, 67], 'two': [36], 'auto-regressive': [37], 'models': [38, 44, 190], '(Transformer-XL,': [39], 'XLNet)': [40], 'four': [42], 'auto-encoder': [43], '(BERT,': [45], 'Albert,': [46], 'Electra,': [47], 'T5)': [48], 'on': [49, 68], 'UniRef': [52], 'BFD': [54], 'containing': [55], 'up': [56], 'to': [57], '393': [58], 'billion': [59], 'amino': [60], 'acids.': [61], 'The': [62], '(pLMs)': [65], 'were': [66], 'the': [69, 85, 100, 104, 146, 152, 156, 173, 181, 184], 'Summit': [70], 'supercomputer': [71], 'using': [72, 103], '5616': [73], 'GPUs': [74], 'TPU': [76], 'Pod': [77], 'up-to': [78], '1024': [79], 'cores.': [80], 'Dimensionality': [81], 'reduction': [82], 'revealed': [83], 'that': [84, 176], 'raw': [86], 'pLM-embeddings': [87], 'unlabeled': [89], 'captured': [91], 'some': [92, 179], 'biophysical': [93], 'features': [94], 'of': [95, 102, 118, 129, 180, 183, 186], 'sequences.': [97], 'We': [98], 'validated': [99], 'advantage': [101], 'embeddings': [105, 149], 'as': [106], 'exclusive': [107], 'input': [108], 'several': [110], 'subsequent': [111], 'tasks:': [112], '(1)': [113], 'a': [114], 'per-residue': [115], '(per-token)': [116], 'secondary': [120, 144], 'structure': [121], '(3-state': [122], 'accuracy': [123, 141], 'Q3=81%-87%);': [124], '(2)': [125], 'per-protein': [126], '(pooling)': [127], 'predictions': [128], 'sub-cellular': [131], 'location': [132], '(ten-state': [133], 'accuracy:': [134], 'Q10=81%)': [135], 'membrane': [137], 'versus': [138], 'water-soluble': [139], '(2-state': [140], 'Q2=91%).': [142], 'For': [143], 'structure,': [145], 'most': [147], 'informative': [148], '(ProtT5)': [150], 'first': [153], 'time': [154], 'outperformed': [155], 'state-of-the-art': [157], 'without': [158], 'multiple': [159], 'sequence': [160], 'alignments': [161], '(MSAs)': [162], 'or': [163], 'evolutionary': [164], 'information': [165], 'thereby': [166], 'bypassing': [167], 'expensive': [168], 'database': [169], 'searches.': [170], 'Taken': [171], 'together,': [172], 'results': [174], 'implied': [175], 'pLMs': [177], 'learned': [178], 'grammar': [182], 'language': [185], 'life.': [187], 'All': [188], 'our': [189], 'are': [191], 'available': [192], 'through': [193], 'https://github.com/agemagician/ProtTrans.': [194]}",2021,"['Computer science', 'Artificial intelligence', 'Machine learning', 'Language acquisition', 'Natural language processing', 'Psychology', 'Mathematics education']","Computational biology and bioinformatics provide vast data gold-mines from protein sequences, ideal for Language Models (LMs) taken from Natural Language Processing (NLP). These LMs reach for new prediction frontiers at low inference costs. Here, we trained two auto-regressive models (Transformer-XL, XLNet) and four auto-encoder models (BERT, Albert, Electra, T5) on data from UniRef and BFD containing up to 393 billion amino acids. The protein LMs (pLMs) were trained on the Summit supercomputer using 5616 GPUs and TPU Pod up-to 1024 cores. Dimensionality reduction revealed that the raw pLM-embeddings from unlabeled data captured some biophysical features of protein sequences. We validated the advantage of using the embeddings as exclusive input for several subsequent tasks: (1) a per-residue (per-token) prediction of protein secondary structure (3-state accuracy Q3=81%-87%); (2) per-protein (pooling) predictions of protein sub-cellular location (ten-state accuracy: Q10=81%) and membrane versus water-soluble (2-state accuracy Q2=91%). For secondary structure, the most informative embeddings (ProtT5) for the first time outperformed the state-of-the-art without multiple sequence alignments (MSAs) or evolutionary information thereby bypassing expensive database searches. Taken together, the results implied that pLMs learned some of the grammar of the language of life. All our models are available through https://github.com/agemagician/ProtTrans."
https://openalex.org/W2963918774,Supervised Learning of Universal Sentence Representations from Natural\n Language Inference Data,"{'Many': [0], 'modern': [1], 'NLP': [2, 115], 'systems': [3], 'rely': [4], 'on': [5, 13, 78], 'word': [6], 'embeddings,': [7], 'previously': [8], 'trained': [9], 'in': [10], 'an\\nunsupervised': [11], 'manner': [12], 'large': [14], 'corpora,': [15], 'as': [16, 28], 'base': [17], 'features.': [18], 'Efforts': [19], 'to': [20, 48, 98], 'obtain\\nembeddings': [21], 'for': [22, 111], 'larger': [23], 'chunks': [24], 'of': [25, 64, 81, 107], 'text,': [26], 'such': [27], 'sentences,': [29], 'have': [30, 42], 'however': [31], 'not': [32, 43], 'been\\nso': [33], 'successful.': [34], 'Several': [35], 'attempts': [36], 'at': [37], 'learning': [38], 'unsupervised': [39, 73], 'representations': [40, 59], 'of\\nsentences': [41], 'reached': [44], 'satisfactory': [45], 'enough': [46], 'performance': [47], 'be': [49, 96], 'widely\\nadopted.': [50], 'In': [51], 'this': [52], 'paper,': [53], 'we': [54], 'show': [55], 'how': [56, 86], 'universal': [57], 'sentence': [58], 'trained\\nusing': [60], 'the': [61, 65, 105], 'supervised': [62], 'data': [63], 'Stanford': [66], 'Natural': [67], 'Language': [68], 'Inference': [69], 'datasets\\ncan': [70], 'consistently': [71], 'outperform': [72], 'methods': [74], 'like': [75, 85], 'SkipThought': [76], 'vectors': [77], 'a\\nwide': [79], 'range': [80], 'transfer': [82, 112], 'tasks.': [83, 116], 'Much': [84], 'computer': [87], 'vision': [88], 'uses': [89], 'ImageNet': [90], 'to\\nobtain': [91], 'features,': [92], 'which': [93], 'can': [94], 'then': [95], 'transferred': [97], 'other': [99, 114], 'tasks,': [100], 'our': [101], 'work': [102], 'tends\\nto': [103], 'indicate': [104], 'suitability': [106], 'natural': [108], 'language': [109], 'inference': [110], 'learning\\nto': [113], 'Our': [117], 'encoder': [118], 'is': [119], 'publicly': [120], 'available.\\n': [121]}",2017,"['Computer science', 'Artificial intelligence', 'Natural language processing', 'Inference', 'Sentence', 'Unsupervised learning', 'Transfer of learning', 'Natural language', 'Word (group theory)', 'Machine learning', 'Linguistics', 'Philosophy']","Many modern NLP systems rely on word embeddings, previously trained in an\nunsupervised manner on large corpora, as base features. Efforts to obtain\nembeddings for larger chunks of text, such as sentences, have however not been\nso successful. Several attempts at learning unsupervised representations of\nsentences have not reached satisfactory enough performance to be widely\nadopted. In this paper, we show how universal sentence representations trained\nusing the supervised data of the Stanford Natural Language Inference datasets\ncan consistently outperform unsupervised methods like SkipThought vectors on a\nwide range of transfer tasks. Much like how computer vision uses ImageNet to\nobtain features, which can then be transferred to other tasks, our work tends\nto indicate the suitability of natural language inference for transfer learning\nto other NLP tasks. Our encoder is publicly available.\n"
https://openalex.org/W3035725276,Self-supervised Learning: Generative or Contrastive,"{'Deep': [0], 'supervised': [1], 'learning': [2, 35, 45, 53, 78, 128], 'has': [3], 'achieved': [4], 'great': [5], 'success': [6], 'in': [7, 46, 82], 'the': [8, 47, 94, 146], 'last': [9, 48], 'decade.': [10], 'However,': [11], 'its': [12, 40], 'deficiencies': [13], 'of': [14, 65], 'dependence': [15], 'on': [16, 43, 125], 'manual': [17], 'labels': [18], 'and': [19, 60, 88, 98, 111, 136], 'vulnerability': [20], 'to': [21, 26, 106, 121], 'attacks': [22], 'have': [23], 'driven': [24], 'people': [25], 'explore': [27], 'a': [28, 73], 'better': [29], 'solution.': [30], 'As': [31], 'an': [32], 'alternative,': [33], 'self-supervised': [34, 77, 127, 140], 'attracts': [36], 'many': [37], 'researchers': [38], 'for': [39, 80, 139, 145], 'soaring': [41], 'performance': [42], 'representation': [44, 52, 81], 'several': [49], 'years.': [50], 'Self-supervised': [51], 'leverages': [54], 'input': [55], 'data': [56], 'itself': [57], 'as': [58], 'supervision': [59], 'benefits': [61], 'almost': [62], 'all': [63], 'types': [64], 'downstream': [66], 'tasks.': [67], 'In': [68], 'this': [69], 'survey,': [70], 'we': [71, 131], 'take': [72], 'look': [74], 'into': [75, 101], 'new': [76], 'methods': [79, 97], 'computer': [83], 'vision,': [84], 'natural': [85], 'language': [86], 'processing,': [87], 'graph': [89], 'learning.': [90, 141], 'We': [91, 114], 'comprehensively': [92], 'review': [93], 'existing': [95], 'empirical': [96], 'summarize': [99], 'them': [100], 'three': [102], 'main': [103], 'categories': [104], 'according': [105], 'their': [107], 'objectives:': [108], 'generative,': [109], 'contrastive,': [110], 'generative-contrastive': [112], '(adversarial).': [113], 'further': [115], 'investigate': [116], 'related': [117], 'theoretical': [118], 'analysis': [119], 'work': [120], 'provide': [122], 'deeper': [123], 'thoughts': [124], 'how': [126], 'works.': [129], 'Finally,': [130], 'briefly': [132], 'discuss': [133], 'open': [134], 'problems': [135], 'future': [137], 'directions': [138], 'An': [142], 'outline': [143], 'slide': [144], 'survey': [147], 'is': [148], 'provided.': [149]}",2021,[],"Deep supervised learning has achieved great success in the last decade. However, its deficiencies of dependence on manual labels and vulnerability to attacks have driven people to explore a better solution. As an alternative, self-supervised learning attracts many researchers for its soaring performance on representation learning in the last several years. Self-supervised representation learning leverages input data itself as supervision and benefits almost all types of downstream tasks. In this survey, we take a look into new self-supervised learning methods for representation in computer vision, natural language processing, and graph learning. We comprehensively review the existing empirical methods and summarize them into three main categories according to their objectives: generative, contrastive, and generative-contrastive (adversarial). We further investigate related theoretical analysis work to provide deeper thoughts on how self-supervised learning works. Finally, we briefly discuss open problems and future directions for self-supervised learning. An outline slide for the survey is provided."
https://openalex.org/W2975059944,ALBERT: A Lite BERT for Self-supervised Learning of Language Representations,"{'Increasing': [0], 'model': [1, 21, 101], 'size': [2], 'when': [3], 'pretraining': [4], 'natural': [5], 'language': [6], 'representations': [7], 'often': [8], 'results': [9, 105], 'in': [10], 'improved': [11], 'performance': [12], 'on': [13, 82, 106], 'downstream': [14, 91], 'tasks.': [15], 'However,': [16], 'at': [17, 128], 'some': [18], 'point': [19], 'further': [20], 'increases': [22], 'become': [23], 'harder': [24], 'due': [25], 'to': [26, 43, 63, 70, 118], 'GPU/TPU': [27], 'memory': [28, 45], 'limitations': [29], 'and': [30, 47, 86, 110, 122], 'longer': [31], 'training': [32, 50], 'times.': [33], 'To': [34], 'address': [35], 'these': [36], 'problems,': [37], 'we': [38], 'present': [39], 'two': [40], 'parameter-reduction': [41], 'techniques': [42], 'lower': [44], 'consumption': [46], 'increase': [48], 'the': [49, 71, 107, 123], 'speed': [51], 'of': [52], 'BERT.': [53, 73], 'Comprehensive': [54], 'empirical': [55], 'evidence': [56], 'shows': [57], 'that': [58, 65, 80], 'our': [59, 99], 'proposed': [60], 'methods': [61], 'lead': [62], 'models': [64, 125], 'scale': [66], 'much': [67], 'better': [68], 'compared': [69, 117], 'original': [72], 'We': [74], 'also': [75], 'use': [76], 'a': [77, 97], 'self-supervised': [78], 'loss': [79], 'focuses': [81], 'modeling': [83], 'inter-sentence': [84], 'coherence,': [85], 'show': [87], 'it': [88], 'consistently': [89], 'helps': [90], 'tasks': [92], 'with': [93], 'multi-sentence': [94], 'inputs.': [95], 'As': [96], 'result,': [98], 'best': [100], 'establishes': [102], 'new': [103], 'state-of-the-art': [104], 'GLUE,': [108], 'RACE,': [109], '\\squad': [111], 'benchmarks': [112], 'while': [113], 'having': [114], 'fewer': [115], 'parameters': [116], 'BERT-large.': [119], 'The': [120], 'code': [121], 'pretrained': [124], 'are': [126], 'available': [127], 'https://github.com/google-research/ALBERT.': [129]}",2019,"['Computer science', 'Sentence', 'Language model', 'Code (set theory)', 'Artificial intelligence', 'Point (geometry)', 'Natural language processing', 'Coherence (philosophical gambling strategy)', 'Machine learning', 'Programming language', 'Set (abstract data type)', 'Physics', 'Quantum mechanics', 'Geometry', 'Mathematics']","Increasing model size when pretraining natural language representations often results in improved performance on downstream tasks. However, at some point further model increases become harder due to GPU/TPU memory limitations and longer training times. To address these problems, we present two parameter-reduction techniques to lower memory consumption and increase the training speed of BERT. Comprehensive empirical evidence shows that our proposed methods lead to models that scale much better compared to the original BERT. We also use a self-supervised loss that focuses on modeling inter-sentence coherence, and show it consistently helps downstream tasks with multi-sentence inputs. As a result, our best model establishes new state-of-the-art results on the GLUE, RACE, and \squad benchmarks while having fewer parameters compared to BERT-large. The code and the pretrained models are available at https://github.com/google-research/ALBERT."
https://openalex.org/W830076066,Semi-Supervised Learning with Ladder Networks,"{'We': [0, 55], 'combine': [1], 'supervised': [2, 22], 'learning': [3, 6], 'with': [4, 53, 76], 'unsupervised': [5, 24], 'in': [7, 64, 70], 'deep': [8], 'neural': [9], 'networks.': [10], 'The': [11], 'proposed': [12, 42], 'model': [13, 52, 60], 'is': [14], 'trained': [15], 'to': [16, 72], 'simultaneously': [17], 'minimize': [18], 'the': [19, 30, 39, 51, 58], 'sum': [20], 'of': [21], 'and': [23, 67], 'cost': [25], 'functions': [26], 'by': [27, 43, 49], 'backpropagation,': [28], 'avoiding': [29], 'need': [31], 'for': [32], 'layer-wise': [33], 'pre-training.': [34], 'Our': [35], 'work': [36], 'builds': [37], 'on': [38], 'Ladder': [40], 'network': [41], 'Valpola': [44], '(2015),': [45], 'which': [46], 'we': [47], 'extend': [48], 'combining': [50], 'supervision.': [54], 'show': [56], 'that': [57], 'resulting': [59], 'reaches': [61], 'state-of-the-art': [62], 'performance': [63], 'semi-supervised': [65], 'MNIST': [66, 74], 'CIFAR-10': [68], 'classification,': [69], 'addition': [71], 'permutation-invariant': [73], 'classification': [75], 'all': [77], 'labels.': [78]}",2015,"['MNIST database', 'Artificial intelligence', 'Computer science', 'Machine learning', 'Supervised learning', 'Backpropagation', 'Artificial neural network', 'Unsupervised learning', 'Permutation (music)', 'Semi-supervised learning', 'Deep learning', 'Pattern recognition (psychology)', 'Acoustics', 'Physics']","We combine supervised learning with unsupervised learning in deep neural networks. The proposed model is trained to simultaneously minimize the sum of supervised and unsupervised cost functions by backpropagation, avoiding the need for layer-wise pre-training. Our work builds on the Ladder network proposed by Valpola (2015), which we extend by combining the model with supervision. We show that the resulting model reaches state-of-the-art performance in semi-supervised MNIST and CIFAR-10 classification, in addition to permutation-invariant MNIST classification with all labels."
https://openalex.org/W3134652006,Barlow Twins: Self-Supervised Learning via Redundancy Reduction,"{'Self-supervised': [0], 'learning': [1], '(SSL)': [2], 'is': [3, 21, 41, 123, 192], 'rapidly': [4], 'closing': [5], 'the': [6, 31, 42, 69, 73, 92, 99, 113, 116, 151, 166, 188, 199], 'gap': [7], 'with': [8, 38, 80, 195, 204], 'supervised': [9], 'methods': [10, 50, 181], 'on': [11, 165, 182, 193], 'large': [12, 146], 'computer': [13], 'vision': [14], 'benchmarks.': [15], 'A': [16], 'successful': [17], 'approach': [18, 40], 'to': [19, 22, 28, 91, 108, 128, 135], 'SSL': [20], 'learn': [23], 'embeddings': [24], 'which': [25], 'are': [26], 'invariant': [27], 'distortions': [29], 'of': [30, 44, 75, 83, 102, 105, 118, 138, 198, 213], 'input': [32], 'sample.': [33], 'However,': [34], 'a': [35, 84, 106, 136, 156, 162, 205], 'recurring': [36], 'issue': [37], 'this': [39], 'existence': [43], 'trivial': [45], 'constant': [46], 'solutions.': [47], 'Most': [48], 'current': [49, 196], 'avoid': [51], 'such': [52, 154], 'solutions': [53], 'by': [54, 67], 'careful': [55], 'implementation': [56], 'details.': [57], 'We': [58], 'propose': [59], 'an': [60], 'objective': [61], 'function': [62], 'that': [63], 'naturally': [64], 'avoids': [65], 'collapse': [66], 'measuring': [68], 'cross-correlation': [70], 'matrix': [71, 94], 'between': [72, 115, 150], 'outputs': [74], 'two': [76], 'identical': [77, 139], 'networks': [78], 'fed': [79], 'distorted': [81, 103], 'versions': [82, 104], 'sample,': [85], 'and': [86, 191, 209, 215], 'making': [87], 'it': [88, 170], 'as': [89, 95, 155], 'close': [90], 'identity': [93], 'possible.': [96], 'This': [97], 'causes': [98], 'embedding': [100], 'vectors': [101], 'sample': [107], 'be': [109], 'similar,': [110], 'while': [111], 'minimizing': [112], 'redundancy': [114], 'components': [117], 'these': [119], 'vectors.': [120, 176], 'The': [121], 'method': [122], 'called': [124], 'Barlow': [125, 141, 177], 'Twins,': [126], 'owing': [127], 'neuroscientist': [129], 'H.': [130], ""Barlow's"": [131], 'redundancy-reduction': [132], 'principle': [133], 'applied': [134], 'pair': [137], 'networks.': [140], 'Twins': [142, 178], 'does': [143], 'not': [144], 'require': [145], 'batches': [147], 'nor': [148], 'asymmetry': [149], 'network': [152], 'twins': [153], 'predictor': [157], 'network,': [158], 'gradient': [159], 'stopping,': [160], 'or': [161], 'moving': [163], 'average': [164], 'weight': [167], 'updates.': [168], 'Intriguingly': [169], 'benefits': [171], 'from': [172], 'very': [173], 'high-dimensional': [174], 'output': [175], 'outperforms': [179], 'previous': [180], 'ImageNet': [183, 202], 'for': [184, 201, 210], 'semi-supervised': [185], 'classification': [186, 203, 214], 'in': [187], 'low-data': [189], 'regime,': [190], 'par': [194], 'state': [197], 'art': [200], 'linear': [206], 'classifier': [207], 'head,': [208], 'transfer': [211], 'tasks': [212], 'object': [216], 'detection.': [217]}",2021,"['Artificial intelligence', 'Computer science', 'Redundancy (engineering)', 'Pattern recognition (psychology)', 'Classifier (UML)', 'Embedding', 'Machine learning', 'Algorithm', 'Mathematics', 'Operating system']","Self-supervised learning (SSL) is rapidly closing the gap with supervised methods on large computer vision benchmarks. A successful approach to SSL is to learn embeddings which are invariant to distortions of the input sample. However, a recurring issue with this approach is the existence of trivial constant solutions. Most current methods avoid such solutions by careful implementation details. We propose an objective function that naturally avoids collapse by measuring the cross-correlation matrix between the outputs of two identical networks fed with distorted versions of a sample, and making it as close to the identity matrix as possible. This causes the embedding vectors of distorted versions of a sample to be similar, while minimizing the redundancy between the components of these vectors. The method is called Barlow Twins, owing to neuroscientist H. Barlow's redundancy-reduction principle applied to a pair of identical networks. Barlow Twins does not require large batches nor asymmetry between the network twins such as a predictor network, gradient stopping, or a moving average on the weight updates. Intriguingly it benefits from very high-dimensional output vectors. Barlow Twins outperforms previous methods on ImageNet for semi-supervised classification in the low-data regime, and is on par with current state of the art for ImageNet classification with a linear classifier head, and for transfer tasks of classification and object detection."
https://openalex.org/W2943865428,MixMatch: A Holistic Approach to Semi-Supervised Learning,"{'Semi-supervised': [0], 'learning': [1, 32], 'has': [2], 'proven': [3], 'to': [4, 13, 33, 93, 125], 'be': [5], 'a': [6, 35, 65, 87, 97, 111], 'powerful': [7], 'paradigm': [8], 'for': [9, 30, 45, 116, 135], 'leveraging': [10], 'unlabeled': [11, 47, 53], 'data': [12, 54, 73], 'mitigate': [14], 'the': [15, 26], 'reliance': [16], 'on': [17, 77, 101], 'large': [18, 66], 'labeled': [19, 51, 72], 'datasets.': [20], 'In': [21], 'this': [22], 'work,': [23], 'we': [24, 82, 120], 'unify': [25], 'current': [27], 'dominant': [28], 'approaches': [29], 'semi-supervised': [31], 'produce': [34], 'new': [36], 'algorithm,': [37], 'MixMatch,': [38], 'that': [39, 59], 'works': [40], 'by': [41, 64, 86, 96], 'guessing': [42], 'low-entropy': [43], 'labels': [44], 'data-augmented': [46], 'examples': [48], 'and': [49, 52, 71, 95], 'mixing': [50], 'using': [55], 'MixUp.': [56], 'We': [57, 103], 'show': [58], 'MixMatch': [60, 107, 131], 'obtains': [61], 'state-of-the-art': [62], 'results': [63], 'margin': [67], 'across': [68], 'many': [69], 'datasets': [70], 'amounts.': [74], 'For': [75], 'example,': [76], 'CIFAR-10': [78], 'with': [79], '250': [80], 'labels,': [81], 'reduce': [83], 'error': [84], 'rate': [85], 'factor': [88, 98], 'of': [89, 99, 130], '4': [90], '(from': [91], '38%': [92], '11%)': [94], '2': [100], 'STL-10.': [102], 'also': [104], 'demonstrate': [105], 'how': [106], 'can': [108], 'help': [109], 'achieve': [110], 'dramatically': [112], 'better': [113], 'accuracy-privacy': [114], 'trade-off': [115], 'differential': [117], 'privacy.': [118], 'Finally,': [119], 'perform': [121], 'an': [122], 'ablation': [123], 'study': [124], 'tease': [126], 'apart': [127], 'which': [128], 'components': [129], 'are': [132], 'most': [133], 'important': [134], 'its': [136], 'success.': [137]}",2019,"['Computer science', 'Margin (machine learning)', 'Labeled data', 'Semi-supervised learning', 'Machine learning', 'Artificial intelligence', 'Supervised learning', 'Factor (programming language)', 'Entropy (arrow of time)', 'Training set', 'Word error rate', 'Data mining', 'Artificial neural network', 'Quantum mechanics', 'Physics', 'Programming language']","Semi-supervised learning has proven to be a powerful paradigm for leveraging unlabeled data to mitigate the reliance on large labeled datasets. In this work, we unify the current dominant approaches for semi-supervised learning to produce a new algorithm, MixMatch, that works by guessing low-entropy labels for data-augmented unlabeled examples and mixing labeled and unlabeled data using MixUp. We show that MixMatch obtains state-of-the-art results by a large margin across many datasets and labeled data amounts. For example, on CIFAR-10 with 250 labels, we reduce error rate by a factor of 4 (from 38% to 11%) and by a factor of 2 on STL-10. We also demonstrate how MixMatch can help achieve a dramatically better accuracy-privacy trade-off for differential privacy. Finally, we perform an ablation study to tease apart which components of MixMatch are most important for its success."
https://openalex.org/W2412510955,Semi-Supervised Learning with Generative Adversarial Networks,"{'We': [0, 19, 69], 'extend': [1], 'Generative': [2], 'Adversarial': [3], 'Networks': [4], '(GANs)': [5], 'to': [6, 15, 35, 46, 62, 64, 77], 'the': [7, 12, 52, 65], 'semi-supervised': [8], 'context': [9], 'by': [10], 'forcing': [11], 'discriminator': [13, 27], 'network': [14], 'output': [16], 'class': [17, 59], 'labels.': [18], 'train': [20], 'a': [21, 26, 30, 79, 93], 'generative': [22], 'model': [23], 'G': [24], 'and': [25, 83], 'D': [28, 43], 'on': [29], 'dataset': [31], 'with': [32], 'inputs': [33], 'belonging': [34], 'one': [36], 'of': [37, 49, 67], 'N': [38], 'classes.': [39], 'At': [40], 'training': [41], 'time,': [42], 'is': [44, 60], 'made': [45], 'predict': [47], 'which': [48], 'N+1': [50], 'classes': [51], 'input': [53], 'belongs': [54], 'to,': [55], 'where': [56], 'an': [57], 'extra': [58], 'added': [61], 'correspond': [63], 'outputs': [66], 'G.': [68], 'show': [70], 'that': [71, 84], 'this': [72], 'method': [73], 'can': [74], 'be': [75], 'used': [76], 'create': [78], 'more': [80], 'data-efficient': [81], 'classifier': [82], 'it': [85], 'allows': [86], 'for': [87], 'generating': [88], 'higher': [89], 'quality': [90], 'samples': [91], 'than': [92], 'regular': [94], 'GAN.': [95]}",2016,"['Discriminator', 'Generative grammar', 'Adversarial system', 'Classifier (UML)', 'Computer science', 'Artificial intelligence', 'Class (philosophy)', 'Machine learning', 'Generative adversarial network', 'Forcing (mathematics)', 'Context (archaeology)', 'Supervised learning', 'Deep learning', 'Artificial neural network', 'Mathematics', 'Geography', 'Detector', 'Mathematical analysis', 'Archaeology', 'Telecommunications']","We extend Generative Adversarial Networks (GANs) to the semi-supervised context by forcing the discriminator network to output class labels. We train a generative model G and a discriminator D on a dataset with inputs belonging to one of N classes. At training time, D is made to predict which of N+1 classes the input belongs to, where an extra class is added to correspond to the outputs of G. We show that this method can be used to create a more data-efficient classifier and that it allows for generating higher quality samples than a regular GAN."
https://openalex.org/W3134210100,Graph Self-Supervised Learning: A Survey,"{'Deep': [0], 'learning': [1, 37, 58], 'on': [2, 16, 49, 66, 77], 'graphs': [3, 78], 'has': [4, 52, 79], 'attracted': [5], 'significant': [6], 'interests': [7], 'recently.': [8], 'However,': [9], 'most': [10], 'of': [11, 90, 101, 122, 129, 151, 171], 'the': [12, 88, 102, 120, 127, 149, 160, 177], 'works': [13], 'have': [14], 'focused': [15], '(semi-)': [17], 'supervised': [18], 'learning,': [19, 93], 'resulting': [20], 'in': [21, 184], 'shortcomings': [22], 'including': [23], 'heavy': [24], 'label': [25], 'reliance,': [26], 'poor': [27], 'generalization,': [28], 'and': [29, 56, 72, 85, 98, 143, 158, 168, 180], 'weak': [30], 'robustness.': [31], 'To': [32], 'address': [33], 'these': [34, 134], 'issues,': [35], 'self-supervised': [36, 92], '(SSL),': [38], 'which': [39, 105], 'extracts': [40], 'informative': [41], 'knowledge': [42], 'through': [43], 'well-designed': [44], 'pretext': [45, 130], 'tasks': [46], 'without': [47], 'relying': [48], 'manual': [50], 'labels,': [51], 'become': [53], 'a': [54, 96, 114], 'promising': [55], 'trending': [57], 'paradigm': [59, 121], 'for': [60, 109], 'graph': [61, 91, 110, 123, 152, 172], 'data.': [62, 111], 'Different': [63], 'from': [64], 'SSL': [65, 76, 107, 153], 'other': [67], 'domains': [68], 'like': [69], 'computer': [70], 'vision': [71], 'natural': [73], 'language': [74], 'processing,': [75], 'an': [80], 'exclusive': [81], 'background,': [82], 'design': [83], 'ideas,': [84], 'taxonomies.': [86], 'Under': [87], 'umbrella': [89], 'we': [94, 132, 175], 'present': [95], 'timely': [97], 'comprehensive': [99], 'review': [100], 'existing': [103], 'approaches': [104, 135], 'employ': [106], 'techniques': [108], 'We': [112, 146], 'construct': [113], 'unified': [115], 'framework': [116], 'that': [117], 'mathematically': [118], 'formalizes': [119], 'SSL.': [124, 173], 'According': [125], 'to': [126], 'objectives': [128], 'tasks,': [131], 'divide': [133], 'into': [136], 'four': [137], 'categories:': [138], 'generation-based,': [139], 'auxiliary': [140], 'property-based,': [141], 'contrast-based,': [142], 'hybrid': [144], 'approaches.': [145], 'further': [147], 'describe': [148], 'applications': [150], 'across': [154], 'various': [155], 'research': [156, 186], 'fields': [157], 'summarize': [159], 'commonly': [161], 'used': [162], 'datasets,': [163], 'evaluation': [164], 'benchmark,': [165], 'performance': [166], 'comparison': [167], 'open-source': [169], 'codes': [170], 'Finally,': [174], 'discuss': [176], 'remaining': [178], 'challenges': [179], 'potential': [181], 'future': [182], 'directions': [183], 'this': [185], 'field.': [187], 'IEEE': [188]}",2022,"['Computer science', 'Artificial intelligence', 'Machine learning', 'Graph', 'Theoretical computer science', 'Robustness (evolution)', 'Semi-supervised learning', 'Chemistry', 'Gene', 'Biochemistry']","Deep learning on graphs has attracted significant interests recently. However, most of the works have focused on (semi-) supervised learning, resulting in shortcomings including heavy label reliance, poor generalization, and weak robustness. To address these issues, self-supervised learning (SSL), which extracts informative knowledge through well-designed pretext tasks without relying on manual labels, has become a promising and trending learning paradigm for graph data. Different from SSL on other domains like computer vision and natural language processing, SSL on graphs has an exclusive background, design ideas, and taxonomies. Under the umbrella of graph self-supervised learning, we present a timely and comprehensive review of the existing approaches which employ SSL techniques for graph data. We construct a unified framework that mathematically formalizes the paradigm of graph SSL. According to the objectives of pretext tasks, we divide these approaches into four categories: generation-based, auxiliary property-based, contrast-based, and hybrid approaches. We further describe the applications of graph SSL across various research fields and summarize the commonly used datasets, evaluation benchmark, performance comparison and open-source codes of graph SSL. Finally, we discuss the remaining challenges and potential future directions in this research field. IEEE"
https://openalex.org/W2996108195,DivideMix: Learning with Noisy Labels as Semi-supervised Learning,"{'Deep': [0], 'neural': [1], 'networks': [2, 113], 'are': [3], 'known': [4], 'to': [5, 13, 69], 'be': [6], 'annotation-hungry.': [7], 'Numerous': [8], 'efforts': [9], 'have': [10], 'been': [11], 'devoted': [12], 'reducing': [14], 'the': [15, 61, 72, 91, 95, 118, 122, 126, 132], 'annotation': [16], 'cost': [17], 'when': [18], 'learning': [19, 27, 33, 48, 55], 'with': [20, 28, 49, 65, 79, 86], 'deep': [21], 'networks.': [22], 'Two': [23], 'prominent': [24], 'directions': [25], 'include': [26], 'noisy': [29, 50, 87], 'labels': [30, 51], 'and': [31, 82, 89, 97, 139, 144], 'semi-supervised': [32, 54, 102, 127], 'by': [34, 52, 135], 'exploiting': [35], 'unlabeled': [36, 84, 98, 145], 'data.': [37], 'In': [38, 57], 'this': [39], 'work,': [40], 'we': [41, 108, 130], 'propose': [42], 'DivideMix,': [43], 'a': [44, 66, 76, 101], 'novel': [45], 'framework': [46], 'for': [47], 'leveraging': [53], 'techniques.': [56], 'particular,': [58], 'DivideMix': [59], 'models': [60], 'per-sample': [62], 'loss': [63], 'distribution': [64], 'mixture': [67], 'model': [68, 92], 'dynamically': [70], 'divide': [71], 'training': [73, 128], 'data': [74, 99], 'into': [75], 'labeled': [77, 96, 143], 'set': [78, 85], 'clean': [80], 'samples': [81], 'an': [83], 'samples,': [88, 146], 'trains': [90], 'on': [93, 142, 149], 'both': [94], 'in': [100], 'manner.': [103], 'To': [104], 'avoid': [105], 'confirmation': [106], 'bias,': [107], 'simultaneously': [109], 'train': [110], 'two': [111], 'diverged': [112], 'where': [114], 'each': [115], 'network': [116], 'uses': [117], 'dataset': [119], 'division': [120], 'from': [121], 'other': [123], 'network.': [124], 'During': [125], 'phase,': [129], 'improve': [131], 'MixMatch': [133], 'strategy': [134], 'performing': [136], 'label': [137, 140], 'co-refinement': [138], 'co-guessing': [141], 'respectively.': [147], 'Experiments': [148], 'multiple': [150], 'benchmark': [151], 'datasets': [152], 'demonstrate': [153], 'substantial': [154], 'improvements': [155], 'over': [156], 'state-of-the-art': [157], 'methods.': [158], 'Code': [159], 'is': [160], 'available': [161], 'at': [162], 'https://github.com/LiJunnan1992/DivideMix': [163], '.': [164]}",2020,"['Computer science', 'Artificial intelligence', 'Benchmark (surveying)', 'Annotation', 'Machine learning', 'Semi-supervised learning', 'Supervised learning', 'Deep learning', 'Labeled data', 'Artificial neural network', 'Set (abstract data type)', 'Sample (material)', 'Code (set theory)', 'Pattern recognition (psychology)', 'Programming language', 'Geography', 'Chemistry', 'Geodesy', 'Chromatography']","Deep neural networks are known to be annotation-hungry. Numerous efforts have been devoted to reducing the annotation cost when learning with deep networks. Two prominent directions include learning with noisy labels and semi-supervised learning by exploiting unlabeled data. In this work, we propose DivideMix, a novel framework for learning with noisy labels by leveraging semi-supervised learning techniques. In particular, DivideMix models the per-sample loss distribution with a mixture model to dynamically divide the training data into a labeled set with clean samples and an unlabeled set with noisy samples, and trains the model on both the labeled and unlabeled data in a semi-supervised manner. To avoid confirmation bias, we simultaneously train two diverged networks where each network uses the dataset division from the other network. During the semi-supervised training phase, we improve the MixMatch strategy by performing label co-refinement and label co-guessing on labeled and unlabeled samples, respectively. Experiments on multiple benchmark datasets demonstrate substantial improvements over state-of-the-art methods. Code is available at https://github.com/LiJunnan1992/DivideMix ."
https://openalex.org/W2950538796,Equality of Opportunity in Supervised Learning,"{'We': [0, 116], 'propose': [1], 'a': [2, 7, 147], 'criterion': [3], 'for': [4], 'discrimination': [5, 53], 'against': [6], 'specified': [8], 'sensitive': [9], 'attribute': [10], 'in': [11, 34], 'supervised': [12], 'learning,': [13], 'where': [14], 'the': [15, 29, 35, 65, 74, 82, 98, 102, 104, 107, 118], 'goal': [16], 'is': [17, 92], 'to': [18, 43, 51, 55, 73], 'predict': [19], 'some': [20], 'target': [21, 105], 'based': [22, 126], 'on': [23, 97, 112, 127], 'available': [24], 'features.': [25], 'Assuming': [26], 'data': [27], 'about': [28], 'predictor,': [30, 103], 'target,': [31], 'and': [32, 106, 123, 134], 'membership': [33], 'protected': [36, 108], 'group': [37], 'are': [38], 'available,': [39], 'we': [40], 'show': [41], 'how': [42], 'optimally': [44], 'adjust': [45], 'any': [46], 'learned': [47], 'predictor': [48], 'so': [49], 'as': [50], 'remove': [52], 'according': [54], 'our': [56, 90, 144], 'definition.': [57], 'Our': [58], 'framework': [59], 'also': [60], 'improves': [61], 'incentives': [62], 'by': [63, 80], 'shifting': [64], 'cost': [66], 'of': [67, 101, 114, 121, 150], 'poor': [68], 'classification': [69, 83], 'from': [70, 138], 'disadvantaged': [71], 'groups': [72], 'decision': [75], 'maker,': [76], 'who': [77], 'can': [78, 133], 'respond': [79], 'improving': [81], 'accuracy.': [84], '\r\nIn': [85], 'line': [86], 'with': [87], 'other': [88], 'studies,': [89], 'notion': [91, 145], 'oblivious:': [93], 'it': [94], 'depends': [95], 'only': [96], 'joint': [99], 'statistics': [100], 'attribute,': [109], 'but': [110], 'not': [111], 'interpretation': [113], 'individualfeatures.': [115], 'study': [117, 149], 'inherent': [119], 'limits': [120], 'defining': [122], 'identifying': [124], 'biases': [125], 'such': [128], 'oblivious': [129, 140], 'measures,': [130], 'outlining': [131], 'what': [132], 'cannot': [135], 'be': [136], 'inferred': [137], 'different': [139], 'tests.': [141], '\r\nWe': [142], 'illustrate': [143], 'using': [146], 'case': [148], 'FICO': [151], 'credit': [152], 'scores.': [153]}",2016,"['Computer science', 'Machine learning', 'Disadvantaged', 'Interpretation (philosophy)', 'Artificial intelligence', 'Incentive', 'Decision maker', 'Line (geometry)', 'Mathematics', 'Microeconomics', 'Economics', 'Operations research', 'Programming language', 'Geometry', 'Economic growth']","We propose a criterion for discrimination against a specified sensitive attribute in supervised learning, where the goal is to predict some target based on available features. Assuming data about the predictor, target, and membership in the protected group are available, we show how to optimally adjust any learned predictor so as to remove discrimination according to our definition. Our framework also improves incentives by shifting the cost of poor classification from disadvantaged groups to the decision maker, who can respond by improving the classification accuracy. 
In line with other studies, our notion is oblivious: it depends only on the joint statistics of the predictor, the target and the protected attribute, but not on interpretation of individualfeatures. We study the inherent limits of defining and identifying biases based on such oblivious measures, outlining what can and cannot be inferred from different oblivious tests. 
We illustrate our notion using a case study of FICO credit scores."
https://openalex.org/W3135367836,Learning Transferable Visual Models From Natural Language Supervision,"{'State-of-the-art': [0], 'computer': [1, 135], 'vision': [2, 136], 'systems': [3], 'are': [4], 'trained': [5, 205], 'to': [6, 31, 77, 103, 118, 159, 194], 'predict': [7], 'a': [8, 45, 50, 85, 167], 'fixed': [9], 'set': [10], 'of': [11, 18, 54, 63, 87, 115, 125, 151, 185, 197], 'predetermined': [12], 'object': [13, 153], 'categories.': [14], 'This': [15], 'restricted': [16], 'form': [17], 'supervision': [19], 'limits': [20], 'their': [21], 'generality': [22], 'and': [23, 74, 148, 162, 211], 'usability': [24], 'since': [25], 'additional': [26], 'labeled': [27], 'data': [28], 'is': [29, 44, 71, 101, 163], 'needed': [30], 'specify': [32], 'any': [33, 175, 196], 'other': [34], 'visual': [35, 106], 'concept.': [36], 'Learning': [37], 'directly': [38], 'from': [39, 82, 94], 'raw': [40], 'text': [41], 'about': [42], 'images': [43], 'promising': [46], 'alternative': [47], 'which': [48, 65, 69], 'leverages': [49], 'much': [51], 'broader': [52], 'source': [53], 'supervision.': [55], 'We': [56, 121, 207], 'demonstrate': [57], 'that': [58], 'the': [59, 95, 116, 123, 172, 183, 186, 198], 'simple': [60], 'pre-training': [61], 'task': [62], 'predicting': [64], 'caption': [66], 'goes': [67], 'with': [68, 166], 'image': [70, 80], 'an': [72], 'efficient': [73], 'scalable': [75], 'way': [76], 'learn': [78], 'SOTA': [79], 'representations': [81], 'scratch': [83], 'on': [84, 130, 189], 'dataset': [86, 176], '400': [88], 'million': [89, 200], '(image,': [90], 'text)': [91], 'pairs': [92], 'collected': [93], 'internet.': [96], 'After': [97], 'pre-training,': [98], 'natural': [99], 'language': [100], 'used': [102], 'reference': [104], 'learned': [105], 'concepts': [107], '(or': [108], 'describe': [109], 'new': [110], 'ones)': [111], 'enabling': [112], 'zero-shot': [113, 191], 'transfer': [114], 'model': [117, 156, 213], 'downstream': [119], 'tasks.': [120], 'study': [122], 'performance': [124], 'this': [126], 'approach': [127], 'by': [128], 'benchmarking': [129], 'over': [131], '30': [132], 'different': [133], 'existing': [134], 'datasets,': [137], 'spanning': [138], 'tasks': [139, 161], 'such': [140], 'as': [141], 'OCR,': [142], 'action': [143], 'recognition': [144], 'in': [145], 'videos,': [146], 'geo-localization,': [147], 'many': [149], 'types': [150], 'fine-grained': [152], 'classification.': [154], 'The': [155], 'transfers': [157], 'non-trivially': [158], 'most': [160], 'often': [164], 'competitive': [165], 'fully': [168], 'supervised': [169], 'baseline': [170], 'without': [171, 192], 'need': [173], 'for': [174], 'specific': [177], 'training.': [178], 'For': [179], 'instance,': [180], 'we': [181], 'match': [182], 'accuracy': [184], 'original': [187], 'ResNet-50': [188], 'ImageNet': [190], 'needing': [193], 'use': [195], '1.28': [199], 'training': [201], 'examples': [202], 'it': [203], 'was': [204], 'on.': [206], 'release': [208], 'our': [209], 'code': [210], 'pre-trained': [212], 'weights': [214], 'at': [215], 'https://github.com/OpenAI/CLIP.': [216]}",2021,"['Computer science', 'Artificial intelligence', 'Generality', 'Transfer of learning', 'Task (project management)', 'Object (grammar)', 'Scalability', 'Natural language processing', 'Machine learning', 'Natural language', 'Set (abstract data type)', 'Usability', 'Human–computer interaction', 'Database', 'Programming language', 'Management', 'Psychotherapist', 'Psychology', 'Economics']","State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. Learning directly from raw text about images is a promising alternative which leverages a much broader source of supervision. We demonstrate that the simple pre-training task of predicting which caption goes with which image is an efficient and scalable way to learn SOTA image representations from scratch on a dataset of 400 million (image, text) pairs collected from the internet. After pre-training, natural language is used to reference learned visual concepts (or describe new ones) enabling zero-shot transfer of the model to downstream tasks. We study the performance of this approach by benchmarking on over 30 different existing computer vision datasets, spanning tasks such as OCR, action recognition in videos, geo-localization, and many types of fine-grained object classification. The model transfers non-trivially to most tasks and is often competitive with a fully supervised baseline without the need for any dataset specific training. For instance, we match the accuracy of the original ResNet-50 on ImageNet zero-shot without needing to use any of the 1.28 million training examples it was trained on. We release our code and pre-trained model weights at https://github.com/OpenAI/CLIP."
https://openalex.org/W2431080869,Regularization With Stochastic Transformations and Perturbations for Deep Semi-Supervised Learning,"{'Effective': [0], 'convolutional': [1, 57], 'neural': [2, 58], 'networks': [3], 'are': [4, 78], 'trained': [5, 79], 'on': [6, 143], 'large': [7, 14], 'sets': [8], 'of': [9, 42, 53, 85, 102, 114, 118, 128, 131], 'labeled': [10, 15, 43], 'data.': [11], 'However,': [12], 'creating': [13], 'datasets': [16], 'is': [17, 38], 'a': [18, 31, 39, 132], 'very': [19], 'costly': [20], 'and': [21, 67, 73, 121], 'time-consuming': [22], 'task.': [23], 'Semi-supervised': [24], 'learning': [25, 55], 'uses': [26], 'unlabeled': [27], 'data': [28, 44, 64], 'to': [29, 94, 98], 'train': [30], 'model': [32], 'with': [33, 56], 'higher': [34], 'accuracy': [35], 'when': [36], 'there': [37], 'limited': [40], 'set': [41], 'available.': [45], 'In': [46], 'this': [47], 'paper,': [48], 'we': [49], 'consider': [50], 'the': [51, 90, 99, 115, 123, 126, 136, 140], 'problem': [52], 'semi-supervised': [54], 'networks.': [59], 'Techniques': [60], 'such': [61], 'as': [62], 'randomized': [63], 'augmentation,': [65], 'dropout': [66], 'random': [68], 'max-pooling': [69], 'provide': [70], 'better': [71], 'generalization': [72], 'stability': [74], 'for': [75], 'classifiers': [76], 'that': [77, 111], 'using': [80], 'gradient': [81], 'descent.': [82], 'Multiple': [83], 'passes': [84, 130], 'an': [86, 107], 'individual': [87], 'sample': [88, 134], 'through': [89, 135], 'network': [91], 'might': [92], 'lead': [93], 'different': [95], 'predictions': [96, 127], 'due': [97], 'non-deterministic': [100], 'behavior': [101], 'these': [103, 119], 'techniques.': [104], 'We': [105, 138], 'propose': [106], 'unsupervised': [108], 'loss': [109], 'function': [110], 'takes': [112], 'advantage': [113], 'stochastic': [116], 'nature': [117], 'methods': [120], 'minimizes': [122], 'difference': [124], 'between': [125], 'multiple': [129], 'training': [133], 'network.': [137], 'evaluate': [139], 'proposed': [141], 'method': [142], 'several': [144], 'benchmark': [145], 'datasets.': [146]}",2016,"['Regularization (linguistics)', 'Artificial intelligence', 'Computer science', 'Deep learning', 'Machine learning']","Effective convolutional neural networks are trained on large sets of labeled data. However, creating large labeled datasets is a very costly and time-consuming task. Semi-supervised learning uses unlabeled data to train a model with higher accuracy when there is a limited set of labeled data available. In this paper, we consider the problem of semi-supervised learning with convolutional neural networks. Techniques such as randomized data augmentation, dropout and random max-pooling provide better generalization and stability for classifiers that are trained using gradient descent. Multiple passes of an individual sample through the network might lead to different predictions due to the non-deterministic behavior of these techniques. We propose an unsupervised loss function that takes advantage of the stochastic nature of these methods and minimizes the difference between the predictions of multiple passes of a training sample through the network. We evaluate the proposed method on several benchmark datasets."
https://openalex.org/W3065542300,S3-Rec: Self-Supervised Learning for Sequential Recommendation with Mutual Information Maximization,"{'Recently,': [0], 'significant': [1], 'progress': [2], 'has': [3, 57], 'been': [4, 59], 'made': [5], 'in': [6, 153], 'sequential': [7, 13, 64, 111], 'recommendation\\nwith': [8], 'deep': [9], 'learning.': [10], 'Existing': [11], 'neural': [12, 85], 'recommendation': [14], 'models': [15], 'usually\\nrely': [16], 'on': [17, 82, 159], 'the': [18, 29, 45, 71, 83, 95, 104, 123, 132, 143, 163], 'item': [19], 'prediction': [20], 'loss': [21, 34], 'to': [22, 37, 93, 121, 186], 'learn': [23, 122], 'model': [24, 30, 72], 'parameters': [25], 'or': [26, 49], 'data\\nrepresentations.': [27], 'However,': [28], 'trained': [31], 'with': [32], 'this': [33, 68], 'is': [35, 92], 'prone': [36], 'suffer\\nfrom': [38], 'data': [39, 53, 56, 97, 105], 'sparsity': [40], 'problem.': [41], 'Since': [42], 'it': [43], 'overemphasizes': [44], 'final': [46], 'performance,': [47], 'the\\nassociation': [48], 'fusion': [50], 'between': [51, 145], 'context': [52], 'and': [54, 61, 102, 128], 'sequence': [55, 129], 'not': [58], 'well\\ncaptured': [60], 'utilized': [62], 'for': [63, 76, 109], 'recommendation.': [65, 112], 'To': [66], 'tackle': [67], 'problem,': [69], 'we\\npropose': [70], 'S^3-Rec,': [73], 'which': [74, 150, 189], 'stands': [75], 'Self-Supervised': [77], 'learning': [78, 184], 'for\\nSequential': [79], 'Recommendation,': [80], 'based': [81], 'self-attentive': [84], 'architecture.': [86], 'The\\nmain': [87], 'idea': [88], 'of': [89, 148, 165], 'our': [90, 114, 154, 166, 182], 'approach': [91], 'utilize': [94], 'intrinsic': [96], 'correlation': [98, 144], 'to\\nderive': [99], 'self-supervision': [100], 'signals': [101], 'enhance': [103], 'representations': [106], 'via\\npre-training': [107], 'methods': [108], 'improving': [110], 'For': [113], 'task,': [115], 'we\\ndevise': [116], 'four': [117], 'auxiliary': [118], 'self-supervised': [119, 183], 'objectives': [120], 'correlations\\namong': [124], 'attribute,': [125], 'item,': [126], 'subsequence,': [127], 'by': [130], 'utilizing': [131], 'mutual\\ninformation': [133], 'maximization': [134], '(MIM)': [135], 'principle.': [136], 'MIM': [137], 'provides': [138], 'a': [139], 'unified': [140], 'way': [141], 'to\\ncharacterize': [142], 'different': [146], 'types': [147], 'data,': [149], 'is\\nparticularly': [151], 'suitable': [152], 'scenario.': [155], 'Extensive': [156], 'experiments': [157], 'conducted': [158], 'six\\nreal-world': [160], 'datasets': [161], 'demonstrate': [162], 'superiority': [164], 'proposed': [167], 'method': [168, 185], 'over\\nexisting': [169], 'state-of-the-art': [170], 'methods,': [171], 'especially': [172], 'when': [173], 'only': [174], 'limited': [175], 'training': [176], 'data\\nis': [177], 'available.': [178], 'Besides,': [179], 'we': [180], 'extend': [181], 'other\\nrecommendation': [187], 'models,': [188], 'also': [190], 'improve': [191], 'their': [192], 'performance.\\n': [193]}",2020,[],"Recently, significant progress has been made in sequential recommendation\nwith deep learning. Existing neural sequential recommendation models usually\nrely on the item prediction loss to learn model parameters or data\nrepresentations. However, the model trained with this loss is prone to suffer\nfrom data sparsity problem. Since it overemphasizes the final performance, the\nassociation or fusion between context data and sequence data has not been well\ncaptured and utilized for sequential recommendation. To tackle this problem, we\npropose the model S^3-Rec, which stands for Self-Supervised learning for\nSequential Recommendation, based on the self-attentive neural architecture. The\nmain idea of our approach is to utilize the intrinsic data correlation to\nderive self-supervision signals and enhance the data representations via\npre-training methods for improving sequential recommendation. For our task, we\ndevise four auxiliary self-supervised objectives to learn the correlations\namong attribute, item, subsequence, and sequence by utilizing the mutual\ninformation maximization (MIM) principle. MIM provides a unified way to\ncharacterize the correlation between different types of data, which is\nparticularly suitable in our scenario. Extensive experiments conducted on six\nreal-world datasets demonstrate the superiority of our proposed method over\nexisting state-of-the-art methods, especially when only limited training data\nis available. Besides, we extend our self-supervised learning method to other\nrecommendation models, which also improve their performance.\n"
https://openalex.org/W1981613567,Multimodal semi-supervised learning for image classification,"{'International': [0], 'audience': [1]}",2010,"['Artificial intelligence', 'Computer science', 'Support vector machine', 'Multiple kernel learning', 'Pattern recognition (psychology)', 'Classifier (UML)', 'Categorization', 'Pascal (unit)', 'Machine learning', 'Binary classification', 'Semi-supervised learning', 'Supervised learning', 'Labeled data', 'Contextual image classification', 'Image (mathematics)', 'Kernel method', 'Artificial neural network', 'Programming language']",International audience
https://openalex.org/W1900101064,A Scaled Conjugate Gradient Algorithm for Fast Supervised Learning,"{'&lt;p&gt;A': [0], 'supervised': [1], 'learning': [2], 'algorithm': [3, 15, 72, 85], '(Scaled': [4], 'Conjugate': [5, 31], 'Gradient,': [6], 'SCG)': [7], 'with': [8], 'superlinear': [9], 'convergence': [10, 106], 'rate': [11], 'is': [12, 16, 51, 63, 121, 198, 205], 'introduced.': [13], 'The': [14, 59, 101, 168], 'based': [17], 'upon': [18], 'a': [19, 89, 131, 160], 'class': [20], 'of': [21, 54, 61, 68, 91, 96, 159, 172], 'optimization': [22], 'techniques': [23], 'well': [24], 'known': [25], 'in': [26, 56, 114, 140, 143, 156], 'numerical': [27], 'analysis': [28], 'as': [29], 'the': [30, 40, 52, 57, 66, 69, 74, 80, 105, 109, 116, 118, 157, 165, 170, 173, 178, 181, 183, 186], 'Gradient': [32], 'Methods.': [33], 'SCG': [34, 62, 87, 120, 208], 'uses': [35], 'second': [36], 'order': [37, 95, 144], 'information': [38, 155], 'from': [39], 'neural': [41, 161, 174], 'network': [42, 162, 175], 'but': [43], 'requires': [44], 'only': [45], 'O(N)': [46], 'memory': [47], 'usage,': [48], 'where': [49], 'N': [50], 'number': [53], 'weights': [55], 'network.': [58], 'performance': [60, 67], 'benchmarked': [64], 'against': [65], 'standard': [70], 'backpropagation': [71, 77], '(BP),': [73], 'conjugate': [75], 'gradient': [76], '(CGB)': [78], 'and': [79, 129, 137], 'one-step': [81], 'Broyden-Fletcher-Goldfarb-Shanno': [82], 'memoryless': [83], 'quasi-Newton': [84], '(BFGS).': [86], 'yields': [88], 'speed-up': [90, 102], 'at': [92], 'least': [93], 'an': [94, 147], 'magnitude': [97], 'relative': [98, 176], 'to': [99, 145, 177], 'BP.': [100], 'depends': [103], 'on': [104, 200], 'criterion,': [107], 'i.e.,': [108], 'bigger': [110, 117, 182], 'demand': [111], 'for': [112], 'reduction': [113], 'error': [115], 'speed-up.': [119], 'fully': [122], 'automated': [123], 'including': [124], 'no': [125], 'user': [126], 'dependent': [127, 153], 'parameters': [128], 'avoids': [130], 'time': [132], 'consuming': [133], 'line-search,': [134], 'which': [135], 'CGB': [136], 'BFGS': [138], 'use': [139], 'each': [141], 'iteration': [142], 'determine': [146], 'appropriate': [148], 'step': [149], 'size.&lt;/p&gt;&lt;p&gt;': [150], '&lt;/p&gt;&lt;p&gt;Incorporating': [151], 'problem': [152, 179], 'structural': [154], 'architecture': [158], 'often': [163], 'lowers': [164], 'overall': [166], 'complexity.': [167], 'smaller': [169], 'complexity': [171], 'domain,': [180], 'possibility': [184], 'that': [185, 207], 'weight': [187], 'space': [188], 'contains': [189], 'long': [190], 'ravines': [191], 'characterized': [192], 'by': [193], 'sharp': [194], 'curvature.': [195], 'While': [196], 'BP': [197], 'inefficient': [199], 'these': [201], 'ravine': [202], 'phenomena,': [203], 'it': [204], 'shown': [206], 'handles': [209], 'them': [210], 'effectively.&lt;/p&gt;': [211]}",1990,"['Broyden–Fletcher–Goldfarb–Shanno algorithm', 'Conjugate gradient method', 'Backpropagation', 'Algorithm', 'Artificial neural network', 'Nonlinear conjugate gradient method', 'Convergence (economics)', 'Gradient method', 'Mathematics', 'Computer science', 'Gradient descent', 'Mathematical optimization', 'Artificial intelligence', 'Telecommunications', 'Asynchronous communication', 'Economic growth', 'Economics']","&lt;p&gt;A supervised learning algorithm (Scaled Conjugate Gradient, SCG) with superlinear convergence rate is introduced. The algorithm is based upon a class of optimization techniques well known in numerical analysis as the Conjugate Gradient Methods. SCG uses second order information from the neural network but requires only O(N) memory usage, where N is the number of weights in the network. The performance of SCG is benchmarked against the performance of the standard backpropagation algorithm (BP), the conjugate gradient backpropagation (CGB) and the one-step Broyden-Fletcher-Goldfarb-Shanno memoryless quasi-Newton algorithm (BFGS). SCG yields a speed-up of at least an order of magnitude relative to BP. The speed-up depends on the convergence criterion, i.e., the bigger demand for reduction in error the bigger the speed-up. SCG is fully automated including no user dependent parameters and avoids a time consuming line-search, which CGB and BFGS use in each iteration in order to determine an appropriate step size.&lt;/p&gt;&lt;p&gt; &lt;/p&gt;&lt;p&gt;Incorporating problem dependent structural information in the architecture of a neural network often lowers the overall complexity. The smaller the complexity of the neural network relative to the problem domain, the bigger the possibility that the weight space contains long ravines characterized by sharp curvature. While BP is inefficient on these ravine phenomena, it is shown that SCG handles them effectively.&lt;/p&gt;"
https://openalex.org/W1982978808,Short-Term Traffic Flow Forecasting: An Experimental Comparison of Time-Series Analysis and Supervised Learning,"{'The': [0, 63, 149], 'literature': [1], 'on': [2, 109], 'short-term': [3, 76], 'traffic': [4, 77, 132], 'flow': [5, 78, 133], 'forecasting': [6, 79], 'has': [7], 'undergone': [8], 'great': [9], 'development': [10], 'recently.': [11], 'Many': [12], 'works,': [13], 'describing': [14], 'a': [15, 52, 96, 110, 154], 'wide': [16], 'variety': [17], 'of': [18, 55, 60, 65, 85], 'different': [19, 40], 'approaches,': [20], 'which': [21, 94, 124], 'very': [22], 'often': [23], 'share': [24], 'similar': [25], 'features': [26], 'and': [27, 44, 58, 103, 135, 146], 'ideas,': [28], 'have': [29], 'been': [30], 'published.': [31], 'However,': [32], 'publications': [33], 'presenting': [34, 89], 'new': [35, 119], 'prediction': [36, 144], 'algorithms': [37], 'usually': [38], 'employ': [39], 'settings,': [41], 'data': [42, 113], 'sets,': [43], 'performance': [45, 101], 'measurements,': [46], 'making': [47], 'it': [48], 'difficult': [49], 'to': [50, 75, 107, 128, 138, 171], 'infer': [51], 'clear': [53], 'picture': [54], 'the': [56, 82, 105, 158, 163, 179], 'advantages': [57], 'limitations': [59], 'each': [61], 'model.': [62], 'aim': [64], 'this': [66], 'paper': [67], 'is': [68, 157], 'twofold.': [69], 'First,': [70], 'we': [71, 116], 'review': [72], 'existing': [73], 'approaches': [74], 'methods': [80], 'under': [81], 'common': [83, 97], 'view': [84], 'probabilistic': [86], 'graphical': [87], 'models,': [88, 123], 'an': [90, 140], 'extensive': [91], 'experimental': [92], 'comparison,': [93], 'proposes': [95], 'baseline': [98], 'for': [99], 'their': [100], 'analysis': [102], 'provides': [104], 'infrastructure': [106], 'operate': [108], 'publicly': [111], 'available': [112], 'set.': [114], 'Second,': [115], 'present': [117], 'two': [118], 'support': [120, 166], 'vector': [121, 167], 'regression': [122], 'are': [125, 136], 'specifically': [126], 'devised': [127], 'benefit': [129], 'from': [130], 'typical': [131], 'seasonality': [134], 'shown': [137], 'represent': [139], 'interesting': [141], 'compromise': [142], 'between': [143], 'accuracy': [145], 'computational': [147], 'efficiency.': [148], 'SARIMA': [150], 'model': [151], 'coupled': [152], 'with': [153], 'Kalman': [155], 'filter': [156], 'most': [159, 180], 'accurate': [160], 'model;': [161], 'however,': [162], 'proposed': [164], 'seasonal': [165], 'regressor': [168], 'turns': [169], 'out': [170], 'be': [172], 'highly': [173], 'competitive': [174], 'when': [175], 'performing': [176], 'forecasts': [177], 'during': [178], 'congested': [181], 'periods.': [182], '©': [183], '2011': [184], 'IEEE.': [185]}",2013,"['Computer science', 'Kalman filter', 'Traffic flow (computer networking)', 'Probabilistic forecasting', 'Term (time)', 'Probabilistic logic', 'Time series', 'Machine learning', 'Set (abstract data type)', 'Data mining', 'Graphical model', 'Artificial intelligence', 'Programming language', 'Physics', 'Computer security', 'Quantum mechanics']","The literature on short-term traffic flow forecasting has undergone great development recently. Many works, describing a wide variety of different approaches, which very often share similar features and ideas, have been published. However, publications presenting new prediction algorithms usually employ different settings, data sets, and performance measurements, making it difficult to infer a clear picture of the advantages and limitations of each model. The aim of this paper is twofold. First, we review existing approaches to short-term traffic flow forecasting methods under the common view of probabilistic graphical models, presenting an extensive experimental comparison, which proposes a common baseline for their performance analysis and provides the infrastructure to operate on a publicly available data set. Second, we present two new support vector regression models, which are specifically devised to benefit from typical traffic flow seasonality and are shown to represent an interesting compromise between prediction accuracy and computational efficiency. The SARIMA model coupled with a Kalman filter is the most accurate model; however, the proposed seasonal support vector regressor turns out to be highly competitive when performing forecasts during the most congested periods. © 2011 IEEE."
https://openalex.org/W2620474507,SuperSpike: Supervised Learning in Multilayer Spiking Neural Networks,"{'A': [0], 'vast': [1], 'majority': [2], 'of': [3, 17, 25, 56, 83, 87, 111, 145, 167], 'computation': [4, 170], 'in': [5, 34, 45, 49, 59, 171], 'the': [6, 15, 54, 109, 159], 'brain': [7], 'is': [8], 'performed': [9], 'by': [10, 67, 101, 175], 'spiking': [11, 28, 47, 63, 172], 'neural': [12, 29, 64, 173], 'networks.': [13, 65], 'Despite': [14], 'ubiquity': [16], 'such': [18, 43], 'spiking,': [19], 'we': [20, 40, 52, 73, 107, 128], 'currently': [21], 'lack': [22], 'an': [23], 'understanding': [24, 166], 'how': [26, 39], 'biological': [27], 'circuits': [30, 48], 'learn': [31], 'and': [32, 132, 169], 'compute': [33], 'vivo,': [35], 'as': [36, 38], 'well': [37], 'can': [41, 139], 'instantiate': [42], 'capabilities': [44], 'artificial': [46], 'silico.': [50], 'Here': [51], 'revisit': [53], 'problem': [55], 'supervised': [57], 'learning': [58, 80, 113, 168], 'temporally': [60], 'coding': [61], 'multilayer': [62, 85], 'First,': [66], 'using': [68], 'a': [69, 76, 163], 'surrogate': [70], 'gradient': [71], 'approach,': [72], 'derive': [74], 'SuperSpike,': [75], 'nonlinear': [77, 93, 184], 'voltage-based': [78], 'three-factor': [79], 'rule': [81, 114], 'capable': [82], 'training': [84], 'networks': [86, 174], 'deterministic': [88], 'integrate-and-fire': [89], 'neurons': [90], 'to': [91, 124, 161, 179, 182], 'perform': [92], 'computations': [94], 'on': [95, 104], 'spatiotemporal': [96, 190], 'spike': [97, 191], 'patterns.': [98, 193], 'Second,': [99], 'inspired': [100], 'recent': [102], 'results': [103, 157], 'feedback': [105], 'alignment,': [106], 'compare': [108], 'performance': [110], 'our': [112, 156, 177], 'under': [115], 'different': [116, 189], 'credit': [117], 'assignment': [118], 'strategies': [119], 'for': [120], 'propagating': [121], 'output': [122], 'errors': [123], 'hidden': [125], 'units.': [126], 'Specifically,': [127], 'test': [129], 'uniform,': [130], 'symmetric,': [131], 'random': [133], 'feedback,': [134, 146], 'finding': [135], 'that': [136], 'simpler': [137], 'tasks': [138, 150], 'be': [140], 'solved': [141], 'with': [142], 'any': [143], 'type': [144], 'while': [147], 'more': [148], 'complex': [149], 'require': [151], 'symmetric': [152], 'feedback.': [153], 'In': [154], 'summary,': [155], 'open': [158], 'door': [160], 'obtaining': [162], 'better': [164], 'scientific': [165], 'advancing': [176], 'ability': [178], 'train': [180], 'them': [181], 'solve': [183], 'problems': [185], 'involving': [186], 'transformations': [187], 'between': [188], 'time': [192]}",2018,[],"A vast majority of computation in the brain is performed by spiking neural networks. Despite the ubiquity of such spiking, we currently lack an understanding of how biological spiking neural circuits learn and compute in vivo, as well as how we can instantiate such capabilities in artificial spiking circuits in silico. Here we revisit the problem of supervised learning in temporally coding multilayer spiking neural networks. First, by using a surrogate gradient approach, we derive SuperSpike, a nonlinear voltage-based three-factor learning rule capable of training multilayer networks of deterministic integrate-and-fire neurons to perform nonlinear computations on spatiotemporal spike patterns. Second, inspired by recent results on feedback alignment, we compare the performance of our learning rule under different credit assignment strategies for propagating output errors to hidden units. Specifically, we test uniform, symmetric, and random feedback, finding that simpler tasks can be solved with any type of feedback, while more complex tasks require symmetric feedback. In summary, our results open the door to obtaining a better scientific understanding of learning and computation in spiking neural networks by advancing our ability to train them to solve nonlinear problems involving transformations between different spatiotemporal spike time patterns."
https://openalex.org/W3205500251,FlexMatch: Boosting Semi-Supervised Learning with Curriculum Pseudo Labeling,"{'The': [0, 74], 'recently': [1], 'proposed': [2], 'FixMatch': [3, 19, 116, 161, 192], 'achieved': [4], 'state-of-the-art': [5, 125], 'results': [6], 'on': [7, 127, 162], 'most': [8], 'semi-supervised': [9], 'learning': [10, 42, 45, 62, 72], '(SSL)': [11], 'benchmarks.': [12], 'However,': [13], 'like': [14], 'other': [15, 208], 'modern': [16], 'SSL': [17, 131, 209], 'algorithms,': [18], 'uses': [20], 'a': [21, 60, 128], 'pre-defined': [22], 'constant': [23], 'threshold': [24], 'for': [25, 83], 'all': [26], 'classes': [27, 85], 'to': [28, 34, 39, 64, 69, 79, 90, 115, 193, 207], 'select': [29], 'unlabeled': [30, 66, 94], 'data': [31, 67, 95, 140], 'that': [32, 201], 'contribute': [33], 'the': [35, 70, 138, 146, 180], 'training,': [36], 'thus': [37], 'failing': [38], 'consider': [40], 'different': [41, 48, 84], 'status': [43], 'and': [44, 96, 117, 155, 164, 211], 'difficulties': [46], 'of': [47, 76, 130, 191], 'classes.': [49], 'To': [50], 'address': [51], 'this': [52], 'issue,': [53], 'we': [54, 199], 'propose': [55], 'Curriculum': [56], 'Pseudo': [57], 'Labeling': [58], '(CPL),': [59], 'curriculum': [61], 'approach': [63], 'leverage': [65], 'according': [68], ""model's"": [71], 'status.': [73], 'core': [75], 'CPL': [77, 100, 114, 176, 202], 'is': [78, 148], 'flexibly': [80], 'adjust': [81], 'thresholds': [82], 'at': [86, 220], 'each': [87], 'time': [88, 190], 'step': [89], 'let': [91], 'pass': [92], 'informative': [93], 'their': [97, 214], 'pseudo': [98], 'labels.': [99], 'does': [101], 'not': [102], 'introduce': [103], 'additional': [104], 'parameters': [105], 'or': [106, 109, 144], 'computations': [107], '(forward': [108], 'backward': [110], 'propagation).': [111], 'We': [112, 216], 'apply': [113], 'call': [118], 'our': [119, 218], 'improved': [120], 'algorithm': [121], 'FlexMatch.': [122], 'FlexMatch': [123, 152, 184], 'achieves': [124, 153], 'performance': [126], 'variety': [129], 'benchmarks,': [132], 'with': [133], 'especially': [134], 'strong': [135], 'performances': [136], 'when': [137, 145, 168], 'labeled': [139], 'are': [141, 170], 'extremely': [142], 'limited': [143], 'task': [147], 'challenging.': [149], 'For': [150], 'example,': [151], '13.96%': [154], '18.96%': [156], 'error': [157], 'rate': [158], 'reduction': [159], 'over': [160], 'CIFAR-100': [163], 'STL-10': [165], 'datasets': [166], 'respectively,': [167], 'there': [169], 'only': [171, 187], '4': [172], 'labels': [173], 'per': [174], 'class.': [175], 'also': [177], 'significantly': [178], 'boosts': [179], 'convergence': [181], 'speed,': [182], 'e.g.,': [183], 'can': [185, 203], 'use': [186], '1/5': [188], 'training': [189], 'achieve': [194], 'even': [195], 'better': [196], 'performance.': [197], 'Furthermore,': [198], 'show': [200], 'be': [204], 'easily': [205], 'adapted': [206], 'algorithms': [210], 'remarkably': [212], 'improve': [213], 'performances.': [215], 'open-source': [217], 'code': [219], 'https://github.com/TorchSSL/TorchSSL.': [221]}",2021,"['Computer science', 'Boosting (machine learning)', 'Leverage (statistics)', 'Machine learning', 'Artificial intelligence', 'Semi-supervised learning', 'Computation', 'Class (philosophy)', 'Algorithm']","The recently proposed FixMatch achieved state-of-the-art results on most semi-supervised learning (SSL) benchmarks. However, like other modern SSL algorithms, FixMatch uses a pre-defined constant threshold for all classes to select unlabeled data that contribute to the training, thus failing to consider different learning status and learning difficulties of different classes. To address this issue, we propose Curriculum Pseudo Labeling (CPL), a curriculum learning approach to leverage unlabeled data according to the model's learning status. The core of CPL is to flexibly adjust thresholds for different classes at each time step to let pass informative unlabeled data and their pseudo labels. CPL does not introduce additional parameters or computations (forward or backward propagation). We apply CPL to FixMatch and call our improved algorithm FlexMatch. FlexMatch achieves state-of-the-art performance on a variety of SSL benchmarks, with especially strong performances when the labeled data are extremely limited or when the task is challenging. For example, FlexMatch achieves 13.96% and 18.96% error rate reduction over FixMatch on CIFAR-100 and STL-10 datasets respectively, when there are only 4 labels per class. CPL also significantly boosts the convergence speed, e.g., FlexMatch can use only 1/5 training time of FixMatch to achieve even better performance. Furthermore, we show that CPL can be easily adapted to other SSL algorithms and remarkably improve their performances. We open-source our code at https://github.com/TorchSSL/TorchSSL."
https://openalex.org/W2189089430,Weakly Supervised Learning of Semantic Parsers for Mapping Instructions to Actions,"{'The': [0, 55], 'context': [1, 41], 'in': [2], 'which': [3], 'language': [4, 47], 'is': [5], 'used': [6, 25], 'provides': [7, 58], 'a': [8, 27, 35, 95], 'strong': [9, 100], 'signal': [10], 'for': [11, 42, 85], 'learning': [12], 'to': [13, 72, 89, 115], 'recover': [14], 'its': [15], 'meaning.': [16], 'In': [17], 'this': [18], 'paper,': [19], 'we': [20], 'show': [21], 'it': [22], 'can': [23], 'be': [24], 'within': [26], 'grounded': [28], 'CCG': [29], 'semantic': [30], 'parsing': [31], 'approach': [32], 'that': [33, 80], 'learns': [34], 'joint': [36, 56], 'model': [37], 'of': [38, 52, 69, 105, 119], 'meaning': [39], 'and': [40, 44], 'interpreting': [43], 'executing': [45, 83, 109], 'natural': [46], 'instructions,': [48, 84], 'using': [49], 'various': [50], 'types': [51], 'weak': [53], 'supervision.': [54], 'nature': [57], 'crucial': [59], 'benefits': [60], 'by': [61, 87], 'allowing': [62], 'situated': [63], 'cues,': [64], 'such': [65], 'as': [66], 'the': [67, 116, 120], 'set': [68], 'visible': [70], 'objects,': [71], 'directly': [73], 'influence': [74], 'learning.': [75], 'It': [76], 'also': [77], 'enables': [78], 'algorithms': [79], 'learn': [81], 'while': [82], 'example': [86], 'trying': [88], 'replicate': [90], 'human': [91], 'actions.': [92], 'Experiments': [93], 'on': [94], 'benchmark': [96], 'navigational': [97], 'dataset': [98], 'demonstrate': [99], 'performance': [101], 'under': [102], 'differing': [103], 'forms': [104], 'supervision,': [106], 'including': [107], 'correctly': [108], '60%': [110], 'more': [111], 'instruction': [112], 'sets': [113], 'relative': [114], 'previous': [117], 'state': [118], 'art.': [121]}",2013,"['Computer science', 'Benchmark (surveying)', 'Parsing', 'Meaning (existential)', 'Natural language processing', 'Artificial intelligence', 'Context (archaeology)', 'Set (abstract data type)', 'Situated', 'Natural language', 'Replicate', 'Programming language', 'Biology', 'Psychology', 'Geography', 'Mathematics', 'Psychotherapist', 'Paleontology', 'Statistics', 'Geodesy']","The context in which language is used provides a strong signal for learning to recover its meaning. In this paper, we show it can be used within a grounded CCG semantic parsing approach that learns a joint model of meaning and context for interpreting and executing natural language instructions, using various types of weak supervision. The joint nature provides crucial benefits by allowing situated cues, such as the set of visible objects, to directly influence learning. It also enables algorithms that learn while executing instructions, for example by trying to replicate human actions. Experiments on a benchmark navigational dataset demonstrate strong performance under differing forms of supervision, including correctly executing 60% more instruction sets relative to the previous state of the art."
https://openalex.org/W2158049734,Semi-Supervised Learning for Natural Language,"{'Statistical': [0], 'supervised': [1, 158], 'learning': [2], 'techniques': [3], 'have': [4], 'been': [5, 116], 'successful': [6], 'for': [7], 'many': [8], 'natural': [9, 62], 'language': [10, 63], 'processing': [11], 'tasks,': [12, 54, 73], 'but': [13], 'they': [14], 'require': [15], 'labeled': [16], 'datasets,': [17], 'which': [18], 'can': [19], 'be': [20], 'expensive': [21], 'to': [22, 86, 106, 138], 'obtain.': [23], 'On': [24], 'the': [25, 48, 108], 'other': [26], 'hand,': [27], 'unlabeled': [28], 'data': [29, 42], '(raw': [30], 'text)': [31], 'is': [32, 85, 105, 127, 151], 'often': [33], 'available': [34], '“for': [35], 'free': [36], '”': [37], 'in': [38, 46, 96, 111, 156], 'large': [39], 'quantities.': [40], 'Unlabeled': [41], 'has': [43, 115], 'shown': [44], 'promise': [45], 'improving': [47], 'performance': [49], 'of': [50, 53, 82, 91, 101, 121, 148], 'a': [51, 97, 112, 119, 131, 157, 161], 'number': [52], 'e.g.': [55], 'word': [56, 78, 103, 109], 'sense': [57], 'disambiguation,': [58], 'information': [59, 144], 'extraction,': [60], 'and': [61, 76, 88, 94, 141], 'parsing.': [64], 'In': [65, 130], 'this': [66, 149], 'thesis,': [67], 'we': [68, 134], 'focus': [69], 'on': [70], 'two': [71], 'segmentation': [72, 104], 'named-entity': [74, 83], 'recognition': [75, 84], 'Chinese': [77, 102], 'segmentation.': [79], 'The': [80, 99, 146], 'goal': [81, 100], 'detect': [87], 'classify': [89], 'names': [90], 'people,': [92], 'organizations,': [93], 'locations': [95], 'sentence.': [98], 'find': [107], 'boundaries': [110], 'sentence': [113], 'that': [114], 'written': [117], 'as': [118, 128, 154], 'string': [120], 'characters': [122], 'without': [123], 'spaces.': [124], 'Our': [125], 'approach': [126], 'follows:': [129], 'preprocessing': [132], 'step,': [133], 'use': [135], 'raw': [136], 'text': [137], 'cluster': [139], 'words': [140], 'calculate': [142], 'mutual': [143], 'statistics.': [145], 'output': [147], 'step': [150], 'then': [152], 'used': [153], 'features': [155], 'model,': [159], 'specifically': [160], 'global': [162], 'linear': [163], 'model': [164], 'trained': [165], 'using': [166]}",2005,"['Natural (archaeology)', 'Natural language processing', 'Natural language', 'Artificial intelligence', 'Computer science', 'Linguistics', 'Geography', 'Philosophy', 'Archaeology']","Statistical supervised learning techniques have been successful for many natural language processing tasks, but they require labeled datasets, which can be expensive to obtain. On the other hand, unlabeled data (raw text) is often available “for free ” in large quantities. Unlabeled data has shown promise in improving the performance of a number of tasks, e.g. word sense disambiguation, information extraction, and natural language parsing. In this thesis, we focus on two segmentation tasks, named-entity recognition and Chinese word segmentation. The goal of named-entity recognition is to detect and classify names of people, organizations, and locations in a sentence. The goal of Chinese word segmentation is to find the word boundaries in a sentence that has been written as a string of characters without spaces. Our approach is as follows: In a preprocessing step, we use raw text to cluster words and calculate mutual information statistics. The output of this step is then used as features in a supervised model, specifically a global linear model trained using"
https://openalex.org/W2784814091,Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning,"{'Many': [0], 'interesting': [1], 'problems': [2], 'in': [3, 36, 152], 'machine': [4], 'learning': [5, 12, 153], 'are': [6, 52], 'being': [7], 'revisited': [8], 'with': [9, 46, 121, 134, 154], 'new': [10], 'deep': [11], 'tools.': [13], 'For': [14], 'graph-based': [15], 'semisupervised': [16], 'learning,': [17], 'a': [18, 59, 99], 'recent': [19], 'important': [20], 'development': [21], 'is': [22, 97, 106], 'graph': [23, 34, 91], 'convolutional': [24, 38, 123], 'networks': [25], '(GCNs),': [26], 'which': [27, 105], 'nicely': [28], 'integrate': [29], 'local': [30], 'vertex': [31], 'features': [32], 'and': [33, 55, 67, 81, 141, 158, 175], 'topology': [35], 'the': [37, 41, 78, 90, 94, 107, 128, 131], 'layers.': [39, 124], 'Although': [40], 'GCN': [42, 79, 95, 132], 'model': [43, 68, 80, 96, 133], 'compares': [44], 'favorably': [45], 'other': [47], 'state-of-the-art': [48], 'methods,': [49], 'its': [50, 83], 'mechanisms': [51], 'not': [53], 'clear': [54], 'it': [56, 114], 'still': [57], 'requires': [58], 'considerable': [60], 'amount': [61], 'of': [62, 93, 102, 119, 130], 'labeled': [63], 'data': [64], 'for': [65, 165], 'validation': [66], 'selection.': [69], 'In': [70], 'this': [71], 'paper,': [72], 'we': [73, 87, 137], 'develop': [74], 'deeper': [75], 'insights': [76], 'into': [77], 'address': [82], 'fundamental': [84], 'limits.': [85], 'First,': [86], 'show': [88], 'that': [89], 'convolution': [92], 'actually': [98], 'special': [100], 'form': [101], 'Laplacian': [103], 'smoothing,': [104], 'key': [108], 'reason': [109], 'why': [110], 'GCNs': [111, 151], 'work,': [112], 'but': [113], 'also': [115], 'brings': [116], 'potential': [117], 'concerns': [118], 'over-smoothing': [120], 'many': [122], 'Second,': [125], 'to': [126, 144], 'overcome': [127], 'limits': [129], 'shallow': [135], 'architectures,': [136], 'propose': [138], 'both': [139], 'co-training': [140], 'self-training': [142], 'approaches': [143, 148], 'train': [145], 'GCNs.': [146], 'Our': [147], 'significantly': [149], 'improve': [150], 'very': [155], 'few': [156], 'labels,': [157], 'exempt': [159], 'them': [160], 'from': [161], 'requiring': [162], 'additional': [163], 'labels': [164], 'validation.': [166], 'Extensive': [167], 'experiments': [168], 'on': [169], 'benchmarks': [170], 'have': [171], 'verified': [172], 'our': [173], 'theory': [174], 'proposals.': [176]}",2018,"['Computer science', 'Graph', 'Artificial intelligence', 'Machine learning', 'Smoothing', 'Deep learning', 'Convolutional neural network', 'Theoretical computer science', 'Convolution (computer science)', 'Artificial neural network', 'Computer vision']","Many interesting problems in machine learning are being revisited with new deep learning tools. For graph-based semisupervised learning, a recent important development is graph convolutional networks (GCNs), which nicely integrate local vertex features and graph topology in the convolutional layers. Although the GCN model compares favorably with other state-of-the-art methods, its mechanisms are not clear and it still requires a considerable amount of labeled data for validation and model selection. In this paper, we develop deeper insights into the GCN model and address its fundamental limits. First, we show that the graph convolution of the GCN model is actually a special form of Laplacian smoothing, which is the key reason why GCNs work, but it also brings potential concerns of over-smoothing with many convolutional layers. Second, to overcome the limits of the GCN model with shallow architectures, we propose both co-training and self-training approaches to train GCNs. Our approaches significantly improve GCNs in learning with very few labels, and exempt them from requiring additional labels for validation. Extensive experiments on benchmarks have verified our theory and proposals."
https://openalex.org/W2943152387,Billion-scale semi-supervised learning for image classification,"{'This': [0], 'paper': [1], 'presents': [2], 'a': [3, 14, 18, 23, 42, 80], 'study': [4], 'of': [5, 26, 55, 59], 'semi-supervised': [6, 77], 'learning': [7], 'with': [8, 76], 'large': [9, 24], 'convolutional': [10], 'networks.': [11], 'We': [12, 50], 'propose': [13], 'pipeline,': [15], 'based': [16], 'on': [17, 112], 'teacher/student': [19], 'paradigm,': [20], 'that': [21], 'leverages': [22], 'collection': [25], 'unlabelled': [27, 102], 'images': [28], '(up': [29], 'to': [30, 37, 65, 69, 87], '1': [31], 'billion).': [32], 'Our': [33], 'main': [34], 'goal': [35], 'is': [36], 'improve': [38], 'the': [39, 56, 113], 'performance': [40], 'for': [41, 73, 90], 'given': [43], 'target': [44], 'architecture,': [45], 'like': [46], 'ResNet-50': [47, 107], 'or': [48], 'ResNext.': [49], 'provide': [51], 'an': [52], 'extensive': [53], 'analysis': [54], 'success': [57], 'factors': [58], 'our': [60, 82, 104], 'approach,': [61], 'which': [62], 'leads': [63], 'us': [64], 'formulate': [66], 'some': [67], 'recommendations': [68], 'produce': [70], 'high-accuracy': [71], 'models': [72], 'image': [74], 'classification': [75], 'learning.': [78], 'As': [79], 'result,': [81], 'approach': [83], 'brings': [84], 'important': [85], 'gains': [86], 'standard': [88], 'architectures': [89], 'image,': [91], 'video': [92], 'and': [93], 'fine-grained': [94], 'classification.': [95], 'For': [96], 'instance,': [97], 'by': [98], 'leveraging': [99], 'one': [100], 'billion': [101], 'images,': [103], 'learned': [105], 'vanilla': [106], 'achieves': [108], '81.2%': [109], 'top-1': [110], 'accuracy': [111], 'ImageNet': [114], 'benchmark.': [115]}",2019,"['Scale (ratio)', 'Computer science', 'Artificial intelligence', 'Image (mathematics)', 'Supervised learning', 'Pattern recognition (psychology)', 'Machine learning', 'Geography', 'Cartography', 'Artificial neural network']","This paper presents a study of semi-supervised learning with large convolutional networks. We propose a pipeline, based on a teacher/student paradigm, that leverages a large collection of unlabelled images (up to 1 billion). Our main goal is to improve the performance for a given target architecture, like ResNet-50 or ResNext. We provide an extensive analysis of the success factors of our approach, which leads us to formulate some recommendations to produce high-accuracy models for image classification with semi-supervised learning. As a result, our approach brings important gains to standard architectures for image, video and fine-grained classification. For instance, by leveraging one billion unlabelled images, our learned vanilla ResNet-50 achieves 81.2% top-1 accuracy on the ImageNet benchmark."
https://openalex.org/W1529410181,Weakly- and Semi-Supervised Learning of a DCNN for Semantic Image Segmentation,"{'Deep': [0], 'convolutional': [1], 'neural': [2], 'networks': [3], '(DCNNs)': [4], 'trained': [5], 'on': [6, 104], 'a': [7, 55], 'large': [8], 'number': [9], 'of': [10, 32, 57], 'images': [11], 'with': [12], 'strong': [13], 'pixel-level': [14], 'annotations': [15], 'have': [16], 'recently': [17], 'significantly': [18, 115], 'pushed': [19], 'the': [20, 28, 95, 105, 124], 'state-of-art': [21], 'in': [22], 'semantic': [23, 36, 78], 'image': [24, 37, 79, 110], 'segmentation.': [25], 'We': [26, 72, 119], 'study': [27], 'more': [29], 'challenging': [30, 106], 'problem': [31], 'learning': [33], 'DCNNs': [34], 'for': [35, 77], 'segmentation': [38, 80, 111], 'from': [39, 67], 'either': [40], '(1)': [41], 'weakly': [42, 63, 85], 'annotated': [43], 'training': [44, 82], 'data': [45], 'such': [46], 'as': [47], 'bounding': [48], 'boxes': [49], 'or': [50, 53, 69], 'image-level': [51], 'labels': [52], '(2)': [54], 'combination': [56], 'few': [58], 'strongly': [59], 'labeled': [60, 64], 'and': [61, 87], 'many': [62], 'images,': [65], 'sourced': [66], 'one': [68], 'multiple': [70], 'datasets.': [71], 'develop': [73], 'Expectation-Maximization': [74], '(EM)': [75], 'methods': [76], 'model': [81], 'under': [83], 'these': [84], 'supervised': [86], 'semi-supervised': [88], 'settings.': [89], 'Extensive': [90], 'experimental': [91], 'evaluation': [92], 'shows': [93], 'that': [94], 'proposed': [96, 125], 'techniques': [97], 'can': [98], 'learn': [99], 'models': [100], 'delivering': [101], 'competitive': [102], 'results': [103], 'PASCAL': [107], 'VOC': [108], '2012': [109], 'benchmark,': [112], 'while': [113], 'requiring': [114], 'less': [116], 'annotation': [117], 'effort.': [118], 'share': [120], 'source': [121], 'code': [122], 'implementing': [123], 'system': [126], 'at': [127], 'https://bitbucket.org/deeplab/deeplab-public.': [128]}",2015,"['Segmentation', 'Artificial intelligence', 'Image (mathematics)', 'Computer science', 'Pattern recognition (psychology)', 'Natural language processing']","Deep convolutional neural networks (DCNNs) trained on a large number of images with strong pixel-level annotations have recently significantly pushed the state-of-art in semantic image segmentation. We study the more challenging problem of learning DCNNs for semantic image segmentation from either (1) weakly annotated training data such as bounding boxes or image-level labels or (2) a combination of few strongly labeled and many weakly labeled images, sourced from one or multiple datasets. We develop Expectation-Maximization (EM) methods for semantic image segmentation model training under these weakly supervised and semi-supervised settings. Extensive experimental evaluation shows that the proposed techniques can learn models delivering competitive results on the challenging PASCAL VOC 2012 image segmentation benchmark, while requiring significantly less annotation effort. We share source code implementing the proposed system at https://bitbucket.org/deeplab/deeplab-public."
https://openalex.org/W3021542222,A Simple Semi-Supervised Learning Framework for Object Detection,"{'Semi-supervised': [0], 'learning': [1, 13], '(SSL)': [2], 'has': [3, 20, 31], 'a': [4, 44, 56], 'potential': [5], 'to': [6, 87, 116], 'improve': [7], 'the': [8, 25, 75, 89, 99, 112], 'predictive': [9], 'performance': [10, 90], 'of': [11, 27, 66, 91, 101], 'machine': [12], 'models': [14], 'using': [15, 95, 130, 141], 'unlabeled': [16, 71], 'data.': [17, 144], 'Although': [18], 'there': [19], 'been': [21, 33], 'remarkable': [22], 'recent': [23], 'progress,': [24], 'scope': [26], 'demonstration': [28], 'in': [29], 'SSL': [30, 48], 'mainly': [32], 'on': [34, 103, 118], 'image': [35, 72], 'classification': [36], 'tasks.': [37], 'In': [38], 'this': [39], 'paper,': [40], 'we': [41], 'propose': [42, 84], 'STAC,': [43], 'simple': [45], 'yet': [46], 'effective': [47], 'framework': [49], 'for': [50], 'visual': [51], 'object': [52, 93], 'detection': [53, 94], 'along': [54], 'with': [55], 'data': [57, 124, 134], 'augmentation': [58], 'strategy.': [59], 'STAC': [60, 102, 110, 120], 'deploys': [61], 'highly': [62], 'confident': [63], 'pseudo': [64], 'labels': [65], 'localized': [67], 'objects': [68], 'from': [69, 114], 'an': [70], 'and': [73, 97, 106], 'updates': [74], 'model': [76], 'by': [77, 126], 'enforcing': [78], 'consistency': [79], 'via': [80], 'strong': [81], 'augmentations.': [82], 'We': [83], 'experimental': [85], 'protocols': [86], 'evaluate': [88], 'semi-supervised': [92], 'MS-COCO': [96, 105], 'show': [98], 'efficacy': [100], 'both': [104], 'VOC07.': [107], 'On': [108], 'VOC07,': [109], 'improves': [111], 'AP$^{0.5}$': [113], '$76.30$': [115], '$79.08$;': [117], 'MS-COCO,': [119], 'demonstrates': [121], '$2{\\times}$': [122], 'higher': [123], 'efficiency': [125], 'achieving': [127], '24.38': [128], 'mAP': [129], 'only': [131], '5\\%': [132], 'labeled': [133, 143], 'than': [135], 'supervised': [136], 'baseline': [137], 'that': [138], 'marks': [139], '23.86\\%': [140], '10\\%': [142], 'The': [145], 'code': [146], 'is': [147], 'available': [148], 'at': [149], 'https://github.com/google-research/ssl_detection/.': [150]}",2020,"['Simple (philosophy)', 'Computer science', 'Artificial intelligence', 'Object (grammar)', 'Machine learning', 'Pattern recognition (psychology)', 'Epistemology', 'Philosophy']","Semi-supervised learning (SSL) has a potential to improve the predictive performance of machine learning models using unlabeled data. Although there has been remarkable recent progress, the scope of demonstration in SSL has mainly been on image classification tasks. In this paper, we propose STAC, a simple yet effective SSL framework for visual object detection along with a data augmentation strategy. STAC deploys highly confident pseudo labels of localized objects from an unlabeled image and updates the model by enforcing consistency via strong augmentations. We propose experimental protocols to evaluate the performance of semi-supervised object detection using MS-COCO and show the efficacy of STAC on both MS-COCO and VOC07. On VOC07, STAC improves the AP$^{0.5}$ from $76.30$ to $79.08$; on MS-COCO, STAC demonstrates $2{\times}$ higher data efficiency by achieving 24.38 mAP using only 5\% labeled data than supervised baseline that marks 23.86\% using 10\% labeled data. The code is available at https://github.com/google-research/ssl_detection/."
https://openalex.org/W2963250052,Unsupervised and Semi-supervised Learning with Categorical Generative\n Adversarial Networks,"{'In': [0], 'this': [1], 'paper': [2], 'we': [3, 84], 'present': [4], 'a': [5, 9, 52], 'method': [6, 81], 'for': [7], 'learning': [8], 'discriminative': [10], 'classifier\\nfrom': [11], 'unlabeled': [12], 'or': [13, 61], 'partially': [14], 'labeled': [15], 'data.': [16], 'Our': [17], 'approach': [18], 'is': [19, 121], 'based': [20], 'on': [21, 92, 98], 'an': [22, 41, 63, 75], 'objective\\nfunction': [23], 'that': [24, 120], 'trades-off': [25], 'mutual': [26], 'information': [27, 68], 'between': [28, 129], 'observed': [29], 'examples': [30], 'and': [31, 126, 133], 'their\\npredicted': [32], 'categorical': [33, 86], 'class': [34], 'distribution,': [35], 'against': [36, 74], 'robustness': [37, 104], 'of': [38, 55, 65, 105, 114], 'the': [39, 56, 66, 103, 106, 112, 117, 124, 130], 'classifier\\nto': [40], 'adversarial': [42, 58, 118], 'generative': [43, 57], 'model.': [44], 'The': [45], 'resulting': [46], 'algorithm': [47], 'can': [48], 'either': [49], 'be\\ninterpreted': [50], 'as': [51, 62, 95, 97, 137], 'natural': [53], 'generalization': [54], 'networks\\n(GAN)': [59], 'framework': [60, 70], 'extension': [64], 'regularized': [67], 'maximization\\n(RIM)': [69], 'to': [71], 'robust': [72], 'classification': [73, 100], 'optimal': [76], 'adversary.': [77], 'We\\nempirically': [78], 'evaluate': [79], 'our': [80], '-': [82, 91], 'which': [83], 'dub': [85], 'generative\\nadversarial': [87], 'networks': [88], '(or': [89], 'CatGAN)': [90], 'synthetic': [93], 'data': [94], 'well': [96], 'challenging\\nimage': [99], 'tasks,': [101], 'demonstrating': [102], 'learned\\nclassifiers.': [107], 'We': [108], 'further': [109], 'qualitatively': [110], 'assess': [111], 'fidelity': [113], 'samples': [115], 'generated\\nby': [116], 'generator': [119], 'learned': [122], 'alongside': [123], 'discriminative\\nclassifier,': [125], 'identify': [127], 'links': [128], 'CatGAN': [131], 'objective': [132], 'discriminative\\nclustering': [134], 'algorithms': [135], '(such': [136], 'RIM).\\n': [138]}",2015,"['Discriminative model', 'Artificial intelligence', 'Generative grammar', 'Classifier (UML)', 'Computer science', 'Adversarial system', 'Machine learning', 'Categorical variable', 'Pattern recognition (psychology)', 'Robustness (evolution)', 'Cluster analysis', 'Chemistry', 'Gene', 'Biochemistry']","In this paper we present a method for learning a discriminative classifier\nfrom unlabeled or partially labeled data. Our approach is based on an objective\nfunction that trades-off mutual information between observed examples and their\npredicted categorical class distribution, against robustness of the classifier\nto an adversarial generative model. The resulting algorithm can either be\ninterpreted as a natural generalization of the generative adversarial networks\n(GAN) framework or as an extension of the regularized information maximization\n(RIM) framework to robust classification against an optimal adversary. We\nempirically evaluate our method - which we dub categorical generative\nadversarial networks (or CatGAN) - on synthetic data as well as on challenging\nimage classification tasks, demonstrating the robustness of the learned\nclassifiers. We further qualitatively assess the fidelity of samples generated\nby the adversarial generator that is learned alongside the discriminative\nclassifier, and identify links between the CatGAN objective and discriminative\nclustering algorithms (such as RIM).\n"
https://openalex.org/W2315403234,Revisiting Semi-Supervised Learning with Graph Embeddings,"{'We': [0, 35], 'present': [1], 'a': [2, 11, 76, 95], 'semi-supervised': [3], 'learning': [4], 'framework': [5], 'based': [6], 'on': [7, 88], 'graph': [8, 12], 'embeddings.': [9], 'Given': [10], 'between': [13], 'instances,': [14], 'we': [15, 113], 'train': [16], 'an': [17], 'embedding': [18], 'for': [19], 'each': [20], 'instance': [21], 'to': [22], 'jointly': [23], 'predict': [24], 'the': [25, 29, 33, 46, 52, 59, 68, 71, 80, 120], 'class': [26, 53], 'label': [27], 'and': [28, 39, 62, 97, 110], 'neighborhood': [30], 'context': [31], 'in': [32, 67], 'graph.': [34], 'develop': [36], 'both': [37, 58], 'transductive': [38, 47], 'inductive': [40, 69], 'variants': [41], 'of': [42, 49, 79, 100, 119], 'our': [43, 50], 'method.': [44], 'In': [45], 'variant': [48], 'method,': [51], 'labels': [54], 'are': [55, 73], 'determined': [56], 'by': [57], 'learned': [60], 'embeddings': [61, 72], 'input': [63], 'feature': [64, 81], 'vectors,': [65, 82], 'while': [66], 'variant,': [70], 'defined': [74], 'as': [75], 'parametric': [77], 'function': [78], 'so': [83], 'predictions': [84], 'can': [85], 'be': [86], 'made': [87], 'instances': [89], 'not': [90], 'seen': [91], 'during': [92], 'training.': [93], 'On': [94], 'large': [96], 'diverse': [98], 'set': [99], 'benchmark': [101], 'tasks,': [102], 'including': [103], 'text': [104], 'classification,': [105, 112], 'distantly': [106], 'supervised': [107], 'entity': [108, 111], 'extraction,': [109], 'show': [114], 'improved': [115], 'performance': [116], 'over': [117], 'many': [118], 'existing': [121], 'models.': [122]}",2016,"['Computer science', 'Embedding', 'Graph', 'Artificial intelligence', 'Supervised learning', 'Machine learning', 'Semi-supervised learning', 'Benchmark (surveying)', 'Graph embedding', 'Class (philosophy)', 'Pattern recognition (psychology)', 'Theoretical computer science', 'Artificial neural network', 'Geography', 'Geodesy']","We present a semi-supervised learning framework based on graph embeddings. Given a graph between instances, we train an embedding for each instance to jointly predict the class label and the neighborhood context in the graph. We develop both transductive and inductive variants of our method. In the transductive variant of our method, the class labels are determined by both the learned embeddings and input feature vectors, while in the inductive variant, the embeddings are defined as a parametric function of the feature vectors, so predictions can be made on instances not seen during training. On a large and diverse set of benchmark tasks, including text classification, distantly supervised entity extraction, and entity classification, we show improved performance over many of the existing models."
https://openalex.org/W2022732522,Semi-supervised learning for potential human microRNA-disease associations inference,"{'MicroRNAs': [0], 'play': [1], 'critical': [2], 'role': [3], 'in': [4, 26, 33, 157, 164], 'the': [5, 27, 31, 47, 79, 91, 112, 165], 'development': [6], 'and': [7, 51, 72, 103, 106, 121, 130], 'progression': [8], 'of': [9, 19, 94, 125, 132], 'various': [10], 'diseases.': [11], 'Predicting': [12], 'potential': [13, 135, 168], 'miRNA-disease': [14], 'associations': [15, 76, 136, 180], 'from': [16], 'vast': [17], 'amount': [18], 'biological': [20, 145], 'data': [21], 'is': [22, 64, 187], 'an': [23], 'important': [24], 'problem': [25], 'biomedical': [28, 198], 'research.': [29], 'Considering': [30], 'limitations': [32], 'previous': [34], 'methods,': [35], 'we': [36], 'developed': [37], 'Regularized': [38], 'Least': [39], 'Squares': [40], 'for': [41, 56, 77, 110, 175, 197], 'MiRNA-Disease': [42], 'Association': [43], '(RLSMDA)': [44], 'to': [45, 100, 151], 'uncover': [46], 'relationship': [48], 'between': [49], 'diseases': [50, 57, 80, 113, 152], 'miRNAs.': [52, 61], 'RLSMDA': [53, 99, 150, 174, 190], 'can': [54], 'work': [55], 'without': [58, 153], 'known': [59, 154], 'related': [60, 155, 169], 'Furthermore,': [62], 'it': [63], 'a': [65, 116, 162, 193], 'semi-supervised': [66], '(does': [67], 'not': [68], 'need': [69], 'negative': [70], 'samples)': [71], 'global': [73, 108, 139], 'method': [74], '(prioritize': [75], 'all': [78, 111], 'simultaneously).': [81], 'Based': [82], 'on': [83, 138], 'leave-one-out': [84], 'cross': [85], 'validation,': [86], 'reliable': [87, 92], 'AUC': [88], 'have': [89, 141], 'demonstrated': [90], 'performance': [93], 'RLSMDA.': [95], 'We': [96, 147], 'also': [97, 148], 'applied': [98, 149], 'Hepatocellular': [101], 'cancer': [102, 105], 'Lung': [104], 'implemented': [107], 'prediction': [109, 140], 'simultaneously.': [114], 'As': [115, 161], 'result,': [117, 163], '80%': [118], '(Hepatocellular': [119], 'cancer)': [120, 124], '84%': [122], '(Lung': [123], 'top': [126, 133, 166], '50': [127], 'predicted': [128, 172], 'miRNAs': [129, 156], '75%': [131], '20': [134], 'based': [137], 'been': [142], 'confirmed': [143, 183], 'by': [144, 173, 184], 'experiments.': [146, 185], 'golden': [158], 'standard': [159], 'dataset.': [160], '3': [167], 'miRNA': [170], 'list': [171], '32': [176], 'diseases,': [177], '34': [178], 'disease-miRNA': [179], 'were': [181], 'successfully': [182], 'It': [186], 'anticipated': [188], 'that': [189], 'would': [191], 'be': [192], 'useful': [194], 'bioinformatics': [195], 'resource': [196], 'researches.': [199]}",2014,"['Inference', 'microRNA', 'Disease', 'Computational biology', 'Lung cancer', 'Bioinformatics', 'Cancer', 'Machine learning', 'Computer science', 'Biology', 'Medicine', 'Artificial intelligence', 'Oncology', 'Pathology', 'Genetics', 'Gene']","MicroRNAs play critical role in the development and progression of various diseases. Predicting potential miRNA-disease associations from vast amount of biological data is an important problem in the biomedical research. Considering the limitations in previous methods, we developed Regularized Least Squares for MiRNA-Disease Association (RLSMDA) to uncover the relationship between diseases and miRNAs. RLSMDA can work for diseases without known related miRNAs. Furthermore, it is a semi-supervised (does not need negative samples) and global method (prioritize associations for all the diseases simultaneously). Based on leave-one-out cross validation, reliable AUC have demonstrated the reliable performance of RLSMDA. We also applied RLSMDA to Hepatocellular cancer and Lung cancer and implemented global prediction for all the diseases simultaneously. As a result, 80% (Hepatocellular cancer) and 84% (Lung cancer) of top 50 predicted miRNAs and 75% of top 20 potential associations based on global prediction have been confirmed by biological experiments. We also applied RLSMDA to diseases without known related miRNAs in golden standard dataset. As a result, in the top 3 potential related miRNA list predicted by RLSMDA for 32 diseases, 34 disease-miRNA associations were successfully confirmed by experiments. It is anticipated that RLSMDA would be a useful bioinformatics resource for biomedical researches."
https://openalex.org/W2869264951,Computational Principles of Supervised Learning in the Cerebellum,"{'Supervised': [0], 'learning': [1, 22, 56, 145], 'plays': [2], 'a': [3, 35], 'key': [4], 'role': [5], 'in': [6, 123, 128], 'the': [7, 18, 26, 33, 52, 58, 116], 'operation': [8], 'of': [9, 17, 32, 66, 99, 115], 'many': [10], 'biological': [11], 'and': [12, 29, 43, 92, 104, 127, 146], 'artificial': [13, 129], 'neural': [14, 130], 'networks.': [15], 'Analysis': [16], 'computations': [19], 'underlying': [20], 'supervised': [21, 55, 144], 'is': [23], 'facilitated': [24], 'by': [25], 'relatively': [27], 'simple': [28], 'uniform': [30], 'architecture': [31], 'cerebellum,': [34], 'brain': [36, 125], 'area': [37], 'that': [38, 51, 88], 'supports': [39], 'numerous': [40], 'motor,': [41], 'sensory,': [42], 'cognitive': [44], 'functions.': [45], 'We': [46], 'highlight': [47], 'recent': [48], 'discoveries': [49], 'indicating': [50], 'cerebellum': [53, 117], 'implements': [54], 'using': [57], 'following': [59], 'organizational': [60], 'principles:': [61], '(': [62, 72, 78, 83, 95, 105], 'a)': [63], 'extensive': [64], 'preprocessing': [65], 'input': [67], 'representations': [68], '(i.e.,': [69], 'feature': [70], 'engineering),': [71], 'b)': [73], 'massively': [74], 'recurrent': [75], 'circuit': [76], 'architecture,': [77], 'c)': [79], 'linear': [80], 'input–output': [81], 'computations,': [82], 'd)': [84], 'sophisticated': [85], 'instructive': [86], 'signals': [87], 'can': [89, 139], 'be': [90], 'regulated': [91], 'are': [93], 'predictive,': [94], 'e)': [96], 'adaptive': [97], 'mechanisms': [98], 'plasticity': [100], 'with': [101, 121], 'multiple': [102], 'timescales,': [103], 'f)': [106], 'task-specific': [107], 'hardware': [108], 'specializations.': [109], 'The': [110], 'principles': [111], 'emerging': [112], 'from': [113], 'studies': [114], 'have': [118], 'striking': [119], 'parallels': [120], 'those': [122], 'other': [124], 'areas': [126], 'networks,': [131], 'as': [132, 134], 'well': [133], 'some': [135], 'notable': [136], 'differences,': [137], 'which': [138], 'inform': [140], 'future': [141], 'research': [142], 'on': [143], 'inspire': [147], 'next-generation': [148], 'machine-based': [149], 'algorithms.': [150]}",2018,"['Computer science', 'Artificial intelligence', 'Machine learning', 'Supervised learning', 'Motor learning', 'Artificial neural network', 'Neuroscience', 'Cerebellum', 'Psychology']","Supervised learning plays a key role in the operation of many biological and artificial neural networks. Analysis of the computations underlying supervised learning is facilitated by the relatively simple and uniform architecture of the cerebellum, a brain area that supports numerous motor, sensory, and cognitive functions. We highlight recent discoveries indicating that the cerebellum implements supervised learning using the following organizational principles: ( a) extensive preprocessing of input representations (i.e., feature engineering), ( b) massively recurrent circuit architecture, ( c) linear input–output computations, ( d) sophisticated instructive signals that can be regulated and are predictive, ( e) adaptive mechanisms of plasticity with multiple timescales, and ( f) task-specific hardware specializations. The principles emerging from studies of the cerebellum have striking parallels with those in other brain areas and in artificial neural networks, as well as some notable differences, which can inform future research on supervised learning and inspire next-generation machine-based algorithms."
https://openalex.org/W2996501936,ReMixMatch: Semi-Supervised Learning with Distribution Matching and Augmentation Anchoring,"{'We': [0], 'improve': [1], 'the': [2, 22, 34, 52, 62, 69, 84, 88, 116], 'recently-proposed': [3], '``MixMatch': [4], 'semi-supervised': [5], 'learning': [6], 'algorithm': [7], 'by': [8], 'introducing': [9], 'two': [10], 'new': [11, 94], 'techniques:': [12], 'distribution': [13, 24, 36], 'alignment': [14, 20], 'and': [15, 54, 109, 140], 'augmentation': [16, 85], 'anchoring.': [17], '-': [18, 40], 'Distribution': [19], 'encourages': [21, 55], 'marginal': [23, 35], 'of': [25, 37, 48, 68, 80, 135, 144], 'predictions': [26], 'on': [27, 121], 'unlabeled': [28], 'data': [29, 113], 'to': [30, 33, 58, 61, 114, 132], 'be': [31, 59], 'close': [32, 60], 'ground-truth': [38], 'labels.': [39], 'Augmentation': [41], 'anchoring}': [42], 'feeds': [43], 'multiple': [44], 'strongly': [45], 'augmented': [46], 'versions': [47], 'an': [49], 'input': [50], 'into': [51], 'model': [53, 89], 'each': [56], 'output': [57], 'prediction': [63], 'for': [64], 'a': [65, 78, 141], 'weakly-augmented': [66], 'version': [67], 'same': [70, 117], 'input.': [71], 'To': [72], 'produce': [73], 'strong': [74], 'augmentations,': [75], 'we': [76, 127], 'propose': [77], 'variant': [79], 'AutoAugment': [81], 'which': [82], 'learns': [83], 'policy': [86], 'while': [87], 'is': [90, 98], 'being': [91], 'trained.': [92], 'Our': [93], 'algorithm,': [95], 'dubbed': [96], 'ReMixMatch,': [97], 'significantly': [99], 'more': [100], 'data-efficient': [101], 'than': [102], 'prior': [103], 'work,': [104], 'requiring': [105], 'between': [106], '5': [107], 'times': [108, 111], '16': [110], 'less': [112], 'reach': [115, 128], 'accuracy.': [118], 'For': [119], 'example,': [120], 'CIFAR-10': [122], 'with': [123, 137, 146], '250': [124], 'labeled': [125], 'examples': [126], '93.73%': [129], 'accuracy': [130, 134, 143], '(compared': [131], ""MixMatch's"": [133], '93.58%': [136], '4000': [138], 'examples)': [139], 'median': [142], '84.92%': [145], 'just': [147], 'four': [148], 'labels': [149], 'per': [150], 'class.': [151]}",2020,"['Anchoring', 'Matching (statistics)', 'Computer science', 'Ground truth', 'Artificial intelligence', 'Labeled data', 'Class (philosophy)', 'Distribution (mathematics)', 'Pattern recognition (psychology)', 'Algorithm', 'Machine learning', 'Mathematics', 'Statistics', 'Engineering', 'Mathematical analysis', 'Structural engineering']","We improve the recently-proposed ``MixMatch semi-supervised learning algorithm by introducing two new techniques: distribution alignment and augmentation anchoring. - Distribution alignment encourages the marginal distribution of predictions on unlabeled data to be close to the marginal distribution of ground-truth labels. - Augmentation anchoring} feeds multiple strongly augmented versions of an input into the model and encourages each output to be close to the prediction for a weakly-augmented version of the same input. To produce strong augmentations, we propose a variant of AutoAugment which learns the augmentation policy while the model is being trained. Our new algorithm, dubbed ReMixMatch, is significantly more data-efficient than prior work, requiring between 5 times and 16 times less data to reach the same accuracy. For example, on CIFAR-10 with 250 labeled examples we reach 93.73% accuracy (compared to MixMatch's accuracy of 93.58% with 4000 examples) and a median accuracy of 84.92% with just four labels per class."
https://openalex.org/W3034749675,An Overview of Deep Semi-Supervised Learning,"{'Deep': [0], 'neural': [1, 97], 'networks': [2, 98], 'demonstrated': [3], 'their': [4], 'ability': [5], 'to': [6, 75, 95, 99, 139], 'provide': [7, 127], 'remarkable': [8], 'performances': [9], 'on': [10, 23], 'a': [11, 37, 67, 85, 119, 128, 144], 'wide': [12], 'range': [13], 'of': [14, 26, 40, 61, 103, 131, 146], 'supervised': [15], 'learning': [16, 64, 73, 91, 116, 121], 'tasks': [17], '(e.g.,': [18, 29], 'image': [19], 'classification)': [20], 'when': [21], 'trained': [22], 'extensive': [24], 'collections': [25], 'labeled': [27, 104], 'data': [28, 105], 'ImageNet).': [30], 'However,': [31], 'creating': [32], 'such': [33], 'large': [34, 80], 'datasets': [35], 'requires': [36], 'considerable': [38], 'amount': [39, 102], 'resources,': [41], 'time,': [42], 'and': [43, 58, 92], 'effort.': [44], 'Such': [45], 'resources': [46], 'may': [47], 'not': [48], 'be': [49], 'available': [50], 'in': [51, 89, 151], 'many': [52, 62], 'practical': [53], 'cases,': [54], 'limiting': [55], 'the': [56, 59, 77, 101, 140, 147], 'adoption': [57], 'application': [60], 'deep': [63, 72, 96, 120, 132, 152], 'methods.': [65], 'In': [66, 123], 'search': [68], 'for': [69, 79, 118], 'more': [70], 'data-efficient': [71], 'methods': [74, 111], 'overcome': [76], 'need': [78], 'annotated': [81], 'datasets,': [82], 'there': [83], 'is': [84], 'rising': [86], 'research': [87], 'interest': [88], 'semi-supervised': [90, 115, 133, 149], 'its': [93], 'applications': [94], 'reduce': [100], 'required,': [106], 'by': [107, 143], 'either': [108], 'developing': [109], 'novel': [110], 'or': [112], 'adopting': [113], 'existing': [114], 'frameworks': [117], 'setting.': [122], 'this': [124], 'paper,': [125], 'we': [126], 'comprehensive': [129], 'overview': [130], 'learning,': [134], 'starting': [135], 'with': [136], 'an': [137], 'introduction': [138], 'field,': [141], 'followed': [142], 'summarization': [145], 'dominant': [148], 'approaches': [150], 'learning.': [153]}",2020,"['Deep learning', 'Artificial intelligence', 'Computer science', 'Machine learning', 'Automatic summarization', 'Semi-supervised learning', 'Supervised learning', 'Field (mathematics)', 'Deep neural networks', 'Limiting', 'Artificial neural network', 'Engineering', 'Mathematics', 'Pure mathematics', 'Mechanical engineering']","Deep neural networks demonstrated their ability to provide remarkable performances on a wide range of supervised learning tasks (e.g., image classification) when trained on extensive collections of labeled data (e.g., ImageNet). However, creating such large datasets requires a considerable amount of resources, time, and effort. Such resources may not be available in many practical cases, limiting the adoption and the application of many deep learning methods. In a search for more data-efficient deep learning methods to overcome the need for large annotated datasets, there is a rising research interest in semi-supervised learning and its applications to deep neural networks to reduce the amount of labeled data required, by either developing novel methods or adopting existing semi-supervised learning frameworks for a deep learning setting. In this paper, we provide a comprehensive overview of deep semi-supervised learning, starting with an introduction to the field, followed by a summarization of the dominant semi-supervised approaches in deep learning."
https://openalex.org/W2178768799,Unsupervised and Semi-supervised Learning with Categorical Generative Adversarial Networks,"{'In': [0], 'this': [1], 'paper': [2], 'we': [3, 92], 'present': [4], 'a': [5, 9, 57], 'method': [6, 89], 'for': [7], 'learning': [8], 'discriminative': [10, 137, 147], 'classifier': [11, 43], 'from': [12], 'unlabeled': [13], 'or': [14, 67], 'partially': [15], 'labeled': [16], 'data.': [17], 'Our': [18], 'approach': [19], 'is': [20, 133], 'based': [21], 'on': [22, 101, 107], 'an': [23, 45, 69, 82], 'objective': [24, 145], 'function': [25], 'that': [26, 132], 'trades-off': [27], 'mutual': [28], 'information': [29, 74], 'between': [30, 142], 'observed': [31], 'examples': [32], 'and': [33, 139, 146], 'their': [34], 'predicted': [35], 'categorical': [36, 94], 'class': [37], 'distribution,': [38], 'against': [39, 81], 'robustness': [40, 114], 'of': [41, 60, 71, 115, 125], 'the': [42, 61, 72, 113, 116, 123, 129, 136, 143], 'to': [44, 78], 'adversarial': [46, 63, 96, 130], 'generative': [47, 62, 95], 'model.': [48], 'The': [49], 'resulting': [50], 'algorithm': [51], 'can': [52], 'either': [53], 'be': [54], 'interpreted': [55], 'as': [56, 68, 104, 106, 151], 'natural': [58], 'generalization': [59], 'networks': [64, 97], '(GAN)': [65], 'framework': [66, 77], 'extension': [70], 'regularized': [73], 'maximization': [75], '(RIM)': [76], 'robust': [79], 'classification': [80, 110], 'optimal': [83], 'adversary.': [84], 'We': [85, 119], 'empirically': [86], 'evaluate': [87], 'our': [88], '-': [90, 100], 'which': [91], 'dub': [93], '(or': [98], 'CatGAN)': [99], 'synthetic': [102], 'data': [103], 'well': [105], 'challenging': [108], 'image': [109], 'tasks,': [111], 'demonstrating': [112], 'learned': [117, 134], 'classifiers.': [118], 'further': [120], 'qualitatively': [121], 'assess': [122], 'fidelity': [124], 'samples': [126], 'generated': [127], 'by': [128], 'generator': [131], 'alongside': [135], 'classifier,': [138], 'identify': [140], 'links': [141], 'CatGAN': [144], 'clustering': [148], 'algorithms': [149], '(such': [150], 'RIM).': [152]}",2015,"['Discriminative model', 'Artificial intelligence', 'Generative grammar', 'Classifier (UML)', 'Computer science', 'Adversarial system', 'Machine learning', 'Categorical variable', 'Pattern recognition (psychology)', 'Robustness (evolution)', 'Cluster analysis', 'Gene', 'Biochemistry', 'Chemistry']","In this paper we present a method for learning a discriminative classifier from unlabeled or partially labeled data. Our approach is based on an objective function that trades-off mutual information between observed examples and their predicted categorical class distribution, against robustness of the classifier to an adversarial generative model. The resulting algorithm can either be interpreted as a natural generalization of the generative adversarial networks (GAN) framework or as an extension of the regularized information maximization (RIM) framework to robust classification against an optimal adversary. We empirically evaluate our method - which we dub categorical generative adversarial networks (or CatGAN) - on synthetic data as well as on challenging image classification tasks, demonstrating the robustness of the learned classifiers. We further qualitatively assess the fidelity of samples generated by the adversarial generator that is learned alongside the discriminative classifier, and identify links between the CatGAN objective and discriminative clustering algorithms (such as RIM)."
https://openalex.org/W3129850062,Self-Supervised Learning of Graph Neural Networks: A Unified Review,"{'Deep': [0], 'models': [1], 'trained': [2], 'in': [3, 110, 154, 171], 'supervised': [4], 'mode': [5], 'have': [6], 'achieved': [7, 40], 'remarkable': [8], 'success': [9, 58], 'on': [10, 43, 126], 'a': [11, 26, 53, 72, 98, 166], 'variety': [12], 'of': [13, 32, 35, 75, 78, 119, 131, 175], 'tasks.': [14, 49], 'When': [15], 'labeled': [16], 'samples': [17], 'are': [18], 'limited,': [19], 'self-supervised': [20], 'learning': [21, 48], '(SSL)': [22], 'is': [23, 52], 'emerging': [24], 'as': [25, 103, 105], 'new': [27, 139], 'paradigm': [28], 'for': [29, 101, 122, 137, 169], 'making': [30], 'use': [31], 'large': [33], 'amounts': [34], 'unlabeled': [36], 'samples.': [37], 'SSL': [38, 86, 120, 147, 170], 'has': [39], 'promising': [41], 'performance': [42], 'natural': [44], 'language': [45], 'and': [46, 90, 129, 141, 149, 161, 180], 'image': [47], 'Recently,': [50], 'there': [51], 'trend': [54], 'to': [55, 59], 'extend': [56], 'such': [57], 'graph': [60, 63], 'data': [61], 'using': [62, 81], 'neural': [64], 'networks': [65], '(GNNs).': [66], 'In': [67, 93], 'this': [68], 'survey,': [69], 'we': [70, 84, 96, 164], 'provide': [71, 97], 'unified': [73, 99, 117], 'review': [74], 'different': [76, 146], 'ways': [77], 'training': [79], 'GNNs': [80, 123], 'SSL.': [82], 'Specifically,': [83], 'categorize': [85], 'methods': [87, 102, 108, 121, 140], 'into': [88], 'contrastive': [89], 'predictive': [91], 'models.': [92], 'either': [94], 'category,': [95], 'framework': [100], 'well': [104], 'how': [106], 'these': [107], 'differ': [109], 'each': [111, 155], 'component': [112], 'under': [113], 'the': [114, 127, 135, 150], 'framework.': [115], 'Our': [116], 'treatment': [118], 'sheds': [124], 'light': [125], 'similarities': [128], 'differences': [130], 'various': [132], 'methods,': [133, 178], 'setting': [134], 'stage': [136], 'developing': [138], 'algorithms.': [142], 'We': [143], 'also': [144], 'summarize': [145], 'settings': [148], 'corresponding': [151], 'datasets': [152], 'used': [153], 'setting.': [156], 'To': [157], 'facilitate': [158], 'methodological': [159], 'development': [160], 'empirical': [162], 'comparison,': [163], 'develop': [165], 'standardized': [167], 'testbed': [168], 'GNNs,': [172], 'including': [173], 'implementations': [174], 'common': [176], 'baseline': [177], 'datasets,': [179], 'evaluation': [181], 'metrics.': [182]}",2022,"['Computer science', 'Artificial intelligence', 'Machine learning', 'Categorization', 'Graph', 'Testbed', 'Artificial neural network', 'Theoretical computer science', 'Computer network']","Deep models trained in supervised mode have achieved remarkable success on a variety of tasks. When labeled samples are limited, self-supervised learning (SSL) is emerging as a new paradigm for making use of large amounts of unlabeled samples. SSL has achieved promising performance on natural language and image learning tasks. Recently, there is a trend to extend such success to graph data using graph neural networks (GNNs). In this survey, we provide a unified review of different ways of training GNNs using SSL. Specifically, we categorize SSL methods into contrastive and predictive models. In either category, we provide a unified framework for methods as well as how these methods differ in each component under the framework. Our unified treatment of SSL methods for GNNs sheds light on the similarities and differences of various methods, setting the stage for developing new methods and algorithms. We also summarize different SSL settings and the corresponding datasets used in each setting. To facilitate methodological development and empirical comparison, we develop a standardized testbed for SSL in GNNs, including implementations of common baseline methods, datasets, and evaluation metrics."
https://openalex.org/W3133518153,Anomaly Detection on Attributed Networks via Contrastive Self-Supervised Learning,"{'Anomaly': [0, 114], 'detection': [1, 29, 79, 115], 'on': [2, 39, 116, 265], 'attributed': [3, 14, 117], 'networks': [4, 15, 40, 90, 118, 251], 'attracts': [5], 'considerable': [6], 'research': [7], 'interests': [8], 'due': [9, 91], 'to': [10, 86, 88, 92, 169, 203, 249], 'wide': [11, 19], 'applications': [12], 'of': [13, 21, 64, 137, 183, 207, 231, 237, 241], 'in': [16, 68, 80, 102, 153], 'modeling': [17], 'a': [18, 107, 134, 158, 222], 'range': [20], 'complex': [22, 45], 'systems.': [23], 'Recently,': [24], 'the': [25, 61, 65, 93, 126, 144, 181, 196, 205, 216, 229, 232, 242, 261], 'deep': [26], 'learning-based': [27], 'anomaly': [28, 78, 224], 'methods': [30, 73, 264], 'have': [31], 'shown': [32], 'promising': [33], 'results': [34, 254], 'over': [35], 'shallow': [36], 'approaches,': [37, 49], 'especially': [38], 'with': [41, 187, 210], 'high-dimensional': [42, 174], 'attributes': [43, 175], 'and': [44, 84, 149, 176, 179], 'structures.': [46], 'However,': [47], 'existing': [48], 'which': [50, 141], 'employ': [51], 'graph': [52, 95, 160], 'autoencoder': [53], 'as': [54], 'their': [55, 81], 'backbone,': [56], 'do': [57, 74], 'not': [58, 75], 'fully': [59, 124], 'exploit': [60], 'rich': [62], 'information': [63, 128], 'network,': [66, 244], 'resulting': [67], 'suboptimal': [69], 'performance.': [70], 'Furthermore,': [71, 227], 'these': [72, 100], 'directly': [76], 'target': [77], 'learning': [82, 165, 198, 217], 'objective': [83], 'fail': [85], 'scale': [87], 'large': [89, 250], 'full': [94, 243], 'training': [96], 'mechanism.': [97], 'To': [98], 'overcome': [99], 'limitations,': [101], 'this': [103, 214], 'article,': [104], 'we': [105], 'present': [106], 'novel': [108, 135], 'Contrastive': [109], 'self-supervised': [110], 'Learning': [111], 'framework': [112, 123, 246, 259], 'for': [113, 120], '(CoLA': [119], 'abbreviation).': [121], 'Our': [122], 'exploits': [125], 'local': [127, 177], 'from': [129, 173], 'network': [130, 162], 'data': [131, 269], 'by': [132, 195, 221], 'sampling': [133], 'type': [136], 'contrastive': [138, 164, 197], 'instance': [139, 185, 238], 'pair,': [140], 'can': [142, 247], 'capture': [143], 'relationship': [145], 'between': [146], 'each': [147, 184, 208], 'node': [148, 209], 'its': [150, 188], 'neighboring': [151], 'substructure': [152], 'an': [154], 'unsupervised': [155], 'way.': [156], 'Meanwhile,': [157], 'well-designed': [159], 'neural': [161], '(GNN)-based': [163], 'model': [166, 199, 218], 'is': [167, 219, 235], 'proposed': [168, 258], 'learn': [170], 'informative': [171], 'embedding': [172], 'structure': [178], 'measure': [180], 'agreement': [182], 'pairs': [186, 239], 'outputted': [189], 'scores.': [190], 'The': [191], 'multiround': [192], 'predicted': [193], 'scores': [194], 'are': [200], 'further': [201], 'used': [202], 'evaluate': [204], 'abnormality': [206], 'statistical': [211], 'estimation.': [212], 'In': [213], 'way,': [215], 'trained': [220], 'specific': [223], 'detection-aware': [225], 'target.': [226], 'since': [228], 'input': [230], 'GNN': [233], 'module': [234], 'batches': [236], 'instead': [240], 'our': [245, 257], 'adapt': [248], 'flexibly.': [252], 'Experimental': [253], 'show': [255], 'that': [256], 'outperforms': [260], 'state-of-the-art': [262], 'baseline': [263], 'all': [266], 'seven': [267], 'benchmark': [268], 'sets.': [270]}",2021,"['Computer science', 'Anomaly detection', 'Autoencoder', 'Artificial intelligence', 'Exploit', 'Graph', 'Anomaly (physics)', 'Deep learning', 'Machine learning', 'Unsupervised learning', 'Feature learning', 'Pattern recognition (psychology)', 'Data mining', 'Theoretical computer science', 'Physics', 'Condensed matter physics', 'Computer security']","Anomaly detection on attributed networks attracts considerable research interests due to wide applications of attributed networks in modeling a wide range of complex systems. Recently, the deep learning-based anomaly detection methods have shown promising results over shallow approaches, especially on networks with high-dimensional attributes and complex structures. However, existing approaches, which employ graph autoencoder as their backbone, do not fully exploit the rich information of the network, resulting in suboptimal performance. Furthermore, these methods do not directly target anomaly detection in their learning objective and fail to scale to large networks due to the full graph training mechanism. To overcome these limitations, in this article, we present a novel Contrastive self-supervised Learning framework for Anomaly detection on attributed networks (CoLA for abbreviation). Our framework fully exploits the local information from network data by sampling a novel type of contrastive instance pair, which can capture the relationship between each node and its neighboring substructure in an unsupervised way. Meanwhile, a well-designed graph neural network (GNN)-based contrastive learning model is proposed to learn informative embedding from high-dimensional attributes and local structure and measure the agreement of each instance pairs with its outputted scores. The multiround predicted scores by the contrastive learning model are further used to evaluate the abnormality of each node with statistical estimation. In this way, the learning model is trained by a specific anomaly detection-aware target. Furthermore, since the input of the GNN module is batches of instance pairs instead of the full network, our framework can adapt to large networks flexibly. Experimental results show that our proposed framework outperforms the state-of-the-art baseline methods on all seven benchmark data sets."
https://openalex.org/W3099025572,Multi-task Self-Supervised Learning for Human Activity Detection,"{'Deep': [0], 'learning': [1, 77, 79, 112, 192, 218, 285], 'methods': [2], 'are': [3, 59, 259], 'successfully': [4], 'used': [5], 'in': [6, 48, 160, 187, 313], 'applications': [7], 'pertaining': [8], 'to': [9, 36, 39, 50, 89, 121, 137, 200, 307], 'ubiquitous': [10], 'computing,': [11], 'pervasive': [12], 'intelligence,': [13], 'health,': [14], 'and': [15, 31, 71, 190, 211, 281, 303], 'well-being.': [16], 'Specifically,': [17], 'the': [18, 29, 83, 91, 156, 170, 176, 223, 226, 231, 257, 269, 277, 295, 298], 'area': [19], 'of': [20, 56, 86, 94, 124, 155, 271, 311], 'human': [21], 'activity': [22, 128, 209, 273], 'recognition': [23], '(HAR)': [24], 'is': [25, 62, 85, 301], 'primarily': [26], 'transformed': [27], 'by': [28, 68, 98, 234], 'convolutional': [30, 135], 'recurrent': [32], 'neural': [33], 'networks,': [34], 'thanks': [35], 'their': [37], 'ability': [38], 'learn': [40, 131], 'semantic': [41, 125], 'representations': [42], 'directly': [43, 207], 'from': [44, 113, 261], 'raw': [45], 'input.': [46], 'However,': [47], 'order': [49], 'extract': [51], 'generalizable': [52], 'features': [53, 168, 228, 258], 'massive': [54], 'amounts': [55], 'well-curated': [57], 'data': [58, 96, 115, 264], 'required,': [60], 'which': [61], 'a': [63, 106, 132, 161, 236, 262, 308], 'notoriously': [64], 'challenging': [65], 'task;': [66], 'hindered': [67], 'privacy': [69], 'issues': [70], 'annotation': [72], 'costs.': [73], 'Therefore,': [74], 'unsupervised': [75, 217, 282], 'representation': [76], '(i.e.,': [78], 'without': [80], 'manually': [81], 'labeling': [82], 'instances)': [84], 'prime': [87], 'importance': [88], 'leverage': [90], 'vast': [92], 'amount': [93], 'unlabeled': [95], 'produced': [97], 'smart': [99], 'devices.': [100], 'In': [101], 'this': [102, 289], 'work,': [103], 'we': [104, 149], 'propose': [105], 'novel': [107], 'self-supervised': [108, 227], 'technique': [109], 'for': [110, 165, 169, 184, 222, 284], 'feature': [111], 'sensory': [114], 'that': [116, 151], 'does': [117], 'not': [118], 'require': [119], 'access': [120], 'any': [122], 'form': [123], 'labels,': [126, 210], 'i.e.,': [127], 'classes.': [129], 'We': [130, 173, 250], 'multi-task': [133], 'temporal': [134], 'network': [136], 'recognize': [138], 'transformations': [139], 'applied': [140, 306], 'on': [141, 179, 292], 'an': [142], 'input': [143], 'signal.': [144], 'By': [145], 'exploiting': [146], 'these': [147], 'transformations,': [148], 'demonstrate': [150], 'simple': [152], 'auxiliary': [153], 'tasks': [154], 'binary': [157], 'classification': [158], 'result': [159], 'strong': [162], 'supervisory': [163], 'signal': [164], 'extracting': [166], 'useful': [167], 'down-stream': [171], 'task.': [172], 'extensively': [174], 'evaluate': [175], 'proposed': [177, 299], 'approach': [178, 300], 'several': [180], 'publicly': [181], 'available': [182], 'datasets': [183], 'smartphone-based': [185], 'HAR': [186, 293], 'unsupervised,': [188], 'semi-supervised': [189, 224], 'transfer': [191], 'settings.': [193], 'Our': [194], 'method': [195], 'achieves': [196], 'performance': [197, 254], 'levels': [198], 'superior': [199], 'or': [201], 'comparable': [202], 'with': [203, 208, 243], 'fully-supervised': [204], 'networks': [205], 'trained': [206], 'it': [212], 'performs': [213], 'significantly': [214], 'better': [215], 'than': [216], 'through': [219], 'autoencoders.': [220], 'Notably,': [221], 'case,': [225], 'substantially': [229], 'boost': [230], 'detection': [232], 'rate': [233], 'attaining': [235], 'kappa': [237], 'score': [238], 'between': [239, 279], '0.7': [240], '-': [241], '0.8': [242], 'only': [244], '10': [245], 'labeled': [246, 272], 'examples': [247], 'per': [248], 'class.': [249], 'get': [251], 'similar': [252], 'impressive': [253], 'even': [255], 'if': [256], 'transferred': [260], 'different': [263], 'source.': [265], 'Self-supervision': [266], 'drastically': [267], 'reduces': [268], 'requirement': [270], 'data,': [274], 'effectively': [275], 'narrowing': [276], 'gap': [278], 'supervised': [280], 'techniques': [283], 'meaningful': [286], 'representations.': [287], 'While': [288], 'paper': [290], 'focuses': [291], 'as': [294], 'application': [296], 'domain,': [297], 'general': [302], 'could': [304], 'be': [305], 'wide': [309], 'variety': [310], 'problems': [312], 'other': [314], 'areas.': [315]}",2019,"['Computer science', 'Artificial intelligence', 'Leverage (statistics)', 'Feature learning', 'Transfer of learning', 'Machine learning', 'Convolutional neural network', 'Supervised learning', 'Task (project management)', 'Deep learning', 'Labeled data', 'Binary classification', 'Unsupervised learning', 'Semi-supervised learning', 'Pattern recognition (psychology)', 'Artificial neural network', 'Support vector machine', 'Economics', 'Management']","Deep learning methods are successfully used in applications pertaining to ubiquitous computing, pervasive intelligence, health, and well-being. Specifically, the area of human activity recognition (HAR) is primarily transformed by the convolutional and recurrent neural networks, thanks to their ability to learn semantic representations directly from raw input. However, in order to extract generalizable features massive amounts of well-curated data are required, which is a notoriously challenging task; hindered by privacy issues and annotation costs. Therefore, unsupervised representation learning (i.e., learning without manually labeling the instances) is of prime importance to leverage the vast amount of unlabeled data produced by smart devices. In this work, we propose a novel self-supervised technique for feature learning from sensory data that does not require access to any form of semantic labels, i.e., activity classes. We learn a multi-task temporal convolutional network to recognize transformations applied on an input signal. By exploiting these transformations, we demonstrate that simple auxiliary tasks of the binary classification result in a strong supervisory signal for extracting useful features for the down-stream task. We extensively evaluate the proposed approach on several publicly available datasets for smartphone-based HAR in unsupervised, semi-supervised and transfer learning settings. Our method achieves performance levels superior to or comparable with fully-supervised networks trained directly with activity labels, and it performs significantly better than unsupervised learning through autoencoders. Notably, for the semi-supervised case, the self-supervised features substantially boost the detection rate by attaining a kappa score between 0.7 - 0.8 with only 10 labeled examples per class. We get similar impressive performance even if the features are transferred from a different data source. Self-supervision drastically reduces the requirement of labeled activity data, effectively narrowing the gap between supervised and unsupervised techniques for learning meaningful representations. While this paper focuses on HAR as the application domain, the proposed approach is general and could be applied to a wide variety of problems in other areas."
https://openalex.org/W2954540134,Using Self-Supervised Learning Can Improve Model Robustness and Uncertainty,"{'Self-supervision': [0], 'provides': [1], 'effective': [2], 'representations': [3], 'for': [4, 30, 84, 99], 'downstream': [5], 'tasks': [6, 93], 'without': [7], 'requiring': [8], 'labels.': [9], 'However,': [10], 'existing': [11], 'approaches': [12], 'lag': [13], 'behind': [14], 'fully': [15, 74], 'supervised': [16, 75], 'training': [17], 'and': [18, 51, 87, 90], 'are': [19], 'often': [20], 'not': [21], 'thought': [22], 'beneficial': [23], 'beyond': [24], 'obviating': [25], 'or': [26], 'reducing': [27], 'the': [28, 71, 80], 'need': [29], 'annotations.': [31], 'We': [32], 'find': [33], 'that': [34, 68], 'self-supervision': [35, 56, 83], 'can': [36], 'benefit': [37], 'robustness': [38, 45, 86], 'in': [39], 'a': [40], 'variety': [41], 'of': [42, 73, 82, 97], 'ways,': [43], 'including': [44], 'to': [46], 'adversarial': [47], 'examples,': [48], 'label': [49], 'corruption,': [50], 'common': [52], 'input': [53], 'corruptions.': [54], 'Additionally,': [55], 'greatly': [57], 'benefits': [58], 'out-of-distribution': [59], 'detection': [60], 'on': [61], 'difficult,': [62], 'near-distribution': [63], 'outliers,': [64], 'so': [65, 67], 'much': [66], 'it': [69], 'exceeds': [70], 'performance': [72], 'methods.': [76], 'These': [77], 'results': [78], 'demonstrate': [79], 'promise': [81], 'improving': [85], 'uncertainty': [88], 'estimation': [89], 'establish': [91], 'these': [92], 'as': [94], 'new': [95], 'axes': [96], 'evaluation': [98], 'future': [100], 'self-supervised': [101], 'learning': [102], 'research.': [103]}",2019,"['Robustness (evolution)', 'Outlier', 'Computer science', 'Machine learning', 'Artificial intelligence', 'Adversarial system', 'Chemistry', 'Gene', 'Biochemistry']","Self-supervision provides effective representations for downstream tasks without requiring labels. However, existing approaches lag behind fully supervised training and are often not thought beneficial beyond obviating or reducing the need for annotations. We find that self-supervision can benefit robustness in a variety of ways, including robustness to adversarial examples, label corruption, and common input corruptions. Additionally, self-supervision greatly benefits out-of-distribution detection on difficult, near-distribution outliers, so much so that it exceeds the performance of fully supervised methods. These results demonstrate the promise of self-supervision for improving robustness and uncertainty estimation and establish these tasks as new axes of evaluation for future self-supervised learning research."
https://openalex.org/W2979476256,vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations,"{'We': [0], 'propose': [1], 'vq-wav2vec': [2], 'to': [3, 28], 'learn': [4], 'discrete': [5, 46], 'representations': [6], 'of': [7, 38, 57], 'audio': [8], 'segments': [9], 'through': [10], 'a': [11, 21, 54], 'wav2vec-style': [12], 'self-supervised': [13], 'context': [14], 'prediction': [15], 'task.': [16], 'The': [17], 'algorithm': [18], 'uses': [19], 'either': [20], 'gumbel': [22], 'softmax': [23], 'or': [24], 'online': [25], 'k-means': [26], 'clustering': [27], 'quantize': [29], 'the': [30, 35, 41, 58], 'dense': [31], 'representations.': [32], 'Discretization': [33], 'enables': [34], 'direct': [36], 'application': [37], 'algorithms': [39], 'from': [40], 'NLP': [42], 'community': [43], 'which': [44], 'require': [45], 'inputs.': [47], 'Experiments': [48], 'show': [49], 'that': [50], 'BERT': [51], 'pre-training': [52], 'achieves': [53], 'new': [55], 'state': [56], 'art': [59], 'on': [60], 'TIMIT': [61], 'phoneme': [62], 'classification': [63], 'and': [64], 'WSJ': [65], 'speech': [66], 'recognition.': [67]}",2019,"['TIMIT', 'Softmax function', 'Computer science', 'Speech recognition', 'Artificial intelligence', 'Cluster analysis', 'Task (project management)', 'Discretization', 'Context (archaeology)', 'Pattern recognition (psychology)', 'Natural language processing', 'Hidden Markov model', 'Artificial neural network', 'Mathematics', 'Mathematical analysis', 'Paleontology', 'Management', 'Economics', 'Biology']",We propose vq-wav2vec to learn discrete representations of audio segments through a wav2vec-style self-supervised context prediction task. The algorithm uses either a gumbel softmax or online k-means clustering to quantize the dense representations. Discretization enables the direct application of algorithms from the NLP community which require discrete inputs. Experiments show that BERT pre-training achieves a new state of the art on TIMIT phoneme classification and WSJ speech recognition.
https://openalex.org/W2794908468,Semi-supervised learning: a brief review,"{'Most': [0], 'of': [1, 59, 99, 103], 'the': [2, 34, 97], 'application': [3], 'domain': [4, 28], 'suffers': [5], 'from': [6], 'not': [7], 'having': [8], 'sufficient': [9], 'labeled': [10, 20], 'data': [11, 14, 36], 'whereas': [12], 'unlabeled': [13, 35], 'is': [15, 23, 73], 'available': [16], 'cheaply.': [17], 'To': [18], 'get': [19], 'instances,': [21], 'it': [22], 'very': [24], 'difficult': [25], 'because': [26], 'experienced': [27], 'experts': [29], 'are': [30], 'required': [31], 'to': [32, 76], 'label': [33], 'patterns.': [37], 'Semi-supervised': [38, 60, 77, 80, 104], 'learning': [39, 61, 91], 'addresses': [40, 56, 96], 'this': [41], 'problem': [42], 'and': [43, 51, 79, 89, 101], 'act': [44], 'as': [45, 64], 'a': [46], 'half': [47], 'way': [48], 'between': [49], 'supervised': [50, 88], 'unsupervised': [52, 90], 'learning.': [53, 105], 'This': [54], 'paper': [55, 94], 'few': [57], 'techniques': [58], '(SSL)': [62], 'such': [63], 'self-training,': [65], 'co-training,': [66], 'multi-view': [67], 'learning,': [68], 'TSVMs': [69], 'methods.': [70], 'Traditionally': [71], 'SSL': [72], 'classified': [74], 'in': [75], 'Classification': [78], 'Clustering': [81], 'which': [82], 'achieves': [83], 'better': [84], 'accuracy': [85], 'than': [86], 'traditional': [87], 'techniques.': [92], 'The': [93], 'also': [95], 'issue': [98], 'scalability': [100], 'applications': [102]}",2018,"['Semi-supervised learning', 'Computer science', 'Unsupervised learning', 'Machine learning', 'Artificial intelligence', 'Supervised learning', 'Labeled data', 'Cluster analysis', 'Scalability', 'Domain (mathematical analysis)', 'Co-training', 'Pattern recognition (psychology)', 'Artificial neural network', 'Mathematics', 'Database', 'Mathematical analysis']","Most of the application domain suffers from not having sufficient labeled data whereas unlabeled data is available cheaply. To get labeled instances, it is very difficult because experienced domain experts are required to label the unlabeled data patterns. Semi-supervised learning addresses this problem and act as a half way between supervised and unsupervised learning. This paper addresses few techniques of Semi-supervised learning (SSL) such as self-training, co-training, multi-view learning, TSVMs methods. Traditionally SSL is classified in to Semi-supervised Classification and Semi-supervised Clustering which achieves better accuracy than traditional supervised and unsupervised learning techniques. The paper also addresses the issue of scalability and applications of Semi-supervised learning."
https://openalex.org/W3041561163,TERA: Self-Supervised Learning of Transformer Encoder Representation for Speech,"{'We': [0, 88, 103, 144], 'introduce': [1], 'a': [2, 21, 45, 65, 105], 'self-supervised': [3, 109], 'speech': [4, 81, 101], 'pre-training': [5, 136, 141], 'method': [6, 175], 'called': [7], 'TERA,': [8], 'which\\nstands': [9], 'for': [10, 80, 165], 'Transformer': [11], 'Encoder': [12], 'Representations': [13], 'from': [14, 59], 'Alteration.': [15], 'Recent\\napproaches': [16], 'often': [17], 'learn': [18], 'by': [19, 117], 'using': [20], 'single': [22], 'auxiliary': [23], 'task': [24], 'like': [25], 'contrastive\\nprediction,': [26], 'autoregressive': [27], 'prediction,': [28], 'or': [29, 83], 'masked': [30], 'reconstruction.': [31], 'Unlike\\nprevious': [32], 'methods,': [33], 'we': [34, 63, 128, 172], 'use': [35, 64], 'alteration': [36], 'along': [37, 70], 'three': [38], 'orthogonal': [39], 'axes': [40], 'to': [41, 68, 178], 'pre-train\\nTransformer': [42], 'Encoders': [43], 'on': [44, 91, 137, 142], 'large': [46], 'amount': [47], 'of': [48, 56, 132], 'unlabeled': [49], 'speech.': [50], 'The': [51], 'model': [52, 147], 'learns\\nthrough': [53], 'the': [54, 130], 'reconstruction': [55], 'acoustic': [57], 'frames': [58], 'their': [60], 'altered': [61], 'counterpart,\\nwhere': [62], 'stochastic': [66], 'policy': [67], 'alter': [69], 'various': [71], 'dimensions:': [72], 'time,\\nfrequency,': [73], 'and': [74, 100, 122, 140, 149], 'magnitude.': [75], 'TERA': [76, 90, 111], 'can': [77], 'be': [78], 'used': [79, 182], 'representations\\nextraction': [82], 'fine-tuning': [84, 167], 'with': [85], 'downstream': [86, 166, 179], 'models.': [87, 110, 170], 'evaluate': [89], 'several\\ndownstream': [92], 'tasks,': [93], 'including': [94], 'phoneme': [95], 'classification,': [96], 'keyword': [97], 'spotting,': [98], 'speaker\\nrecognition,': [99], 'recognition.': [102], 'present': [104], 'large-scale': [106], 'comparison': [107], 'of\\nvarious': [108], 'achieves': [112], 'strong': [113], 'performance': [114], 'in': [115], 'the\\ncomparison': [116], 'improving': [118], 'upon': [119], 'surface': [120], 'features': [121], 'outperforming': [123], 'previous\\nmodels.': [124], 'In': [125], 'our': [126], 'experiments,': [127], 'study': [129], 'effect': [131], 'applying': [133], 'different\\nalteration': [134], 'techniques,': [135], 'more': [138], 'data,': [139], 'various\\nfeatures.': [143], 'analyze': [145], 'different': [146], 'sizes': [148], 'find': [150], 'that': [151], 'smaller': [152, 169], 'models': [153, 162], 'are\\nstrong': [154], 'representation': [155], 'learners': [156], 'than': [157, 168], 'larger': [158, 161], 'models,': [159], 'while': [160], 'are': [163], 'more\\neffective': [164], 'Furthermore,': [171], 'show\\nthe': [173], 'proposed': [174], 'is': [176], 'transferable': [177], 'datasets': [180], 'not': [181], 'in\\npre-training.\\n': [183]}",2021,"['Tera-', 'Computer science', 'Transformer', 'Encoder', 'Autoregressive model', 'Speech recognition', 'Keyword spotting', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Machine learning', 'Mathematics', 'Engineering', 'Voltage', 'Operating system', 'Electrical engineering', 'Econometrics']","We introduce a self-supervised speech pre-training method called TERA, which\nstands for Transformer Encoder Representations from Alteration. Recent\napproaches often learn by using a single auxiliary task like contrastive\nprediction, autoregressive prediction, or masked reconstruction. Unlike\nprevious methods, we use alteration along three orthogonal axes to pre-train\nTransformer Encoders on a large amount of unlabeled speech. The model learns\nthrough the reconstruction of acoustic frames from their altered counterpart,\nwhere we use a stochastic policy to alter along various dimensions: time,\nfrequency, and magnitude. TERA can be used for speech representations\nextraction or fine-tuning with downstream models. We evaluate TERA on several\ndownstream tasks, including phoneme classification, keyword spotting, speaker\nrecognition, and speech recognition. We present a large-scale comparison of\nvarious self-supervised models. TERA achieves strong performance in the\ncomparison by improving upon surface features and outperforming previous\nmodels. In our experiments, we study the effect of applying different\nalteration techniques, pre-training on more data, and pre-training on various\nfeatures. We analyze different model sizes and find that smaller models are\nstrong representation learners than larger models, while larger models are more\neffective for downstream fine-tuning than smaller models. Furthermore, we show\nthe proposed method is transferable to downstream datasets not used in\npre-training.\n"
https://openalex.org/W4288020585,ReMixMatch: Semi-Supervised Learning with Distribution Alignment and\n Augmentation Anchoring,"{'We': [0, 135], 'improve': [1], 'the': [2, 19, 30, 45, 54, 61, 74, 78, 102], 'recently-proposed': [3], '""MixMatch""': [4], 'semi-supervised': [5], 'learning\\nalgorithm': [6], 'by': [7], 'introducing': [8], 'two': [9], 'new': [10], 'techniques:': [11], 'distribution': [12], 'alignment': [13, 17], 'and\\naugmentation': [14], 'anchoring.': [15], 'Distribution': [16], 'encourages': [18, 48], 'marginal\\ndistribution': [20, 31], 'of': [21, 32, 41, 60, 71, 119, 127], 'predictions': [22], 'on': [23, 106], 'unlabeled': [24], 'data': [25, 99, 139], 'to': [26, 29, 50, 53, 100, 116], 'be': [27, 51], 'close': [28, 52], 'ground-truth': [33], 'labels.': [34], 'Augmentation': [35], 'anchoring': [36], 'feeds': [37], 'multiple\\nstrongly': [38], 'augmented': [39], 'versions': [40], 'an': [42], 'input': [43], 'into': [44], 'model': [46, 79], 'and': [47, 96, 138], 'each\\noutput': [49], 'prediction': [55], 'for': [56], 'a': [57, 69, 124], 'weakly-augmented': [58], 'version': [59], 'same\\ninput.': [62], 'To': [63], 'produce': [64], 'strong': [65], 'augmentations,': [66], 'we': [67, 112], 'propose': [68], 'variant': [70], 'AutoAugment\\nwhich': [72], 'learns': [73], 'augmentation': [75], 'policy': [76], 'while': [77], 'is': [80, 87], 'being': [81], 'trained.': [82], 'Our': [83], 'new\\nalgorithm,': [84], 'dubbed': [85], 'ReMixMatch,': [86], 'significantly': [88], 'more': [89], 'data-efficient': [90], 'than': [91], 'prior\\nwork,': [92], 'requiring': [93], 'between': [94], '$5\\\\times$': [95], '$16\\\\times$': [97], 'less': [98], 'reach': [101, 113], 'same\\naccuracy.': [103], 'For': [104], 'example,': [105], 'CIFAR-10': [107], 'with': [108, 121, 129], '250': [109], 'labeled': [110], 'examples': [111], '$93.73\\\\%$\\naccuracy': [114], '(compared': [115], ""MixMatch's"": [117], 'accuracy': [118, 126], '$93.58\\\\%$': [120], '$4{,}000$': [122], 'examples)\\nand': [123], 'median': [125], '$84.92\\\\%$': [128], 'just': [130], 'four': [131], 'labels': [132], 'per': [133], 'class.': [134], 'make': [136], 'our\\ncode': [137], 'open-source': [140], 'at': [141], 'https://github.com/google-research/remixmatch.\\n': [142]}",2019,"['Anchoring', 'Computer science', 'Code (set theory)', 'Ground truth', 'Class (philosophy)', 'Artificial intelligence', 'Labeled data', 'Distribution (mathematics)', 'Pattern recognition (psychology)', 'Machine learning', 'Mathematics', 'Set (abstract data type)', 'Psychology', 'Social psychology', 'Programming language', 'Mathematical analysis']","We improve the recently-proposed ""MixMatch"" semi-supervised learning\nalgorithm by introducing two new techniques: distribution alignment and\naugmentation anchoring. Distribution alignment encourages the marginal\ndistribution of predictions on unlabeled data to be close to the marginal\ndistribution of ground-truth labels. Augmentation anchoring feeds multiple\nstrongly augmented versions of an input into the model and encourages each\noutput to be close to the prediction for a weakly-augmented version of the same\ninput. To produce strong augmentations, we propose a variant of AutoAugment\nwhich learns the augmentation policy while the model is being trained. Our new\nalgorithm, dubbed ReMixMatch, is significantly more data-efficient than prior\nwork, requiring between $5\\times$ and $16\\times$ less data to reach the same\naccuracy. For example, on CIFAR-10 with 250 labeled examples we reach $93.73\\%$\naccuracy (compared to MixMatch's accuracy of $93.58\\%$ with $4{,}000$ examples)\nand a median accuracy of $84.92\\%$ with just four labels per class. We make our\ncode and data open-source at https://github.com/google-research/remixmatch.\n"
https://openalex.org/W4286695273,VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning,"{'Recent': [0], 'self-supervised': [1], 'methods': [2, 129], 'for': [3], 'image': [4], 'representation': [5], 'learning': [6, 45], 'are': [7], 'based': [8, 95], 'on': [9, 76, 96, 105, 113], 'maximizing': [10], 'the': [11, 20, 29, 44, 68, 77, 80, 88, 108, 111, 132], 'agreement': [12], 'between': [13], 'embedding': [14], 'vectors': [15], 'from': [16], 'different': [17], 'views': [18], 'of': [19, 79, 110], 'same': [21], 'image.': [22], 'A': [23], 'trivial': [24], 'solution': [25], 'is': [26, 37], 'obtained': [27], 'when': [28], 'encoder': [30], 'outputs': [31], 'constant': [32], 'vectors.': [33], 'This': [34], 'collapse': [35, 69], 'problem': [36, 70], 'often': [38, 48], 'avoided': [39], 'through': [40], 'implicit': [41], 'biases': [42], 'in': [43], 'architecture,': [46], 'that': [47, 65, 121], 'lack': [49], 'a': [50, 63, 72, 92], 'clear': [51], 'justification': [52], 'or': [53], 'interpretation.': [54], 'In': [55, 117], 'this': [56], 'paper,': [57], 'we': [58, 119], 'introduce': [59], 'VICReg': [60, 86], '(Variance-Invariance-Covariance': [61], 'Regularization),': [62], 'method': [64], 'explicitly': [66], 'avoids': [67], 'with': [71, 91, 107], 'simple': [73], 'regularization': [74], 'term': [75, 90, 126], 'variance': [78, 89, 125], 'embeddings': [81], 'along': [82], 'each': [83], 'dimension': [84], 'individually.': [85], 'combines': [87], 'decorrelation': [93], 'mechanism': [94], 'redundancy': [97], 'reduction': [98], 'and': [99, 102, 134], 'covariance': [100], 'regularization,': [101], 'achieves': [103], 'results': [104], 'par': [106], 'state': [109], 'art': [112], 'several': [114], 'downstream': [115], 'tasks.': [116], 'addition,': [118], 'show': [120], 'incorporating': [122], 'our': [123], 'new': [124], 'into': [127], 'other': [128], 'helps': [130], 'stabilize': [131], 'training': [133], 'leads': [135], 'to': [136], 'performance': [137], 'improvements.': [138]}",2021,"['Regularization (linguistics)', 'Decorrelation', 'Covariance', 'Embedding', 'Computer science', 'Algorithm', 'Artificial intelligence', 'Mathematics', 'Statistics']","Recent self-supervised methods for image representation learning are based on maximizing the agreement between embedding vectors from different views of the same image. A trivial solution is obtained when the encoder outputs constant vectors. This collapse problem is often avoided through implicit biases in the learning architecture, that often lack a clear justification or interpretation. In this paper, we introduce VICReg (Variance-Invariance-Covariance Regularization), a method that explicitly avoids the collapse problem with a simple regularization term on the variance of the embeddings along each dimension individually. VICReg combines the variance term with a decorrelation mechanism based on redundancy reduction and covariance regularization, and achieves results on par with the state of the art on several downstream tasks. In addition, we show that incorporating our new variance term into other methods helps stabilize the training and leads to performance improvements."
https://openalex.org/W3040739508,ProtTrans: Towards Cracking the Language of Life’s Code Through Self-Supervised Learning,"{'Abstract': [0], 'Computational': [1], 'biology': [2], 'and': [3, 38, 50, 70, 135], 'bioinformatics': [4], 'provide': [5], 'vast': [6], 'data': [7, 47, 87], 'gold-mines': [8], 'from': [9, 17, 48, 85], 'protein': [10, 82, 93, 117, 129, 176], 'sequences,': [11], 'ideal': [12], 'for': [13, 22, 106, 154], 'Language': [14], 'Models': [15], 'taken': [16], 'NLP.': [18], 'These': [19], 'LMs': [20, 60, 177], 'reach': [21], 'new': [23], 'prediction': [24, 115], 'frontiers': [25], 'at': [26, 197], 'low': [27], 'inference': [28], 'costs.': [29], 'Here,': [30], 'we': [31, 193], 'trained': [32, 62], 'two': [33], 'auto-regressive': [34], 'models': [35, 41, 196], '(Transformer-XL,': [36], 'XLNet)': [37], 'four': [39], 'auto-encoder': [40], '(BERT,': [42], 'Albert,': [43], 'Electra,': [44], 'T5)': [45], 'on': [46, 63], 'UniRef': [49], 'BFD': [51], 'containing': [52], 'up': [53], 'to': [54], '393': [55], 'billion': [56], 'amino': [57], 'acids.': [58], 'The': [59, 110], 'were': [61, 125], 'the': [64, 80, 97, 101, 123, 143, 146, 149, 155, 159, 172, 181, 184], 'Summit': [65], 'supercomputer': [66], 'using': [67, 100, 162], '5616': [68], 'GPUs': [69], 'TPU': [71], 'Pod': [72], 'up-to': [73], '1024': [74], 'cores.': [75], 'Dimensionality': [76], 'reduction': [77], 'revealed': [78], 'that': [79, 175], 'raw': [81], 'LM-': [83], 'embeddings': [84, 102, 152], 'unlabeled': [86], 'captured': [88], 'some': [89, 179], 'biophysical': [90], 'features': [91], 'of': [92, 99, 116, 128, 148, 180, 183, 186], 'sequences.': [94], 'We': [95], 'validated': [96], 'advantage': [98], 'as': [103], 'exclusive': [104], 'input': [105], 'several': [107], 'subsequent': [108], 'tasks.': [109], 'first': [111, 156], 'was': [112], 'a': [113], 'per-residue': [114, 144], 'secondary': [118], 'structure': [119], '(3-state': [120], 'accuracy': [121, 140], 'Q3=81%-87%);': [122], 'second': [124], 'per-protein': [126], 'predictions': [127, 145], 'sub-cellular': [130], 'localization': [131], '(ten-state': [132], 'accuracy:': [133], 'Q10=81%)': [134], 'membrane': [136], 'vs.': [137], 'water-soluble': [138], '(2-state': [139], 'Q2=91%).': [141], 'For': [142], 'transfer': [147], 'most': [150], 'informative': [151], '(ProtT5)': [153], 'time': [157], 'outperformed': [158], 'state-of-the-art': [160], 'without': [161], 'evolutionary': [163], 'information': [164], 'thereby': [165], 'bypassing': [166], 'expensive': [167], 'database': [168], 'searches.': [169], 'Taken': [170], 'together,': [171], 'results': [173], 'implied': [174], 'learned': [178], 'grammar': [182], 'language': [185], 'life': [187], '.': [188, 199], 'To': [189], 'facilitate': [190], 'future': [191], 'work,': [192], 'released': [194], 'our': [195], 'https://github.com/agemagician/ProtTrans': [198]}",2020,[],"Abstract Computational biology and bioinformatics provide vast data gold-mines from protein sequences, ideal for Language Models taken from NLP. These LMs reach for new prediction frontiers at low inference costs. Here, we trained two auto-regressive models (Transformer-XL, XLNet) and four auto-encoder models (BERT, Albert, Electra, T5) on data from UniRef and BFD containing up to 393 billion amino acids. The LMs were trained on the Summit supercomputer using 5616 GPUs and TPU Pod up-to 1024 cores. Dimensionality reduction revealed that the raw protein LM- embeddings from unlabeled data captured some biophysical features of protein sequences. We validated the advantage of using the embeddings as exclusive input for several subsequent tasks. The first was a per-residue prediction of protein secondary structure (3-state accuracy Q3=81%-87%); the second were per-protein predictions of protein sub-cellular localization (ten-state accuracy: Q10=81%) and membrane vs. water-soluble (2-state accuracy Q2=91%). For the per-residue predictions the transfer of the most informative embeddings (ProtT5) for the first time outperformed the state-of-the-art without using evolutionary information thereby bypassing expensive database searches. Taken together, the results implied that protein LMs learned some of the grammar of the language of life . To facilitate future work, we released our models at https://github.com/agemagician/ProtTrans ."
https://openalex.org/W1516529420,Supervised learning in the brain,"{'Experience': [0], 'shapes': [1, 24], 'the': [2, 6, 14, 25, 49, 58, 74, 104, 109, 132, 136, 155, 160, 166, 175, 182, 186, 189, 199, 208, 214, 218, 225, 229, 232, 237, 254, 257, 266, 282, 319], 'functional': [3], 'organization': [4], 'of': [5, 40, 51, 85, 113, 116, 157, 168, 174, 181, 201, 210, 217, 231, 269, 284, 306, 322], 'brain,': [7], 'optimizing': [8], 'and': [9, 16, 88, 111, 192, 295], 'customizing': [10], 'its': [11], 'properties': [12], 'for': [13], 'individual': [15], 'his': [17], 'or': [18, 70], 'her': [19], 'environment.One': [20], 'way': [21], 'that': [22, 66, 92, 122, 143, 184, 264, 276, 286], 'experience': [23], 'constituent': [26], 'networks': [27, 121, 285], 'ofthe': [28], 'brain': [29, 117], 'is': [30, 77, 162, 274], 'through': [31], 'supervised': [32, 34, 81, 277, 311], 'learning.In': [33], 'learning,': [35], 'information': [36, 64, 171, 202], 'from': [37, 224, 236, 256], 'one': [38], 'network': [39, 60], 'neurons': [41, 212], 'acts': [42], 'as': [43, 292, 301, 313], 'an': [44, 261], 'instructive': [45, 75, 152, 262, 323], 'signal': [46, 76, 263], 'to': [47, 62, 96, 108, 164, 281], 'influence': [48], 'pattern': [50, 293], 'connectivity': [52, 86], 'in': [53, 103, 203, 207, 213, 252, 318], 'another': [54], 'network.As': [55], 'a': [56, 67, 90, 114, 140, 150], 'result,': [57], 'instructed': [59], 'learns': [61], 'process': [63], 'so': [65, 79], 'particular': [68], 'goal': [69], 'transformation': [71, 167], 'specified': [72], 'by': [73, 128], 'achieved.In': [78], 'doing,': [80], 'learning': [82, 106, 195, 278, 312], 'establishes': [83], 'patterns': [84], 'efficiently': [87], 'with': [89, 134], 'precision': [91], 'does': [93], 'not': [94], 'need': [95], 'be': [97, 101, 145, 250, 316], 'and,': [98], 'often,': [99], 'cannot': [100], 'encoded': [102], 'genome.Supervised': [105], 'contributes': [107, 280], 'development': [110, 209], 'maintenance': [112], 'variety': [115], 'functions.For': [118], 'example,': [119, 206, 246], 'sensorimotor': [120], 'control': [123, 198], 'goal-directed': [124], 'movements': [125, 137, 180], 'are': [126, 138], 'calibrated': [127], 'sensory': [129, 170, 204], 'feedback': [130], 'indicating': [131, 154], 'accuracy': [133], 'which': [135, 247], 'made.In': [139], 'specific': [141], 'example': [142], 'will': [144, 249], 'discussed': [146, 251], 'at': [147], 'some': [148], 'length,': [149], 'visual': [151, 233], 'signal,': [153], 'slip': [156], 'images': [158, 187], 'across': [159], 'retinae,': [161], 'used': [163], 'calibrate': [165], 'vestibular': [169], '(indicating': [172], 'rotation': [173], 'head)': [176], 'into': [177], 'precise,': [178], 'compensatory': [179], 'eyes': [183], 'stabilize': [185], 'on': [188], 'retinae': [190], '(Miles': [191], 'Eighmy,': [193], '1980).Supervised': [194], 'can': [196], 'also': [197, 248, 279], 'representation': [200], 'networks.For': [205], 'binocular': [211], 'optic': [215], 'tectum': [216], 'frog': [219], 'Xenopus,': [220], 'visually': [221], 'driven': [222], 'activity': [223, 255], 'contralateral': [226, 258], 'eye': [227, 239, 259], 'specifies': [228], 'topography': [230], 'map': [234], 'originating': [235], 'ipsilateral': [238], '(Gaze': [240], 'et': [241], 'al.,': [242], '1970;Udin,': [243], '1985).In': [244], 'this': [245, 307], 'detail,': [253], 'provides': [260], 'assures': [265], 'mutual': [267], 'alignment': [268], 'left-and': [270], 'right-eye': [271], 'receptive': [272], 'fields.It': [273], 'likely': [275], 'establishment': [283], 'support': [287], 'certain': [288], 'cognitive': [289], 'skills,': [290], 'such': [291], 'recognition': [294], 'language': [296], 'acquisition,': [297], 'although': [298], 'there': [299], 'is,': [300], 'yet,': [302], 'no': [303], 'experimental': [304], 'confirmation': [305], 'proposition.This': [308], 'article': [309], 'discusses': [310], 'it': [314], 'might': [315], 'implemented': [317], 'brain.Different': [320], 'kinds': [321], 'signals,': [324]}",1994,"['Psychology', 'Neuroscience', 'Cognitive science', 'Cognitive psychology']","Experience shapes the functional organization of the brain, optimizing and customizing its properties for the individual and his or her environment.One way that experience shapes the constituent networks ofthe brain is through supervised learning.In supervised learning, information from one network of neurons acts as an instructive signal to influence the pattern of connectivity in another network.As a result, the instructed network learns to process information so that a particular goal or transformation specified by the instructive signal is achieved.In so doing, supervised learning establishes patterns of connectivity efficiently and with a precision that does not need to be and, often, cannot be encoded in the genome.Supervised learning contributes to the development and maintenance of a variety of brain functions.For example, sensorimotor networks that control goal-directed movements are calibrated by sensory feedback indicating the accuracy with which the movements are made.In a specific example that will be discussed at some length, a visual instructive signal, indicating the slip of images across the retinae, is used to calibrate the transformation of vestibular sensory information (indicating rotation of the head) into precise, compensatory movements of the eyes that stabilize the images on the retinae (Miles and Eighmy, 1980).Supervised learning can also control the representation of information in sensory networks.For example, in the development of binocular neurons in the optic tectum of the frog Xenopus, visually driven activity from the contralateral eye specifies the topography of the visual map originating from the ipsilateral eye (Gaze et al., 1970;Udin, 1985).In this example, which also will be discussed in detail, the activity from the contralateral eye provides an instructive signal that assures the mutual alignment of left-and right-eye receptive fields.It is likely that supervised learning also contributes to the establishment of networks that support certain cognitive skills, such as pattern recognition and language acquisition, although there is, as yet, no experimental confirmation of this proposition.This article discusses supervised learning as it might be implemented in the brain.Different kinds of instructive signals,"
https://openalex.org/W2946856970,S4L: Self-Supervised Semi-Supervised Learning,"{'This': [0], 'work': [1], 'tackles': [2], 'the': [3, 16, 24, 39, 58], 'problem': [4], 'of': [5, 8, 18, 28, 41, 60, 99], 'semi-supervised': [6, 19, 43, 52, 72, 83, 95], 'learning': [7, 20, 44, 73], 'image': [9, 53], 'classifiers.': [10], 'Our': [11], 'main': [12], 'insight': [13], 'is': [14], 'that': [15, 78], 'field': [17, 27], 'can': [21, 85], 'benefit': [22], 'from': [23], 'quickly': [25], 'advancing': [26], 'self-supervised': [29, 42], 'visual': [30], 'representation': [31], 'learning.': [32], 'Unifying': [33], 'these': [34, 61], 'two': [35, 50], 'approaches,': [36], 'we': [37], 'propose': [38], 'framework': [40], 'and': [45, 70, 81], 'use': [46], 'it': [47], 'to': [48, 65], 'derive': [49], 'novel': [51], 'classification': [54], 'methods.': [55, 74], 'We': [56, 75], 'demonstrate': [57], 'effectiveness': [59], 'methods': [62, 84], 'in': [63], 'comparison': [64], 'both': [66], 'carefully': [67], 'tuned': [68], 'baselines,': [69], 'existing': [71, 82], 'then': [76], 'show': [77], 'our': [79], 'approach': [80], 'be': [86], 'jointly': [87], 'trained,': [88], 'yielding': [89], 'a': [90], 'new': [91], 'state-of-the-art': [92], 'result': [93], 'on': [94], 'ILSVRC-2012': [96], 'with': [97], '10%': [98], 'labels.': [100]}",2019,"['Semi-supervised learning', 'Supervised learning', 'Computer science', 'Machine learning', 'Artificial intelligence', 'Field (mathematics)', 'Representation (politics)', 'Unsupervised learning', 'Pattern recognition (psychology)', 'Mathematics', 'Artificial neural network', 'Pure mathematics', 'Law', 'Politics', 'Political science']","This work tackles the problem of semi-supervised learning of image classifiers. Our main insight is that the field of semi-supervised learning can benefit from the quickly advancing field of self-supervised visual representation learning. Unifying these two approaches, we propose the framework of self-supervised semi-supervised learning and use it to derive two novel semi-supervised image classification methods. We demonstrate the effectiveness of these methods in comparison to both carefully tuned baselines, and existing semi-supervised learning methods. We then show that our approach and existing semi-supervised methods can be jointly trained, yielding a new state-of-the-art result on semi-supervised ILSVRC-2012 with 10% of labels."
https://openalex.org/W2738853914,"WILDCAT: Weakly Supervised Learning of Deep ConvNets for Image Classification, Pointwise Localization and Segmentation","{'International': [0], 'audience': [1]}",2017,"['Artificial intelligence', 'Computer science', 'Convolutional neural network', 'Pattern recognition (psychology)', 'Pointwise', 'Contextual image classification', 'Image (mathematics)', 'Image segmentation', 'Deep learning', 'Segmentation', 'Class (philosophy)', 'Supervised learning', 'Artificial neural network', 'Computer vision', 'Machine learning', 'Mathematics', 'Mathematical analysis']",International audience
https://openalex.org/W2586937979,Supervised Learning of Semantics-Preserving Hash via Deep Convolutional Neural Networks,"{'This': [0], 'paper': [1], 'presents': [2], 'a': [3, 63, 67, 96, 106, 123, 141], 'simple': [4, 135], 'yet': [5, 151], 'effective': [6, 154], 'supervised': [7, 54], 'deep': [8, 56, 68, 147], 'hash': [9, 14, 60, 88, 118], 'approach': [10], 'that': [11, 25, 99], 'constructs': [12, 59], 'binary': [13, 72], 'codes': [15, 73, 89], 'from': [16], 'labeled': [17], 'data': [18], 'for': [19, 149], 'large-scale': [20, 131], 'image': [21, 116], 'search.': [22], 'We': [23], 'assume': [24], 'the': [26, 71, 176], 'semantic': [27], 'labels': [28], 'are': [29, 74, 103], 'governed': [30], 'by': [31, 76, 140], 'several': [32, 161], 'latent': [33, 64], 'attributes': [34], 'with': [35, 167], 'each': [36], 'attribute': [37], 'on': [38, 44, 48, 160], 'or': [39], 'off,': [40], 'and': [41, 70, 85, 101, 120, 126, 136, 155, 163], 'classification': [42, 83, 100, 121, 177], 'relies': [43], 'these': [45], 'attributes.': [46], 'Based': [47], 'this': [49, 92], 'assumption,': [50], 'our': [51], 'approach,': [52], 'dubbed': [53], 'semantics-preserving': [55], 'hashing': [57, 158], '(SSDH),': [58], 'functions': [61], 'as': [62], 'layer': [65], 'in': [66, 105, 122], 'network': [69], 'learned': [75], 'minimizing': [77], 'an': [78, 145], 'objective': [79], 'function': [80], 'defined': [81], 'over': [82], 'error': [84], 'other': [86, 157], 'desirable': [87], 'properties.': [90], 'With': [91], 'design,': [93], 'SSDH': [94, 111, 133, 170], 'has': [95], 'nice': [97], 'characteristic': [98], 'retrieval': [102, 173], 'unified': [104], 'single': [107], 'learning': [108, 114], 'model.': [109], 'Moreover,': [110], 'performs': [112], 'joint': [113], 'of': [115, 144], 'representations,': [117], 'codes,': [119], 'point-wised': [124], 'manner,': [125], 'thus': [127], 'is': [128, 134, 153, 179], 'scalable': [129], 'to': [130], 'datasets.': [132, 165], 'can': [137], 'be': [138], 'realized': [139], 'slight': [142], 'enhancement': [143], 'existing': [146], 'architecture': [148], 'classification;': [150], 'it': [152], 'outperforms': [156], 'approaches': [159], 'benchmarks': [162], 'large': [164], 'Compared': [166], 'state-of-the-art': [168], 'approaches,': [169], 'achieves': [171], 'higher': [172], 'accuracy,': [174], 'while': [175], 'performance': [178], 'not': [180], 'sacrificed.': [181]}",2017,"['Hash function', 'Computer science', 'Convolutional neural network', 'Scalability', 'Artificial intelligence', 'Deep learning', 'Feature hashing', 'Hash table', 'Semantics (computer science)', 'Pattern recognition (psychology)', 'Machine learning', 'Double hashing', 'Database', 'Computer security', 'Programming language']","This paper presents a simple yet effective supervised deep hash approach that constructs binary hash codes from labeled data for large-scale image search. We assume that the semantic labels are governed by several latent attributes with each attribute on or off, and classification relies on these attributes. Based on this assumption, our approach, dubbed supervised semantics-preserving deep hashing (SSDH), constructs hash functions as a latent layer in a deep network and the binary codes are learned by minimizing an objective function defined over classification error and other desirable hash codes properties. With this design, SSDH has a nice characteristic that classification and retrieval are unified in a single learning model. Moreover, SSDH performs joint learning of image representations, hash codes, and classification in a point-wised manner, and thus is scalable to large-scale datasets. SSDH is simple and can be realized by a slight enhancement of an existing deep architecture for classification; yet it is effective and outperforms other hashing approaches on several benchmarks and large datasets. Compared with state-of-the-art approaches, SSDH achieves higher retrieval accuracy, while the classification performance is not sacrificed."
https://openalex.org/W2619371851,Good Semi-supervised Learning that Requires a Bad GAN,"{'Semi-supervised': [0], 'learning': [1, 57], 'methods': [2], 'based': [3, 77], 'on': [4, 78, 91], 'generative': [5], 'adversarial': [6], 'networks': [7], '(GANs)': [8], 'obtained': [9, 42], 'strong': [10], 'empirical': [11], 'results,': [12], 'but': [13], 'it': [14], 'is': [15], 'not': [16], 'clear': [17], '1)': [18], 'how': [19], 'the': [20, 44, 52, 65], 'discriminator': [21, 53], 'benefits': [22], 'from': [23], 'joint': [24], 'training': [25], 'with': [26], 'a': [27, 37, 60, 68, 74], 'generator,': [28, 62], 'and': [29, 36, 63], '2)': [30], 'why': [31], 'good': [32, 38, 55], 'semi-supervised': [33], 'classification': [34], 'performance': [35], 'generator': [39], 'cannot': [40], 'be': [41], 'at': [43], 'same': [45], 'time.': [46], 'Theoretically,': [47], 'we': [48, 72], 'show': [49], 'that': [50, 81], 'given': [51], 'objective,': [54], 'semisupervised': [56], 'indeed': [58], 'requires': [59], 'bad': [61], 'propose': [64], 'definition': [66], 'of': [67], 'preferred': [69], 'generator.': [70], 'Empirically,': [71], 'derive': [73], 'novel': [75], 'formulation': [76], 'our': [79], 'analysis': [80], 'substantially': [82], 'improves': [83], 'over': [84], 'feature': [85], 'matching': [86], 'GANs,': [87], 'obtaining': [88], 'state-of-the-art': [89], 'results': [90], 'multiple': [92], 'benchmark': [93], 'datasets.': [94]}",2017,"['Discriminator', 'Generator (circuit theory)', 'Benchmark (surveying)', 'Computer science', 'Artificial intelligence', 'Machine learning', 'Generative grammar', 'Feature matching', 'Matching (statistics)', 'Feature (linguistics)', 'Supervised learning', 'Pattern recognition (psychology)', 'Artificial neural network', 'Feature extraction', 'Power (physics)', 'Mathematics', 'Statistics', 'Philosophy', 'Quantum mechanics', 'Detector', 'Geography', 'Linguistics', 'Geodesy', 'Telecommunications', 'Physics']","Semi-supervised learning methods based on generative adversarial networks (GANs) obtained strong empirical results, but it is not clear 1) how the discriminator benefits from joint training with a generator, and 2) why good semi-supervised classification performance and a good generator cannot be obtained at the same time. Theoretically, we show that given the discriminator objective, good semisupervised learning indeed requires a bad generator, and propose the definition of a preferred generator. Empirically, we derive a novel formulation based on our analysis that substantially improves over feature matching GANs, obtaining state-of-the-art results on multiple benchmark datasets."
https://openalex.org/W3154596443,"VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text","{'We': [0, 40, 84], 'present': [1], 'a': [2, 35, 73, 168], 'framework': [3], 'for': [4], 'learning': [5], 'multimodal': [6, 27, 47], 'representations': [7, 28], 'from': [8, 44, 147], 'unlabeled': [9], 'data': [10], 'using': [11, 46], 'convolution-free': [12, 88], 'Transformer': [13, 18, 76, 101, 146, 165], 'architectures.': [14], 'Specifically,': [15], 'our': [16, 153], 'Video-Audio-Text': [17], '(VATT)': [19], 'takes': [20], 'raw': [21], 'signals': [22], 'as': [23], 'inputs': [24], 'and': [25, 50, 67, 116, 161], 'extracts': [26], 'that': [29, 86], 'are': [30], 'rich': [31], 'enough': [32], 'to': [33, 129, 133, 140], 'benefit': [34], 'variety': [36], 'of': [37, 58, 106, 152, 180], 'downstream': [38, 56, 96], 'tasks.': [39, 97], 'train': [41], 'VATT': [42, 89], 'end-to-end': [43], 'scratch': [45], 'contrastive': [48], 'losses': [49], 'evaluate': [51], 'its': [52], 'performance': [53], 'by': [54, 77, 142, 176], 'the': [55, 81, 87, 95, 103, 144, 150, 156, 178], 'tasks': [57], 'video': [59], 'action': [60], 'recognition,': [61], 'audio': [62, 164, 173], 'event': [63, 174], 'classification,': [64, 66], 'image': [65, 130], 'text-to-video': [68], 'retrieval.': [69], 'Furthermore,': [70], 'we': [71], 'study': [72], 'modality-agnostic,': [74], 'single-backbone': [75], 'sharing': [78], 'weights': [79], 'among': [80], 'three': [82], 'modalities.': [83], 'show': [85], 'outperforms': [90], 'state-of-the-art': [91], 'ConvNet-based': [92], 'architectures': [93], 'in': [94, 120], 'Especially,': [98], ""VATT's"": [99, 163, 188], 'vision': [100], 'achieves': [102], 'top-1': [104, 135], 'accuracy': [105, 136], '82.1%': [107], 'on': [108, 111, 114, 118, 137, 171, 182], 'Kinetics-400,': [109], '83.6%': [110], 'Kinetics-600,': [112], '72.7%': [113], 'Kinetics-700,': [115], '41.1%': [117], 'Moments': [119], 'Time,': [121], 'new': [122, 169], 'records': [123], 'while': [124], 'avoiding': [125], 'supervised': [126, 186], 'pre-training.': [127, 187], 'Transferring': [128], 'classification': [131], 'leads': [132], '78.7%': [134], 'ImageNet': [138], 'compared': [139], '64.7%': [141], 'training': [143], 'same': [145], 'scratch,': [148], 'showing': [149], 'generalizability': [151], 'model': [154], 'despite': [155], 'domain': [157], 'gap': [158], 'between': [159], 'videos': [160], 'images.': [162], 'also': [166], 'sets': [167], 'record': [170], 'waveform-based': [172], 'recognition': [175], 'achieving': [177], 'mAP': [179], '39.4%': [181], 'AudioSet': [183], 'without': [184], 'any': [185], 'source': [189], 'code': [190], 'is': [191], 'publicly': [192], 'available.': [193]}",2021,"['Computer science', 'Transformer', 'Generalizability theory', 'Artificial intelligence', 'Action recognition', 'Speech recognition', 'Pattern recognition (psychology)', 'Voltage', 'Quantum mechanics', 'Mathematics', 'Physics', 'Statistics', 'Class (philosophy)']","We present a framework for learning multimodal representations from unlabeled data using convolution-free Transformer architectures. Specifically, our Video-Audio-Text Transformer (VATT) takes raw signals as inputs and extracts multimodal representations that are rich enough to benefit a variety of downstream tasks. We train VATT end-to-end from scratch using multimodal contrastive losses and evaluate its performance by the downstream tasks of video action recognition, audio event classification, image classification, and text-to-video retrieval. Furthermore, we study a modality-agnostic, single-backbone Transformer by sharing weights among the three modalities. We show that the convolution-free VATT outperforms state-of-the-art ConvNet-based architectures in the downstream tasks. Especially, VATT's vision Transformer achieves the top-1 accuracy of 82.1% on Kinetics-400, 83.6% on Kinetics-600, 72.7% on Kinetics-700, and 41.1% on Moments in Time, new records while avoiding supervised pre-training. Transferring to image classification leads to 78.7% top-1 accuracy on ImageNet compared to 64.7% by training the same Transformer from scratch, showing the generalizability of our model despite the domain gap between videos and images. VATT's audio Transformer also sets a new record on waveform-based audio event recognition by achieving the mAP of 39.4% on AudioSet without any supervised pre-training. VATT's source code is publicly available."
https://openalex.org/W2129947832,Weakly Supervised Learning of Interactions between Humans and Objects,"{'We': [0, 21, 141], 'introduce': [1], 'a': [2, 24, 51, 66, 83, 89, 100, 124, 163], 'weakly': [3], 'supervised': [4], 'approach': [5, 18, 63, 108], 'for': [6, 35], 'learning': [7], 'human': [8, 25, 67, 137], 'actions': [9], 'modeled': [10], 'as': [11], 'interactions': [12], 'between': [13, 135], 'humans': [14, 97], 'and': [15, 29, 38, 113, 138, 162], 'objects.': [16], 'Our': [17, 62], 'is': [19, 47, 123], 'human-centric:': [20], 'first': [22], 'localize': [23], 'in': [26, 99], 'the': [27, 32, 36, 43, 59, 71, 105, 110, 118, 128, 132, 136, 139, 148, 155], 'image': [28], 'then': [30], 'determine': [31], 'object': [33, 112], 'relevant': [34], 'action': [37, 60, 111, 150], 'its': [39, 114], 'spatial': [40, 115, 133], 'relation': [41, 116, 134], 'with': [42, 58], 'human.': [44, 119], 'The': [45], 'model': [46, 72, 126], 'learned': [48], 'automatically': [49], 'from': [50, 96, 153], 'set': [52, 90, 101, 152, 160], 'of': [53, 79, 91, 102, 127], 'still': [54], 'images': [55, 103], 'annotated': [56], 'only': [57], 'label.': [61], 'relies': [64], 'on': [65, 147], 'detector': [68, 84], 'to': [69, 76, 87, 117], 'initialize': [70], 'learning.': [73], 'For': [74], 'robustness': [75], 'various': [77], 'degrees': [78], 'visibility,': [80], 'we': [81], 'build': [82], 'that': [85], 'learns': [86], 'combine': [88], 'existing': [92], 'part': [93], 'detectors.': [94], 'Starting': [95], 'detected': [98], 'depicting': [104], 'action,': [106], 'our': [107], 'determines': [109], 'Its': [120], 'final': [121], 'output': [122], 'probabilistic': [125], 'human-object': [129, 165], 'interaction,': [130], 'i.e.,': [131], 'object.': [140], 'present': [142], 'an': [143], 'extensive': [144], 'experimental': [145], 'evaluation': [146], 'sports': [149], 'data': [151, 159, 167], '[1],': [154], 'PASCAL': [156], 'Action': [157], '2010': [158], '[2],': [161], 'new': [164], 'interaction': [166], 'set.': [168]}",2011,"['Artificial intelligence', 'Computer science', 'Pascal (unit)', 'Relation (database)', 'Object (grammar)', 'Robustness (evolution)', 'Pattern recognition (psychology)', 'Set (abstract data type)', 'Probabilistic logic', 'Computer vision', 'Machine learning', 'Object detection', 'Data mining', 'Programming language', 'Gene', 'Biochemistry', 'Chemistry']","We introduce a weakly supervised approach for learning human actions modeled as interactions between humans and objects. Our approach is human-centric: We first localize a human in the image and then determine the object relevant for the action and its spatial relation with the human. The model is learned automatically from a set of still images annotated only with the action label. Our approach relies on a human detector to initialize the model learning. For robustness to various degrees of visibility, we build a detector that learns to combine a set of existing part detectors. Starting from humans detected in a set of images depicting the action, our approach determines the action object and its spatial relation to the human. Its final output is a probabilistic model of the human-object interaction, i.e., the spatial relation between the human and the object. We present an extensive experimental evaluation on the sports action data set from [1], the PASCAL Action 2010 data set [2], and a new human-object interaction data set."
https://openalex.org/W4367000428,A Cookbook of Self-Supervised Learning,"{'Self-supervised': [0], 'learning,': [1], 'dubbed': [2], 'the': [3, 50, 61, 70, 77, 86, 91, 96, 99, 104], 'dark': [4], 'matter': [5], 'of': [6, 47, 79, 93, 98], 'intelligence,': [7], 'is': [8, 23, 58], 'a': [9, 24, 28, 40, 44, 80], 'promising': [10], 'path': [11], 'to': [12, 31, 53, 59, 63, 84, 89, 107], 'advance': [13], 'machine': [14], 'learning.': [15], 'Yet,': [16], 'much': [17], 'like': [18], 'cooking,': [19], 'training': [20, 39, 54], 'SSL': [21, 41, 66, 74, 111], 'methods': [22], 'delicate': [25], 'art': [26], 'with': [27], 'high': [29], 'barrier': [30, 62], 'entry.': [32], 'While': [33], 'many': [34], 'components': [35], 'are': [36], 'familiar,': [37], 'successfully': [38], 'method': [42], 'involves': [43], 'dizzying': [45], 'set': [46], 'choices': [48], 'from': [49], 'pretext': [51], 'tasks': [52], 'hyper-parameters.': [55], 'Our': [56], 'goal': [57], 'lower': [60], 'entry': [64], 'into': [65], 'research': [67], 'by': [68], 'laying': [69], 'foundations': [71], 'and': [72, 102], 'latest': [73], 'recipes': [75], 'in': [76], 'style': [78], 'cookbook.': [81], 'We': [82], 'hope': [83], 'empower': [85], 'curious': [87], 'researcher': [88], 'navigate': [90], 'terrain': [92], 'methods,': [94], 'understand': [95], 'role': [97], 'various': [100], 'knobs,': [101], 'gain': [103], 'know-how': [105], 'required': [106], 'explore': [108], 'how': [109], 'delicious': [110], 'can': [112], 'be.': [113]}",2023,"['Pretext', 'Computer science', 'Set (abstract data type)', 'Artificial intelligence', 'Style (visual arts)', 'Human–computer interaction', 'Visual arts', 'Art', 'Politics', 'Law', 'Programming language', 'Political science']","Self-supervised learning, dubbed the dark matter of intelligence, is a promising path to advance machine learning. Yet, much like cooking, training SSL methods is a delicate art with a high barrier to entry. While many components are familiar, successfully training a SSL method involves a dizzying set of choices from the pretext tasks to training hyper-parameters. Our goal is to lower the barrier to entry into SSL research by laying the foundations and latest SSL recipes in the style of a cookbook. We hope to empower the curious researcher to navigate the terrain of methods, understand the role of the various knobs, and gain the know-how required to explore how delicious SSL can be."
https://openalex.org/W2103715332,Contextual Bandit Algorithms with Supervised Learning Guarantees,"{'We': [0, 29], 'address': [1], 'the': [2, 12, 50, 141], 'problem': [3], 'of': [4, 55, 97, 99, 119], 'learning': [5, 137], 'in': [6, 52, 77, 124], 'an': [7], 'online,': [8], 'bandit': [9, 143], 'setting': [10], 'where': [11], 'learner': [13], 'must': [14], 'repeatedly': [15], 'select': [16], 'among': [17], '$K$': [18], 'actions,': [19], 'but': [20], 'only': [21], 'receives': [22], 'partial': [23], 'feedback': [24], 'based': [25], 'on': [26, 117], 'its': [27], 'choices.': [28], 'establish': [30], 'two': [31], 'new': [32, 37, 72, 86], 'facts:': [33], 'First,': [34], 'using': [35], 'a': [36, 53, 78, 85, 93, 125], 'algorithm': [38, 73, 87], 'called': [39, 88], 'Exp4.P,': [40], 'we': [41, 83], 'show': [42], 'that': [43, 90], 'it': [44], 'is': [45, 74], 'possible': [46], 'to': [47, 134], 'compete': [48], 'with': [49, 58, 92, 111], 'best': [51], 'set': [54, 96], '$N$': [56], 'experts': [57], 'probability': [59, 112], '$1-δ$': [60], 'while': [61, 102], 'incurring': [62, 103], 'regret': [63, 104], 'at': [64, 105], 'most': [65, 106], '$O(\\sqrt{KT\\ln(N/δ)})$': [66], 'over': [67], '$T$': [68], 'time': [69], 'steps.': [70], 'The': [71], 'tested': [75], 'empirically': [76], 'large-scale,': [79], 'real-world': [80], 'dataset.': [81], 'Second,': [82], 'give': [84], 'VE': [89], 'competes': [91], 'possibly': [94], 'infinite': [95], 'policies': [98], 'VC-dimension': [100], '$d$': [101], '$O(\\sqrt{T(d\\ln(T)': [107], '+': [108], '\\ln': [109], '(1/δ))})$': [110], '$1-δ$.': [113], 'These': [114], 'guarantees': [115, 139], 'improve': [116], 'those': [118], 'all': [120], 'previous': [121], 'algorithms,': [122], 'whether': [123], 'stochastic': [126], 'or': [127], 'adversarial': [128], 'environment,': [129], 'and': [130], 'bring': [131], 'us': [132], 'closer': [133], 'providing': [135], 'supervised': [136], 'type': [138], 'for': [140], 'contextual': [142], 'setting.': [144]}",2010,"['Regret', 'Dimension (graph theory)', 'Set (abstract data type)', 'Computer science', 'Artificial intelligence', 'Algorithm', 'Scale (ratio)', 'Adversarial system', 'Online learning', 'Machine learning', 'Mathematics', 'Combinatorics', 'Programming language', 'Quantum mechanics', 'World Wide Web', 'Physics']","We address the problem of learning in an online, bandit setting where the learner must repeatedly select among $K$ actions, but only receives partial feedback based on its choices. We establish two new facts: First, using a new algorithm called Exp4.P, we show that it is possible to compete with the best in a set of $N$ experts with probability $1-δ$ while incurring regret at most $O(\sqrt{KT\ln(N/δ)})$ over $T$ time steps. The new algorithm is tested empirically in a large-scale, real-world dataset. Second, we give a new algorithm called VE that competes with a possibly infinite set of policies of VC-dimension $d$ while incurring regret at most $O(\sqrt{T(d\ln(T) + \ln (1/δ))})$ with probability $1-δ$. These guarantees improve on those of all previous algorithms, whether in a stochastic or adversarial environment, and bring us closer to providing supervised learning type guarantees for the contextual bandit setting."
https://openalex.org/W2740962769,Weakly-Supervised Learning of Visual Relations,"{'This': [0], 'paper': [1, 92], 'introduces': [2], 'a': [3, 16, 28, 35, 41, 128], 'novel': [4], 'approach': [5], 'for': [6, 78, 108], 'modeling': [7], 'visual': [8, 100, 144, 158], 'relations': [9, 48, 121, 133], 'between\\npairs': [10], 'of': [11, 18, 43, 90, 110, 143], 'objects.': [12, 111], 'We': [13, 147], 'call': [14], 'relation': [15, 62, 145], 'triplet': [17], 'the': [19, 24, 52, 61, 71, 104, 157], 'form': [20], '(subject,': [21, 45], 'predicate,\\nobject)': [22], 'where': [23], 'predicate': [25], 'is': [26, 49], 'typically': [27], 'preposition': [29], '(eg.': [30], ""'under',"": [31], ""'in"": [32], ""front\\nof')"": [33], 'or': [34], 'verb': [36], ""('hold',"": [37], ""'ride')"": [38], 'that': [39, 102, 140], 'links': [40], 'pair': [42], 'objects': [44, 53], 'object).\\nLearning': [46], 'such': [47], 'challenging': [50, 130], 'as': [51], 'have': [54], 'different': [55], 'spatial\\nconfigurations': [56], 'and': [57, 168], 'appearances': [58], 'depending': [59], 'on': [60, 156, 163, 172], 'in': [63, 153], 'which': [64, 82], 'they': [65], 'occur.\\nAnother': [66], 'major': [67], 'challenge': [68], 'comes': [69], 'from': [70], 'difficulty': [72], 'to': [73, 119], 'get': [74], 'annotations,\\nespecially': [75], 'at': [76], 'box-level,': [77], 'all': [79], 'possible': [80], 'triplets,': [81], 'makes': [83], 'both': [84], 'learning\\nand': [85], 'evaluation': [86, 142], 'difficult.': [87], 'The': [88], 'contributions': [89], 'this': [91, 170], 'are': [93], 'threefold.': [94], 'First,\\nwe': [95], 'design': [96], 'strong': [97], 'yet': [98], 'flexible': [99], 'features': [101], 'encode': [103], 'appearance': [105], 'and\\nspatial': [106], 'configuration': [107], 'pairs': [109], 'Second,': [112], 'we': [113, 126], 'propose': [114], 'a\\nweakly-supervised': [115], 'discriminative': [116], 'clustering': [117], 'model': [118, 151], 'learn': [120], 'from\\nimage-level': [122], 'labels': [123], 'only.': [124], 'Third': [125], 'introduce': [127], 'new': [129], 'dataset': [131], 'of\\nunusual': [132], '(UnRel)': [134], 'together': [135], 'with': [136], 'an': [137], 'exhaustive': [138], 'annotation,': [139], 'enables\\naccurate': [141], 'retrieval.': [146], 'show': [148], 'experimentally': [149], 'that\\nour': [150], 'results': [152, 155], 'state-of-the-art': [154], 'relationship\\ndataset': [159], 'significantly': [160], 'improving': [161], 'performance': [162], 'previously': [164], 'unseen': [165], 'relations\\n(zero-shot': [166], 'learning),': [167], 'confirm': [169], 'observation': [171], 'our': [173], 'newly': [174], 'introduced\\nUnRel': [175], 'dataset.\\n': [176]}",2017,"['Computer science', 'Discriminative model', 'Spatial relation', 'Artificial intelligence', 'Predicate (mathematical logic)', 'Object (grammar)', 'Relation (database)', 'Cluster analysis', 'Visualization', 'Natural language processing', 'Pattern recognition (psychology)', 'Machine learning', 'Data mining', 'Programming language']","This paper introduces a novel approach for modeling visual relations between\npairs of objects. We call relation a triplet of the form (subject, predicate,\nobject) where the predicate is typically a preposition (eg. 'under', 'in front\nof') or a verb ('hold', 'ride') that links a pair of objects (subject, object).\nLearning such relations is challenging as the objects have different spatial\nconfigurations and appearances depending on the relation in which they occur.\nAnother major challenge comes from the difficulty to get annotations,\nespecially at box-level, for all possible triplets, which makes both learning\nand evaluation difficult. The contributions of this paper are threefold. First,\nwe design strong yet flexible visual features that encode the appearance and\nspatial configuration for pairs of objects. Second, we propose a\nweakly-supervised discriminative clustering model to learn relations from\nimage-level labels only. Third we introduce a new challenging dataset of\nunusual relations (UnRel) together with an exhaustive annotation, that enables\naccurate evaluation of visual relation retrieval. We show experimentally that\nour model results in state-of-the-art results on the visual relationship\ndataset significantly improving performance on previously unseen relations\n(zero-shot learning), and confirm this observation on our newly introduced\nUnRel dataset.\n"
https://openalex.org/W2990408345,Self-Supervised Learning by Cross-Modal Audio-Video Clustering,"{'Visual': [0], 'and': [1, 47, 96, 111, 125, 148, 155], 'audio': [2, 48, 126], 'modalities': [3], 'are': [4], 'highly': [5], 'correlated,': [6], 'yet': [7], 'they': [8], 'contain': [9], 'different': [10], 'information.': [11], 'Their': [12, 30], 'strong': [13], 'correlation': [14, 95], 'makes': [15], 'it': [16], 'possible': [17], 'to': [18, 51], 'predict': [19], 'the': [20, 25, 82, 93, 97, 100, 140, 158, 165, 179], 'semantics': [21], 'of': [22, 45, 160], 'one': [23, 73], 'from': [24], 'other': [26, 83, 112], 'with': [27, 144], 'good': [28], 'accuracy.': [29], 'intrinsic': [31], 'differences': [32, 98], 'make': [33], 'cross-modal': [34, 88], 'prediction': [35], 'a': [36, 64, 78], 'potentially': [37], 'more': [38], 'rewarding': [39], 'pretext': [40], 'task': [41], 'for': [42, 81, 150, 175], 'self-supervised': [43, 66, 120, 167], 'learning': [44, 168], 'video': [46, 124, 131], 'representations': [49], 'compared': [50], 'within-modality': [52], 'learning.': [53], 'Based': [54], 'on': [55, 122, 134, 146, 153, 178], 'this': [56], 'intuition,': [57], 'we': [58], 'propose': [59], 'Cross-Modal': [60], 'Deep': [61], 'Clustering': [62], '(XDC),': [63], 'novel': [65], 'method': [67, 169], 'that': [68, 106, 170], 'leverages': [69], 'unsupervised': [70], 'clustering': [71, 110], 'in': [72], 'modality': [74, 84], '(e.g.,': [75, 85], 'audio)': [76], 'as': [77], 'supervisory': [79], 'signal': [80], 'video).': [86], 'This': [87], 'supervision': [89], 'helps': [90], 'XDC': [91, 107, 115, 163], 'utilize': [92], 'semantic': [94], 'between': [99], 'two': [101], 'modalities.': [102], 'Our': [103], 'experiments': [104], 'show': [105], 'outperforms': [108, 139, 171], 'single-modality': [109], 'multi-modal': [113], 'variants.': [114], 'achieves': [116], 'state-of-the-art': [117], 'accuracy': [118], 'among': [119], 'methods': [121], 'multiple': [123], 'benchmarks.': [127], 'Most': [128], 'importantly,': [129], 'our': [130, 161], 'model': [132, 142], 'pretrained': [133, 143], 'large-scale': [135, 172], 'unlabeled': [136], 'data': [137], 'significantly': [138], 'same': [141, 180], 'full-supervision': [145], 'ImageNet': [147], 'Kinetics': [149], 'action': [151, 176], 'recognition': [152, 177], 'HMDB51': [154], 'UCF101.': [156], 'To': [157], 'best': [159], 'knowledge,': [162], 'is': [164], 'first': [166], 'fully-supervised': [173], 'pretraining': [174], 'architecture.': [181]}",2019,"['Cluster analysis', 'Computer science', 'Modal', 'Artificial intelligence', 'Speech recognition', 'Chemistry', 'Polymer chemistry']","Visual and audio modalities are highly correlated, yet they contain different information. Their strong correlation makes it possible to predict the semantics of one from the other with good accuracy. Their intrinsic differences make cross-modal prediction a potentially more rewarding pretext task for self-supervised learning of video and audio representations compared to within-modality learning. Based on this intuition, we propose Cross-Modal Deep Clustering (XDC), a novel self-supervised method that leverages unsupervised clustering in one modality (e.g., audio) as a supervisory signal for the other modality (e.g., video). This cross-modal supervision helps XDC utilize the semantic correlation and the differences between the two modalities. Our experiments show that XDC outperforms single-modality clustering and other multi-modal variants. XDC achieves state-of-the-art accuracy among self-supervised methods on multiple video and audio benchmarks. Most importantly, our video model pretrained on large-scale unlabeled data significantly outperforms the same model pretrained with full-supervision on ImageNet and Kinetics for action recognition on HMDB51 and UCF101. To the best of our knowledge, XDC is the first self-supervised learning method that outperforms large-scale fully-supervised pretraining for action recognition on the same architecture."
https://openalex.org/W2787740662,Attention-based Graph Neural Network for Semi-supervised Learning,"{'Recently': [0], 'popularized': [1], 'graph': [2, 112], 'neural': [3, 113], 'networks': [4, 166], 'achieve': [5, 64, 154], 'the': [6, 34, 38, 56, 69, 75, 118, 124, 132, 135, 151, 178], 'state-of-the-art': [7, 70], 'accuracy': [8], 'on': [9, 105, 163, 192], 'a': [10, 29, 42, 50, 65, 96, 110, 144, 159], 'number': [11, 76, 86, 160], 'of': [12, 37, 77, 87, 134, 150, 161], 'standard': [13], 'benchmark': [14, 164], 'datasets': [15], 'for': [16, 82, 98], 'graph-based': [17], 'semi-supervised': [18, 83], 'learning,': [19], 'improving': [20], 'significantly': [21, 73], 'over': [22], 'existing': [23], 'approaches.': [24], 'These': [25], 'architectures': [26], 'alternate': [27], 'between': [28], 'propagation': [30, 102, 125], 'layer': [31], 'that': [32, 49, 53, 115, 130, 170, 185], 'aggregates': [33], 'hidden': [35], 'states': [36], 'local': [39, 148], 'neighborhood': [40, 152], 'and': [41, 122, 146], 'fully-connected': [43, 58, 120], 'layer.': [44], 'Perhaps': [45], 'surprisingly,': [46], 'we': [47, 108, 168, 183], 'show': [48, 184], 'linear': [51], 'model,': [52], 'removes': [54, 116], 'all': [55, 117], 'intermediate': [57, 119], 'layers,': [59, 121], 'is': [60, 80], 'still': [61], 'able': [62], 'to': [63, 68, 142, 153], 'performance': [66], 'comparable': [67], 'models.': [71], 'This': [72, 92], 'reduces': [74], 'parameters,': [78], 'which': [79], 'critical': [81], 'learning': [84], 'where': [85], 'labeled': [88], 'examples': [89], 'are': [90], 'small.': [91], 'in': [93], 'turn': [94], 'allows': [95, 140], 'room': [97], 'designing': [99], 'more': [100, 155], 'innovative': [101], 'layers.': [103], 'Based': [104], 'this': [106], 'insight,': [107], 'propose': [109], 'novel': [111], 'network': [114], 'replaces': [123], 'layers': [126], 'with': [127], 'attention': [128, 138, 179], 'mechanisms': [129], 'respect': [131], 'structure': [133], 'graph.': [136], 'The': [137], 'mechanism': [139], 'us': [141], 'learn': [143], 'dynamic': [145], 'adaptive': [147], 'summary': [149], 'accurate': [156], 'predictions.': [157], 'In': [158], 'experiments': [162], 'citation': [165], 'datasets,': [167], 'demonstrate': [169], 'our': [171, 186], 'approach': [172], 'outperforms': [173], 'competing': [174], 'methods.': [175], 'By': [176], 'examining': [177], 'weights': [180], 'among': [181], 'neighbors,': [182], 'model': [187], 'provides': [188], 'some': [189], 'interesting': [190], 'insights': [191], 'how': [193], 'neighbors': [194], 'influence': [195], 'each': [196], 'other.': [197]}",2018,"['Computer science', 'Benchmark (surveying)', 'Graph', 'Artificial neural network', 'Artificial intelligence', 'Machine learning', 'Theoretical computer science', 'Geography', 'Geodesy']","Recently popularized graph neural networks achieve the state-of-the-art accuracy on a number of standard benchmark datasets for graph-based semi-supervised learning, improving significantly over existing approaches. These architectures alternate between a propagation layer that aggregates the hidden states of the local neighborhood and a fully-connected layer. Perhaps surprisingly, we show that a linear model, that removes all the intermediate fully-connected layers, is still able to achieve a performance comparable to the state-of-the-art models. This significantly reduces the number of parameters, which is critical for semi-supervised learning where number of labeled examples are small. This in turn allows a room for designing more innovative propagation layers. Based on this insight, we propose a novel graph neural network that removes all the intermediate fully-connected layers, and replaces the propagation layers with attention mechanisms that respect the structure of the graph. The attention mechanism allows us to learn a dynamic and adaptive local summary of the neighborhood to achieve more accurate predictions. In a number of experiments on benchmark citation networks datasets, we demonstrate that our approach outperforms competing methods. By examining the attention weights among neighbors, we show that our model provides some interesting insights on how neighbors influence each other."
https://openalex.org/W4367055910,Self-supervised learning for medical image classification: a systematic review and implementation guidelines,"{'Abstract': [0], 'Advancements': [1], 'in': [2, 152], 'deep': [3, 27], 'learning': [4, 28, 49, 88, 110, 155], 'and': [5, 18, 41, 90, 100, 105, 123, 130, 144], 'computer': [6], 'vision': [7], 'provide': [8, 82, 145], 'promising': [9], 'solutions': [10], 'for': [11, 45, 127, 148], 'medical': [12, 46, 62, 74, 112, 160], 'image': [13], 'analysis,': [14], 'potentially': [15], 'improving': [16], 'healthcare': [17], 'patient': [19], 'outcomes.': [20], 'However,': [21], 'the': [22, 51, 58, 138], 'prevailing': [23], 'paradigm': [24], 'of': [25, 33, 60, 85, 95, 119, 141, 159], 'training': [26, 35], 'models': [29, 64], 'requires': [30], 'large': [31], 'quantities': [32], 'labeled': [34], 'data,': [36], 'which': [37], 'is': [38], 'both': [39], 'time-consuming': [40], 'cost-prohibitive': [42], 'to': [43, 53, 57, 68, 111, 156], 'curate': [44], 'images.': [47], 'Self-supervised': [48], 'has': [50], 'potential': [52], 'make': [54], 'significant': [55], 'contributions': [56], 'development': [59, 158], 'robust': [61], 'imaging': [63, 113, 161], 'through': [65], 'its': [66], 'ability': [67], 'learn': [69], 'useful': [70], 'insights': [71], 'from': [72], 'copious': [73], 'datasets': [75], 'without': [76], 'labels.': [77], 'In': [78], 'this': [79, 133], 'review,': [80], 'we': [81, 136], 'consistent': [83], 'descriptions': [84], 'different': [86], 'self-supervised': [87, 109, 154], 'strategies': [89], 'compose': [91], 'a': [92, 117], 'systematic': [93], 'review': [94], 'papers': [96, 126], 'published': [97], 'between': [98], '2012': [99], '2022': [101], 'on': [102], 'PubMed,': [103], 'Scopus,': [104], 'ArXiv': [106], 'that': [107], 'applied': [108], 'classification.': [114], 'We': [115], 'screened': [116], 'total': [118], '412': [120], 'relevant': [121], 'studies': [122], 'included': [124], '79': [125], 'data': [128], 'extraction': [129], 'analysis.': [131], 'With': [132], 'comprehensive': [134], 'effort,': [135], 'synthesize': [137], 'collective': [139], 'knowledge': [140], 'prior': [142], 'work': [143], 'implementation': [146], 'guidelines': [147], 'future': [149], 'researchers': [150], 'interested': [151], 'applying': [153], 'their': [157], 'classification': [162], 'models.': [163]}",2023,"['Artificial intelligence', 'Computer science', 'Machine learning', 'Deep learning', 'Supervised learning', 'Medical imaging', 'Scopus', 'Data science', 'MEDLINE', 'Artificial neural network', 'Law', 'Political science']","Abstract Advancements in deep learning and computer vision provide promising solutions for medical image analysis, potentially improving healthcare and patient outcomes. However, the prevailing paradigm of training deep learning models requires large quantities of labeled training data, which is both time-consuming and cost-prohibitive to curate for medical images. Self-supervised learning has the potential to make significant contributions to the development of robust medical imaging models through its ability to learn useful insights from copious medical datasets without labels. In this review, we provide consistent descriptions of different self-supervised learning strategies and compose a systematic review of papers published between 2012 and 2022 on PubMed, Scopus, and ArXiv that applied self-supervised learning to medical imaging classification. We screened a total of 412 relevant studies and included 79 papers for data extraction and analysis. With this comprehensive effort, we synthesize the collective knowledge of prior work and provide implementation guidelines for future researchers interested in applying self-supervised learning to their development of medical imaging classification models."
https://openalex.org/W2473876819,NLLSS: Predicting Synergistic Drug Combinations Based on Semi-supervised Learning,"{'Fungal': [0], 'infection': [1], 'has': [2], 'become': [3], 'one': [4], 'of': [5, 9, 54, 70, 116, 149, 169], 'the': [6], 'leading': [7], 'causes': [8], 'hospital-acquired': [10], 'infections': [11], 'with': [12, 79], 'high': [13], 'mortality': [14], 'rates.': [15], 'Furthermore,': [16, 89], 'drug': [17, 25, 34, 38, 46, 56, 71, 102, 110, 122, 127, 137, 174], 'resistance': [18], 'is': [19], 'common': [20], 'for': [21, 58, 160], 'fungus-causing': [22, 59], 'diseases.': [23], 'Synergistic': [24, 101], 'combinations': [26, 39, 57, 111, 138], 'could': [27], 'provide': [28], 'an': [29, 178], 'effective': [30], 'strategy': [31, 180], 'to': [32, 48, 106, 133, 165, 181], 'overcome': [33], 'resistance.': [35], 'Meanwhile,': [36], 'synergistic': [37, 55, 77, 109, 121, 136, 173, 184], 'can': [40], 'increase': [41], 'treatment': [42], 'efficacy': [43], 'and': [44, 86, 126, 139, 152], 'decrease': [45], 'dosage': [47], 'avoid': [49], 'toxicity.': [50], 'Therefore,': [51], 'computational': [52], 'prediction': [53, 104], 'diseases': [60], 'becomes': [61], 'attractive.': [62], 'In': [63], 'this': [64], 'study,': [65], 'we': [66, 90, 156], 'proposed': [67], 'similar': [68, 80, 85], 'nature': [69], 'combinations:': [72], 'principal': [73], 'drugs': [74, 82], 'which': [75], 'obtain': [76], 'effect': [78], 'adjuvant': [81], 'are': [83], 'often': [84], 'vice': [87], 'versa.': [88], 'developed': [91], 'a': [92], 'novel': [93], 'algorithm': [94], 'termed': [95], 'Network-based': [96], 'Laplacian': [97], 'regularized': [98], 'Least': [99], 'Square': [100], 'combination': [103], '(NLLSS)': [105], 'predict': [107, 134], 'potential': [108, 183], 'by': [112], 'integrating': [113], 'different': [114], 'kinds': [115], 'information': [117], 'such': [118], 'as': [119], 'known': [120], 'combinations,': [123], 'drug-target': [124], 'interactions,': [125], 'chemical': [128], 'structures.': [129], 'We': [130], 'applied': [131], 'NLLSS': [132, 176], 'antifungal': [135, 172, 185], 'showed': [140], 'that': [141], 'it': [142], 'achieved': [143], 'excellent': [144], 'performance': [145], 'both': [146], 'in': [147], 'terms': [148], 'cross': [150], 'validation': [151], 'independent': [153], 'prediction.': [154], 'Finally,': [155], 'performed': [157], 'biological': [158], 'experiments': [159], 'fungal': [161], 'pathogen': [162], 'Candida': [163], 'albicans': [164], 'confirm': [166], '7': [167], 'out': [168], '13': [170], 'predicted': [171], 'combinations.': [175, 186], 'provides': [177], 'efficient': [179], 'identify': [182]}",2016,"['Drug', 'Antifungal drug', 'Drug resistance', 'Candida albicans', 'Antifungal', 'Antifungal drugs', 'Computational biology', 'Pharmacology', 'Biology', 'Microbiology']","Fungal infection has become one of the leading causes of hospital-acquired infections with high mortality rates. Furthermore, drug resistance is common for fungus-causing diseases. Synergistic drug combinations could provide an effective strategy to overcome drug resistance. Meanwhile, synergistic drug combinations can increase treatment efficacy and decrease drug dosage to avoid toxicity. Therefore, computational prediction of synergistic drug combinations for fungus-causing diseases becomes attractive. In this study, we proposed similar nature of drug combinations: principal drugs which obtain synergistic effect with similar adjuvant drugs are often similar and vice versa. Furthermore, we developed a novel algorithm termed Network-based Laplacian regularized Least Square Synergistic drug combination prediction (NLLSS) to predict potential synergistic drug combinations by integrating different kinds of information such as known synergistic drug combinations, drug-target interactions, and drug chemical structures. We applied NLLSS to predict antifungal synergistic drug combinations and showed that it achieved excellent performance both in terms of cross validation and independent prediction. Finally, we performed biological experiments for fungal pathogen Candida albicans to confirm 7 out of 13 predicted antifungal synergistic drug combinations. NLLSS provides an efficient strategy to identify potential synergistic antifungal combinations."
https://openalex.org/W2564414379,Visualizing the Effects of Predictor Variables in Black Box Supervised Learning Models,"{'When': [0], 'fitting': [1], 'black': [2], 'box': [3], 'supervised': [4], 'learning': [5], 'models': [6], '(e.g.,': [7], 'complex': [8], 'trees,': [9, 13], 'neural': [10], 'networks,': [11], 'boosted': [12], 'random': [14], 'forests,': [15], 'nearest': [16], 'neighbors,': [17], 'local': [18, 145], 'kernel-weighted': [19], 'methods,': [20], 'etc.),': [21], 'visualizing': [22], 'the': [23, 27, 45, 60, 82, 91, 95, 101, 123, 129, 151, 182], 'main': [24], 'effects': [25, 35, 146], 'of': [26, 81, 94, 154], 'individual': [28], 'predictor': [29, 61, 85], 'variables': [30, 62], 'and': [31, 39, 119, 156, 173], 'their': [32, 161], 'low-order': [33], 'interaction': [34], 'is': [36, 68], 'often': [37], 'important,': [38], 'partial': [40], 'dependence': [41], '(PD)': [42], 'plots': [43, 54, 78, 103, 107, 168, 188], 'are': [44, 63, 88, 125, 178, 189], 'most': [46], 'popular': [47], 'approach': [48, 140], 'for': [49], 'accomplishing': [50], 'this.': [51], 'However,': [52], 'PD': [53, 77, 102, 155, 175, 195], 'involve': [55], 'a': [56, 137], 'serious': [57], 'pitfall': [58], 'if': [59], 'far': [64, 89, 190], 'from': [65], 'independent,': [66], 'which': [67, 98, 149], 'quite': [69], 'common': [70], 'with': [71], 'large': [72], 'observational': [73], 'data': [74], 'sets.': [75], 'Namely,': [76], 'require': [79, 112, 171], 'extrapolation': [80], 'response': [83], 'at': [84], 'values': [86], 'that': [87, 141], 'outside': [90], 'multivariate': [92], 'envelope': [93], 'training': [96], 'data,': [97], 'can': [99], 'render': [100], 'unreliable.': [104], 'Although': [105], 'marginal': [106], '(M': [108], 'plots)': [109], 'do': [110, 169], 'not': [111, 170, 179], 'such': [113], 'extrapolation,': [114], 'they': [115, 177], 'produce': [116], 'substantially': [117], 'biased': [118, 180], 'misleading': [120], 'results': [121], 'when': [122], 'predictors': [124], 'dependent,': [126], 'analogous': [127], 'to': [128], 'omitted': [130, 183], 'variable': [131, 184], 'bias': [132], 'in': [133], 'regression.': [134], 'We': [135], 'present': [136], 'new': [138], 'visualization': [139], 'we': [142], 'term': [143], 'accumulated': [144], '(ALE)': [147], 'plots,': [148, 158, 166, 176], 'inherits': [150], 'desirable': [152], 'characteristics': [153], 'M': [157, 165], 'without': [159], 'inheriting': [160], 'preceding': [162], 'shortcomings.': [163], 'Like': [164], 'ALE': [167, 187], 'extrapolation;': [172], 'like': [174], 'by': [181], 'phenomenon.': [185], 'Moreover,': [186], 'less': [191], 'computationally': [192], 'expensive': [193], 'than': [194], 'plots.': [196]}",2016,"['Extrapolation', 'Random forest', 'Regression', 'Variable (mathematics)', 'Multivariate statistics', 'Regression analysis', 'Scatter plot', 'Artificial neural network', 'Variables', 'Omitted-variable bias', 'Statistics', 'Computer science', 'Term (time)', 'Machine learning', 'Mathematics', 'Artificial intelligence', 'Econometrics', 'Physics', 'Quantum mechanics', 'Mathematical analysis']","When fitting black box supervised learning models (e.g., complex trees, neural networks, boosted trees, random forests, nearest neighbors, local kernel-weighted methods, etc.), visualizing the main effects of the individual predictor variables and their low-order interaction effects is often important, and partial dependence (PD) plots are the most popular approach for accomplishing this. However, PD plots involve a serious pitfall if the predictor variables are far from independent, which is quite common with large observational data sets. Namely, PD plots require extrapolation of the response at predictor values that are far outside the multivariate envelope of the training data, which can render the PD plots unreliable. Although marginal plots (M plots) do not require such extrapolation, they produce substantially biased and misleading results when the predictors are dependent, analogous to the omitted variable bias in regression. We present a new visualization approach that we term accumulated local effects (ALE) plots, which inherits the desirable characteristics of PD and M plots, without inheriting their preceding shortcomings. Like M plots, ALE plots do not require extrapolation; and like PD plots, they are not biased by the omitted variable phenomenon. Moreover, ALE plots are far less computationally expensive than PD plots."
https://openalex.org/W3201675569,Data Analytics for the Identification of Fake Reviews Using Supervised Learning,"{'Fake': [0], 'reviews,': [1], 'also': [2], 'known': [3], 'as': [4, 30, 178], 'deceptive': [5], 'opinions,': [6], 'are': [7], 'used': [8, 134, 253], 'to': [9, 21, 40, 101, 175], 'mislead': [10], 'people': [11], 'and': [12, 32, 43, 91, 120, 143, 147, 158, 163, 194, 197, 226, 234, 241, 257], 'have': [13], 'gained': [14], 'more': [15], 'importance': [16], 'recently.': [17], 'This': [18], 'is': [19, 74], 'due': [20], 'the': [22, 46, 57, 63, 71, 93, 117, 125, 172, 183, 204, 254, 258, 262], 'rapid': [23], 'increase': [24], 'in': [25, 131, 265], 'online': [26], 'marketing': [27], 'transactions,': [28], 'such': [29], 'selling': [31], 'purchasing.': [33], 'E-commerce': [34], 'provides': [35], 'a': [36, 67, 135, 148, 200], 'facility': [37], 'for': [38, 141, 155], 'customers': [39, 53], 'post': [41], 'reviews': [42, 59, 81, 110], 'comment': [44], 'about': [45], 'product': [47], 'or': [48, 60, 180], 'service': [49], 'when': [50], 'purchased.': [51], 'New': [52], 'usually': [54], 'go': [55], 'through': [56], 'posted': [58], 'comments': [61], 'on': [62, 111, 199, 238], 'website': [64], 'before': [65], 'making': [66], 'purchase': [68], 'decision.': [69], 'However,': [70, 182], 'current': [72], 'challenge': [73], 'how': [75], 'new': [76], 'individuals': [77], 'can': [78, 107], 'distinguish': [79], 'truthful': [80], 'from': [82, 203], 'fake': [83, 109, 137, 179], 'ones,': [84], 'which': [85], 'later': [86], 'deceives': [87], 'customers,': [88], 'inflicts': [89], 'losses,': [90], 'tarnishes': [92], 'reputation': [94], 'of': [95, 116, 166, 211, 267], 'companies.': [96], 'The': [97, 127, 208, 244], 'present': [98], 'paper': [99], 'attempts': [100], 'develop': [102], 'an': [103], 'intelligent': [104], 'system': [105], 'that': [106, 215, 252], 'detect': [108], 'e-commerce': [112], 'platforms': [113], 'using': [114, 188], 'n-grams': [115, 165], 'review': [118, 139, 167], 'text': [119], 'sentiment': [121], 'scores': [122], 'given': [123], 'by': [124], 'reviewer.': [126], 'proposed': [128, 259], 'methodology': [129], 'adopted': [130], 'this': [132], 'study': [133], 'standard': [136], 'hotel': [138], 'dataset': [140, 201], 'experimenting': [142], 'data': [144], 'preprocessing': [145], 'methods': [146, 260, 264], 'term': [149], 'frequency-Inverse': [150], 'document': [151], 'frequency': [152], '(TF-IDF)': [153], 'approach': [154], 'extracting': [156], 'features': [157], 'their': [159], 'representation.': [160], 'For': [161], 'detection': [162], 'classification,': [164], 'texts': [168], 'were': [169, 185, 195, 247], 'inputted': [170], 'into': [171], 'constructed': [173], 'models': [174], 'be': [176], 'classified': [177], 'truthful.': [181], 'experiments': [184, 213], 'carried': [186], 'out': [187], 'four': [189], 'different': [190], 'supervised': [191], 'machine-learning': [192], 'techniques': [193], 'trained': [196], 'tested': [198], 'collected': [202], 'Trip': [205], 'Advisor': [206], 'website.': [207], 'classification': [209], 'results': [210, 246], 'these': [212], 'showed': [214], 'naïve': [216], 'Bayes': [217], '(NB),': [218], 'support': [219], 'vector': [220], 'machine': [221], '(SVM),': [222], 'adaptive': [223], 'boosting': [224], '(AB),': [225], 'random': [227], 'forest': [228], '(RF)': [229], 'received': [230], '88%,': [231], '93%,': [232], '94%,': [233], '95%,': [235], 'respectively,': [236], 'based': [237], 'testing': [239], 'accuracy': [240], 'tje': [242], 'F1-score.': [243], 'obtained': [245], 'compared': [248], 'with': [249], 'existing': [250], 'works': [251], 'same': [255], 'dataset,': [256], 'outperformed': [261], 'comparable': [263], 'terms': [266], 'accuracy.': [268]}",2021,"['Naive Bayes classifier', 'Computer science', 'Support vector machine', 'Machine learning', 'Artificial intelligence', 'Purchasing', 'Reputation', 'Random forest', 'Sentiment analysis', 'Identification (biology)', 'Preprocessor', 'Product (mathematics)', 'Misinformation', 'Marketing', 'Computer security', 'Social science', 'Mathematics', 'Business', 'Sociology', 'Geometry', 'Botany', 'Biology']","Fake reviews, also known as deceptive opinions, are used to mislead people and have gained more importance recently. This is due to the rapid increase in online marketing transactions, such as selling and purchasing. E-commerce provides a facility for customers to post reviews and comment about the product or service when purchased. New customers usually go through the posted reviews or comments on the website before making a purchase decision. However, the current challenge is how new individuals can distinguish truthful reviews from fake ones, which later deceives customers, inflicts losses, and tarnishes the reputation of companies. The present paper attempts to develop an intelligent system that can detect fake reviews on e-commerce platforms using n-grams of the review text and sentiment scores given by the reviewer. The proposed methodology adopted in this study used a standard fake hotel review dataset for experimenting and data preprocessing methods and a term frequency-Inverse document frequency (TF-IDF) approach for extracting features and their representation. For detection and classification, n-grams of review texts were inputted into the constructed models to be classified as fake or truthful. However, the experiments were carried out using four different supervised machine-learning techniques and were trained and tested on a dataset collected from the Trip Advisor website. The classification results of these experiments showed that naïve Bayes (NB), support vector machine (SVM), adaptive boosting (AB), and random forest (RF) received 88%, 93%, 94%, and 95%, respectively, based on testing accuracy and tje F1-score. The obtained results were compared with existing works that used the same dataset, and the proposed methods outperformed the comparable methods in terms of accuracy."
https://openalex.org/W3208338073,Self-supervised Learning for Large-scale Item Recommendations,"{'Large': [0], 'scale': [1], 'recommender': [2, 34], 'models': [3], 'find': [4], 'most': [5], 'relevant': [6], 'items': [7, 48, 59, 86], 'from': [8, 49], 'huge': [9], 'catalogs,': [10], 'and': [11, 20, 47], 'they': [12], 'play': [13], 'a': [14, 32, 37, 69, 76], 'critical': [15], 'role': [16], 'in': [17, 60], 'modern': [18], 'search': [19], 'recommendation': [21], 'systems.': [22], 'To': [23], 'model': [24, 35], 'the': [25, 61, 81], 'input': [26], 'space': [27, 40], 'with': [28, 54], 'large-vocab': [29], 'categorical': [30], 'features,': [31], 'typical': [33], 'learns': [36], 'joint': [38], 'embedding': [39], 'through': [41], 'neural': [42], 'networks': [43], 'for': [44, 68, 84], 'both': [45], 'queries': [46], 'user': [50], 'feedback': [51, 67, 82], 'data.': [52], 'However,': [53], 'millions': [55], 'to': [56, 65], 'billions': [57], 'of': [58, 73], 'corpus,': [62], 'users': [63], 'tend': [64], 'provide': [66], 'very': [70], 'small': [71], 'set': [72], 'them,': [74], 'causing': [75], 'power-law': [77], 'distribution.': [78], 'This': [79], 'makes': [80], 'data': [83], 'long-tail': [85], 'extremely': [87], 'sparse.': [88]}",2021,"['Recommender system', 'Categorical variable', 'Computer science', 'Space (punctuation)', 'Set (abstract data type)', 'Embedding', 'Scale (ratio)', 'Machine learning', 'Data set', 'Information retrieval', 'Collaborative filtering', 'Artificial intelligence', 'Data mining', 'Quantum mechanics', 'Programming language', 'Physics', 'Operating system']","Large scale recommender models find most relevant items from huge catalogs, and they play a critical role in modern search and recommendation systems. To model the input space with large-vocab categorical features, a typical recommender model learns a joint embedding space through neural networks for both queries and items from user feedback data. However, with millions to billions of items in the corpus, users tend to provide feedback for a very small set of them, causing a power-law distribution. This makes the feedback data for long-tail items extremely sparse."
https://openalex.org/W2606711863,Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning,"{'We': [0], 'propose': [1], 'a': [2, 11, 133], 'new': [3, 12], 'regularization': [4], 'method': [5, 49, 80], 'based': [6, 139], 'on': [7, 128, 140, 154], 'virtual': [8, 81, 100], 'adversarial': [9, 25, 46, 52, 82, 101], 'loss:': [10], 'measure': [13], 'of': [14, 17, 32, 88, 99, 112, 136], 'local': [15, 43], 'smoothness': [16], 'the': [18, 30, 33, 51, 65, 71, 96, 137, 141], 'conditional': [19, 34], 'label': [20, 35, 55], 'distribution': [21, 36], 'given': [22], 'input.': [23], 'Virtual': [24], 'loss': [26, 102], 'is': [27, 58, 90], 'defined': [28], 'as': [29], 'robustness': [31], 'around': [37], 'each': [38], 'input': [39], 'data': [40], 'point': [41], 'against': [42], 'perturbation.': [44], 'Unlike': [45], 'training,': [47], 'our': [48, 79, 117, 145], 'defines': [50], 'direction': [53], 'without': [54], 'information': [56], 'and': [57, 114, 124, 156], 'hence': [59], 'applicable': [60], 'to': [61, 122], 'semi-supervised': [62, 125, 151], 'learning.': [63], 'Because': [64], 'directions': [66], 'in': [67], 'which': [68], 'we': [69, 77, 119], 'smooth': [70], 'model': [72], 'are': [73], 'only': [74], '""virtually""': [75], 'adversarial,': [76], 'call': [78], 'training': [83], '(VAT).': [84], 'The': [85], 'computational': [86], 'cost': [87], 'VAT': [89, 121, 146], 'relatively': [91], 'low.': [92], 'For': [93], 'neural': [94], 'networks,': [95], 'approximated': [97], 'gradient': [98], 'can': [103], 'be': [104], 'computed': [105], 'with': [106], 'no': [107], 'more': [108], 'than': [109], 'two': [110], 'pairs': [111], 'forward-': [113], 'back-propagations.': [115], 'In': [116], 'experiments,': [118], 'applied': [120], 'supervised': [123], 'learning': [126, 152], 'tasks': [127, 153], 'multiple': [129], 'benchmark': [130], 'datasets.': [131], 'With': [132], 'simple': [134], 'enhancement': [135], 'algorithm': [138], 'entropy': [142], 'minimization': [143], 'principle,': [144], 'achieves': [147], 'state-of-the-art': [148], 'performance': [149], 'for': [150], 'SVHN': [155], 'CIFAR-10.': [157]}",2017,"['Adversarial system', 'Computer science', 'Artificial intelligence', 'Machine learning', 'Regularization (linguistics)', 'Cross entropy', 'Entropy (arrow of time)', 'Minification', 'Supervised learning', 'Deep neural networks', 'Mathematical optimization', 'Deep learning', 'Artificial neural network', 'Pattern recognition (psychology)', 'Mathematics', 'Quantum mechanics', 'Programming language', 'Physics']","We propose a new regularization method based on virtual adversarial loss: a new measure of local smoothness of the conditional label distribution given input. Virtual adversarial loss is defined as the robustness of the conditional label distribution around each input data point against local perturbation. Unlike adversarial training, our method defines the adversarial direction without label information and is hence applicable to semi-supervised learning. Because the directions in which we smooth the model are only ""virtually"" adversarial, we call our method virtual adversarial training (VAT). The computational cost of VAT is relatively low. For neural networks, the approximated gradient of virtual adversarial loss can be computed with no more than two pairs of forward- and back-propagations. In our experiments, we applied VAT to supervised and semi-supervised learning tasks on multiple benchmark datasets. With a simple enhancement of the algorithm based on the entropy minimization principle, our VAT achieves state-of-the-art performance for semi-supervised learning tasks on SVHN and CIFAR-10."
https://openalex.org/W2794523151,Realistic Evaluation of Deep Semi-Supervised Learning Algorithms,"{'Semi-supervised': [0], 'learning': [1], '(SSL)': [2], 'provides': [3], 'a': [4, 55, 67], 'powerful': [5], 'framework': [6], 'for': [7], 'leveraging': [8], 'unlabeled': [9, 88, 105, 115], 'data': [10, 89], 'when': [11, 113], 'labels': [12], 'are': [13], 'limited': [14], 'or': [15], 'expensive': [16], 'to': [17, 41, 72, 99], 'obtain.': [18], 'SSL': [19, 61, 94, 123], 'algorithms': [20, 47], 'based': [21], 'on': [22, 30], 'deep': [23], 'neural': [24], 'networks': [25], 'have': [26], 'recently': [27], 'proven': [28], 'successful': [29], 'standard': [31], 'benchmark': [32], 'tasks.': [33], 'However,': [34], 'we': [35, 63, 128], 'argue': [36], 'that': [37, 45, 78, 93, 108], 'these': [38, 46, 74], 'benchmarks': [39], 'fail': [40], 'address': [42, 73], 'many': [43], 'issues': [44], 'would': [48], 'face': [49], 'in': [50, 66, 97], 'real-world': [51, 126], 'applications.': [52], 'After': [53], 'creating': [54], 'unified': [56, 131], 'reimplementation': [57], 'of': [58, 69, 81, 102], 'various': [59], 'widely-used': [60], 'techniques,': [62], 'test': [64], 'them': [65], 'suite': [68], 'experiments': [70], 'designed': [71], 'issues.': [75], 'We': [76], 'find': [77], 'the': [79, 100, 114], 'performance': [80, 109], 'simple': [82], 'baselines': [83], 'which': [84], 'do': [85], 'not': [86], 'use': [87], 'is': [90], 'often': [91], 'underreported,': [92], 'methods': [95], 'differ': [96], 'sensitivity': [98], 'amount': [101], 'labeled': [103], 'and': [104, 107, 133], 'data,': [106], 'can': [110], 'degrade': [111], 'substantially': [112], 'dataset': [116], 'contains': [117], 'out-of-class': [118], 'examples.': [119], 'To': [120], 'help': [121], 'guide': [122], 'research': [124], 'towards': [125], 'applicability,': [127], 'make': [129], 'our': [130], 'reimplemention': [132], 'evaluation': [134], 'platform': [135], 'publicly': [136], 'available.': [137]}",2018,"['Computer science', 'Suite', 'Benchmark (surveying)', 'Machine learning', 'Artificial intelligence', 'Labeled data', 'Test suite', 'Class (philosophy)', 'Simple (philosophy)', 'Deep learning', 'Data mining', 'Test case', 'Geography', 'Geodesy', 'Epistemology', 'History', 'Archaeology', 'Philosophy', 'Regression analysis']","Semi-supervised learning (SSL) provides a powerful framework for leveraging unlabeled data when labels are limited or expensive to obtain. SSL algorithms based on deep neural networks have recently proven successful on standard benchmark tasks. However, we argue that these benchmarks fail to address many issues that these algorithms would face in real-world applications. After creating a unified reimplementation of various widely-used SSL techniques, we test them in a suite of experiments designed to address these issues. We find that the performance of simple baselines which do not use unlabeled data is often underreported, that SSL methods differ in sensitivity to the amount of labeled and unlabeled data, and that performance can degrade substantially when the unlabeled dataset contains out-of-class examples. To help guide SSL research towards real-world applicability, we make our unified reimplemention and evaluation platform publicly available."
https://openalex.org/W2172251087,A high-performance semi-supervised learning method for text chunking,"{'In': [0], 'machine': [1], 'learning,': [2], 'whether': [3], 'one': [4], 'can': [5, 92, 96], 'build': [6], 'a': [7, 22, 42, 48], 'more': [8], 'accurate': [9], 'classifier': [10], 'by': [11, 66, 87], 'using': [12], 'unlabeled': [13, 77], 'data': [14], '(semi-supervised': [15], 'learning)': [16], 'is': [17, 35, 58], 'an': [18], 'important': [19], 'issue.': [20], 'Although': [21], 'number': [23], 'of': [24, 70], 'semi-supervised': [25, 44], 'methods': [26], 'have': [27], 'been': [28], 'proposed,': [29], 'their': [30], 'effectiveness': [31], 'on': [32, 76, 103, 117], 'NLP': [33], 'tasks': [34], 'not': [36], 'always': [37], 'clear.': [38], 'This': [39], 'paper': [40], 'presents': [41], 'novel': [43], 'method': [45, 108], 'that': [46], 'employs': [47], 'learning': [49, 67], 'paradigm': [50], 'which': [51, 95], 'we': [52], 'call': [53], 'structural': [54], 'learning.': [55], 'The': [56, 107], 'idea': [57], 'to': [59, 100], 'find': [60], '""what': [61], 'good': [62], 'classifiers': [63], 'are': [64], 'like""': [65], 'from': [68], 'thousands': [69], 'automatically': [71], 'generated': [72], 'auxiliary': [73], 'classification': [74, 90], 'problems': [75, 91], 'data.': [78], 'By': [79], 'doing': [80], 'so,': [81], 'the': [82, 88, 104, 113], 'common': [83], 'predictive': [84], 'structure': [85], 'shared': [86], 'multiple': [89], 'be': [93, 98], 'discovered,': [94], 'then': [97], 'used': [99], 'improve': [101], 'performance': [102, 110], 'target': [105], 'problem.': [106], 'produces': [109], 'higher': [111], 'than': [112], 'previous': [114], 'best': [115], 'results': [116], ""CoNLL'00"": [118], 'syntactic': [119], 'chunking': [120, 125], 'and': [121, 127], ""CoNLL'03"": [122], 'named': [123], 'entity': [124], '(English': [126], 'German).': [128]}",2005,"['Chunking (psychology)', 'Computer science', 'Artificial intelligence', 'Semi-supervised learning', 'Classifier (UML)', 'Machine learning', 'Labeled data', 'Supervised learning', 'Natural language processing', 'German', 'Artificial neural network', 'History', 'Archaeology']","In machine learning, whether one can build a more accurate classifier by using unlabeled data (semi-supervised learning) is an important issue. Although a number of semi-supervised methods have been proposed, their effectiveness on NLP tasks is not always clear. This paper presents a novel semi-supervised method that employs a learning paradigm which we call structural learning. The idea is to find ""what good classifiers are like"" by learning from thousands of automatically generated auxiliary classification problems on unlabeled data. By doing so, the common predictive structure shared by the multiple classification problems can be discovered, which can then be used to improve performance on the target problem. The method produces performance higher than the previous best results on CoNLL'00 syntactic chunking and CoNLL'03 named entity chunking (English and German)."
https://openalex.org/W3119308075,"VoxPopuli: A Large-Scale Multilingual Speech Corpus for Representation Learning, Semi-Supervised Learning and Interpretation","{'International': [0], 'audience': [1]}",2021,"['Computer science', 'Natural language processing', 'Interpretation (philosophy)', 'Representation (politics)', 'Artificial intelligence', 'Computational linguistics', 'Scale (ratio)', 'Linguistics', 'Joint (building)', 'Corpus linguistics', 'Association (psychology)', 'Volume (thermodynamics)', 'Speech recognition', 'Programming language', 'Engineering', 'Philosophy', 'Geography', 'Epistemology', 'Cartography', 'Politics', 'Architectural engineering', 'Political science', 'Physics', 'Quantum mechanics', 'Law']",International audience
https://openalex.org/W1543911290,Safe Feature Elimination in Sparse Supervised Learning,"{'We': [0, 124], 'investigate': [1], 'fast': [2], 'methods': [3, 43], 'that': [4, 51, 181], 'allow': [5], 'to': [6, 25, 36, 55, 66, 91, 128, 148, 163, 173], 'quickly': [7], 'eliminate': [8, 49], 'variables': [9, 34], '(features)': [10], 'in': [11, 30, 97, 132, 144], 'supervised': [12, 39, 100], 'learning': [13, 40, 61, 101, 151], 'problems': [14], 'involving': [15], 'a': [16, 21, 26, 67, 137], 'convex': [17], 'loss': [18], 'function': [19], 'and': [20, 79, 135], '$l_1$-norm': [22], 'penalty,': [23], 'leading': [24], 'potentially': [27], 'substantial': [28], 'reduction': [29, 139], 'the': [31, 38, 60, 84, 92, 98, 107, 112, 141, 150, 166], 'number': [32, 108, 113], 'of': [33, 70, 83, 109, 114, 140, 168, 179, 184], 'prior': [35], 'running': [37], 'algorithm.': [41], 'The': [42, 81], 'are': [44, 52, 158], 'not': [45], 'heuristic:': [46], 'they': [47], 'only': [48], 'features': [50, 110], '{\\em': [53], 'guaranteed}': [54], 'be': [56], 'absent': [57], 'after': [58], 'solving': [59], 'problem.': [62], 'Our': [63, 160], 'framework': [64], 'applies': [65], 'large': [68], 'class': [69], 'problems,': [71], 'including': [72], 'support': [73], 'vector': [74], 'machine': [75], 'classification,': [76], 'logistic': [77], 'regression': [78], 'least-squares.': [80], 'complexity': [82], 'feature': [85], 'elimination': [86], 'step': [87], 'is': [88, 122], 'negligible': [89], 'compared': [90], 'typical': [93], 'computational': [94, 145], 'effort': [95, 146], 'involved': [96], 'sparse': [99, 156], 'problem:': [102], 'it': [103], 'grows': [104], 'linearly': [105], 'with': [106, 116], 'times': [111], 'examples,': [115], 'much': [117], 'better': [118], 'count': [119], 'if': [120], 'data': [121, 129, 177], 'sparse.': [123], 'apply': [125], 'our': [126], 'method': [127, 161], 'sets': [130, 178], 'arising': [131], 'text': [133], 'classification': [134], 'observe': [136], 'dramatic': [138], 'dimensionality,': [142], 'hence': [143], 'required': [147], 'solve': [149], 'problem,': [152], 'especially': [153], 'when': [154], 'very': [155], 'classifiers': [157], 'sought.': [159], 'allows': [162], 'immediately': [164], 'extend': [165], 'scope': [167], 'existing': [169], 'algorithms,': [170], 'allowing': [171], 'us': [172], 'run': [174], 'them': [175], 'on': [176], 'sizes': [180], 'were': [182], 'out': [183], 'their': [185], 'reach': [186], 'before.': [187]}",2010,"['Computer science', 'Machine learning', 'Artificial intelligence', 'Supervised learning', 'Semi-supervised learning', 'Dimensionality reduction', 'Heuristic', 'Feature vector', 'Curse of dimensionality', 'Support vector machine', 'Feature (linguistics)', 'Pattern recognition (psychology)', 'Artificial neural network', 'Philosophy', 'Linguistics']","We investigate fast methods that allow to quickly eliminate variables (features) in supervised learning problems involving a convex loss function and a $l_1$-norm penalty, leading to a potentially substantial reduction in the number of variables prior to running the supervised learning algorithm. The methods are not heuristic: they only eliminate features that are {\em guaranteed} to be absent after solving the learning problem. Our framework applies to a large class of problems, including support vector machine classification, logistic regression and least-squares. The complexity of the feature elimination step is negligible compared to the typical computational effort involved in the sparse supervised learning problem: it grows linearly with the number of features times the number of examples, with much better count if data is sparse. We apply our method to data sets arising in text classification and observe a dramatic reduction of the dimensionality, hence in computational effort required to solve the learning problem, especially when very sparse classifiers are sought. Our method allows to immediately extend the scope of existing algorithms, allowing us to run them on data sets of sizes that were out of their reach before."
https://openalex.org/W3026732421,CERT: Contrastive Self-supervised Learning for Language Understanding,"{'Pretrained': [0], 'language': [1, 12, 53, 77, 112], 'models': [2, 55], 'such': [3], 'as': [4], 'BERT,': [5], 'GPT': [6], 'have': [7], 'shown': [8], 'great': [9], 'effectiveness': [10], 'in': [11, 18], 'understanding.': [13], 'The': [14], 'auxiliary': [15], 'predictive': [16], 'tasks': [17], 'existing': [19], 'pretraining': [20], 'approaches': [21], 'are': [22], 'mostly': [23], 'defined': [24], 'on': [25, 110], 'tokens,': [26], 'thus': [27], 'may': [28], 'not': [29], 'be': [30, 99], 'able': [31], 'to': [32, 95], 'capture': [33], 'sentence-level': [34], 'semantics': [35], 'very': [36], 'well.': [37], 'To': [38], 'address': [39], 'this': [40], 'issue,': [41], 'we': [42], 'propose': [43], 'CERT:': [44], 'Contrastive': [45], 'self-supervised': [46, 58], 'Encoder': [47], 'Representations': [48], 'from': [49, 88], 'Transformers,': [50], 'which': [51], 'pretrains': [52], 'representation': [54], 'using': [56, 70], 'contrastive': [57], 'learning': [59], 'at': [60], 'the': [61, 89], 'sentence': [62], 'level.': [63], 'CERT': [64, 92, 109, 119], 'creates': [65], 'augmentations': [66], 'of': [67], 'original': [68], 'sentences': [69, 86], 'back-translation.': [71], 'Then': [72], 'it': [73], 'finetunes': [74], 'a': [75], 'pretrained': [76], 'encoder': [78], '(e.g.,': [79], 'BERT)': [80], 'by': [81], 'predicting': [82], 'whether': [83], 'two': [84], 'augmented': [85], 'originate': [87], 'same': [90], 'sentence.': [91], 'is': [93], 'simple': [94], 'use': [96], 'and': [97, 117], 'can': [98], 'flexibly': [100], 'plugged': [101], 'into': [102], 'any': [103], 'pretraining-finetuning': [104], 'NLP': [105], 'pipeline.': [106], 'We': [107], 'evaluate': [108], 'three': [111], 'understanding': [113], 'tasks:': [114], 'CoLA,': [115], 'RTE,': [116], 'QNLI.': [118], 'outperforms': [120], 'BERT': [121], 'significantly.&lt;br&gt;': [122]}",2020,"['Computer science', 'Sentence', 'Natural language processing', 'Artificial intelligence', 'Encoder', 'Transformer', 'Pipeline (software)', 'Programming language', 'Operating system', 'Physics', 'Quantum mechanics', 'Voltage']","Pretrained language models such as BERT, GPT have shown great effectiveness in language understanding. The auxiliary predictive tasks in existing pretraining approaches are mostly defined on tokens, thus may not be able to capture sentence-level semantics very well. To address this issue, we propose CERT: Contrastive self-supervised Encoder Representations from Transformers, which pretrains language representation models using contrastive self-supervised learning at the sentence level. CERT creates augmentations of original sentences using back-translation. Then it finetunes a pretrained language encoder (e.g., BERT) by predicting whether two augmented sentences originate from the same sentence. CERT is simple to use and can be flexibly plugged into any pretraining-finetuning NLP pipeline. We evaluate CERT on three language understanding tasks: CoLA, RTE, and QNLI. CERT outperforms BERT significantly.&lt;br&gt;"
https://openalex.org/W4389265550,"A comparison review of transfer learning and self-supervised learning: Definitions, applications, advantages and limitations","{'Deep': [0], 'learning': [1, 13, 34, 53, 65, 70, 114, 123, 172, 222, 236, 312], 'has': [2], 'emerged': [3], 'as': [4, 81, 200], 'a': [5, 77, 87, 293], 'powerful': [6], 'tool': [7], 'in': [8, 112, 176, 197, 258], 'various': [9, 177, 259], 'domains,': [10, 233], 'revolutionising': [11], 'machine': [12], 'research.': [14, 290], 'However,': [15, 208], 'one': [16], 'persistent': [17], 'challenge': [18], 'is': [19], 'the': [20, 28, 101, 119, 160, 229, 251, 262, 269, 277, 306, 316], 'scarcity': [21, 48, 318], 'of': [22, 32, 146, 240, 254, 273, 279, 296], 'labelled': [23, 92, 164], 'training': [24, 126], 'data,': [25], 'which': [26], 'hampers': [27], 'performance': [29, 115, 278], 'and': [30, 49, 66, 83, 104, 116, 170, 185, 205, 231, 271, 284], 'generalisation': [31], 'deep': [33, 51, 311], 'models.': [35], 'To': [36], 'address': [37, 315], 'this': [38, 300], 'limitation,': [39], 'researchers': [40], 'have': [41, 59, 173, 191, 217], 'developed': [42], 'innovative': [43], 'methods': [44, 211, 257], 'to': [45, 86, 98, 108, 139, 243, 314], 'overcome': [46], 'data': [47, 317], 'enhance': [50], 'model': [52], 'capabilities.': [54], 'Two': [55], 'prevalent': [56], 'techniques': [57], 'that': [58, 131], 'gained': [60], 'significant': [61], 'attention': [62], 'are': [63], 'transfer': [64, 106, 169, 221], 'self-supervised': [67, 122, 171, 235], 'learning.': [68], 'Transfer': [69], 'leverages': [71], 'knowledge': [72, 107], 'learned': [73, 102, 150], 'from': [74, 100, 143], 'pre-training': [75, 230, 256, 298], 'on': [76, 125], 'large-scale': [78], 'dataset,': [79], 'such': [80, 199], 'ImageNet,': [82], 'applies': [84], 'it': [85], 'target': [88, 232], 'task': [89], 'with': [90], 'limited': [91], 'data.': [93, 148, 165], 'This': [94, 247], 'approach': [95], 'allows': [96], 'models': [97, 127, 280], 'benefit': [99], 'representations': [103, 142, 151], 'effectively': [105], 'new': [109], 'tasks,': [110, 158], 'resulting': [111], 'improved': [113], 'generalisation.': [117], 'On': [118], 'other': [120], 'hand,': [121], 'focuses': [124], 'using': [128], 'pretext': [129, 241], 'tasks': [130, 242], 'do': [132], 'not': [133], 'require': [134], 'manual': [135], 'annotation,': [136], 'allowing': [137], 'them': [138], 'learn': [140], 'valuable': [141], 'large': [144], 'amounts': [145], 'unlabelled': [147], 'These': [149, 189], 'can': [152], 'then': [153], 'be': [154], 'fine-tuned': [155], 'for': [156, 162, 288, 304, 309], 'downstream': [157], 'mitigating': [159], 'need': [161], 'extensive': [163], 'In': [166], 'recent': [167, 252], 'years,': [168], 'found': [174], 'applications': [175, 253, 313], 'fields,': [178], 'including': [179], 'medical': [180], 'image': [181], 'processing,': [182], 'video': [183], 'recognition,': [184, 204], 'natural': [186], 'language': [187, 206], 'processing.': [188], 'approaches': [190], 'demonstrated': [192], 'remarkable': [193], 'achievements,': [194], 'enabling': [195], 'breakthroughs': [196], 'areas': [198], 'disease': [201], 'diagnosis,': [202], 'object': [203], 'understanding.': [207], 'while': [209, 234], 'these': [210, 255, 282], 'offer': [212], 'numerous': [213], 'advantages,': [214], 'they': [215], 'also': [216], 'limitations.': [218], 'For': [219], 'example,': [220], 'may': [223], 'face': [224], 'domain': [225], 'mismatch': [226], 'issues': [227], 'between': [228], 'requires': [237], 'careful': [238], 'design': [239], 'ensure': [244], 'meaningful': [245], 'representations.': [246], 'review': [248, 295], 'paper': [249], 'explores': [250], 'fields': [260], 'within': [261], 'past': [263], 'three': [264], 'years.': [265], 'It': [266], 'delves': [267], 'into': [268], 'advantages': [270], 'limitations': [272], 'each': [274], 'approach,': [275], 'assesses': [276], 'employing': [281], 'techniques,': [283], 'identifies': [285], 'potential': [286], 'directions': [287], 'future': [289], 'By': [291], 'providing': [292], 'comprehensive': [294], 'current': [297], 'methods,': [299], 'article': [301], 'offers': [302], 'guidance': [303], 'selecting': [305], 'best': [307], 'technique': [308], 'specific': [310], 'issue.': [319]}",2023,"['Computer science', 'Transfer of learning', 'Artificial intelligence', 'Machine learning', 'Deep learning', 'Task (project management)', 'Multi-task learning', 'Supervised learning', 'Artificial neural network', 'Management', 'Economics']","Deep learning has emerged as a powerful tool in various domains, revolutionising machine learning research. However, one persistent challenge is the scarcity of labelled training data, which hampers the performance and generalisation of deep learning models. To address this limitation, researchers have developed innovative methods to overcome data scarcity and enhance deep model learning capabilities. Two prevalent techniques that have gained significant attention are transfer learning and self-supervised learning. Transfer learning leverages knowledge learned from pre-training on a large-scale dataset, such as ImageNet, and applies it to a target task with limited labelled data. This approach allows models to benefit from the learned representations and effectively transfer knowledge to new tasks, resulting in improved learning performance and generalisation. On the other hand, self-supervised learning focuses on training models using pretext tasks that do not require manual annotation, allowing them to learn valuable representations from large amounts of unlabelled data. These learned representations can then be fine-tuned for downstream tasks, mitigating the need for extensive labelled data. In recent years, transfer and self-supervised learning have found applications in various fields, including medical image processing, video recognition, and natural language processing. These approaches have demonstrated remarkable achievements, enabling breakthroughs in areas such as disease diagnosis, object recognition, and language understanding. However, while these methods offer numerous advantages, they also have limitations. For example, transfer learning may face domain mismatch issues between the pre-training and target domains, while self-supervised learning requires careful design of pretext tasks to ensure meaningful representations. This review paper explores the recent applications of these pre-training methods in various fields within the past three years. It delves into the advantages and limitations of each approach, assesses the performance of models employing these techniques, and identifies potential directions for future research. By providing a comprehensive review of current pre-training methods, this article offers guidance for selecting the best technique for specific deep learning applications to address the data scarcity issue."
https://openalex.org/W4221145109,"data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language","{'While': [0], 'the': [1, 11, 43, 63, 73, 113, 118, 135], 'general': [2, 33], 'idea': [3, 56], 'of': [4, 62, 72, 85, 96, 121, 134], 'self-supervised': [5, 34], 'learning': [6, 45], 'is': [7, 57], 'identical': [8], 'across': [9], 'modalities,': [10], 'actual': [12], 'algorithms': [13], 'and': [14, 126], 'objectives': [15], 'differ': [16], 'widely': [17], 'because': [18], 'they': [19], 'were': [20], 'developed': [21], 'with': [22], 'a': [23, 39, 69, 76, 80, 131], 'single': [24], 'modality': [25], 'in': [26, 75, 102], 'mind.': [27], 'To': [28], 'get': [29], 'us': [30], 'closer': [31], 'to': [32, 58, 140], 'learning,': [35], 'we': [36], 'present': [37], 'data2vec,': [38], 'framework': [40], 'that': [41, 109], 'uses': [42], 'same': [44], 'method': [46], 'for': [47], 'either': [48], 'speech,': [49], 'NLP': [50], 'or': [51, 94, 137], 'computer': [52], 'vision.': [53], 'The': [54], 'core': [55], 'predict': [59], 'latent': [60, 107], 'representations': [61, 108], 'full': [64], 'input': [65, 74], 'data': [66], 'based': [67], 'on': [68, 117], 'masked': [70], 'view': [71], 'self-distillation': [77], 'setup': [78], 'using': [79], 'standard': [81], 'Transformer': [82], 'architecture.': [83], 'Instead': [84], 'predicting': [86], 'modality-specific': [87], 'targets': [88], 'such': [89], 'as': [90], 'words,': [91], 'visual': [92], 'tokens': [93], 'units': [95], 'human': [97], 'speech': [98, 122], 'which': [99], 'are': [100], 'local': [101], 'nature,': [103], 'data2vec': [104], 'predicts': [105], 'contextualized': [106], 'contain': [110], 'information': [111], 'from': [112], 'entire': [114], 'input.': [115], 'Experiments': [116], 'major': [119], 'benchmarks': [120], 'recognition,': [123], 'image': [124], 'classification,': [125], 'natural': [127], 'language': [128], 'understanding': [129], 'demonstrate': [130], 'new': [132], 'state': [133], 'art': [136], 'competitive': [138], 'performance': [139], 'predominant': [141], 'approaches.': [142]}",2022,"['Computer science', 'Transformer', 'Artificial intelligence', 'Modalities', 'Natural language processing', 'Modality (human–computer interaction)', 'Natural language', 'Speech recognition', 'Machine learning', 'Multimodal learning', 'Supervised learning', 'Language understanding', 'Artificial neural network', 'Physics', 'Sociology', 'Voltage', 'Quantum mechanics', 'Social science']","While the general idea of self-supervised learning is identical across modalities, the actual algorithms and objectives differ widely because they were developed with a single modality in mind. To get us closer to general self-supervised learning, we present data2vec, a framework that uses the same learning method for either speech, NLP or computer vision. The core idea is to predict latent representations of the full input data based on a masked view of the input in a self-distillation setup using a standard Transformer architecture. Instead of predicting modality-specific targets such as words, visual tokens or units of human speech which are local in nature, data2vec predicts contextualized latent representations that contain information from the entire input. Experiments on the major benchmarks of speech recognition, image classification, and natural language understanding demonstrate a new state of the art or competitive performance to predominant approaches."
https://openalex.org/W2921948732,Retinal Image Synthesis and Semi-Supervised Learning for Glaucoma Assessment,"{'[EN]': [0], 'Recent': [1], 'works': [2], 'show': [3], 'that': [4, 72, 86], 'Generative': [5, 127], 'Adversarial': [6, 128], 'Networks': [7, 129], '(GANs)': [8], 'can': [9, 74], 'be': [10, 75, 246], 'successfully': [11], 'applied': [12], 'to': [13, 33, 107, 134, 162, 167, 198, 212, 225, 249], 'image': [14, 45, 112, 208, 239], 'synthesis': [15], 'and': [16, 25, 47, 64, 82, 114, 133, 185, 230, 241], 'semi-supervised': [17, 49, 116], 'learning,': [18], 'where,': [19], 'given': [20], 'a': [21, 26, 35, 43, 48, 61, 109, 115], 'small': [22, 62], 'labelled': [23], 'database': [24], 'large': [27, 65], 'unlabelled': [28, 66], 'database,': [29], 'the': [30, 79, 88, 98, 124, 135, 138, 183, 193, 199, 203, 220, 242], 'goal': [31], 'is': [32, 106, 143, 158, 210, 223], 'train': [34], 'powerful': [36], 'classifier.': [37], 'In': [38, 131], 'this': [39, 92, 104, 141], 'paper,': [40], 'we': [41], 'trained': [42, 144], 'retinal': [44, 111, 216, 238, 256], 'synthesizer': [46, 113, 209, 240], 'learning': [50, 117], 'method': [51, 118], 'for': [52, 85, 119], 'automatic': [53], 'glaucoma': [54, 73, 120, 221, 243, 259], 'assessment': [55, 121], 'using': [56, 176], 'an': [57, 146, 251], 'adversarial': [58], 'model': [59], 'on': [60, 123, 145], 'glaucoma-labelled': [63], 'database.': [67], 'Various': [68], 'studies': [69], 'have': [70], 'shown': [71], 'monitored': [76], 'by': [77, 191], 'analyzing': [78], 'optic': [80, 99, 204], 'disc': [81], 'its': [83], 'surroundings,': [84], 'reason': [87], 'images': [89, 152, 164, 172, 184, 217, 257], 'used': [90, 247], 'in': [91], 'work': [93, 105], 'were': [94, 173, 189], 'automatically': [95], 'cropped': [96, 255], 'around': [97, 202], 'disc.': [100, 205], 'The': [101, 206, 236], 'novelty': [102], 'of': [103, 137, 149, 179, 195, 254], 'propose': [108], 'new': [110], 'based': [122], 'Deep': [125], 'Convolutional': [126], '(DCGAN).': [130], 'addition,': [132], 'best': [136], ""authors'"": [139], 'knowledge,': [140], 'system': [142], 'unprecedented': [147], 'number': [148, 253], 'publicly': [150], 'available': [151], '(86926': [153], 'images).': [154], 'This': [155], 'system,': [156], 'hence,': [157], 'not': [159], 'only': [160], 'able': [161, 211, 224], 'generate': [163, 213, 250], 'synthetically': [165], 'but': [166], 'provide': [168], 'labels': [169], 'automatically.': [170], 'Synthetic': [171], 'qualitatively': [174], 'evaluated': [175], 't-SNE': [177], 'plots': [178], 'features': [180], 'associated': [181], 'with': [182, 232, 258], 'their': [186], 'anatomical': [187, 200], 'consistency': [188], 'estimated': [190], 'measuring': [192], 'proportion': [194], 'pixels': [196], 'corresponding': [197], 'structures': [201], 'resulting': [207], 'realistic': [214], '(cropped)': [215], 'and,': [218], 'subsequently,': [219], 'classifier': [222, 244], 'classify': [226], 'them': [227], 'into': [228], 'glaucomatous': [229], 'normal': [231], 'high': [233], 'accuracy': [234], '(AUC=0.9017).': [235], 'obtained': [237], 'could': [245], 'then': [248], 'unlimited': [252], 'labels.': [260]}",2019,"['Artificial intelligence', 'Computer science', 'Glaucoma', 'Optic disc', 'Classifier (UML)', 'Pattern recognition (psychology)', 'Computer vision', 'Ophthalmology', 'Medicine']","[EN] Recent works show that Generative Adversarial Networks (GANs) can be successfully applied to image synthesis and semi-supervised learning, where, given a small labelled database and a large unlabelled database, the goal is to train a powerful classifier. In this paper, we trained a retinal image synthesizer and a semi-supervised learning method for automatic glaucoma assessment using an adversarial model on a small glaucoma-labelled and large unlabelled database. Various studies have shown that glaucoma can be monitored by analyzing the optic disc and its surroundings, for that reason the images used in this work were automatically cropped around the optic disc. The novelty of this work is to propose a new retinal image synthesizer and a semi-supervised learning method for glaucoma assessment based on the Deep Convolutional Generative Adversarial Networks (DCGAN). In addition, and to the best of the authors' knowledge, this system is trained on an unprecedented number of publicly available images (86926 images). This system, hence, is not only able to generate images synthetically but to provide labels automatically. Synthetic images were qualitatively evaluated using t-SNE plots of features associated with the images and their anatomical consistency were estimated by measuring the proportion of pixels corresponding to the anatomical structures around the optic disc. The resulting image synthesizer is able to generate realistic (cropped) retinal images and, subsequently, the glaucoma classifier is able to classify them into glaucomatous and normal with high accuracy (AUC=0.9017). The obtained retinal image synthesizer and the glaucoma classifier could be used then to generate an unlimited number of cropped retinal images with glaucoma labels."
https://openalex.org/W4382240004,Spatio-Temporal Self-Supervised Learning for Traffic Flow Prediction,"{'Robust': [0], 'prediction': [1, 101, 188], 'of': [2, 112, 172], 'citywide': [3], 'traffic': [4, 56, 71, 100, 106, 161, 175, 187], 'flows': [5, 44], 'at': [6, 165, 232], 'different': [7, 51], 'time': [8, 86], 'periods': [9], 'plays': [10], 'a': [11, 80, 94], 'crucial': [12], 'role': [13], 'in': [14, 214], 'intelligent': [15], 'transportation': [16], 'systems.': [17], 'While': [18], 'previous': [19], 'work': [20], 'has': [21], 'made': [22], 'great': [23], 'efforts': [24], 'to': [25, 63, 109, 183], 'model': [26, 76], 'spatio-temporal': [27, 149, 210], 'correlations,': [28], 'existing': [29], 'methods': [30], 'still': [31], 'suffer': [32], 'from': [33], 'two': [34, 177], 'key': [35], 'limitations:': [36], 'i)': [37], 'Most': [38], 'models': [39, 61], 'collectively': [40], 'predict': [41], 'all': [42, 85], ""regions'"": [43], 'without': [45], 'accounting': [46], 'for': [47, 84, 137], 'spatial': [48, 114, 135, 191], 'heterogeneity,': [49, 117], 'i.e.,': [50], 'regions': [52], 'may': [53, 220], 'have': [54], 'skewed': [55], 'flow': [57, 162], 'distributions.': [58], 'ii)': [59], 'These': [60], 'fail': [62], 'capture': [64], 'the': [65, 105, 139, 147, 156, 160, 173, 185, 217], 'temporal': [66, 77, 116, 133, 193], 'heterogeneity': [67, 211], 'induced': [68], 'by': [69], 'time-varying': [70], 'patterns,': [72], 'as': [73], 'they': [74], 'typically': [75], 'correlations': [78], 'with': [79, 118, 132, 190], 'shared': [81], 'parameterized': [82], 'space': [83, 142], 'periods.': [87], 'To': [88, 145], 'tackle': [89], 'these': [90], 'challenges,': [91], 'we': [92], 'propose': [93], 'novel': [95], 'Spatio-Temporal': [96], 'Self-Supervised': [97], 'Learning': [98], '(ST-SSL)': [99], 'framework': [102, 219], 'which': [103], 'enhances': [104], 'pattern': [107], 'representations': [108], 'be': [110], 'reflective': [111], 'both': [113, 166], 'and': [115, 134, 143, 168, 192], 'auxiliary': [119, 179], 'self-supervised': [120, 150], 'learning': [121], 'paradigms.': [122], 'Specifically,': [123], 'our': [124, 152], 'ST-SSL': [125, 153, 203], 'is': [126, 230], 'built': [127], 'over': [128, 159], 'an': [129], 'integrated': [130], 'module': [131], 'convolutions': [136], 'encoding': [138], 'information': [140], 'across': [141], 'time.': [144], 'achieve': [146], 'adaptive': [148, 157], 'learning,': [151], 'first': [154], 'performs': [155], 'augmentation': [158], 'graph': [163], 'data': [164], 'attribute-': [167], 'structure-levels.': [169], 'On': [170], 'top': [171], 'augmented': [174], 'graph,': [176], 'SSL': [178], 'tasks': [180], 'are': [181], 'constructed': [182], 'supplement': [184], 'main': [186], 'task': [189], 'heterogeneity-aware': [194], 'augmentation.': [195], 'Experiments': [196], 'on': [197, 224], 'four': [198], 'benchmark': [199], 'datasets': [200], 'demonstrate': [201], 'that': [202], 'consistently': [204], 'outperforms': [205], 'various': [206], 'state-of-the-art': [207], 'baselines.': [208], 'Since': [209], 'widely': [212], 'exists': [213], 'practical': [215], 'datasets,': [216], 'proposed': [218], 'also': [221], 'cast': [222], 'light': [223], 'other': [225], 'spatial-temporal': [226], 'applications.': [227], 'Model': [228], 'implementation': [229], 'available': [231], 'https://github.com/Echo-Ji/ST-SSL.': [233]}",2023,"['Computer science', 'Benchmark (surveying)', 'Temporal database', 'Graph', 'Artificial intelligence', 'Data mining', 'Machine learning', 'Parameterized complexity', 'Deep learning', 'Key (lock)', 'Theoretical computer science', 'Geography', 'Computer security', 'Geodesy', 'Algorithm']","Robust prediction of citywide traffic flows at different time periods plays a crucial role in intelligent transportation systems. While previous work has made great efforts to model spatio-temporal correlations, existing methods still suffer from two key limitations: i) Most models collectively predict all regions' flows without accounting for spatial heterogeneity, i.e., different regions may have skewed traffic flow distributions. ii) These models fail to capture the temporal heterogeneity induced by time-varying traffic patterns, as they typically model temporal correlations with a shared parameterized space for all time periods. To tackle these challenges, we propose a novel Spatio-Temporal Self-Supervised Learning (ST-SSL) traffic prediction framework which enhances the traffic pattern representations to be reflective of both spatial and temporal heterogeneity, with auxiliary self-supervised learning paradigms. Specifically, our ST-SSL is built over an integrated module with temporal and spatial convolutions for encoding the information across space and time. To achieve the adaptive spatio-temporal self-supervised learning, our ST-SSL first performs the adaptive augmentation over the traffic flow graph data at both attribute- and structure-levels. On top of the augmented traffic graph, two SSL auxiliary tasks are constructed to supplement the main traffic prediction task with spatial and temporal heterogeneity-aware augmentation. Experiments on four benchmark datasets demonstrate that ST-SSL consistently outperforms various state-of-the-art baselines. Since spatio-temporal heterogeneity widely exists in practical datasets, the proposed framework may also cast light on other spatial-temporal applications. Model implementation is available at https://github.com/Echo-Ji/ST-SSL."
https://openalex.org/W4321593910,Multi-Modal Self-Supervised Learning for Recommendation,"{'The': [0, 171], 'online': [1], 'emergence': [2], 'of': [3, 60, 74, 158], 'multi-modal': [4, 30, 106], 'sharing': [5], 'platforms': [6], '(eg,': [7], 'TikTok,': [8], 'Youtube)\\nis': [9], 'powering': [10], 'personalized': [11], 'recommender': [12], 'systems': [13], 'to': [14, 123, 142], 'incorporate': [15], 'various': [16, 168], 'modalities\\n(eg,': [17], 'visual,': [18], 'textual': [19], 'and': [20, 48, 78, 148], 'acoustic)': [21], 'into': [22], 'the': [23, 57, 98, 101, 125, 145, 156], 'latent': [24], 'user': [25, 53, 76, 149], 'representations.': [26], 'While\\nexisting': [27], 'works': [28], 'on': [29, 51, 153], 'recommendation': [31], 'exploit': [32], 'multimedia': [33], 'content\\nfeatures': [34], 'in': [35, 161], 'enhancing': [36], 'item': [37], 'embeddings,': [38], 'their': [39], 'model': [40], 'representation': [41], 'capability': [42], 'is\\nlimited': [43], 'by': [44, 56], 'heavy': [45], 'label': [46, 64], 'reliance': [47], 'weak': [49], 'robustness': [50], 'sparse': [52], 'behavior\\ndata.': [54], 'Inspired': [55], 'recent': [58], 'progress': [59], 'self-supervised': [61], 'learning': [62, 73, 114], 'in\\nalleviating': [63], 'scarcity': [65], 'issue,': [66], 'we': [67, 83, 109], 'explore': [68], 'deriving': [69], 'self-supervision': [70], 'signals\\nwith': [71], 'effectively': [72], 'modality-aware': [75, 112], 'preference': [77, 150], 'cross-modal\\ndependencies.': [79], 'To': [80], 'this': [81], 'end,': [82], 'propose': [84], 'a': [85, 111, 136], 'new': [86], 'Multi-Modal': [87], 'Self-Supervised\\nLearning': [88], '(MMSSL)': [89], 'method': [90, 160], 'which': [91], 'tackles': [92], 'two': [93], 'key': [94], 'challenges.': [95], 'Specifically,': [96], 'to\\ncharacterize': [97], 'inter-dependency': [99], 'between': [100], 'user-item': [102], 'collaborative': [103], 'view': [104], 'and\\nitem': [105], 'semantic': [107], 'view,': [108], 'design': [110], 'interactive\\nstructure': [113], 'paradigm': [115], 'via': [116], 'adversarial': [117], 'perturbations': [118], 'for': [119, 165], 'data\\naugmentation.': [120], 'In': [121], 'addition,': [122], 'capture': [124], 'effects': [126], 'that': [127], ""user's"": [128], 'modality-aware\\ninteraction': [129], 'pattern': [130], 'would': [131], 'interweave': [132], 'with': [133], 'each': [134], 'other,': [135], 'cross-modal': [137], 'contrastive\\nlearning': [138], 'approach': [139], 'is': [140], 'introduced': [141], 'jointly': [143], 'preserve': [144], 'inter-modal': [146], 'semantic\\ncommonality': [147], 'diversity.': [151], 'Experiments': [152], 'real-world': [154], 'datasets\\nverify': [155], 'superiority': [157], 'our': [159], 'offering': [162], 'great': [163], 'potential': [164], 'multimedia\\nrecommendation': [166], 'over': [167], 'state-of-the-art': [169], 'baselines.': [170], 'implementation': [172], 'is\\nreleased': [173], 'at:': [174], 'https://github.com/HKUDS/MMSSL.\\n': [175]}",2023,"['Computer science', 'Modal', 'Artificial intelligence', 'Recommender system', 'Machine learning', 'Polymer chemistry', 'Chemistry']","The online emergence of multi-modal sharing platforms (eg, TikTok, Youtube)\nis powering personalized recommender systems to incorporate various modalities\n(eg, visual, textual and acoustic) into the latent user representations. While\nexisting works on multi-modal recommendation exploit multimedia content\nfeatures in enhancing item embeddings, their model representation capability is\nlimited by heavy label reliance and weak robustness on sparse user behavior\ndata. Inspired by the recent progress of self-supervised learning in\nalleviating label scarcity issue, we explore deriving self-supervision signals\nwith effectively learning of modality-aware user preference and cross-modal\ndependencies. To this end, we propose a new Multi-Modal Self-Supervised\nLearning (MMSSL) method which tackles two key challenges. Specifically, to\ncharacterize the inter-dependency between the user-item collaborative view and\nitem multi-modal semantic view, we design a modality-aware interactive\nstructure learning paradigm via adversarial perturbations for data\naugmentation. In addition, to capture the effects that user's modality-aware\ninteraction pattern would interweave with each other, a cross-modal contrastive\nlearning approach is introduced to jointly preserve the inter-modal semantic\ncommonality and user preference diversity. Experiments on real-world datasets\nverify the superiority of our method in offering great potential for multimedia\nrecommendation over various state-of-the-art baselines. The implementation is\nreleased at: https://github.com/HKUDS/MMSSL.\n"
https://openalex.org/W3093579165,Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition,"{'We': [0], 'employ': [1], 'a': [2], 'combination': [3], 'of': [4, 24], 'recent': [5], 'developments': [6], 'in': [7], 'semi-supervised': [8], 'learning': [9], 'for': [10], 'automatic': [11], 'speech': [12], 'recognition': [13], 'to': [14, 53], 'obtain': [15], 'state-of-the-art': [16, 66], 'results': [17], 'on': [18, 58], 'LibriSpeech': [19, 60], 'utilizing': [20], 'the': [21, 25, 59, 64], 'unlabeled': [22], 'audio': [23], 'Libri-Light': [26], 'dataset.': [27], 'More': [28], 'precisely,': [29], 'we': [30, 50], 'carry': [31], 'out': [32], 'noisy': [33], 'student': [34], 'training': [35], 'with': [36], 'SpecAugment': [37], 'using': [38, 43], 'giant': [39], 'Conformer': [40], 'models': [41], 'pre-trained': [42], 'wav2vec': [44], '2.0': [45], 'pre-training.': [46], 'By': [47], 'doing': [48], 'so,': [49], 'are': [51], 'able': [52], 'achieve': [54], 'word-error-rates': [55], '(WERs)': [56], '1.4%/2.6%': [57], 'test/test-other': [61], 'sets': [62], 'against': [63], 'current': [65], 'WERs': [67], '1.7%/3.3%.': [68]}",2020,"['State (computer science)', 'Speech recognition', 'Test (biology)', 'Computer science', 'Word (group theory)', 'Word error rate', 'Artificial intelligence', 'Mathematics', 'Algorithm', 'Biology', 'Paleontology', 'Geometry']","We employ a combination of recent developments in semi-supervised learning for automatic speech recognition to obtain state-of-the-art results on LibriSpeech utilizing the unlabeled audio of the Libri-Light dataset. More precisely, we carry out noisy student training with SpecAugment using giant Conformer models pre-trained using wav2vec 2.0 pre-training. By doing so, we are able to achieve word-error-rates (WERs) 1.4%/2.6% on the LibriSpeech test/test-other sets against the current state-of-the-art WERs 1.7%/3.3%."
https://openalex.org/W2054113233,Supervised Learning in Multilayer Spiking Neural Networks,"{'We': [0], 'introduce': [1], 'a': [2, 14], 'supervised': [3], 'learning': [4, 18], 'algorithm': [5, 12, 58, 88], 'for': [6, 112], 'multilayer': [7], 'spiking': [8], 'neural': [9, 31], 'networks.': [10], 'The': [11, 57, 87], 'overcomes': [13], 'limitation': [15], 'of': [16, 53, 96], 'existing': [17, 110], 'algorithms:': [19], 'it': [20], 'can': [21, 37], 'be': [22, 41], 'applied': [23, 60], 'to': [24, 62, 80], 'neurons': [25], 'firing': [26], 'multiple': [27], 'spikes': [28], 'in': [29, 39, 93, 106], 'artificial': [30], 'networks': [32, 100], 'with': [33, 43], 'hidden': [34], 'layers.': [35], 'It': [36], 'also,': [38], 'principle,': [40], 'used': [42], 'any': [44], 'linearizable': [45], 'neuron': [46], 'model': [47], 'and': [48, 72, 84, 104], 'allows': [49], 'different': [50], 'coding': [51], 'schemes': [52], 'spike': [54], 'train': [55], 'patterns.': [56], 'is': [59], 'successfully': [61, 91], 'classic': [63], 'linearly': [64], 'nonseparable': [65], 'benchmarks': [66], 'such': [67, 115], 'as': [68, 77, 79, 116], 'the': [69, 73, 94], 'XOR': [70], 'problem': [71], 'Iris': [74], 'data': [75], 'set,': [76], 'well': [78], 'more': [81], 'complex': [82], 'classification': [83], 'mapping': [85], 'problems.': [86], 'has': [89], 'been': [90], 'tested': [92], 'presence': [95], 'noise,': [97], 'requires': [98], 'smaller': [99], 'than': [101, 109], 'reservoir': [102], 'computing,': [103], 'results': [105], 'faster': [107], 'convergence': [108], 'algorithms': [111], 'similar': [113], 'tasks': [114], 'SpikeProp.': [117]}",2012,"['Artificial neural network', 'Computer science', 'Artificial intelligence', 'Spiking neural network', 'Coding (social sciences)', 'Algorithm', 'Convergence (economics)', 'Set (abstract data type)', 'Supervised learning', 'Spike (software development)', 'Neural coding', 'Noise (video)', 'Pattern recognition (psychology)', 'Mathematics', 'Economic growth', 'Software engineering', 'Image (mathematics)', 'Economics', 'Statistics', 'Programming language']","We introduce a supervised learning algorithm for multilayer spiking neural networks. The algorithm overcomes a limitation of existing learning algorithms: it can be applied to neurons firing multiple spikes in artificial neural networks with hidden layers. It can also, in principle, be used with any linearizable neuron model and allows different coding schemes of spike train patterns. The algorithm is applied successfully to classic linearly nonseparable benchmarks such as the XOR problem and the Iris data set, as well as to more complex classification and mapping problems. The algorithm has been successfully tested in the presence of noise, requires smaller networks than reservoir computing, and results in faster convergence than existing algorithms for similar tasks such as SpikeProp."
https://openalex.org/W3201190151,Self-supervised learning methods and applications in medical imaging analysis: a survey,"{'The': [0, 88], 'scarcity': [1, 56], 'of': [2, 21, 57, 84, 93, 128, 137], 'high-quality': [3], 'annotated': [4, 58], 'medical': [5, 22, 59, 85, 111, 141], 'imaging': [6, 23, 86, 112, 142], 'datasets': [7], 'is': [8, 31], 'a': [9, 32, 76, 91], 'major': [10], 'problem': [11], 'that': [12, 36], 'collides': [13], 'with': [14, 75, 160], 'machine': [15], 'learning': [16, 30, 38, 70, 98, 139], 'applications': [17, 80], 'in': [18, 68, 81, 134, 140, 153, 165], 'the': [19, 42, 55, 64, 82, 94, 101, 110, 124, 129, 135, 147, 150, 154, 157, 166], 'field': [20, 83, 104, 136], 'analysis': [24, 113, 143], 'and': [25, 114, 120], 'impedes': [26], 'its': [27], 'advancement.': [28], 'Self-supervised': [29], 'recent': [33, 96, 131, 151], 'training': [34], 'paradigm': [35], 'enables': [37], 'robust': [39], 'representations': [40], 'without': [41], 'need': [43], 'for': [44, 54, 72], 'human': [45], 'annotation': [46], 'which': [47], 'can': [48], 'be': [49], 'considered': [50], 'an': [51], 'effective': [52], 'solution': [53], 'data.': [60], 'This': [61], 'article': [62, 89, 125, 158], 'reviews': [63], 'state-of-the-art': [65], 'research': [66, 132, 163], 'directions': [67, 164], 'self-supervised': [69, 97, 138], 'approaches': [71], 'image': [73], 'data': [74], 'concentration': [77], 'on': [78, 149], 'their': [79], 'analysis.': [87], 'covers': [90, 126], 'set': [92], 'most': [95, 130], 'methods': [99], 'from': [100], 'computer': [102], 'vision': [103], 'as': [105, 117], 'they': [106], 'are': [107], 'applicable': [108], 'to': [109], 'categorize': [115], 'them': [116], 'predictive,': [118], 'generative,': [119], 'contrastive': [121], 'approaches.': [122], 'Moreover,': [123], '40': [127], 'papers': [133], 'aiming': [144], 'at': [145], 'shedding': [146], 'light': [148], 'innovation': [152], 'field.': [155, 167], 'Finally,': [156], 'concludes': [159], 'possible': [161], 'future': [162]}",2022,"['Field (mathematics)', 'Computer science', 'Artificial intelligence', 'Medical imaging', 'Categorization', 'Data science', 'Machine learning', 'Supervised learning', 'Scarcity', 'Medical research', 'Artificial neural network', 'Medicine', 'Mathematics', 'Economics', 'Pathology', 'Microeconomics', 'Pure mathematics']","The scarcity of high-quality annotated medical imaging datasets is a major problem that collides with machine learning applications in the field of medical imaging analysis and impedes its advancement. Self-supervised learning is a recent training paradigm that enables learning robust representations without the need for human annotation which can be considered an effective solution for the scarcity of annotated medical data. This article reviews the state-of-the-art research directions in self-supervised learning approaches for image data with a concentration on their applications in the field of medical imaging analysis. The article covers a set of the most recent self-supervised learning methods from the computer vision field as they are applicable to the medical imaging analysis and categorize them as predictive, generative, and contrastive approaches. Moreover, the article covers 40 of the most recent research papers in the field of self-supervised learning in medical imaging analysis aiming at shedding the light on the recent innovation in the field. Finally, the article concludes with possible future research directions in the field."
https://openalex.org/W2890787190,Supervised Learning for Suicidal Ideation Detection in Online User Content,"{'Early': [0], 'detection': [1, 59, 165], 'and': [2, 15, 67, 93, 100, 109, 129, 132, 142, 153, 158, 173], 'treatment': [3], 'are': [4, 29], 'regarded': [5], 'as': [6, 77], 'the': [7, 55, 151, 156, 162, 167], 'most': [8], 'effective': [9], 'ways': [10], 'to': [11, 36, 46], 'prevent': [12], 'suicidal': [13, 39, 48, 84, 114, 163], 'ideation': [14, 49, 164], 'potential': [16], 'suicide': [17], 'attempts—two': [18], 'critical': [19], 'risk': [20], 'factors': [21], 'resulting': [22], 'in': [23], 'successful': [24], 'suicides.': [25], 'Online': [26], 'communication': [27], 'channels': [28], 'becoming': [30], 'a': [31], 'new': [32], 'way': [33], 'for': [34, 82, 161], 'people': [35], 'express': [37, 88], 'their': [38], 'tendencies.': [40, 85], 'This': [41], 'paper': [42], 'presents': [43], 'an': [44, 78], 'approach': [45, 157], 'understand': [47], 'through': [50], 'online': [51, 169], 'user‐generated': [52], 'content': [53], 'with': [54], 'goal': [56], 'of': [57, 121, 155], 'early': [58, 79], 'via': [60], 'supervised': [61, 140], 'learning.': [62], 'Analysing': [63], 'users’': [64], 'language': [65], 'preferences': [66], 'topic': [68, 130], 'descriptions': [69], 'reveals': [70], 'rich': [71], 'knowledge': [72], 'that': [73], 'can': [74], 'be': [75], 'used': [76], 'warning': [80], 'system': [81], 'detecting': [83], 'Suicidal': [86, 95], 'individuals': [87], 'strong': [89], 'negative': [90], 'feelings,': [91], 'anxiety,': [92], 'hopelessness.': [94], 'thoughts': [96], 'may': [97], 'involve': [98], 'family': [99], 'friends.': [101], 'And': [102], 'topics': [103], 'they': [104], 'discuss': [105], 'cover': [106], 'both': [107], 'personal': [108], 'social': [110], 'issues.': [111], 'To': [112], 'detect': [113], 'ideation,': [115], 'we': [116, 133], 'extract': [117], 'several': [118], 'informative': [119], 'sets': [120], 'features,': [122, 131], 'including': [123, 137], 'statistical,': [124], 'syntactic,': [125], 'linguistic,': [126], 'word': [127], 'embedding,': [128], 'compare': [134], 'six': [135], 'classifiers,': [136], 'four': [138], 'traditional': [139], 'classifiers': [141], 'two': [143], 'neural': [144], 'network': [145], 'models.': [146], 'An': [147], 'experimental': [148], 'study': [149], 'demonstrates': [150], 'feasibility': [152], 'practicability': [154], 'provides': [159], 'benchmarks': [160], 'on': [166], 'active': [168], 'platforms:': [170], 'Reddit': [171], 'SuicideWatch': [172], 'Twitter.': [174]}",2018,"['Suicidal ideation', 'Ideation', 'Feeling', 'Psychology', 'Computer science', 'Anxiety', 'Social media', 'Word embedding', 'Artificial intelligence', 'Machine learning', 'Suicide prevention', 'Poison control', 'Social psychology', 'World Wide Web', 'Embedding', 'Medicine', 'Psychiatry', 'Cognitive science', 'Environmental health']","Early detection and treatment are regarded as the most effective ways to prevent suicidal ideation and potential suicide attempts—two critical risk factors resulting in successful suicides. Online communication channels are becoming a new way for people to express their suicidal tendencies. This paper presents an approach to understand suicidal ideation through online user‐generated content with the goal of early detection via supervised learning. Analysing users’ language preferences and topic descriptions reveals rich knowledge that can be used as an early warning system for detecting suicidal tendencies. Suicidal individuals express strong negative feelings, anxiety, and hopelessness. Suicidal thoughts may involve family and friends. And topics they discuss cover both personal and social issues. To detect suicidal ideation, we extract several informative sets of features, including statistical, syntactic, linguistic, word embedding, and topic features, and we compare six classifiers, including four traditional supervised classifiers and two neural network models. An experimental study demonstrates the feasibility and practicability of the approach and provides benchmarks for the suicidal ideation detection on the active online platforms: Reddit SuicideWatch and Twitter."
https://openalex.org/W2914913933,Exploiting Unlabeled Data in CNNs by Self-Supervised Learning to Rank,"{'For': [0, 104], 'many': [1], 'applications': [2], 'the': [3, 39, 80, 85, 127, 162], 'collection': [4], 'of': [5, 12, 23, 170, 172], 'labeled': [6, 132], 'data': [7, 14, 44, 133, 141], 'is': [8, 17, 45, 166], 'expensive': [9], 'laborious.': [10], 'Exploitation': [11], 'unlabeled': [13, 116, 140, 173], 'during': [15], 'training': [16], 'thus': [18], 'a': [19, 59, 167], 'long': [20], 'pursued': [21], 'objective': [22], 'machine': [24], 'learning.': [25], 'Self-supervised': [26], 'learning': [27, 185], 'addresses': [28], 'this': [29, 49, 190], 'by': [30, 84, 194], 'positing': [31], 'an': [32, 71, 181], 'auxiliary': [33], 'task': [34, 61, 165], '(different,': [35], 'but': [36], 'related': [37], 'to': [38, 93, 109, 124, 126, 135, 138, 179, 196], 'supervised': [40], 'task)': [41], 'for': [42, 62, 75, 131, 147, 183], 'which': [43, 78], 'abundantly': [46], 'available.': [47], 'In': [48, 153], 'paper,': [50], 'we': [51, 69, 106, 155, 187], 'show': [52, 107, 120, 156, 188], 'how': [53, 108], 'ranking': [54], 'can': [55, 176], 'be': [56, 177], 'used': [57, 178], 'as': [58], 'proxy': [60, 164], 'some': [63], 'regression': [64, 95], 'problems.': [65], 'As': [66], 'another': [67], 'contribution,': [68], 'propose': [70], 'efficient': [72], 'backpropagation': [73], 'technique': [74], 'Siamese': [76], 'networks': [77, 122], 'prevents': [79], 'redundant': [81], 'computation': [82], 'introduced': [83], 'multi-branch': [86], 'network': [87, 159], 'architecture.': [88], 'We': [89], 'apply': [90], 'our': [91], 'framework': [92], 'two': [94], 'problems:': [96], 'Image': [97], 'Quality': [98], 'Assessment': [99], '(IQA)': [100], 'and': [101, 134, 150, 186], 'Crowd': [102], 'Counting.': [103], 'both': [105, 148], 'automatically': [110], 'generate': [111], 'ranked': [112], 'image': [113], 'sets': [114], 'from': [115], 'data.': [117, 174], 'Our': [118], 'results': [119, 146], 'that': [121, 157, 189], 'trained': [123], 'regress': [125], 'ground': [128], 'truth': [129], 'targets': [130], 'simultaneously': [136], 'learn': [137], 'rank': [139], 'obtain': [142], 'significantly': [143], 'better,': [144], 'state-of-the-art': [145], 'IQA': [149], 'crowd': [151], 'counting.': [152], 'addition,': [154], 'measuring': [158], 'uncertainty': [160], 'on': [161], 'self-supervised': [163], 'good': [168], 'measure': [169], 'informativeness': [171], 'This': [175], 'drive': [180], 'algorithm': [182], 'active': [184], 'reduces': [191], 'labeling': [192], 'effort': [193], 'up': [195], '50': [197], 'percent.': [198]}",2019,"['Artificial intelligence', 'Computer science', 'Machine learning', 'Labeled data', 'Ranking (information retrieval)', 'Task (project management)', 'Supervised learning', 'Regression', 'Learning to rank', 'Ground truth', 'Pattern recognition (psychology)', 'Semi-supervised learning', 'Rank (graph theory)', 'Data mining', 'Artificial neural network', 'Mathematics', 'Statistics', 'Economics', 'Management', 'Combinatorics']","For many applications the collection of labeled data is expensive laborious. Exploitation of unlabeled data during training is thus a long pursued objective of machine learning. Self-supervised learning addresses this by positing an auxiliary task (different, but related to the supervised task) for which data is abundantly available. In this paper, we show how ranking can be used as a proxy task for some regression problems. As another contribution, we propose an efficient backpropagation technique for Siamese networks which prevents the redundant computation introduced by the multi-branch network architecture. We apply our framework to two regression problems: Image Quality Assessment (IQA) and Crowd Counting. For both we show how to automatically generate ranked image sets from unlabeled data. Our results show that networks trained to regress to the ground truth targets for labeled data and to simultaneously learn to rank unlabeled data obtain significantly better, state-of-the-art results for both IQA and crowd counting. In addition, we show that measuring network uncertainty on the self-supervised proxy task is a good measure of informativeness of unlabeled data. This can be used to drive an algorithm for active learning and we show that this reduces labeling effort by up to 50 percent."
https://openalex.org/W3036224891,Unsupervised Learning of Visual Features by Contrasting Cluster Assignments,"{'Unsupervised': [0], 'image': [1], 'representations': [2], 'have': [3], 'significantly': [4], 'reduced': [5], 'the': [6, 13, 67, 82, 105, 112, 188, 215], 'gap': [7], 'with': [8, 12, 122, 177, 205], 'supervised': [9, 211], 'pretraining,': [10], 'notably': [11], 'recent': [14], 'achievements': [15], 'of': [16, 32, 53, 81, 86, 108, 114, 133, 175, 182], 'contrastive': [17, 21, 54, 92, 138], 'learning': [18], 'methods.': [19], 'These': [20], 'methods': [22, 55], 'typically': [23], 'work': [24], 'online': [25, 47], 'and': [26, 124, 127], 'rely': [27], 'on': [28, 203, 213], 'a': [29, 98, 109, 151, 156, 165, 173], 'large': [30, 123, 152], 'number': [31], 'explicit': [33], 'pairwise': [34, 60], 'feature': [35], 'comparisons,': [36], 'which': [37], 'is': [38, 142], 'computationally': [39], 'challenging.': [40], 'In': [41, 160], 'this': [42], 'paper,': [43], 'we': [44, 96, 103, 162], 'propose': [45, 164], 'an': [46], 'algorithm,': [48], 'SwAV,': [49], 'that': [50, 171], 'takes': [51], 'advantage': [52], 'without': [56, 186], 'requiring': [57], 'to': [58, 130, 136], 'compute': [59, 191], 'comparisons.': [61], 'Specifically,': [62], 'our': [63, 140, 196], 'method': [64, 118, 141], 'simultaneously': [65], 'clusters': [66], 'data': [68, 167], 'while': [69], 'enforcing': [70], 'consistency': [71], 'between': [72], 'cluster': [73, 106], 'assignments': [74], 'produced': [75], 'for': [76], 'different': [77, 178], 'augmentations': [78], '(or': [79], 'views)': [80], 'same': [83], 'image,': [84], 'instead': [85], 'comparing': [87], 'features': [88], 'directly': [89], 'as': [90, 207, 209], 'in': [91, 180], 'learning.': [93], 'Simply': [94], 'put,': [95], 'use': [97], 'swapped': [99], 'prediction': [100], 'mechanism': [101], 'where': [102], 'predict': [104], 'assignment': [107], 'view': [110], 'from': [111], 'representation': [113], 'another': [115], 'view.': [116], 'Our': [117], 'can': [119, 128], 'be': [120], 'trained': [121], 'small': [125], 'batches': [126], 'scale': [129], 'unlimited': [131], 'amounts': [132], 'data.': [134], 'Compared': [135], 'previous': [137], 'methods,': [139], 'more': [143], 'memory': [144, 153, 189], 'efficient': [145], 'since': [146], 'it': [147], 'does': [148], 'not': [149], 'require': [150], 'bank': [154], 'or': [155, 190], 'special': [157], 'momentum': [158], 'network.': [159], 'addition,': [161], 'also': [163], 'new': [166], 'augmentation': [168], 'strategy,': [169], 'multi-crop,': [170], 'uses': [172], 'mix': [174], 'views': [176], 'resolutions': [179], 'place': [181], 'two': [183], 'full-resolution': [184], 'views,': [185], 'increasing': [187], 'requirements': [192], 'much.': [193], 'We': [194], 'validate': [195], 'findings': [197], 'by': [198], 'achieving': [199], '75.3%': [200], 'top-1': [201], 'accuracy': [202], 'ImageNet': [204], 'ResNet-50,': [206], 'well': [208], 'surpassing': [210], 'pretraining': [212], 'all': [214], 'considered': [216], 'transfer': [217], 'tasks.': [218]}",2020,"['Computer science', 'Pairwise comparison', 'Artificial intelligence', 'Consistency (knowledge bases)', 'Representation (politics)', 'Feature (linguistics)', 'Machine learning', 'Pattern recognition (psychology)', 'Politics', 'Philosophy', 'Political science', 'Linguistics', 'Law']","Unsupervised image representations have significantly reduced the gap with supervised pretraining, notably with the recent achievements of contrastive learning methods. These contrastive methods typically work online and rely on a large number of explicit pairwise feature comparisons, which is computationally challenging. In this paper, we propose an online algorithm, SwAV, that takes advantage of contrastive methods without requiring to compute pairwise comparisons. Specifically, our method simultaneously clusters the data while enforcing consistency between cluster assignments produced for different augmentations (or views) of the same image, instead of comparing features directly as in contrastive learning. Simply put, we use a swapped prediction mechanism where we predict the cluster assignment of a view from the representation of another view. Our method can be trained with large and small batches and can scale to unlimited amounts of data. Compared to previous contrastive methods, our method is more memory efficient since it does not require a large memory bank or a special momentum network. In addition, we also propose a new data augmentation strategy, multi-crop, that uses a mix of views with different resolutions in place of two full-resolution views, without increasing the memory or compute requirements much. We validate our findings by achieving 75.3% top-1 accuracy on ImageNet with ResNet-50, as well as surpassing supervised pretraining on all the considered transfer tasks."
https://openalex.org/W2116435618,Unsupervised Learning of Video Representations using LSTMs,"{'We': [0, 56, 82, 99, 126, 135, 151, 174], 'use': [1], 'multilayer': [2], 'Long': [3], 'Short': [4], 'Term': [5], 'Memory': [6], '(LSTM)': [7], 'networks': [8], 'to': [9, 21, 41, 107, 128], 'learn': [10], 'representations': [11, 71, 155, 178], 'of': [12, 61, 66, 73, 103, 200], 'video': [13, 74, 117], 'sequences.': [14], 'Our': [15], 'model': [16, 105, 112, 139], 'uses': [17], 'an': [18, 23], 'encoder': [19], 'LSTM': [20], 'map': [22], 'input': [24, 49, 62], 'sequence': [25], 'into': [26, 119, 123], 'a': [27, 78, 160, 188], 'fixed': [28], 'length': [29], 'representation.': [30], 'This': [31], 'representation': [32, 118], 'is': [33], 'decoded': [34], 'using': [35, 77], 'single': [36], 'or': [37, 51], 'multiple': [38], 'decoder': [39, 91], 'LSTMs': [40, 92], 'perform': [42], 'different': [43, 84], 'tasks,': [44], 'such': [45, 87], 'as': [46, 88], 'reconstructing': [47], 'the': [48, 53, 90, 96, 101, 104, 111, 115, 120, 124, 132, 138, 154, 169, 177], 'sequence,': [50], 'predicting': [52], 'future': [54, 121], 'sequence.': [55], 'experiment': [57], 'with': [58], 'two': [59], 'kinds': [60], 'sequences': [63], '-': [64, 164], 'patches': [65], 'image': [67], 'pixels': [68], 'and': [69, 122, 130, 147, 171], 'high-level': [70], '(""percepts"")': [72], 'frames': [75], 'extracted': [76], 'pretrained': [79, 194], 'convolutional': [80], 'net.': [81], 'explore': [83], 'design': [85], 'choices': [86], 'whether': [89], 'should': [93], 'condition': [94], 'on': [95, 143, 148, 168, 195], 'generated': [97], 'output.': [98], 'analyze': [100], 'outputs': [102], 'qualitatively': [106], 'see': [108], 'how': [109], 'well': [110], 'can': [113, 203], 'extrapolate': [114], 'learned': [116, 133], 'past.': [125], 'try': [127], 'visualize': [129], 'interpret': [131], 'features.': [134], 'stress': [136], 'test': [137], 'by': [140, 156], 'running': [141], 'it': [142], 'longer': [144], 'time': [145], 'scales': [146], 'out-of-domain': [149], 'data.': [150], 'further': [152], 'evaluate': [153], 'finetuning': [157], 'them': [158], 'for': [159], 'supervised': [161], 'learning': [162], 'problem': [163], 'human': [165], 'action': [166, 205], 'recognition': [167, 206], 'UCF-101': [170], 'HMDB-51': [172], 'datasets.': [173], 'show': [175], 'that': [176], 'help': [179, 204], 'improve': [180], 'classification': [181], 'accuracy,': [182], 'especially': [183], 'when': [184], 'there': [185], 'are': [186], 'only': [187], 'few': [189], 'training': [190], 'examples.': [191], 'Even': [192], 'models': [193], 'unrelated': [196], 'datasets': [197], '(300': [198], 'hours': [199], 'YouTube': [201], 'videos)': [202], 'performance.': [207]}",2015,"['Computer science', 'Encoder', 'Artificial intelligence', 'Representation (politics)', 'Sequence (biology)', 'Pattern recognition (psychology)', 'Feature learning', 'Convolutional neural network', 'Deep learning', 'Sequence labeling', 'Machine learning', 'Task (project management)', 'Economics', 'Operating system', 'Political science', 'Law', 'Genetics', 'Politics', 'Management', 'Biology']","We use multilayer Long Short Term Memory (LSTM) networks to learn representations of video sequences. Our model uses an encoder LSTM to map an input sequence into a fixed length representation. This representation is decoded using single or multiple decoder LSTMs to perform different tasks, such as reconstructing the input sequence, or predicting the future sequence. We experiment with two kinds of input sequences - patches of image pixels and high-level representations (""percepts"") of video frames extracted using a pretrained convolutional net. We explore different design choices such as whether the decoder LSTMs should condition on the generated output. We analyze the outputs of the model qualitatively to see how well the model can extrapolate the learned video representation into the future and into the past. We try to visualize and interpret the learned features. We stress test the model by running it on longer time scales and on out-of-domain data. We further evaluate the representations by finetuning them for a supervised learning problem - human action recognition on the UCF-101 and HMDB-51 datasets. We show that the representations help improve classification accuracy, especially when there are only a few training examples. Even models pretrained on unrelated datasets (300 hours of YouTube videos) can help action recognition performance."
https://openalex.org/W3146944767,Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences,"{'Significance': [0], 'Learning': [1], 'biological': [2, 59], 'properties': [3, 50], 'from': [4], 'sequence': [5], 'data': [6], 'is': [7], 'a': [8, 23], 'logical': [9], 'step': [10], 'toward': [11], 'generative': [12], 'and': [13, 58, 81, 94, 97], 'predictive': [14], 'artificial': [15], 'intelligence': [16], 'for': [17, 70, 101], 'biology.': [18], 'Here,': [19], 'we': [20], 'propose': [21], 'scaling': [22], 'deep': [24], 'contextual': [25], 'language': [26], 'model': [27], 'with': [28], 'unsupervised': [29], 'learning': [30, 86], 'to': [31], 'sequences': [32], 'spanning': [33], 'evolutionary': [34], 'diversity.': [35], 'We': [36, 61], 'find': [37], 'that': [38], 'without': [39], 'prior': [40], 'knowledge,': [41], 'information': [42], 'emerges': [43], 'in': [44], 'the': [45, 63], 'learned': [46, 64], 'representations': [47, 65], 'on': [48], 'fundamental': [49], 'of': [51, 75, 91], 'proteins': [52], 'such': [53], 'as': [54], 'secondary': [55, 76, 95], 'structure,': [56, 77], 'contacts,': [57, 80], 'activity.': [60], 'show': [62], 'are': [66], 'useful': [67], 'across': [68], 'benchmarks': [69], 'remote': [71], 'homology': [72], 'detection,': [73], 'prediction': [74, 90], 'long-range': [78, 102], 'residue–residue': [79], 'mutational': [82, 92], 'effect.': [83], 'Unsupervised': [84], 'representation': [85], 'enables': [87], 'state-of-the-art': [88, 99], 'supervised': [89], 'effect': [93], 'structure': [96], 'improves': [98], 'features': [100], 'contact': [103], 'prediction.': [104]}",2021,"['Artificial intelligence', 'Generative grammar', 'Generative model', 'Unsupervised learning', 'Computer science', 'Machine learning', 'Protein secondary structure', 'Biology', 'Biochemistry']","Significance Learning biological properties from sequence data is a logical step toward generative and predictive artificial intelligence for biology. Here, we propose scaling a deep contextual language model with unsupervised learning to sequences spanning evolutionary diversity. We find that without prior knowledge, information emerges in the learned representations on fundamental properties of proteins such as secondary structure, contacts, and biological activity. We show the learned representations are useful across benchmarks for remote homology detection, prediction of secondary structure, long-range residue–residue contacts, and mutational effect. Unsupervised representation learning enables state-of-the-art supervised prediction of mutational effect and secondary structure and improves state-of-the-art features for long-range contact prediction."
https://openalex.org/W2129069237,Deep Unsupervised Learning using Nonequilibrium Thermodynamics,"{'A': [0], 'central': [1], 'problem': [2], 'in': [3, 17, 57, 77, 102], 'machine': [4], 'learning': [5], 'involves': [6], 'modeling': [7], 'complex': [8], 'data-sets': [9], 'using': [10], 'highly': [11, 81], 'flexible': [12, 82], 'families': [13], 'of': [14, 87, 108, 134], 'probability': [15], 'distributions': [16], 'which': [18], 'learning,': [19], 'sampling,': [20], 'inference,': [21], 'and': [22, 40, 53, 83, 99, 119], 'evaluation': [23], 'are': [24], 'still': [25], 'analytically': [26], 'or': [27, 110], 'computationally': [28], 'tractable.': [29], 'Here,': [30], 'we': [31], 'develop': [32], 'an': [33, 62, 129], 'approach': [34, 91], 'that': [35, 74], 'simultaneously': [36], 'achieves': [37], 'both': [38], 'flexibility': [39], 'tractability.': [41], 'The': [42], 'essential': [43], 'idea,': [44], 'inspired': [45], 'by': [46], 'non-equilibrium': [47], 'statistical': [48], 'physics,': [49], 'is': [50], 'to': [51, 94, 116], 'systematically': [52], 'slowly': [54], 'destroy': [55], 'structure': [56, 76], 'a': [58, 70, 80], 'data': [59], 'distribution': [60], 'through': [61], 'iterative': [63], 'forward': [64], 'diffusion': [65, 72], 'process.': [66], 'We': [67, 126], 'then': [68], 'learn': [69], 'reverse': [71], 'process': [73], 'restores': [75], 'data,': [78], 'yielding': [79], 'tractable': [84], 'generative': [85, 104], 'model': [86], 'the': [88, 123, 135], 'data.': [89], 'This': [90], 'allows': [92], 'us': [93], 'rapidly': [95], 'learn,': [96], 'sample': [97], 'from,': [98], 'evaluate': [100], 'probabilities': [101, 121], 'deep': [103], 'models': [105], 'with': [106], 'thousands': [107], 'layers': [109], 'time': [111], 'steps,': [112], 'as': [113, 115], 'well': [114], 'compute': [117], 'conditional': [118], 'posterior': [120], 'under': [122], 'learned': [124], 'model.': [125], 'additionally': [127], 'release': [128], 'open': [130], 'source': [131], 'reference': [132], 'implementation': [133], 'algorithm.': [136]}",2015,"['Non-equilibrium thermodynamics', 'Thermodynamics', 'Statistical physics', 'Economics', 'Artificial intelligence', 'Physics', 'Computer science']","A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm."
https://openalex.org/W1570411240,Unsupervised learning of digit recognition using spike-timing-dependent plasticity,"{'In': [0], 'order': [1], 'to': [2, 17, 33, 44, 66, 81, 109, 165], 'understand': [3], 'how': [4, 39, 58], 'the': [5, 23, 166, 179, 201, 209, 217, 234], 'mammalian': [6], 'neocortex': [7], 'is': [8, 53, 120, 183], 'performing': [9], 'computations,': [10], 'two': [11], 'things': [12], 'are': [13, 42], 'necessary;': [14], 'we': [15, 31, 151, 194], 'need': [16, 32], 'have': [18], 'a': [19, 35, 78, 103, 110, 114, 155], 'good': [20], 'understanding': [21, 37], 'of': [22, 38, 131, 204, 211, 219, 233, 237], 'available': [24], 'neuronal': [25], 'processing': [26], 'units': [27], 'and': [28, 30, 106, 142, 158, 222], 'mechanisms,': [29, 238], 'gain': [34], 'better': [36, 184], 'those': [40], 'mechanisms': [41, 88, 123], 'combined': [43], 'build': [45], 'functioning': [46], 'systems.': [47], 'Therefore,': [48], 'in': [49, 57, 102, 242], 'recent': [50], 'years': [51], 'there': [52], 'an': [54, 143], 'increasing': [55], 'interest': [56], 'spiking': [59, 145], 'neural': [60, 245], 'networks': [61], '(SNN)': [62], 'can': [63], 'be': [64], 'used': [65, 195, 221], 'perform': [67], 'complex': [68], 'computations': [69], 'or': [70], 'solve': [71], 'pattern': [72], 'recognition': [73, 118], 'tasks.': [74], 'However,': [75], 'it': [76], 'remains': [77], 'challenging': [79], 'task': [80], 'design': [82], 'SNNs': [83], 'which': [84, 119, 182, 239], 'use': [85, 154], 'biologically': [86], 'plausible': [87], '(especially': [89], 'for': [90, 116, 226], 'learning': [91, 171, 229], 'new': [92], 'patterns),': [93], 'since': [94], 'most': [95, 148], 'such': [96], 'SNN': [97, 115, 187], 'architectures': [98], 'rely': [99], 'on': [100, 122, 178], 'training': [101], 'rate-based': [104], 'network': [105, 206, 213], 'subsequent': [107], 'conversion': [108], 'SNN.': [111], 'We': [112], 'present': [113, 161], 'digit': [117], 'based': [121], 'with': [124, 136, 216], 'increased': [125], 'biological': [126, 244], 'plausibility,': [127], 'i.e.,': [128], 'conductance-based': [129], 'instead': [130], 'current-based': [132], 'synapses,': [133], 'spike-timing-dependent': [134], 'plasticity': [135], 'time-dependent': [137], 'weight': [138], 'change,': [139], 'lateral': [140], 'inhibition,': [141], 'adaptive': [144], 'threshold.': [146], 'Unlike': [147], 'other': [149], 'systems,': [150], 'do': [152, 159], 'not': [153, 160], 'teaching': [156], 'signal': [157], 'any': [162], 'class': [163], 'labels': [164], 'network.': [167], 'Using': [168], 'this': [169], 'unsupervised': [170], 'scheme,': [172], 'our': [173, 205, 212], 'architecture': [174], 'achieves': [175], '95%': [176], 'accuracy': [177], 'MNIST': [180], 'benchmark,': [181], 'than': [185], 'previous': [186], 'implementations': [188], 'without': [189], 'supervision.': [190], 'The': [191], 'fact': [192], 'that': [193], 'no': [196], 'domain-specific': [197], 'knowledge': [198], 'points': [199], 'toward': [200], 'general': [202], 'applicability': [203, 241], 'design.': [207], 'Also,': [208], 'performance': [210, 225], 'scales': [214], 'well': [215], 'number': [218], 'neurons': [220], 'shows': [223], 'similar': [224], 'four': [227], 'different': [228], 'rules,': [230], 'indicating': [231], 'robustness': [232], 'full': [235], 'combination': [236], 'suggests': [240], 'heterogeneous': [243], 'networks.': [246]}",2015,"['Spiking neural network', 'Computer science', 'Spike-timing-dependent plasticity', 'MNIST database', 'Artificial intelligence', 'Machine learning', 'Robustness (evolution)', 'Artificial neural network', 'Benchmark (surveying)', 'Pattern recognition (psychology)', 'Synaptic plasticity', 'Receptor', 'Gene', 'Biochemistry', 'Geodesy', 'Chemistry', 'Geography']","In order to understand how the mammalian neocortex is performing computations, two things are necessary; we need to have a good understanding of the available neuronal processing units and mechanisms, and we need to gain a better understanding of how those mechanisms are combined to build functioning systems. Therefore, in recent years there is an increasing interest in how spiking neural networks (SNN) can be used to perform complex computations or solve pattern recognition tasks. However, it remains a challenging task to design SNNs which use biologically plausible mechanisms (especially for learning new patterns), since most such SNN architectures rely on training in a rate-based network and subsequent conversion to a SNN. We present a SNN for digit recognition which is based on mechanisms with increased biological plausibility, i.e., conductance-based instead of current-based synapses, spike-timing-dependent plasticity with time-dependent weight change, lateral inhibition, and an adaptive spiking threshold. Unlike most other systems, we do not use a teaching signal and do not present any class labels to the network. Using this unsupervised learning scheme, our architecture achieves 95% accuracy on the MNIST benchmark, which is better than previous SNN implementations without supervision. The fact that we used no domain-specific knowledge points toward the general applicability of our network design. Also, the performance of our network scales well with the number of neurons used and shows similar performance for four different learning rules, indicating robustness of the full combination of mechanisms, which suggests applicability in heterogeneous biological neural networks."
https://openalex.org/W2101711363,Unsupervised Learning of the Morphology of a Natural Language,"{'This': [0], 'study': [1], 'reports': [2], 'the': [3, 17, 57, 61, 73, 84, 89, 99], 'results': [4], 'of': [5, 16, 20, 38, 91, 94, 101], 'using': [6, 23], 'minimum': [7], 'description': [8], 'length': [9], '(MDL)': [10], 'analysis': [11, 74, 97], 'to': [12, 31, 54, 98], 'model': [13], 'unsupervised': [14], 'learning': [15], 'morphological': [18, 45], 'segmentation': [19], 'European': [21], 'languages,': [22], 'corpora': [24], 'ranging': [25], 'in': [26, 104], 'size': [27], 'from': [28], '5,000': [29], 'words': [30], '500,000': [32], 'words.': [33], 'We': [34], 'develop': [35, 42], 'a': [36, 43, 80], 'set': [37], 'heuristics': [39, 62], 'that': [40, 75], 'rapidly': [41], 'probabilistic': [44], 'grammar,': [46], 'and': [47], 'use': [48], 'MDL': [49, 95], 'as': [50], 'our': [51], 'primary': [52], 'tool': [53], 'determine': [55], 'whether': [56], 'modifications': [58], 'proposed': [59], 'by': [60, 79], 'will': [63], 'be': [64, 77], 'adopted': [65], 'or': [66], 'not.': [67], 'The': [68], 'resulting': [69], 'grammar': [70], 'matches': [71], 'well': [72], 'would': [76], 'developed': [78], 'human': [81], 'morphologist.': [82], 'In': [83], 'final': [85], 'section,': [86], 'we': [87], 'discuss': [88], 'relationship': [90], 'this': [92], 'style': [93], 'grammatical': [96], 'notion': [100], 'evaluation': [102], 'metric': [103], 'early': [105], 'generative': [106], 'grammar.': [107]}",2001,"['Computer science', 'Generative grammar', 'Heuristics', 'Natural language processing', 'Artificial intelligence', 'Minimum description length', 'Grammar', 'Metric (unit)', 'Segmentation', 'Set (abstract data type)', 'Natural language', 'Generative model', 'Probabilistic logic', 'Linguistics', 'Programming language', 'Philosophy', 'Economics', 'Operating system', 'Operations management']","This study reports the results of using minimum description length (MDL) analysis to model unsupervised learning of the morphological segmentation of European languages, using corpora ranging in size from 5,000 words to 500,000 words. We develop a set of heuristics that rapidly develop a probabilistic morphological grammar, and use MDL as our primary tool to determine whether the modifications proposed by the heuristics will be adopted or not. The resulting grammar matches well the analysis that would be developed by a human morphologist. In the final section, we discuss the relationship of this style of MDL grammatical analysis to the notion of evaluation metric in early generative grammar."
https://openalex.org/W2414456771,Discovering phase transitions with unsupervised learning,"{'Unsupervised': [0], 'learning': [1, 7], 'is': [2], 'a': [3, 50], 'discipline': [4], 'of': [5, 49, 92, 100], 'machine': [6], 'which': [8], 'aims': [9], 'at\\ndiscovering': [10], 'patterns': [11], 'in': [12, 73], 'big': [13], 'data': [14, 19, 65], 'sets': [15], 'or': [16], 'classifying': [17], 'the': [18, 63, 74, 93], 'into': [20], 'several\\ncategories': [21], 'without': [22], 'being': [23], 'trained': [24], 'explicitly.': [25], 'We': [26, 96], 'show': [27], 'that': [28], 'unsupervised': [29, 108], 'learning\\ntechniques': [30], 'can': [31], 'be': [32], 'readily': [33], 'used': [34], 'to': [35, 58, 90], 'identify': [36], 'phases': [37, 39, 72, 103], 'and': [38, 66, 87, 104], 'transitions': [40, 106], 'of\\nmany': [41], 'body': [42], 'systems.': [43], 'Starting': [44], 'with': [45], 'raw': [46], 'spin': [47], 'configurations': [48], 'prototypical\\nIsing': [51], 'model,': [52], 'we': [53], 'use': [54, 67], 'principal': [55], 'component': [56], 'analysis': [57, 69], 'extract': [59], 'relevant': [60], 'low\\ndimensional': [61], 'representations': [62], 'original': [64], 'clustering': [68], 'to\\nidentify': [70], 'distinct': [71], 'feature': [75], 'space.': [76], 'This': [77], 'approach': [78], 'successfully': [79], 'finds\\nout': [80], 'physical': [81], 'concepts': [82], 'such': [83], 'as': [84], 'order': [85], 'parameter': [86], 'structure': [88], 'factor': [89], 'be\\nindicators': [91], 'phase': [94, 105], 'transition.': [95], 'discuss': [97], 'future': [98], 'prospects': [99], 'discovering\\nmore': [101], 'complex': [102], 'using': [107], 'learning\\ntechniques.\\n': [109]}",2016,"['Phase (matter)', 'Unsupervised learning', 'Computer science', 'Artificial intelligence', 'Physics', 'Quantum mechanics']","Unsupervised learning is a discipline of machine learning which aims at\ndiscovering patterns in big data sets or classifying the data into several\ncategories without being trained explicitly. We show that unsupervised learning\ntechniques can be readily used to identify phases and phases transitions of\nmany body systems. Starting with raw spin configurations of a prototypical\nIsing model, we use principal component analysis to extract relevant low\ndimensional representations the original data and use clustering analysis to\nidentify distinct phases in the feature space. This approach successfully finds\nout physical concepts such as order parameter and structure factor to be\nindicators of the phase transition. We discuss future prospects of discovering\nmore complex phases and phase transitions using unsupervised learning\ntechniques.\n"
https://openalex.org/W2173520492,Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks,"{'In': [0, 26], 'recent': [1], 'years,': [2], 'supervised': [3, 42], 'learning': [4, 19, 43], 'with': [5, 20], 'convolutional': [6, 55, 88], 'networks': [7, 58], '(CNNs)': [8], 'has': [9, 22], 'seen': [10], 'huge': [11], 'adoption': [12], 'in': [13, 101], 'computer': [14], 'vision': [15], 'applications.': [16], 'Comparatively,': [17], 'unsupervised': [18, 45, 74], 'CNNs': [21, 40, 52], 'received': [23], 'less': [24], 'attention.': [25], 'this': [27], 'work': [28], 'we': [29, 81, 108], 'hope': [30], 'to': [31, 99], 'help': [32], 'bridge': [33], 'the': [34, 37, 103, 110], 'gap': [35], 'between': [36], 'success': [38], 'of': [39, 51, 94], 'for': [41, 73, 113], 'and': [44, 65, 105], 'learning.': [46, 75], 'We': [47], 'introduce': [48], 'a': [49, 70, 92], 'class': [50], 'called': [53], 'deep': [54, 87], 'generative': [56], 'adversarial': [57, 89], '(DCGANs),': [59], 'that': [60, 67, 85], 'have': [61], 'certain': [62], 'architectural': [63], 'constraints,': [64], 'demonstrate': [66], 'they': [68], 'are': [69], 'strong': [71], 'candidate': [72], 'Training': [76], 'on': [77], 'various': [78], 'image': [79, 122], 'datasets,': [80], 'show': [82], 'convincing': [83], 'evidence': [84], 'our': [86], 'pair': [90], 'learns': [91], 'hierarchy': [93], 'representations': [95], 'from': [96], 'object': [97], 'parts': [98], 'scenes': [100], 'both': [102], 'generator': [104], 'discriminator.': [106], 'Additionally,': [107], 'use': [109], 'learned': [111], 'features': [112], 'novel': [114], 'tasks': [115], '-': [116], 'demonstrating': [117], 'their': [118], 'applicability': [119], 'as': [120], 'general': [121], 'representations.': [123]}",2015,"['Artificial intelligence', 'Computer science', 'Convolutional neural network', 'Unsupervised learning', 'Deep learning', 'Discriminator', 'Feature learning', 'Adversarial system', 'Representation (politics)', 'Generative grammar', 'Machine learning', 'Generator (circuit theory)', 'Class (philosophy)', 'Hierarchy', 'Pattern recognition (psychology)', 'Telecommunications', 'Power (physics)', 'Law', 'Political science', 'Physics', 'Quantum mechanics', 'Economics', 'Politics', 'Market economy', 'Detector']","In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations."
https://openalex.org/W2963684088,Unsupervised Representation Learning with Deep Convolutional Generative\n Adversarial Networks,"{'In': [0, 24], 'recent': [1], 'years,': [2], 'supervised': [3, 39], 'learning': [4, 40], 'with': [5, 18], 'convolutional': [6, 80], 'networks': [7, 53], '(CNNs)': [8], 'has\\nseen': [9], 'huge': [10], 'adoption': [11], 'in': [12, 92], 'computer': [13], 'vision': [14], 'applications.': [15], 'Comparatively,': [16], 'unsupervised\\nlearning': [17], 'CNNs': [19, 37, 48], 'has': [20], 'received': [21], 'less': [22], 'attention.': [23], 'this': [25], 'work': [26], 'we': [27, 74, 98], 'hope': [28], 'to': [29, 90], 'help\\nbridge': [30], 'the': [31, 34, 94, 100], 'gap': [32], 'between': [33], 'success': [35], 'of': [36, 47, 86], 'for': [38, 67, 103], 'and\\nunsupervised': [41], 'learning.': [42], 'We': [43], 'introduce': [44], 'a': [45, 64, 84], 'class': [46], 'called': [49], 'deep': [50, 79], 'convolutional\\ngenerative': [51], 'adversarial': [52, 81], '(DCGANs),': [54], 'that': [55, 61], 'have': [56], 'certain': [57], 'architectural\\nconstraints,': [58], 'and': [59, 96], 'demonstrate': [60], 'they': [62], 'are': [63], 'strong': [65], 'candidate': [66], 'unsupervised\\nlearning.': [68], 'Training': [69], 'on': [70], 'various': [71], 'image': [72, 111], 'datasets,': [73], 'show': [75], 'convincing': [76], 'evidence': [77], 'that\\nour': [78], 'pair': [82], 'learns': [83], 'hierarchy': [85], 'representations\\nfrom': [87], 'object': [88], 'parts': [89], 'scenes': [91], 'both': [93], 'generator': [95], 'discriminator.\\nAdditionally,': [97], 'use': [99], 'learned': [101], 'features': [102], 'novel': [104], 'tasks': [105], '-': [106], 'demonstrating': [107], 'their\\napplicability': [108], 'as': [109], 'general': [110], 'representations.\\n': [112]}",2015,"['Artificial intelligence', 'Computer science', 'Convolutional neural network', 'Unsupervised learning', 'Deep learning', 'Discriminator', 'Feature learning', 'Representation (politics)', 'Adversarial system', 'Generative grammar', 'Machine learning', 'Generator (circuit theory)', 'Class (philosophy)', 'Hierarchy', 'Pattern recognition (psychology)', 'Political science', 'Law', 'Economics', 'Physics', 'Telecommunications', 'Quantum mechanics', 'Detector', 'Politics', 'Market economy', 'Power (physics)']","In recent years, supervised learning with convolutional networks (CNNs) has\nseen huge adoption in computer vision applications. Comparatively, unsupervised\nlearning with CNNs has received less attention. In this work we hope to help\nbridge the gap between the success of CNNs for supervised learning and\nunsupervised learning. We introduce a class of CNNs called deep convolutional\ngenerative adversarial networks (DCGANs), that have certain architectural\nconstraints, and demonstrate that they are a strong candidate for unsupervised\nlearning. Training on various image datasets, we show convincing evidence that\nour deep convolutional adversarial pair learns a hierarchy of representations\nfrom object parts to scenes in both the generator and discriminator.\nAdditionally, we use the learned features for novel tasks - demonstrating their\napplicability as general image representations.\n"
https://openalex.org/W2903538854,Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations,"{'The': [0], 'key': [1], 'idea': [2], 'behind': [3], 'the': [4, 43, 55, 69, 72, 103, 111, 153, 168], 'unsupervised': [5, 28, 56], 'learning': [6, 29, 57, 136, 148], 'of': [7, 21, 58, 135, 155, 164, 167], 'disentangled': [8, 59], 'representations': [9, 60], 'is': [10, 14, 61], 'that': [11, 54, 101, 143], 'real-world': [12], 'data': [13, 97, 179], 'generated': [15], 'by': [16, 27, 110], 'a': [17, 36, 89, 131, 173], 'few': [18], 'explanatory': [19], 'factors': [20], 'variation': [22], 'which': [23], 'can': [24], 'be': [25, 118, 150], 'recovered': [26], 'algorithms.': [30], 'In': [31], 'this': [32], 'paper,': [33], 'we': [34, 75], 'provide': [35], 'sober': [37], 'look': [38], 'at': [39], 'recent': [40], 'progress': [41], 'in': [42, 88], 'field': [44], 'and': [45, 71, 85, 158, 171], 'challenge': [46], 'some': [47], 'common': [48], 'assumptions.': [49], 'We': [50, 99], 'first': [51], 'theoretically': [52], 'show': [53], 'fundamentally': [62], 'impossible': [63], 'without': [64, 120], 'inductive': [65, 156], 'biases': [66, 157], 'on': [67, 94, 146], 'both': [68], 'models': [70, 80, 115], 'data.': [73], 'Then,': [74], 'train': [76], 'more': [77], 'than': [78], '12000': [79], 'covering': [81, 177], 'most': [82], 'prominent': [83], 'methods': [84, 105], 'evaluation': [86], 'metrics': [87], 'reproducible': [90, 174], 'large-scale': [91], 'experimental': [92, 175], 'study': [93], 'seven': [95], 'different': [96, 104], 'sets.': [98, 180], 'observe': [100], 'while': [102], 'successfully': [106], 'enforce': [107], 'properties': [108], ""``encouraged''"": [109], 'corresponding': [112], 'losses,': [113], 'well-disentangled': [114], 'seemingly': [116], 'cannot': [117], 'identified': [119], 'supervision.': [121], 'Furthermore,': [122], 'increased': [123], 'disentanglement': [124, 147, 166], 'does': [125], 'not': [126], 'seem': [127], 'to': [128, 130], 'lead': [129], 'decreased': [132], 'sample': [133], 'complexity': [134], 'for': [137], 'downstream': [138], 'tasks.': [139], 'Our': [140], 'results': [141], 'suggest': [142], 'future': [144], 'work': [145], 'should': [149], 'explicit': [151], 'about': [152], 'role': [154], '(implicit)': [159], 'supervision,': [160], 'investigate': [161], 'concrete': [162], 'benefits': [163], 'enforcing': [165], 'learned': [169], 'representations,': [170], 'consider': [172], 'setup': [176], 'several': [178]}",2018,"['Computer science', 'Artificial intelligence', 'Unsupervised learning', 'Natural language processing', 'Machine learning']","The key idea behind the unsupervised learning of disentangled representations is that real-world data is generated by a few explanatory factors of variation which can be recovered by unsupervised learning algorithms. In this paper, we provide a sober look at recent progress in the field and challenge some common assumptions. We first theoretically show that the unsupervised learning of disentangled representations is fundamentally impossible without inductive biases on both the models and the data. Then, we train more than 12000 models covering most prominent methods and evaluation metrics in a reproducible large-scale experimental study on seven different data sets. We observe that while the different methods successfully enforce properties ``encouraged'' by the corresponding losses, well-disentangled models seemingly cannot be identified without supervision. Furthermore, increased disentanglement does not seem to lead to a decreased sample complexity of learning for downstream tasks. Our results suggest that future work on disentanglement learning should be explicit about the role of inductive biases and (implicit) supervision, investigate concrete benefits of enforcing disentanglement of the learned representations, and consider a reproducible experimental setup covering several data sets."
https://openalex.org/W2605035112,Unsupervised Learning of Sentence Embeddings Using Compositional n-Gram Features,"{'The': [0], 'recent': [1], 'tremendous': [2], 'success': [3], 'of': [4, 11, 29, 46, 62], 'unsupervised': [5, 40, 53], 'word': [6, 30], 'embeddings': [7, 25], 'in': [8], 'a': [9, 36], 'multitude': [10], 'applications': [12], 'raises': [13], 'the': [14, 51, 60, 63], 'obvious': [15], 'question': [16], 'if': [17], 'similar': [18], 'methods': [19], 'could': [20], 'be': [21], 'derived': [22], 'to': [23, 42], 'improve': [24], '(i.e.': [26], 'semantic': [27], 'representations)': [28], 'sequences': [31], 'as': [32], 'well.': [33], 'We': [34], 'present': [35], 'simple': [37], 'but': [38], 'efficient': [39], 'objective': [41], 'train': [43], 'distributed': [44], 'representations': [45], 'sentences.': [47], 'Our': [48], 'method': [49], 'outperforms': [50], 'state-of-the-art': [52], 'models': [54], 'on': [55], 'most': [56], 'benchmark': [57], 'tasks,': [58], 'highlighting': [59], 'robustness': [61], 'produced': [64], 'general-purpose': [65], 'sentence': [66], 'embeddings.': [67]}",2018,"['Computer science', 'Unsupervised learning', 'Robustness (evolution)', 'Artificial intelligence', 'Sentence', 'Natural language processing', 'n-gram', 'Benchmark (surveying)', 'Word (group theory)', 'Simple (philosophy)', 'Machine learning', 'Language model', 'Mathematics', 'Geography', 'Biochemistry', 'Geodesy', 'Gene', 'Geometry', 'Epistemology', 'Philosophy', 'Chemistry']","The recent tremendous success of unsupervised word embeddings in a multitude of applications raises the obvious question if similar methods could be derived to improve embeddings (i.e. semantic representations) of word sequences as well. We present a simple but efficient unsupervised objective to train distributed representations of sentences. Our method outperforms the state-of-the-art unsupervised models on most benchmark tasks, highlighting the robustness of the produced general-purpose sentence embeddings."
https://openalex.org/W2787740020,An Unsupervised Learning Model for Deformable Medical Image Registration,"{'We': [0, 33, 76, 123], 'present': [1], 'a': [2, 37, 45, 50, 55, 64, 81, 88], 'fast': [3], 'learning-based': [4, 159], 'algorithm': [5], 'for': [6, 21, 30], 'deformable,': [7], 'pairwise': [8], '3D': [9, 130], 'medical': [10, 148], 'image': [11, 95, 131, 149], 'registration.': [12], 'Current': [13], 'registration': [14, 35, 65, 104, 118, 125, 160], 'methods': [15], 'optimize': [16, 41], 'an': [17], 'objective': [18], 'function': [19, 71, 79], 'independently': [20], 'each': [22], 'pair': [23, 57], 'of': [24, 47, 52, 58, 136], 'images,': [25], 'which': [26], 'can': [27, 61], 'be': [28], 'time-consuming': [29], 'large': [31], 'data.': [32], 'define': [34], 'as': [36, 115], 'parametric': [38], 'function,': [39], 'and': [40, 86, 151, 161], 'its': [42, 162], 'parameters': [43], 'given': [44], 'set': [46], 'images': [48], 'from': [49, 96], 'collection': [51], 'interest.': [53], 'Given': [54], 'new': [56], 'scans,': [59], 'we': [60], 'quickly': [62], 'compute': [63], 'field': [66], 'by': [67], 'directly': [68], 'evaluating': [69], 'the': [70, 73, 103], 'using': [72, 80], 'learned': [74], 'parameters.': [75], 'model': [77], 'this': [78], 'convolutional': [82], 'neural': [83], 'network': [84], '(CNN),': [85], 'use': [87], 'spatial': [89], 'transform': [90], 'layer': [91], 'to': [92, 128, 144], 'reconstruct': [93], 'one': [94], 'another': [97], 'while': [98, 133, 154], 'imposing': [99], 'smoothness': [100], 'constraints': [101], 'on': [102], 'field.': [105], 'The': [106], 'proposed': [107], 'method': [108, 142], 'does': [109], 'not': [110], 'require': [111], 'supervised': [112], 'information': [113], 'such': [114], 'ground': [116], 'truth': [117], 'fields': [119], 'or': [120], 'anatomical': [121], 'landmarks.': [122], 'demonstrate': [124], 'accuracy': [126], 'comparable': [127], 'state-of-the-art': [129], 'registration,': [132], 'operating': [134], 'orders': [135], 'magnitude': [137], 'faster': [138], 'in': [139, 158], 'practice.': [140], 'Our': [141, 164], 'promises': [143], 'significantly': [145], 'speed': [146], 'up': [147], 'analysis': [150], 'processing': [152], 'pipelines,': [153], 'facilitating': [155], 'novel': [156], 'directions': [157], 'applications.': [163], 'code': [165], 'is': [166], 'available': [167], 'at': [168], 'https://github.com/balakg/voxelmorph': [169], '.': [170]}",2018,[],"We present a fast learning-based algorithm for deformable, pairwise 3D medical image registration. Current registration methods optimize an objective function independently for each pair of images, which can be time-consuming for large data. We define registration as a parametric function, and optimize its parameters given a set of images from a collection of interest. Given a new pair of scans, we can quickly compute a registration field by directly evaluating the function using the learned parameters. We model this function using a convolutional neural network (CNN), and use a spatial transform layer to reconstruct one image from another while imposing smoothness constraints on the registration field. The proposed method does not require supervised information such as ground truth registration fields or anatomical landmarks. We demonstrate registration accuracy comparable to state-of-the-art 3D image registration, while operating orders of magnitude faster in practice. Our method promises to significantly speed up medical image analysis and processing pipelines, while facilitating novel directions in learning-based registration and its applications. Our code is available at https://github.com/balakg/voxelmorph ."
https://openalex.org/W2950180292,Deep Clustering for Unsupervised Learning of Visual Features,"{'Clustering': [0], 'is': [1], 'a': [2, 43, 52, 69, 117], 'class': [3], 'of': [4, 30, 51, 59, 85, 95, 113], 'unsupervised': [5, 93], 'learning': [6], 'methods': [7], 'that': [8, 46], 'has': [9, 20], 'been': [10, 21], 'extensively': [11], 'applied': [12], 'and': [13, 55, 74, 104], 'studied': [14], 'in': [15], 'computer': [16], 'vision.': [17], 'Little': [18], 'work': [19], 'done': [22], 'to': [23, 26, 81, 91], 'adapt': [24], 'it': [25], 'the': [27, 49, 56, 60, 66, 76, 83, 86, 92, 110, 114, 122], 'end-to-end': [28], 'training': [29, 94], 'visual': [31], 'features': [32, 67], 'on': [33, 99, 120], 'large': [34, 100], 'scale': [35], 'datasets.': [36], 'In': [37], 'this': [38], 'work,': [39], 'we': [40], 'present': [41], 'DeepCluster,': [42], 'clustering': [44, 71], 'method': [45], 'jointly': [47], 'learns': [48], 'parameters': [50], 'neural': [53, 97], 'network': [54], 'cluster': [57], 'assignments': [58, 78], 'resulting': [61, 107], 'features.': [62], 'DeepCluster': [63, 90], 'iteratively': [64], 'groups': [65], 'with': [68], 'standard': [70, 123], 'algorithm,': [72], 'k-means,': [73], 'uses': [75], 'subsequent': [77], 'as': [79], 'supervision': [80], 'update': [82], 'weights': [84], 'network.': [87], 'We': [88], 'apply': [89], 'convolutional': [96], 'networks': [98], 'datasets': [101], 'like': [102], 'ImageNet': [103], 'YFCC100M.': [105], 'The': [106], 'model': [108], 'outperforms': [109], 'current': [111], 'state': [112], 'art': [115], 'by': [116], 'significant': [118], 'margin': [119], 'all': [121], 'benchmarks.': [124]}",2018,"['Cluster analysis', 'Computer science', 'Margin (machine learning)', 'Artificial intelligence', 'Unsupervised learning', 'Convolutional neural network', 'Pattern recognition (psychology)', 'Machine learning', 'Artificial neural network', 'Class (philosophy)', 'Deep learning']","Clustering is a class of unsupervised learning methods that has been extensively applied and studied in computer vision. Little work has been done to adapt it to the end-to-end training of visual features on large scale datasets. In this work, we present DeepCluster, a clustering method that jointly learns the parameters of a neural network and the cluster assignments of the resulting features. DeepCluster iteratively groups the features with a standard clustering algorithm, k-means, and uses the subsequent assignments as supervision to update the weights of the network. We apply DeepCluster to the unsupervised training of convolutional neural networks on large datasets like ImageNet and YFCC100M. The resulting model outperforms the current state of the art by a significant margin on all the standard benchmarks."
https://openalex.org/W2158794898,Unsupervised learning of narrative schemas and their participants,"{'We': [0], 'describe': [1], 'an': [2], 'unsupervised': [3, 68], 'system': [4, 52], 'for': [5], 'learning': [6, 69, 100], 'narrative': [7, 82], 'schemas,': [8], 'coherent': [9], 'sequences': [10], 'or': [11, 47, 60, 65], 'sets': [12], 'of': [13, 63, 76], 'events': [14, 64], '(arrested(POLICE,': [15], 'SUSPECT),': [16], 'convicted(JUDGE,': [17], 'SUSPECT))': [18], 'whose': [19], 'arguments': [20, 73], 'are': [21], 'filled': [22], 'with': [23], 'participant': [24], 'semantic': [25, 48, 105], 'roles': [26], 'defined': [27], 'over': [28], 'words': [29], '(Judge': [30], '=': [31, 36], '{judge,': [32], 'jury,': [33], 'court},': [34], 'Police': [35], '{police,': [37], 'agent,': [38], 'authorities}).': [39], 'Unlike': [40], 'most': [41], 'previous': [42, 96], 'work': [43], 'in': [44, 74, 98], 'event': [45, 83], 'structure': [46, 84], 'role': [49], 'learning,': [50], 'our': [51], 'does': [53], 'not': [54], 'use': [55], 'supervised': [56], 'techniques,': [57], 'hand-built': [58], 'knowledge,': [59], 'predefined': [61], 'classes': [62], 'roles.': [66, 87, 106], 'Our': [67], 'algorithm': [70], 'uses': [71], 'coreferring': [72], 'chains': [75], 'verbs': [77], 'to': [78], 'learn': [79], 'both': [80, 91], 'rich': [81, 103], 'and': [85, 101], 'argument': [86], 'By': [88], 'jointly': [89], 'addressing': [90], 'tasks,': [92], 'we': [93], 'improve': [94], 'on': [95], 'results': [97], 'narrative/frame': [99], 'induce': [102], 'frame-specific': [104]}",2009,"['Narrative', 'Suspect', 'Computer science', 'Argument (complex analysis)', 'Frame (networking)', 'Jury', 'Event (particle physics)', 'Artificial intelligence', 'Natural language processing', 'Unsupervised learning', 'Psychology', 'Cognitive psychology', 'Linguistics', 'Telecommunications', 'Law', 'Chemistry', 'Philosophy', 'Criminology', 'Quantum mechanics', 'Biochemistry', 'Political science', 'Physics']","We describe an unsupervised system for learning narrative schemas, coherent sequences or sets of events (arrested(POLICE, SUSPECT), convicted(JUDGE, SUSPECT)) whose arguments are filled with participant semantic roles defined over words (Judge = {judge, jury, court}, Police = {police, agent, authorities}). Unlike most previous work in event structure or semantic role learning, our system does not use supervised techniques, hand-built knowledge, or predefined classes of events or roles. Our unsupervised learning algorithm uses coreferring arguments in chains of verbs to learn both rich narrative event structure and argument roles. By jointly addressing both tasks, we improve on previous results in narrative/frame learning and induce rich frame-specific semantic roles."
https://openalex.org/W2143296986,Unsupervised learning of natural languages,"{'We': [0], 'address': [1], 'the': [2], 'problem,': [3], 'fundamental': [4], 'to': [5, 20], 'linguistics,': [6], 'bioinformatics,': [7], 'and': [8, 71, 103, 105, 126], 'certain': [9], 'other': [10, 130], 'disciplines,': [11], 'of': [12, 15, 31, 60, 94, 118], 'using': [13], 'corpora': [14], 'raw': [16, 138], 'symbolic': [17], 'sequential': [18], 'data': [19, 108], 'infer': [21], 'underlying': [22], 'rules': [23], 'that': [24, 77, 132], 'govern': [25], 'their': [26], 'production.': [27], 'Given': [28], 'a': [29, 65], 'corpus': [30], 'strings': [32], '(such': [33], 'as': [34, 99, 101, 141], 'text,': [35], 'transcribed': [36], 'speech,': [37], 'chromosome': [38], 'or': [39], 'protein': [40, 107], 'sequence': [41, 110], 'data,': [42, 139], 'sheet': [43], 'music,': [44], 'etc.),': [45], 'our': [46], 'unsupervised': [47, 114], 'algorithm': [48, 62, 115], 'recursively': [49], 'distills': [50], 'from': [51, 137], 'it': [52], 'hierarchically': [53], 'structured': [54, 73], 'patterns.': [55], 'The': [56], 'adios': [57], '(automatic': [58], 'distillation': [59], 'structure)': [61], 'relies': [63], 'on': [64, 72, 88, 96, 106], 'statistical': [66], 'method': [67], 'for': [68, 134], 'pattern': [69], 'extraction': [70], 'generalization,': [74], 'two': [75], 'processes': [76], 'have': [78], 'been': [79, 86], 'implicated': [80], 'in': [81, 129], 'language': [82], 'acquisition.': [83], 'It': [84], 'has': [85], 'evaluated': [87], 'artificial': [89], 'context-free': [90], 'grammars': [91], 'with': [92, 111], 'thousands': [93], 'rules,': [95], 'natural': [97], 'languages': [98], 'diverse': [100], 'English': [102], 'Chinese,': [104], 'correlating': [109], 'function.': [112], 'This': [113], 'is': [116], 'capable': [117], 'learning': [119], 'complex': [120], 'syntax,': [121], 'generating': [122], 'grammatical': [123], 'novel': [124], 'sentences,': [125], 'proving': [127], 'useful': [128], 'fields': [131], 'call': [133], 'structure': [135], 'discovery': [136], 'such': [140], 'bioinformatics.': [142]}",2005,"['Computer science', 'Grammar induction', 'Natural language processing', 'Artificial intelligence', 'Syntax', 'Rule-based machine translation', 'Natural language', 'Generalization', 'Stochastic context-free grammar', 'Context (archaeology)', 'Context-free grammar', 'Unsupervised learning', 'Information extraction', 'Tree-adjoining grammar', 'Biology', 'Mathematics', 'Mathematical analysis', 'Paleontology']","We address the problem, fundamental to linguistics, bioinformatics, and certain other disciplines, of using corpora of raw symbolic sequential data to infer underlying rules that govern their production. Given a corpus of strings (such as text, transcribed speech, chromosome or protein sequence data, sheet music, etc.), our unsupervised algorithm recursively distills from it hierarchically structured patterns. The adios (automatic distillation of structure) algorithm relies on a statistical method for pattern extraction and on structured generalization, two processes that have been implicated in language acquisition. It has been evaluated on artificial context-free grammars with thousands of rules, on natural languages as diverse as English and Chinese, and on protein data correlating sequence with function. This unsupervised algorithm is capable of learning complex syntax, generating grammatical novel sentences, and proving useful in other fields that call for structure discovery from raw data, such as bioinformatics."
https://openalex.org/W2335728318,Reading digits in natural images with unsupervised feature learning,"{'Detecting': [0], 'and': [1, 35, 39, 154], 'reading': [2, 47, 96], 'text': [3], 'from': [4, 99, 121], 'natural': [5], 'images': [6], 'is': [7, 14, 60, 137], 'a': [8, 17, 88, 108], 'hard': [9], 'computer': [10, 33], 'vision': [11, 34], 'task': [12], 'that': [13, 156], 'central': [15], 'to': [16], 'variety': [18], 'of': [19, 84, 130, 146], 'emerging': [20], 'applications.': [21], 'Related': [22], 'problems': [23], 'like': [24, 46, 57], 'document': [25], 'character': [26], 'recognition': [27], 'have': [28], 'been': [29], 'widely': [30], 'studied': [31], 'by': [32], 'machine': [36], 'learning': [37, 94, 152], 'researchers': [38], 'are': [40, 158], 'virtually': [41], 'solved': [42], 'for': [43, 112], 'practical': [44], 'applications': [45], 'handwritten': [48], 'digits.': [49], 'Reliably': [50], 'recognizing': [51, 85, 131], 'characters': [52], 'in': [53, 87], 'more': [54, 62], 'complex': [55], 'scenes': [56], 'photographs,': [58], 'however,': [59], 'far': [61], 'difficult:': [63], 'the': [64, 74, 82, 128, 135], 'best': [65], 'existing': [66], 'methods': [67, 153], 'lag': [68], 'well': [69], 'behind': [70], 'human': [71], 'performance': [72], 'on': [73, 161], 'same': [75], 'tasks.': [76], 'In': [77], 'this': [78, 104], 'paper': [79], 'we': [80, 106, 143], 'attack': [81], 'problem': [83, 136], 'digits': [86, 119, 133], 'real': [89], 'application': [90], 'using': [91], 'unsupervised': [92, 150], 'feature': [93, 151], 'methods:': [95], 'house': [97], 'numbers': [98], 'street': [100], 'level': [101], 'photos.': [102], 'To': [103], 'end,': [105], 'introduce': [107], 'new': [109], 'benchmark': [110], 'dataset': [111], 'research': [113], 'use': [114], 'containing': [115], 'over': [116], '600,000': [117], 'labeled': [118], 'cropped': [120], 'Street': [122], 'View': [123], 'images.': [124], 'We': [125], 'then': [126], 'demonstrate': [127], 'difficulty': [129], 'these': [132], 'when': [134], 'approached': [138], 'with': [139], 'hand-designed': [140], 'features.': [141], 'Finally,': [142], 'employ': [144], 'variants': [145], 'two': [147], 'recently': [148], 'proposed': [149], 'find': [155], 'they': [157], 'convincingly': [159], 'superior': [160], 'our': [162], 'benchmarks.': [163], '1': [164]}",2024,"['Computer science', 'Artificial intelligence', 'Feature (linguistics)', 'Benchmark (surveying)', 'Reading (process)', 'Task (project management)', 'Unsupervised learning', 'Feature learning', 'Pattern recognition (psychology)', 'Variety (cybernetics)', 'Feature extraction', 'Machine learning', 'Deep learning', 'Natural language processing', 'Speech recognition', 'Geodesy', 'Management', 'Law', 'Philosophy', 'Political science', 'Economics', 'Linguistics', 'Geography']","Detecting and reading text from natural images is a hard computer vision task that is central to a variety of emerging applications. Related problems like document character recognition have been widely studied by computer vision and machine learning researchers and are virtually solved for practical applications like reading handwritten digits. Reliably recognizing characters in more complex scenes like photographs, however, is far more difficult: the best existing methods lag well behind human performance on the same tasks. In this paper we attack the problem of recognizing digits in a real application using unsupervised feature learning methods: reading house numbers from street level photos. To this end, we introduce a new benchmark dataset for research use containing over 600,000 labeled digits cropped from Street View images. We then demonstrate the difficulty of recognizing these digits when the problem is approached with hand-designed features. Finally, we employ variants of two recently proposed unsupervised feature learning methods and find that they are convincingly superior on our benchmarks. 1"
https://openalex.org/W2119018277,Comparison of Supervised and Unsupervised Learning Algorithms for Pattern Classification,"{'This': [0], 'paper': [1], 'presents': [2], 'a': [3, 26, 58], 'comparative': [4], 'account': [5], 'of': [6, 60, 65], 'unsupervised': [7, 66], 'and': [8, 12, 34, 72], 'supervised': [9, 51], 'learning': [10, 32, 46, 52, 67], 'models': [11], 'their': [13], 'pattern': [14], 'classification': [15, 73], 'evaluations': [16], 'as': [17, 48], 'applied': [18], 'to': [19], 'the': [20, 36, 43, 75], 'higher': [21], 'education': [22], 'scenario.': [23], 'Classification': [24], 'plays': [25], 'vital': [27], 'role': [28], 'in': [29, 35, 74], 'machine': [30], 'based': [31], 'algorithms': [33], 'present': [37, 76], 'study,': [38], 'we': [39], 'found': [40], 'that,': [41], 'though': [42], 'error': [44], 'back-propagation': [45], 'algorithm': [47], 'provided': [49], 'by': [50], 'model': [53], 'is': [54], 'very': [55], 'efficient': [56, 70], 'for': [57], 'number': [59], 'non-linear': [61], 'real-time': [62], 'problems,': [63], 'KSOM': [64], 'model,': [68], 'offers': [69], 'solution': [71], 'study.': [77]}",2013,"['Computer science', 'Unsupervised learning', 'Machine learning', 'Artificial intelligence', 'Semi-supervised learning', 'Wake-sleep algorithm', 'Supervised learning', 'Linear classifier', 'Statistical classification', 'Pattern recognition (psychology)', 'Generalization error', 'Support vector machine', 'Artificial neural network']","This paper presents a comparative account of unsupervised and supervised learning models and their pattern classification evaluations as applied to the higher education scenario. Classification plays a vital role in machine based learning algorithms and in the present study, we found that, though the error back-propagation learning algorithm as provided by supervised learning model is very efficient for a number of non-linear real-time problems, KSOM of unsupervised learning model, offers efficient solution and classification in the present study."
https://openalex.org/W2007815184,Unsupervised Learning of Visual Features through Spike Timing Dependent Plasticity,"{'Spike': [0], 'timing': [1, 19], 'dependent': [2], 'plasticity': [3], '(STDP)': [4], 'is': [5, 28, 35, 82], 'a': [6, 14, 26, 134], 'learning': [7, 61], 'rule': [8, 62], 'that': [9, 48, 70, 78, 100, 129, 148], 'modifies': [10], 'synaptic': [11, 44], 'strength': [12], 'as': [13, 118], 'function': [15], 'of': [16, 20, 41], 'the': [17, 39, 72, 80, 108, 138, 144], 'relative': [18], 'pre-': [21], 'and': [22, 76, 104, 113, 147, 154], 'postsynaptic': [23, 53], 'spikes.': [24], 'When': [25], 'neuron': [27], 'repeatedly': [29], 'presented': [30, 83], 'with': [31, 84], 'similar': [32], 'inputs,': [33], 'STDP': [34, 149], 'known': [36], 'to': [37, 88, 97, 136, 152], 'have': [38], 'effect': [40], 'concentrating': [42], 'high': [43], 'weights': [45], 'on': [46, 120], 'afferents': [47], 'systematically': [49], 'fire': [50], 'early,': [51], 'while': [52], 'spike': [54], 'latencies': [55], 'decrease.': [56], 'Here': [57], 'we': [58], 'use': [59], 'this': [60], 'in': [63, 107], 'an': [64], 'asynchronous': [65], 'feedforward': [66], 'spiking': [67], 'neural': [68], 'network': [69, 81], 'mimics': [71], 'ventral': [73], 'visual': [74, 90, 145], 'pathway': [75], 'shows': [77], 'when': [79], 'natural': [85], 'images,': [86, 109], 'selectivity': [87], 'intermediate-complexity': [89], 'features': [91], 'emerges.': [92], 'Those': [93], 'features,': [94], 'which': [95], 'correspond': [96], 'prototypical': [98], 'patterns': [99], 'are': [101, 110], 'both': [102], 'salient': [103], 'consistently': [105], 'present': [106], 'highly': [111], 'informative': [112], 'enable': [114], 'robust': [115], 'object': [116], 'recognition,': [117], 'demonstrated': [119], 'various': [121], 'classification': [122], 'tasks.': [123], 'Taken': [124], 'together,': [125], 'these': [126], 'results': [127], 'show': [128], 'temporal': [130], 'codes': [131], 'may': [132], 'be': [133], 'key': [135], 'understanding': [137], 'phenomenal': [139], 'processing': [140], 'speed': [141], 'achieved': [142], 'by': [143], 'system': [146], 'can': [150], 'lead': [151], 'fast': [153], 'selective': [155], 'responses.': [156]}",2007,"['Spike-timing-dependent plasticity', 'Computer science', 'Spike (software development)', 'Artificial intelligence', 'Postsynaptic potential', 'Learning rule', 'Feed forward', 'Neuroscience', 'Pattern recognition (psychology)', 'Synaptic plasticity', 'Visual processing', 'Artificial neural network', 'Biology', 'Perception', 'Software engineering', 'Control engineering', 'Receptor', 'Engineering', 'Biochemistry']","Spike timing dependent plasticity (STDP) is a learning rule that modifies synaptic strength as a function of the relative timing of pre- and postsynaptic spikes. When a neuron is repeatedly presented with similar inputs, STDP is known to have the effect of concentrating high synaptic weights on afferents that systematically fire early, while postsynaptic spike latencies decrease. Here we use this learning rule in an asynchronous feedforward spiking neural network that mimics the ventral visual pathway and shows that when the network is presented with natural images, selectivity to intermediate-complexity visual features emerges. Those features, which correspond to prototypical patterns that are both salient and consistently present in the images, are highly informative and enable robust object recognition, as demonstrated on various classification tasks. Taken together, these results show that temporal codes may be a key to understanding the phenomenal processing speed achieved by the visual system and that STDP can lead to fast and selective responses."
https://openalex.org/W3159156584,Unsupervised Learning Methods for Molecular Simulation Data,"{'Unsupervised': [0], 'learning': [1, 43], 'is': [2], 'becoming': [3], 'an': [4], 'essential': [5], 'tool': [6], 'to': [7, 50], 'analyze': [8, 133], 'the': [9, 39, 62, 106, 112, 121], 'increasingly': [10], 'large': [11], 'amounts': [12], 'of': [13, 38, 41, 70, 77, 111], 'data': [14, 53], 'produced': [15], 'by': [16], 'atomistic': [17], 'and': [18, 28, 54, 73, 82, 84, 108, 117, 119], 'molecular': [19, 71, 134], 'simulations,': [20], 'in': [21, 61, 124], 'material': [22], 'science,': [23], 'solid': [24], 'state': [25], 'physics,': [26], 'biophysics,': [27], 'biochemistry.': [29], 'In': [30, 64, 99], 'this': [31], 'Review,': [32], 'we': [33, 66, 102], 'provide': [34], 'a': [35, 96], 'comprehensive': [36], 'overview': [37], 'methods': [40], 'unsupervised': [42], 'that': [44], 'have': [45], 'been': [46, 128], 'most': [47], 'commonly': [48], 'used': [49], 'investigate': [51], 'simulation': [52, 135], 'indicate': [55], 'likely': [56], 'directions': [57], 'for': [58], 'further': [59], 'developments': [60], 'field.': [63], 'particular,': [65], 'discuss': [67], 'feature': [68], 'representation': [69], 'systems': [72], 'present': [74], 'state-of-the-art': [75], 'algorithms': [76], 'dimensionality': [78], 'reduction,': [79], 'density': [80], 'estimation,': [81], 'clustering,': [83], 'kinetic': [85], 'models.': [86], 'We': [87], 'divide': [88], 'our': [89], 'discussion': [90], 'into': [91], 'self-contained': [92], 'sections,': [93], 'each': [94, 100], 'discussing': [95], 'specific': [97, 122], 'method.': [98], 'section,': [101], 'briefly': [103], 'touch': [104], 'upon': [105], 'mathematical': [107], 'algorithmic': [109], 'foundations': [110], 'method,': [113], 'highlight': [114], 'its': [115], 'strengths': [116], 'limitations,': [118], 'describe': [120], 'ways': [123], 'which': [125], 'it': [126], 'has': [127], 'used-or': [129], 'can': [130], 'be': [131], 'used-to': [132], 'data.': [136]}",2021,"['Cluster analysis', 'Dimensionality reduction', 'Unsupervised learning', 'Representation (politics)', 'Field (mathematics)', 'Artificial intelligence', 'Feature (linguistics)', 'Curse of dimensionality', 'Computer science', 'Chemistry', 'Machine learning', 'Pure mathematics', 'Philosophy', 'Political science', 'Linguistics', 'Politics', 'Law', 'Mathematics']","Unsupervised learning is becoming an essential tool to analyze the increasingly large amounts of data produced by atomistic and molecular simulations, in material science, solid state physics, biophysics, and biochemistry. In this Review, we provide a comprehensive overview of the methods of unsupervised learning that have been most commonly used to investigate simulation data and indicate likely directions for further developments in the field. In particular, we discuss feature representation of molecular systems and present state-of-the-art algorithms of dimensionality reduction, density estimation, and clustering, and kinetic models. We divide our discussion into self-contained sections, each discussing a specific method. In each section, we briefly touch upon the mathematical and algorithmic foundations of the method, highlight its strengths and limitations, and describe the specific ways in which it has been used-or can be used-to analyze molecular simulation data."
https://openalex.org/W2401640538,Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning,"{'While': [0], 'great': [1], 'strides': [2], 'have': [3], 'been': [4], 'made': [5], 'in': [6, 46, 92, 99, 136, 190, 198], 'using': [7], 'deep': [8], 'learning': [9, 14, 20, 53, 56, 224], 'algorithms': [10], 'to': [11, 25, 88, 112, 123, 126, 170], 'solve': [12], 'supervised': [13], 'tasks,': [15], 'the': [16, 28, 58, 61, 76, 82, 100, 128, 139, 186, 191, 195, 205], 'problem': [17], 'of': [18, 30, 43, 60, 78, 130, 181, 188, 225], 'unsupervised': [19, 52, 219], '-': [21, 33], 'leveraging': [22], 'unlabeled': [23], 'examples': [24], 'learn': [26, 87, 125, 141], 'about': [27, 57], 'structure': [29, 59], 'a': [31, 35, 47, 66, 93, 215], 'domain': [32], 'remains': [34], 'difficult': [36], 'unsolved': [37], 'challenge.': [38], 'Here,': [39], 'we': [40], 'explore': [41], 'prediction': [42, 213], 'future': [44, 90], 'frames': [45, 91], 'video': [48, 94], 'sequence': [49], 'as': [50], 'an': [51], 'rule': [54], 'for': [55, 147, 203, 218, 222], 'visual': [62, 192], 'world.': [63], 'We': [64, 116, 162], 'describe': [65], 'predictive': [67], 'neural': [68], 'network': [69, 101, 114], '(""PredNet"")': [70], 'architecture': [71], 'that': [72, 118, 135, 144, 154, 165, 212], 'is': [73, 201], 'inspired': [74], 'by': [75], 'concept': [77], '""predictive': [79], 'coding""': [80], 'from': [81, 109], 'neuroscience': [83], 'literature.': [84], 'These': [85], 'networks': [86, 120, 140, 167], 'predict': [89, 127], 'sequence,': [95], 'with': [96, 158], 'each': [97], 'layer': [98], 'making': [102], 'local': [103], 'predictions': [104, 111], 'and': [105, 134, 185, 194, 227], 'only': [106], 'forwarding': [107], 'deviations': [108], 'those': [110], 'subsequent': [113], 'layers.': [115], 'show': [117, 164], 'these': [119, 166, 209], 'are': [121, 145], 'able': [122], 'robustly': [124], 'movement': [129, 184, 187], 'synthetic': [131], '(rendered)': [132], 'objects,': [133], 'doing': [137], 'so,': [138], 'internal': [142], 'representations': [143], 'useful': [146, 202], 'decoding': [148], 'latent': [149], 'object': [150, 156, 226], 'parameters': [151], '(e.g.': [152], 'pose)': [153], 'support': [155], 'recognition': [157], 'fewer': [159], 'training': [160], 'views.': [161], 'also': [163], 'can': [168], 'scale': [169], 'complex': [171], 'natural': [172], 'image': [173], 'streams': [174], '(car-mounted': [175], 'camera': [176], 'videos),': [177], 'capturing': [178], 'key': [179], 'aspects': [180], 'both': [182], 'egocentric': [183], 'objects': [189], 'scene,': [193], 'representation': [196], 'learned': [197], 'this': [199], 'setting': [200], 'estimating': [204], 'steering': [206], 'angle.': [207], 'Altogether,': [208], 'results': [210], 'suggest': [211], 'represents': [214], 'powerful': [216], 'framework': [217], 'learning,': [220], 'allowing': [221], 'implicit': [223], 'scene': [228], 'structure.': [229]}",2016,"['Computer science', 'Artificial intelligence', 'Unsupervised learning', 'Feature learning', 'Deep learning', 'Artificial neural network', 'Coding (social sciences)', 'Machine learning', 'Supervised learning', 'Predictive coding', 'Object (grammar)', 'Mathematics', 'Statistics']","While great strides have been made in using deep learning algorithms to solve supervised learning tasks, the problem of unsupervised learning - leveraging unlabeled examples to learn about the structure of a domain - remains a difficult unsolved challenge. Here, we explore prediction of future frames in a video sequence as an unsupervised learning rule for learning about the structure of the visual world. We describe a predictive neural network (""PredNet"") architecture that is inspired by the concept of ""predictive coding"" from the neuroscience literature. These networks learn to predict future frames in a video sequence, with each layer in the network making local predictions and only forwarding deviations from those predictions to subsequent network layers. We show that these networks are able to robustly learn to predict the movement of synthetic (rendered) objects, and that in doing so, the networks learn internal representations that are useful for decoding latent object parameters (e.g. pose) that support object recognition with fewer training views. We also show that these networks can scale to complex natural image streams (car-mounted camera videos), capturing key aspects of both egocentric movement and the movement of objects in the visual scene, and the representation learned in this setting is useful for estimating the steering angle. Altogether, these results suggest that prediction represents a powerful framework for unsupervised learning, allowing for implicit learning of object and scene structure."
https://openalex.org/W2594041373,Unsupervised learning of phase transitions: From principal component analysis to variational autoencoders,"{'We': [0, 60], 'examine': [1], 'unsupervised': [2], 'machine': [3], 'learning': [4], 'techniques': [5], 'to': [6, 35, 43, 79, 98], 'learn': [7], 'features': [8], 'that': [9, 62, 110], 'best': [10], 'describe': [11], 'configurations': [12, 46], 'of': [13, 87, 104], 'the': [14, 19, 54, 57, 63, 80, 88, 111], 'two-dimensional': [15], 'Ising': [16], 'model': [17], 'and': [18, 32, 47, 71], 'three-dimensional': [20], 'XY': [21], 'model.': [22], 'The': [23, 84], 'methods': [24, 34], 'range': [25], 'from': [26], 'principal': [27, 68], 'component': [28, 69], 'analysis': [29, 70], 'over': [30], 'manifold': [31], 'clustering': [33], 'artificial': [36], 'neural-network-based': [37], 'variational': [38, 72], 'autoencoders.': [39, 73], 'They': [40], 'are': [41, 67, 92], 'applied': [42], 'Monte': [44], 'Carlo-sampled': [45], 'have,': [48], 'a': [49, 119], 'priori,': [50], 'no': [51], 'knowledge': [52, 103], 'about': [53], 'Hamiltonian': [55], 'or': [56], 'order': [58, 82], 'parameter.': [59], 'find': [61, 109], 'most': [64], 'promising': [65], 'algorithms': [66], 'Their': [74], 'predicted': [75], 'latent': [76, 85], 'parameters': [77], 'correspond': [78], 'known': [81], 'parameters.': [83], 'representations': [86], 'models': [89], 'in': [90], 'question': [91], 'clustered,': [93], 'which': [94], 'makes': [95], 'it': [96], 'possible': [97], 'identify': [99], 'phases': [100], 'without': [101], 'prior': [102], 'their': [105], 'existence.': [106], 'Furthermore,': [107], 'we': [108], 'reconstruction': [112], 'loss': [113], 'function': [114], 'can': [115], 'be': [116], 'used': [117], 'as': [118], 'universal': [120], 'identifier': [121], 'for': [122], 'phase': [123], 'transitions.': [124]}",2017,"['Principal component analysis', 'A priori and a posteriori', 'Artificial intelligence', 'Cluster analysis', 'Unsupervised learning', 'Artificial neural network', 'Computer science', 'Ising model', 'Pattern recognition (psychology)', 'Latent variable', 'Monte Carlo method', 'Hamiltonian (control theory)', 'Machine learning', 'Algorithm', 'Mathematics', 'Statistical physics', 'Mathematical optimization', 'Physics', 'Philosophy', 'Epistemology', 'Statistics']","We examine unsupervised machine learning techniques to learn features that best describe configurations of the two-dimensional Ising model and the three-dimensional XY model. The methods range from principal component analysis over manifold and clustering methods to artificial neural-network-based variational autoencoders. They are applied to Monte Carlo-sampled configurations and have, a priori, no knowledge about the Hamiltonian or the order parameter. We find that the most promising algorithms are principal component analysis and variational autoencoders. Their predicted latent parameters correspond to the known order parameters. The latent representations of the models in question are clustered, which makes it possible to identify phases without prior knowledge of their existence. Furthermore, we find that the reconstruction loss function can be used as a universal identifier for phase transitions."
https://openalex.org/W1971014294,Unsupervised learning of hierarchical representations with convolutional deep belief networks,"{'There': [0], 'has': [1], 'been': [2], 'much': [3], 'interest': [4], 'in': [5, 82], 'unsupervised': [6], 'learning': [7], 'of': [8, 79, 105], 'hierarchical': [9, 43, 126], 'generative': [10, 44], 'models': [11, 21], 'such': [12, 20, 98], 'as': [13, 99], 'deep': [14, 38], 'belief': [15, 39], 'networks': [16], '(DBNs);': [17], 'however,': [18], 'scaling': [19], 'to': [22, 48, 65], 'full-sized,': [23], 'high-dimensional': [24], 'images': [25, 104], 'remains': [26], 'a': [27, 42, 72, 83], 'difficult': [28], 'problem.': [29], 'To': [30], 'address': [31], 'this': [32], 'problem,': [33], 'we': [34], 'present': [35], 'the': [36, 77, 91], 'convolutional': [37], 'network': [40], ',': [41, 71], 'model': [45, 53, 123], 'that': [46, 75, 90, 121], 'scales': [47], 'realistic': [49], 'image': [50], 'sizes.': [51], 'This': [52], 'is': [54, 68], 'translation-invariant': [55], 'and': [56, 60, 107, 119, 128], 'supports': [57], 'efficient': [58], 'bottom-up': [59], 'top-down': [61], 'probabilistic': [62, 69], 'inference.': [63], 'Key': [64], 'our': [66, 122], 'approach': [67], 'max-pooling': [70], 'novel': [73], 'technique': [74], 'shrinks': [76], 'representations': [78], 'higher': [80], 'layers': [81], 'probabilistically': [84], 'sound': [85], 'way.': [86], 'Our': [87], 'experiments': [88], 'show': [89, 120], 'algorithm': [92], 'learns': [93], 'useful': [94], 'high-level': [95], 'visual': [96, 116], 'features,': [97], 'object': [100], 'parts,': [101], 'from': [102], 'unlabeled': [103], 'objects': [106], 'natural': [108], 'scenes.': [109], 'We': [110], 'demonstrate': [111], 'excellent': [112], 'performance': [113], 'on': [114], 'several': [115], 'recognition': [117], 'tasks': [118], 'can': [124], 'perform': [125], '(bottom-up': [127], 'top-down)': [129], 'inference': [130], 'over': [131], 'full-sized': [132], 'images.': [133]}",2011,"['Computer science', 'Artificial intelligence', 'Deep belief network', 'Pooling', 'Generative model', 'Inference', 'Deep learning', 'Probabilistic logic', 'Convolutional neural network', 'Pattern recognition (psychology)', 'Unsupervised learning', 'Machine learning', 'Generative grammar']","There has been much interest in unsupervised learning of hierarchical generative models such as deep belief networks (DBNs); however, scaling such models to full-sized, high-dimensional images remains a difficult problem. To address this problem, we present the convolutional deep belief network , a hierarchical generative model that scales to realistic image sizes. This model is translation-invariant and supports efficient bottom-up and top-down probabilistic inference. Key to our approach is probabilistic max-pooling , a novel technique that shrinks the representations of higher layers in a probabilistically sound way. Our experiments show that the algorithm learns useful high-level visual features, such as object parts, from unlabeled images of objects and natural scenes. We demonstrate excellent performance on several visual recognition tasks and show that our model can perform hierarchical (bottom-up and top-down) inference over full-sized images."
https://openalex.org/W1982304603,Unsupervised learning techniques for an intrusion detection system,"{'With': [0], 'the': [1, 5, 60, 64, 72, 87, 97, 119, 124], 'continuous': [2], 'evolution': [3], 'of': [4, 7, 29, 63, 121], 'types': [6], 'attacks': [8], 'against': [9], 'computer': [10], 'networks,': [11], 'traditional': [12, 110], 'intrusion': [13, 45], 'detection': [14, 112], 'systems,': [15], 'based': [16], 'on': [17, 51, 123], 'pattern': [18], 'matching': [19], 'and': [20, 32], 'static': [21], 'signatures,': [22], 'are': [23], 'increasingly': [24], 'limited': [25], 'by': [26, 59, 70, 118], 'their': [27], 'need': [28], 'an': [30, 91], 'up-to-date': [31], 'comprehensive': [33], 'knowledge': [34], 'base.': [35], 'Data': [36], 'mining': [37, 49], 'techniques': [38, 50], 'have': [39], 'been': [40], 'successfully': [41], 'applied': [42], 'in': [43], 'host-based': [44], 'detection.': [46], 'Applying': [47], 'data': [48, 122], 'raw': [52], 'network': [53, 73, 98], 'data,': [54], 'however,': [55], 'is': [56, 67, 90, 108, 116], 'made': [57], 'difficult': [58], 'sheer': [61], 'size': [62], 'input;': [65], 'this': [66, 76, 85], 'usually': [68], 'avoided': [69], 'discarding': [71], 'packet': [74, 125], 'contents.In': [75], 'paper,': [77], 'we': [78], 'introduce': [79], 'a': [80, 102, 109], 'two-tier': [81], 'architecture': [82], 'to': [83, 101], 'overcome': [84], 'problem:': [86], 'first': [88], 'tier': [89, 107], 'unsupervised': [92], 'clustering': [93], 'algorithm': [94], 'which': [95], 'reduces': [96], 'packets': [99], 'payload': [100, 126], 'tractable': [103], 'size.': [104], 'The': [105], 'second': [106], 'anomaly': [111], 'algorithm,': [113], 'whose': [114], 'efficiency': [115], 'improved': [117], 'availability': [120], 'content.': [127]}",2004,"['Computer science', 'Intrusion detection system', 'Payload (computing)', 'Cluster analysis', 'Network packet', 'Data mining', 'Anomaly detection', 'Matching (statistics)', 'Unsupervised learning', 'Raw data', 'Artificial intelligence', 'Machine learning', 'Computer network', 'Programming language', 'Mathematics', 'Statistics']","With the continuous evolution of the types of attacks against computer networks, traditional intrusion detection systems, based on pattern matching and static signatures, are increasingly limited by their need of an up-to-date and comprehensive knowledge base. Data mining techniques have been successfully applied in host-based intrusion detection. Applying data mining techniques on raw network data, however, is made difficult by the sheer size of the input; this is usually avoided by discarding the network packet contents.In this paper, we introduce a two-tier architecture to overcome this problem: the first tier is an unsupervised clustering algorithm which reduces the network packets payload to a tractable size. The second tier is a traditional anomaly detection algorithm, whose efficiency is improved by the availability of data on the packet payload content."
https://openalex.org/W2950662112,Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations,"{'The': [0], 'key': [1], 'idea': [2], 'behind': [3], 'the': [4, 43, 55, 69, 72, 103, 111, 153, 168], 'unsupervised': [5, 28, 56], 'learning': [6, 29, 57, 136, 148], 'of': [7, 21, 58, 135, 155, 164, 167], 'disentangled': [8, 59], 'representations': [9, 60], 'is': [10, 14, 61], 'that': [11, 54, 101, 143], 'real-world': [12], 'data': [13, 97, 179], 'generated': [15], 'by': [16, 27, 110], 'a': [17, 36, 89, 131, 173], 'few': [18], 'explanatory': [19], 'factors': [20], 'variation': [22], 'which': [23], 'can': [24], 'be': [25, 118, 150], 'recovered': [26], 'algorithms.': [30], 'In': [31], 'this': [32], 'paper,': [33], 'we': [34, 75], 'provide': [35], 'sober': [37], 'look': [38], 'at': [39], 'recent': [40], 'progress': [41], 'in': [42, 88], 'field': [44], 'and': [45, 71, 85, 158, 171], 'challenge': [46], 'some': [47], 'common': [48], 'assumptions.': [49], 'We': [50, 99], 'first': [51], 'theoretically': [52], 'show': [53], 'fundamentally': [62], 'impossible': [63], 'without': [64, 120], 'inductive': [65, 156], 'biases': [66, 157], 'on': [67, 94, 146], 'both': [68], 'models': [70, 80, 115], 'data.': [73], 'Then,': [74], 'train': [76], 'more': [77], 'than': [78], '12000': [79], 'covering': [81, 177], 'most': [82], 'prominent': [83], 'methods': [84, 105], 'evaluation': [86], 'metrics': [87], 'reproducible': [90, 174], 'large-scale': [91], 'experimental': [92, 175], 'study': [93], 'seven': [95], 'different': [96, 104], 'sets.': [98, 180], 'observe': [100], 'while': [102], 'successfully': [106], 'enforce': [107], 'properties': [108], ""``encouraged''"": [109], 'corresponding': [112], 'losses,': [113], 'well-disentangled': [114], 'seemingly': [116], 'cannot': [117], 'identified': [119], 'supervision.': [121], 'Furthermore,': [122], 'increased': [123], 'disentanglement': [124, 147, 166], 'does': [125], 'not': [126], 'seem': [127], 'to': [128, 130], 'lead': [129], 'decreased': [132], 'sample': [133], 'complexity': [134], 'for': [137], 'downstream': [138], 'tasks.': [139], 'Our': [140], 'results': [141], 'suggest': [142], 'future': [144], 'work': [145], 'should': [149], 'explicit': [151], 'about': [152], 'role': [154], '(implicit)': [159], 'supervision,': [160], 'investigate': [161], 'concrete': [162], 'benefits': [163], 'enforcing': [165], 'learned': [169], 'representations,': [170], 'consider': [172], 'setup': [176], 'several': [178]}",2018,"['Computer science', 'Unsupervised learning', 'Artificial intelligence', 'Machine learning', 'Inductive bias', 'Variation (astronomy)', 'Sample complexity', 'Field (mathematics)', 'Scale (ratio)', 'Key (lock)', 'Multi-task learning', 'Mathematics', 'Physics', 'Economics', 'Pure mathematics', 'Management', 'Computer security', 'Quantum mechanics', 'Astrophysics', 'Task (project management)']","The key idea behind the unsupervised learning of disentangled representations is that real-world data is generated by a few explanatory factors of variation which can be recovered by unsupervised learning algorithms. In this paper, we provide a sober look at recent progress in the field and challenge some common assumptions. We first theoretically show that the unsupervised learning of disentangled representations is fundamentally impossible without inductive biases on both the models and the data. Then, we train more than 12000 models covering most prominent methods and evaluation metrics in a reproducible large-scale experimental study on seven different data sets. We observe that while the different methods successfully enforce properties ``encouraged'' by the corresponding losses, well-disentangled models seemingly cannot be identified without supervision. Furthermore, increased disentanglement does not seem to lead to a decreased sample complexity of learning for downstream tasks. Our results suggest that future work on disentanglement learning should be explicit about the role of inductive biases and (implicit) supervision, investigate concrete benefits of enforcing disentanglement of the learned representations, and consider a reproducible experimental setup covering several data sets."
https://openalex.org/W2162095731,Unsupervised Learning of Semantic Orientation from a Hundred-Billion-Word Corpus,"{'The': [0, 46, 65, 110, 120], 'evaluative': [1], 'character': [2], 'of': [3, 39, 74, 83, 108, 148], 'a': [4, 21, 33, 52, 71, 134], 'word': [5], 'is': [6, 67, 87, 122, 141], 'called': [7], 'its': [8], 'semantic': [9, 13, 23, 40, 146], 'orientation.': [10], 'A': [11], 'positive': [12, 99], 'orientation': [14, 24, 41, 147], 'implies': [15, 25], 'desirability': [16], '(e.g.,': [17, 27], '""honest"",': [18], '""intrepid"")': [19], 'and': [20, 56, 100, 118, 130], 'negative': [22], 'undesirability': [26], '""disturbing"",': [28], '""superfluous"").': [29], 'This': [30], 'paper': [31], 'introduces': [32], 'simple': [34], 'algorithm': [35, 66, 104, 139], 'for': [36], 'unsupervised': [37], 'learning': [38, 138], 'from': [42], 'extremely': [43], 'large': [44], 'corpora.': [45], 'method': [47], 'involves': [48], 'issuing': [49], 'queries': [50], 'to': [51, 61, 143], 'Web': [53, 85], 'search': [54, 92], 'engine': [55], 'using': [57, 70, 133], 'pointwise': [58], 'mutual': [59], 'information': [60], 'analyse': [62], 'the': [63, 81, 84, 90, 103, 125, 145], 'results.': [64], 'empirically': [68], 'evaluated': [69], 'training': [72], 'corpus': [73], 'approximately': [75], 'one': [76], 'hundred': [77], 'billion': [78], 'words': [79, 97, 113], '--': [80], 'subset': [82], 'that': [86, 140], 'indexed': [88], 'by': [89, 128], 'chosen': [91], 'engine.': [93], 'Tested': [94], 'with': [95, 124], '3,596': [96, 111], '(1,614': [98], '1,982': [101], 'negative),': [102], 'attains': [105], 'an': [106], 'accuracy': [107, 121], '80%.': [109], 'test': [112], 'include': [114], 'adjectives,': [115], 'adverbs,': [116], 'nouns,': [117], 'verbs.': [119], 'comparable': [123], 'results': [126], 'achieved': [127], 'Hatzivassiloglou': [129], 'McKeown': [131], '(1997),': [132], 'complex': [135], 'four-stage': [136], 'supervised': [137], 'restricted': [142], 'determining': [144], 'adjectives.': [149]}",2002,"['Pointwise mutual information', 'Pointwise', 'Natural language processing', 'Artificial intelligence', 'Computer science', 'Orientation (vector space)', 'Word (group theory)', 'Noun', 'Character (mathematics)', 'Simple (philosophy)', 'Information retrieval', 'Mutual information', 'Linguistics', 'Mathematics', 'Epistemology', 'Geometry', 'Mathematical analysis', 'Philosophy']","The evaluative character of a word is called its semantic orientation. A positive semantic orientation implies desirability (e.g., ""honest"", ""intrepid"") and a negative semantic orientation implies undesirability (e.g., ""disturbing"", ""superfluous""). This paper introduces a simple algorithm for unsupervised learning of semantic orientation from extremely large corpora. The method involves issuing queries to a Web search engine and using pointwise mutual information to analyse the results. The algorithm is empirically evaluated using a training corpus of approximately one hundred billion words -- the subset of the Web that is indexed by the chosen search engine. Tested with 3,596 words (1,614 positive and 1,982 negative), the algorithm attains an accuracy of 80%. The 3,596 test words include adjectives, adverbs, nouns, and verbs. The accuracy is comparable with the results achieved by Hatzivassiloglou and McKeown (1997), using a complex four-stage supervised learning algorithm that is restricted to determining the semantic orientation of adjectives."
https://openalex.org/W2152565110,Recursive unsupervised learning of finite mixture models,"{'There': [0], 'are': [1, 9], 'two': [2], 'open': [3], 'problems': [4], 'when': [5], 'finite': [6], 'mixture': [7, 40], 'densities': [8], 'used': [10, 64], 'to': [11, 80, 90], 'model': [12], 'multivariate': [13], 'data:': [14], 'the': [15, 18, 23, 36, 39, 45, 83, 92], 'selection': [16], 'of': [17, 20, 38, 47, 57], 'number': [19, 46, 56], 'components': [21], 'and': [22, 41, 89], 'initialization.': [24], 'In': [25], 'this': [26], 'paper,': [27], 'we': [28], 'propose': [29], 'an': [30], 'online': [31], '(recursive)': [32], 'algorithm': [33, 51, 77], 'that': [34, 42], 'estimates': [35], 'parameters': [37], 'simultaneously': [43], 'selects': [44], 'components.': [48, 60, 94], 'The': [49], 'new': [50], 'starts': [52], 'with': [53], 'a': [54, 66, 85], 'large': [55], 'randomly': [58], 'initialized': [59], 'A': [61, 72], 'prior': [62], 'is': [63, 78], 'as': [65], 'bias': [67], 'for': [68, 82], 'maximally': [69], 'structured': [70], 'models.': [71], 'stochastic': [73], 'approximation': [74], 'recursive': [75], 'learning': [76], 'proposed': [79], 'search': [81], 'maximum': [84], 'posteriori': [86], '(MAP)': [87], 'solution': [88], 'discard': [91], 'irrelevant': [93]}",2004,"['Initialization', 'A priori and a posteriori', 'Computer science', 'Maximum a posteriori estimation', 'Stochastic approximation', 'Artificial intelligence', 'Mixture model', 'Multivariate statistics', 'Unsupervised learning', 'Algorithm', 'Selection (genetic algorithm)', 'Expectation–maximization algorithm', 'Component (thermodynamics)', 'Pattern recognition (psychology)', 'Mathematics', 'Machine learning', 'Maximum likelihood', 'Statistics', 'Thermodynamics', 'Physics', 'Epistemology', 'Programming language', 'Philosophy', 'Computer security', 'Key (lock)']","There are two open problems when finite mixture densities are used to model multivariate data: the selection of the number of components and the initialization. In this paper, we propose an online (recursive) algorithm that estimates the parameters of the mixture and that simultaneously selects the number of components. The new algorithm starts with a large number of randomly initialized components. A prior is used as a bias for maximally structured models. A stochastic approximation recursive learning algorithm is proposed to search for the maximum a posteriori (MAP) solution and to discard the irrelevant components."
https://openalex.org/W2400532028,Unsupervised Learning for Physical Interaction through Video Prediction,"{'A': [0], 'core': [1], 'challenge': [2], 'for': [3, 26, 111], 'an': [4, 66], 'agent': [5], 'learning': [6, 27, 42, 149], 'to': [7, 13, 38, 43, 96, 101, 103, 148, 180], 'interact': [8], 'with': [9, 131], 'the': [10, 28, 143], 'world': [11], 'is': [12, 93], 'predict': [14], 'how': [15], 'its': [16, 21], 'actions': [17, 146], 'affect': [18], 'objects': [19], 'in': [20], 'environment.': [22], 'Many': [23], 'existing': [24], 'methods': [25], 'dynamics': [29], 'of': [30, 46, 120, 139, 153, 160], 'physical': [31, 59], 'interactions': [32, 123], 'require': [33], 'labeled': [34, 51], 'object': [35, 60, 97], 'information.': [36], 'However,': [37], 'scale': [39], 'real-world': [40, 112], 'interaction': [41], 'a': [44, 78, 118, 128, 150], 'variety': [45], 'scenes': [47], 'and': [48, 176], 'objects,': [49], 'acquiring': [50], 'data': [52], 'becomes': [53], 'increasingly': [54], 'impractical.': [55], 'To': [56, 107], 'learn': [57], 'about': [58], 'motion': [61, 82], 'without': [62], 'labels,': [63], 'we': [64, 115], 'develop': [65], 'action-conditioned': [67], 'video': [68, 109, 172], 'prediction': [69, 110, 138], 'model': [70, 88], 'that': [71, 165], 'explicitly': [72, 89], 'models': [73], 'pixel': [74, 81], 'motion,': [75, 91], 'by': [76], 'predicting': [77], 'distribution': [79], 'over': [80], 'from': [83], 'previous': [84], 'frames.': [85], 'Because': [86], 'our': [87, 166], 'predicts': [90], 'it': [92, 100], 'partially': [94], 'invariant': [95], 'appearance,': [98], 'enabling': [99], 'generalize': [102], 'previously': [104], 'unseen': [105], 'objects.': [106, 133], 'explore': [108], 'interactive': [113], 'agents,': [114], 'also': [116], 'introduce': [117], 'dataset': [119], '59,000': [121], 'robot': [122], 'involving': [124], 'pushing': [125], 'motions,': [126], 'including': [127], 'test': [129], 'set': [130], 'novel': [132], 'In': [134], 'this': [135], 'dataset,': [136], 'accurate': [137, 171], 'videos': [140], 'conditioned': [141], 'on': [142, 157], ""robot's"": [144], 'future': [145], 'amounts': [147], '""visual': [151], 'imagination""': [152], 'different': [154, 158], 'futures': [155], 'based': [156], 'courses': [159], 'action.': [161], 'Our': [162], 'experiments': [163], 'show': [164], 'proposed': [167], 'method': [168], 'produces': [169], 'more': [170], 'predictions': [173], 'both': [174], 'quantitatively': [175], 'qualitatively,': [177], 'when': [178], 'compared': [179], 'prior': [181], 'methods.': [182]}",2016,"['Artificial intelligence', 'Computer science', 'Object (grammar)', 'Motion (physics)', 'Action (physics)', 'Robot', 'Computer vision', 'Machine learning', 'Invariant (physics)', 'Set (abstract data type)', 'Mathematics', 'Quantum mechanics', 'Physics', 'Mathematical physics', 'Programming language']","A core challenge for an agent learning to interact with the world is to predict how its actions affect objects in its environment. Many existing methods for learning the dynamics of physical interactions require labeled object information. However, to scale real-world interaction learning to a variety of scenes and objects, acquiring labeled data becomes increasingly impractical. To learn about physical object motion without labels, we develop an action-conditioned video prediction model that explicitly models pixel motion, by predicting a distribution over pixel motion from previous frames. Because our model explicitly predicts motion, it is partially invariant to object appearance, enabling it to generalize to previously unseen objects. To explore video prediction for real-world interactive agents, we also introduce a dataset of 59,000 robot interactions involving pushing motions, including a test set with novel objects. In this dataset, accurate prediction of videos conditioned on the robot's future actions amounts to learning a ""visual imagination"" of different futures based on different courses of action. Our experiments show that our proposed method produces more accurate video predictions both quantitatively and qualitatively, when compared to prior methods."
https://openalex.org/W2031056773,Quantum speed-up for unsupervised learning,"{'International': [0], 'audience': [1]}",2012,"['Computer science', 'Cluster analysis', 'Unsupervised learning', 'Initialization', 'Graph', 'Speedup', 'Quantum', 'Quantum machine learning', 'Theoretical computer science', 'Quantization (signal processing)', 'Algorithm', 'Artificial intelligence', 'Quantum algorithm', 'Quantum mechanics', 'Programming language', 'Physics', 'Operating system']",International audience
https://openalex.org/W2619034550,Unsupervised Learning of Disentangled Representations from Video,"{'We': [0, 69], 'present': [1], 'a': [2, 22, 28, 35, 39, 50, 57, 74], 'new': [3], 'model': [4], 'DrNET': [5], 'that': [6, 30], 'learns': [7], 'disentangled': [8, 44], 'image': [9], 'representations': [10], 'from': [11], 'video.': [12], 'Our': [13], 'approach': [14, 72], 'leverages': [15], 'the': [16, 61, 82, 91], 'temporal': [17], 'coherence': [18], 'of': [19, 52, 66, 76, 88], 'video': [20], 'and': [21, 38, 78], 'novel': [23], 'adversarial': [24], 'loss': [25], 'to': [26, 60, 84], 'learn': [27], 'representation': [29, 45], 'factorizes': [31], 'each': [32], 'frame': [33], 'into': [34, 90], 'stationary': [36], 'part': [37], 'temporally': [40], 'varying': [41], 'component.': [42], 'The': [43], 'can': [46], 'be': [47], 'used': [48], 'for': [49], 'range': [51, 75], 'tasks.': [53], 'For': [54], 'example,': [55], 'applying': [56], 'standard': [58], 'LSTM': [59], 'time-vary': [62], 'components': [63], 'enables': [64], 'prediction': [65], 'future': [67], 'frames.': [68], 'evaluate': [70], 'our': [71], 'on': [73], 'synthetic': [77], 'real': [79], 'videos,': [80], 'demonstrating': [81], 'ability': [83], 'coherently': [85], 'generate': [86], 'hundreds': [87], 'steps': [89], 'future.': [92]}",2017,"['Representation (politics)', 'Computer science', 'Coherence (philosophical gambling strategy)', 'Artificial intelligence', 'Range (aeronautics)', 'Frame (networking)', 'Component (thermodynamics)', 'Feature learning', 'Adversarial system', 'Pattern recognition (psychology)', 'Mathematics', 'Politics', 'Telecommunications', 'Physics', 'Thermodynamics', 'Composite material', 'Statistics', 'Law', 'Materials science', 'Political science']","We present a new model DrNET that learns disentangled image representations from video. Our approach leverages the temporal coherence of video and a novel adversarial loss to learn a representation that factorizes each frame into a stationary part and a temporally varying component. The disentangled representation can be used for a range of tasks. For example, applying a standard LSTM to the time-vary components enables prediction of future frames. We evaluate our approach on a range of synthetic and real videos, demonstrating the ability to coherently generate hundreds of steps into the future."
https://openalex.org/W2153767712,Unsupervised learning of vowel categories from infant-directed speech,"{'Infants': [0], 'rapidly': [1], 'learn': [2], 'the': [3, 32, 42, 61, 87, 100, 117, 121, 143, 164, 174], 'sound': [4], 'categories': [5, 62, 90, 124, 179], 'of': [6, 34, 66, 89, 142], 'their': [7], 'native': [8], 'language,': [9], 'even': [10], 'though': [11], 'they': [12], 'do': [13], 'not': [14], 'receive': [15], 'explicit': [16], 'or': [17, 93, 113], 'focused': [18], 'training.': [19], 'Recent': [20], 'research': [21], 'suggests': [22], 'that': [23, 38, 176, 186], 'this': [24], 'learning': [25, 60, 184, 188], 'is': [26, 56], 'due': [27], 'to': [28, 31, 46, 91, 99, 106, 147, 162], ""infants'"": [29], 'sensitivity': [30], 'distribution': [33], 'speech': [35, 40, 178], 'sounds': [36], 'and': [37, 155, 185], 'infant-directed': [39, 115], 'contains': [41], 'distributional': [43, 183], 'information': [44, 76], 'needed': [45], 'form': [47], 'native-language': [48, 177], 'vowel': [49, 67, 79, 107, 123, 165], 'categories.': [50], 'An': [51], 'algorithm,': [52, 144], 'based': [53, 151], 'on': [54, 152], 'Expectation–Maximization,': [55], 'presented': [57], 'here': [58], 'for': [59, 131, 137], 'from': [63, 110], 'a': [64, 193], 'sequence': [65], 'tokens': [68, 108], 'without': [69], '(': [70, 81, 94], 'i': [71, 126], ')': [72, 83, 96], 'receiving': [73], 'any': [74], 'category': [75], 'with': [77], 'each': [78], 'token,': [80], 'ii': [82], 'knowing': [84], 'in': [85, 192], 'advance': [86], 'number': [88], 'learn,': [92], 'iii': [95], 'having': [97], 'access': [98], 'entire': [101], 'data': [102], 'ensemble.': [103], 'When': [104], 'exposed': [105], 'drawn': [109], 'either': [111], 'English': [112], 'Japanese': [114], 'speech,': [116], 'algorithm': [118], 'successfully': [119], 'discovered': [120], 'language-specific': [122], '(/': [125], ',': [127], 'i,': [128], 'ε,': [129], 'e/': [130], 'English,': [132], '/i,': [133], 'iː,': [134], 'e,': [135], 'eː/': [136], 'Japanese).': [138], 'A': [139], 'nonparametric': [140], 'version': [141], 'closely': [145], 'related': [146], 'neural': [148], 'network': [149], 'models': [150], 'topographic': [153], 'representation': [154], 'competitive': [156], 'Hebbian': [157], 'learning,': [158], 'also': [159], 'was': [160], 'able': [161], 'discover': [163], 'categories,': [166], 'albeit': [167], 'somewhat': [168], 'less': [169], 'reliably.': [170], 'These': [171], 'results': [172], 'reinforce': [173], 'proposal': [175], 'are': [180], 'acquired': [181], 'through': [182], 'such': [187], 'may': [189], 'be': [190], 'instantiated': [191], 'biologically': [194], 'plausible': [195], 'manner.': [196]}",2007,"['Vowel', 'Computer science', 'Language acquisition', 'Artificial intelligence', 'Speech recognition', 'Natural language processing', 'Vowel length', 'Psychology', 'Mathematics education']","Infants rapidly learn the sound categories of their native language, even though they do not receive explicit or focused training. Recent research suggests that this learning is due to infants' sensitivity to the distribution of speech sounds and that infant-directed speech contains the distributional information needed to form native-language vowel categories. An algorithm, based on Expectation–Maximization, is presented here for learning the categories from a sequence of vowel tokens without ( i ) receiving any category information with each vowel token, ( ii ) knowing in advance the number of categories to learn, or ( iii ) having access to the entire data ensemble. When exposed to vowel tokens drawn from either English or Japanese infant-directed speech, the algorithm successfully discovered the language-specific vowel categories (/ i , i, ε, e/ for English, /i, iː, e, eː/ for Japanese). A nonparametric version of the algorithm, closely related to neural network models based on topographic representation and competitive Hebbian learning, also was able to discover the vowel categories, albeit somewhat less reliably. These results reinforce the proposal that native-language speech categories are acquired through distributional learning and that such learning may be instantiated in a biologically plausible manner."
https://openalex.org/W2943495267,Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences,"{'Abstract': [0], 'In': [1, 31], 'the': [2, 32, 35, 51, 124, 146], 'field': [3], 'of': [4, 9, 38, 53, 126, 129, 135, 164, 170], 'artificial': [5, 63], 'intelligence,': [6], 'a': [7, 56, 76, 118, 162], 'combination': [8], 'scale': [10, 52], 'in': [11, 25, 102, 145], 'data': [12, 42, 111], 'and': [13, 28, 61, 140, 148, 173, 176], 'model': [14, 80, 96], 'capacity': [15], 'enabled': [16], 'by': [17, 152], 'un-supervised': [18], 'learning': [19, 27, 73, 156], 'has': [20, 117], 'led': [21], 'to': [22, 74, 132], 'major': [23], 'advances': [24], 'representation': [26, 115], 'statistical': [29], 'generation.': [30], 'life': [33], 'sciences,': [34], 'anticipated': [36], 'growth': [37], 'sequencing': [39], 'promises': [40], 'unprecedented': [41], 'on': [43, 81], 'natural': [44], 'sequence': [45, 110], 'diversity.': [46, 93], 'Protein': [47], 'language': [48, 79], 'modeling': [49], 'at': [50], 'evolution': [54], 'is': [55, 143], 'logical': [57], 'step': [58], 'toward': [59], 'predictive': [60], 'generative': [62], 'intelligence': [64], 'for': [65, 180], 'biology.': [66], 'To': [67], 'this': [68], 'end': [69], 'we': [70], 'use': [71], 'unsupervised': [72], 'train': [75], 'deep': [77], 'contextual': [78], '86': [82], 'billion': [83], 'amino': [84, 130], 'acids': [85, 131], 'across': [86, 161], '250': [87], 'million': [88], 'protein': [89], 'sequences': [90], 'spanning': [91], 'evolutionary': [92], 'The': [94, 105, 113], 'resulting': [95], 'contains': [97], 'information': [98], 'about': [99, 138], 'biological': [100], 'properties': [101, 128], 'its': [103], 'representations.': [104], 'representations': [106, 147], 'are': [107], 'learned': [108, 114], 'from': [109, 123], 'alone.': [112], 'space': [116], 'multi-scale': [119], 'organization': [120], 'reflecting': [121], 'structure': [122, 142], 'level': [125], 'biochemical': [127], 'remote': [133], 'homology': [134], 'proteins.': [136], 'Information': [137], 'secondary': [139, 174], 'tertiary': [141], 'encoded': [144], 'can': [149], 'be': [150], 'identified': [151], 'linear': [153], 'projections.': [154], 'Representation': [155], 'produces': [157], 'features': [158, 179], 'that': [159], 'generalize': [160], 'range': [163], 'applications,': [165], 'enabling': [166], 'state-of-the-art': [167, 178], 'supervised': [168], 'prediction': [169], 'mutational': [171], 'effect': [172], 'structure,': [175], 'improving': [177], 'long-range': [181], 'contact': [182], 'prediction.': [183]}",2019,"['Artificial intelligence', 'Representation (politics)', 'Computer science', 'Unsupervised learning', 'Machine learning', 'Generative model', 'Protein tertiary structure', 'Protein structure prediction', 'Sequence space', 'Sequence (biology)', 'Generative grammar', 'Protein structure', 'Biology', 'Mathematics', 'Law', 'Biochemistry', 'Political science', 'Genetics', 'Pure mathematics', 'Politics', 'Banach space']","Abstract In the field of artificial intelligence, a combination of scale in data and model capacity enabled by un-supervised learning has led to major advances in representation learning and statistical generation. In the life sciences, the anticipated growth of sequencing promises unprecedented data on natural sequence diversity. Protein language modeling at the scale of evolution is a logical step toward predictive and generative artificial intelligence for biology. To this end we use unsupervised learning to train a deep contextual language model on 86 billion amino acids across 250 million protein sequences spanning evolutionary diversity. The resulting model contains information about biological properties in its representations. The representations are learned from sequence data alone. The learned representation space has a multi-scale organization reflecting structure from the level of biochemical properties of amino acids to remote homology of proteins. Information about secondary and tertiary structure is encoded in the representations and can be identified by linear projections. Representation learning produces features that generalize across a range of applications, enabling state-of-the-art supervised prediction of mutational effect and secondary structure, and improving state-of-the-art features for long-range contact prediction."
https://openalex.org/W2556930864,Unsupervised learning of spoken language with visual context,"{'Humans': [0], 'learn': [1], 'to': [2, 92], 'speak': [3], 'before': [4], 'they': [5], 'can': [6], 'read': [7], 'or': [8], 'write,': [9], 'so': [10], 'why': [11], ""can't"": [12], 'computers': [13], 'do': [14], 'the': [15, 43, 52, 65, 97], 'same?': [16], 'In': [17], 'this': [18], 'paper,': [19], 'we': [20], 'present': [21], 'a': [22], 'deep': [23], 'neural': [24], 'network': [25], 'model': [26, 72, 89], 'capable': [27], 'of': [28, 45, 54, 58], 'rudimentary': [29], 'spoken': [30, 61], 'language': [31], 'acquisition': [32], 'using': [33], 'untranscribed': [34], 'audio': [35, 62], 'training': [36], 'data,': [37], 'whose': [38], 'only': [39], 'supervision': [40], 'comes': [41], 'in': [42], 'form': [44], 'contextually': [46], 'relevant': [47], 'visual': [48], 'images.': [49], 'We': [50, 80], 'describe': [51], 'collection': [53], 'our': [55, 71, 88], 'data': [56], 'comprised': [57], 'over': [59], '120,000': [60], 'captions': [63], 'for': [64], 'Places': [66], 'image': [67, 75], 'dataset': [68], 'and': [69, 77], 'evaluate': [70], 'on': [73], 'an': [74], 'search': [76], 'annotation': [78], 'task.': [79], 'also': [81], 'provide': [82], 'some': [83], 'visualizations': [84], 'which': [85], 'suggest': [86], 'that': [87], 'is': [90], 'learning': [91], 'recognize': [93], 'meaningful': [94], 'words': [95], 'within': [96], 'caption': [98], 'spectrograms.': [99]}",2016,"['Computer science', 'Annotation', 'Artificial intelligence', 'Spectrogram', 'Natural language processing', 'Context (archaeology)', 'Spoken language', 'Speech recognition', 'Task (project management)', 'Artificial neural network', 'Deep learning', 'Biology', 'Paleontology', 'Economics', 'Management']","Humans learn to speak before they can read or write, so why can't computers do the same? In this paper, we present a deep neural network model capable of rudimentary spoken language acquisition using untranscribed audio training data, whose only supervision comes in the form of contextually relevant visual images. We describe the collection of our data comprised of over 120,000 spoken audio captions for the Places image dataset and evaluate our model on an image search and annotation task. We also provide some visualizations which suggest that our model is learning to recognize meaningful words within the caption spectrograms."
https://openalex.org/W2953259386,Unsupervised Learning of Visual Representations using Videos,"{'Is': [0], 'strong': [1], 'supervision': [2], 'necessary': [3], 'for': [4, 36], 'learning': [5, 38], 'a': [6, 20, 30, 73, 97, 101, 112, 155], 'good': [7], 'visual': [8, 55, 62, 78], 'representation?': [9], 'Do': [10], 'we': [11, 28, 42, 127], 'really': [12], 'need': [13], 'millions': [14], 'of': [15, 39, 45, 47, 131, 157], 'semantically-labeled': [16], 'images': [17], 'to': [18, 53, 88, 105, 147], 'train': [19, 106, 128], 'Convolutional': [21], 'Neural': [22], 'Network': [23], '(CNN)?': [24], 'In': [25], 'this': [26, 107], 'paper,': [27], 'present': [29], 'simple': [31], 'yet': [32], 'surprisingly': [33], 'powerful': [34], 'approach': [35], 'unsupervised': [37, 132, 164], 'CNN.': [40], 'Specifically,': [41], 'use': [43], 'hundreds': [44], 'thousands': [46], 'unlabeled': [48, 120], 'videos': [49, 121], 'from': [50, 115], 'the': [51, 65, 89, 123], 'web': [52], 'learn': [54], 'representations.': [56], 'Our': [57], 'key': [58], 'idea': [59], 'is': [60], 'that': [61, 134, 162], 'tracking': [63], 'provides': [64], 'supervision.': [66], 'That': [67], 'is,': [68], 'two': [69], 'patches': [70], 'connected': [71], 'by': [72], 'track': [74], 'should': [75], 'have': [76], 'similar': [77], 'representation': [79], 'in': [80, 169], 'deep': [81], 'feature': [82], 'space': [83], 'since': [84], 'they': [85], 'probably': [86], 'belong': [87], 'same': [90], 'object': [91, 93], 'or': [92], 'part.': [94], 'We': [95, 159], 'design': [96], 'Siamese-triplet': [98], 'network': [99, 165], 'with': [100], 'ranking': [102], 'loss': [103], 'function': [104], 'CNN': [108], 'representation.': [109], 'Without': [110], 'using': [111, 118], 'single': [113], 'image': [114], 'ImageNet,': [116], 'just': [117], '100K': [119], 'and': [122], 'VOC': [124], '2012': [125], 'dataset,': [126], 'an': [129, 151], 'ensemble': [130, 152], 'networks': [133], 'achieves': [135, 154], '52%': [136], 'mAP': [137, 156], '(no': [138], 'bounding': [139], 'box': [140], 'regression).': [141], 'This': [142], 'performance': [143], 'comes': [144], 'tantalizingly': [145], 'close': [146], 'its': [148], 'ImageNet-supervised': [149], 'counterpart,': [150], 'which': [153], '54.4%.': [158], 'also': [160], 'show': [161], 'our': [163], 'can': [166], 'perform': [167], 'competitively': [168], 'other': [170], 'tasks': [171], 'such': [172], 'as': [173], 'surface-normal': [174], 'estimation.': [175]}",2015,"['Computer science', 'Artificial intelligence', 'Representation (politics)', 'Convolutional neural network', 'Unsupervised learning', 'Bounding overwatch', 'Feature learning', 'Pattern recognition (psychology)', 'Object (grammar)', 'Ranking (information retrieval)', 'Deep learning', 'Minimum bounding box', 'Machine learning', 'Visualization', 'Feature (linguistics)', 'Image (mathematics)', 'Linguistics', 'Law', 'Philosophy', 'Political science', 'Politics']","Is strong supervision necessary for learning a good visual representation? Do we really need millions of semantically-labeled images to train a Convolutional Neural Network (CNN)? In this paper, we present a simple yet surprisingly powerful approach for unsupervised learning of CNN. Specifically, we use hundreds of thousands of unlabeled videos from the web to learn visual representations. Our key idea is that visual tracking provides the supervision. That is, two patches connected by a track should have similar visual representation in deep feature space since they probably belong to the same object or object part. We design a Siamese-triplet network with a ranking loss function to train this CNN representation. Without using a single image from ImageNet, just using 100K unlabeled videos and the VOC 2012 dataset, we train an ensemble of unsupervised networks that achieves 52% mAP (no bounding box regression). This performance comes tantalizingly close to its ImageNet-supervised counterpart, an ensemble which achieves a mAP of 54.4%. We also show that our unsupervised network can perform competitively in other tasks such as surface-normal estimation."
https://openalex.org/W2951261569,Unsupervised Learning of Depth and Ego-Motion from Video,"{'We': [0, 20], 'present': [1], 'an': [2], 'unsupervised': [3], 'learning': [4], 'framework': [5], 'for': [6, 89], 'the': [7, 33, 39, 48, 65, 69], 'task': [8, 34], 'of': [9, 35, 71], 'monocular': [10, 75], 'depth': [11, 26, 76, 88], 'and': [12, 27, 91], 'camera': [13, 28], 'motion': [14], 'estimation': [15, 30, 94], 'from': [16], 'unstructured': [17], 'video': [18], 'sequences.': [19], 'achieve': [21], 'this': [22], 'by': [23], 'simultaneously': [24], 'training': [25], 'pose': [29, 86, 93], 'networks': [31, 43], 'using': [32], 'view': [36, 49], 'synthesis': [37, 50], 'as': [38], 'supervisory': [40], 'signal.': [41], 'The': [42], 'are': [44], 'thus': [45], 'coupled': [46], 'via': [47], 'objective': [51], 'during': [52], 'training,': [53, 90], 'but': [54], 'can': [55], 'be': [56], 'applied': [57], 'independently': [58], 'at': [59], 'test': [60], 'time.': [61], 'Empirical': [62], 'evaluation': [63], 'on': [64], 'KITTI': [66], 'dataset': [67], 'demonstrates': [68], 'effectiveness': [70], 'our': [72], 'approach:': [73], '1)': [74], 'performing': [77, 95], 'comparably': [78], 'with': [79, 97], 'supervised': [80], 'methods': [81], 'that': [82], 'use': [83], 'either': [84], 'ground-truth': [85], 'or': [87], '2)': [92], 'favorably': [96], 'established': [98], 'SLAM': [99], 'systems': [100], 'under': [101], 'comparable': [102], 'input': [103], 'settings.': [104]}",2017,"['Artificial intelligence', 'Computer science', 'Monocular', 'Task (project management)', 'Computer vision', 'Motion (physics)', 'Ground truth', 'Unsupervised learning', 'Training (meteorology)', 'SIGNAL (programming language)', 'Motion estimation', 'Geography', 'Engineering', 'Systems engineering', 'Programming language', 'Meteorology']","We present an unsupervised learning framework for the task of monocular depth and camera motion estimation from unstructured video sequences. We achieve this by simultaneously training depth and camera pose estimation networks using the task of view synthesis as the supervisory signal. The networks are thus coupled via the view synthesis objective during training, but can be applied independently at test time. Empirical evaluation on the KITTI dataset demonstrates the effectiveness of our approach: 1) monocular depth performing comparably with supervised methods that use either ground-truth pose or depth for training, and 2) pose estimation performing favorably with established SLAM systems under comparable input settings."
https://openalex.org/W3146384714,Extraction of organic chemistry grammar from unsupervised learning of chemical reactions,"{'RXNmapper': [0], 'constructs': [1], 'coherent': [2], 'atom-mapping': [3], 'rules': [4], 'from': [5], 'raw': [6], 'chemical': [7], 'reactions': [8], 'using': [9], 'unsupervised': [10], 'training': [11], 'of': [12], 'neural': [13], 'networks.': [14]}",2021,"['Extraction (chemistry)', 'Computer science', 'Grammar', 'Chemistry', 'Artificial intelligence', 'Organic chemistry', 'Linguistics', 'Philosophy']",RXNmapper constructs coherent atom-mapping rules from raw chemical reactions using unsupervised training of neural networks.
https://openalex.org/W2810701348,Unsupervised learning by competing hidden units,"{'It': [0], 'is': [1, 11, 52, 74, 114, 151], 'widely': [2], 'believed': [3], 'that': [4, 26, 40, 79, 105, 144], 'end-to-end': [5, 161], 'training': [6], 'with': [7, 162], 'the': [8, 32, 36, 44, 47, 56, 82, 92, 95, 110, 145, 148, 154], 'backpropagation': [9, 51, 164], 'algorithm': [10, 104, 165], 'essential': [12], 'for': [13, 31], 'learning': [14, 63, 103, 117], 'good': [15], 'feature': [16, 119, 129], 'detectors': [17, 28, 120, 130], 'in': [18, 109, 121, 138], 'early': [19, 118], 'layers': [20, 38], 'of': [21, 39, 50, 69, 81, 94, 116, 147, 156], 'artificial': [22], 'neural': [23, 41], 'networks,': [24], 'so': [25, 143], 'these': [27], 'are': [29], 'useful': [30], 'task': [33], 'performed': [34], 'by': [35, 76], 'higher': [37], 'network.': [42], 'At': [43], 'same': [45], 'time,': [46], 'traditional': [48], 'form': [49], 'biologically': [53], 'implausible.': [54], 'In': [55], 'present': [57], 'paper': [58], 'we': [59], 'propose': [60], 'an': [61], 'unusual': [62], 'rule,': [64], 'which': [65, 73], 'has': [66], 'a': [67, 102, 122, 139, 163], 'degree': [68], 'biological': [70], 'plausibility': [71], 'and': [72, 97, 113], 'motivated': [75], 'Hebb’s': [77], 'idea': [78], 'change': [80], 'synapse': [83], 'strength': [84], 'should': [85, 88], 'be': [86, 132], 'local—i.e.,': [87], 'depend': [89], 'only': [90], 'on': [91, 166], 'activities': [93], 'pre-': [96], 'postsynaptic': [98], 'neurons.': [99], 'We': [100], 'design': [101], 'utilizes': [106], 'global': [107], 'inhibition': [108], 'hidden': [111], 'layer': [112], 'capable': [115], 'completely': [123], 'unsupervised': [124], 'way.': [125], 'These': [126], 'learned': [127], 'lower-layer': [128], 'can': [131], 'used': [133], 'to': [134, 153], 'train': [135], 'higher-layer': [136], 'weights': [137], 'usual': [140], 'supervised': [141], 'way': [142], 'performance': [146, 155], 'full': [149], 'network': [150], 'comparable': [152], 'standard': [157], 'feedforward': [158], 'networks': [159], 'trained': [160], 'simple': [167], 'tasks.': [168]}",2019,"['Backpropagation', 'Artificial intelligence', 'Computer science', 'Artificial neural network', 'Feature (linguistics)', 'Feed forward', 'Unsupervised learning', 'Learning rule', 'Layer (electronics)', 'Supervised learning', 'Feedforward neural network', 'Task (project management)', 'Pattern recognition (psychology)', 'Competitive learning', 'Machine learning', 'Engineering', 'Philosophy', 'Control engineering', 'Organic chemistry', 'Chemistry', 'Linguistics', 'Systems engineering']","It is widely believed that end-to-end training with the backpropagation algorithm is essential for learning good feature detectors in early layers of artificial neural networks, so that these detectors are useful for the task performed by the higher layers of that neural network. At the same time, the traditional form of backpropagation is biologically implausible. In the present paper we propose an unusual learning rule, which has a degree of biological plausibility and which is motivated by Hebb’s idea that change of the synapse strength should be local—i.e., should depend only on the activities of the pre- and postsynaptic neurons. We design a learning algorithm that utilizes global inhibition in the hidden layer and is capable of learning early feature detectors in a completely unsupervised way. These learned lower-layer feature detectors can be used to train higher-layer weights in a usual supervised way so that the performance of the full network is comparable to the performance of standard feedforward networks trained end-to-end with a backpropagation algorithm on simple tasks."
https://openalex.org/W2169147927,Unsupervised Learning of Morphology,"{'This': [0], 'article': [1], 'surveys': [2], 'work': [3, 61], 'on': [4], 'Unsupervised': [5, 11], 'Learning': [6, 12], 'of': [7, 13, 18, 29, 41, 52, 60], 'Morphology.': [8], 'We': [9, 44, 79], 'define': [10], 'Morphology': [14], 'as': [15], 'the': [16, 48, 53, 69, 74, 81], 'problem': [17], 'inducing': [19], 'a': [20, 42, 65], 'description': [21], '(of': [22], 'some': [23], 'kind,': [24], 'even': [25], 'if': [26], 'only': [27, 37], 'morpheme-segmentation)': [28], 'how': [30], 'orthographic': [31], 'words': [32], 'are': [33, 62, 76], 'built': [34], 'up': [35], 'given': [36], 'raw': [38], 'text': [39], 'data': [40], 'language.': [43], 'briefly': [45], 'go': [46], 'through': [47], 'history': [49], 'and': [50, 68, 85], 'motivation': [51], 'this': [54], 'problem.': [55], 'Next,': [56], 'over': [57], '200': [58], 'items': [59], 'listed': [63], 'with': [64], 'brief': [66], 'characterization,': [67], 'most': [70], 'important': [71], 'ideas': [72], 'in': [73], 'field': [75], 'critically': [77], 'discussed.': [78], 'summarize': [80], 'achievements': [82], 'so': [83], 'far': [84], 'give': [86], 'pointers': [87], 'for': [88], 'future': [89], 'developments.': [90]}",2011,"['Morpheme', 'Computer science', 'Artificial intelligence', 'Unsupervised learning', 'Morphology (biology)', 'Field (mathematics)', 'Natural language processing', 'Segmentation', 'Linguistics', 'Genetics', 'Mathematics', 'Pure mathematics', 'Philosophy', 'Biology']","This article surveys work on Unsupervised Learning of Morphology. We define Unsupervised Learning of Morphology as the problem of inducing a description (of some kind, even if only morpheme-segmentation) of how orthographic words are built up given only raw text data of a language. We briefly go through the history and motivation of the this problem. Next, over 200 items of work are listed with a brief characterization, and the most important ideas in the field are critically discussed. We summarize the achievements so far and give pointers for future developments."
https://openalex.org/W2905885786,Unsupervised Learning-Based Fast Beamforming Design for Downlink MIMO,"{'©': [0], '2018': [1], 'IEEE.': [2], 'Personal': [3], 'use': [4], 'of': [5, 49, 53], 'this': [6, 28, 54], 'material': [7, 29], 'is': [8], 'permitted.': [9], 'Permission': [10], 'from': [11], 'IEEE': [12], 'must': [13], 'be': [14], 'obtained': [15], 'for': [16, 30, 39], 'all': [17], 'other': [18, 57], 'uses,': [19], 'in': [20, 56], 'any': [21, 50], 'current': [22], 'or': [23, 32, 41, 45, 47], 'future': [24], 'media,': [25], 'including': [26], 'reprinting/republishing': [27], 'advertising': [31], 'promotional': [33], 'purposes,': [34], 'creating': [35], 'new': [36], 'collective': [37], 'works,': [38], 'resale': [40], 'redistribution': [42], 'to': [43], 'servers': [44], 'lists,': [46], 'reuse': [48], 'copyrighted': [51], 'component': [52], 'work': [55], 'works.': [58]}",2018,"['Computer science', 'Beamforming', 'Computational complexity theory', 'MIMO', 'Pruning', 'Telecommunications link', 'Artificial neural network', 'Transmitter', 'Minimum mean square error', 'Algorithm', 'Channel (broadcasting)', 'Artificial intelligence', 'Mathematics', 'Telecommunications', 'Estimator', 'Biology', 'Statistics', 'Agronomy']","© 2018 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works."
https://openalex.org/W3042615550,Unsupervised Learning of Image Segmentation Based on Differentiable Feature Clustering,"{'The': [0, 89, 179], 'usage': [1], 'of': [2, 33, 54, 70, 81, 107, 126, 138, 161, 181, 190], 'convolutional': [3], 'neural': [4], 'networks': [5, 169], '(CNNs)': [6], 'for': [7, 112, 141], 'unsupervised': [8], 'image\\nsegmentation': [9], 'was': [10, 185], 'investigated': [11], 'in': [12], 'this': [13], 'study.': [14], 'In': [15], 'the': [16, 39, 48, 52, 64, 68, 85, 124, 162, 182], 'proposed': [17, 65, 163, 183], 'approach,': [18], 'label\\nprediction': [19], 'and': [20, 72, 109], 'network': [21, 101], 'parameter': [22], 'learning': [23], 'are': [24, 93], 'alternately': [25], 'iterated': [26], 'to': [27, 76], 'meet': [28], 'the\\nfollowing': [29], 'criteria:': [30], '(a)': [31], 'pixels': [32, 44], 'similar': [34], 'features': [35], 'should': [36, 45, 57], 'be': [37, 46, 58], 'assigned': [38, 47], 'same\\nlabel,': [40], '(b)': [41], 'spatially': [42], 'continuous': [43], 'same': [49], 'label,': [50], 'and\\n(c)': [51], 'number': [53], 'unique': [55], 'labels': [56], 'large.': [59], 'Although': [60], 'these': [61], 'criteria': [62, 87], 'are\\nincompatible,': [63], 'approach': [66, 184], 'minimizes': [67], 'combination': [69], 'similarity\\nloss': [71], 'spatial': [73], 'continuity': [74], 'loss': [75, 120], 'find': [77], 'a': [78, 98, 118, 172], 'plausible': [79], 'solution': [80], 'label\\nassignment': [82], 'that': [83, 105, 122], 'balances': [84], 'aforementioned': [86], 'well.': [88], 'contributions': [90], 'of\\nthis': [91], 'study': [92], 'four-fold.': [94], 'First,': [95], 'we': [96, 116, 134], 'propose': [97], 'novel': [99], 'end-to-end': [100], 'of\\nunsupervised': [102], 'image': [103, 166, 191], 'segmentation': [104, 142], 'consists': [106], 'normalization': [108], 'an': [110, 136], 'argmax\\nfunction': [111], 'differentiable': [113], 'clustering.': [114], 'Second,': [115], 'introduce': [117], 'spatial\\ncontinuity': [119], 'function': [121], 'mitigates': [123], 'limitations': [125], 'fixed': [127], 'segment\\nboundaries': [128], 'possessed': [129], 'by': [130], 'previous': [131], 'work.': [132], 'Third,': [133], 'present': [135], 'extension': [137, 160], 'the\\nproposed': [139], 'method': [140], 'with': [143, 171], 'scribbles': [144], 'as': [145], 'user': [146], 'input,': [147], 'which': [148], 'showed\\nbetter': [149], 'accuracy': [150], 'than': [151], 'existing': [152], 'methods': [153], 'while': [154], 'maintaining': [155], 'efficiency.': [156], 'Finally,': [157], 'we\\nintroduce': [158], 'another': [159], 'method:': [164], 'unseen': [165], 'segmentation\\nby': [167], 'using': [168], 'pre-trained': [170], 'few': [173], 'reference': [174], 'images': [175], 'without': [176], 're-training\\nthe': [177], 'networks.': [178], 'effectiveness': [180], 'examined': [186], 'on\\nseveral': [187], 'benchmark': [188], 'datasets': [189], 'segmentation.\\n': [192]}",2020,[],"The usage of convolutional neural networks (CNNs) for unsupervised image\nsegmentation was investigated in this study. In the proposed approach, label\nprediction and network parameter learning are alternately iterated to meet the\nfollowing criteria: (a) pixels of similar features should be assigned the same\nlabel, (b) spatially continuous pixels should be assigned the same label, and\n(c) the number of unique labels should be large. Although these criteria are\nincompatible, the proposed approach minimizes the combination of similarity\nloss and spatial continuity loss to find a plausible solution of label\nassignment that balances the aforementioned criteria well. The contributions of\nthis study are four-fold. First, we propose a novel end-to-end network of\nunsupervised image segmentation that consists of normalization and an argmax\nfunction for differentiable clustering. Second, we introduce a spatial\ncontinuity loss function that mitigates the limitations of fixed segment\nboundaries possessed by previous work. Third, we present an extension of the\nproposed method for segmentation with scribbles as user input, which showed\nbetter accuracy than existing methods while maintaining efficiency. Finally, we\nintroduce another extension of the proposed method: unseen image segmentation\nby using networks pre-trained with a few reference images without re-training\nthe networks. The effectiveness of the proposed approach was examined on\nseveral benchmark datasets of image segmentation.\n"
https://openalex.org/W3171229070,"A Survey on Semi-, Self- and Unsupervised Learning for Image Classification","{'While': [0], 'deep': [1], 'learning': [2], 'strategies': [3, 16], 'achieve': [4, 162], 'outstanding': [5], 'results': [6, 58, 164], 'in': [7, 91, 101, 139], 'computer': [8], 'vision': [9], 'tasks,': [10], 'one': [11], 'issue': [12], 'remains:': [13], 'The': [14, 154], 'current': [15], 'rely': [17], 'heavily': [18], 'on': [19, 104], 'a': [20, 64, 114, 183], 'huge': [21], 'amount': [22, 38], 'of': [23, 39, 66, 75, 85, 156, 168, 186, 199], 'labeled': [24, 40], 'data.': [25, 42], 'In': [26, 78, 117], 'many': [27, 205], 'real-world': [28, 137], 'problems,': [29], 'it': [30, 44, 69], 'is': [31, 45, 70, 159, 171], 'not': [32, 151, 203], 'feasible': [33], 'to': [34, 47, 55, 63, 72, 127, 136, 161, 165, 177, 180, 217], 'create': [35], 'such': [36], 'an': [37, 83], 'training': [41, 53], 'Therefore,': [43], 'common': [46, 193], 'incorporate': [48], 'unlabeled': [49], 'data': [50], 'into': [51], 'the': [52, 166], 'process': [54], 'reach': [56], 'equal': [57], 'with': [59, 94, 182], 'fewer': [60, 95], 'labels.': [61, 96], 'Due': [62], 'lot': [65], 'concurrent': [67], 'research,': [68], 'difficult': [71], 'keep': [73], 'track': [74], 'recent': [76], 'developments.': [77], 'this': [79], 'survey,': [80], 'we': [81, 120, 196], 'provide': [82], 'overview': [84], 'often': [86], 'used': [87, 110], 'ideas': [88, 111, 194, 211], 'and': [89, 107, 173], 'methods': [90, 100, 133, 175, 190, 200], 'image': [92], 'classification': [93], 'We': [97, 207], 'compare': [98], '34': [99], 'detail': [102], 'based': [103], 'their': [105, 108], 'performance': [106], 'commonly': [109], 'rather': [112], 'than': [113], 'fine-grained': [115], 'taxonomy.': [116], 'our': [118], 'analysis,': [119], 'identify': [121, 197], 'three': [122], 'major': [123], 'trends': [124], 'that': [125, 201, 209], 'lead': [126, 216], 'future': [128], 'research': [129], 'opportunities.': [130], '1.': [131], 'State-of-the-art': [132], 'are': [134, 150], 'scalable': [135], 'applications': [138], 'theory': [140], 'but': [141, 195], 'issues': [142], 'like': [143], 'class': [144], 'imbalance,': [145], 'robustness,': [146], 'or': [147], 'fuzzy': [148], 'labels': [149, 170], 'considered.': [152], '2.': [153], 'degree': [155], 'supervision': [157], 'which': [158], 'needed': [160], 'comparable': [163], 'usage': [167], 'all': [169], 'decreasing': [172], 'therefore': [174], 'need': [176], 'be': [178], 'extended': [179], 'settings': [181], 'variable': [184], 'number': [185], 'classes.': [187], '3.': [188], 'All': [189], 'share': [191, 204], 'some': [192], 'clusters': [198, 214], 'do': [202], 'ideas.': [206], 'show': [208], 'combining': [210], 'from': [212], 'different': [213], 'can': [215], 'better': [218], 'performance.': [219]}",2021,"['Computer science', 'Robustness (evolution)', 'Artificial intelligence', 'Machine learning', 'Process (computing)', 'Taxonomy (biology)', 'Contextual image classification', 'Class (philosophy)', 'Training set', 'Variable (mathematics)', 'Data science', 'Data mining', 'Image (mathematics)', 'Botany', 'Mathematics', 'Operating system', 'Biology', 'Mathematical analysis', 'Biochemistry', 'Chemistry', 'Gene']","While deep learning strategies achieve outstanding results in computer vision tasks, one issue remains: The current strategies rely heavily on a huge amount of labeled data. In many real-world problems, it is not feasible to create such an amount of labeled training data. Therefore, it is common to incorporate unlabeled data into the training process to reach equal results with fewer labels. Due to a lot of concurrent research, it is difficult to keep track of recent developments. In this survey, we provide an overview of often used ideas and methods in image classification with fewer labels. We compare 34 methods in detail based on their performance and their commonly used ideas rather than a fine-grained taxonomy. In our analysis, we identify three major trends that lead to future research opportunities. 1. State-of-the-art methods are scalable to real-world applications in theory but issues like class imbalance, robustness, or fuzzy labels are not considered. 2. The degree of supervision which is needed to achieve comparable results to the usage of all labels is decreasing and therefore methods need to be extended to settings with a variable number of classes. 3. All methods share some common ideas but we identify clusters of methods that do not share many ideas. We show that combining ideas from different clusters can lead to better performance."
https://openalex.org/W2118681326,Supervised and unsupervised learning for sentence compression,"{'In': [0], 'Statistics-Based': [1], 'Summarization': [2], '-': [3], 'Step': [4], 'One:': [5], 'Sentence': [6], 'Compression,': [7], 'Knight': [8, 35], 'and': [9, 12, 36, 64], 'Marcu': [10, 37], '(Knight': [11], 'Marcu,': [13], '2000)': [14], '(K&M)': [15], 'present': [16], 'a': [17, 39], 'noisy-channel': [18, 59], 'model': [19], 'for': [20, 85], 'sentence': [21], 'compression.': [22], 'The': [23], 'main': [24], 'difficulty': [25], 'in': [26, 52, 79], 'using': [27], 'this': [28, 80], 'method': [29], 'is': [30, 47], 'the': [31, 56, 68, 77], 'lack': [32], 'of': [33, 41, 67], 'data;': [34], 'use': [38], 'corpus': [40], '1035': [42], 'training': [43], 'sentences.': [44], 'More': [45], 'data': [46], 'not': [48], 'easily': [49], 'available,': [50], 'so': [51], 'addition': [53], 'to': [54], 'improving': [55], 'original': [57], 'K&M': [58], 'model,': [60], 'we': [61, 71], 'create': [62], 'unsupervised': [63], 'semi-supervised': [65], 'models': [66], 'task.': [69], 'Finally,': [70], 'point': [72], 'out': [73], 'problems': [74], 'with': [75], 'modeling': [76], 'task': [78], 'way.': [81], 'They': [82], 'suggest': [83], 'areas': [84], 'future': [86], 'research.': [87]}",2005,"['Computer science', 'Automatic summarization', 'Sentence', 'Artificial intelligence', 'Task (project management)', 'Natural language processing', 'Unsupervised learning', 'Compression (physics)', 'Point (geometry)', 'Knight', 'Channel (broadcasting)', 'Speech recognition', 'Machine learning', 'Mathematics', 'Physics', 'Computer network', 'Materials science', 'Astronomy', 'Economics', 'Management', 'Geometry', 'Composite material']","In Statistics-Based Summarization - Step One: Sentence Compression, Knight and Marcu (Knight and Marcu, 2000) (K&M) present a noisy-channel model for sentence compression. The main difficulty in using this method is the lack of data; Knight and Marcu use a corpus of 1035 training sentences. More data is not easily available, so in addition to improving the original K&M noisy-channel model, we create unsupervised and semi-supervised models of the task. Finally, we point out problems with modeling the task in this way. They suggest areas for future research."
https://openalex.org/W2908875379,Lung and Pancreatic Tumor Characterization in the Deep Learning Era: Novel Supervised and Unsupervised Learning Approaches,"{'Risk': [0], 'stratification': [1], '(characterization)': [2], 'of': [3, 39, 92, 130, 173], 'tumors': [4], 'from': [5, 144], 'radiology': [6], 'images': [7], 'can': [8, 24], 'be': [9], 'more': [10], 'accurate': [11], 'and': [12, 31, 49, 84, 185, 196, 201, 206, 211], 'faster': [13], 'with': [14, 72, 198], 'computer-aided': [15], 'diagnosis': [16, 193], '(CAD)': [17], 'tools.': [18], 'Tumor': [19], 'characterization': [20], 'through': [21], 'such': [22], 'tools': [23], 'also': [25, 162], 'enable': [26], 'non-invasive': [27], 'cancer': [28], 'staging,': [29], 'prognosis,': [30], 'foster': [32], 'personalized': [33], 'treatment': [34], 'planning': [35], 'as': [36], 'a': [37, 79, 105, 109, 134], 'part': [38], 'precision': [40], 'medicine.': [41], 'In': [42, 115], 'this': [43], 'papet,': [44], 'we': [45, 68, 95, 119, 151], 'propose': [46, 152], 'both': [47, 215], 'supervised': [48, 64, 184], 'unsupervised': [50, 122, 177, 186], 'machine': [51, 157], 'learning': [52, 65, 74, 113, 123, 143, 187], 'strategies': [53], 'to': [54, 99, 125, 153, 166], 'improve': [55], 'tumor': [56, 178, 192], 'characterization.': [57], 'Our': [58], 'first': [59], 'approach': [60], 'is': [61], 'based': [62], 'on': [63, 189], 'for': [66, 158, 176], 'which': [67], 'demonstrate': [69], 'significant': [70], 'gains': [71], 'deep': [73], 'algorithms,': [75], 'particularly': [76], 'by': [77, 88, 142], 'utilizing': [78], '3D': [80], 'convolutional': [81], 'neural': [82], 'network': [83], 'transfer': [85], 'learning.': [86], 'Motivated': [87], 'the': [89, 93, 116, 127, 164, 167, 171, 208], ""radiologists'"": [90], 'interpretations': [91], 'scans,': [94, 204], 'then': [96], 'show': [97], 'how': [98], 'incorporate': [100], 'task-dependent': [101], 'feature': [102], 'representations': [103], 'into': [104], 'CAD': [106], 'system': [107], 'via': [108], 'graph-regularized': [110], 'sparse': [111], 'multi-task': [112], 'framework.': [114], 'second': [117], 'approach,': [118], 'explore': [120], 'an': [121], 'algorithm': [124], 'address': [126], 'limited': [128], 'availability': [129], 'labeled': [131], 'training': [132], 'data,': [133], 'common': [135], 'problem': [136], 'in': [137, 148, 214], 'medical': [138], 'imaging': [139], 'applications.': [140], 'Inspired': [141], 'label': [145], 'proportion': [146], 'approaches': [147], 'computer': [149], 'vision,': [150], 'use': [154], 'proportion-support': [155], 'vector': [156], 'characterizing': [159], 'tumors.': [160], 'We': [161, 180], 'seek': [163], 'answer': [165], 'fundamental': [168], 'question': [169], 'about': [170], 'goodness': [172], '""deep': [174], 'features""': [175], 'classification.': [179], 'evaluate': [181], 'our': [182], 'proposed': [183], 'algorithms': [188], 'two': [190], 'different': [191], 'challenges:': [194], 'lung': [195], 'pancreas': [197], '1018': [199], 'CT': [200], '171': [202], 'MRI': [203], 'respectively,': [205], 'obtain': [207], 'state-of-the-art': [209], 'sensitivity': [210], 'specificity': [212], 'results': [213], 'problems.': [216]}",2019,"['Artificial intelligence', 'Machine learning', 'Computer science', 'Deep learning', 'Unsupervised learning', 'Convolutional neural network', 'Feature learning', 'Semi-supervised learning', 'Multi-task learning', 'Medical imaging', 'Feature engineering', 'Supervised learning', 'Pattern recognition (psychology)', 'Artificial neural network', 'Task (project management)', 'Economics', 'Management']","Risk stratification (characterization) of tumors from radiology images can be more accurate and faster with computer-aided diagnosis (CAD) tools. Tumor characterization through such tools can also enable non-invasive cancer staging, prognosis, and foster personalized treatment planning as a part of precision medicine. In this papet, we propose both supervised and unsupervised machine learning strategies to improve tumor characterization. Our first approach is based on supervised learning for which we demonstrate significant gains with deep learning algorithms, particularly by utilizing a 3D convolutional neural network and transfer learning. Motivated by the radiologists' interpretations of the scans, we then show how to incorporate task-dependent feature representations into a CAD system via a graph-regularized sparse multi-task learning framework. In the second approach, we explore an unsupervised learning algorithm to address the limited availability of labeled training data, a common problem in medical imaging applications. Inspired by learning from label proportion approaches in computer vision, we propose to use proportion-support vector machine for characterizing tumors. We also seek the answer to the fundamental question about the goodness of ""deep features"" for unsupervised tumor classification. We evaluate our proposed supervised and unsupervised learning algorithms on two different tumor diagnosis challenges: lung and pancreas with 1018 CT and 171 MRI scans, respectively, and obtain the state-of-the-art sensitivity and specificity results in both problems."
https://openalex.org/W2085256060,Automatic text categorization by unsupervised learning,"{'Tile': [0], 'goal': [1], 'of': [2, 13, 27, 97, 120], 'text': [3, 139], 'categorization': [4], 'is': [5, 36, 39, 49, 57, 141], 'to': [6, 41, 51, 61, 78], 'classify': [7], 'documents': [8, 30, 87], 'iuto': [9], 'a': [10, 24, 117], 'certain': [11], 'number': [12, 26], 'predefined': [14], 'categories.': [15], 'The': [16, 82, 113], 'previous': [17], 'works': [18], 'iu': [19], 'this': [20, 70, 130], 'area': [21], 'have': [22], 'used': [23, 134, 147], 'large': [25], 'labeled': [28, 44], 'training': [29, 45], 'IBr': [31], 'supervised': [32, 126], 'learning.': [33], 'One': [34], 'problem': [35], 'that': [37], 'it': [38, 48, 56, 106], 'difficult': [40], 'create': [42], 'the': [43, 53, 86, 108, 124], 'documeuls.': [46], 'While': [47], 'easy': [50, 60], 'collect': [52], 'unlabeled': [54], 'documents,': [55], 'not': [58], 'so': [59], 'mauually': [62], 'categorize': [63], 'them': [64], 'for': [65, 111, 148], 'creating': [66, 149], 'traiuiug': [67], 'documents.': [68, 151], 'In': [69], 'paper,': [71], 'we': [72], 'propose': [73], 'an': [74], 'unsupervised': [75], '!earntug': [76], 'method': [77, 84, 115], 'overcome': [79], 'these': [80], 'difficulties.': [81], 'proposed': [83, 114], 'divides': [85], 'into': [88], 'sentences,': [89], 'aud': [90], 'categorizes': [91], 'each': [92, 98], 'sentence': [93], 'using': [94], 'keyword': [95], 'lists': [96], 'category': [99], 'and': [100], 'scnteuce': [101], 'similarity': [102], 'measure.': [103], 'And': [104], 'lhen,': [105], 'uses': [107], 'categorized': [109], 'senteuces': [110], 'training.': [112], 'shows': [116], 'silnilar': [118], 'degree': [119], 'performance,': [121], 'compared': [122], 'with': [123], 'traditional': [125], 'learuing': [127], 'inethods.': [128], 'Therefore,': [129], 'nethod': [131], 'can': [132, 145], 'be': [133, 146], 'in': [135], 'areas': [136], 'where': [137], 'low-cost': [138], 'catcgorizatiou': [140], 'needed.': [142], 'It': [143], 'also': [144], 'traiuing': [150]}",2000,"['Categorization', 'Computer science', 'Artificial intelligence', 'Unsupervised learning', 'Text categorization', 'Natural language processing', 'Machine learning']","Tile goal of text categorization is to classify documents iuto a certain number of predefined categories. The previous works iu this area have used a large number of labeled training documents IBr supervised learning. One problem is that it is difficult to create the labeled training documeuls. While it is easy to collect the unlabeled documents, it is not so easy to mauually categorize them for creating traiuiug documents. In this paper, we propose an unsupervised !earntug method to overcome these difficulties. The proposed method divides the documents into sentences, aud categorizes each sentence using keyword lists of each category and scnteuce similarity measure. And lhen, it uses the categorized senteuces for training. The proposed method shows a silnilar degree of performance, compared with the traditional supervised learuing inethods. Therefore, this nethod can be used in areas where low-cost text catcgorizatiou is needed. It also can be used for creating traiuing documents."
https://openalex.org/W2578257192,Unsupervised Learning of Long-Term Motion Dynamics for Videos,"{'We': [0, 58, 73, 101], 'present': [1], 'an': [2], 'unsupervised': [3], 'representation': [4, 92], 'learning': [5, 39], 'approach': [6], 'that': [7, 75, 93], 'compactly': [8], 'encodes': [9], 'the': [10, 29, 35, 38, 45, 79, 85, 103], 'motion': [11, 46, 96], 'dependencies': [12, 97], 'in': [13, 76], 'videos.': [14, 140], 'Given': [15], 'a': [16, 21, 48, 60, 89], 'pair': [17], 'of': [18, 37, 50, 71, 105], 'images': [19], 'from': [20], 'video': [22, 91], 'clip,': [23], 'our': [24, 106], 'framework': [25, 66, 128], 'learns': [26], 'to': [27, 43, 67, 81, 131], 'predict': [28, 68], 'long-term': [30, 95], '3D': [31, 52], 'motions.': [32], 'To': [33], 'reduce': [34], 'complexity': [36], 'framework,': [40], 'we': [41], 'propose': [42], 'describe': [44], 'as': [47, 119], 'sequence': [49], 'atomic': [51], 'flows': [53], 'computed': [54], 'with': [55], 'RGB-D': [56, 139], 'modality.': [57], 'use': [59], 'Recurrent': [61], 'Neural': [62], 'Network': [63], 'based': [64], 'Encoder-Decoder': [65], 'these': [69, 83], 'sequences': [70], 'flows.': [72], 'argue': [74], 'order': [77], 'for': [78], 'decoder': [80], 'reconstruct': [82], 'sequences,': [84], 'encoder': [86], 'must': [87], 'learn': [88], 'robust': [90], 'captures': [94], 'and': [98, 116, 122, 138], 'spatial-temporal': [99], 'relations.': [100], 'demonstrate': [102], 'effectiveness': [104], 'learned': [107], 'temporal': [108], 'representations': [109], 'on': [110], 'activity': [111], 'classification': [112], 'across': [113], 'multiple': [114], 'modalities': [115], 'datasets': [117], 'such': [118], 'NTU': [120], 'RGB+D': [121], 'MSR': [123], 'Daily': [124], 'Activity': [125], '3D.': [126], 'Our': [127], 'is': [129], 'generic': [130], 'any': [132], 'input': [133], 'modality,': [134], 'i.e.,': [135], 'RGB,': [136], 'Depth,': [137]}",2017,"['Computer science', 'Artificial intelligence', 'RGB color model', 'Representation (politics)', 'Encoder', 'Modality (human–computer interaction)', 'Motion (physics)', 'Term (time)', 'Computer vision', 'Feature learning', 'Sequence (biology)', 'Artificial neural network', 'Recurrent neural network', 'Modalities', 'Pattern recognition (psychology)', 'Physics', 'Political science', 'Law', 'Politics', 'Operating system', 'Genetics', 'Sociology', 'Biology', 'Quantum mechanics', 'Social science']","We present an unsupervised representation learning approach that compactly encodes the motion dependencies in videos. Given a pair of images from a video clip, our framework learns to predict the long-term 3D motions. To reduce the complexity of the learning framework, we propose to describe the motion as a sequence of atomic 3D flows computed with RGB-D modality. We use a Recurrent Neural Network based Encoder-Decoder framework to predict these sequences of flows. We argue that in order for the decoder to reconstruct these sequences, the encoder must learn a robust video representation that captures long-term motion dependencies and spatial-temporal relations. We demonstrate the effectiveness of our learned temporal representations on activity classification across multiple modalities and datasets such as NTU RGB+D and MSR Daily Activity 3D. Our framework is generic to any input modality, i.e., RGB, Depth, and RGB-D videos."
https://openalex.org/W2607510315,Unsupervised Learning by Predicting Noise,"{'Convolutional': [0], 'neural': [1], 'networks': [2, 18], 'provide': [3], 'visual': [4], 'features': [5, 57], 'that': [6, 103], 'perform': [7, 104], 'remarkably': [8], 'well': [9], 'in': [10], 'many': [11], 'computer': [12], 'vision': [13], 'applications.': [14], 'However,': [15], 'training': [16], 'these': [17], 'requires': [19], 'significant': [20], 'amounts': [21], 'of': [22, 44, 72, 77, 96], 'supervision.': [23, 37], 'This': [24, 62], 'paper': [25], 'introduces': [26], 'a': [27, 42, 81, 87], 'generic': [28], 'framework': [29], 'to': [30, 40, 53, 58, 60, 80, 94], 'train': [31], 'deep': [32, 56], 'networks,': [33], 'end-to-end,': [34], 'with': [35, 107], 'no': [36], 'We': [38], 'propose': [39], 'fix': [41], 'set': [43], 'target': [45], 'representations,': [46], 'called': [47], 'Noise': [48], 'As': [49], 'Targets': [50], '(NAT),': [51], 'and': [52, 75, 86, 113], 'constrain': [54], 'the': [55, 67], 'align': [59], 'them.': [61], 'domain': [63], 'agnostic': [64], 'approach': [65, 100], 'avoids': [66], 'standard': [68], 'unsupervised': [69, 109], 'learning': [70], 'issues': [71], 'trivial': [73], 'solutions': [74], 'collapsing': [76], 'features.': [78], 'Thanks': [79], 'stochastic': [82], 'batch': [83], 'reassignment': [84], 'strategy': [85], 'separable': [88], 'square': [89], 'loss': [90], 'function,': [91], 'it': [92], 'scales': [93], 'millions': [95], 'images.': [97], 'The': [98], 'proposed': [99], 'produces': [101], 'representations': [102], 'on': [105, 111], 'par': [106], 'state-of-the-art': [108], 'methods': [110], 'ImageNet': [112], 'Pascal': [114], 'VOC.': [115]}",2017,"['Pascal (unit)', 'Computer science', 'Artificial intelligence', 'Deep learning', 'Deep neural networks', 'Unsupervised learning', 'Convolutional neural network', 'Noise (video)', 'Set (abstract data type)', 'Machine learning', 'Domain (mathematical analysis)', 'Pattern recognition (psychology)', 'Image (mathematics)', 'Mathematics', 'Mathematical analysis', 'Programming language']","Convolutional neural networks provide visual features that perform remarkably well in many computer vision applications. However, training these networks requires significant amounts of supervision. This paper introduces a generic framework to train deep networks, end-to-end, with no supervision. We propose to fix a set of target representations, called Noise As Targets (NAT), and to constrain the deep features to align to them. This domain agnostic approach avoids the standard unsupervised learning issues of trivial solutions and collapsing of features. Thanks to a stochastic batch reassignment strategy and a separable square loss function, it scales to millions of images. The proposed approach produces representations that perform on par with state-of-the-art unsupervised methods on ImageNet and Pascal VOC."
https://openalex.org/W2895106137,Unsupervised Learning via Meta-Learning,"{'A': [0], 'central': [1], 'goal': [2], 'of': [3, 23, 29, 70, 75, 121, 152], 'unsupervised': [4, 34, 57, 134, 164], 'learning': [5, 22, 35, 139, 165], 'is': [6, 146], 'to': [7, 38, 66, 115, 148], 'acquire': [8], 'representations': [9], 'from': [10, 26, 72, 83], 'unlabeled': [11, 84], 'data': [12, 85, 144], 'or': [13], 'experience': [14], 'that': [15, 60, 132, 145], 'can': [16], 'be': [17], 'used': [18], 'for': [19, 63], 'more': [20], 'effective': [21], 'downstream': [24, 153], 'tasks': [25, 71, 82], 'modest': [27], 'amounts': [28, 74], 'labeled': [30, 143], 'data.': [31, 76], 'Many': [32], 'prior': [33, 163], 'works': [36], 'aim': [37], 'do': [39, 78], 'so': [40], 'by': [41, 161], 'developing': [42], 'proxy': [43], 'objectives': [44], 'based': [45], 'on': [46, 118], 'reconstruction,': [47], 'disentanglement,': [48], 'prediction,': [49], 'and': [50, 90], 'other': [51], 'metrics.': [52], 'Instead,': [53], 'we': [54, 80, 98], 'develop': [55], 'an': [56, 87], 'meta-learning': [58, 92, 135], 'method': [59], 'explicitly': [61], 'optimizes': [62], 'the': [64, 94, 158], 'ability': [65], 'learn': [67], 'a': [68, 119, 138, 149], 'variety': [69, 120], 'small': [73], 'To': [77], 'so,': [79], 'construct': [81], 'in': [86], 'automatic': [88], 'way': [89], 'run': [91], 'over': [93], 'constructed': [95], 'tasks.': [96, 124], 'Surprisingly,': [97], 'find': [99], 'that,': [100], 'when': [101], 'integrated': [102], 'with': [103], 'meta-learning,': [104], 'relatively': [105], 'simple': [106], 'task': [107], 'construction': [108], 'mechanisms,': [109], 'such': [110], 'as': [111], 'clustering': [112], 'embeddings,': [113], 'lead': [114], 'good': [116], 'performance': [117], 'downstream,': [122], 'human-specified': [123], 'Our': [125], 'experiments': [126], 'across': [127], 'four': [128, 162], 'image': [129], 'datasets': [130], 'indicate': [131], 'our': [133], 'approach': [136], 'acquires': [137], 'algorithm': [140], 'without': [141], 'any': [142], 'applicable': [147], 'wide': [150], 'range': [151], 'classification': [154], 'tasks,': [155], 'improving': [156], 'upon': [157], 'embedding': [159], 'learned': [160], 'methods.': [166]}",2018,"['Unsupervised learning', 'Computer science', 'Meta learning (computer science)', 'Machine learning', 'Artificial intelligence', 'Cluster analysis', 'Embedding', 'Construct (python library)', 'Variety (cybernetics)', 'Task (project management)', 'Feature learning', 'Conceptual clustering', 'Competitive learning', 'Fuzzy clustering', 'Management', 'Programming language', 'CURE data clustering algorithm', 'Economics']","A central goal of unsupervised learning is to acquire representations from unlabeled data or experience that can be used for more effective learning of downstream tasks from modest amounts of labeled data. Many prior unsupervised learning works aim to do so by developing proxy objectives based on reconstruction, disentanglement, prediction, and other metrics. Instead, we develop an unsupervised meta-learning method that explicitly optimizes for the ability to learn a variety of tasks from small amounts of data. To do so, we construct tasks from unlabeled data in an automatic way and run meta-learning over the constructed tasks. Surprisingly, we find that, when integrated with meta-learning, relatively simple task construction mechanisms, such as clustering embeddings, lead to good performance on a variety of downstream, human-specified tasks. Our experiments across four image datasets indicate that our unsupervised meta-learning approach acquires a learning algorithm without any labeled data that is applicable to a wide range of downstream classification tasks, improving upon the embedding learned by four prior unsupervised learning methods."
https://openalex.org/W2785325870,Unsupervised Representation Learning by Predicting Image Rotations,"{'Over': [0], 'the': [1, 11, 74, 98, 105, 175, 195, 210], 'last': [2], 'years,': [3], 'deep': [4], 'convolutional': [5], 'neural': [6], 'networks': [7], '(ConvNets)': [8], 'have': [9], 'transformed': [10], 'field': [12], 'of': [13, 41, 66, 77, 150, 201, 244], 'computer': [14], 'vision': [15], 'thanks': [16], 'to': [17, 21, 31, 51, 71, 89, 96, 104], 'their': [18], 'unparalleled': [19], 'capacity': [20], 'learn': [22, 33, 90], 'high': [23], 'level': [24], 'semantic': [25, 55, 131], 'image': [26, 91, 106], 'features.': [27], 'However,': [28], 'in': [29, 69, 139, 148, 167, 183], 'order': [30, 70], 'successfully': [32, 72], 'those': [34, 158], 'features,': [35], 'they': [36], 'usually': [37], 'require': [38], 'massive': [39], 'amounts': [40], 'manually': [42], 'labeled': [43], 'data,': [44], 'which': [45], 'is': [46, 65, 102, 204], 'both': [47, 114], 'expensive': [48], 'and': [49, 116, 145, 171, 237, 242], 'impractical': [50], 'scale.': [52], 'Therefore,': [53], 'unsupervised': [54, 141, 168, 190, 198, 222], 'feature': [56, 132, 142, 179], 'learning,': [57], 'i.e.,': [58], 'learning': [59, 143, 170], 'without': [60], 'requiring': [61], 'manual': [62], 'annotation': [63], 'effort,': [64], 'crucial': [67], 'importance': [68], 'harvest': [73], 'vast': [75], 'amount': [76], 'visual': [78], 'data': [79], 'that': [80, 101, 107, 118, 203], 'are': [81], 'available': [82], 'today.': [83], 'In': [84], 'our': [85, 137, 155, 189, 221, 245], 'work': [86], 'we': [87, 146, 219], 'propose': [88], 'features': [92, 224], 'by': [93], 'training': [94], 'ConvNets': [95], 'recognize': [97], '2d': [99], 'rotation': [100], 'applied': [103], 'it': [108], 'gets': [109], 'as': [110, 230], 'input.': [111], 'We': [112, 134, 213], 'demonstrate': [113, 160], 'qualitatively': [115], 'quantitatively': [117], 'this': [119], 'apparently': [120], 'simple': [121], 'task': [122, 188], 'actually': [123], 'provides': [124], 'a': [125], 'very': [126], 'powerful': [127], 'supervisory': [128], 'signal': [129], 'for': [130], 'learning.': [133, 180], 'exhaustively': [135], 'evaluate': [136], 'method': [138], 'various': [140, 226], 'benchmarks': [144, 159], 'exhibit': [147], 'all': [149], 'them': [151], 'state-of-the-art': [152, 165, 196], 'performance.': [153], 'Specifically,': [154], 'results': [156, 217], 'on': [157, 225], 'dramatic': [161], 'improvements': [162], 'w.r.t.': [163], 'prior': [164], 'approaches': [166], 'representation': [169], 'thus': [172], 'significantly': [173], 'close': [174], 'gap': [176], 'with': [177], 'supervised': [178, 211], 'For': [181], 'instance,': [182], 'PASCAL': [184, 233, 235], 'VOC': [185], '2007': [186], 'detection': [187], 'pre-trained': [191], 'AlexNet': [192], 'model': [193], 'achieves': [194], '(among': [197], 'methods)': [199], 'mAP': [200], '54.4%': [202], 'only': [205], '2.4': [206], 'points': [207], 'lower': [208], 'from': [209], 'case.': [212], 'get': [214], 'similarly': [215], 'striking': [216], 'when': [218], 'transfer': [220], 'learned': [223], 'other': [227], 'tasks,': [228], 'such': [229], 'ImageNet': [231], 'classification,': [232, 234], 'segmentation,': [236], 'CIFAR-10': [238], 'classification.': [239], 'The': [240], 'code': [241], 'models': [243], 'paper': [246], 'will': [247], 'be': [248], 'published': [249], 'on:': [250], 'https://github.com/gidariss/FeatureLearningRotNet': [251], '.': [252]}",2018,"['Pascal (unit)', 'Artificial intelligence', 'Computer science', 'Unsupervised learning', 'Convolutional neural network', 'Feature learning', 'Pattern recognition (psychology)', 'Transfer of learning', 'Deep learning', 'Machine learning', 'Feature extraction', 'Supervised learning', 'Feature (linguistics)', 'Artificial neural network', 'Linguistics', 'Programming language', 'Philosophy']","Over the last years, deep convolutional neural networks (ConvNets) have transformed the field of computer vision thanks to their unparalleled capacity to learn high level semantic image features. However, in order to successfully learn those features, they usually require massive amounts of manually labeled data, which is both expensive and impractical to scale. Therefore, unsupervised semantic feature learning, i.e., learning without requiring manual annotation effort, is of crucial importance in order to successfully harvest the vast amount of visual data that are available today. In our work we propose to learn image features by training ConvNets to recognize the 2d rotation that is applied to the image that it gets as input. We demonstrate both qualitatively and quantitatively that this apparently simple task actually provides a very powerful supervisory signal for semantic feature learning. We exhaustively evaluate our method in various unsupervised feature learning benchmarks and we exhibit in all of them state-of-the-art performance. Specifically, our results on those benchmarks demonstrate dramatic improvements w.r.t. prior state-of-the-art approaches in unsupervised representation learning and thus significantly close the gap with supervised feature learning. For instance, in PASCAL VOC 2007 detection task our unsupervised pre-trained AlexNet model achieves the state-of-the-art (among unsupervised methods) mAP of 54.4% that is only 2.4 points lower from the supervised case. We get similarly striking results when we transfer our unsupervised learned features on various other tasks, such as ImageNet classification, PASCAL classification, PASCAL segmentation, and CIFAR-10 classification. The code and models of our paper will be published on: https://github.com/gidariss/FeatureLearningRotNet ."
https://openalex.org/W2297862270,Unsupervised Learning by Spike Timing Dependent Plasticity in Phase Change Memory (PCM) Synapses,"{'We': [0], 'present': [1], 'a': [2, 47, 101], 'novel': [3], 'one-transistor/one-resistor': [4], '(1T1R)': [5], 'synapse': [6, 18, 73], 'for': [7, 74, 105], 'neuromorphic': [8, 86], 'networks,': [9], 'based': [10], 'on': [11, 30], 'phase': [12], 'change': [13], 'memory': [14], '(PCM)': [15], 'technology.': [16], 'The': [17, 97], 'is': [19, 40], 'capable': [20], 'of': [21, 46, 63, 70, 78, 83], 'spike-timing': [22], 'dependent': [23], 'plasticity': [24], '(STDP),': [25], 'where': [26], 'gradual': [27], 'potentiation': [28], 'relies': [29], 'set': [31], 'transition,': [32], 'namely': [33], 'crystallization,': [34], 'in': [35, 110], 'the': [36, 68, 71], 'PCM,': [37], 'while': [38], 'depression': [39], 'achieved': [41], 'via': [42], 'reset': [43], 'or': [44, 90], 'amorphization': [45], 'chalcogenide': [48], 'active': [49], 'volume.': [50], 'STDP': [51], 'characteristics': [52], 'are': [53], 'demonstrated': [54], 'by': [55, 81], 'experiments': [56], 'under': [57], 'variable': [58], 'initial': [59], 'conditions': [60], 'and': [61, 76], 'number': [62], 'pulses.': [64], 'Finally,': [65], 'we': [66], 'support': [67], 'applicability': [69], '1T1R': [72], 'learning': [75, 109], 'recognition': [77, 95], 'visual': [79], 'patterns': [80], 'simulations': [82], 'fully': [84], 'connected': [85], 'networks': [87], 'with': [88, 93], '2': [89], '3': [91], 'layers': [92], 'high': [94], 'efficiency.': [96], 'proposed': [98], 'scheme': [99], 'provides': [100], 'feasible': [102], 'low-power': [103], 'solution': [104], 'on-line': [106], 'unsupervised': [107], 'machine': [108], 'smart': [111], 'reconfigurable': [112], 'sensors.': [113]}",2016,"['Neuromorphic engineering', 'Spike-timing-dependent plasticity', 'Phase-change memory', 'Computer science', 'Spike (software development)', 'Reset (finance)', 'Synapse', 'Transistor', 'Unsupervised learning', 'Memristor', 'Resistor', 'Spiking neural network', 'Long-term potentiation', 'Artificial intelligence', 'Artificial neural network', 'Neuroscience', 'Electronic engineering', 'Phase change', 'Voltage', 'Physics', 'Electrical engineering', 'Engineering', 'Psychology', 'Chemistry', 'Software engineering', 'Economics', 'Financial economics', 'Engineering physics', 'Biochemistry', 'Receptor']","We present a novel one-transistor/one-resistor (1T1R) synapse for neuromorphic networks, based on phase change memory (PCM) technology. The synapse is capable of spike-timing dependent plasticity (STDP), where gradual potentiation relies on set transition, namely crystallization, in the PCM, while depression is achieved via reset or amorphization of a chalcogenide active volume. STDP characteristics are demonstrated by experiments under variable initial conditions and number of pulses. Finally, we support the applicability of the 1T1R synapse for learning and recognition of visual patterns by simulations of fully connected neuromorphic networks with 2 or 3 layers with high recognition efficiency. The proposed scheme provides a feasible low-power solution for on-line unsupervised machine learning in smart reconfigurable sensors."
https://openalex.org/W2532666972,Analog Memristive Synapse in Spiking Networks Implementing Unsupervised Learning,"{'Emerging': [0], 'brain-inspired': [1], 'architectures': [2], 'call': [3], 'for': [4, 169, 204], 'devices': [5, 28], 'that': [6], 'can': [7], 'emulate': [8], 'the': [9, 44, 47, 50, 59, 66, 129, 133, 137], 'functionality': [10, 61], 'of': [11, 62, 177, 233], 'biological': [12, 73], 'synapses': [13, 171, 175], 'in': [14, 36, 46, 72, 149, 217], 'order': [15], 'to': [16, 23, 43, 57, 83, 114, 212, 229, 235], 'implement': [17], 'new': [18], 'efficient': [19], 'computational': [20], 'schemes': [21], 'able': [22, 56, 82, 113, 211], 'solve': [24], 'ill-posed': [25], 'problems.': [26], 'Various': [27], 'and': [29, 97, 225], 'solutions': [30], 'are': [31, 223], 'still': [32], 'under': [33], 'investigation': [34], 'and,': [35], 'this': [37, 158], 'respect,': [38], 'a': [39, 54, 63, 80, 145, 189, 196, 230], 'challenge': [40], 'is': [41, 53, 139, 144, 210, 227], 'opened': [42], 'researchers': [45], 'field.': [48], 'Indeed,': [49], 'optimal': [51], 'candidate': [52], 'device': [55, 81], 'reproduce': [58], 'complete': [60], 'synapse,': [64], 'i.e.,': [65], 'typical': [67], 'synaptic': [68, 76, 190], 'process': [69], 'underlying': [70], 'learning': [71, 125, 147, 162, 203], 'systems': [74], '(activity-dependent': [75], 'plasticity).': [77], 'This': [78, 142, 181], 'implies': [79], 'change': [84], 'its': [85, 104], 'resistance': [86], '(synaptic': [87, 95], 'strength,': [88], 'or': [89, 220], 'weight)': [90], 'upon': [91], 'proper': [92], 'electrical': [93], 'stimuli': [94], 'activity)': [96], 'showing': [98], 'several': [99, 166], 'stable': [100], 'resistive': [101], 'states': [102], 'throughout': [103], 'dynamic': [105], 'range': [106], '(analog': [107], 'behavior).': [108], 'Moreover,': [109], 'it': [110, 153, 226], 'should': [111], 'be': [112], 'perform': [115], 'spike': [116], 'timing': [117], 'dependent': [118], 'plasticity': [119, 124], '(STDP),': [120], 'an': [121, 184], 'associative': [122], 'homosynaptic': [123], 'rule': [126, 143], 'based': [127], 'on': [128], 'delay': [130], 'time': [131], 'between': [132], 'two': [134], 'firing': [135], 'neurons': [136], 'synapse': [138], 'connected': [140], 'to.': [141], 'fundamental': [146], 'protocol': [148], 'state-of-art': [150], 'networks,': [151], 'because': [152], 'allows': [154], 'unsupervised': [155, 161, 202], 'learning.': [156], 'Notwithstanding': [157], 'fact,': [159], 'STDP-based': [160], 'has': [163], 'been': [164], 'proposed': [165], 'times': [167], 'mainly': [168], 'binary': [170, 179], 'rather': [172], 'than': [173], 'multilevel': [174], 'composed': [176], 'many': [178], 'memristors.': [180], 'paper': [182], 'proposes': [183], 'HfO<sub>2</sub>-based': [185], 'analog': [186], 'memristor': [187], 'as': [188], 'element': [191], 'which': [192], 'performs': [193], 'STDP': [194], 'within': [195], 'small': [197], 'spiking': [198], 'neuromorphic': [199], 'network': [200, 209], 'operating': [201], 'character': [205], 'recognition.': [206], 'The': [207], 'trained': [208], 'recognize': [213], 'five': [214], 'characters': [215], 'even': [216], 'case': [218], 'incomplete': [219], 'noisy': [221], 'images': [222], 'displayed': [224], 'robust': [228], 'device-to-device': [231], 'variability': [232], 'up': [234], '±30%.': [236]}",2016,"['Spiking neural network', 'Synapse', 'Computer science', 'Unsupervised learning', 'Neuroscience', 'Artificial intelligence', 'Artificial neural network', 'Psychology']","Emerging brain-inspired architectures call for devices that can emulate the functionality of biological synapses in order to implement new efficient computational schemes able to solve ill-posed problems. Various devices and solutions are still under investigation and, in this respect, a challenge is opened to the researchers in the field. Indeed, the optimal candidate is a device able to reproduce the complete functionality of a synapse, i.e., the typical synaptic process underlying learning in biological systems (activity-dependent synaptic plasticity). This implies a device able to change its resistance (synaptic strength, or weight) upon proper electrical stimuli (synaptic activity) and showing several stable resistive states throughout its dynamic range (analog behavior). Moreover, it should be able to perform spike timing dependent plasticity (STDP), an associative homosynaptic plasticity learning rule based on the delay time between the two firing neurons the synapse is connected to. This rule is a fundamental learning protocol in state-of-art networks, because it allows unsupervised learning. Notwithstanding this fact, STDP-based unsupervised learning has been proposed several times mainly for binary synapses rather than multilevel synapses composed of many binary memristors. This paper proposes an HfO<sub>2</sub>-based analog memristor as a synaptic element which performs STDP within a small spiking neuromorphic network operating unsupervised learning for character recognition. The trained network is able to recognize five characters even in case incomplete or noisy images are displayed and it is robust to a device-to-device variability of up to ±30%."
https://openalex.org/W3095121901,Unsupervised Learning of Visual Features by Contrasting Cluster Assignments,"{'International': [0], 'audience': [1]}",2020,"['Computer science', 'Unsupervised learning', 'Cluster (spacecraft)', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Operating system']",International audience
https://openalex.org/W2950789693,Building high-level features using large scale unsupervised learning,"{'We': [0, 69, 143], 'consider': [1], 'the': [2, 57, 67, 147, 190], 'problem': [3], 'of': [4, 49, 185], 'building': [5], 'high-level,': [6], 'class-specific': [7], 'feature': [8, 128], 'detectors': [9], 'from': [10, 66, 181], 'only': [11, 25, 133], 'unlabeled': [12, 26], 'data.': [13], 'For': [14], 'example,': [15], 'is': [16, 105, 130, 150], 'it': [17, 104], 'possible': [18, 106], 'to': [19, 91, 94, 107, 114, 134, 138, 152, 172], 'learn': [20], 'a': [21, 33, 46, 80, 96, 109, 119, 183], 'face': [22, 110, 120], 'detector': [23, 111, 129], 'using': [24, 73], 'images?': [27], 'To': [28], 'answer': [29], 'this,': [30], 'we': [31, 168], 'train': [32, 70, 108], '9-layered': [34], 'locally': [35], 'connected': [36], 'sparse': [37], 'autoencoder': [38], 'with': [39, 82, 164], 'pooling': [40], 'and': [41, 76, 140, 160], 'local': [42], 'contrast': [43], 'normalization': [44], 'on': [45, 79], 'large': [47], 'dataset': [48, 58], 'images': [50, 64, 116], '(the': [51], 'model': [52, 74], 'has': [53, 59], '1': [54], 'billion': [55], 'connections,': [56], '10': [60], 'million': [61], '200x200': [62], 'pixel': [63], 'downloaded': [65], 'Internet).': [68], 'this': [71, 127], 'network': [72, 149, 171], 'parallelism': [75], 'asynchronous': [77], 'SGD': [78], 'cluster': [81], '1,000': [83], 'machines': [84], '(16,000': [85], 'cores)': [86], 'for': [87], 'three': [88], 'days.': [89], 'Contrary': [90], 'what': [92], 'appears': [93], 'be': [95], 'widely-held': [97], 'intuition,': [98], 'our': [99, 170], 'experimental': [100], 'results': [101], 'reveal': [102], 'that': [103, 126, 146], 'without': [112], 'having': [113], 'label': [115], 'as': [117, 157], 'containing': [118], 'or': [121], 'not.': [122], 'Control': [123], 'experiments': [124], 'show': [125], 'robust': [131], 'not': [132], 'translation': [135], 'but': [136], 'also': [137, 144], 'scaling': [139], 'out-of-plane': [141], 'rotation.': [142], 'find': [145], 'same': [148], 'sensitive': [151], 'other': [153], 'high-level': [154], 'concepts': [155], 'such': [156], 'cat': [158], 'faces': [159], 'human': [161], 'bodies.': [162], 'Starting': [163], 'these': [165], 'learned': [166], 'features,': [167], 'trained': [169], 'obtain': [173], '15.8%': [174], 'accuracy': [175], 'in': [176], 'recognizing': [177], '20,000': [178], 'object': [179], 'categories': [180], 'ImageNet,': [182], 'leap': [184], '70%': [186], 'relative': [187], 'improvement': [188], 'over': [189], 'previous': [191], 'state-of-the-art.': [192]}",2011,"['Artificial intelligence', 'Computer science', 'Normalization (sociology)', 'Autoencoder', 'Pattern recognition (psychology)', 'Detector', 'Pooling', 'Deep learning', 'Machine learning', 'Computer vision', 'Anthropology', 'Sociology', 'Telecommunications']","We consider the problem of building high-level, class-specific feature detectors from only unlabeled data. For example, is it possible to learn a face detector using only unlabeled images? To answer this, we train a 9-layered locally connected sparse autoencoder with pooling and local contrast normalization on a large dataset of images (the model has 1 billion connections, the dataset has 10 million 200x200 pixel images downloaded from the Internet). We train this network using model parallelism and asynchronous SGD on a cluster with 1,000 machines (16,000 cores) for three days. Contrary to what appears to be a widely-held intuition, our experimental results reveal that it is possible to train a face detector without having to label images as containing a face or not. Control experiments show that this feature detector is robust not only to translation but also to scaling and out-of-plane rotation. We also find that the same network is sensitive to other high-level concepts such as cat faces and human bodies. Starting with these learned features, we trained our network to obtain 15.8% accuracy in recognizing 20,000 object categories from ImageNet, a leap of 70% relative improvement over the previous state-of-the-art."
https://openalex.org/W2337374958,Joint Unsupervised Learning of Deep Representations and Image Clusters,"{'In': [0, 19], 'this': [1, 76], 'paper,': [2], 'we': [3, 114], 'propose': [4], 'a': [5, 25, 33, 43, 101, 105, 141], 'recurrent': [6, 34], 'framework': [7, 77], 'for': [8], 'Joint': [9], 'Unsupervised': [10], 'LEarning': [11], '(JULE)': [12], 'of': [13, 39, 143], 'deep': [14], 'representations': [15, 40, 53, 81, 149], 'and': [16, 52, 87, 110], 'image': [17, 50, 57, 85, 126, 138, 144], 'clusters.': [18, 127], 'our': [20, 132], 'framework,': [21], 'successive': [22], 'operations': [23], 'in': [24, 32, 61, 68], 'clustering': [26, 58, 86, 88, 139], 'algorithm': [27], 'are': [28, 54, 82], 'expressed': [29], 'as': [30], 'steps': [31], 'process,': [35], 'stacked': [36], 'on': [37, 137], 'top': [38], 'output': [41], 'by': [42], 'Convolutional': [44], 'Neural': [45], 'Network': [46], '(CNN).': [47], 'During': [48], 'training,': [49], 'clusters': [51], 'updated': [55], 'jointly:': [56], 'is': [59, 78], 'conducted': [60], 'the': [62, 69, 135, 147], 'forward': [63], 'pass,': [64], 'while': [65], 'representation': [66, 94], 'learning': [67], 'backward': [70], 'pass.': [71], 'Our': [72], 'key': [73], 'idea': [74], 'behind': [75], 'that': [79, 131], 'good': [80], 'beneficial': [83], 'to': [84, 93, 154], 'results': [89], 'provide': [90], 'supervisory': [91], 'signals': [92], 'learning.': [95], 'By': [96], 'integrating': [97], 'two': [98], 'processes': [99], 'into': [100], 'single': [102], 'model': [103], 'with': [104], 'unified': [106], 'weighted': [107], 'triplet': [108], 'loss': [109], 'optimizing': [111], 'it': [112], 'end-to-end,': [113], 'can': [115], 'obtain': [116], 'not': [117], 'only': [118], 'more': [119, 124], 'powerful': [120], 'representations,': [121], 'but': [122], 'also': [123], 'precise': [125], 'Extensive': [128], 'experiments': [129], 'show': [130], 'method': [133], 'outperforms': [134], 'state-of-the-art': [136], 'across': [140], 'variety': [142], 'datasets.': [145], 'Moreover,': [146], 'learned': [148], 'generalize': [150], 'well': [151], 'when': [152], 'transferred': [153], 'other': [155], 'tasks.': [156]}",2016,"['Cluster analysis', 'Computer science', 'Artificial intelligence', 'Image (mathematics)', 'Representation (politics)', 'Feature learning', 'Pattern recognition (psychology)', 'Convolutional neural network', 'Unsupervised learning', 'Deep learning', 'Key (lock)', 'Machine learning', 'Computer security', 'Political science', 'Politics', 'Law']","In this paper, we propose a recurrent framework for Joint Unsupervised LEarning (JULE) of deep representations and image clusters. In our framework, successive operations in a clustering algorithm are expressed as steps in a recurrent process, stacked on top of representations output by a Convolutional Neural Network (CNN). During training, image clusters and representations are updated jointly: image clustering is conducted in the forward pass, while representation learning in the backward pass. Our key idea behind this framework is that good representations are beneficial to image clustering and clustering results provide supervisory signals to representation learning. By integrating two processes into a single model with a unified weighted triplet loss and optimizing it end-to-end, we can obtain not only more powerful representations, but also more precise image clusters. Extensive experiments show that our method outperforms the state-of-the-art on image clustering across a variety of image datasets. Moreover, the learned representations generalize well when transferred to other tasks."
https://openalex.org/W2105000456,Cue Integration With Categories: Weighting Acoustic Cues in Speech Using Unsupervised Learning and Distributional Statistics,"{'Abstract': [0], 'During': [1], 'speech': [2, 53, 136], 'perception,': [3], 'listeners': [4, 29, 36], 'make': [5], 'judgments': [6], 'about': [7], 'the': [8, 49, 74, 106, 120, 135], 'phonological': [9, 22, 99], 'category': [10, 50], 'of': [11, 16, 48, 63, 76, 94, 122], 'sounds': [12], 'by': [13], 'taking': [14], 'advantage': [15], 'multiple': [17], 'acoustic': [18, 40], 'cues': [19, 32, 41, 72, 88], 'for': [20, 51], 'each': [21], 'contrast.': [23], 'Perceptual': [24], 'experiments': [25], 'have': [26], 'shown': [27], 'that': [28, 66, 82, 127], 'weight': [30, 37, 90], 'these': [31, 116], 'differently.': [33], 'How': [34], 'do': [35], 'and': [38, 70], 'combine': [39, 71], 'to': [42, 105], 'arrive': [43], 'at': [44, 97], 'an': [45], 'overall': [46], 'estimate': [47], 'a': [52, 61, 83, 92, 102], 'sound?': [54], 'Here,': [55], 'we': [56], 'present': [57], 'several': [58], 'simulations': [59], 'using': [60], 'mixture': [62], 'Gaussians': [64], 'models': [65], 'learn': [67], 'cue': [68, 128], 'weights': [69, 117, 129], 'on': [73], 'basis': [75], 'their': [77, 95], 'distributional': [78], 'statistics.': [79], 'We': [80], 'show': [81], 'cue‐weighting': [84], 'metric': [85], 'in': [86], 'which': [87], 'receive': [89], 'as': [91], 'function': [93], 'reliability': [96], 'distinguishing': [98], 'categories': [100], 'provides': [101], 'good': [103], 'fit': [104], 'perceptual': [107], 'data': [108], 'obtained': [109], 'from': [110, 134], 'human': [111], 'listeners,': [112], 'but': [113], 'only': [114], 'when': [115], 'emerge': [118], 'through': [119, 138], 'dynamics': [121], 'learning.': [123], 'These': [124], 'results': [125], 'suggest': [126], 'can': [130], 'be': [131], 'readily': [132], 'extracted': [133], 'signal': [137], 'unsupervised': [139], 'learning': [140], 'processes.': [141]}",2010,"['Weighting', 'Perception', 'Speech recognition', 'Contrast (vision)', 'Speech perception', 'Metric (unit)', 'Computer science', 'Psychology', 'Pattern recognition (psychology)', 'Artificial intelligence', 'Operations management', 'Economics', 'Radiology', 'Neuroscience', 'Medicine']","Abstract During speech perception, listeners make judgments about the phonological category of sounds by taking advantage of multiple acoustic cues for each phonological contrast. Perceptual experiments have shown that listeners weight these cues differently. How do listeners weight and combine acoustic cues to arrive at an overall estimate of the category for a speech sound? Here, we present several simulations using a mixture of Gaussians models that learn cue weights and combine cues on the basis of their distributional statistics. We show that a cue‐weighting metric in which cues receive weight as a function of their reliability at distinguishing phonological categories provides a good fit to the perceptual data obtained from human listeners, but only when these weights emerge through the dynamics of learning. These results suggest that cue weights can be readily extracted from the speech signal through unsupervised learning processes."
https://openalex.org/W2134368421,Unsupervised learning of generalized names,"{'We': [0, 78, 88], 'present': [1, 79], 'an': [2], 'algorithm,': [3], 'NOMEN,': [4], 'for': [5], 'learning': [6, 71], 'generalized': [7], 'names': [8, 15, 27, 76], 'in': [9], 'text.': [10], 'Examples': [11], 'of': [12, 16, 39, 48, 53, 57, 65, 72, 75, 81, 94], 'these': [13], 'are': [14], 'diseases': [17], 'and': [18, 24, 56], 'infectious': [19], 'agents,': [20], 'such': [21], 'as': [22], 'bacteria': [23], 'viruses.': [25], 'These': [26], 'exhibit': [28], 'certain': [29], 'properties': [30], 'that': [31, 38], 'make': [32], 'their': [33, 58], 'identification': [34], 'more': [35], 'complex': [36], 'than': [37], 'regular': [40], 'proper': [41], 'names,': [42], 'NOMEN': [43], 'uses': [44], 'a': [45, 85], 'novel': [46], 'form': [47], 'bootstrapping': [49], 'to': [50, 68], 'grow': [51], 'sets': [52], 'textual': [54], 'instances': [55], 'contextual': [59], 'patterns.': [60], 'The': [61], 'algorithm': [62, 83], 'makes': [63], 'use': [64], 'competing': [66], 'evidence': [67], 'boost': [69], 'the': [70, 82, 91], 'several': [73, 95], 'categories': [74], 'simultaneously.': [77], 'results': [80], 'on': [84], 'large': [86], 'corpus.': [87], 'also': [89], 'investigate': [90], 'relative': [92], 'merits': [93], 'evaluation': [96], 'strategies.': [97]}",2002,"['Bootstrapping (finance)', 'Computer science', 'Identification (biology)', 'Artificial intelligence', 'Natural language processing', 'Mathematics', 'Botany', 'Biology', 'Econometrics']","We present an algorithm, NOMEN, for learning generalized names in text. Examples of these are names of diseases and infectious agents, such as bacteria and viruses. These names exhibit certain properties that make their identification more complex than that of regular proper names, NOMEN uses a novel form of bootstrapping to grow sets of textual instances and of their contextual patterns. The algorithm makes use of competing evidence to boost the learning of several categories of names simultaneously. We present results of the algorithm on a large corpus. We also investigate the relative merits of several evaluation strategies."
https://openalex.org/W2758785877,Unsupervised Learning of Disentangled and Interpretable Representations from Sequential Data,"{'We': [0], 'present': [1], 'a': [2, 34], 'factorized': [3, 35], 'hierarchical': [4, 36], 'variational': [5], 'autoencoder,': [6], 'which': [7], 'learns': [8], 'disentangled': [9], 'and': [10, 43, 78, 90], 'interpretable': [11], 'representations': [12], 'from': [13], 'sequential': [14, 27], 'data': [15, 28], 'without': [16], 'supervision.': [17], 'Specifically,': [18], 'we': [19], 'exploit': [20], 'the': [21, 92], 'multi-scale': [22], 'nature': [23], 'of': [24, 49, 75], 'information': [25], 'in': [26, 101], 'by': [29, 71, 96], 'formulating': [30], 'it': [31], 'explicitly': [32], 'within': [33], 'graphical': [37], 'model': [38, 53], 'that': [39], 'imposes': [40], 'sequence-dependent': [41], 'priors': [42, 45], 'sequence-independent': [44], 'to': [46, 60, 65, 82], 'different': [47, 73], 'sets': [48, 74], 'latent': [50, 76], 'variables.': [51], 'The': [52], 'is': [54], 'evaluated': [55], 'on': [56], 'two': [57], 'speech': [58, 107], 'corpora': [59], 'demonstrate,': [61], 'qualitatively,': [62], 'its': [63, 80], 'ability': [64, 81], 'transform': [66], 'speakers': [67], 'or': [68], 'linguistic': [69], 'content': [70], 'manipulating': [72], 'variables;': [77], 'quantitatively,': [79], 'outperform': [83], 'an': [84], 'i-vector': [85], 'baseline': [86], 'for': [87, 105], 'speaker': [88], 'verification': [89], 'reduce': [91], 'word': [93], 'error': [94], 'rate': [95], 'as': [97, 99], 'much': [98], '35%': [100], 'mismatched': [102], 'train/test': [103], 'scenarios': [104], 'automatic': [106], 'recognition': [108], 'tasks.': [109]}",2017,"['Prior probability', 'Computer science', 'Autoencoder', 'Sequence (biology)', 'Artificial intelligence', 'Latent variable', 'Word (group theory)', 'Natural language processing', 'Pattern recognition (psychology)', 'Machine learning', 'Artificial neural network', 'Mathematics', 'Bayesian probability', 'Biology', 'Genetics', 'Geometry']","We present a factorized hierarchical variational autoencoder, which learns disentangled and interpretable representations from sequential data without supervision. Specifically, we exploit the multi-scale nature of information in sequential data by formulating it explicitly within a factorized hierarchical graphical model that imposes sequence-dependent priors and sequence-independent priors to different sets of latent variables. The model is evaluated on two speech corpora to demonstrate, qualitatively, its ability to transform speakers or linguistic content by manipulating different sets of latent variables; and quantitatively, its ability to outperform an i-vector baseline for speaker verification and reduce the word error rate by as much as 35% in mismatched train/test scenarios for automatic speech recognition tasks."
https://openalex.org/W2594132308,Revisiting unsupervised learning for defect prediction,"{'Collecting': [0], 'quality': [1], 'data': [2, 36, 129], 'from': [3, 34], 'software': [4, 98], 'projects': [5], 'can': [6, 52], 'be': [7, 195], 'time-consuming': [8], 'and\\nexpensive.': [9], 'Hence,': [10, 191], 'some': [11, 127, 196], 'researchers': [12, 43], 'explore': [13], '""unsupervised""': [14], 'approaches': [15, 30], 'to': [16, 83, 132, 155, 200, 204, 210], 'quality\\nprediction': [17], 'that': [18, 31, 93], 'does': [19], 'not': [20, 180], 'require': [21], 'labelled': [22, 37], 'data.': [23], 'An': [24], 'alternate': [25], 'technique': [26], 'is': [27, 49, 94, 112, 130], 'to\\nuse': [28], '""supervised""': [29], 'learn': [32], 'models': [33], 'project': [35], 'with,\\nsay,': [38], '""defective""': [39], 'or': [40], '""not-defective"".': [41], 'Most': [42], 'use': [44], 'these': [45, 79], 'supervised\\nmodels': [46], 'since,': [47], 'it': [48], 'argued,': [50], 'they': [51, 192], 'exploit': [53], 'more': [54], 'knowledge': [55], 'of': [56, 86, 117, 165], 'the': [57, 97, 115, 118, 162], 'projects.\\n': [58], 'At': [59], ""FSE'16,"": [60], 'Yang': [61, 119, 166], 'et': [62, 120, 167], 'al.': [63, 121], 'reported': [64], 'startling': [65], 'results': [66, 80, 107], 'where': [67], 'unsupervised': [68, 185], 'defect\\npredictors': [69], 'outperformed': [70], 'supervised': [71, 128, 151, 178, 205], 'predictors': [72, 122, 135, 152], 'for': [73, 187], 'effort-aware': [74], 'just-in-time\\ndefect': [75], 'prediction.': [76, 190], 'If': [77], 'confirmed,': [78], 'would': [81], 'lead': [82], 'a': [84, 87, 148], 'dramatic\\nsimplification': [85], 'seemingly': [88], 'complex': [89], 'task': [90], '(data': [91], 'mining)': [92], 'widely\\nexplored': [95], 'in': [96, 114, 212], 'engineering': [99], 'literature.\\n': [100], 'This': [101], 'paper': [102, 160], 'repeats': [103], 'and': [104], 'refutes': [105], 'those': [106], 'as': [108], 'follows.': [109], '(1)': [110], 'There': [111], 'much\\nvariability': [113], 'efficacy': [116], 'so': [123], 'even': [124], 'with': [125], 'their\\napproach,': [126], 'required': [131], 'prune': [133], 'weaker': [134], 'away.\\n(2)Their': [136], 'findings': [137], 'were': [138], 'grouped': [139], 'across': [140], '$N$': [141], 'projects.': [142], 'When': [143], 'we': [144], 'repeat': [145], 'their\\nanalysis': [146], 'on': [147], 'project-by-project': [149], 'basis,': [150], 'are': [153], 'seen': [154], 'work\\nbetter.\\n': [156], 'Even': [157], 'though': [158], 'this': [159, 213], 'rejects': [161], 'specific': [163], 'conclusions': [164], 'al.,': [168], 'we\\nstill': [169], 'endorse': [170], 'their': [171], 'general': [172], 'goal.': [173], 'In': [174], 'our': [175, 176], 'experiments,': [177], 'predictors\\ndid': [179], 'perform': [181], 'outstandingly': [182], 'better': [183], 'than': [184], 'ones': [186], 'effort-aware\\njust-in-time': [188], 'defect': [189], 'may': [193], 'indeed': [194], 'combination': [197], 'of\\nunsupervised': [198], 'learners': [199], 'achieve': [201], 'comparable': [202], 'performance': [203], 'ones.': [206], 'We\\ntherefore': [207], 'encourage': [208], 'others': [209], 'work': [211], 'promising': [214], 'area.\\n': [215]}",2017,[],"Collecting quality data from software projects can be time-consuming and\nexpensive. Hence, some researchers explore ""unsupervised"" approaches to quality\nprediction that does not require labelled data. An alternate technique is to\nuse ""supervised"" approaches that learn models from project data labelled with,\nsay, ""defective"" or ""not-defective"". Most researchers use these supervised\nmodels since, it is argued, they can exploit more knowledge of the projects.\n At FSE'16, Yang et al. reported startling results where unsupervised defect\npredictors outperformed supervised predictors for effort-aware just-in-time\ndefect prediction. If confirmed, these results would lead to a dramatic\nsimplification of a seemingly complex task (data mining) that is widely\nexplored in the software engineering literature.\n This paper repeats and refutes those results as follows. (1) There is much\nvariability in the efficacy of the Yang et al. predictors so even with their\napproach, some supervised data is required to prune weaker predictors away.\n(2)Their findings were grouped across $N$ projects. When we repeat their\nanalysis on a project-by-project basis, supervised predictors are seen to work\nbetter.\n Even though this paper rejects the specific conclusions of Yang et al., we\nstill endorse their general goal. In our our experiments, supervised predictors\ndid not perform outstandingly better than unsupervised ones for effort-aware\njust-in-time defect prediction. Hence, they may indeed be some combination of\nunsupervised learners to achieve comparable performance to supervised ones. We\ntherefore encourage others to work in this promising area.\n"
https://openalex.org/W2903922555,Almost Unsupervised Learning for Dense Crowd Counting,"{'We': [0], 'present': [1, 156], 'an': [2], 'unsupervised': [3, 142], 'learning': [4], 'method': [5], 'for': [6, 33], 'dense': [7], 'crowd': [8, 40, 82], 'count': [9], 'estimation.': [10], 'Marred': [11], 'by': [12, 64], 'large': [13], 'variability': [14], 'in': [15, 22], 'appearance': [16], 'of': [17, 52, 60, 77, 95, 113, 116, 151, 163], 'people': [18, 25], 'and': [19, 44, 144, 158], 'extreme': [20], 'overlap': [21], 'crowds,': [23], 'enumerating': [24], 'proves': [26], 'to': [27, 73, 107, 140, 148], 'be': [28], 'a': [29, 47, 88, 93], 'difficult': [30], 'task': [31], 'even': [32], 'humans.': [34], 'This': [35], 'implies': [36], 'creating': [37], 'large-scale': [38], 'annotated': [39], 'data': [41, 125], 'is': [42, 105], 'expensive': [43], 'directly': [45], 'takes': [46], 'toll': [48], 'on': [49, 58], 'the': [50, 101, 109, 114, 117, 127, 149, 161], 'performance': [51], 'existing': [53], 'CNN': [54], 'based': [55], 'counting': [56], 'models': [57], 'account': [59], 'small': [61], 'datasets.': [62], 'Motivated': [63], 'these': [65], 'challenges,': [66], 'we': [67, 155], 'develop': [68], 'Grid': [69], 'Winner-Take-All': [70], '(GWTA)': [71], 'autoencoder': [72], 'learn': [74], 'several': [75], 'layers': [76], 'useful': [78], 'filters': [79], 'from': [80], 'unlabeled': [81], 'images.': [83], 'Our': [84], 'GWTA': [85], 'approach': [86], 'divides': [87], 'convolution': [89], 'layer': [90], 'spatially': [91], 'into': [92], 'grid': [94], 'cells.': [96], 'Within': [97], 'each': [98], 'cell,': [99], 'only': [100], 'maximally': [102], 'activated': [103], 'neuron': [104], 'allowed': [106], 'update': [108], 'filter.': [110], 'Almost': [111], '99.9%': [112], 'parameters': [115], 'proposed': [118], 'model': [119, 135], 'are': [120, 130], 'trained': [121], 'without': [122], 'any': [123], 'labeled': [124], 'while': [126], 'rest': [128], '0.1%': [129], 'tuned': [131], 'with': [132], 'supervision.': [133], 'The': [134], 'achieves': [136], 'superior': [137], 'results': [138], 'compared': [139], 'other': [141], 'methods': [143], 'stays': [145], 'reasonably': [146], 'close': [147], 'accuracy': [150], 'supervised': [152], 'baseline.': [153], 'Furthermore,': [154], 'comparisons': [157], 'analyses': [159], 'regarding': [160], 'quality': [162], 'learned': [164], 'features': [165], 'across': [166], 'various': [167], 'models.': [168]}",2019,"['Autoencoder', 'Computer science', 'Crowds', 'Unsupervised learning', 'Artificial intelligence', 'Grid', 'Filter (signal processing)', 'Task (project management)', 'Pattern recognition (psychology)', 'Convolution (computer science)', 'Machine learning', 'Labeled data', 'Deep learning', 'Computer vision', 'Mathematics', 'Artificial neural network', 'Management', 'Geometry', 'Computer security', 'Economics']","We present an unsupervised learning method for dense crowd count estimation. Marred by large variability in appearance of people and extreme overlap in crowds, enumerating people proves to be a difficult task even for humans. This implies creating large-scale annotated crowd data is expensive and directly takes a toll on the performance of existing CNN based counting models on account of small datasets. Motivated by these challenges, we develop Grid Winner-Take-All (GWTA) autoencoder to learn several layers of useful filters from unlabeled crowd images. Our GWTA approach divides a convolution layer spatially into a grid of cells. Within each cell, only the maximally activated neuron is allowed to update the filter. Almost 99.9% of the parameters of the proposed model are trained without any labeled data while the rest 0.1% are tuned with supervision. The model achieves superior results compared to other unsupervised methods and stays reasonably close to the accuracy of supervised baseline. Furthermore, we present comparisons and analyses regarding the quality of learned features across various models."
https://openalex.org/W2946254251,Evaluation Metrics for Unsupervised Learning Algorithms,"{'Determining': [0], 'the': [1, 4, 22, 50, 57, 60, 64], 'quality': [2, 51], 'of': [3, 25, 43, 52, 59], 'results': [5, 54], 'obtained': [6], 'by': [7], 'clustering': [8, 27, 53, 61], 'techniques': [9, 47], 'is': [10], 'a': [11, 39, 41], 'key': [12], 'issue': [13], 'in': [14], 'unsupervised': [15], 'machine': [16], 'learning.': [17], 'Many': [18], 'authors': [19], 'have': [20, 45], 'discussed': [21], 'desirable': [23], 'features': [24], 'good': [26], 'algorithms.': [28], 'However,': [29], 'Jon': [30], 'Kleinberg': [31], 'established': [32], 'an': [33], 'impossibility': [34], 'theorem': [35], 'for': [36], 'clustering.': [37], 'As': [38], 'consequence,': [40], 'wealth': [42], 'studies': [44], 'proposed': [46], 'to': [48, 68], 'evaluate': [49], 'depending': [55], 'on': [56], 'characteristics': [58], 'problem': [62], 'and': [63], 'algorithmic': [65], 'technique': [66], 'employed': [67], 'cluster': [69], 'data.': [70]}",2019,"['Cluster analysis', 'Computer science', 'Conceptual clustering', 'Impossibility', 'Unsupervised learning', 'Artificial intelligence', 'Machine learning', 'Correlation clustering', 'Key (lock)', 'Quality (philosophy)', 'Cluster (spacecraft)', 'Data mining', 'CURE data clustering algorithm', 'Algorithm', 'Computer security', 'Political science', 'Programming language', 'Epistemology', 'Law', 'Philosophy']","Determining the quality of the results obtained by clustering techniques is a key issue in unsupervised machine learning. Many authors have discussed the desirable features of good clustering algorithms. However, Jon Kleinberg established an impossibility theorem for clustering. As a consequence, a wealth of studies have proposed techniques to evaluate the quality of clustering results depending on the characteristics of the clustering problem and the algorithmic technique employed to cluster data."
https://openalex.org/W2461267643,Feuding Families and Former Friends: Unsupervised Learning for Dynamic Fictional Relationships,"{'Mohit': [0], 'Iyyer,': [1], 'Anupam': [2], 'Guha,': [3], 'Snigdha': [4], 'Chaturvedi,': [5], 'Jordan': [6], 'Boyd-Graber,': [7], 'Hal': [8], 'Daumé': [9], 'III.': [10], 'Proceedings': [11], 'of': [12, 16, 21], 'the': [13, 17, 22], '2016': [14], 'Conference': [15], 'North': [18], 'American': [19], 'Chapter': [20], 'Association': [23], 'for': [24], 'Computational': [25], 'Linguistics:': [26], 'Human': [27], 'Language': [28], 'Technologies.': [29], '2016.': [30]}",2016,"['Computer science', 'Natural language processing', 'Linguistics', 'Artificial intelligence', 'Cognitive science', 'Sociology', 'Psychology', 'Philosophy']","Mohit Iyyer, Anupam Guha, Snigdha Chaturvedi, Jordan Boyd-Graber, Hal Daumé III. Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2016."
https://openalex.org/W2047733998,Supervised and unsupervised learning of multidimensional acoustic categories.,"{'Learning': [0, 96], 'to': [1, 40, 102, 148, 165], 'recognize': [2], 'the': [3, 23, 93, 97, 129, 134, 139, 153, 157], 'contrasts': [4], 'of': [5, 25], 'a': [6, 17, 63, 66, 120], 'language-specific': [7], 'phonemic': [8], 'repertoire': [9], 'can': [10], 'be': [11, 103], 'viewed': [12], 'as': [13, 112, 114], 'forming': [14], 'categories': [15, 29, 33, 46, 135], 'in': [16, 88, 156], 'multidimensional': [18, 45, 67, 98, 122], 'psychophysical': [19], 'space.': [20], 'Research': [21], 'on': [22], 'learning': [24, 44, 91, 94], 'distributionally': [26], 'defined': [27, 34, 117], 'visual': [28], 'has': [30], 'shown': [31], 'that': [32, 43, 132, 144], 'over': [35], '1': [36], 'dimension': [37], 'are': [38, 146], 'easy': [39], 'learn': [41], 'and': [42, 83, 107, 152], 'is': [47], 'more': [48, 105], 'difficult': [49, 106], 'but': [50], 'tractable': [51], 'under': [52], 'specific': [53], 'task': [54], 'conditions.': [55], 'In': [56], '2': [57, 167], 'experiments,': [58], 'adult': [59], 'participants': [60], 'learned': [61, 82, 121, 164], 'either': [62], 'unidimensional': [64, 78], 'or': [65, 71], 'category': [68, 90, 99, 123], 'distinction': [69, 100, 124], 'with': [70, 115, 171], 'without': [72], 'supervision': [73, 84, 108], '(feedback)': [74], 'during': [75], 'learning.': [76], 'The': [77], 'distinctions': [79], 'were': [80], 'readily': [81], 'proved': [85, 101], 'beneficial,': [86], 'especially': [87], 'maintaining': [89], 'beyond': [92], 'phase.': [95, 141], 'much': [104], 'was': [109, 125], 'not': [110], 'nearly': [111], 'beneficial': [113], 'unidimensionally': [116], 'categories.': [118], 'Maintaining': [119], 'only': [126], 'possible': [127], 'when': [128], 'distributional': [130, 154], 'information': [131, 155], 'identified': [133], 'remained': [136], 'present': [137], 'throughout': [138], 'testing': [140], 'We': [142], 'conclude': [143], 'listeners': [145, 163], 'sensitive': [147], 'both': [149], 'trial-by-trial': [150], 'feedback': [151], 'stimuli.': [158], 'Even': [159], 'given': [160], 'limited': [161], 'exposure,': [162], 'use': [166], 'relevant': [168], 'dimensions,': [169], 'albeit': [170], 'considerable': [172], 'difficulty.': [173]}",2009,"['Dimension (graph theory)', 'Categorization', 'Cognitive psychology', 'Concept learning', 'Psychology', 'Space (punctuation)', 'Task (project management)', 'Multidimensional analysis', 'Artificial intelligence', 'Computer science', 'Natural language processing', 'Machine learning', 'Mathematics', 'Statistics', 'Pure mathematics', 'Operating system', 'Management', 'Economics']","Learning to recognize the contrasts of a language-specific phonemic repertoire can be viewed as forming categories in a multidimensional psychophysical space. Research on the learning of distributionally defined visual categories has shown that categories defined over 1 dimension are easy to learn and that learning multidimensional categories is more difficult but tractable under specific task conditions. In 2 experiments, adult participants learned either a unidimensional or a multidimensional category distinction with or without supervision (feedback) during learning. The unidimensional distinctions were readily learned and supervision proved beneficial, especially in maintaining category learning beyond the learning phase. Learning the multidimensional category distinction proved to be much more difficult and supervision was not nearly as beneficial as with unidimensionally defined categories. Maintaining a learned multidimensional category distinction was only possible when the distributional information that identified the categories remained present throughout the testing phase. We conclude that listeners are sensitive to both trial-by-trial feedback and the distributional information in the stimuli. Even given limited exposure, listeners learned to use 2 relevant dimensions, albeit with considerable difficulty."
https://openalex.org/W2751471435,A Disentangled Recognition and Nonlinear Dynamics Model for Unsupervised Learning,"{'This': [0], 'paper': [1], 'takes': [2], 'a': [3, 9, 24, 44, 62, 66, 73, 108], 'step': [4], 'towards': [5], 'temporal': [6], 'reasoning': [7], 'in': [8, 14, 23, 35, 118], 'dynamically': [10], 'changing': [11], 'video,': [12], 'not': [13], 'the': [15, 29, 33, 40, 75, 78, 89], 'pixel': [16], 'space': [17, 26], 'that': [18, 27, 52], 'constitutes': [19], 'its': [20, 36, 70], 'frames,': [21], 'but': [22], 'latent': [25, 55, 67], 'describes': [28], 'non-linear': [30], 'dynamics': [31], 'of': [32, 49, 77, 107, 110], 'objects': [34], 'world.': [37], 'We': [38], 'introduce': [39], 'Kalman': [41], 'variational': [42], 'auto-encoder,': [43], 'framework': [45], 'for': [46], 'unsupervised': [47], 'learning': [48], 'sequential': [50], 'data': [51, 85, 122], 'disentangles': [53], 'two': [54], 'representations:': [56], 'an': [57], ""object's"": [58], 'representation,': [59], 'coming': [60], 'from': [61], 'recognition': [63], 'model,': [64], 'and': [65, 83, 114, 120], 'state': [68], 'describing': [69], 'dynamics.': [71], 'As': [72], 'result,': [74], 'evolution': [76], 'world': [79], 'can': [80], 'be': [81], 'imagined': [82], 'missing': [84, 121], 'imputed,': [86], 'both': [87], 'without': [88], 'need': [90], 'to': [91], 'generate': [92], 'high': [93], 'dimensional': [94], 'frames': [95], 'at': [96], 'each': [97], 'time': [98], 'step.': [99], 'The': [100], 'model': [101], 'is': [102], 'trained': [103], 'end-to-end': [104], 'on': [105], 'videos': [106], 'variety': [109], 'simulated': [111], 'physical': [112], 'systems,': [113], 'outperforms': [115], 'competing': [116], 'methods': [117], 'generative': [119], 'imputation': [123], 'tasks.': [124]}",2017,"['Dynamics (music)', 'Nonlinear system', 'Computer science', 'Unsupervised learning', 'Artificial intelligence', 'Psychology', 'Physics', 'Pedagogy', 'Quantum mechanics']","This paper takes a step towards temporal reasoning in a dynamically changing video, not in the pixel space that constitutes its frames, but in a latent space that describes the non-linear dynamics of the objects in its world. We introduce the Kalman variational auto-encoder, a framework for unsupervised learning of sequential data that disentangles two latent representations: an object's representation, coming from a recognition model, and a latent state describing its dynamics. As a result, the evolution of the world can be imagined and missing data imputed, both without the need to generate high dimensional frames at each time step. The model is trained end-to-end on videos of a variety of simulated physical systems, and outperforms competing methods in generative and missing data imputation tasks."
https://openalex.org/W3096925471,The Hidden Pandemic of Family Violence During COVID-19: Unsupervised Learning of Tweets,"{'Background': [0], 'Family': [1], 'violence': [2, 24, 54, 71, 108, 119, 132, 144, 156, 168, 191, 251, 259], '(including': [3], 'intimate': [4], 'partner': [5], 'violence/domestic': [6], 'violence,': [7, 137], 'child': [8, 134], 'abuse,': [9, 135, 159], 'and': [10, 28, 30, 35, 55, 72, 90, 95, 109, 117, 176, 216, 223, 284], 'elder': [11], 'abuse)': [12], 'is': [13, 269], 'a': [14, 46], 'hidden': [15], 'pandemic': [16, 58, 262], 'happening': [17], 'alongside': [18], 'COVID-19.': [19], 'The': [20], 'rates': [21], 'of': [22, 49, 130, 142, 166, 183, 247], 'family': [23, 53, 70, 107, 118, 131, 143, 155, 167, 190, 250, 258], 'are': [25, 32, 252], 'rising': [26, 121], 'fast,': [27], 'women': [29, 182], 'children': [31], 'disproportionately': [33], 'affected': [34], 'vulnerable': [36], 'during': [37, 260], 'this': [38], 'time.': [39], 'Objective': [40], 'This': [41, 234, 268], 'study': [42, 235], 'aims': [43], 'to': [44, 69, 77, 154, 256], 'provide': [45], 'large-scale': [47], 'analysis': [48], 'public': [50], 'discourse': [51], 'on': [52, 59, 106, 244, 249], 'the': [56, 83, 110, 170, 239, 245, 261], 'COVID-19': [57, 73, 111, 116, 248], 'Twitter.': [60], 'Methods': [61], 'We': [62, 81, 99, 254], 'analyzed': [63], 'over': [64], '1': [65], 'million': [66], 'tweets': [67, 105], 'related': [68], 'from': [74, 103], 'April': [75], '12': [76], 'July': [78], '16,': [79], '2020.': [80], 'used': [82], 'machine': [84], 'learning': [85], 'approach': [86], 'Latent': [87], 'Dirichlet': [88], 'Allocation': [89], 'identified': [91], 'salient': [92], 'themes,': [93], 'topics,': [94], 'representative': [96], 'tweets.': [97, 267], 'Results': [98], 'extracted': [100], '9': [101], 'themes': [102], '1,015,874': [104], 'pandemic:': [112], '(1)': [113], 'increased': [114], 'vulnerability:': [115], '(eg,': [120, 133, 145, 157, 169, 192, 204, 218, 228], 'rates,': [122], 'increases': [123], 'in': [124, 238], 'hotline': [125], 'calls,': [126, 206], 'homicide);': [127], '(2)': [128], 'types': [129], 'domestic': [136, 225], 'sexual': [138], 'abuse);': [139], '(3)': [140], 'forms': [141], 'physical': [146], 'aggression,': [147], 'coercive': [148], 'control);': [149], '(4)': [150], 'risk': [151], 'factors': [152], 'linked': [153], 'alcohol': [158], 'financial': [160], 'constraints,': [161], 'guns,': [162], 'quarantine);': [163], '(5)': [164], 'victims': [165, 283], 'LGBTQ': [171], '[lesbian,': [172], 'gay,': [173], 'bisexual,': [174], 'transgender,': [175], 'queer': [177], 'or': [178], 'questioning]': [179], 'community,': [180], 'women,': [181], 'color,': [184], 'children);': [185], '(6)': [186], 'social': [187, 194, 214], 'services': [188], 'for': [189, 271, 282, 289], 'hotlines,': [193], 'workers,': [195], 'confidential': [196], 'services,': [197], 'shelters,': [198], 'funding);': [199], '(7)': [200], 'law': [201], 'enforcement': [202], 'response': [203], '911': [205], 'police': [207], 'arrest,': [208], 'protective': [209], 'orders,': [210], 'abuse': [211], 'reports);': [212], '(8)': [213], 'movements': [215], 'awareness': [217], 'support': [219, 281], 'victims,': [220], 'raise': [221], 'awareness);': [222], '(9)': [224], 'violence–related': [226], 'news': [227], 'Tara': [229], 'Reade,': [230], 'Melissa': [231], 'DeRosa).': [232], 'Conclusions': [233], 'overcomes': [236], 'limitations': [237], 'existing': [240], 'scholarship': [241], 'where': [242], 'data': [243], 'consequences': [246], 'lacking.': [253], 'contribute': [255], 'understanding': [257], 'by': [263], 'providing': [264], 'surveillance': [265], 'via': [266], 'essential': [270], 'identifying': [272], 'potentially': [273], 'useful': [274], 'policy': [275], 'programs': [276], 'that': [277], 'can': [278], 'offer': [279], 'targeted': [280], 'survivors': [285], 'as': [286], 'we': [287], 'prepare': [288], 'future': [290], 'outbreaks.': [291]}",2020,"['Domestic violence', 'Transgender', 'Criminology', 'Poison control', 'Psychiatry', 'Psychology', 'Medicine', 'Suicide prevention', 'Medical emergency', 'Psychoanalysis']","Background Family violence (including intimate partner violence/domestic violence, child abuse, and elder abuse) is a hidden pandemic happening alongside COVID-19. The rates of family violence are rising fast, and women and children are disproportionately affected and vulnerable during this time. Objective This study aims to provide a large-scale analysis of public discourse on family violence and the COVID-19 pandemic on Twitter. Methods We analyzed over 1 million tweets related to family violence and COVID-19 from April 12 to July 16, 2020. We used the machine learning approach Latent Dirichlet Allocation and identified salient themes, topics, and representative tweets. Results We extracted 9 themes from 1,015,874 tweets on family violence and the COVID-19 pandemic: (1) increased vulnerability: COVID-19 and family violence (eg, rising rates, increases in hotline calls, homicide); (2) types of family violence (eg, child abuse, domestic violence, sexual abuse); (3) forms of family violence (eg, physical aggression, coercive control); (4) risk factors linked to family violence (eg, alcohol abuse, financial constraints, guns, quarantine); (5) victims of family violence (eg, the LGBTQ [lesbian, gay, bisexual, transgender, and queer or questioning] community, women, women of color, children); (6) social services for family violence (eg, hotlines, social workers, confidential services, shelters, funding); (7) law enforcement response (eg, 911 calls, police arrest, protective orders, abuse reports); (8) social movements and awareness (eg, support victims, raise awareness); and (9) domestic violence–related news (eg, Tara Reade, Melissa DeRosa). Conclusions This study overcomes limitations in the existing scholarship where data on the consequences of COVID-19 on family violence are lacking. We contribute to understanding family violence during the pandemic by providing surveillance via tweets. This is essential for identifying potentially useful policy programs that can offer targeted support for victims and survivors as we prepare for future outbreaks."
https://openalex.org/W2896377340,Toward an artificial intelligence physicist for unsupervised learning,"{'©': [0], '2019': [1], 'American': [2], 'Physical': [3], 'Society.': [4], 'We': [5, 130], 'investigate': [6], 'opportunities': [7], 'and': [8, 26, 31, 50, 65, 92, 102, 122, 164, 172, 194], 'challenges': [9], 'for': [10, 210], 'improving': [11], 'unsupervised': [12, 150], 'machine': [13], 'learning': [14, 49, 139], 'using': [15, 36], 'four': [16], 'common': [17], 'strategies': [18], 'with': [19, 204], 'a': [20, 44, 77, 93, 114, 142, 178, 183, 211, 217], 'long': [21], 'history': [22], 'in': [23, 68, 87, 113, 216], 'physics:': [24], 'divide': [25], 'conquer,': [27], ""Occam's"": [28], 'razor,': [29], 'unification,': [30], 'lifelong': [32], 'learning.': [33], 'Instead': [34], 'of': [35, 52, 59, 144, 152, 159, 188, 207], 'one': [37], 'model': [38], 'to': [39, 81, 85, 98], 'learn': [40], 'everything,': [41], 'we': [42, 75], 'propose': [43, 76, 124], 'paradigm': [45], 'centered': [46], 'around': [47], 'the': [48, 60, 66, 134], 'manipulation': [51], 'theories,': [53], 'which': [54, 69, 117], 'parsimoniously': [55], 'predict': [56], 'both': [57], 'aspects': [58], 'future': [61], '(from': [62], 'past': [63], 'observations)': [64], 'domain': [67], 'these': [70], 'predictions': [71], 'are': [72, 111], 'accurate.': [73], 'Specifically,': [74], 'generalized': [78], 'mean': [79], 'loss': [80], 'encourage': [82], 'each': [83], 'theory': [84, 196], 'specialize': [86], 'its': [88], 'comparatively': [89], 'advantageous': [90], 'domain,': [91], 'differentiable': [94], 'description': [95], 'length': [96], 'objective': [97], 'downweight': [99], 'bad': [100], 'data': [101], '""snap""': [103], 'learned': [104, 120], 'theories': [105, 121, 125], 'into': [106], 'simple': [107], 'symbolic': [108], 'formulas.': [109], 'Theories': [110], 'stored': [112], '""theory': [115], 'hub,""': [116], 'continuously': [118], 'unifies': [119], 'can': [123], 'when': [126], 'encountering': [127], 'new': [128], 'environments.': [129, 148], 'test': [131], 'our': [132, 167], 'implementation,': [133], 'toy': [135], '""artificial': [136], 'intelligence': [137], 'physicist""': [138], 'agent,': [140], 'on': [141], 'suite': [143], 'increasingly': [145], 'complex': [146], 'physics': [147], 'From': [149], 'observation': [151], 'trajectories': [153], 'through': [154], 'worlds': [155], 'involving': [156], 'random': [157], 'combinations': [158], 'gravity,': [160], 'electromagnetism,': [161], 'harmonic': [162], 'motion,': [163], 'elastic': [165], 'bounces,': [166], 'agent': [168, 200], 'typically': [169, 191], 'learns': [170], 'faster': [171], 'produces': [173], 'mean-squared': [174], 'prediction': [175], 'errors': [176], 'about': [177], 'billion': [179], 'times': [180], 'smaller': [181], 'than': [182], 'standard': [184], 'feedforward': [185], 'neural': [186], 'net': [187], 'comparable': [189], 'complexity,': [190], 'recovering': [192], 'integer': [193], 'rational': [195], 'parameters': [197], 'exactly.': [198], 'Our': [199], 'successfully': [201], 'identifies': [202], 'domains': [203], 'different': [205], 'laws': [206], 'motion': [208], 'also': [209], 'nonlinear': [212], 'chaotic': [213], 'double': [214], 'pendulum': [215], 'piecewise': [218], 'constant': [219], 'force': [220], 'field.': [221]}",2019,"['occam', 'Artificial intelligence', 'Computer science', 'Double pendulum', 'Unsupervised learning', 'Domain (mathematical analysis)', 'Artificial neural network', 'Divide and conquer algorithms', 'Machine learning', 'Mathematics', 'Nonlinear system', 'Algorithm', 'Physics', 'Inverted pendulum', 'Quantum mechanics', 'Programming language', 'Mathematical analysis']","© 2019 American Physical Society. We investigate opportunities and challenges for improving unsupervised machine learning using four common strategies with a long history in physics: divide and conquer, Occam's razor, unification, and lifelong learning. Instead of using one model to learn everything, we propose a paradigm centered around the learning and manipulation of theories, which parsimoniously predict both aspects of the future (from past observations) and the domain in which these predictions are accurate. Specifically, we propose a generalized mean loss to encourage each theory to specialize in its comparatively advantageous domain, and a differentiable description length objective to downweight bad data and ""snap"" learned theories into simple symbolic formulas. Theories are stored in a ""theory hub,"" which continuously unifies learned theories and can propose theories when encountering new environments. We test our implementation, the toy ""artificial intelligence physicist"" learning agent, on a suite of increasingly complex physics environments. From unsupervised observation of trajectories through worlds involving random combinations of gravity, electromagnetism, harmonic motion, and elastic bounces, our agent typically learns faster and produces mean-squared prediction errors about a billion times smaller than a standard feedforward neural net of comparable complexity, typically recovering integer and rational theory parameters exactly. Our agent successfully identifies domains with different laws of motion also for a nonlinear chaotic double pendulum in a piecewise constant force field."
https://openalex.org/W2788857104,Unsupervised Learning of Geometry From Videos With Edge-Aware Depth-Normal Consistency,"{'Learning': [0], 'to': [1, 34, 49, 131, 144, 156], 'reconstruct': [2], 'depths': [3, 46, 89], 'from': [4], 'a': [5, 73, 77, 112], 'single': [6], 'image': [7, 130], 'by': [8, 71], 'watching': [9], 'unlabeled': [10], 'videos': [11], 'via': [12], 'deep': [13], 'convolutional': [14], 'network': [15], '(DCN)': [16], 'is': [17], 'attracting': [18], 'significant': [19], 'attention': [20], 'in': [21], 'recent': [22], 'years,': [23], 'e.g.': [24], '(Zhou': [25], 'et': [26], 'al.': [27], '2017).': [28], 'In': [29], 'this': [30], 'paper,': [31], 'we': [32, 61, 148], 'propose': [33], 'use': [35], 'surface': [36], 'normal': [37, 94, 161], 'representation': [38], 'for': [39], 'unsupervised': [40], 'depth': [41, 114, 159], 'estimation': [42], 'framework.': [43], 'Our': [44], 'estimated': [45, 88, 106], 'are': [47, 122], 'constrained': [48], 'be': [50], 'compatible': [51], 'with': [52, 124], 'predicted': [53], 'normals,': [54, 107], 'yielding': [55], 'more': [56], 'robust': [57], 'geometry': [58], 'results.': [59], 'Specifically,': [60], 'formulate': [62], 'an': [63], 'edge-aware': [64], 'depth-normal': [65], 'consistency': [66], 'term,': [67], 'and': [68, 76, 92, 139, 153, 160, 170, 174], 'solve': [69], 'it': [70], 'constructing': [72], 'depth-to-normal': [74, 85], 'layer': [75, 79, 86, 110], 'normal-to-depth': [78, 109], 'inside': [80, 128], 'of': [81, 126, 136, 186], 'the': [82, 105, 108, 129, 134, 146, 150, 184], 'DCN.': [83], 'The': [84], 'takes': [87], 'as': [90], 'input,': [91], 'computes': [93], 'directions': [95], 'using': [96], 'cross': [97], 'production': [98], 'based': [99], 'on': [100, 166], 'neighboring': [101], 'pixels.': [102], 'Then': [103], 'given': [104], 'outputs': [111], 'regularized': [113], 'map': [115], 'through': [116], 'local': [117], 'planar': [118], 'smoothness.': [119], 'Both': [120], 'layers': [121], 'computed': [123], 'awareness': [125], 'edges': [127], 'help': [132], 'address': [133], 'issue': [135], 'depth/normal': [137], 'discontinuity': [138], 'preserve': [140], 'sharp': [141], 'edges.': [142], 'Finally,': [143], 'train': [145], 'network,': [147], 'apply': [149], 'photometric': [151], 'error': [152], 'gradient': [154], 'smoothness': [155], 'supervise': [157], 'both': [158, 167], 'predictions.': [162], 'We': [163], 'conducted': [164], 'experiments': [165], 'outdoor': [168], '(KITTI)': [169], 'indoor': [171], '(NYUv2)': [172], 'datasets,': [173], 'showed': [175], 'that': [176], 'our': [177, 187], 'algorithm': [178], 'vastly': [179], 'outperforms': [180], 'state-of-the-art,': [181], 'which': [182], 'demonstrates': [183], 'benefits': [185], 'approach.': [188]}",2018,"['Normal', 'Consistency (knowledge bases)', 'Smoothness', 'Artificial intelligence', 'Computer science', 'Discontinuity (linguistics)', 'Enhanced Data Rates for GSM Evolution', 'Image (mathematics)', 'Depth map', 'Pixel', 'Representation (politics)', 'Layer (electronics)', 'Planar', 'Computer vision', 'Geometry', 'Algorithm', 'Mathematics', 'Surface (topology)', 'Mathematical analysis', 'Computer graphics (images)', 'Political science', 'Law', 'Organic chemistry', 'Chemistry', 'Politics']","Learning to reconstruct depths from a single image by watching unlabeled videos via deep convolutional network (DCN) is attracting significant attention in recent years, e.g. (Zhou et al. 2017). In this paper, we propose to use surface normal representation for unsupervised depth estimation framework. Our estimated depths are constrained to be compatible with predicted normals, yielding more robust geometry results. Specifically, we formulate an edge-aware depth-normal consistency term, and solve it by constructing a depth-to-normal layer and a normal-to-depth layer inside of the DCN. The depth-to-normal layer takes estimated depths as input, and computes normal directions using cross production based on neighboring pixels. Then given the estimated normals, the normal-to-depth layer outputs a regularized depth map through local planar smoothness. Both layers are computed with awareness of edges inside the image to help address the issue of depth/normal discontinuity and preserve sharp edges. Finally, to train the network, we apply the photometric error and gradient smoothness to supervise both depth and normal predictions. We conducted experiments on both outdoor (KITTI) and indoor (NYUv2) datasets, and showed that our algorithm vastly outperforms state-of-the-art, which demonstrates the benefits of our approach."
https://openalex.org/W2188492526,Unsupervised Learning Of Sparse Features For Scalable Audio Classification.,"{'[TODO]': [0], 'Add': [1], 'abstract': [2], 'here.': [3]}",2011,"['Computer science', 'Spectrogram', 'Artificial intelligence', 'Classifier (UML)', 'Pattern recognition (psychology)', 'Neural coding', 'Feature extraction', 'Scalability', 'Support vector machine', 'Autoencoder', 'Encoder', 'Feature vector', 'Machine learning', 'Deep learning', 'Database', 'Operating system']",[TODO] Add abstract here.
https://openalex.org/W2117041980,Unsupervised learning of acoustic sub-word units,"{'Accurate': [0], 'unsupervised': [1, 18, 49], 'learning': [2, 19, 50, 109], 'of': [3, 5, 20, 25, 51, 67], 'phonemes': [4], 'a': [6, 26, 55, 82, 92], 'language': [7], 'directly': [8], 'from': [9, 110], 'speech': [10], 'is': [11, 73, 85, 105], 'demonstrated': [12, 106], 'via': [13], 'an': [14, 88], 'algorithm': [15], 'for': [16, 48, 107], 'joint': [17], 'the': [21, 40, 68, 77], 'topology': [22], 'and': [23, 32, 94], 'parameters': [24], 'hidden': [27], 'Markov': [28], 'model': [29], '(HMM);': [30], 'states': [31], 'short': [33], 'state-sequences': [34], 'through': [35], 'this': [36], 'HMM': [37], 'correspond': [38], 'to': [39, 62, 81, 91, 96], 'learnt': [41], 'sub-word': [42], 'units.': [43], 'The': [44], 'algorithm,': [45], 'originally': [46], 'proposed': [47], 'allophonic': [52], 'variations': [53], 'within': [54], 'given': [56], 'phoneme': [57, 102], 'set,': [58], 'has': [59], 'been': [60], 'adapted': [61], 'learn': [63], 'without': [64], 'any': [65], 'knowledge': [66], 'phonemes.': [69], 'An': [70], 'evaluation': [71], 'methodology': [72], 'also': [74], 'proposed,': [75], 'whereby': [76], 'state-sequence': [78], 'that': [79], 'aligns': [80], 'test': [83], 'utterance': [84], 'transduced': [86], 'in': [87], 'automatic': [89], 'manner': [90], 'phoneme-sequence': [93], 'compared': [95], 'its': [97], 'manual': [98], 'transcription.': [99], 'Over': [100], '85%': [101], 'recognition': [103], 'accuracy': [104], 'speaker-dependent': [108], 'fluent,': [111], 'large-vocabulary': [112], 'speech.': [113]}",2008,"['Hidden Markov model', 'Computer science', 'Unsupervised learning', 'Speech recognition', 'Utterance', 'Artificial intelligence', 'Word (group theory)', 'Vocabulary', 'Natural language processing', 'Sequence (biology)', 'Set (abstract data type)', 'Sequence labeling', 'Pattern recognition (psychology)', 'Mathematics', 'Linguistics', 'Biology', 'Geometry', 'Task (project management)', 'Programming language', 'Economics', 'Management', 'Genetics', 'Philosophy']","Accurate unsupervised learning of phonemes of a language directly from speech is demonstrated via an algorithm for joint unsupervised learning of the topology and parameters of a hidden Markov model (HMM); states and short state-sequences through this HMM correspond to the learnt sub-word units. The algorithm, originally proposed for unsupervised learning of allophonic variations within a given phoneme set, has been adapted to learn without any knowledge of the phonemes. An evaluation methodology is also proposed, whereby the state-sequence that aligns to a test utterance is transduced in an automatic manner to a phoneme-sequence and compared to its manual transcription. Over 85% phoneme recognition accuracy is demonstrated for speaker-dependent learning from fluent, large-vocabulary speech."
https://openalex.org/W2987283559,Momentum Contrast for Unsupervised Visual Representation Learning,"{'We': [0], 'present': [1], 'Momentum': [2], 'Contrast': [3], '(MoCo)': [4], 'for': [5], 'unsupervised': [6, 43, 99], 'visual': [7], 'representation': [8, 102], 'learning.': [9, 44], 'From': [10], 'a': [11, 21, 25, 28, 34], 'perspective': [12], 'on': [13, 54, 80], 'contrastive': [14, 42], 'learning': [15, 103], 'as': [16], 'dictionary': [17, 23, 38], 'look-up,': [18], 'we': [19], 'build': [20], 'dynamic': [22], 'with': [24], 'queue': [26], 'and': [27, 36, 84, 100], 'moving-averaged': [29], 'encoder.': [30], 'This': [31, 93], 'enables': [32], 'building': [33], 'large': [35, 91], 'consistent': [37], 'on-the-fly': [39], 'that': [40, 95], 'facilitates': [41], 'MoCo': [45, 63, 69], 'provides': [46], 'competitive': [47], 'results': [48], 'under': [49], 'the': [50, 59, 96], 'common': [51], 'linear': [52], 'protocol': [53], 'ImageNet': [55], 'classification.': [56], 'More': [57], 'importantly,': [58], 'representations': [60], 'learned': [61], 'by': [62, 90], 'transfer': [64], 'well': [65], 'to': [66], 'downstream': [67], 'tasks.': [68, 111], 'can': [70], 'outperform': [71], 'its': [72], 'supervised': [73, 101], 'pre-training': [74], 'counterpart': [75], 'in': [76, 108], '7': [77], 'detection/segmentation': [78], 'tasks': [79], 'PASCAL': [81], 'VOC,': [82], 'COCO,': [83], 'other': [85], 'datasets,': [86], 'sometimes': [87], 'surpassing': [88], 'it': [89], 'margins.': [92], 'suggests': [94], 'gap': [97], 'between': [98], 'has': [104], 'been': [105], 'largely': [106], 'closed': [107], 'many': [109], 'vision': [110]}",2019,"['Pascal (unit)', 'Contrast (vision)', 'Artificial intelligence', 'Computer science', 'Unsupervised learning', 'Segmentation', 'Machine learning', 'Representation (politics)', 'Feature learning', 'Perspective (graphical)', 'Pattern recognition (psychology)', 'Natural language processing', 'Programming language', 'Political science', 'Politics', 'Law']","We present Momentum Contrast (MoCo) for unsupervised visual representation learning. From a perspective on contrastive learning as dictionary look-up, we build a dynamic dictionary with a queue and a moving-averaged encoder. This enables building a large and consistent dictionary on-the-fly that facilitates contrastive unsupervised learning. MoCo provides competitive results under the common linear protocol on ImageNet classification. More importantly, the representations learned by MoCo transfer well to downstream tasks. MoCo can outperform its supervised pre-training counterpart in 7 detection/segmentation tasks on PASCAL VOC, COCO, and other datasets, sometimes surpassing it by large margins. This suggests that the gap between unsupervised and supervised representation learning has been largely closed in many vision tasks."
https://openalex.org/W2469266052,Unsupervised Learning of 3D Structure from Images,"{'A': [0], 'key': [1], 'goal': [2], 'of': [3, 16, 28, 89, 95], 'computer': [4], 'vision': [5], 'is': [6], 'to': [7, 91], 'recover': [8, 32], 'the': [9, 17, 58, 62, 84, 87, 96], 'underlying': [10], '3D': [11, 29, 36, 93], 'structure': [12], 'from': [13, 35, 78], '2D': [14, 38, 79], 'observations': [15], 'world.': [18], 'In': [19], 'this': [20], 'paper': [21], 'we': [22], 'learn': [23], 'strong': [24], 'deep': [25], 'generative': [26], 'models': [27, 69], 'structures,': [30], 'and': [31, 37, 47, 56, 70], 'these': [33, 68], 'structures': [34], 'images': [39], 'via': [40], 'probabilistic': [41], 'inference.': [42], 'We': [43, 64], 'demonstrate': [44], 'high-quality': [45], 'samples': [46], 'report': [48], 'log-likelihoods': [49], 'on': [50], 'several': [51], 'datasets,': [52], 'including': [53], 'ShapeNet': [54], '[2],': [55], 'establish': [57], 'first': [59, 85], 'benchmarks': [60], 'in': [61, 98], 'literature.': [63], 'also': [65], 'show': [66], 'how': [67], 'their': [71], 'inference': [72], 'networks': [73], 'can': [74], 'be': [75], 'trained': [76], 'end-to-end': [77], 'images.': [80], 'This': [81], 'demonstrates': [82], 'for': [83], 'time': [86], 'feasibility': [88], 'learning': [90], 'infer': [92], 'representations': [94], 'world': [97], 'a': [99], 'purely': [100], 'unsupervised': [101], 'manner.': [102]}",2016,"['Inference', 'Computer science', 'Artificial intelligence', 'Generative grammar', 'Probabilistic logic', 'Unsupervised learning', 'Key (lock)', 'Generative model', 'Deep learning', 'Machine learning', 'Pattern recognition (psychology)', '3d model', 'Computer security']","A key goal of computer vision is to recover the underlying 3D structure from 2D observations of the world. In this paper we learn strong deep generative models of 3D structures, and recover these structures from 3D and 2D images via probabilistic inference. We demonstrate high-quality samples and report log-likelihoods on several datasets, including ShapeNet [2], and establish the first benchmarks in the literature. We also show how these models and their inference networks can be trained end-to-end from 2D images. This demonstrates for the first time the feasibility of learning to infer 3D representations of the world in a purely unsupervised manner."
https://openalex.org/W2267038056,Convolutional Clustering for Unsupervised Learning,"{'The': [0], 'task': [1], 'of': [2, 16, 29, 59, 68, 74, 100, 116, 139, 147], 'labeling': [3], 'data': [4, 31], 'for': [5], 'training': [6], 'deep': [7, 51, 102], 'neural': [8, 104], 'networks': [9], 'is': [10], 'daunting': [11], 'and': [12, 77, 143], 'tedious,': [13], 'requiring': [14], 'millions': [15], 'labels': [17], 'to': [18, 48, 109], 'achieve': [19], 'the': [20, 60, 66, 72, 95, 98, 123], 'current': [21], 'state-of-the-art': [22], 'results.': [23], 'Such': [24], 'reliance': [25], 'on': [26, 55, 112, 141, 149], 'large': [27], 'amounts': [28], 'labeled': [30, 117], 'can': [32], 'be': [33, 110], 'relaxed': [34], 'by': [35], 'exploiting': [36], 'hierarchical': [37], 'features': [38], 'via': [39], 'unsupervised': [40], 'learning': [41, 94], 'techniques.': [42], 'In': [43], 'this': [44], 'work,': [45], 'we': [46, 134], 'propose': [47], 'train': [49], 'a': [50, 101, 113, 136, 144], 'convolutional': [52, 87, 103], 'network': [53, 105], 'based': [54], 'an': [56], 'enhanced': [57], 'version': [58], 'k-means': [61, 88], 'clustering': [62], 'algorithm,': [63], 'which': [64], 'reduces': [65], 'number': [67], 'correlated': [69], 'parameters': [70], 'in': [71], 'form': [73], 'similar': [75], 'filters,': [76], 'thus': [78], 'increases': [79], 'test': [80, 137, 145], 'categorization': [81], 'accuracy.': [82], 'We': [83, 90], 'call': [84], 'our': [85], 'algorithm': [86, 125], 'clustering.': [89], 'further': [91], 'show': [92, 121], 'that': [93, 122, 129], 'connection': [96], 'between': [97], 'layers': [99], 'improves': [106], 'its': [107], 'ability': [108], 'trained': [111], 'smaller': [114], 'amount': [115], 'data.': [118], 'Our': [119], 'experiments': [120], 'proposed': [124], 'outperforms': [126], 'other': [127], 'techniques': [128], 'learn': [130], 'filters': [131], 'unsupervised.': [132], 'Specifically,': [133], 'obtained': [135], 'accuracy': [138], '74.1%': [140], 'STL-10': [142], 'error': [146], '0.5%': [148], 'MNIST.': [150]}",2015,"['MNIST database', 'Computer science', 'Artificial intelligence', 'Convolutional neural network', 'Cluster analysis', 'Categorization', 'Unsupervised learning', 'Pattern recognition (psychology)', 'Deep learning', 'Task (project management)', 'Machine learning', 'Test data', 'Programming language', 'Management', 'Economics']","The task of labeling data for training deep neural networks is daunting and tedious, requiring millions of labels to achieve the current state-of-the-art results. Such reliance on large amounts of labeled data can be relaxed by exploiting hierarchical features via unsupervised learning techniques. In this work, we propose to train a deep convolutional network based on an enhanced version of the k-means clustering algorithm, which reduces the number of correlated parameters in the form of similar filters, and thus increases test categorization accuracy. We call our algorithm convolutional k-means clustering. We further show that learning the connection between the layers of a deep convolutional neural network improves its ability to be trained on a smaller amount of labeled data. Our experiments show that the proposed algorithm outperforms other techniques that learn filters unsupervised. Specifically, we obtained a test accuracy of 74.1% on STL-10 and a test error of 0.5% on MNIST."
https://openalex.org/W2739958663,Supervised and Unsupervised Learning Technology in the Study of Rodent Behavior,"{'Quantifying': [0], 'behavior': [1, 15, 89, 95, 111, 133, 173], 'is': [2, 174], 'a': [3, 92, 107, 121], 'challenge': [4], 'for': [5], 'scientists': [6, 36, 60], 'studying': [7], 'neuroscience,': [8], 'ethology,': [9], 'psychology,': [10], 'pathology,': [11], 'etc.': [12], 'Until': [13], 'now,': [14], 'was': [16], 'mostly': [17], 'considered': [18, 139], 'as': [19], 'qualitative': [20], 'descriptions': [21], 'of': [22, 28, 30, 41, 84, 88, 94, 105, 110, 123, 132, 143, 177, 181], 'postures': [23, 40], 'or': [24], 'labor': [25], 'intensive': [26], 'counting': [27], 'bouts': [29], 'individual': [31], 'movements.': [32], 'Many': [33], 'prominent': [34], 'behavioral': [35, 64], 'conducted': [37], 'studies': [38], 'describing': [39], 'mice': [42, 135], 'and': [43, 52, 68, 90, 136, 141, 145, 187], 'rats,': [44], 'depicting': [45], 'step': [46, 48], 'by': [47], 'eating,': [49], 'grooming,': [50], 'courting,': [51], 'other': [53], 'behaviors.': [54], 'Automated': [55], 'video': [56, 130, 159], 'assessment': [57, 131], 'technologies': [58, 124], 'permit': [59], 'to': [61, 112, 115, 170], 'quantify': [62], 'daily': [63], 'patterns/routines,': [65], 'social': [66], 'interactions,': [67], 'postural': [69], 'changes': [70], 'in': [71, 128, 134], 'an': [72], 'unbiased': [73], 'manner.': [74], 'Here,': [75], 'we': [76, 163], 'extensively': [77], 'reviewed': [78], 'published': [79], 'research': [80], 'on': [81, 97, 189], 'the': [82, 85, 98, 103, 150, 166, 175, 179], 'topic': [83], 'structural': [86], 'blocks': [87], 'proposed': [91, 164], 'structure': [93, 109], 'based': [96], 'latest': [99, 151], 'publications.': [100], 'We': [101, 119, 138, 148], 'discuss': [102], 'importance': [104], 'defining': [106], 'clear': [108], 'allow': [113], 'professionals': [114], 'write': [116], 'viable': [117], 'algorithms.': [118], 'presented': [120, 149], 'discussion': [122], 'that': [125, 154, 165], 'are': [126], 'used': [127], 'automated': [129, 158, 167], 'rats.': [137], 'advantages': [140], 'limitations': [142], 'supervised': [144], 'unsupervised': [146], 'learning.': [147], 'scientific': [152], 'discoveries': [153], 'were': [155], 'made': [156], 'using': [157], 'assessment.': [160], 'In': [161], 'conclusion,': [162], 'quantitative': [168], 'approach': [169], 'evaluating': [171], 'animal': [172], 'future': [176], 'understanding': [178], 'effect': [180], 'brain': [182], 'signaling,': [183], 'pathologies,': [184], 'genetic': [185], 'content,': [186], 'environment': [188], 'behavior.': [190]}",2017,"['Ethology', 'Animal behavior', 'Psychology', 'Behavioral neuroscience', 'Artificial intelligence', 'Behavioural sciences', 'Computer science', 'Cognitive psychology', 'Data science', 'Cognitive science', 'Neuroscience', 'Ecology', 'Biology', 'Psychotherapist', 'Zoology']","Quantifying behavior is a challenge for scientists studying neuroscience, ethology, psychology, pathology, etc. Until now, behavior was mostly considered as qualitative descriptions of postures or labor intensive counting of bouts of individual movements. Many prominent behavioral scientists conducted studies describing postures of mice and rats, depicting step by step eating, grooming, courting, and other behaviors. Automated video assessment technologies permit scientists to quantify daily behavioral patterns/routines, social interactions, and postural changes in an unbiased manner. Here, we extensively reviewed published research on the topic of the structural blocks of behavior and proposed a structure of behavior based on the latest publications. We discuss the importance of defining a clear structure of behavior to allow professionals to write viable algorithms. We presented a discussion of technologies that are used in automated video assessment of behavior in mice and rats. We considered advantages and limitations of supervised and unsupervised learning. We presented the latest scientific discoveries that were made using automated video assessment. In conclusion, we proposed that the automated quantitative approach to evaluating animal behavior is the future of understanding the effect of brain signaling, pathologies, genetic content, and environment on behavior."
https://openalex.org/W3093010610,Deep Variational Bayes Filters: Unsupervised Learning of State Space\n Models from Raw Data,"{'We': [0], 'introduce': [1], 'Deep': [2], 'Variational': [3, 25], 'Bayes': [4], 'Filters': [5], '(DVBF),': [6], 'a': [7], 'new': [8], 'method': [9], 'for\\nunsupervised': [10], 'learning': [11], 'and': [12, 63], 'identification': [13], 'of': [14, 68], 'latent': [15], 'Markovian': [16], 'state': [17], 'space\\nmodels.': [18], 'Leveraging': [19], 'recent': [20], 'advances': [21], 'in': [22], 'Stochastic': [23], 'Gradient': [24], 'Bayes,\\nDVBF': [26], 'can': [27, 36], 'overcome': [28], 'intractable': [29], 'inference': [30], 'distributions': [31], 'via': [32], 'variational\\ninference.': [33], 'Thus,': [34], 'it': [35], 'handle': [37], 'highly': [38], 'nonlinear': [39], 'input': [40], 'data': [41], 'with': [42], 'temporal': [43], 'and\\nspatial': [44], 'dependencies': [45], 'such': [46], 'as': [47], 'image': [48], 'sequences': [49], 'without': [50], 'domain': [51], 'knowledge.': [52], 'Our\\nexperiments': [53], 'show': [54], 'that': [55], 'enabling': [56], 'backpropagation': [57], 'through': [58], 'transitions': [59], 'enforces\\nstate': [60], 'space': [61], 'assumptions': [62], 'significantly': [64], 'improves': [65], 'information': [66], 'content': [67], 'the\\nlatent': [69], 'embedding.': [70], 'This': [71], 'also': [72], 'enables': [73], 'realistic': [74], 'long-term': [75], 'prediction.\\n': [76]}",2016,"['Inference', ""Bayes' theorem"", 'Computer science', 'Artificial intelligence', 'Embedding', 'Bayesian inference', 'Backpropagation', 'Machine learning', 'Algorithm', 'Pattern recognition (psychology)', 'Artificial neural network', 'Bayesian probability']","We introduce Deep Variational Bayes Filters (DVBF), a new method for\nunsupervised learning and identification of latent Markovian state space\nmodels. Leveraging recent advances in Stochastic Gradient Variational Bayes,\nDVBF can overcome intractable inference distributions via variational\ninference. Thus, it can handle highly nonlinear input data with temporal and\nspatial dependencies such as image sequences without domain knowledge. Our\nexperiments show that enabling backpropagation through transitions enforces\nstate space assumptions and significantly improves information content of the\nlatent embedding. This also enables realistic long-term prediction.\n"
https://openalex.org/W2794387644,"GeoNet: Unsupervised Learning of Dense Depth, Optical Flow and Camera Pose","{'We': [0], 'propose': [1, 68], 'GeoNet,': [2], 'a': [3], 'jointly': [4, 30], 'unsupervised': [5, 112], 'learning': [6], 'framework': [7, 34], 'for': [8], 'monocular': [9], 'depth,': [10], 'optical': [11], 'flow': [12], 'and': [13, 50, 61, 79, 85, 114], 'ego-motion': [14], 'estimation': [15], 'from': [16], 'videos.': [17], 'The': [18], 'three': [19, 106], 'components': [20], 'are': [21, 42], 'coupled': [22], 'by': [23, 32], 'the': [24, 45, 91, 105], 'nature': [25], 'of': [26, 47, 104], '3D': [27], 'scene': [28, 63], 'geometry,': [29], 'learned': [31], 'our': [33, 97], 'in': [35, 102], 'an': [36, 54, 69], 'end-to-end': [37], 'manner.': [38], 'Specifically,': [39], 'geometric': [40, 71], 'relationships': [41], 'extracted': [43], 'over': [44], 'predictions': [46], 'individual': [48], 'modules': [49], 'then': [51], 'combined': [52], 'as': [53], 'image': [55], 'reconstruction': [56], 'loss,': [57], 'reasoning': [58], 'about': [59], 'static': [60], 'dynamic': [62], 'parts': [64], 'separately.': [65], 'Furthermore,': [66], 'we': [67], 'adaptive': [70], 'consistency': [72], 'loss': [73], 'to': [74], 'increase': [75], 'robustness': [76], 'towards': [77], 'outliers': [78], 'non-Lambertian': [80], 'regions,': [81], 'which': [82], 'resolves': [83], 'occlusions': [84], 'texture': [86], 'ambiguities': [87], 'effectively.': [88], 'Experimentation': [89], 'on': [90], 'KITTI': [92], 'driving': [93], 'dataset': [94], 'reveals': [95], 'that': [96], 'scheme': [98], 'achieves': [99], 'state-of-the-art': [100], 'results': [101], 'all': [103], 'tasks,': [107], 'performing': [108], 'better': [109], 'than': [110], 'previously': [111], 'methods': [113], 'comparably': [115], 'with': [116], 'supervised': [117], 'ones.': [118]}",2018,"['Artificial intelligence', 'Robustness (evolution)', 'Computer science', 'Outlier', 'Optical flow', 'Computer vision', 'Unsupervised learning', 'Monocular', 'Consistency (knowledge bases)', 'View synthesis', 'Pattern recognition (psychology)', 'Image (mathematics)', 'Gene', 'Chemistry', 'Biochemistry', 'Rendering (computer graphics)']","We propose GeoNet, a jointly unsupervised learning framework for monocular depth, optical flow and ego-motion estimation from videos. The three components are coupled by the nature of 3D scene geometry, jointly learned by our framework in an end-to-end manner. Specifically, geometric relationships are extracted over the predictions of individual modules and then combined as an image reconstruction loss, reasoning about static and dynamic scene parts separately. Furthermore, we propose an adaptive geometric consistency loss to increase robustness towards outliers and non-Lambertian regions, which resolves occlusions and texture ambiguities effectively. Experimentation on the KITTI driving dataset reveals that our scheme achieves state-of-the-art results in all of the three tasks, performing better than previously unsupervised methods and comparably with supervised ones."
https://openalex.org/W2528605693,Firms' knowledge profiles: Mapping patent data with unsupervised learning,"{'Patent': [0], 'data': [1, 31], 'has': [2], 'been': [3], 'an': [4, 107], 'obvious': [5], 'choice': [6], 'for': [7, 207, 213], 'analysis': [8, 22, 32, 63], 'leading': [9, 66], 'to': [10, 53, 105, 116, 144, 179], 'strategic': [11, 214], 'technology': [12, 147, 186], 'intelligence,': [13], 'yet,': [14], 'the': [15, 26, 39, 65, 95, 113, 133, 136, 155, 164, 173, 196], 'recent': [16], 'proliferation': [17], 'of': [18, 28, 43, 59, 64, 110, 135, 139, 157, 172, 176, 198], 'machine': [19, 44, 200], 'learning': [20, 45, 61, 97, 201], 'text': [21], 'methods': [23, 33], 'is': [24], 'changing': [25], 'status': [27, 175], 'traditional': [29], 'patent': [30, 50, 180], 'and': [34, 41, 52, 71, 90, 103, 115, 159, 188], 'approaches.': [35, 202], 'This': [36], 'article': [37], 'discusses': [38], 'benefits': [40], 'constraints': [42], 'approaches': [46, 178, 190], 'in': [47, 125, 163, 195, 211, 216], 'industry': [48, 140], 'level': [49], 'analysis,': [51], 'this': [54], 'end': [55], 'offers': [56], 'a': [57, 170], 'demonstration': [58], 'unsupervised': [60, 96], 'based': [62, 73], 'telecommunication': [67, 165], 'firms': [68], 'between': [69], '2001': [70], '2014': [72], 'on': [74, 154, 192], 'about': [75], '160,000': [76], 'USPTO': [77], 'full-text': [78, 84], 'patents.': [79], 'Data': [80], 'were': [81, 99], 'classified': [82], 'using': [83], 'descriptions': [85], 'with': [86], 'Latent': [87], 'Dirichlet': [88], 'Allocation,': [89], 'latent': [91], 'patterns': [92], 'emerging': [93, 158], 'through': [94], 'process': [98], 'modelled': [100], 'by': [101], 'company': [102], 'year': [104], 'create': [106], 'overall': [108], 'view': [109], 'patenting': [111], 'within': [112], 'industry,': [114], 'forecast': [117], 'future': [118], 'trends.': [119], 'Our': [120, 167], 'results': [121, 150, 168], 'demonstrate': [122], 'company-specific': [123], 'differences': [124], 'their': [126], 'knowledge': [127, 137, 161], 'profiles,': [128], 'as': [129, 131, 183], 'well': [130], 'show': [132], 'evolution': [134], 'profiles': [138], 'leaders': [141], 'from': [142], 'hardware': [143], 'software': [145], 'focussed': [146], 'strategies.': [148], 'The': [149], 'cast': [151], 'also': [152], 'light': [153], 'dynamics': [156], 'declining': [160], 'areas': [162], 'industry.': [166], 'prompt': [169], 'consideration': [171], 'current': [174], 'established': [177], 'landscaping,': [181], 'such': [182], 'key-word': [184], 'or': [185], 'classifications': [187], 'other': [189], 'relying': [191], 'semantic': [193], 'labelling,': [194], 'context': [197], 'novel': [199], 'Finally,': [203], 'we': [204], 'discuss': [205], 'implications': [206], 'policy': [208], 'makers,': [209], 'and,': [210], 'particular,': [212], 'management': [215], 'firms.': [217]}",2016,"['Latent Dirichlet allocation', 'Computer science', 'Context (archaeology)', 'Topic model', 'Data science', 'Unsupervised learning', 'Patent analysis', 'Process (computing)', 'Artificial intelligence', 'Knowledge management', 'Hierarchical Dirichlet process', 'Machine learning', 'Strategic management', 'Interpretability', 'Business', 'Marketing', 'Biology', 'Paleontology', 'Operating system']","Patent data has been an obvious choice for analysis leading to strategic technology intelligence, yet, the recent proliferation of machine learning text analysis methods is changing the status of traditional patent data analysis methods and approaches. This article discusses the benefits and constraints of machine learning approaches in industry level patent analysis, and to this end offers a demonstration of unsupervised learning based analysis of the leading telecommunication firms between 2001 and 2014 based on about 160,000 USPTO full-text patents. Data were classified using full-text descriptions with Latent Dirichlet Allocation, and latent patterns emerging through the unsupervised learning process were modelled by company and year to create an overall view of patenting within the industry, and to forecast future trends. Our results demonstrate company-specific differences in their knowledge profiles, as well as show the evolution of the knowledge profiles of industry leaders from hardware to software focussed technology strategies. The results cast also light on the dynamics of emerging and declining knowledge areas in the telecommunication industry. Our results prompt a consideration of the current status of established approaches to patent landscaping, such as key-word or technology classifications and other approaches relying on semantic labelling, in the context of novel machine learning approaches. Finally, we discuss implications for policy makers, and, in particular, for strategic management in firms."
https://openalex.org/W1920845339,Map of science with topic modeling: Comparison of unsupervised learning and human‐assigned subject classification,"{'The': [0], 'delineation': [1], 'of': [2, 9, 16, 30, 44, 70, 84, 116, 131, 157, 169, 178], 'coordinates': [3], 'is': [4, 141], 'fundamental': [5], 'for': [6, 65, 92], 'the': [7, 40, 107, 167, 175], 'cartography': [8], 'science,': [10], 'and': [11, 13, 38, 42, 58, 87, 127, 163], 'accurate': [12], 'credible': [14], 'classification': [15, 68, 98, 103], 'scientific': [17, 71, 85, 161], 'knowledge': [18, 80], 'presents': [19], 'a': [20, 28, 129, 152], 'persistent': [21], 'challenge': [22], 'in': [23, 100, 155], 'this': [24, 45], 'regard.': [25], 'We': [26, 53], 'present': [27], 'map': [29], 'F': [31], 'innish': [32], 'science': [33], 'based': [34], 'on': [35, 174], 'unsupervised‐learning': [36], 'classification,': [37], 'discuss': [39], 'advantages': [41], 'disadvantages': [43], 'approach': [46, 154, 171], 'vis‐à‐vis': [47], 'those': [48], 'generated': [49], 'by': [50], 'human': [51, 66], 'reasoning.': [52], 'conclude': [54], 'that': [55, 139, 166], 'from': [56, 106], 'theoretical': [57], 'practical': [59, 176], 'perspectives': [60], 'there': [61], 'exist': [62], 'several': [63], 'challenges': [64], 'reasoning‐based': [67], 'frameworks': [69], 'knowledge,': [72, 86, 162], 'as': [73], 'they': [74], 'typically': [75], 'try': [76], 'to': [77, 122, 146, 159], 'fit': [78], 'new‐to‐the‐world': [79], 'into': [81], 'historical': [82], 'models': [83, 104], 'cannot': [88], 'easily': [89], 'be': [90], 'deployed': [91], 'new': [93], 'large‐scale': [94, 124], 'data': [95, 125], 'sets.': [96], 'Automated': [97], 'schemes,': [99], 'contrast,': [101], 'generate': [102], 'only': [105], 'available': [108], 'text': [109], 'corpus,': [110], 'thereby': [111], 'identifying': [112], 'credibly': [113], 'novel': [114], 'bodies': [115], 'knowledge.': [117], 'They': [118], 'also': [119, 137], 'lend': [120], 'themselves': [121], 'versatile': [123], 'analysis,': [126], 'enable': [128], 'range': [130], 'Big': [132], 'Data': [133], 'possibilities.': [134], 'However,': [135], 'we': [136, 164], 'argue': [138], 'it': [140], 'neither': [142], 'possible': [143], 'nor': [144], 'fruitful': [145], 'declare': [147], 'one': [148], 'or': [149], 'another': [150], 'method': [151], 'superior': [153], 'terms': [156], 'realism': [158], 'classify': [160], 'believe': [165], 'merits': [168], 'each': [170], 'are': [172], 'dependent': [173], 'objectives': [177], 'analysis.': [179]}",2015,"['Computer science', 'Subject (documents)', 'Data science', 'Artificial intelligence', 'Scale (ratio)', 'Range (aeronautics)', 'Big data', 'Sociology of scientific knowledge', 'Machine learning', 'Data mining', 'Epistemology', 'Library science', 'Philosophy', 'Physics', 'Composite material', 'Materials science', 'Quantum mechanics']","The delineation of coordinates is fundamental for the cartography of science, and accurate and credible classification of scientific knowledge presents a persistent challenge in this regard. We present a map of F innish science based on unsupervised‐learning classification, and discuss the advantages and disadvantages of this approach vis‐à‐vis those generated by human reasoning. We conclude that from theoretical and practical perspectives there exist several challenges for human reasoning‐based classification frameworks of scientific knowledge, as they typically try to fit new‐to‐the‐world knowledge into historical models of scientific knowledge, and cannot easily be deployed for new large‐scale data sets. Automated classification schemes, in contrast, generate classification models only from the available text corpus, thereby identifying credibly novel bodies of knowledge. They also lend themselves to versatile large‐scale data analysis, and enable a range of Big Data possibilities. However, we also argue that it is neither possible nor fruitful to declare one or another method a superior approach in terms of realism to classify scientific knowledge, and we believe that the merits of each approach are dependent on the practical objectives of analysis."
https://openalex.org/W2890967717,Unsupervised Learning of Object Landmarks through Conditional Image Generation,"{'We': [0, 25, 136, 161], 'propose': [1], 'a': [2, 19, 44, 57, 67, 83, 129, 170], 'method': [3, 166], 'for': [4, 8], 'learning': [5], 'landmark': [6, 159], 'detectors': [7], 'visual': [9], 'objects': [10], '(such': [11], 'as': [12, 28, 41, 54], 'the': [13, 16, 29, 36, 39, 49, 52, 62, 87, 125], 'eyes': [14], 'and': [15, 79, 92, 116, 118, 180], 'nose': [17], 'in': [18, 43, 56, 86], 'face)': [20], 'without': [21, 152, 183], 'any': [22, 184], 'manual': [23, 153], 'supervision.': [24], 'cast': [26], 'this': [27], 'problem': [30], 'of': [31, 38, 51, 173], 'generating': [32], 'images': [33], 'that': [34, 90, 127, 138, 164], 'combine': [35], 'appearance': [37, 78, 115], 'object': [40, 53, 72, 143], 'seen': [42, 55], 'first': [45], 'example': [46, 59], 'image': [47, 99, 147], 'with': [48], 'geometry': [50, 117], 'second': [58], 'image,': [60], 'where': [61], 'two': [63], 'examples': [64], 'differ': [65], 'by': [66], 'viewpoint': [68], 'change': [69], 'and/or': [70], 'an': [71], 'deformation.': [73], 'In': [74], 'order': [75], 'to': [76, 97, 124, 169], 'factorize': [77], 'geometry,': [80], 'we': [81], 'introduce': [82], 'tight': [84], 'bottleneck': [85], 'geometry-extraction': [88], 'process': [89], 'selects': [91], 'distils': [93], 'geometry-related': [94], 'features.': [95], 'Compared': [96], 'standard': [98], 'generation': [100, 109], 'problems,': [101], 'which': [102], 'often': [103], 'use': [104], 'generative': [105], 'adversarial': [106], 'networks,': [107], 'our': [108, 139, 165], 'task': [110], 'is': [111, 120, 134, 167], 'conditioned': [112], 'on': [113], 'both': [114], 'thus': [119], 'significantly': [121], 'less': [122], 'ambiguous,': [123], 'point': [126], 'adopting': [128], 'simple': [130], 'perceptual': [131], 'loss': [132], 'formulation': [133], 'sufficient.': [135], 'demonstrate': [137], 'approach': [140], 'can': [141], 'learn': [142], 'landmarks': [144], 'from': [145], 'synthetic': [146], 'deformations': [148], 'or': [149], 'videos,': [150], 'all': [151], 'supervision,': [154], 'while': [155], 'outperforming': [156], 'state-of-the-art': [157], 'unsupervised': [158], 'detectors.': [160], 'further': [162], 'show': [163], 'applicable': [168], 'large': [171], 'variety': [172], 'datasets': [174], '-': [175, 182], 'faces,': [176], 'people,': [177], '3D': [178], 'objects,': [179], 'digits': [181], 'modifications.': [185]}",2018,"['Artificial intelligence', 'Computer science', 'Landmark', 'Computer vision', 'Object (grammar)', 'Face (sociological concept)', 'Object detection', 'Generative model', 'Point cloud', 'Image (mathematics)', 'Pattern recognition (psychology)', 'Generative grammar', 'Social science', 'Sociology']","We propose a method for learning landmark detectors for visual objects (such as the eyes and the nose in a face) without any manual supervision. We cast this as the problem of generating images that combine the appearance of the object as seen in a first example image with the geometry of the object as seen in a second example image, where the two examples differ by a viewpoint change and/or an object deformation. In order to factorize appearance and geometry, we introduce a tight bottleneck in the geometry-extraction process that selects and distils geometry-related features. Compared to standard image generation problems, which often use generative adversarial networks, our generation task is conditioned on both appearance and geometry and thus is significantly less ambiguous, to the point that adopting a simple perceptual loss formulation is sufficient. We demonstrate that our approach can learn object landmarks from synthetic image deformations or videos, all without manual supervision, while outperforming state-of-the-art unsupervised landmark detectors. We further show that our method is applicable to a large variety of datasets - faces, people, 3D objects, and digits - without any modifications."
https://openalex.org/W1616871572,Unsupervised learning of morphology without morphemes,"{'The': [0], 'first': [1], 'morphological': [2], 'learner': [3], 'based': [4], 'upon': [5], 'the': [6], 'theory': [7], 'of': [8], 'Whole': [9], 'Word': [10], 'Morphology': [11], '(Ford': [12], 'et': [13], 'al.,': [14], '1997)': [15], 'is': [16], 'outlined,': [17], 'and': [18], 'preliminary': [19], 'evaluation': [20], 'results': [21], 'are': [22], 'presented.': [23]}",2002,"['Morpheme', 'Lexicon', 'Computer science', 'Natural language processing', 'Artificial intelligence', 'Word (group theory)', 'Morphology (biology)', 'Word formation', 'Linguistics', 'Biology', 'Philosophy', 'Genetics']","The first morphological learner based upon the theory of Whole Word Morphology (Ford et al., 1997) is outlined, and preliminary evaluation results are presented."
https://openalex.org/W2767981409,Unsupervised Learning of Geometry with Edge-aware Depth-Normal Consistency,"{'Learning': [0], 'to': [1, 43, 125, 138], 'reconstruct': [2], 'depths': [3, 40, 83], 'in': [4, 21], 'a': [5, 29, 67, 71, 106], 'single': [6], 'image': [7, 124], 'by': [8, 65], 'watching': [9], 'unlabeled': [10], 'videos': [11], 'via': [12], 'deep': [13], 'convolutional': [14], 'network': [15], '(DCN)': [16], 'is': [17], 'attracting': [18], 'significant': [19], 'attention': [20], 'recent': [22], 'years.': [23], 'In': [24], 'this': [25], 'paper,': [26], 'we': [27, 55, 142], 'introduce': [28], 'surface': [30], 'normal': [31, 88, 154], 'representation': [32], 'for': [33, 150], 'unsupervised': [34], 'depth': [35, 108, 152], 'estimation': [36], 'framework.': [37], 'Our': [38], 'estimated': [39, 82, 100], 'are': [41, 116], 'constrained': [42], 'be': [44], 'compatible': [45], 'with': [46, 118], 'predicted': [47], 'normals,': [48, 101], 'yielding': [49], 'more': [50], 'robust': [51], 'geometry': [52], 'results.': [53], 'Specifically,': [54], 'formulate': [56], 'an': [57], 'edge-aware': [58], 'depth-normal': [59], 'consistency': [60], 'term,': [61], 'and': [62, 70, 86, 133, 147, 153, 163, 167], 'solve': [63], 'it': [64], 'constructing': [66], 'depth-to-normal': [68, 79], 'layer': [69, 73, 80, 104], 'normal-to-depth': [72, 103], 'inside': [74, 122], 'of': [75, 120, 130, 175], 'the': [76, 99, 102, 123, 128, 140, 144, 176, 180], 'DCN.': [77], 'The': [78], 'takes': [81], 'as': [84], 'input,': [85], 'computes': [87], 'directions': [89], 'using': [90], 'cross': [91], 'production': [92], 'based': [93], 'on': [94, 159], 'neighboring': [95], 'pixels.': [96], 'Then': [97], 'given': [98], 'outputs': [105], 'regularized': [107], 'map': [109], 'through': [110], 'local': [111], 'planar': [112], 'smoothness.': [113], 'Both': [114], 'layers': [115], 'computed': [117], 'awareness': [119], 'edges': [121], 'help': [126], 'address': [127], 'issue': [129], 'depth/normal': [131], 'discontinuity': [132], 'preserve': [134], 'sharp': [135], 'edges.': [136], 'Finally,': [137], 'train': [139], 'network,': [141], 'apply': [143], 'photometric': [145], 'error': [146], 'gradient': [148], 'smoothness': [149], 'both': [151, 160], 'predictions.': [155], 'We': [156], 'conducted': [157], 'experiments': [158], 'outdoor': [161], '(KITTI)': [162], 'indoor': [164], '(NYUv2)': [165], 'datasets,': [166], 'show': [168], 'that': [169], 'our': [170, 183], 'algorithm': [171], 'vastly': [172], 'outperforms': [173], 'state': [174], 'art,': [177], 'which': [178], 'demonstrates': [179], 'benefits': [181], 'from': [182], 'approach.': [184]}",2017,"['Normal', 'Consistency (knowledge bases)', 'Smoothness', 'Discontinuity (linguistics)', 'Computer science', 'Enhanced Data Rates for GSM Evolution', 'Artificial intelligence', 'Image (mathematics)', 'Pixel', 'Representation (politics)', 'Layer (electronics)', 'Depth map', 'Geometry', 'Algorithm', 'Surface (topology)', 'Mathematics', 'Computer vision', 'Mathematical analysis', 'Chemistry', 'Organic chemistry', 'Law', 'Political science', 'Politics']","Learning to reconstruct depths in a single image by watching unlabeled videos via deep convolutional network (DCN) is attracting significant attention in recent years. In this paper, we introduce a surface normal representation for unsupervised depth estimation framework. Our estimated depths are constrained to be compatible with predicted normals, yielding more robust geometry results. Specifically, we formulate an edge-aware depth-normal consistency term, and solve it by constructing a depth-to-normal layer and a normal-to-depth layer inside of the DCN. The depth-to-normal layer takes estimated depths as input, and computes normal directions using cross production based on neighboring pixels. Then given the estimated normals, the normal-to-depth layer outputs a regularized depth map through local planar smoothness. Both layers are computed with awareness of edges inside the image to help address the issue of depth/normal discontinuity and preserve sharp edges. Finally, to train the network, we apply the photometric error and gradient smoothness for both depth and normal predictions. We conducted experiments on both outdoor (KITTI) and indoor (NYUv2) datasets, and show that our algorithm vastly outperforms state of the art, which demonstrates the benefits from our approach."
https://openalex.org/W1988951376,Online Adaptation of a c-VEP Brain-Computer Interface(BCI) Based on Error-Related Potentials and Unsupervised Learning,"{'The': [0], 'goal': [1], 'of': [2, 45, 63, 76, 92, 111, 139, 149, 164, 173], 'a': [3, 10, 38, 70, 123, 127, 154, 162], 'Brain-Computer': [4], 'Interface': [5], '(BCI)': [6], 'is': [7, 115, 176], 'to': [8, 29, 48, 105, 134], 'control': [9], 'computer': [11], 'by': [12], 'pure': [13], 'brain': [14], 'activity.': [15], 'Recently,': [16], 'BCIs': [17], 'based': [18, 98, 169], 'on': [19, 99, 170], 'code-modulated': [20], 'visual': [21], 'evoked': [22], 'potentials': [23, 175], '(c-VEPs)': [24], 'have': [25], 'shown': [26], 'great': [27], 'potential': [28], 'establish': [30], 'high-performance': [31], 'communication.': [32], 'In': [33, 126, 157], 'this': [34], 'paper': [35], 'we': [36, 159], 'present': [37], 'c-VEP': [39], 'BCI': [40, 151, 166], 'that': [41, 72, 161], 'uses': [42, 73], 'online': [43, 61, 85], 'adaptation': [44, 62, 97], 'the': [46, 64, 74, 116, 130, 147, 150, 165, 171, 180], 'classifier': [47], 'reduce': [49], 'calibration': [50, 163], 'time': [51], 'and': [52, 69], 'increase': [53], 'performance.': [54], 'We': [55], 'compare': [56], 'two': [57], 'different': [58], 'approaches': [59, 80], 'for': [60, 122], 'system:': [65], 'an': [66, 84, 89, 106, 137], 'unsupervised': [67], 'method': [68, 71], 'detection': [75, 172], 'error-related': [77, 100, 174], 'potentials.': [78, 101], 'Both': [79], 'were': [81, 132], 'tested': [82], 'in': [83, 87, 153], 'study,': [86], 'which': [88, 114, 145], 'average': [90, 107, 138], 'accuracy': [91, 103], '96%': [93], 'was': [94], 'achieved': [95], 'with': [96, 136], 'This': [102], 'corresponds': [104], 'information': [108], 'transfer': [109], 'rate': [110], '144': [112], 'bit/min,': [113], 'highest': [117], 'bitrate': [118], 'reported': [119], 'so': [120], 'far': [121], 'non-invasive': [124], 'BCI.': [125], 'free-spelling': [128], 'mode,': [129], 'subjects': [131], 'able': [133], 'write': [135], '21.3': [140], 'error-free': [141], 'letters': [142], 'per': [143], 'minute,': [144], 'shows': [146], 'feasibility': [148], 'system': [152, 167], 'normal-use': [155], 'scenario.': [156], 'addition': [158], 'show': [160], 'solely': [168], 'possible,': [177], 'without': [178], 'knowing': [179], 'true': [181], 'class': [182], 'labels.': [183]}",2012,"['Brain–computer interface', 'Computer science', 'Interface (matter)', 'Adaptation (eye)', 'Visual evoked potentials', 'Artificial intelligence', 'Error detection and correction', 'Speech recognition', 'Classifier (UML)', 'Pattern recognition (psychology)', 'Electroencephalography', 'Algorithm', 'Neuroscience', 'Psychology', 'Maximum bubble pressure method', 'Bubble', 'Parallel computing']","The goal of a Brain-Computer Interface (BCI) is to control a computer by pure brain activity. Recently, BCIs based on code-modulated visual evoked potentials (c-VEPs) have shown great potential to establish high-performance communication. In this paper we present a c-VEP BCI that uses online adaptation of the classifier to reduce calibration time and increase performance. We compare two different approaches for online adaptation of the system: an unsupervised method and a method that uses the detection of error-related potentials. Both approaches were tested in an online study, in which an average accuracy of 96% was achieved with adaptation based on error-related potentials. This accuracy corresponds to an average information transfer rate of 144 bit/min, which is the highest bitrate reported so far for a non-invasive BCI. In a free-spelling mode, the subjects were able to write with an average of 21.3 error-free letters per minute, which shows the feasibility of the BCI system in a normal-use scenario. In addition we show that a calibration of the BCI system solely based on the detection of error-related potentials is possible, without knowing the true class labels."
https://openalex.org/W2935908327,Local Aggregation for Unsupervised Learning of Visual Embeddings,"{'Unsupervised': [0], 'approaches': [1], 'to': [2, 77, 102, 113, 124, 137], 'learning': [3, 45, 153], 'in': [4, 63, 72, 88, 116, 158, 162, 168], 'neural': [5], 'networks': [6, 23, 51], 'are': [7], 'of': [8, 22, 30, 40, 43, 58, 66, 106, 134], 'substantial': [9], 'interest': [10], 'for': [11, 27], 'furthering': [12], 'artificial': [13], 'intelligence,': [14], 'both': [15], 'because': [16, 34], 'they': [17, 35], 'would': [18, 36], 'enable': [19], 'the': [20, 25, 41, 56, 64, 117], 'training': [21, 73], 'without': [24], 'need': [26], 'large': [28], 'numbers': [29], 'expensive': [31], 'annotations,': [32], 'and': [33, 82, 165], 'be': [37], 'better': [38], 'models': [39], 'kind': [42], 'general-purpose': [44], 'deployed': [46], 'by': [47], 'humans.': [48], 'However,': [49], 'unsupervised': [50, 151], 'have': [52, 85], 'long': [53], 'lagged': [54], 'behind': [55], 'performance': [57, 154], 'their': [59], 'supervised': [60], 'counterparts,': [61], 'especially': [62], 'domain': [65], 'large-scale': [67, 145], 'visual': [68, 146], 'recognition.': [69], 'Recent': [70], 'developments': [71], 'deep': [74], 'convolutional': [75], 'embeddings': [76], 'maximize': [78, 103], 'non-parametric': [79], 'instance': [80], 'separation': [81], 'clustering': [83], 'objectives': [84], 'shown': [86], 'promise': [87], 'closing': [89], 'this': [90], 'gap.': [91], 'Here,': [92], 'we': [93], 'describe': [94], 'a': [95, 104], 'method': [96], 'that': [97], 'trains': [98], 'an': [99], 'embedding': [100, 118], 'function': [101], 'metric': [105, 128], 'local': [107], 'aggregation,': [108], 'causing': [109], 'similar': [110], 'data': [111], 'instances': [112, 123], 'move': [114], 'together': [115], 'space,': [119], 'while': [120], 'allowing': [121, 131], 'dissimilar': [122], 'separate.': [125], 'This': [126], 'aggregation': [127], 'is': [129], 'dynamic,': [130], 'soft': [132], 'clusters': [133], 'different': [135], 'scales': [136], 'emerge.': [138], 'We': [139], 'evaluate': [140], 'our': [141], 'procedure': [142], 'on': [143, 155], 'several': [144], 'recognition': [147, 157, 161], 'datasets,': [148], 'achieving': [149], 'state-of-the-art': [150], 'transfer': [152], 'object': [156, 166], 'ImageNet,': [159], 'scene': [160], 'Places': [163], '205,': [164], 'detection': [167], 'PASCAL': [169], 'VOC.': [170]}",2019,"['Computer science', 'Artificial intelligence', 'Embedding', 'Unsupervised learning', 'Pascal (unit)', 'Cluster analysis', 'Machine learning', 'Convolutional neural network', 'Transfer of learning', 'Competitive learning', 'Pattern recognition (psychology)', 'Metric (unit)', 'Deep learning', 'Programming language', 'Operations management', 'Economics']","Unsupervised approaches to learning in neural networks are of substantial interest for furthering artificial intelligence, both because they would enable the training of networks without the need for large numbers of expensive annotations, and because they would be better models of the kind of general-purpose learning deployed by humans. However, unsupervised networks have long lagged behind the performance of their supervised counterparts, especially in the domain of large-scale visual recognition. Recent developments in training deep convolutional embeddings to maximize non-parametric instance separation and clustering objectives have shown promise in closing this gap. Here, we describe a method that trains an embedding function to maximize a metric of local aggregation, causing similar data instances to move together in the embedding space, while allowing dissimilar instances to separate. This aggregation metric is dynamic, allowing soft clusters of different scales to emerge. We evaluate our procedure on several large-scale visual recognition datasets, achieving state-of-the-art unsupervised transfer learning performance on object recognition in ImageNet, scene recognition in Places 205, and object detection in PASCAL VOC."
https://openalex.org/W2883294120,Unsupervised Learning of a Hierarchical Spiking Neural Network for Optical Flow Estimation: From Events to Global Motion Perception,"{'The': [0, 129], 'combination': [1], 'of': [2, 13, 64, 84, 154], 'spiking': [3, 27, 156], 'neural': [4, 66, 78, 157], 'networks': [5], 'and': [6, 16, 33, 55, 72, 92, 94, 106, 114, 136, 161], 'event-based': [7, 48], 'vision': [8], 'sensors': [9], 'holds': [10], 'the': [11, 24, 42, 62, 77, 81, 146], 'potential': [12], 'highly': [14], 'efficient': [15], 'high-bandwidth': [17], 'optical': [18], 'flow': [19], 'estimation.': [20], 'This': [21], 'paper': [22], 'presents': [23], 'first': [25], 'hierarchical': [26], 'architecture': [28, 79], 'in': [29, 37, 124], 'which': [30], 'motion': [31, 87, 96, 116, 121], '(direction': [32], 'speed)': [34], 'selectivity': [35, 122], 'emerges': [36, 123], 'an': [38, 47], 'unsupervised': [39], 'fashion': [40], 'from': [41], 'raw': [43], 'stimuli': [44], 'generated': [45], 'with': [46, 100, 141], 'camera.': [49], 'A': [50], 'novel': [51], 'adaptive': [52], 'neuron': [53], 'model': [54], 'stable': [56], 'spike-timing-dependent': [57], 'plasticity': [58], 'formulation': [59], 'are': [60, 110, 163], 'at': [61, 165], 'core': [63], 'this': [65, 142], 'network': [67], 'governing': [68], 'its': [69], 'spike-based': [70], 'processing': [71], 'learning,': [73], 'respectively.': [74], 'After': [75], 'convergence,': [76], 'exhibits': [80], 'main': [82], 'properties': [83], 'biological': [85], 'visual': [86], 'systems,': [88], 'namely': [89], 'feature': [90, 113], 'extraction': [91], 'local': [93, 115], 'global': [95, 120], 'perception.': [97], 'Convolutional': [98], 'layers': [99], 'input': [101], 'synapses': [102], 'characterized': [103], 'by': [104], 'single': [105], 'multiple': [107], 'transmission': [108], 'delays': [109], 'employed': [111], 'for': [112], 'perception,': [117], 'respectively;': [118], 'while': [119], 'a': [125, 148], 'final': [126], 'fully-connected': [127], 'layer.': [128], 'proposed': [130], 'solution': [131], 'is': [132], 'validated': [133], 'using': [134], 'synthetic': [135], 'real': [137], 'event': [138], 'sequences.': [139], 'Along': [140], 'paper,': [143], 'we': [144], 'provide': [145], 'cuSNNlibrary,': [147], 'framework': [149], 'that': [150], 'enables': [151], 'GPU-accelerated': [152], 'simulations': [153], 'large-scale': [155], 'networks.': [158], 'Source': [159], 'code': [160], 'samples': [162], 'available': [164], 'https://github.com/tudelft/cuSNN.': [166]}",2019,"['Computer science', 'Artificial intelligence', 'Spiking neural network', 'Optical flow', 'Neuromorphic engineering', 'Motion estimation', 'Convolutional neural network', 'Artificial neural network', 'Feature extraction', 'Feature (linguistics)', 'Spike (software development)', 'Pattern recognition (psychology)', 'Unsupervised learning', 'Computer vision', 'Image (mathematics)', 'Software engineering', 'Linguistics', 'Philosophy']","The combination of spiking neural networks and event-based vision sensors holds the potential of highly efficient and high-bandwidth optical flow estimation. This paper presents the first hierarchical spiking architecture in which motion (direction and speed) selectivity emerges in an unsupervised fashion from the raw stimuli generated with an event-based camera. A novel adaptive neuron model and stable spike-timing-dependent plasticity formulation are at the core of this neural network governing its spike-based processing and learning, respectively. After convergence, the neural architecture exhibits the main properties of biological visual motion systems, namely feature extraction and local and global motion perception. Convolutional layers with input synapses characterized by single and multiple transmission delays are employed for feature and local motion perception, respectively; while global motion selectivity emerges in a final fully-connected layer. The proposed solution is validated using synthetic and real event sequences. Along with this paper, we provide the cuSNNlibrary, a framework that enables GPU-accelerated simulations of large-scale spiking neural networks. Source code and samples are available at https://github.com/tudelft/cuSNN."
https://openalex.org/W2255128034,The use of an unsupervised learning approach for characterizing latent behaviors in accelerometer data,"{'Abstract': [0], 'The': [1, 132], 'recent': [2], 'increase': [3], 'in': [4, 236], 'data': [5, 83, 219], 'accuracy': [6], 'from': [7], 'high': [8], 'resolution': [9], 'accelerometers': [10], 'offers': [11], 'substantial': [12], 'potential': [13], 'for': [14, 26, 53, 210], 'improved': [15], 'understanding': [16], 'and': [17, 90, 101, 123, 129, 153, 174, 189, 195, 248], 'prediction': [18], 'of': [19, 35, 38, 60, 71, 88, 134, 146, 157, 186, 214, 244], 'animal': [20], 'movements.': [21], 'However,': [22], 'current': [23, 242], 'approaches': [24, 252], 'used': [25], 'analysing': [27], 'these': [28], 'multivariable': [29, 217], 'datasets': [30], 'typically': [31], 'require': [32], 'existing': [33, 249], 'knowledge': [34, 59, 243], 'the': [36, 39, 43, 54, 61, 69, 78, 110, 143, 147, 155, 158, 178, 211, 245], 'behaviors': [37, 63, 191, 246], 'animals': [40], 'to': [41, 116, 162], 'inform': [42], 'behavioral': [44, 119, 164], 'classification': [45], 'process.': [46], 'These': [47], 'methods': [48], 'are': [49, 221], 'thus': [50], 'not': [51], 'well‐suited': [52], 'many': [55], 'cases': [56, 237], 'where': [57, 238], 'limited': [58, 241, 255], 'different': [62], 'performed': [64, 247], 'exist.': [65], 'Here,': [66], 'we': [67, 81, 232, 239], 'introduce': [68], 'use': [70], 'an': [72, 184, 207], 'unsupervised': [73, 111, 203], 'learning': [74, 112, 204, 251], 'algorithm.': [75], 'To': [76], 'illustrate': [77], ""method's"": [79], 'capability': [80], 'analyse': [82], 'collected': [84], 'using': [85], 'a': [86], 'combination': [87], 'GPS': [89], 'Accelerometers': [91], 'on': [92], 'two': [93, 148], 'seabird': [94], 'species:': [95], 'razorbills': [96], '(': [97, 104], 'Alca': [98], 'torda': [99], ')': [100], 'common': [102], 'guillemots': [103], 'Uria': [105], 'aalge': [106], ').': [107], 'We': [108, 199], 'applied': [109], 'algorithm': [113], 'Expectation': [114], 'Maximization': [115], 'characterize': [117], 'latent': [118], 'states': [120], 'both': [121, 127, 151], 'above': [122, 152], 'below': [124, 154], 'water': [125, 179], 'at': [126], 'individual': [128], 'group': [130], 'level.': [131], 'application': [133, 235], 'this': [135, 181, 202], 'flexible': [136], 'approach': [137, 182, 205], 'yielded': [138], 'significant': [139], 'new': [140], 'insights': [141], 'into': [142], 'foraging': [144], 'strategies': [145], 'study': [149], 'species,': [150], 'surface': [156], 'water.': [159], 'In': [160, 230], 'addition': [161], 'general': [163], 'modes': [165], 'such': [166, 192, 215], 'as': [167, 170, 172, 193], 'flying,': [168], 'floating,': [169], 'well': [171], 'descending': [173], 'ascending': [175], 'phases': [176], 'within': [177], 'column,': [180], 'allowed': [183], 'exploration': [185], 'previously': [187], 'unstudied': [188], 'important': [190], 'searching': [194], 'prey': [196], 'chasing/capture': [197], 'events.': [198], 'propose': [200], 'that': [201, 220], 'provides': [206], 'ideal': [208], 'tool': [209], 'systematic': [212], 'analysis': [213], 'complex': [216], 'movement': [218], 'increasingly': [222], 'being': [223], 'obtained': [224], 'with': [225], 'accelerometer': [226], 'tags': [227], 'across': [228], 'species.': [229], 'particular,': [231], 'recommend': [233], 'its': [234], 'have': [240, 254], 'supervised': [250], 'may': [253], 'utility.': [256]}",2016,"['Accelerometer', 'Unsupervised learning', 'Computer science', 'Artificial intelligence', 'Machine learning', 'Operating system']","Abstract The recent increase in data accuracy from high resolution accelerometers offers substantial potential for improved understanding and prediction of animal movements. However, current approaches used for analysing these multivariable datasets typically require existing knowledge of the behaviors of the animals to inform the behavioral classification process. These methods are thus not well‐suited for the many cases where limited knowledge of the different behaviors performed exist. Here, we introduce the use of an unsupervised learning algorithm. To illustrate the method's capability we analyse data collected using a combination of GPS and Accelerometers on two seabird species: razorbills ( Alca torda ) and common guillemots ( Uria aalge ). We applied the unsupervised learning algorithm Expectation Maximization to characterize latent behavioral states both above and below water at both individual and group level. The application of this flexible approach yielded significant new insights into the foraging strategies of the two study species, both above and below the surface of the water. In addition to general behavioral modes such as flying, floating, as well as descending and ascending phases within the water column, this approach allowed an exploration of previously unstudied and important behaviors such as searching and prey chasing/capture events. We propose that this unsupervised learning approach provides an ideal tool for the systematic analysis of such complex multivariable movement data that are increasingly being obtained with accelerometer tags across species. In particular, we recommend its application in cases where we have limited current knowledge of the behaviors performed and existing supervised learning approaches may have limited utility."
https://openalex.org/W2955804754,Unsupervised learning for local structure detection in colloidal systems,"{'We': [0, 44, 63], 'introduce': [1], 'a': [2, 18, 29, 47, 73, 101, 130], 'simple,': [3], 'fast,': [4], 'and': [5, 92, 110, 115, 137], 'easy': [6], 'to': [7, 36, 57, 89, 123, 129, 143, 155], 'implement': [8], 'unsupervised': [9], 'learning': [10], 'algorithm': [11], 'for': [12], 'detecting': [13], 'different': [14], 'local': [15, 39, 127], 'environments': [16, 128], 'on': [17, 70], 'single-particle': [19], 'level': [20], 'in': [21, 55, 153, 164], 'colloidal': [22, 77], 'systems.': [23], 'In': [24, 117, 141], 'this': [25], 'algorithm,': [26], 'we': [27, 98, 120, 147], 'use': [28, 46, 149], 'vector': [30], 'of': [31, 41, 67, 72, 76, 103], 'standard': [32], 'bond-orientational': [33], 'order': [34, 56, 139, 154, 162], 'parameters': [35, 163], 'describe': [37], 'the': [38, 65, 68, 125, 150, 157, 165], 'environment': [40], 'each': [42], 'particle.': [43], 'then': [45], 'neural-network-based': [48], 'autoencoder': [49, 152], 'combined': [50], 'with': [51], 'Gaussian': [52], 'mixture': [53], 'models': [54], 'autonomously': [58], 'group': [59], 'together': [60], 'similar': [61, 131], 'environments.': [62], 'test': [64], 'performance': [66], 'method': [69], 'snapshots': [71], 'wide': [74], 'variety': [75, 102], 'systems': [78, 88, 166], 'obtained': [79], 'via': [80], 'computer': [81], 'simulations,': [82], 'ranging': [83], 'from': [84], 'simple': [85], 'isotropically': [86], 'interacting': [87], 'binary': [90], 'mixtures,': [91], 'even': [93], 'anisotropic': [94], 'hard': [95], 'cubes.': [96], 'Additionally,': [97], 'look': [99], 'at': [100], 'common': [104], 'self-assembled': [105], 'situations': [106], 'such': [107, 145], 'as': [108, 133], 'fluid-crystal': [109], 'crystal-crystal': [111], 'coexistences,': [112], 'grain': [113], 'boundaries,': [114], 'nucleation.': [116], 'all': [118], 'cases,': [119], 'are': [121], 'able': [122], 'identify': [124], 'relevant': [126, 159], 'precision': [132], '“standard,”': [134], 'manually': [135], 'tuned,': [136], 'system-specific,': [138], 'parameters.': [140], 'addition': [142], 'classifying': [144], 'environments,': [146], 'also': [148], 'trained': [151], 'determine': [156], 'most': [158], 'bond': [160], 'orientational': [161], 'analyzed.': [167]}",2019,[],"We introduce a simple, fast, and easy to implement unsupervised learning algorithm for detecting different local environments on a single-particle level in colloidal systems. In this algorithm, we use a vector of standard bond-orientational order parameters to describe the local environment of each particle. We then use a neural-network-based autoencoder combined with Gaussian mixture models in order to autonomously group together similar environments. We test the performance of the method on snapshots of a wide variety of colloidal systems obtained via computer simulations, ranging from simple isotropically interacting systems to binary mixtures, and even anisotropic hard cubes. Additionally, we look at a variety of common self-assembled situations such as fluid-crystal and crystal-crystal coexistences, grain boundaries, and nucleation. In all cases, we are able to identify the relevant local environments to a similar precision as “standard,” manually tuned, and system-specific, order parameters. In addition to classifying such environments, we also use the trained autoencoder in order to determine the most relevant bond orientational order parameters in the systems analyzed."
https://openalex.org/W2787109437,Deep Temporal Clustering : Fully Unsupervised Learning of Time-Domain Features,"{'Unsupervised': [0], 'learning': [1, 40], 'of': [2, 125, 134], 'time': [3, 130, 140], 'series': [4, 141], 'data,': [5], 'also': [6], 'known': [7], 'as': [8], 'temporal': [9, 34, 50, 56, 81, 89, 106, 174], 'clustering,': [10, 115], 'is': [11, 137, 168], 'a': [12, 21, 37, 54, 118, 123], 'challenging': [13], 'problem': [14], 'in': [15], 'machine': [16], 'learning.': [17], 'Here': [18], 'we': [19, 116, 156], 'propose': [20], 'novel': [22, 55], 'algorithm,': [23], 'Deep': [24], 'Temporal': [25], 'Clustering': [26], '(DTC),': [27], 'to': [28, 149, 170], 'naturally': [29], 'integrate': [30], 'dimensionality': [31, 51, 71, 175], 'reduction': [32, 52, 72, 176], 'and': [33, 53, 69, 78, 95, 100, 177], 'clustering': [35, 57, 67, 82, 178], 'into': [36, 105], 'single': [38], 'end-to-end': [39], 'framework,': [41], 'fully': [42, 172], 'unsupervised.': [43], 'The': [44, 132, 165], 'algorithm': [45, 136, 161], 'utilizes': [46], 'an': [47], 'autoencoder': [48], 'for': [49, 59, 113, 128], 'layer': [58, 83], 'cluster': [60], 'assignment.': [61], 'Then': [62], 'it': [63], 'jointly': [64], 'optimizes': [65], 'the': [66, 70, 80, 109, 129, 135, 159, 171], 'objective': [68], 'objec': [73], 'tive.': [74], 'Based': [75], 'on': [76], 'requirement': [77], 'application,': [79], 'can': [84], 'be': [85], 'customized': [86], 'with': [87], 'any': [88], 'similarity': [90, 93], 'metric.': [91], 'Several': [92], 'metrics': [94], 'state-of-the-art': [96], 'algorithms': [97], 'are': [98], 'considered': [99], 'compared.': [101], 'To': [102], 'gain': [103], 'insight': [104], 'features': [107], 'that': [108, 121, 158], 'network': [110], 'has': [111], 'learned': [112], 'its': [114], 'apply': [117], 'visualization': [119], 'method': [120], 'generates': [122], 'region': [124], 'interest': [126], 'heatmap': [127], 'series.': [131], 'viability': [133], 'demonstrated': [138], 'using': [139], 'data': [142], 'from': [143, 147], 'diverse': [144], 'domains,': [145], 'ranging': [146], 'earthquakes': [148], 'spacecraft': [150], 'sensor': [151], 'data.': [152], 'In': [153], 'each': [154], 'case,': [155], 'show': [157], 'proposed': [160], 'outperforms': [162], 'traditional': [163], 'methods.': [164], 'superior': [166], 'performance': [167], 'attributed': [169], 'integrated': [173], 'criterion.': [179]}",2018,"['Cluster analysis', 'Autoencoder', 'Dimensionality reduction', 'Computer science', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Correlation clustering', 'Temporal database', 'Data stream clustering', 'Unsupervised learning', 'Deep learning', 'Canopy clustering algorithm', 'Clustering high-dimensional data', 'CURE data clustering algorithm', 'Data mining']","Unsupervised learning of time series data, also known as temporal clustering, is a challenging problem in machine learning. Here we propose a novel algorithm, Deep Temporal Clustering (DTC), to naturally integrate dimensionality reduction and temporal clustering into a single end-to-end learning framework, fully unsupervised. The algorithm utilizes an autoencoder for temporal dimensionality reduction and a novel temporal clustering layer for cluster assignment. Then it jointly optimizes the clustering objective and the dimensionality reduction objec tive. Based on requirement and application, the temporal clustering layer can be customized with any temporal similarity metric. Several similarity metrics and state-of-the-art algorithms are considered and compared. To gain insight into temporal features that the network has learned for its clustering, we apply a visualization method that generates a region of interest heatmap for the time series. The viability of the algorithm is demonstrated using time series data from diverse domains, ranging from earthquakes to spacecraft sensor data. In each case, we show that the proposed algorithm outperforms traditional methods. The superior performance is attributed to the fully integrated temporal dimensionality reduction and clustering criterion."
https://openalex.org/W2963194800,auDeep: Unsupervised Learning of Representations from Audio with Deep\n Recurrent Neural Networks,"{'auDeep': [0], 'is': [1, 13], 'a': [2, 16, 45], 'Python': [3, 46], 'toolkit': [4], 'for': [5, 48], 'deep': [6], 'unsupervised': [7], 'representation': [8], 'learning': [9], 'from\\nacoustic': [10], 'data.': [11], 'It': [12], 'based': [14], 'on': [15], 'recurrent': [17], 'sequence': [18, 20], 'to': [19, 44], 'autoencoder\\napproach': [21], 'which': [22, 54], 'can': [23], 'learn': [24], 'representations': [25], 'of': [26, 53], 'time': [27], 'series': [28], 'data': [29], 'by': [30], 'taking': [31], 'into\\naccount': [32], 'their': [33], 'temporal': [34], 'dynamics.': [35], 'We': [36], 'provide': [37], 'an': [38], 'extensive': [39], 'command': [40], 'line': [41], 'interface\\nin': [42], 'addition': [43], 'API': [47], 'users': [49], 'and': [50, 57], 'developers,': [51], 'both': [52], 'are\\ncomprehensively': [55], 'documented': [56], 'publicly': [58], 'available': [59], 'at\\nhttps://github.com/auDeep/auDeep.': [60], 'Experimental': [61], 'results': [62], 'indicate': [63], 'that': [64], 'auDeep\\nfeatures': [65], 'are': [66], 'competitive': [67], 'with': [68], 'state-of-the': [69], 'art': [70], 'audio': [71], 'classification.\\n': [72]}",2017,"['Python (programming language)', 'Autoencoder', 'Computer science', 'Deep learning', 'Unsupervised learning', 'Artificial intelligence', 'Encoder', 'Feature learning', 'Recurrent neural network', 'Artificial neural network', 'Speech recognition', 'Machine learning', 'Programming language', 'Operating system']","auDeep is a Python toolkit for deep unsupervised representation learning from\nacoustic data. It is based on a recurrent sequence to sequence autoencoder\napproach which can learn representations of time series data by taking into\naccount their temporal dynamics. We provide an extensive command line interface\nin addition to a Python API for users and developers, both of which are\ncomprehensively documented and publicly available at\nhttps://github.com/auDeep/auDeep. Experimental results indicate that auDeep\nfeatures are competitive with state-of-the art audio classification.\n"
https://openalex.org/W2889050299,Microstructure Cluster Analysis with Transfer Learning and Unsupervised Learning,"{'Abstract': [0], 'We': [1, 97], 'apply': [2], 'computer': [3], 'vision': [4], 'and': [5, 85], 'machine': [6], 'learning': [7, 18, 37, 103], 'methods': [8], 'to': [9, 43, 108], 'analyze': [10], 'two': [11, 51], 'datasets': [12], 'of': [13, 25, 48, 73, 89], 'microstructural': [14], 'images.': [15], 'A': [16, 53], 'transfer': [17, 102], 'pipeline': [19], 'utilizes': [20], 'the': [21, 32, 40, 79, 100], 'fully': [22, 109], 'connected': [23], 'layer': [24], 'a': [26, 71, 87], 'pre-trained': [27], 'convolutional': [28], 'neural': [29], 'network': [30], 'as': [31], 'image': [33, 41, 80], 'representation.': [34], 'An': [35], 'unsupervised': [36], 'method': [38, 104], 'uses': [39], 'representations': [42], 'discover': [44], 'visually': [45, 61, 83], 'distinct': [46, 84], 'clusters': [47], 'images': [49, 68], 'within': [50], 'datasets.': [52], 'minimally': [54], 'supervised': [55], 'clustering': [56], 'approach': [57, 65], 'classifies': [58, 67], 'micrographs': [59], 'into': [60], 'similar': [62], 'groups.': [63], 'This': [64], 'successfully': [66], 'both': [69], 'in': [70, 76, 86], 'dataset': [72, 88], 'surface': [74], 'defects': [75], 'steel,': [77], 'where': [78], 'classes': [81], 'are': [82], 'fracture': [90], 'surfaces': [91], 'that': [92, 99], 'humans': [93], 'have': [94], 'difficulty': [95], 'classifying.': [96], 'find': [98], 'unsupervised,': [101], 'gives': [105], 'results': [106], 'comparable': [107], 'supervised,': [110], 'custom-built': [111], 'approaches.': [112]}",2018,"['Artificial intelligence', 'Unsupervised learning', 'Transfer of learning', 'Computer science', 'Convolutional neural network', 'Pattern recognition (psychology)', 'Cluster analysis', 'Pipeline (software)', 'Deep learning', 'Image (mathematics)', 'Representation (politics)', 'Supervised learning', 'Machine learning', 'Artificial neural network', 'Politics', 'Law', 'Programming language', 'Political science']","Abstract We apply computer vision and machine learning methods to analyze two datasets of microstructural images. A transfer learning pipeline utilizes the fully connected layer of a pre-trained convolutional neural network as the image representation. An unsupervised learning method uses the image representations to discover visually distinct clusters of images within two datasets. A minimally supervised clustering approach classifies micrographs into visually similar groups. This approach successfully classifies images both in a dataset of surface defects in steel, where the image classes are visually distinct and in a dataset of fracture surfaces that humans have difficulty classifying. We find that the unsupervised, transfer learning method gives results comparable to fully supervised, custom-built approaches."
https://openalex.org/W2908779501,Low-Complexity Non-Intrusive Load Monitoring Using Unsupervised Learning and Generalized Appliance Models,"{'Awareness': [0], 'of': [1, 35, 65, 77, 134, 141, 174], 'electric': [2, 51], 'energy': [3, 14, 20, 42, 52, 86, 151], 'usage': [4, 53, 59, 143], 'has': [5, 26, 165], 'both': [6], 'societal': [7], 'and': [8, 16, 47, 54, 122, 192], 'economic': [9], 'benefits,': [10], 'which': [11, 44, 98], 'include': [12], 'reduced': [13], 'bills': [15], 'stress': [17], 'on': [18, 58], 'non-renewable': [19], 'sources.': [21], 'In': [22, 88], 'recent': [23, 172], 'years,': [24], 'there': [25], 'been': [27], 'a': [28, 74, 91, 109, 125, 132, 145], 'surge': [29], 'in': [30, 32, 68, 124], 'interest': [31], 'the': [33, 139, 154, 163, 175], 'field': [34], 'load': [36, 127], 'monitoring,': [37], 'also': [38], 'referred': [39], 'to': [40, 61, 130], 'as': [41, 187], 'disaggregation,': [43], 'involves': [45], 'methods': [46], 'techniques': [48], 'for': [49, 85, 138, 167, 178], 'monitoring': [50, 128], 'providing': [55], 'appropriate': [56], 'feedback': [57], 'patterns': [60], 'homeowners.': [62], 'The': [63, 104], 'use': [64], 'unsupervised': [66, 93, 179], 'learning': [67], 'Non-Intrusive': [69], 'Load': [70], 'Monitoring': [71], '(NILM)': [72], 'is': [73, 96, 99, 106], 'key': [75], 'area': [76], 'study,': [78], 'with': [79, 171], 'practical': [80, 102, 126], 'solutions': [81], 'having': [82], 'wide': [83], 'implications': [84], 'monitoring.': [87], 'this': [89], 'paper,': [90], 'low-complexity': [92], 'NILM': [94, 180, 184], 'algorithm': [95, 105, 112, 164], 'presented,': [97], 'designed': [100], 'toward': [101], 'implementation.': [103], 'inspired': [107], 'by': [108], 'fuzzy': [110], 'clustering': [111], 'called': [113], 'Entropy': [114], 'Index': [115], 'Constraints': [116], 'Competitive': [117], 'Agglomeration': [118], '(EICCA),': [119], 'but': [120], 'facilitated': [121], 'improved': [123], 'environment': [129], 'produce': [131], 'set': [133], 'generalized': [135], 'appliance': [136, 142], 'models': [137], 'detection': [140, 169], 'within': [144], 'household.': [146], 'Experimental': [147], 'evaluation': [148], 'conducted': [149], 'using': [150], 'data': [152], 'from': [153], 'Reference': [155], 'Energy': [156, 194], 'Data': [157], 'Disaggregation': [158], 'Dataset': [159], '(REDD)': [160], 'indicates': [161], 'that': [162], 'out-performance': [166], 'event': [168], 'compared': [170], 'state': [173], 'art': [176], 'work': [177], 'when': [181], 'considering': [182], 'common': [183], 'metrics': [185], 'such': [186], 'Accuracy,': [188], 'Precision,': [189], 'Recall,': [190], 'F-measure,': [191], 'Total': [193], 'Correctly': [195], 'Assigned': [196], '(TECA).': [197]}",2019,"['Computer science', 'Unsupervised learning', 'Cluster analysis', 'Data mining', 'Energy (signal processing)', 'Entropy (arrow of time)', 'Machine learning', 'Artificial intelligence', 'Statistics', 'Mathematics', 'Physics', 'Quantum mechanics']","Awareness of electric energy usage has both societal and economic benefits, which include reduced energy bills and stress on non-renewable energy sources. In recent years, there has been a surge in interest in the field of load monitoring, also referred to as energy disaggregation, which involves methods and techniques for monitoring electric energy usage and providing appropriate feedback on usage patterns to homeowners. The use of unsupervised learning in Non-Intrusive Load Monitoring (NILM) is a key area of study, with practical solutions having wide implications for energy monitoring. In this paper, a low-complexity unsupervised NILM algorithm is presented, which is designed toward practical implementation. The algorithm is inspired by a fuzzy clustering algorithm called Entropy Index Constraints Competitive Agglomeration (EICCA), but facilitated and improved in a practical load monitoring environment to produce a set of generalized appliance models for the detection of appliance usage within a household. Experimental evaluation conducted using energy data from the Reference Energy Data Disaggregation Dataset (REDD) indicates that the algorithm has out-performance for event detection compared with recent state of the art work for unsupervised NILM when considering common NILM metrics such as Accuracy, Precision, Recall, F-measure, and Total Energy Correctly Assigned (TECA)."
https://openalex.org/W4385452929,From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy,"{'Undoubtedly,': [0], 'the': [1, 10, 16, 20, 51, 58, 68, 81, 91, 100, 116, 120, 137, 148, 157, 224, 234, 252], 'evolution': [2], 'of': [3, 12, 53, 63, 88, 93, 102, 230], 'Generative': [4], 'AI': [5], '(GenAI)': [6], 'models': [7, 23], 'has': [8], 'been': [9], 'highlight': [11], 'digital': [13], 'transformation': [14], 'in': [15, 56, 90, 151], 'year': [17], '2022.': [18], 'As': [19], 'different': [21], 'GenAI': [22, 54, 89, 149, 191, 245], 'like': [24, 128], 'ChatGPT': [25, 160], 'and': [26, 34, 60, 65, 71, 86, 95, 132, 155, 180, 189, 207, 217, 227, 239, 249], 'Google': [27], 'Bard': [28], 'continue': [29], 'to': [30, 38, 111, 166, 193, 242], 'foster': [31], 'their': [32], 'complexity': [33], 'capability,': [35], 'it&#x2019;s': [36], 'critical': [37], 'understand': [39], 'its': [40, 255], 'consequences': [41], 'from': [42], 'a': [43], 'cybersecurity': [44, 94, 256], 'perspective.': [45], 'Several': [46], 'instances': [47], 'recently': [48], 'have': [49], 'demonstrated': [50], 'use': [52, 147], 'tools': [55, 150, 192], 'both': [57], 'defensive': [59], 'offensive': [61], 'side': [62], 'cybersecurity,': [64], 'focusing': [66], 'on': [67, 119, 136], 'social,': [69, 225], 'ethical': [70, 117, 212, 228, 250], 'privacy': [72], 'implications': [73, 229], 'this': [74, 244], 'technology': [75], 'possesses.': [76], 'This': [77, 122, 183], 'research': [78], 'paper': [79, 123, 140, 184, 235], 'highlights': [80, 236], 'limitations,': [82], 'challenges,': [83], 'potential': [84], 'risks,': [85], 'opportunities': [87], 'domain': [92], 'privacy.': [96], 'The': [97, 139], 'work': [98], 'presents': [99], 'vulnerabilities': [101], 'ChatGPT,': [103], 'which': [104], 'can': [105, 146, 161], 'be': [106, 162], 'exploited': [107], 'by': [108, 164], 'malicious': [109, 113], 'users': [110], 'exfiltrate': [112], 'information': [114], 'bypassing': [115], 'constraints': [118], 'model.': [121], 'demonstrates': [124], 'successful': [125], 'example': [126], 'attacks': [127, 135], 'Jailbreaks,': [129], 'reverse': [130], 'psychology,': [131], 'prompt': [133], 'injection': [134], 'ChatGPT.': [138, 231], 'also': [141, 222], 'investigates': [142], 'how': [143], 'cyber': [144, 153, 198], 'offenders': [145], 'developing': [152, 211], 'attacks,': [154, 170, 172], 'explore': [156], 'scenarios': [158], 'where': [159], 'used': [163], 'adversaries': [165], 'create': [167], 'social': [168], 'engineering': [169], 'phishing': [171], 'automated': [173], 'hacking,': [174], 'attack': [175, 209], 'payload': [176], 'generation,': [177], 'malware': [178, 218], 'creation,': [179], 'polymorphic': [181], 'malware.': [182], 'then': [185], 'examines': [186], 'defense': [187, 199], 'techniques': [188], 'uses': [190], 'improve': [194], 'security': [195], 'measures,': [196], 'including': [197], 'automation,': [200], 'reporting,': [201], 'threat': [202], 'intelligence,': [203], 'secure': [204], 'code': [205], 'generation': [206], 'detection,': [208], 'identification,': [210], 'guidelines,': [213], 'incidence': [214], 'response': [215], 'plans,': [216], 'detection.': [219], 'We': [220], 'will': [221], 'discuss': [223], 'legal,': [226], 'In': [232], 'conclusion,': [233], 'open': [237], 'challenges': [238], 'future': [240], 'directions': [241], 'make': [243], 'secure,': [246], 'safe,': [247], 'trustworthy,': [248], 'as': [251], 'community': [253], 'understands': [254], 'impacts.': [257]}",2023,"['Computer science', 'Computer security', 'Information privacy', 'Generative grammar', 'Internet privacy', 'Artificial intelligence']","Undoubtedly, the evolution of Generative AI (GenAI) models has been the highlight of digital transformation in the year 2022. As the different GenAI models like ChatGPT and Google Bard continue to foster their complexity and capability, it&#x2019;s critical to understand its consequences from a cybersecurity perspective. Several instances recently have demonstrated the use of GenAI tools in both the defensive and offensive side of cybersecurity, and focusing on the social, ethical and privacy implications this technology possesses. This research paper highlights the limitations, challenges, potential risks, and opportunities of GenAI in the domain of cybersecurity and privacy. The work presents the vulnerabilities of ChatGPT, which can be exploited by malicious users to exfiltrate malicious information bypassing the ethical constraints on the model. This paper demonstrates successful example attacks like Jailbreaks, reverse psychology, and prompt injection attacks on the ChatGPT. The paper also investigates how cyber offenders can use the GenAI tools in developing cyber attacks, and explore the scenarios where ChatGPT can be used by adversaries to create social engineering attacks, phishing attacks, automated hacking, attack payload generation, malware creation, and polymorphic malware. This paper then examines defense techniques and uses GenAI tools to improve security measures, including cyber defense automation, reporting, threat intelligence, secure code generation and detection, attack identification, developing ethical guidelines, incidence response plans, and malware detection. We will also discuss the social, legal, and ethical implications of ChatGPT. In conclusion, the paper highlights open challenges and future directions to make this GenAI secure, safe, trustworthy, and ethical as the community understands its cybersecurity impacts."
https://openalex.org/W4396833271,"Deepfakes, Phrenology, Surveillance, and More! A Taxonomy of AI Privacy Risks","{'Privacy': [0], 'is': [1, 100], 'a': [2, 25, 106, 129], 'key': [3], 'principle': [4], 'for': [5], 'developing': [6], 'ethical': [7], 'AI': [8, 14, 28, 35, 47, 75, 103], 'technologies,': [9], 'but': [10], 'how': [11, 40], 'does': [12], 'including': [13], 'technologies': [15, 48, 76, 104], 'in': [16, 50], 'products': [17], 'and': [18, 44, 139], 'services': [19], 'change': [20], 'privacy': [21, 29, 36, 55, 72, 111, 133], 'risks?': [22], 'We': [23, 38, 68], 'constructed': [24], 'taxonomy': [26], 'of': [27, 46, 97, 131, 142], 'risks': [30, 73, 82, 90, 112, 134], 'by': [31], 'analyzing': [32], '321': [33], 'documented': [34], 'incidents.': [37], 'codified': [39], 'the': [41, 66, 110, 132, 137], 'unique': [42], 'capabilities': [43, 138], 'requirements': [45, 141], 'described': [49], 'those': [51], 'incidents': [52], 'generated': [53], 'new': [54], 'risks,': [56], 'exacerbated': [57, 87], 'known': [58], 'ones,': [59], 'or': [60, 86], 'otherwise': [61], 'did': [62], 'not': [63], 'meaningfully': [64], 'alter': [65, 109], 'risk.': [67], 'present': [69], '12': [70], 'high-level': [71], 'that': [74, 101], 'either': [77], 'newly': [78], 'created': [79], '(e.g.,': [80, 88, 121], 'exposure': [81], 'from': [83, 91, 136], 'deepfake': [84], 'pornography)': [85], 'surveillance': [89], 'collecting': [92], 'training': [93], 'data).': [94], 'One': [95], 'upshot': [96], 'our': [98], 'work': [99], 'incorporating': [102], 'into': [105], 'product': [107], 'can': [108], 'it': [113], 'entails.': [114], 'Yet,': [115], 'current': [116], 'approaches': [117], 'to': [118], 'privacy-preserving': [119], 'AI/ML': [120], 'federated': [122], 'learning,': [123], 'differential': [124], 'privacy,': [125], 'checklists)': [126], 'only': [127], 'address': [128], 'subset': [130], 'arising': [135], 'data': [140], 'AI.': [143]}",2024,"['Differential privacy', 'Computer science', 'Internet privacy', 'Information privacy', 'Privacy by Design', 'Privacy software', 'Computer security', 'Privacy protection', 'Data science', 'Data mining']","Privacy is a key principle for developing ethical AI technologies, but how does including AI technologies in products and services change privacy risks? We constructed a taxonomy of AI privacy risks by analyzing 321 documented AI privacy incidents. We codified how the unique capabilities and requirements of AI technologies described in those incidents generated new privacy risks, exacerbated known ones, or otherwise did not meaningfully alter the risk. We present 12 high-level privacy risks that AI technologies either newly created (e.g., exposure risks from deepfake pornography) or exacerbated (e.g., surveillance risks from collecting training data). One upshot of our work is that incorporating AI technologies into a product can alter the privacy risks it entails. Yet, current approaches to privacy-preserving AI/ML (e.g., federated learning, differential privacy, checklists) only address a subset of the privacy risks arising from the capabilities and data requirements of AI."
https://openalex.org/W4390829176,"Balancing Privacy and Progress: A Review of Privacy Challenges, Systemic Oversight, and Patient Perceptions in AI-Driven Healthcare","{'Integrating': [0], 'Artificial': [1], 'Intelligence': [2], '(AI)': [3], 'in': [4, 31, 57, 98, 133, 167, 199], 'healthcare': [5, 59, 73, 134, 183], 'represents': [6], 'a': [7, 50], 'transformative': [8], 'shift': [9], 'with': [10, 112, 121, 185], 'substantial': [11], 'potential': [12], 'for': [13, 53, 95, 142, 170], 'enhancing': [14], 'patient': [15, 32, 55, 103, 151, 163, 200], 'care.': [16, 201], 'This': [17], 'paper': [18, 86, 179], 'critically': [19], 'examines': [20], 'this': [21], 'integration,': [22], 'confronting': [23], 'significant': [24], 'ethical,': [25], 'legal,': [26], 'and': [27, 36, 68, 82, 91, 105, 146, 162, 175, 191, 196], 'technological': [28], 'challenges,': [29], 'particularly': [30], 'privacy,': [33], 'decision-making': [34], 'autonomy,': [35], 'data': [37, 158], 'integrity.': [38], 'A': [39], 'structured': [40], 'exploration': [41], 'of': [42, 72, 78, 108, 115, 130, 156], 'these': [43], 'issues': [44], 'focuses': [45], 'on': [46], 'Differential': [47, 80], 'Privacy': [48], 'as': [49], 'critical': [51], 'method': [52], 'preserving': [54], 'confidentiality': [56], 'AI-driven': [58], 'systems.': [60], 'We': [61, 100], 'analyze': [62], 'the': [63, 69, 76, 88, 106, 113, 122, 139, 178], 'balance': [64], 'between': [65], 'privacy': [66], 'preservation': [67], 'practical': [70], 'utility': [71], 'data,': [74], 'emphasizing': [75], 'effectiveness': [77], 'encryption,': [79], 'Privacy,': [81], 'mixed-model': [83], 'approaches.': [84], 'The': [85, 128, 153], 'navigates': [87], 'complex': [89], 'ethical': [90, 186], 'legal': [92], 'frameworks': [93], 'essential': [94], 'AI': [96, 184, 193], 'integration': [97], 'healthcare.': [99], 'comprehensively': [101], 'examine': [102], 'rights': [104], 'nuances': [107], 'informed': [109], 'consent,': [110], 'along': [111], 'challenges': [114], 'harmonizing': [116], 'advanced': [117], 'technologies': [118], 'like': [119], 'blockchain': [120], 'General': [123], 'Data': [124], 'Protection': [125], 'Regulation': [126], '(GDPR).': [127], 'issue': [129], 'algorithmic': [131], 'bias': [132, 144], 'is': [135], 'also': [136], 'explored,': [137], 'underscoring': [138], 'urgent': [140], 'need': [141], 'effective': [143], 'detection': [145], 'mitigation': [147], 'strategies': [148], 'to': [149, 181], 'build': [150], 'trust.': [152], 'evolving': [154], 'roles': [155], 'decentralized': [157], 'sharing,': [159], 'regulatory': [160], 'frameworks,': [161], 'agency': [164], 'are': [165], 'discussed': [166], 'depth.': [168], 'Advocating': [169], 'an': [171], 'interdisciplinary,': [172], 'multi-stakeholder': [173], 'approach': [174], 'responsive': [176], 'governance,': [177], 'aims': [180], 'align': [182], 'principles,': [187], 'prioritize': [188], 'patient-centered': [189], 'outcomes,': [190], 'steer': [192], 'towards': [194], 'responsible': [195], 'equitable': [197], 'enhancements': [198]}",2024,"['Health care', 'Autonomy', 'Confidentiality', 'Transformative learning', 'Information privacy', 'Data sharing', 'Data governance', 'Corporate governance', 'Business', 'Internet privacy', 'Knowledge management', 'Political science', 'Psychology', 'Computer science', 'Medicine', 'Computer security', 'Law', 'Service (business)', 'Data quality', 'Marketing', 'Alternative medicine', 'Pedagogy', 'Pathology', 'Finance']","Integrating Artificial Intelligence (AI) in healthcare represents a transformative shift with substantial potential for enhancing patient care. This paper critically examines this integration, confronting significant ethical, legal, and technological challenges, particularly in patient privacy, decision-making autonomy, and data integrity. A structured exploration of these issues focuses on Differential Privacy as a critical method for preserving patient confidentiality in AI-driven healthcare systems. We analyze the balance between privacy preservation and the practical utility of healthcare data, emphasizing the effectiveness of encryption, Differential Privacy, and mixed-model approaches. The paper navigates the complex ethical and legal frameworks essential for AI integration in healthcare. We comprehensively examine patient rights and the nuances of informed consent, along with the challenges of harmonizing advanced technologies like blockchain with the General Data Protection Regulation (GDPR). The issue of algorithmic bias in healthcare is also explored, underscoring the urgent need for effective bias detection and mitigation strategies to build patient trust. The evolving roles of decentralized data sharing, regulatory frameworks, and patient agency are discussed in depth. Advocating for an interdisciplinary, multi-stakeholder approach and responsive governance, the paper aims to align healthcare AI with ethical principles, prioritize patient-centered outcomes, and steer AI towards responsible and equitable enhancements in patient care."
https://openalex.org/W4403827347,AI Privacy in Context: A Comparative Study of Public and Institutional Discourse on Conversational AI Privacy in the US and Chinese Social Media,"{'The': [0], 'proliferation': [1], 'of': [2, 50, 100, 119, 128, 140], 'conversational': [3, 36], 'artificial': [4], 'intelligence': [5], '(AI)': [6], 'systems,': [7], 'such': [8], 'as': [9], 'chatbots,': [10], 'has': [11], 'sparked': [12], 'widespread': [13], 'privacy': [14, 20, 38, 65, 81, 92, 133, 141], 'concerns.': [15], 'Previous': [16], 'research': [17, 134], 'suggests': [18], 'that': [19], 'perceptions': [21], 'and': [22, 32, 43, 47, 55, 67, 69, 94, 116], 'practices': [23], 'vary': [24], 'across': [25], 'sociocultural': [26], 'contexts.': [27, 144], 'This': [28], 'study': [29, 124], 'examines': [30], 'public': [31, 62, 86], 'institutional': [33, 75, 105], 'discourses': [34], 'on': [35, 53, 84, 91, 96], 'AI': [37], 'in': [39, 131, 142], 'the': [40, 97, 112, 120, 126], 'United': [41], 'States': [42], 'China.': [44], 'Semantic': [45], 'network': [46], 'discourse': [48, 63, 76, 87], 'analyses': [49], 'privacy-related': [51], 'discussions': [52], 'Twitter': [54], 'Weibo': [56], 'reveal': [57], 'divergent': [58], 'patterns.': [59], 'On': [60], 'Twitter,': [61], 'emphasizes': [64], 'risks': [66, 93], 'concerns': [68], 'advocates': [70], 'for': [71], 'systemic': [72], 'changes,': [73], 'while': [74], 'promotes': [77], 'individualistic': [78], 'approaches': [79], 'to': [80, 135], 'protection.': [82], 'Conversely,': [83], 'Weibo,': [85], 'is': [88], 'less': [89], 'focused': [90], 'more': [95], 'positive': [98], 'impacts': [99], 'AI,': [101], 'aligning': [102], 'closely': [103], 'with': [104, 111], 'narratives.': [106], 'These': [107], 'variations': [108], 'are': [109], 'intertwined': [110], 'cultural,': [113], 'political,': [114], 'economic,': [115], 'regulatory': [117], 'contexts': [118], 'two': [121], 'countries.': [122], 'Our': [123], 'underscores': [125], 'importance': [127], 'multi-level': [129], 'analysis': [130], 'comparative': [132], 'provide': [136], 'a': [137], 'holistic': [138], 'view': [139], 'various': [143]}",2024,"['Internet privacy', 'Context (archaeology)', 'Social media', 'Public discourse', 'Information privacy', 'Privacy policy', 'Psychology', 'Sociology', 'Political science', 'Computer science', 'World Wide Web', 'Law', 'History', 'Archaeology', 'Politics']","The proliferation of conversational artificial intelligence (AI) systems, such as chatbots, has sparked widespread privacy concerns. Previous research suggests that privacy perceptions and practices vary across sociocultural contexts. This study examines public and institutional discourses on conversational AI privacy in the United States and China. Semantic network and discourse analyses of privacy-related discussions on Twitter and Weibo reveal divergent patterns. On Twitter, public discourse emphasizes privacy risks and concerns and advocates for systemic changes, while institutional discourse promotes individualistic approaches to privacy protection. Conversely, on Weibo, public discourse is less focused on privacy risks and more on the positive impacts of AI, aligning closely with institutional narratives. These variations are intertwined with the cultural, political, economic, and regulatory contexts of the two countries. Our study underscores the importance of multi-level analysis in comparative privacy research to provide a holistic view of privacy in various contexts."
https://openalex.org/W4392599656,Generative AI in Medical Practice: In-Depth Exploration of Privacy and Security Challenges,"{'As': [0], 'advances': [1], 'in': [2, 22, 43, 75, 130, 175, 202], 'artificial': [3], 'intelligence': [4], '(AI)': [5], 'continue': [6], 'to': [7, 60, 68, 122, 178, 240, 262], 'transform': [8], 'and': [9, 37, 50, 88, 95, 113, 135, 137, 150, 156, 168, 182, 205, 215, 226, 248], 'revolutionize': [10], 'the': [11, 16, 102, 124, 162, 166, 180, 195, 212, 223], 'field': [12], 'of': [13, 19, 72, 101, 105, 118, 127, 164, 185, 190, 197, 228], 'medicine,': [14], 'understanding': [15], 'potential': [17, 213], 'uses': [18], 'generative': [20, 34, 73, 128, 173, 199, 229, 264], 'AI': [21, 74, 129, 174, 200, 230, 244, 265], 'health': [23, 62, 76, 84, 131, 147, 176, 203, 207, 235], 'care': [24, 148, 177, 204, 208], 'becomes': [25], 'increasingly': [26], 'important.': [27], 'Generative': [28], 'AI,': [29], 'including': [30, 78], 'models': [31], 'such': [32, 106], 'as': [33], 'adversarial': [35], 'networks': [36], 'large': [38], 'language': [39], 'models,': [40], 'shows': [41], 'promise': [42], 'transforming': [44], 'medical': [45, 79, 86], 'diagnostics,': [46, 80], 'research,': [47, 87], 'treatment': [48], 'planning,': [49], 'patient': [51], 'care.': [52], 'However,': [53], 'these': [54, 143, 186, 219], 'data-intensive': [55], 'systems': [56, 107, 201], 'pose': [57], 'new': [58], 'threats': [59, 97, 170], 'protected': [61], 'information.': [63], 'This': [64, 159], 'Viewpoint': [65], 'paper': [66, 238], 'aims': [67], 'explore': [69], 'various': [70], 'categories': [71], 'care,': [77, 132, 236], 'drug': [81], 'discovery,': [82], 'virtual': [83], 'assistants,': [85], 'clinical': [89], 'decision': [90], 'support,': [91], 'while': [92], 'identifying': [93], 'security': [94, 138, 155, 167, 246], 'privacy': [96, 136, 157, 169, 250], 'within': [98, 234, 267], 'each': [99], 'phase': [100], 'life': [103], 'cycle': [104], '(ie,': [108], 'data': [109, 249], 'collection,': [110], 'model': [111], 'development,': [112], 'implementation': [114], 'phases).': [115], 'The': [116, 188], 'objectives': [117], 'this': [119, 191, 237, 254], 'study': [120, 160, 192, 255], 'were': [121], 'analyze': [123], 'current': [125], 'state': [126], 'identify': [133], 'opportunities': [134], 'challenges': [139], 'posed': [140], 'by': [141], 'integrating': [142], 'technologies': [144], 'into': [145], 'existing': [146], 'infrastructure,': [149], 'propose': [151], 'strategies': [152], 'for': [153, 259], 'mitigating': [154], 'risks.': [158], 'highlights': [161], 'importance': [163], 'addressing': [165], 'associated': [171, 217], 'with': [172, 218], 'ensure': [179], 'safe': [181], 'effective': [183], 'use': [184, 224], 'systems.': [187, 220], 'findings': [189], 'can': [193], 'inform': [194], 'development': [196], 'future': [198], 'help': [206], 'organizations': [209], 'better': [210], 'understand': [211], 'benefits': [214, 227], 'risks': [216], 'By': [221], 'examining': [222], 'cases': [225], 'across': [231], 'diverse': [232], 'domains': [233], 'contributes': [239], 'theoretical': [241], 'discussions': [242], 'surrounding': [243], 'ethics,': [245], 'vulnerabilities,': [247], 'regulations.': [251], 'In': [252], 'addition,': [253], 'provides': [256], 'practical': [257], 'insights': [258], 'stakeholders': [260], 'looking': [261], 'adopt': [263], 'solutions': [266], 'their': [268], 'organizations.': [269]}",2024,"['Generative grammar', 'Health care', 'Computer science', 'Field (mathematics)', 'Knowledge management', 'Data science', 'Artificial intelligence', 'Political science', 'Law', 'Pure mathematics', 'Mathematics']","As advances in artificial intelligence (AI) continue to transform and revolutionize the field of medicine, understanding the potential uses of generative AI in health care becomes increasingly important. Generative AI, including models such as generative adversarial networks and large language models, shows promise in transforming medical diagnostics, research, treatment planning, and patient care. However, these data-intensive systems pose new threats to protected health information. This Viewpoint paper aims to explore various categories of generative AI in health care, including medical diagnostics, drug discovery, virtual health assistants, medical research, and clinical decision support, while identifying security and privacy threats within each phase of the life cycle of such systems (ie, data collection, model development, and implementation phases). The objectives of this study were to analyze the current state of generative AI in health care, identify opportunities and privacy and security challenges posed by integrating these technologies into existing health care infrastructure, and propose strategies for mitigating security and privacy risks. This study highlights the importance of addressing the security and privacy threats associated with generative AI in health care to ensure the safe and effective use of these systems. The findings of this study can inform the development of future generative AI systems in health care and help health care organizations better understand the potential benefits and risks associated with these systems. By examining the use cases and benefits of generative AI across diverse domains within health care, this paper contributes to theoretical discussions surrounding AI ethics, security vulnerabilities, and data privacy regulations. In addition, this study provides practical insights for stakeholders looking to adopt generative AI solutions within their organizations."
https://openalex.org/W4223947403,"AI Technologies, Privacy, and Security","{'Privacy': [0], 'remains': [1], 'one': [2], 'of': [3, 16, 19, 152, 167, 187], 'the': [4, 17, 28, 51, 88, 135, 150, 165, 185], 'most': [5], 'recurrent': [6], 'concerns': [7, 29, 86, 102], 'that': [8, 76, 90, 128, 137], 'people': [9, 30, 100], 'have': [10, 31, 143], 'about': [11, 32, 87, 103, 157, 175], 'AI': [12, 55, 108, 168, 188], 'technologies.': [13], 'The': [14], 'meaning': [15], 'concept': [18], '“privacy”': [20], 'has': [21], 'proven': [22], 'to': [23, 44, 49, 63, 72, 107, 114, 147, 170], 'be': [24], 'fairly': [25], 'elusive.': [26], 'Accordingly,': [27], 'privacy': [33, 104, 121, 140], 'are': [34, 77, 111, 178, 180], 'often': [35], 'vague': [36], 'and': [37, 48, 80, 149, 179], 'ill-formed,': [38], 'which': [39, 54], 'makes': [40], 'it': [41, 162], 'correspondingly': [42], 'difficult': [43], 'address': [45], 'these': [46, 158], 'concerns,': [47], 'explain': [50], 'ways': [52], 'in': [53, 105, 120, 139], 'technologies': [56, 169], 'do': [57, 59], 'or': [58], 'not': [60, 181], 'pose': [61], 'threats': [62, 89], ""people's"": [64], 'interests.': [65], 'In': [66], 'this': [67], 'article,': [68], 'we': [69, 126], 'draw': [70], 'attention': [71], 'some': [73], 'important': [74], 'distinctions': [75], 'frequently': [78], 'overlooked,': [79], 'spell': [81], 'out': [82], 'their': [83, 145], 'implications': [84], 'for': [85, 94, 164, 173], 'AI-related': [91], 'technology': [92], 'poses': [93], 'privacy.': [95], 'We': [96], 'argue': [97, 127], 'that,': [98], 'when': [99], 'express': [101], 'relation': [106], 'technologies,': [109], 'they': [110], 'usually': [112], 'referring': [113], 'security': [115, 132], 'interests': [116, 119, 133, 138, 177], 'rather': [117], 'than': [118], 'per': [122, 141], 'se': [123, 142], '.': [124], 'Nevertheless,': [125], 'focusing': [129], 'primarily': [130], 'on': [131], 'misses': [134], 'importance': [136], 'through': [144, 184], 'contribution': [146], 'autonomy': [148], 'development': [151], 'our': [153], 'identities.': [154], 'Improving': [155], 'insight': [156], 'issues': [159], 'can': [160], 'make': [161], 'easier': [163], 'developers': [166], 'provide': [171], 'explanations': [172], 'users': [174], 'what': [176], 'at': [182], 'stake': [183], 'use': [186], 'systems.': [189]}",2022,"['Internet privacy', 'Computer security', 'Computer science']","Privacy remains one of the most recurrent concerns that people have about AI technologies. The meaning of the concept of “privacy” has proven to be fairly elusive. Accordingly, the concerns people have about privacy are often vague and ill-formed, which makes it correspondingly difficult to address these concerns, and to explain the ways in which AI technologies do or do not pose threats to people's interests. In this article, we draw attention to some important distinctions that are frequently overlooked, and spell out their implications for concerns about the threats that AI-related technology poses for privacy. We argue that, when people express concerns about privacy in relation to AI technologies, they are usually referring to security interests rather than interests in privacy per se . Nevertheless, we argue that focusing primarily on security interests misses the importance that interests in privacy per se have through their contribution to autonomy and the development of our identities. Improving insight about these issues can make it easier for the developers of AI technologies to provide explanations for users about what interests are and are not at stake through the use of AI systems."
https://openalex.org/W3003326204,"Smart Contract Privacy Protection Using AI in Cyber-Physical Systems: Tools, Techniques and Challenges","{'Applications': [0], 'of': [1, 30, 208], 'Blockchain': [2], '(BC)': [3], 'technology': [4], 'and': [5, 15, 43, 50, 77, 99, 147, 176, 188, 197, 216, 222], 'Cyber-Physical': [6], 'Systems': [7], '(CPS)': [8], 'are': [9, 85, 149, 202], 'increasing': [10], 'exponentially.': [11], 'However,': [12, 83], 'framing': [13], 'resilient': [14], 'correct': [16], 'smart': [17, 22], 'contracts': [18], '(SCs)': [19], 'for': [20, 59, 190, 199], 'these': [21], 'application': [23], 'is': [24, 37, 47, 135, 211], 'a': [25, 109, 125, 169, 205], 'quite': [26], 'challenging': [27], 'task': [28], 'because': [29], 'the': [31, 39, 53, 57, 79, 88, 116, 131, 139, 141, 154, 157, 160], 'complexity': [32], 'associated': [33, 80], 'with': [34], 'them.': [35], 'SC': [36, 112, 145, 191, 201, 217], 'modernizing': [38], 'traditional': [40], 'industrial,': [41], 'technical,': [42], 'business': [44], 'processes.': [45], 'It': [46, 72], 'self-executable,': [48], 'self-verifiable,': [49], 'embedded': [51], 'into': [52], 'BC': [54, 133], 'that': [55, 119, 167], 'eliminates': [56], 'need': [58, 102], 'trusted': [60], 'third-party': [61], 'systems,': [62], 'which': [63, 213], 'ultimately': [64], 'saves': [65], 'administration': [66], 'as': [67, 69], 'well': [68, 86], 'service': [70], 'costs.': [71], 'also': [73], 'improves': [74], 'system': [75], 'efficiency': [76], 'reduces': [78], 'security': [81, 98, 113, 146, 177, 221], 'risks.': [82], 'SCs': [84, 171], 'encouraging': [87], 'new': [89], 'technological': [90], 'reforms': [91], 'in': [92, 115], 'Industry': [93], '4.0,': [94], 'but': [95], 'still,': [96], 'various': [97, 183], 'privacy': [100, 148, 175, 192], 'challenges': [101, 142, 198], 'to': [103, 144, 218], 'be': [104, 121], 'addressed.': [105], 'In': [106], 'this': [107, 180], 'paper,': [108], 'survey': [110], 'on': [111], 'vulnerabilities': [114], 'software': [117], 'code': [118], 'can': [120], 'easily': [122], 'hacked': [123], 'by': [124, 153], 'malicious': [126], 'user': [127], 'or': [128], 'may': [129], 'compromise': [130], 'entire': [132], 'network': [134], 'presented.': [136], 'As': [137], 'per': [138], 'literature,': [140], 'related': [143], 'not': [150], 'explored': [151], 'much': [152], 'authors': [155], 'around': [156], 'world.': [158], 'From': [159], 'existing': [161], 'proposals,': [162], 'it': [163], 'has': [164], 'been': [165], 'observed': [166], 'designing': [168], 'complex': [170], 'cannot': [172], 'mitigate': [173], 'its': [174, 220], 'issues.': [178], 'So,': [179], 'paper': [181], 'investigates': [182], 'Artificial': [184], 'Intelligence': [185], '(AI)': [186], 'techniques': [187], 'tools': [189], 'protection.': [193], 'Then,': [194], 'open': [195], 'issues': [196], 'AI-based': [200], 'analyzed.': [203], 'Finally,': [204], 'case': [206], 'study': [207], 'retail': [209], 'marketing': [210], 'presented,': [212], 'uses': [214], 'AI': [215], 'preserve': [219], 'privacy.': [223]}",2020,"['Computer security', 'Computer science', 'Verifiable secret sharing', 'Compromise', 'Privacy by Design', 'Security service', 'Information privacy', 'Software security assurance', 'Cyber-physical system', 'Information security', 'Programming language', 'Sociology', 'Set (abstract data type)', 'Operating system', 'Social science']","Applications of Blockchain (BC) technology and Cyber-Physical Systems (CPS) are increasing exponentially. However, framing resilient and correct smart contracts (SCs) for these smart application is a quite challenging task because of the complexity associated with them. SC is modernizing the traditional industrial, technical, and business processes. It is self-executable, self-verifiable, and embedded into the BC that eliminates the need for trusted third-party systems, which ultimately saves administration as well as service costs. It also improves system efficiency and reduces the associated security risks. However, SCs are well encouraging the new technological reforms in Industry 4.0, but still, various security and privacy challenges need to be addressed. In this paper, a survey on SC security vulnerabilities in the software code that can be easily hacked by a malicious user or may compromise the entire BC network is presented. As per the literature, the challenges related to SC security and privacy are not explored much by the authors around the world. From the existing proposals, it has been observed that designing a complex SCs cannot mitigate its privacy and security issues. So, this paper investigates various Artificial Intelligence (AI) techniques and tools for SC privacy protection. Then, open issues and challenges for AI-based SC are analyzed. Finally, a case study of retail marketing is presented, which uses AI and SC to preserve its security and privacy."
https://openalex.org/W4393170828,Privacy and Security Concerns in Generative AI: A Comprehensive Survey,"{'Generative': [0], 'Artificial': [1], 'Intelligence': [2], '(GAI)': [3], 'has': [4], 'sparked': [5], 'a': [6, 32, 51], 'transformative': [7], 'wave': [8], 'across': [9], 'various': [10], 'domains,': [11], 'including': [12], 'machine': [13], 'learning,': [14], 'healthcare,': [15], 'business,': [16], 'and': [17, 38, 70, 83, 91], 'entertainment,': [18], 'owing': [19], 'to': [20, 24, 42], 'its': [21], 'remarkable': [22], 'ability': [23], 'generate': [25], 'lifelike': [26], 'data.': [27], 'This': [28], 'comprehensive': [29, 52], 'survey': [30], 'offers': [31], 'meticulous': [33], 'examination': [34], 'of': [35, 54], 'the': [36, 74], 'privacy': [37], 'security': [39, 81], 'challenges': [40], 'inherent': [41], 'GAI.': [43], 'It': [44], 'provides': [45], 'five': [46], 'pivotal': [47], 'perspectives': [48], 'essential': [49], 'for': [50], 'understanding': [53], 'these': [55], 'intricacies.': [56], 'The': [57], 'paper': [58], 'encompasses': [59], 'discussions': [60], 'on': [61], 'GAI': [62], 'architectures,': [63], 'diverse': [64], 'generative': [65], 'model': [66], 'types,': [67], 'practical': [68], 'applications,': [69], 'recent': [71], 'advancements': [72], 'within': [73], 'field.': [75], 'In': [76], 'addition,': [77], 'it': [78], 'highlights': [79], 'current': [80], 'strategies': [82], 'proposes': [84], 'sustainable': [85], 'solutions,': [86], 'emphasizing': [87], 'user,': [88], 'developer,': [89], 'institutional,': [90], 'policymaker': [92], 'involvement.': [93]}",2024,"['Computer science', 'Computer security', 'Internet privacy', 'Information privacy', 'Data science']","Generative Artificial Intelligence (GAI) has sparked a transformative wave across various domains, including machine learning, healthcare, business, and entertainment, owing to its remarkable ability to generate lifelike data. This comprehensive survey offers a meticulous examination of the privacy and security challenges inherent to GAI. It provides five pivotal perspectives essential for a comprehensive understanding of these intricacies. The paper encompasses discussions on GAI architectures, diverse generative model types, practical applications, and recent advancements within the field. In addition, it highlights current security strategies and proposes sustainable solutions, emphasizing user, developer, institutional, and policymaker involvement."
https://openalex.org/W3013109186,"Emotional AI, soft biometrics and the surveillance of emotional life: An unusual consensus on privacy","{'By': [0], 'the': [1, 47, 76, 86, 107, 111, 117, 164, 198], 'early': [2], '2020s,': [3], 'emotional': [4, 48, 90, 105], 'artificial': [5], 'intelligence': [6], '(emotional': [7], 'AI)': [8], 'will': [9], 'become': [10], 'increasingly': [11], 'present': [12], 'in': [13, 39, 128], 'everyday': [14], 'objects': [15], 'and': [16, 31, 45, 62, 125, 173, 197], 'practices': [17, 92], 'such': [18, 52], 'as': [19, 53], 'assistants,': [20], 'cars,': [21], 'games,': [22], 'mobile': [23], 'phones,': [24], 'wearables,': [25], 'toys,': [26], 'marketing,': [27], 'insurance,': [28], 'policing,': [29], 'education': [30], 'border': [32], 'controls.': [33], 'There': [34], 'is': [35], 'also': [36], 'keen': [37], 'interest': [38], 'using': [40, 139], 'these': [41], 'technologies': [42], 'to': [43, 134, 189], 'regulate': [44], 'optimize': [46], 'experiences': [49], 'of': [50, 89, 146, 187, 193, 200], 'spaces,': [51], 'workplaces,': [54], 'hospitals,': [55], 'prisons,': [56], 'classrooms,': [57], 'travel': [58], 'infrastructures,': [59], 'restaurants,': [60], 'retail': [61], 'chain': [63], 'stores.': [64], 'Developers': [65], 'frequently': [66], 'claim': [67, 77], 'that': [68, 93, 181], 'their': [69], 'applications': [70], 'do': [71, 94], 'not': [72, 95], 'identify': [73, 96], 'people.': [74], 'Taking': [75], 'at': [78], 'face': [79], 'value,': [80], 'this': [81, 168, 176], 'paper': [82, 108], 'asks,': [83], 'what': [84], 'are': [85], 'privacy': [87, 100, 196], 'implications': [88], 'AI': [91], 'individuals?': [97], 'To': [98], 'investigate': [99], 'perspectives': [101], 'on': [102, 149, 163], 'soft': [103], 'non-identifying': [104], 'AI,': [106], 'draws': [109], 'upon': [110], 'following:': [112], 'over': [113], '100': [114], 'interviews': [115], 'with': [116, 132], 'emotion': [118, 152], 'detection': [119], 'industry,': [120], 'legal': [121], 'community,': [122], 'policy-makers,': [123], 'regulators': [124], 'NGOs': [126], 'interested': [127], 'privacy;': [129], 'a': [130, 143, 157, 184], 'workshop': [131], 'stakeholders': [133, 162], 'design': [135], 'ethical': [136], 'codes': [137], 'for': [138, 166], 'data': [140, 201], 'about': [141, 151, 202], 'emotions;': [142], 'UK': [144], 'survey': [145], '2068': [147], 'citizens': [148], 'feelings': [150], 'capture': [153], 'technologies.': [154], 'It': [155], 'finds': [156], 'weak': [158, 177], 'consensus': [159], 'among': [160], 'social': [161], 'need': [165], 'privacy,': [167], 'driven': [169], 'by': [170], 'different': [171], 'interests': [172], 'motivations.': [174], 'Given': [175], 'consensus,': [178], 'it': [179], 'concludes': [180], 'there': [182], 'exists': [183], 'limited': [185], 'window': [186], 'opportunity': [188], 'societally': [190], 'agree': [191], 'principles': [192], 'practice': [194], 'regarding': [195], 'use': [199], 'emotions.': [203]}",2020,"['Feeling', 'Internet privacy', 'Public relations', 'Face (sociological concept)', 'Emotional intelligence', 'Sociology', 'Psychology', 'Social psychology', 'Political science', 'Computer science', 'Social science']","By the early 2020s, emotional artificial intelligence (emotional AI) will become increasingly present in everyday objects and practices such as assistants, cars, games, mobile phones, wearables, toys, marketing, insurance, policing, education and border controls. There is also keen interest in using these technologies to regulate and optimize the emotional experiences of spaces, such as workplaces, hospitals, prisons, classrooms, travel infrastructures, restaurants, retail and chain stores. Developers frequently claim that their applications do not identify people. Taking the claim at face value, this paper asks, what are the privacy implications of emotional AI practices that do not identify individuals? To investigate privacy perspectives on soft non-identifying emotional AI, the paper draws upon the following: over 100 interviews with the emotion detection industry, legal community, policy-makers, regulators and NGOs interested in privacy; a workshop with stakeholders to design ethical codes for using data about emotions; a UK survey of 2068 citizens on feelings about emotion capture technologies. It finds a weak consensus among social stakeholders on the need for privacy, this driven by different interests and motivations. Given this weak consensus, it concludes that there exists a limited window of opportunity to societally agree principles of practice regarding privacy and the use of data about emotions."
https://openalex.org/W4323926479,AI privacy toolkit,"{'The': [0, 64], 'need': [1], 'to': [2, 6, 12, 56, 69], 'analyse': [3], 'personal': [4, 42, 58], 'data': [5, 17], 'drive': [7], 'business': [8], 'alongside': [9], 'the': [10, 14, 37, 90], 'requirement': [11], 'preserve': [13], 'privacy': [15, 86], 'of': [16, 41, 92], 'subjects': [18], 'creates': [19], 'a': [20], 'known': [21], 'tension.': [22], 'Data': [23], 'protection': [24], 'regulations': [25], 'such': [26], 'as': [27], 'GDPR': [28], 'and': [29, 34, 39, 76, 87], 'CCPA': [30], 'define': [31], 'strict': [32], 'restrictions': [33], 'obligations': [35], 'on': [36], 'collection': [38], 'processing': [40], 'data.': [43], 'These': [44], 'are': [45], 'also': [46], 'relevant': [47], 'for': [48], 'machine': [49], 'learning': [50], 'models,': [51], 'which': [52], 'can': [53], 'be': [54], 'used': [55], 'derive': [57], 'information': [59], 'about': [60], 'their': [61], 'training': [62], 'sets.': [63], 'open-source': [65], 'ai-privacy-toolkit': [66], 'is': [67], 'designed': [68], 'help': [70, 88], 'organizations': [71], 'navigate': [72], 'this': [73], 'challenging': [74], 'area': [75], 'build': [77], 'more': [78], 'trustworthy': [79], 'AI': [80, 93], 'solutions,': [81], 'with': [82], 'tools': [83], 'that': [84], 'protect': [85], 'ensure': [89], 'compliance': [91], 'models.': [94]}",2023,"['Computer science', 'World Wide Web', 'Computer security']","The need to analyse personal data to drive business alongside the requirement to preserve the privacy of data subjects creates a known tension. Data protection regulations such as GDPR and CCPA define strict restrictions and obligations on the collection and processing of personal data. These are also relevant for machine learning models, which can be used to derive personal information about their training sets. The open-source ai-privacy-toolkit is designed to help organizations navigate this challenging area and build more trustworthy AI solutions, with tools that protect privacy and help ensure the compliance of AI models."
https://openalex.org/W4407243994,"AI Ethics: Integrating Transparency, Fairness, and Privacy in AI Development","{'The': [0, 102, 179], 'expansion': [1], 'of': [2, 34, 56, 92, 140, 166, 184], 'Artificial': [3], 'Intelligence': [4], 'in': [5, 50, 107, 118, 187], 'sectors': [6], 'such': [7, 76], 'as': [8, 77], 'healthcare,': [9], 'finance,': [10], 'and': [11, 21, 32, 47, 69, 80, 89, 114, 137, 174], 'communication': [12], 'has': [13], 'raised': [14], 'critical': [15], 'ethical': [16, 42, 94, 122, 146, 156, 189], 'concerns': [17], 'surrounding': [18], 'transparency,': [19, 112], 'fairness,': [20, 113], 'privacy.': [22], 'Addressing': [23], 'these': [24, 126], 'issues': [25], 'is': [26, 71], 'essential': [27], 'for': [28, 86, 154, 163], 'the': [29, 64, 93, 138, 159, 164, 182], 'responsible': [30], 'development': [31, 98, 142], 'deployment': [33], 'AI': [35, 51, 58, 97, 147, 160, 167, 190], 'systems.': [36], 'This': [37, 149], 'research': [38], 'establishes': [39], 'a': [40, 87, 120], 'comprehensive': [41], 'framework': [43], 'that': [44, 169], 'mitigates': [45], 'biases': [46], 'promotes': [48], 'accountability': [49], 'technologies.': [52], 'A': [53], 'comparative': [54], 'analysis': [55], 'international': [57], 'policy': [59], 'frameworks': [60], 'from': [61], 'regions': [62, 110], 'including': [63, 132], 'European': [65], 'Union,': [66], 'United': [67], 'States,': [68], 'China': [70], 'conducted': [72], 'using': [73], 'analytical': [74], 'tools': [75, 84], 'Venn': [78], 'diagrams': [79], 'Cartesian': [81], 'graphs.': [82], 'These': [83], 'allow': [85], 'visual': [88], 'systematic': [90], 'evaluation': [91], 'principles': [95], 'guiding': [96], 'across': [99], 'different': [100], 'jurisdictions.': [101], 'results': [103], 'reveal': [104], 'significant': [105], 'variations': [106], 'how': [108], 'global': [109, 185], 'prioritize': [111], 'privacy,': [115], 'with': [116, 176], 'challenges': [117], 'creating': [119], 'unified': [121], 'standard.': [123], 'To': [124], 'address': [125], 'challenges,': [127], 'we': [128], 'propose': [129], 'technical': [130], 'strategies,': [131], 'fairness-aware': [133], 'algorithms,': [134], 'routine': [135], 'audits,': [136], 'establishment': [139], 'diverse': [141], 'teams': [143], 'to': [144], 'ensure': [145], 'practices.': [148], 'paper': [150], 'provides': [151], 'actionable': [152], 'recommendations': [153], 'integrating': [155], 'oversight': [157], 'into': [158], 'lifecycle,': [161], 'advocating': [162], 'creation': [165], 'systems': [168], 'are': [170], 'both': [171], 'technically': [172], 'sophisticated': [173], 'aligned': [175], 'societal': [177], 'values.': [178], 'findings': [180], 'underscore': [181], 'necessity': [183], 'collaboration': [186], 'fostering': [188], 'development.': [191]}",2025,"['Computer science', 'Transparency (behavior)', 'Development (topology)', 'Knowledge management', 'Data science', 'Computer security', 'Mathematics', 'Mathematical analysis']","The expansion of Artificial Intelligence in sectors such as healthcare, finance, and communication has raised critical ethical concerns surrounding transparency, fairness, and privacy. Addressing these issues is essential for the responsible development and deployment of AI systems. This research establishes a comprehensive ethical framework that mitigates biases and promotes accountability in AI technologies. A comparative analysis of international AI policy frameworks from regions including the European Union, United States, and China is conducted using analytical tools such as Venn diagrams and Cartesian graphs. These tools allow for a visual and systematic evaluation of the ethical principles guiding AI development across different jurisdictions. The results reveal significant variations in how global regions prioritize transparency, fairness, and privacy, with challenges in creating a unified ethical standard. To address these challenges, we propose technical strategies, including fairness-aware algorithms, routine audits, and the establishment of diverse development teams to ensure ethical AI practices. This paper provides actionable recommendations for integrating ethical oversight into the AI lifecycle, advocating for the creation of AI systems that are both technically sophisticated and aligned with societal values. The findings underscore the necessity of global collaboration in fostering ethical AI development."
https://openalex.org/W4383911728,"Building Trust in Fintech: An Analysis of Ethical and Privacy Considerations in the Intersection of Big Data, AI, and Customer Trust","{'This': [0], 'research': [1, 123], 'paper': [2], 'explores': [3], 'the': [4, 26, 48, 72, 83, 90, 98, 109, 116, 136], 'ethical': [5, 29], 'considerations': [6], 'in': [7], 'using': [8], 'financial': [9], 'technology': [10], '(fintech),': [11], 'focusing': [12], 'on': [13, 94], 'big': [14], 'data,': [15, 53], 'artificial': [16], 'intelligence': [17], '(AI),': [18], 'and': [19, 30, 43, 59, 81, 89, 108, 128], 'privacy.': [20], 'Using': [21], 'a': [22], 'systematic': [23], 'literature-review': [24], 'methodology,': [25], 'study': [27, 65, 99], 'identifies': [28], 'privacy': [31], 'issues': [32, 138], 'related': [33], 'to': [34, 114, 133], 'fintech,': [35], 'including': [36, 71], 'bias,': [37], 'discrimination,': [38], 'privacy,': [39], 'transparency,': [40], 'justice,': [41], 'ownership,': [42], 'control.': [44], 'The': [45, 64], 'findings': [46], 'emphasize': [47], 'importance': [49], 'of': [50, 74, 85, 92, 105], 'safeguarding': [51], 'customer': [52, 86], 'complying': [54], 'with': [55], 'data': [56, 79, 132], 'protection': [57], 'laws,': [58], 'promoting': [60], 'corporate': [61], 'digital': [62], 'responsibility.': [63], 'provides': [66], 'practical': [67], 'suggestions': [68], 'for': [69, 111], 'companies,': [70], 'use': [73], 'encryption': [75], 'techniques,': [76], 'transparency': [77], 'regarding': [78], 'collection': [80], 'usage,': [82], 'provision': [84], 'opt-out': [87], 'options,': [88], 'training': [91], 'staff': [93], 'data-protection': [95], 'policies.': [96], 'However,': [97], 'is': [100], 'limited': [101], 'by': [102], 'its': [103], 'exclusion': [104], 'non-English-language': [106], 'studies': [107], 'need': [110], 'additional': [112], 'resources': [113], 'deepen': [115], 'findings.': [117], 'To': [118], 'overcome': [119], 'these': [120], 'limitations,': [121], 'future': [122], 'could': [124], 'expand': [125], 'existing': [126], 'knowledge': [127], 'collect': [129], 'more': [130], 'comprehensive': [131], 'better': [134], 'understand': [135], 'complex': [137], 'examined.': [139]}",2023,"['Transparency (behavior)', 'Safeguarding', 'Big data', 'Data Protection Act 1998', 'Business', 'Data governance', 'Data collection', 'Information privacy', 'Internet privacy', 'Profiling (computer programming)', 'Privacy by Design', 'Privacy policy', 'Marketing', 'Computer science', 'Computer security', 'Data quality', 'Sociology', 'Operating system', 'Metric (unit)', 'Social science', 'Nursing', 'Medicine']","This research paper explores the ethical considerations in using financial technology (fintech), focusing on big data, artificial intelligence (AI), and privacy. Using a systematic literature-review methodology, the study identifies ethical and privacy issues related to fintech, including bias, discrimination, privacy, transparency, justice, ownership, and control. The findings emphasize the importance of safeguarding customer data, complying with data protection laws, and promoting corporate digital responsibility. The study provides practical suggestions for companies, including the use of encryption techniques, transparency regarding data collection and usage, the provision of customer opt-out options, and the training of staff on data-protection policies. However, the study is limited by its exclusion of non-English-language studies and the need for additional resources to deepen the findings. To overcome these limitations, future research could expand existing knowledge and collect more comprehensive data to better understand the complex issues examined."
https://openalex.org/W4366547469,"Emotion AI at Work: Implications for Workplace Surveillance, Emotional Labor, and Emotional Privacy","{'Workplaces': [0], 'are': [1], 'increasingly': [2], 'adopting': [3], 'emotion': [4, 23, 44, 60, 104], 'AI,': [5], 'promising': [6], 'benefits': [7], 'to': [8, 22, 64, 83, 94, 113, 120, 138], 'organizations.': [9], 'However,': [10], 'little': [11], 'is': [12], 'known': [13], 'about': [14], 'the': [15, 26, 52, 107, 111, 147], 'perceptions': [16], 'and': [17, 72, 115, 133, 140, 145], 'experiences': [18], 'of': [19, 54, 98, 103], 'workers': [20, 35, 74, 90], 'subject': [21], 'AI': [24, 45, 61, 105], 'in': [25, 77, 106], 'workplace.': [27, 108, 148], 'Our': [28], 'interview': [29], 'study': [30], 'with': [31, 68], '(n=15)': [32], 'US': [33], 'adult': [34], 'addresses': [36], 'this': [37], 'gap,': [38], 'finding': [39], 'that': [40, 73], '(1)': [41], 'participants': [42], 'viewed': [43], 'as': [46, 80, 100, 124, 127, 129], 'a': [47, 81, 95, 101], 'deep': [48], 'privacy': [49, 53, 85, 143], 'violation': [50], 'over': [51, 86], ""workers'"": [55, 66], 'sensitive': [56], 'emotional': [57, 69, 78, 125, 142], 'information;': [58], '(2)': [59], 'may': [62, 75, 91], 'function': [63], 'enforce': [65], 'compliance': [67], 'labor': [70, 79], 'expectations,': [71], 'engage': [76], 'mechanism': [82], 'preserve': [84, 141], 'their': [87], 'emotions;': [88], '(3)': [89], 'be': [92], 'exposed': [93], 'wide': [96], 'range': [97], 'harms': [99], 'consequence': [102], 'Findings': [109], 'reveal': [110], 'need': [112], 'recognize': [114], 'define': [116], 'an': [117], 'individual': [118], 'right': [119], 'what': [121], 'we': [122], 'introduce': [123], 'privacy,': [126], 'well': [128], 'raise': [130], 'important': [131], 'research': [132], 'policy': [134], 'questions': [135], 'on': [136], 'how': [137], 'protect': [139], 'within': [144], 'beyond': [146]}",2023,"['Emotional labor', 'Work (physics)', 'Psychology', 'Emotion work', 'Applied psychology', 'Social psychology', 'Computer science', 'Engineering', 'Mechanical engineering']","Workplaces are increasingly adopting emotion AI, promising benefits to organizations. However, little is known about the perceptions and experiences of workers subject to emotion AI in the workplace. Our interview study with (n=15) US adult workers addresses this gap, finding that (1) participants viewed emotion AI as a deep privacy violation over the privacy of workers' sensitive emotional information; (2) emotion AI may function to enforce workers' compliance with emotional labor expectations, and that workers may engage in emotional labor as a mechanism to preserve privacy over their emotions; (3) workers may be exposed to a wide range of harms as a consequence of emotion AI in the workplace. Findings reveal the need to recognize and define an individual right to what we introduce as emotional privacy, as well as raise important research and policy questions on how to protect and preserve emotional privacy within and beyond the workplace."
https://openalex.org/W4285740054,You Can’t Have AI Both Ways: Balancing Health Data Privacy and Access Fairly,"{'Artificial': [0], 'intelligence': [1], '(AI)': [2], 'in': [3, 77, 96, 104, 198], 'healthcare': [4, 8, 108, 199], 'promises': [5], 'to': [6, 30, 46, 116, 142, 145, 150, 154, 165], 'make': [7, 151], 'safer,': [9], 'more': [10, 13], 'accurate,': [11], 'and': [12, 16, 42, 64, 80, 99, 102, 125, 128, 134, 222, 228], 'cost-effective.': [14], 'Public': [15], 'private': [17], 'actors': [18], 'have': [19, 44], 'been': [20, 50], 'investing': [21], 'significant': [22, 167], 'amounts': [23, 168], 'of': [24, 107, 122, 169, 192], 'resources': [25, 144], 'into': [26, 172], 'the': [27, 54, 91, 97, 105, 112, 120, 129, 177, 214], 'field.': [28], 'However,': [29], 'benefit': [31], 'from': [32, 36], 'data-intensive': [33, 62, 117], 'medicine,': [34, 63, 118], 'particularly': [35, 119], 'AI': [37, 133, 173, 226], 'technologies,': [38], 'one': [39], 'must': [40], 'first': [41], 'foremost': [43], 'access': [45, 182], 'data.': [47], 'It': [48], 'has': [49], 'previously': [51], 'argued': [52], 'that': [53, 161], 'conventionally': [55], 'used': [56], '“consent': [57], 'or': [58], 'anonymize': [59], 'approach”': [60], 'undermines': [61], 'worse,': [65], 'may': [66], 'ultimately': [67], 'harm': [68], 'patients.': [69], 'Yet,': [70], 'this': [71, 87, 188], 'is': [72, 163], 'still': [73], 'a': [74, 190, 207], 'dominant': [75], 'approach': [76], 'European': [78], 'countries': [79, 140], 'framed': [81], 'as': [82, 187], 'an': [83], 'either-or': [84], 'choice.': [85], 'In': [86], 'paper,': [88], 'we': [89], 'contrast': [90], 'different': [92], 'data': [93, 123, 126, 157, 181, 219], 'governance': [94, 220], 'approaches': [95], 'EU': [98], 'their': [100, 223], 'advantages': [101], 'disadvantages': [103], 'context': [106], 'AI.': [109], 'We': [110, 159], 'detail': [111], 'ethical': [113], 'trade-offs': [114], 'inherent': [115], 'balancing': [121], 'privacy': [124, 185], 'access,': [127], 'subsequent': [130], 'prioritization': [131], 'between': [132], 'other': [135], 'effective': [136], 'health': [137], 'interventions.': [138], 'If': [139], 'wish': [141], 'allocate': [143], 'AI,': [146], 'they': [147], 'also': [148], 'need': [149], 'corresponding': [152], 'efforts': [153], 'improve': [155], '(secure)': [156], 'access.': [158], 'conclude': [160], 'it': [162], 'unethical': [164], 'invest': [166], 'public': [170, 193], 'funds': [171], 'development': [174], 'whilst': [175], 'at': [176], 'same': [178], 'time': [179], 'limiting': [180], 'through': [183], 'strict': [184], 'measures,': [186], 'constitutes': [189], 'waste': [191], 'resources.': [194], 'The': [195], '“AI': [196], 'revolution”': [197], 'can': [200], 'only': [201], 'realise': [202], 'its': [203], 'full': [204], 'potential': [205], 'if': [206], 'fair,': [208], 'inclusive': [209], 'engagement': [210], 'process': [211], 'spells': [212], 'out': [213], 'values': [215], 'underlying': [216], '(trans)': [217], 'national': [218], 'policies': [221], 'impact': [224], 'on': [225], 'development,': [227], 'priorities': [229], 'are': [230], 'set': [231], 'accordingly.': [232]}",2022,"['Context (archaeology)', 'Data governance', 'Harm', 'Health care', 'Internet privacy', 'Data Protection Act 1998', 'Corporate governance', 'Data access', 'Information privacy', 'General Data Protection Regulation', 'Big data', 'SAFER', 'Computer science', 'Business', 'Computer security', 'Public relations', 'Data quality', 'Political science', 'Law', 'Marketing', 'Data mining', 'Finance', 'Paleontology', 'Metric (unit)', 'Programming language', 'Biology']","Artificial intelligence (AI) in healthcare promises to make healthcare safer, more accurate, and more cost-effective. Public and private actors have been investing significant amounts of resources into the field. However, to benefit from data-intensive medicine, particularly from AI technologies, one must first and foremost have access to data. It has been previously argued that the conventionally used “consent or anonymize approach” undermines data-intensive medicine, and worse, may ultimately harm patients. Yet, this is still a dominant approach in European countries and framed as an either-or choice. In this paper, we contrast the different data governance approaches in the EU and their advantages and disadvantages in the context of healthcare AI. We detail the ethical trade-offs inherent to data-intensive medicine, particularly the balancing of data privacy and data access, and the subsequent prioritization between AI and other effective health interventions. If countries wish to allocate resources to AI, they also need to make corresponding efforts to improve (secure) data access. We conclude that it is unethical to invest significant amounts of public funds into AI development whilst at the same time limiting data access through strict privacy measures, as this constitutes a waste of public resources. The “AI revolution” in healthcare can only realise its full potential if a fair, inclusive engagement process spells out the values underlying (trans) national data governance policies and their impact on AI development, and priorities are set accordingly."
https://openalex.org/W3211102095,AI-enabled Automation for Completeness Checking of Privacy Policies,"{'Technological': [0], 'advances': [1], 'in': [2, 84, 175, 252, 257, 261], 'information': [3, 173], 'sharing': [4], 'have': [5], 'raised': [6], 'concerns': [7], 'about': [8, 16], 'data': [9, 20], 'protection.': [10], 'Privacy': [11], 'policies': [12, 43, 81, 177, 195], 'contain': [13], 'privacy-related': [14, 94, 131], 'requirements': [15], 'how': [17], 'the': [18, 49, 65, 75, 113, 130, 171, 183, 197, 213], 'personal': [19], 'of': [21, 67, 77, 116, 133, 142, 153, 160, 203, 212, 215, 218, 234, 238, 255], 'individuals': [22], 'will': [23], 'be': [24], 'handled': [25], 'by': [26, 156], 'an': [27, 38, 148, 253], 'organization': [28, 89], 'or': [29, 37], 'a': [30, 34, 68, 136, 140, 158, 201, 232, 242], 'software': [31, 95], 'system': [32], '(e.g.,': [33], 'web': [35], 'service': [36], 'app).': [39], 'In': [40, 105], 'Europe,': [41], 'privacy': [42, 69, 80, 117, 176, 194, 206], 'are': [44], 'subject': [45], 'to': [46, 62, 74, 128, 241], 'compliance': [47, 59], 'with': [48], 'General': [50], 'Data': [51], 'Protection': [52], 'Regulation': [53], '(GDPR).': [54], 'A': [55], 'prerequisite': [56], 'for': [57, 112], 'GDPR': [58], 'checking': [60, 99, 115], 'is': [61, 71, 100], 'verify': [63], 'whether': [64], 'content': [66, 174], 'policy': [70], 'complete': [72], 'according': [73], 'provisions': [76, 132], 'GDPR.': [78], 'Incomplete': [79], 'might': [82], 'result': [83], 'large': [85], 'fines': [86], 'on': [87, 151], 'violating': [88], 'as': [90, 92], 'well': [91], 'incomplete': [93], 'specifications.': [96], 'Manual': [97], 'completeness': [98, 114, 143, 184, 220], 'both': [101], 'time-consuming': [102], 'and': [103, 139, 164, 178, 236, 259], 'error-prone.': [104], 'this': [106], 'paper,': [107], 'we': [108, 123, 146, 169, 190], 'propose': [109], 'AI-based': [110], 'automation': [111], 'policies.': [118], 'Through': [119], 'systematic': [120], 'qualitative': [121], 'methods,': [122], 'first': [124], 'build': [125], 'two': [126], 'artifacts': [127, 155], 'characterize': [129], 'GDPR,': [134], 'namely': [135], 'conceptual': [137], 'model': [138], 'set': [141, 202], 'criteria.': [144, 185], 'Then,': [145], 'develop': [147], 'automated': [149], 'solution': [150], 'top': [152], 'these': [154], 'leveraging': [157], 'combination': [159], 'natural': [161], 'language': [162], 'processing': [163], 'supervised': [165], 'machine': [166], 'learning.': [167], 'Specifically,': [168], 'identify': [170], 'GDPR-relevant': [172], 'subsequently': [179], 'check': [180], 'them': [181], 'against': [182], 'To': [186], 'evaluate': [187], 'our': [188, 208, 249], 'approach,': [189], 'collected': [191], '234': [192], 'real': [193], 'from': [196], 'fund': [198], 'industry.': [199], 'Over': [200], '48': [204], 'unseen': [205], 'policies,': [207], 'approach': [209, 229, 250], 'detected': [210], '300': [211], 'total': [214], '334': [216], 'violations': [217], 'some': [219], 'criteria': [221], 'correctly,': [222], 'while': [223], 'producing': [224], '23': [225], 'false': [226], 'positives.': [227], 'The': [228], 'thus': [230], 'has': [231], 'precision': [233, 258], '92.9%': [235], 'recall': [237], '89.8%.': [239], 'Compared': [240], 'baseline': [243], 'that': [244], 'applies': [245], 'keyword': [246], 'search': [247], 'only,': [248], 'results': [251], 'improvement': [254], '24.5%': [256], '38%': [260], 'recall.': [262]}",2021,"['Computer science', 'Privacy policy', 'Completeness (order theory)', 'General Data Protection Regulation', 'Information privacy', 'Privacy software', 'Privacy by Design', 'Computer security', 'Privacy law', 'Data Protection Act 1998', 'Mathematical analysis', 'Mathematics']","Technological advances in information sharing have raised concerns about data protection. Privacy policies contain privacy-related requirements about how the personal data of individuals will be handled by an organization or a software system (e.g., a web service or an app). In Europe, privacy policies are subject to compliance with the General Data Protection Regulation (GDPR). A prerequisite for GDPR compliance checking is to verify whether the content of a privacy policy is complete according to the provisions of GDPR. Incomplete privacy policies might result in large fines on violating organization as well as incomplete privacy-related software specifications. Manual completeness checking is both time-consuming and error-prone. In this paper, we propose AI-based automation for the completeness checking of privacy policies. Through systematic qualitative methods, we first build two artifacts to characterize the privacy-related provisions of GDPR, namely a conceptual model and a set of completeness criteria. Then, we develop an automated solution on top of these artifacts by leveraging a combination of natural language processing and supervised machine learning. Specifically, we identify the GDPR-relevant information content in privacy policies and subsequently check them against the completeness criteria. To evaluate our approach, we collected 234 real privacy policies from the fund industry. Over a set of 48 unseen privacy policies, our approach detected 300 of the total of 334 violations of some completeness criteria correctly, while producing 23 false positives. The approach thus has a precision of 92.9% and recall of 89.8%. Compared to a baseline that applies keyword search only, our approach results in an improvement of 24.5% in precision and 38% in recall."
https://openalex.org/W4383895105,Privacy and Data Protection in ChatGPT and Other AI Chatbots,"{'The': [0, 92], 'evolution': [1], 'of': [2, 15, 36, 45, 59, 68, 98, 112], 'artificial': [3, 139], 'intelligence': [4], '(AI)': [5], 'and': [6, 39, 78, 88, 129], 'machine': [7, 69], 'learning': [8, 70], '(ML)': [9], 'has': [10], 'led': [11], 'to': [12, 101, 106, 120, 132], 'the': [13, 33, 43, 56, 66, 110, 133], 'development': [14], 'sophisticated': [16], 'large': [17], 'language': [18], 'models': [19], '(LLMs)': [20], 'that': [21], 'are': [22], 'used': [23], 'extensively': [24], 'in': [25, 42, 138], 'applications': [26], 'such': [27, 82], 'as': [28, 83, 122], 'chatbots.': [29], 'This': [30, 116], 'research': [31], 'investigates': [32], 'critical': [34], 'issues': [35], 'data': [37, 89, 107, 136], 'protection': [38, 137], 'privacy': [40, 108], 'enhancement': [41], 'context': [44], 'LLM-based': [46, 114], 'chatbots,': [47], 'with': [48, 109], 'a': [49, 96, 123], 'focus': [50], 'on': [51, 135], ""OpenAI's"": [52], 'ChatGPT.': [53], 'It': [54, 72], 'explores': [55], 'dual': [57], 'challenges': [58], 'safeguarding': [60], 'sensitive': [61], 'user': [62], 'information': [63], 'while': [64], 'ensuring': [65], 'efficiency': [67], 'models.': [71], 'assesses': [73], 'existing': [74], 'privacy-enhancing': [75], 'technologies': [76], '(PETs)': [77], 'proposes': [79], 'innovative': [80], 'methods,': [81], 'differential': [84], 'privacy,': [85], 'federated': [86], 'learning,': [87], 'minimization': [90], 'techniques.': [91], 'study': [93, 117], 'also': [94], 'includes': [95], 'survey': [97], 'Chatbot': [99], 'users': [100], 'measure': [102], 'their': [103], 'concerns': [104], 'related': [105], 'use': [111], 'these': [113], 'applications.': [115], 'is': [118], 'meant': [119], 'serve': [121], 'comprehensive': [124], 'guide': [125], 'for': [126], 'developers,': [127], 'policymakers,': [128], 'researchers,': [130], 'contributing': [131], 'discourse': [134], 'intelligence.': [140]}",2023,"['Safeguarding', 'Chatbot', 'Computer science', 'Context (archaeology)', 'Information privacy', 'Data Protection Act 1998', 'Internet privacy', 'Data science', 'Privacy by Design', 'Differential privacy', 'Computer security', 'Artificial intelligence', 'Data mining', 'Nursing', 'Paleontology', 'Biology', 'Medicine']","The evolution of artificial intelligence (AI) and machine learning (ML) has led to the development of sophisticated large language models (LLMs) that are used extensively in applications such as chatbots. This research investigates the critical issues of data protection and privacy enhancement in the context of LLM-based chatbots, with a focus on OpenAI's ChatGPT. It explores the dual challenges of safeguarding sensitive user information while ensuring the efficiency of machine learning models. It assesses existing privacy-enhancing technologies (PETs) and proposes innovative methods, such as differential privacy, federated learning, and data minimization techniques. The study also includes a survey of Chatbot users to measure their concerns related to data privacy with the use of these LLM-based applications. This study is meant to serve as a comprehensive guide for developers, policymakers, and researchers, contributing to the discourse on data protection in artificial intelligence."
https://openalex.org/W4387461693,"Artificial Intelligence (AI) Trust Framework and Maturity Model: Applying an Entropy Lens to Improve Security, Privacy, and Ethical AI","{'Recent': [0], 'advancements': [1], 'in': [2, 38, 59, 68, 91, 99, 110, 118, 135, 144, 153, 162, 178], 'artificial': [3], 'intelligence': [4], '(AI)': [5], 'technology': [6, 37], 'have': [7], 'raised': [8], 'concerns': [9], 'about': [10, 78], 'the': [11, 60, 89, 171, 179], 'ethical,': [12], 'moral,': [13], 'and': [14, 28, 33, 51, 62, 76, 94, 97, 120, 133, 139, 181], 'legal': [15], 'safeguards.': [16], 'There': [17], 'is': [18, 54], 'a': [19, 39], 'pressing': [20], 'need': [21], 'to': [22, 34, 56, 87, 130, 150, 159, 169, 175], 'improve': [23, 131, 151], 'metrics': [24], 'for': [25], 'assessing': [26], 'security': [27], 'privacy': [29], 'of': [30, 64, 183], 'AI': [31, 36, 48, 65, 69, 102, 111, 154, 172, 184], 'systems': [32, 112], 'manage': [35], 'more': [40], 'ethical': [41, 106], 'manner.': [42], 'To': [43], 'address': [44], 'these': [45], 'challenges,': [46], 'an': [47, 71, 84], 'Trust': [49, 67], 'Framework': [50], 'Maturity': [52], 'Model': [53], 'proposed': [55], 'enhance': [57, 95], 'trust': [58, 98, 132, 152, 177], 'design': [61, 180], 'management': [63, 182], 'systems.': [66, 146, 185], 'involves': [70], 'agreed-upon': [72], 'understanding': [73], 'between': [74], 'humans': [75], 'machines': [77], 'system': [79], 'performance.': [80], 'The': [81, 123], 'framework': [82], 'utilizes': [83], '“entropy': [85], 'lens”': [86], 'root': [88], 'study': [90], 'information': [92], 'theory': [93], 'transparency': [96], '“black': [100], 'box”': [101], 'systems,': [103, 140], 'which': [104], 'lack': [105], 'guardrails.': [107], 'High': [108], 'entropy': [109, 128], 'can': [113], 'decrease': [114], 'human': [115], 'trust,': [116], 'particularly': [117], 'uncertain': [119], 'competitive': [121], 'environments.': [122], 'research': [124], 'draws': [125], 'inspiration': [126], 'from': [127], 'studies': [129], 'performance': [134, 161], 'autonomous': [136], 'human–machine': [137], 'teams': [138], 'including': [141], 'interconnected': [142], 'elements': [143], 'hierarchical': [145], 'Applying': [147], 'this': [148], 'lens': [149], 'also': [155], 'highlights': [156], 'new': [157], 'opportunities': [158], 'optimize': [160], 'teams.': [163], 'Two': [164], 'use': [165], 'cases': [166], 'are': [167], 'described': [168], 'validate': [170], 'framework’s': [173], 'ability': [174], 'measure': [176]}",2023,"['Computer science', 'Transparency (behavior)', 'Through-the-lens metering', 'Entropy (arrow of time)', 'Artificial intelligence', 'Maturity (psychological)', 'Trust management (information system)', 'Knowledge management', 'Computer security', 'Lens (geology)', 'Engineering', 'Psychology', 'Physics', 'Quantum mechanics', 'Developmental psychology', 'Petroleum engineering']","Recent advancements in artificial intelligence (AI) technology have raised concerns about the ethical, moral, and legal safeguards. There is a pressing need to improve metrics for assessing security and privacy of AI systems and to manage AI technology in a more ethical manner. To address these challenges, an AI Trust Framework and Maturity Model is proposed to enhance trust in the design and management of AI systems. Trust in AI involves an agreed-upon understanding between humans and machines about system performance. The framework utilizes an “entropy lens” to root the study in information theory and enhance transparency and trust in “black box” AI systems, which lack ethical guardrails. High entropy in AI systems can decrease human trust, particularly in uncertain and competitive environments. The research draws inspiration from entropy studies to improve trust and performance in autonomous human–machine teams and systems, including interconnected elements in hierarchical systems. Applying this lens to improve trust in AI also highlights new opportunities to optimize performance in teams. Two use cases are described to validate the AI framework’s ability to measure trust in the design and management of AI systems."
https://openalex.org/W4396215553,Transparency and Privacy: The Role of Explainable AI and Federated Learning in Financial Fraud Detection,"{'Fraudulent': [0], 'transactions': [1, 60, 79, 171], 'and': [2, 27, 44, 63, 151, 181, 199, 209, 241], 'how': [3], 'to': [4, 24, 99, 110, 115, 155, 163, 168, 211], 'detect': [5, 169], 'them': [6], 'remain': [7], 'a': [8, 49, 117, 144, 166, 205], 'significant': [9, 75], 'problem': [10], 'for': [11, 19, 33], 'financial': [12, 34, 106, 161], 'institutions': [13, 107, 162], 'around': [14], 'the': [15, 40, 56, 88, 93, 100, 124, 137, 184, 190, 194, 212, 223, 245], 'world.': [16], 'The': [17], 'need': [18], 'advanced': [20], 'fraud': [21, 46, 94, 125, 225], 'detection': [22, 47, 95, 126, 226], 'systems': [23, 48], 'safeguard': [25], 'assets': [26], 'maintain': [28], 'customer': [29, 113, 175], 'trust': [30, 210], 'is': [31, 55, 121], 'paramount': [32], 'institutions,': [35], 'but': [36], 'some': [37], 'factors': [38, 54], 'make': [39], 'development': [41], 'of': [42, 52, 77, 92, 186, 207], 'effective': [43, 240], 'efficient': [45], 'challenge.': [50], 'One': [51], 'such': [53], 'fact': [57], 'that': [58, 64, 70, 104, 132, 189, 222], 'fraudulent': [59, 78, 170], 'are': [61, 68, 73, 108], 'rare': [62], 'many': [65], 'transaction': [66, 219], 'datasets': [67], 'imbalanced;': [69], 'is,': [71], 'there': [72], 'fewer': [74], 'samples': [76], 'than': [80], 'legitimate': [81], 'ones.': [82], 'This': [83, 233], 'data': [84, 101, 114, 179], 'imbalance': [85], 'can': [86, 196], 'affect': [87, 136], 'performance': [89, 231], 'or': [90], 'reliability': [91], 'model.': [96], 'Moreover,': [97], 'due': [98], 'privacy': [102, 180], 'laws': [103], 'all': [105], 'subject': [109], 'follow,': [111], 'sharing': [112, 174], 'facilitate': [116], 'higher-performing': [118], 'centralized': [119], 'model': [120, 167, 195], 'impossible.': [122], 'Furthermore,': [123], 'technique': [127], 'should': [128], 'be': [129, 197], 'transparent': [130], 'so': [131], 'it': [133], 'does': [134], 'not': [135], 'user': [138], 'experience.': [139], 'Hence,': [140], 'this': [141], 'research': [142], 'introduces': [143], 'novel': [145], 'approach': [146], 'using': [147], 'Federated': [148], 'Learning': [149], '(FL)': [150], 'Explainable': [152], 'AI': [153], '(XAI)': [154], 'address': [156], 'these': [157], 'challenges.': [158], 'FL': [159], 'enables': [160], 'collaboratively': [164], 'train': [165], 'without': [172], 'directly': [173], 'data,': [176], 'thereby': [177], 'preserving': [178], 'confidentiality.': [182], 'Meanwhile,': [183], 'integration': [185], 'XAI': [187], 'ensures': [188], 'predictions': [191], 'made': [192], 'by': [193, 201], 'understood': [198], 'interpreted': [200], 'human': [202], 'experts,': [203], 'adding': [204], 'layer': [206], 'transparency': [208], 'system.': [213], 'Experimental': [214], 'results,': [215], 'based': [216], 'on': [217], 'realistic': [218], 'datasets,': [220], 'reveal': [221], 'FL-based': [224], 'system': [227], 'consistently': [228], 'demonstrates': [229], 'high': [230], 'metrics.': [232], 'study': [234], 'grounds': [235], 'FL&#x2019;s': [236], 'potential': [237], 'as': [238], 'an': [239], 'privacy-preserving': [242], 'tool': [243], 'in': [244], 'fight': [246], 'against': [247], 'fraud.': [248]}",2024,"['Transparency (behavior)', 'Computer science', 'Internet privacy', 'Information privacy', 'Computer security', 'Accounting', 'Business']","Fraudulent transactions and how to detect them remain a significant problem for financial institutions around the world. The need for advanced fraud detection systems to safeguard assets and maintain customer trust is paramount for financial institutions, but some factors make the development of effective and efficient fraud detection systems a challenge. One of such factors is the fact that fraudulent transactions are rare and that many transaction datasets are imbalanced; that is, there are fewer significant samples of fraudulent transactions than legitimate ones. This data imbalance can affect the performance or reliability of the fraud detection model. Moreover, due to the data privacy laws that all financial institutions are subject to follow, sharing customer data to facilitate a higher-performing centralized model is impossible. Furthermore, the fraud detection technique should be transparent so that it does not affect the user experience. Hence, this research introduces a novel approach using Federated Learning (FL) and Explainable AI (XAI) to address these challenges. FL enables financial institutions to collaboratively train a model to detect fraudulent transactions without directly sharing customer data, thereby preserving data privacy and confidentiality. Meanwhile, the integration of XAI ensures that the predictions made by the model can be understood and interpreted by human experts, adding a layer of transparency and trust to the system. Experimental results, based on realistic transaction datasets, reveal that the FL-based fraud detection system consistently demonstrates high performance metrics. This study grounds FL&#x2019;s potential as an effective and privacy-preserving tool in the fight against fraud."
https://openalex.org/W3092011919,An AI-assisted Approach for Checking the Completeness of Privacy Policies Against GDPR,"{'Privacy': [0], 'policies': [1, 17, 140, 194, 219], 'are': [2, 18], 'critical': [3], 'for': [4, 49, 81, 89, 125, 132], 'helping': [5], 'individuals': [6], 'make': [7], 'informed': [8], 'decisions': [9], 'about': [10], 'their': [11], 'personal': [12], 'data.': [13], 'In': [14, 69], 'Europe,': [15], 'privacy': [16, 37, 82, 97, 126, 139, 169, 193, 218], 'subject': [19], 'to': [20, 102, 117], 'compliance': [21, 79], 'with': [22, 40], 'the': [23, 56, 67, 92, 103, 119, 134, 146, 150, 196, 209, 216, 227], 'General': [24], 'Data': [25], 'Protection': [26], 'Regulation': [27], '(GDPR).': [28], 'If': [29], 'done': [30], 'entirely': [31], 'manually,': [32], 'checking': [33, 80, 90, 143], 'whether': [34, 91], 'a': [35, 95, 114, 163, 175, 237], 'given': [36, 96], 'policy': [38, 98], 'complies': [39], 'GDPR': [41, 78, 124, 138], 'is': [42, 52, 59, 99, 188], 'both': [43], 'time-consuming': [44], 'and': [45, 141, 155, 181, 241], 'error-prone.': [46], 'Automated': [47], 'support': [48, 65, 88], 'this': [50, 70], 'task': [51], 'thus': [53, 235], 'advantageous.': [54], 'At': [55], 'moment,': [57], 'there': [58], 'an': [60, 74, 129, 157], 'evident': [61], 'lack': [62], 'of': [63, 77, 94, 153, 159, 177, 190, 208, 211, 239, 243], 'such': [64], 'on': [66], 'market.': [68], 'paper,': [71], 'we': [72, 85, 111, 173], 'tackle': [73], 'important': [75], 'dimension': [76], 'policies.': [83, 170], 'Specifically,': [84], 'provide': [86], 'automated': [87], 'content': [93, 121, 136, 148], 'complete': [100], 'according': [101], 'provisions': [104], 'stipulated': [105], 'by': [106, 123], 'GDPR.': [107], 'To': [108], 'do': [109], 'so,': [110], 'present:': [112], '(1)': [113], 'conceptual': [115], 'model': [116], 'characterize': [118], 'information': [120, 135], 'envisaged': [122], 'policies,': [127, 226], '(2)': [128], 'AI-assisted': [130], 'approach': [131, 161, 205, 228, 234], 'classifying': [133], 'in': [137, 215], 'subsequently': [142], 'how': [144], 'well': [145], 'classified': [147], 'meets': [149], 'completeness': [151], 'criteria': [152], 'interest;': [154], '(3)': [156], 'evaluation': [158], 'our': [160, 204, 246], 'through': [162], 'case': [164, 247], 'study': [165], 'over': [166, 245], '24': [167, 217], 'unseen': [168], 'For': [171], 'classification,': [172], 'leverage': [174], 'combination': [176], 'Natural': [178], 'Language': [179], 'Processing': [180], 'supervised': [182], 'Machine': [183], 'Learning.': [184], 'Our': [185, 199], 'experimental': [186], 'material': [187], 'comprised': [189], '234': [191], 'real': [192], 'from': [195], 'fund': [197], 'industry.': [198], 'empirical': [200], 'results': [201], 'indicate': [202], 'that': [203], 'detected': [206], '45': [207], 'total': [210], '47': [212], 'incompleteness': [213], 'issues': [214], 'it': [220], 'was': [221], 'applied': [222], 'to.': [223], 'Over': [224], 'these': [225], 'had': [229], 'eight': [230], 'false': [231], 'positives.': [232], 'The': [233], 'has': [236], 'precision': [238], '85%': [240], 'recall': [242], '96%': [244], 'study.': [248]}",2020,"['Computer science', 'Privacy policy', 'General Data Protection Regulation', 'Information privacy', 'Leverage (statistics)', 'Computer security', 'Privacy by Design', 'Privacy software', 'Privacy law', 'Completeness (order theory)', 'Internet privacy', 'Artificial intelligence', 'Data Protection Act 1998', 'Mathematical analysis', 'Mathematics']","Privacy policies are critical for helping individuals make informed decisions about their personal data. In Europe, privacy policies are subject to compliance with the General Data Protection Regulation (GDPR). If done entirely manually, checking whether a given privacy policy complies with GDPR is both time-consuming and error-prone. Automated support for this task is thus advantageous. At the moment, there is an evident lack of such support on the market. In this paper, we tackle an important dimension of GDPR compliance checking for privacy policies. Specifically, we provide automated support for checking whether the content of a given privacy policy is complete according to the provisions stipulated by GDPR. To do so, we present: (1) a conceptual model to characterize the information content envisaged by GDPR for privacy policies, (2) an AI-assisted approach for classifying the information content in GDPR privacy policies and subsequently checking how well the classified content meets the completeness criteria of interest; and (3) an evaluation of our approach through a case study over 24 unseen privacy policies. For classification, we leverage a combination of Natural Language Processing and supervised Machine Learning. Our experimental material is comprised of 234 real privacy policies from the fund industry. Our empirical results indicate that our approach detected 45 of the total of 47 incompleteness issues in the 24 privacy policies it was applied to. Over these policies, the approach had eight false positives. The approach thus has a precision of 85% and recall of 96% over our case study."
https://openalex.org/W4383176079,From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy,"{'Undoubtedly,': [0], 'the': [1, 10, 16, 20, 51, 58, 68, 81, 91, 100, 116, 120, 137, 148, 157, 224, 234, 252], 'evolution': [2], 'of': [3, 12, 53, 63, 88, 93, 102, 230], 'Generative': [4], 'AI': [5], '(GenAI)': [6], 'models': [7, 23], 'has': [8], 'been': [9], 'highlight': [11], 'digital': [13], 'transformation': [14], 'in': [15, 56, 90, 151], 'year': [17], '2022.': [18], 'As': [19], 'different': [21], 'GenAI': [22, 54, 89, 149, 191, 245], 'like': [24, 128], 'ChatGPT': [25, 160], 'and': [26, 34, 60, 65, 71, 86, 95, 132, 155, 180, 189, 207, 217, 227, 239, 249], 'Google': [27], 'Bard': [28], 'continue': [29], 'to': [30, 38, 111, 166, 193, 242], 'foster': [31], 'their': [32], 'complexity': [33], 'capability,': [35], ""it's"": [36], 'critical': [37], 'understand': [39], 'its': [40, 255], 'consequences': [41], 'from': [42], 'a': [43], 'cybersecurity': [44, 94, 256], 'perspective.': [45], 'Several': [46], 'instances': [47], 'recently': [48], 'have': [49], 'demonstrated': [50], 'use': [52, 147], 'tools': [55, 150, 192], 'both': [57], 'defensive': [59], 'offensive': [61], 'side': [62], 'cybersecurity,': [64], 'focusing': [66], 'on': [67, 119, 136], 'social,': [69, 225], 'ethical': [70, 117, 212, 228, 250], 'privacy': [72], 'implications': [73, 229], 'this': [74, 244], 'technology': [75], 'possesses.': [76], 'This': [77, 122, 183], 'research': [78], 'paper': [79, 123, 140, 184, 235], 'highlights': [80, 236], 'limitations,': [82], 'challenges,': [83], 'potential': [84], 'risks,': [85], 'opportunities': [87], 'domain': [92], 'privacy.': [96], 'The': [97, 139], 'work': [98], 'presents': [99], 'vulnerabilities': [101], 'ChatGPT,': [103], 'which': [104], 'can': [105, 146, 161], 'be': [106, 162], 'exploited': [107], 'by': [108, 164], 'malicious': [109, 113], 'users': [110], 'exfiltrate': [112], 'information': [114], 'bypassing': [115], 'constraints': [118], 'model.': [121], 'demonstrates': [124], 'successful': [125], 'example': [126], 'attacks': [127, 135], 'Jailbreaks,': [129], 'reverse': [130], 'psychology,': [131], 'prompt': [133], 'injection': [134], 'ChatGPT.': [138, 231], 'also': [141, 222], 'investigates': [142], 'how': [143], 'cyber': [144, 153, 198], 'offenders': [145], 'developing': [152, 211], 'attacks,': [154, 170, 172], 'explore': [156], 'scenarios': [158], 'where': [159], 'used': [163], 'adversaries': [165], 'create': [167], 'social': [168], 'engineering': [169], 'phishing': [171], 'automated': [173], 'hacking,': [174], 'attack': [175, 209], 'payload': [176], 'generation,': [177], 'malware': [178, 218], 'creation,': [179], 'polymorphic': [181], 'malware.': [182], 'then': [185], 'examines': [186], 'defense': [187, 199], 'techniques': [188], 'uses': [190], 'improve': [194], 'security': [195], 'measures,': [196], 'including': [197], 'automation,': [200], 'reporting,': [201], 'threat': [202], 'intelligence,': [203], 'secure': [204], 'code': [205], 'generation': [206], 'detection,': [208], 'identification,': [210], 'guidelines,': [213], 'incidence': [214], 'response': [215], 'plans,': [216], 'detection.': [219], 'We': [220], 'will': [221], 'discuss': [223], 'legal,': [226], 'In': [232], 'conclusion,': [233], 'open': [237], 'challenges': [238], 'future': [240], 'directions': [241], 'make': [243], 'secure,': [246], 'safe,': [247], 'trustworthy,': [248], 'as': [251], 'community': [253], 'understands': [254], 'impacts.': [257]}",2023,"['Computer security', 'Phishing', 'Malware', 'Computer science', 'Hacker', 'Offensive', 'Social engineering (security)', 'Internet privacy', 'Cyber-attack', 'The Internet', 'Engineering', 'World Wide Web', 'Operations research']","Undoubtedly, the evolution of Generative AI (GenAI) models has been the highlight of digital transformation in the year 2022. As the different GenAI models like ChatGPT and Google Bard continue to foster their complexity and capability, it's critical to understand its consequences from a cybersecurity perspective. Several instances recently have demonstrated the use of GenAI tools in both the defensive and offensive side of cybersecurity, and focusing on the social, ethical and privacy implications this technology possesses. This research paper highlights the limitations, challenges, potential risks, and opportunities of GenAI in the domain of cybersecurity and privacy. The work presents the vulnerabilities of ChatGPT, which can be exploited by malicious users to exfiltrate malicious information bypassing the ethical constraints on the model. This paper demonstrates successful example attacks like Jailbreaks, reverse psychology, and prompt injection attacks on the ChatGPT. The paper also investigates how cyber offenders can use the GenAI tools in developing cyber attacks, and explore the scenarios where ChatGPT can be used by adversaries to create social engineering attacks, phishing attacks, automated hacking, attack payload generation, malware creation, and polymorphic malware. This paper then examines defense techniques and uses GenAI tools to improve security measures, including cyber defense automation, reporting, threat intelligence, secure code generation and detection, attack identification, developing ethical guidelines, incidence response plans, and malware detection. We will also discuss the social, legal, and ethical implications of ChatGPT. In conclusion, the paper highlights open challenges and future directions to make this GenAI secure, safe, trustworthy, and ethical as the community understands its cybersecurity impacts."
https://openalex.org/W3048763337,Privacy Issues of AI,"{'This': [0], 'chapter': [1], 'sheds': [2], 'light': [3], 'on': [4], 'how': [5], 'private': [6], 'data': [7, 35], 'is': [8, 42], 'systematically': [9], 'collected,': [10], 'stored': [11], 'and': [12, 29], 'analysed': [13], 'with': [14], 'the': [15, 44], 'help': [16], 'of': [17, 24], 'artificial': [18], 'intelligence.': [19], 'We': [20], 'discuss': [21], 'various': [22], 'forms': [23], 'persistent': [25], 'surveillance': [26], 'at': [27], 'home': [28], 'in': [30], 'public': [31], 'spaces.': [32], 'While': [33], 'massive': [34], 'collection': [36], 'raises': [37], 'considerable': [38], 'ethical': [39], 'concerns,': [40], 'it': [41], 'also': [43], 'basis': [45], 'for': [46, 49], 'better': [47], 'performance': [48], 'AI': [50], 'systems.': [51]}",2020,"['Internet privacy', 'Computer science', 'Data science', 'Data collection', 'Computer security', 'Political science', 'Sociology', 'Social science']","This chapter sheds light on how private data is systematically collected, stored and analysed with the help of artificial intelligence. We discuss various forms of persistent surveillance at home and in public spaces. While massive data collection raises considerable ethical concerns, it is also the basis for better performance for AI systems."
https://openalex.org/W4360765051,AI privacy preserving robots working in a smart sensor environment,"{'sponsorship:': [0], 'This': [1], 'research': [2], 'received': [3], 'funding': [4], 'from': [5], 'the': [6], 'Flemish': [7], 'regional': [8, 14], 'government': [9, 15], '(AI': [10, 16], 'Research': [11, 17], 'Program).': [12], '(Flemish': [13], 'Program))': [18]}",2022,"['Computer science', 'Robot', 'Broadcasting (networking)', 'Bandwidth (computing)', 'Real-time computing', 'Inference', 'Information privacy', 'Artificial intelligence', 'Embedded system', 'Computer network', 'Computer security']",sponsorship: This research received funding from the Flemish regional government (AI Research Program). (Flemish regional government (AI Research Program))
https://openalex.org/W4404024323,Privacy-Preserving Techniques in Generative AI and Large Language Models: A Narrative Review,"{'Generative': [0], 'AI,': [1, 48, 147, 186], 'including': [2, 90], 'large': [3, 189], 'language': [4, 190], 'models': [5, 26], '(LLMs),': [6], 'has': [7], 'transformed': [8], 'the': [9, 85, 114, 117, 137, 148, 151, 167, 182], 'paradigm': [10], 'of': [11, 38, 119, 142, 184], 'data': [12, 44, 72, 132], 'generation': [13], 'and': [14, 60, 74, 93, 125, 139, 161, 172, 196], 'creative': [15], 'content,': [16], 'but': [17], 'this': [18], 'progress': [19], 'raises': [20], 'critical': [21], 'privacy': [22, 45, 52, 101, 110, 143, 162], 'concerns,': [23], 'especially': [24, 187], 'when': [25], 'are': [27, 79], 'trained': [28], 'on': [29], 'sensitive': [30], 'data.': [31], 'This': [32], 'review': [33, 86, 115, 149], 'provides': [34], 'a': [35, 154], 'comprehensive': [36], 'overview': [37], 'privacy-preserving': [39, 176], 'techniques': [40, 66, 177], 'aimed': [41], 'at': [42], 'safeguarding': [43], 'in': [46, 102, 145, 188], 'generative': [47, 103, 146, 185], 'such': [49], 'as': [50, 96], 'differential': [51], '(DP),': [53], 'federated': [54], 'learning': [55], '(FL),': [56], 'homomorphic': [57], 'encryption': [58], '(HE),': [59], 'secure': [61], 'multi-party': [62], 'computation': [63], '(SMPC).': [64], 'These': [65], 'mitigate': [67], 'risks': [68, 144], 'like': [69], 'model': [70], 'inversion,': [71], 'leakage,': [73], 'membership': [75], 'inference': [76], 'attacks,': [77], 'which': [78], 'particularly': [80], 'relevant': [81], 'to': [82, 128, 174, 194], 'LLMs.': [83], 'Additionally,': [84], 'explores': [87], 'emerging': [88], 'solutions,': [89], 'privacy-enhancing': [91], 'technologies': [92], 'post-quantum': [94], 'cryptography,': [95], 'future': [97], 'directions': [98], 'for': [99, 153, 169], 'enhancing': [100], 'AI': [104], 'systems.': [105], 'Recognizing': [106], 'that': [107, 157, 178], 'achieving': [108], 'absolute': [109], 'is': [111], 'mathematically': [112], 'impossible,': [113], 'emphasizes': [116], 'necessity': [118], 'aligning': [120], 'technical': [121], 'safeguards': [122], 'with': [123, 131, 181], 'legal': [124, 140], 'regulatory': [126, 195], 'frameworks': [127], 'ensure': [129], 'compliance': [130], 'protection': [133], 'laws.': [134], 'By': [135], 'discussing': [136], 'ethical': [138, 197], 'implications': [141], 'underscores': [150], 'need': [152, 168], 'balanced': [155], 'approach': [156], 'considers': [158], 'performance,': [159], 'scalability,': [160], 'preservation.': [163], 'The': [164], 'findings': [165], 'highlight': [166], 'ongoing': [170], 'research': [171], 'innovation': [173], 'develop': [175], 'keep': [179], 'pace': [180], 'scaling': [183], 'models,': [191], 'while': [192], 'adhering': [193], 'standards.': [198]}",2024,"['Generative grammar', 'Narrative', 'Computer science', 'Linguistics', 'Natural language processing', 'Artificial intelligence', 'Philosophy']","Generative AI, including large language models (LLMs), has transformed the paradigm of data generation and creative content, but this progress raises critical privacy concerns, especially when models are trained on sensitive data. This review provides a comprehensive overview of privacy-preserving techniques aimed at safeguarding data privacy in generative AI, such as differential privacy (DP), federated learning (FL), homomorphic encryption (HE), and secure multi-party computation (SMPC). These techniques mitigate risks like model inversion, data leakage, and membership inference attacks, which are particularly relevant to LLMs. Additionally, the review explores emerging solutions, including privacy-enhancing technologies and post-quantum cryptography, as future directions for enhancing privacy in generative AI systems. Recognizing that achieving absolute privacy is mathematically impossible, the review emphasizes the necessity of aligning technical safeguards with legal and regulatory frameworks to ensure compliance with data protection laws. By discussing the ethical and legal implications of privacy risks in generative AI, the review underscores the need for a balanced approach that considers performance, scalability, and privacy preservation. The findings highlight the need for ongoing research and innovation to develop privacy-preserving techniques that keep pace with the scaling of generative AI, especially in large language models, while adhering to regulatory and ethical standards."
https://openalex.org/W4399906749,Reconciling privacy and accuracy in AI for medical imaging,"{'Abstract': [0], 'Artificial': [1], 'intelligence': [2, 119, 169], '(AI)': [3], 'models': [4, 44, 120, 170], 'are': [5, 153], 'vulnerable': [6], 'to': [7, 32, 110, 171, 178], 'information': [8, 78], 'leakage': [9], 'of': [10, 49, 53, 77, 86, 102, 117, 133], 'their': [11], 'training': [12, 43, 54], 'data,': [13], 'which': [14], 'can': [15, 144], 'be': [16], 'highly': [17], 'sensitive,': [18], 'for': [19, 42, 182], 'example,': [20], 'in': [21, 151], 'medical': [22], 'imaging.': [23], 'Privacy-enhancing': [24], 'technologies,': [25], 'such': [26, 87], 'as': [27], 'differential': [28], 'privacy': [29, 68, 104, 123, 142, 190], '(DP),': [30], 'aim': [31], 'circumvent': [33], 'these': [34], 'susceptibilities.': [35], 'DP': [36, 61, 161], 'is': [37, 164], 'the': [38, 47, 51, 58, 75, 84, 100, 115], 'strongest': [39], 'possible': [40], 'protection': [41], 'while': [45, 149], 'bounding': [46], 'risks': [48, 191], 'inferring': [50], 'inclusion': [52], 'samples': [55], 'or': [56], 'reconstructing': [57], 'original': [59], 'data.': [60, 173], 'achieves': [62], 'this': [63], 'by': [64], 'setting': [65], 'a': [66, 71, 91, 103, 180, 187], 'quantifiable': [67], 'budget.': [69], 'Although': [70], 'lower': [72], 'budget': [73, 105], 'decreases': [74], 'risk': [76, 128], 'leakage,': [79], 'it': [80], 'typically': [81], 'also': [82], 'reduces': [83], 'performance': [85, 95, 116, 152], 'models.': [88], 'This': [89], 'imposes': [90], 'trade-off': [92], 'between': [93, 189], 'robust': [94], 'and': [96, 108, 130, 192], 'stringent': [97], 'privacy.': [98], 'Additionally,': [99], 'interpretation': [101], 'remains': [106], 'abstract': [107], 'challenging': [109], 'contextualize.': [111], 'Here': [112], 'we': [113], 'contrast': [114], 'artificial': [118, 168], 'at': [121, 162], 'various': [122], 'budgets': [124, 143], 'against': [125], 'both': [126], 'theoretical': [127], 'bounds': [129], 'empirical': [131], 'success': [132], 'reconstruction': [134, 146], 'attacks.': [135], 'We': [136, 155, 174], 'show': [137], 'that': [138, 158], 'using': [139, 160], 'very': [140], 'large': [141], 'render': [145], 'attacks': [147], 'impossible,': [148], 'drops': [150], 'negligible.': [154], 'thus': [156], 'conclude': [157], 'not': [159], 'all': [163], 'negligent': [165], 'when': [166], 'applying': [167], 'sensitive': [172], 'deem': [175], 'our': [176], 'results': [177], 'lay': [179], 'foundation': [181], 'further': [183], 'debates': [184], 'on': [185], 'striking': [186], 'balance': [188], 'model': [193], 'performance.': [194]}",2024,"['Internet privacy', 'Computer security', 'Computer science', 'Business', 'Medicine']","Abstract Artificial intelligence (AI) models are vulnerable to information leakage of their training data, which can be highly sensitive, for example, in medical imaging. Privacy-enhancing technologies, such as differential privacy (DP), aim to circumvent these susceptibilities. DP is the strongest possible protection for training models while bounding the risks of inferring the inclusion of training samples or reconstructing the original data. DP achieves this by setting a quantifiable privacy budget. Although a lower budget decreases the risk of information leakage, it typically also reduces the performance of such models. This imposes a trade-off between robust performance and stringent privacy. Additionally, the interpretation of a privacy budget remains abstract and challenging to contextualize. Here we contrast the performance of artificial intelligence models at various privacy budgets against both theoretical risk bounds and empirical success of reconstruction attacks. We show that using very large privacy budgets can render reconstruction attacks impossible, while drops in performance are negligible. We thus conclude that not using DP at all is negligent when applying artificial intelligence models to sensitive data. We deem our results to lay a foundation for further debates on striking a balance between privacy risks and model performance."
https://openalex.org/W4404199748,Is AI-based digital marketing ethical? Assessing a new data privacy paradox,"{'The': [0, 73, 88, 107], 'rapid': [1], 'development': [2], 'of': [3, 28, 39, 63, 66, 93, 123, 141, 153, 171, 199, 222, 314], 'artificial': [4], 'intelligence': [5], '(AI)': [6], 'has': [7], 'significantly': [8], 'transformed': [9], 'digital': [10, 30, 130, 155, 286], 'marketing': [11], 'enhancing': [12], 'its': [13], 'effectiveness': [14], 'and': [15, 19, 80, 100, 120, 192, 226, 279, 319, 326], 'raising': [16], 'new': [17], 'ethical': [18, 26, 121, 294, 320], 'privacy': [20, 119, 181, 213, 253, 282], 'concerns.': [21], 'This': [22], 'study': [23, 140, 258], 'investigates': [24], 'the': [25, 61, 97, 104, 110, 139, 151, 160, 197, 217, 219, 230, 323], 'implications': [27], 'AI-based': [29, 129, 154, 285], 'marketing,': [31, 156], 'particularly': [32], 'focusing': [33], 'on': [34], 'user': [35, 118, 237, 309], 'privacy.': [36], 'In': [37], 'terms': [38], 'methodology,': [40], 'a': [41, 91, 113, 184, 249], 'systematic': [42], 'literature': [43], 'review': [44], '(SLR)': [45], 'was': [46], 'conducted': [47], 'to': [48, 180, 212, 233, 252, 299], 'identify': [49], 'relevant': [50], 'variables,': [51], 'followed': [52], 'by': [53], 'Multiple': [54], 'Correspondence': [55], 'Analysis': [56], '(MCA)': [57], 'using': [58, 68, 128], 'R': [59], 'within': [60], 'framework': [62], 'homogeneity': [64], 'analysis': [65, 75], 'variance': [67], 'alternating': [69], 'least': [70], 'squares': [71], '(HOMALS).': [72], 'MCA': [74, 89], 'identified': [76, 90], '3': [77], 'multivariate': [78], 'groupings,': [79], '21': [81, 260], 'individual': [82], 'variables': [83, 142, 228], 'extracted': [84], 'from': [85], '28': [86], 'studies.': [87], 'total': [92], '4': [94], 'clusters': [95, 102], 'in': [96, 103, 164, 203, 239, 284], 'eigenvalues/variances': [98], 'analysis,': [99], '5': [101], 'biplot': [105], 'analysis.': [106], 'findings': [108], 'emphasize': [109], 'need': [111, 232], 'for': [112, 307], 'balanced': [114], 'approach': [115], 'that': [116, 264], 'respects': [117], 'use': [122], 'data': [124, 303, 310, 324], 'when': [125], 'developing': [126, 172], 'actions': [127, 163], 'marketing.': [131, 287], 'However,': [132, 183], 'no': [133, 169], 'significant': [134], 'relationship': [135], 'is': [136, 168, 194, 209, 241, 297], 'evident': [137], 'between': [138, 187], 'such': [143], 'as': [144, 207, 244, 311], 'cross-device': [145], 'tracking': [146], 'or': [147, 177, 214, 254, 277], 'data-driven': [148], 'technologies': [149], 'and,': [150], 'ethics': [152], 'despite': [157], 'these': [158, 267, 290], 'being': [159, 242, 270], 'most': [161], 'profitable': [162], 'this': [165, 200, 204, 257], 'environment.': [166], 'There': [167], 'evidence': [170], 'personalized': [173], 'social': [174], 'media': [175], 'content': [176, 191], 'ads': [178], 'linked': [179, 211], 'standards.': [182], 'strong': [185, 220, 250], 'connection': [186], 'behavioral': [188], 'analytics,': [189], 'smart': [190], 'metaverse': [193], 'identified,': [195], 'highlighting': [196], 'risks': [198], 'emerging': [201], 'technology': [202], 'research': [205, 262], 'field,': [206], 'it': [208, 296], 'not': [210, 247], 'ethics.': [215, 255], 'Among': [216], 'results,': [218], 'proximity': [221], 'real-time': [223, 240], 'tracking,': [224], 'IoT,': [225], 'surveillance': [227], 'underscores': [229], 'critical': [231], 'ethically': [234, 271], 'understand': [235], 'how': [236], 'behavior': [238], 'monitored,': [243], 'they': [245], 'do': [246], 'offer': [248], 'link': [251], 'Additionally,': [256], 'provides': [259], 'future': [261], 'questions': [263], 'address': [265], 'whether': [266], 'practices': [268, 291], 'are': [269], 'implemented,': [272], 'following': [273], 'standards': [274], 'like': [275], '“privacy-by-default”': [276], '“privacy-by-design,”': [278], 'complying': [280], 'with': [281, 293], 'laws': [283], 'To': [288], 'ensure': [289], 'align': [292], 'standards,': [295], 'essential': [298], 'adopt': [300], 'frameworks': [301], 'prioritizing': [302], 'dignity,': [304], 'which': [305], 'calls': [306], 'treating': [308], 'an': [312], 'extension': [313], 'personal': [315], 'identity,': [316], 'requiring': [317], 'responsible': [318], 'handling': [321], 'throughout': [322], 'collection': [325], 'processing': [327], 'lifecycle.': [328]}",2024,"['Internet privacy', 'Information privacy', 'Consumer privacy', 'Psychology', 'Computer science', 'Business', 'Marketing']","The rapid development of artificial intelligence (AI) has significantly transformed digital marketing enhancing its effectiveness and raising new ethical and privacy concerns. This study investigates the ethical implications of AI-based digital marketing, particularly focusing on user privacy. In terms of methodology, a systematic literature review (SLR) was conducted to identify relevant variables, followed by Multiple Correspondence Analysis (MCA) using R within the framework of homogeneity analysis of variance using alternating least squares (HOMALS). The MCA analysis identified 3 multivariate groupings, and 21 individual variables extracted from 28 studies. The MCA identified a total of 4 clusters in the eigenvalues/variances analysis, and 5 clusters in the biplot analysis. The findings emphasize the need for a balanced approach that respects user privacy and ethical use of data when developing actions using AI-based digital marketing. However, no significant relationship is evident between the study of variables such as cross-device tracking or data-driven technologies and, the ethics of AI-based digital marketing, despite these being the most profitable actions in this environment. There is no evidence of developing personalized social media content or ads linked to privacy standards. However, a strong connection between behavioral analytics, smart content and metaverse is identified, highlighting the risks of this emerging technology in this research field, as it is not linked to privacy or ethics. Among the results, the strong proximity of real-time tracking, IoT, and surveillance variables underscores the critical need to ethically understand how user behavior in real-time is being monitored, as they do not offer a strong link to privacy or ethics. Additionally, this study provides 21 future research questions that address whether these practices are being ethically implemented, following standards like “privacy-by-default” or “privacy-by-design,” and complying with privacy laws in AI-based digital marketing. To ensure these practices align with ethical standards, it is essential to adopt frameworks prioritizing data dignity, which calls for treating user data as an extension of personal identity, requiring responsible and ethical handling throughout the data collection and processing lifecycle."
https://openalex.org/W2789589462,"An agent on my shoulder: AI, privacy and the application of human-like computing technologies to music creation","{'Human-Like': [0], 'Computing': [1], 'technologies': [2, 44, 55], 'are': [3, 34], 'intelligent': [4], 'systems': [5], 'that': [6, 42, 64, 74], 'interact': [7], 'with': [8], 'people': [9], 'in': [10, 28, 50, 79], 'human-like': [11], 'way.': [12], 'By': [13], 'bringing': [14], 'together': [15], 'the': [16, 40, 57, 68, 80], 'disciplines': [17], 'of': [18, 39, 70], 'Artificial': [19], 'Intelligence,': [20], 'Ethnography': [21], 'and': [22, 25, 60], 'Interaction': [23], 'Design,': [24], 'applying': [26], 'them': [27], 'a': [29, 62], 'real': [30], 'world': [31], 'context': [32], 'we': [33], 'able': [35, 76], 'to': [36, 56, 77], 'understand': [37], 'some': [38], 'ways': [41], 'such': [43, 54], 'can': [45], 'be': [46], 'applied.': [47], 'This': [48], 'work': [49], 'progress': [51], 'poster': [52], 'applies': [53], 'music': [58, 81], 'creation': [59, 82], 'develops': [61], 'design': [63], 'is': [65, 75], 'based': [66], 'on': [67], 'notion': [69], 'an': [71], '‘Intelligent’': [72], 'Agent': [73], 'support': [78], 'process.': [83]}",2017,"['Computer science', 'Process (computing)', 'Context (archaeology)', 'Intelligent agent', 'Ethnography', 'Ubiquitous computing', 'Human–computer interaction', 'Data science', 'Artificial intelligence', 'Sociology', 'Paleontology', 'Anthropology', 'Operating system', 'Biology']","Human-Like Computing technologies are intelligent systems that interact with people in human-like way. By bringing together the disciplines of Artificial Intelligence, Ethnography and Interaction Design, and applying them in a real world context we are able to understand some of the ways that such technologies can be applied. This work in progress poster applies such technologies to the music creation and develops a design that is based on the notion of an ‘Intelligent’ Agent that is able to support in the music creation process."
https://openalex.org/W4410721456,A Comparative Analysis of AI Privacy Concerns in Higher Education: News Coverage in China and Western Countries,"{'This': [0], 'study': [1], 'examines': [2], 'how': [3, 54], 'Chinese': [4, 106, 130], 'and': [5, 46, 67, 86, 98, 107, 113, 123, 138, 148, 185], 'Western': [6, 117], 'news': [7], 'media': [8, 55], 'covered': [9], 'artificial': [10], 'intelligence': [11], '(AI)': [12], 'privacy': [13, 40, 121, 162, 183], 'issues': [14], 'in': [15, 42, 58, 104, 125, 163], 'higher': [16, 164], 'education': [17, 145], 'from': [18, 26, 154], '2019': [19], 'to': [20, 36, 60, 79, 143, 175], '2024.': [21], 'News': [22], 'articles': [23], 'were': [24], 'retrieved': [25], 'Nexis': [27], 'Uni.': [28], 'First,': [29], 'non-negative': [30], 'matrix': [31], 'factorization': [32], '(NMF)': [33], 'was': [34, 77], 'employed': [35], 'identify': [37], 'core': [38], 'AI': [39, 153, 161, 180], 'topics': [41], 'university': [43], 'teaching,': [44], 'administration,': [45], 'research.': [47], 'Next,': [48], 'a': [49, 74, 169, 187], 'time': [50], 'trend': [51], 'analysis': [52, 76], 'investigated': [53], 'attention': [56], 'shifted': [57], 'relation': [59], 'key': [61], 'events,': [62], 'including': [63], 'the': [64, 68, 81, 111, 149, 177], 'COVID-19': [65], 'pandemic': [66], 'emergence': [69], 'of': [70, 83, 151, 179], 'generative': [71, 152], 'AI.': [72], 'Finally,': [73], 'sentiment': [75], 'conducted': [78], 'compare': [80], 'distribution': [82], 'positive,': [84], 'negative,': [85], 'neutral': [87], 'reporting.': [88], 'The': [89, 141, 166], 'findings': [90], 'indicate': [91], 'that': [92], 'AI-driven': [93, 135], 'proctoring,': [94], 'student': [95], 'data': [96, 191], 'security,': [97], 'institutional': [99], 'governance': [100, 192], 'are': [101], 'central': [102], 'concerns': [103], 'both': [105], 'English': [108], 'media.': [109], 'However,': [110], 'focus': [112], 'framing': [114], 'differ:': [115], 'some': [116], 'outlets': [118], 'highlight': [119], 'individual': [120], 'rights': [122], 'controversies': [124], 'remote': [126, 144], 'exam': [127], 'monitoring,': [128], 'while': [129], 'coverage': [131], 'more': [132], 'frequently': [133], 'addresses': [134], 'educational': [136], 'innovation': [137], 'policy': [139], 'support.': [140], 'shift': [142], 'after': [146], '2020': [147], 'rise': [150], '2023': [155], 'onward': [156], 'have': [157], 'intensified': [158], 'discussions': [159], 'on': [160], 'education.': [165], 'results': [167], 'offer': [168], 'cross-cultural': [170], 'perspective': [171], 'for': [172, 189], 'institutions': [173], 'seeking': [174], 'reconcile': [176], 'adoption': [178], 'with': [181], 'robust': [182], 'safeguards': [184], 'provide': [186], 'foundation': [188], 'future': [190], 'frameworks': [193], 'under': [194], 'diverse': [195], 'regulatory': [196], 'environments.': [197]}",2025,"['Framing (construction)', 'Corporate governance', 'China', 'Public relations', 'Political science', 'Big data', 'Internet privacy', 'Sociology', 'Business', 'Computer science', 'Law', 'Engineering', 'Structural engineering', 'Finance', 'Operating system']","This study examines how Chinese and Western news media covered artificial intelligence (AI) privacy issues in higher education from 2019 to 2024. News articles were retrieved from Nexis Uni. First, non-negative matrix factorization (NMF) was employed to identify core AI privacy topics in university teaching, administration, and research. Next, a time trend analysis investigated how media attention shifted in relation to key events, including the COVID-19 pandemic and the emergence of generative AI. Finally, a sentiment analysis was conducted to compare the distribution of positive, negative, and neutral reporting. The findings indicate that AI-driven proctoring, student data security, and institutional governance are central concerns in both Chinese and English media. However, the focus and framing differ: some Western outlets highlight individual privacy rights and controversies in remote exam monitoring, while Chinese coverage more frequently addresses AI-driven educational innovation and policy support. The shift to remote education after 2020 and the rise of generative AI from 2023 onward have intensified discussions on AI privacy in higher education. The results offer a cross-cultural perspective for institutions seeking to reconcile the adoption of AI with robust privacy safeguards and provide a foundation for future data governance frameworks under diverse regulatory environments."
https://openalex.org/W4390577108,Data Security and Privacy in the Age of AI and Digital Twins,"{'Data': [0], 'security': [1, 39, 78, 105, 129], 'and': [2, 15, 26, 34, 40, 47, 63, 71, 86, 99, 106, 117, 127, 137], 'privacy': [3, 41], 'have': [4], 'emerged': [5], 'as': [6, 81], 'businesses': [7], 'struggle': [8], 'with': [9], 'the': [10, 16, 21, 32, 43, 58, 67, 108, 111], 'growing': [11], 'digitization': [12], 'of': [13, 18, 23, 31, 45, 60, 76, 113], 'operations': [14], 'abundance': [17], 'data': [19, 38, 61, 68, 95, 104], 'in': [20, 42, 52, 91], 'age': [22], 'artificial': [24], 'intelligence': [25], 'digital': [27, 48], 'twins.': [28], 'An': [29], 'overview': [30], 'issues': [33], 'solutions': [35], 'relating': [36], 'to': [37, 93, 124], 'context': [44], 'AI': [46], 'twins': [49], 'is': [50, 89], 'given': [51], 'this': [53], 'chapter.': [54], 'The': [55, 74], 'chapter': [56, 109], 'emphasizes': [57], 'value': [59], 'classification': [62], 'recognizing': [64], 'how': [65, 123], 'sensitive': [66], 'being': [69], 'created': [70], 'used': [72], 'is.': [73], 'necessity': [75], 'strong': [77], 'measures,': [79], 'such': [80], 'access': [82, 98], 'controls,': [83], 'authentication': [84], 'procedures,': [85], 'encryption': [87], 'methods,': [88], 'emphasized': [90], 'order': [92], 'safeguard': [94], 'against': [96], 'unwanted': [97], 'breaches.': [100], 'To': [101], 'further': [102], 'assure': [103], 'compliance,': [107], 'underlines': [110], 'significance': [112], 'ongoing': [114], 'monitoring,': [115, 134], 'auditing,': [116], 'risk': [118, 139], 'assessment': [119], 'procedures.': [120], 'It': [121], 'examines': [122], 'successfully': [125], 'detect': [126], 'mitigate': [128], 'problems': [130], 'by': [131], 'utilizing': [132], 'real-time': [133], 'routine': [135], 'audits,': [136], 'proactive': [138], 'assessments.': [140]}",2024,"['Digitization', 'Computer security', 'Audit', 'Computer science', 'Encryption', 'Data security', 'Context (archaeology)', 'Internet privacy', 'Authentication (law)', 'Business', 'Accounting', 'Geography', 'Archaeology', 'Computer vision']","Data security and privacy have emerged as businesses struggle with the growing digitization of operations and the abundance of data in the age of artificial intelligence and digital twins. An overview of the issues and solutions relating to data security and privacy in the context of AI and digital twins is given in this chapter. The chapter emphasizes the value of data classification and recognizing how sensitive the data being created and used is. The necessity of strong security measures, such as access controls, authentication procedures, and encryption methods, is emphasized in order to safeguard data against unwanted access and breaches. To further assure data security and compliance, the chapter underlines the significance of ongoing monitoring, auditing, and risk assessment procedures. It examines how to successfully detect and mitigate security problems by utilizing real-time monitoring, routine audits, and proactive risk assessments."
https://openalex.org/W3094276725,Evaluating If Trust and Personal Information Privacy Concerns Are Barriers to Using Health Insurance That Explicitly Utilizes AI,"{'Trust': [0], 'and': [1, 22, 50, 77, 95], 'privacy': [2, 51], 'have': [3], 'emerged': [4], 'as': [5], 'significant': [6, 140], 'concerns': [7, 130], 'in': [8, 34, 60, 74, 121], 'online\\ntransactions.': [9], 'Sharing': [10], 'information': [11], 'on': [12], 'health': [13, 24], 'is': [14, 80, 91, 99, 119, 127, 137], 'especially': [15], 'sensitive': [16], 'but': [17, 134], 'it': [18], 'is\\nnecessary': [19], 'for': [20], 'purchasing': [21], 'utilizing': [23], 'insurance.': [25], 'Evidence': [26], 'shows': [27], 'that\\nconsumers': [28], 'are': [29, 53, 64, 131], 'increasingly': [30], 'comfortable': [31], 'with': [32], 'technology': [33], 'place': [35], 'of': [36, 41, 58], 'humans,': [37], 'but\\nthe': [38], 'expanding': [39], 'use': [40], 'AI': [42, 59, 71, 93, 96, 126, 133], 'potentially': [43], 'changes': [44], 'this.': [45], 'This': [46], 'research': [47], 'explores\\nwhether': [48], 'trust': [49, 118], 'concern': [52], 'barriers': [54], 'to': [55, 84, 102], 'the': [56, 75, 87, 103, 122, 135, 142], 'adoption': [57], 'health\\ninsurance.': [61], 'Two': [62], 'scenarios': [63, 107], 'compared:': [65], 'The': [66, 105, 114], 'first': [67], 'scenario': [68, 89, 124], 'has': [69], 'limited': [70], 'that\\nis': [72], 'not': [73, 81, 138], 'interface': [76, 94], 'its': [78], 'presence': [79], 'explicitly': [82, 100], 'revealed': [83, 101], 'the\\nconsumer.': [85], 'In': [86], 'second': [88, 123], 'there': [90], 'an': [92], 'evaluation,\\nand': [97], 'this': [98], 'consumer.': [104], 'two': [106], 'were': [108], 'modeled\\nand': [109], 'compared': [110], 'using': [111], 'SEM': [112], 'PLS-MGA.': [113], 'findings': [115], 'show': [116], 'that': [117], 'significantly\\nlower': [120], 'where': [125], 'visible.': [128], 'Privacy': [129], 'higher\\nwith': [132], 'difference': [136], 'statistically': [139], 'within': [141], 'model.\\n': [143]}",2020,"['Purchasing', 'Internet privacy', 'Business', 'Personally identifiable information', 'Interface (matter)', 'Computer science', 'Computer security', 'Marketing', 'Bubble', 'Parallel computing', 'Maximum bubble pressure method']","Trust and privacy have emerged as significant concerns in online\ntransactions. Sharing information on health is especially sensitive but it is\nnecessary for purchasing and utilizing health insurance. Evidence shows that\nconsumers are increasingly comfortable with technology in place of humans, but\nthe expanding use of AI potentially changes this. This research explores\nwhether trust and privacy concern are barriers to the adoption of AI in health\ninsurance. Two scenarios are compared: The first scenario has limited AI that\nis not in the interface and its presence is not explicitly revealed to the\nconsumer. In the second scenario there is an AI interface and AI evaluation,\nand this is explicitly revealed to the consumer. The two scenarios were modeled\nand compared using SEM PLS-MGA. The findings show that trust is significantly\nlower in the second scenario where AI is visible. Privacy concerns are higher\nwith AI but the difference is not statistically significant within the model.\n"
https://openalex.org/W4399771211,"Evaluating privacy, security, and trust perceptions in conversational AI: A systematic review","{'Conversational': [0], 'AI': [1], '(CAI)': [2], 'systems': [3], 'which': [4, 150], 'encompass': [5], 'voice-': [6], 'and': [7, 14, 33, 49, 51, 57, 80, 92, 106, 109, 115, 127, 132, 163, 191, 204, 212, 215], 'text-based': [8], 'assistants': [9], 'are': [10, 151], 'on': [11, 46, 89, 112, 167, 200], 'the': [12, 39, 52, 61, 72, 84, 96, 125, 140, 158, 168, 173, 218], 'rise': [13], 'have': [15], 'been': [16], 'largely': [17], 'integrated': [18], 'into': [19, 83, 124], 'people’s': [20], 'everyday': [21], 'lives.': [22], 'Despite': [23], 'their': [24, 44], 'widespread': [25], 'adoption,': [26], 'users': [27], 'voice': [28], 'concerns': [29], 'regarding': [30], 'privacy,': [31, 55, 90, 130, 189, 210], 'security': [32, 56, 91, 131, 164, 190, 211], 'trust': [34, 58, 93, 133, 192, 213], 'in': [35, 60, 95], 'these': [36, 42, 180], 'systems.': [37, 100, 223], 'However,': [38], 'composition': [40], 'of': [41, 87, 98, 129, 142, 160, 175, 179, 220], 'perceptions,': [43], 'impact': [45], 'technology': [47], 'adoption': [48], 'usage': [50], 'relationship': [53], 'between': [54], 'perceptions': [59, 94, 159, 193, 214], 'CAI': [62, 99, 222], 'context': [63, 97], 'remain': [64], 'open': [65], 'research': [66, 88, 196], 'challenges.': [67], 'This': [68], 'study': [69], 'contributes': [70], 'to': [71, 198, 202, 217], 'field': [73], 'by': [74], 'conducting': [75], 'a': [76, 183], 'Systematic': [77], 'Literature': [78], 'Review': [79], 'offers': [81], 'insights': [82, 123], 'current': [85], 'state': [86], 'The': [101], 'review': [102], 'covers': [103], 'application': [104], 'fields': [105], 'user': [107], 'groups': [108], 'sheds': [110], 'light': [111], 'empirical': [113], 'methods': [114], 'tools': [116], 'used': [117], 'for': [118, 208], 'assessment.': [119], 'Moreover,': [120], 'it': [121], 'provides': [122], 'reliability': [126], 'validity': [128], 'scales,': [134], 'as': [135, 137, 145, 147], 'well': [136, 146], 'extensively': [138], 'investigating': [139], 'subconstructs': [141, 169], 'each': [143], 'item': [144], 'additional': [148], 'concepts': [149], 'concurrently': [152], 'collected.': [153], 'We': [154], 'point': [155], 'out': [156], 'that': [157], 'trust,': [161], 'privacy': [162], 'overlap': [165], 'based': [166], 'we': [170], 'identified.': [171], 'While': [172], 'majority': [174], 'studies': [176, 185], 'investigate': [177], 'one': [178], 'concepts,': [181], 'only': [182], 'few': [184], 'were': [186], 'found': [187], 'exploring': [188], 'jointly.': [194], 'Our': [195], 'aims': [197], 'inform': [199], 'directions': [201], 'develop': [203], 'use': [205], 'reliable': [206], 'scales': [207], 'users’': [209], 'contribute': [216], 'development': [219], 'trustworthy': [221]}",2024,"['Internet privacy', 'Perception', 'Psychology', 'Computer security', 'Computer science', 'Neuroscience']","Conversational AI (CAI) systems which encompass voice- and text-based assistants are on the rise and have been largely integrated into people’s everyday lives. Despite their widespread adoption, users voice concerns regarding privacy, security and trust in these systems. However, the composition of these perceptions, their impact on technology adoption and usage and the relationship between privacy, security and trust perceptions in the CAI context remain open research challenges. This study contributes to the field by conducting a Systematic Literature Review and offers insights into the current state of research on privacy, security and trust perceptions in the context of CAI systems. The review covers application fields and user groups and sheds light on empirical methods and tools used for assessment. Moreover, it provides insights into the reliability and validity of privacy, security and trust scales, as well as extensively investigating the subconstructs of each item as well as additional concepts which are concurrently collected. We point out that the perceptions of trust, privacy and security overlap based on the subconstructs we identified. While the majority of studies investigate one of these concepts, only a few studies were found exploring privacy, security and trust perceptions jointly. Our research aims to inform on directions to develop and use reliable scales for users’ privacy, security and trust perceptions and contribute to the development of trustworthy CAI systems."
https://openalex.org/W3012606812,Privacy-preserving AI Services Through Data Decentralization,"{'User': [0], 'services': [1, 53], 'increasingly': [2], 'base': [3], 'their': [4, 41], 'actions': [5], 'on': [6], 'AI': [7, 19, 83, 113, 136], 'models,': [8], 'e.g.,': [9], 'to': [10, 28, 35, 50, 55, 79, 91], 'offer': [11], 'personalized': [12, 82], 'and': [13, 68, 123, 143, 155], 'proactive': [14], 'support.': [15], 'However,': [16], 'the': [17, 56, 73, 98, 107, 153], 'underlying': [18], 'algorithms': [20, 114], 'require': [21], 'a': [22, 65, 139], 'continuous': [23], 'stream': [24], 'of': [25, 40, 58, 100, 126, 157], 'personal': [26, 92], 'data—leading': [27], 'privacy': [29], 'issues,': [30], 'as': [31, 162], 'users': [32], 'typically': [33], 'have': [34], 'share': [36], 'this': [37], 'data': [38, 78, 93], 'out': [39], 'territory.': [42], 'Current': [43], 'privacy-preserving': [44], 'concepts': [45], 'are': [46], 'either': [47], 'not': [48], 'applicable': [49], 'such': [51], 'AI-based': [52], 'or': [54], 'disadvantage': [57], 'any': [59], 'party.': [60], 'This': [61], 'paper': [62], 'presents': [63], 'PrivAI,': [64], 'new': [66, 130], 'decentralized': [67], 'privacy-by-design': [69], 'platform': [70], 'for': [71, 75, 129], 'overcoming': [72], 'need': [74], 'sharing': [76, 125], 'user': [77, 102], 'benefit': [80], 'from': [81], 'services.': [84], 'In': [85], 'short,': [86], 'PrivAI': [87, 104, 158], 'complements': [88], 'existing': [89], 'approaches': [90], 'stores,': [94], 'but': [95], 'strictly': [96], 'enforces': [97], 'confinement': [99], 'raw': [101], 'data.': [103], 'further': [105], 'addresses': [106], 'resulting': [108], 'challenges': [109], 'by': [110, 132], '(1)': [111], 'dividing': [112], 'into': [115, 138], 'cloud-based': [116], 'general': [117], 'model': [118, 127], 'training,': [119], 'subsequent': [120], 'local': [121], 'personalization,': [122], 'community-based': [124], 'updates': [128], 'users;': [131], '(2)': [133], 'loading': [134], 'confidential': [135], 'models': [137], 'trusted': [140], 'execution': [141], 'environment,': [142], 'thus,': [144], 'protecting': [145], ""provider's"": [146], 'intellectual': [147], 'property': [148], '(IP).': [149], 'Our': [150], 'experiments': [151], 'show': [152], 'feasibility': [154], 'effectiveness': [156], 'with': [159], 'comparable': [160], 'performance': [161], 'currently-practiced': [163], 'approaches.': [164]}",2020,"['Computer science', 'Personalization', 'Information privacy', 'Confidentiality', 'Cloud computing', 'Data sharing', 'Computer security', 'Raw data', 'Decentralization', 'World Wide Web', 'Internet privacy', 'Operating system', 'Law', 'Programming language', 'Pathology', 'Alternative medicine', 'Medicine', 'Political science']","User services increasingly base their actions on AI models, e.g., to offer personalized and proactive support. However, the underlying AI algorithms require a continuous stream of personal data—leading to privacy issues, as users typically have to share this data out of their territory. Current privacy-preserving concepts are either not applicable to such AI-based services or to the disadvantage of any party. This paper presents PrivAI, a new decentralized and privacy-by-design platform for overcoming the need for sharing user data to benefit from personalized AI services. In short, PrivAI complements existing approaches to personal data stores, but strictly enforces the confinement of raw user data. PrivAI further addresses the resulting challenges by (1) dividing AI algorithms into cloud-based general model training, subsequent local personalization, and community-based sharing of model updates for new users; by (2) loading confidential AI models into a trusted execution environment, and thus, protecting provider's intellectual property (IP). Our experiments show the feasibility and effectiveness of PrivAI with comparable performance as currently-practiced approaches."
https://openalex.org/W4387634936,"Deepfakes, Phrenology, Surveillance, and More! A Taxonomy of AI Privacy Risks","{'Privacy': [0], 'is': [1, 100], 'a': [2, 25, 106, 129], 'key': [3], 'principle': [4], 'for': [5], 'developing': [6], 'ethical': [7], 'AI': [8, 14, 28, 35, 47, 75, 103], 'technologies,': [9], 'but': [10], 'how': [11, 40], 'does': [12], 'including': [13], 'technologies': [15, 48, 76, 104], 'in': [16, 50], 'products': [17], 'and': [18, 44, 139], 'services': [19], 'change': [20], 'privacy': [21, 29, 36, 55, 72, 111, 133], 'risks?': [22], 'We': [23, 38, 68], 'constructed': [24], 'taxonomy': [26], 'of': [27, 46, 97, 131, 142], 'risks': [30, 73, 82, 90, 112, 134], 'by': [31], 'analyzing': [32], '321': [33], 'documented': [34], 'incidents.': [37], 'codified': [39], 'the': [41, 66, 110, 132, 137], 'unique': [42], 'capabilities': [43, 138], 'requirements': [45, 141], 'described': [49], 'those': [51], 'incidents': [52], 'generated': [53], 'new': [54], 'risks,': [56], 'exacerbated': [57, 87], 'known': [58], 'ones,': [59], 'or': [60, 86], 'otherwise': [61], 'did': [62], 'not': [63], 'meaningfully': [64], 'alter': [65, 109], 'risk.': [67], 'present': [69], '12': [70], 'high-level': [71], 'that': [74, 101], 'either': [77], 'newly': [78], 'created': [79], '(e.g.,': [80, 88, 121], 'exposure': [81], 'from': [83, 91, 136], 'deepfake': [84], 'pornography)': [85], 'surveillance': [89], 'collecting': [92], 'training': [93], 'data).': [94], 'One': [95], 'upshot': [96], 'our': [98], 'work': [99], 'incorporating': [102], 'into': [105], 'product': [107], 'can': [108], 'it': [113], 'entails.': [114], 'Yet,': [115], 'current': [116], 'approaches': [117], 'to': [118], 'privacy-preserving': [119], 'AI/ML': [120], 'federated': [122], 'learning,': [123], 'differential': [124], 'privacy,': [125], 'checklists)': [126], 'only': [127], 'address': [128], 'subset': [130], 'arising': [135], 'data': [140], 'AI.': [143]}",2023,"['Internet privacy', 'Differential privacy', 'Computer science', 'Privacy by Design', 'Information privacy', 'Privacy software', 'Computer security', 'Data science', 'Data mining']","Privacy is a key principle for developing ethical AI technologies, but how does including AI technologies in products and services change privacy risks? We constructed a taxonomy of AI privacy risks by analyzing 321 documented AI privacy incidents. We codified how the unique capabilities and requirements of AI technologies described in those incidents generated new privacy risks, exacerbated known ones, or otherwise did not meaningfully alter the risk. We present 12 high-level privacy risks that AI technologies either newly created (e.g., exposure risks from deepfake pornography) or exacerbated (e.g., surveillance risks from collecting training data). One upshot of our work is that incorporating AI technologies into a product can alter the privacy risks it entails. Yet, current approaches to privacy-preserving AI/ML (e.g., federated learning, differential privacy, checklists) only address a subset of the privacy risks arising from the capabilities and data requirements of AI."
https://openalex.org/W4405064614,Ontology for Healthcare AI Privacy in Brazil,"{'This': [0], 'article': [1], 'details': [2], 'the': [3, 11, 92], 'creation': [4], 'of': [5, 13, 68, 94, 102], 'a': [6, 22, 99], 'novel': [7], 'domain': [8], 'ontology': [9, 104], 'at': [10], 'intersection': [12], 'epidemiology,': [14], 'medicine,': [15], 'statistics,': [16], 'and': [17, 70, 88, 110], 'computer': [18], 'science.': [19], 'It': [20, 96], 'outlines': [21], 'systematic': [23], 'approach': [24], 'to': [25, 83, 108], 'handling': [26], 'structured': [27], 'data': [28, 69, 75], 'anonymously': [29], 'in': [30, 35, 40, 61, 105], 'preparation': [31], 'for': [32, 90], 'its': [33], 'use': [34], 'Artificial': [36], 'Intelligence': [37], '(AI)': [38], 'applications': [39], 'healthcare.': [41], 'The': [42], 'development': [43], 'followed': [44], '7': [45], 'steps,': [46], 'including': [47], 'defining': [48], 'scope,': [49], 'selecting': [50], 'knowledge,': [51], 'reviewing': [52], 'important': [53], 'terms,': [54], 'constructing': [55], 'classes': [56], 'that': [57, 73], 'describe': [58], 'designs': [59], 'used': [60], 'epidemiological': [62], 'studies,': [63], 'machine': [64], 'learning': [65], 'paradigms,': [66], 'types': [67], 'attributes,': [71], 'risks': [72], 'anonymized': [74], 'may': [76], 'be': [77], 'exposed': [78], 'to,': [79], 'privacy': [80, 86], 'attacks,': [81], 'techniques': [82], 'mitigate': [84], 're-identification,': [85], 'models,': [87], 'metrics': [89], 'measuring': [91], 'effects': [93], 'anonymization.': [95], 'concludes': [97], 'with': [98], 'practical': [100], 'implementation': [101], 'this': [103], 'hospital': [106], 'settings': [107], 'develop': [109], 'validate': [111], 'AI': [112], 'systems.': [113]}",2024,"['Ontology', 'Computer science', 'Scope (computer science)', 'Intersection (aeronautics)', 'Data science', 'Identification (biology)', 'Domain (mathematical analysis)', 'Health care', 'Information privacy', 'Computer security', 'Engineering', 'Philosophy', 'Aerospace engineering', 'Botany', 'Economics', 'Epistemology', 'Economic growth', 'Programming language', 'Mathematical analysis', 'Biology', 'Mathematics']","This article details the creation of a novel domain ontology at the intersection of epidemiology, medicine, statistics, and computer science. It outlines a systematic approach to handling structured data anonymously in preparation for its use in Artificial Intelligence (AI) applications in healthcare. The development followed 7 steps, including defining scope, selecting knowledge, reviewing important terms, constructing classes that describe designs used in epidemiological studies, machine learning paradigms, types of data and attributes, risks that anonymized data may be exposed to, privacy attacks, techniques to mitigate re-identification, privacy models, and metrics for measuring the effects of anonymization. It concludes with a practical implementation of this ontology in hospital settings to develop and validate AI systems."
https://openalex.org/W4391614477,"Trustworthy Distributed AI Systems: Robustness, Privacy, and Governance","{'Emerging': [0], 'Distributed': [1], 'AI': [2, 37, 53, 86, 154, 187, 191], 'systems': [3], 'are': [4, 96], 'revolutionizing': [5], 'big': [6], 'data': [7, 10, 137, 162], 'computing': [8], 'and': [9, 16, 27, 33, 47, 59, 83, 91, 123, 128, 135, 147, 152, 156, 163, 173, 194, 196], 'processing': [11], 'capabilities': [12], 'with': [13, 158, 167], 'growing': [14], 'economic': [15], 'societal': [17], 'impact.': [18], 'However,': [19], 'recent': [20], 'studies': [21], 'have': [22], 'identified': [23], 'new': [24], 'attack': [25], 'surfaces': [26], 'risks': [28], 'caused': [29], 'by': [30], 'security,': [31, 81], 'privacy,': [32, 82], 'fairness': [34, 60, 84, 155], 'issues': [35], 'in': [36, 62, 88, 98], 'systems.': [38], 'In': [39], 'this': [40], 'article,': [41], 'we': [42, 106], 'review': [43], 'representative': [44], 'techniques,': [45], 'algorithms,': [46], 'theoretical': [48], 'foundations': [49], 'for': [50, 74, 80, 113, 185], 'trustworthy': [51, 114, 178, 186], 'distributed': [52, 63, 75, 89, 99, 115, 145, 179], 'through': [54], 'robustness': [55, 119, 129], 'guarantee,': [56], 'privacy': [57, 142], 'protection,': [58], 'awareness': [61], 'learning.': [64], 'We': [65, 165], 'first': [66], 'provide': [67, 107], 'a': [68, 108, 168], 'brief': [69], 'overview': [70], 'of': [71, 85, 102, 111], 'alternative': [72], 'architectures': [73], 'learning,': [76, 90], 'discuss': [77], 'inherent': [78], 'vulnerabilities': [79], 'algorithms': [87], 'analyze': [92], 'why': [93], 'these': [94], 'problems': [95], 'present': [97], 'learning': [100, 146], 'regardless': [101], 'specific': [103], 'architectures.': [104], 'Then,': [105], 'unique': [109], 'taxonomy': [110], 'countermeasures': [112], 'AI,': [116, 180], 'covering': [117], '(1)': [118], 'to': [120, 130, 160], 'evasion': [121], 'attacks': [122], 'irregular': [124, 136], 'queries': [125], 'at': [126, 150], 'inference,': [127], 'poisoning': [131], 'attacks,': [132, 134], 'Byzantine': [133], 'distribution': [138], 'during': [139, 144], 'training;': [140], '(2)': [141], 'protection': [143], 'model': [148], 'inference': [149], 'deployment;': [151], '(3)': [153], 'governance': [157], 'respect': [159], 'both': [161], 'models.': [164], 'conclude': [166], 'discussion': [169], 'on': [170], 'open': [171], 'challenges': [172], 'future': [174], 'research': [175], 'directions': [176], 'toward': [177], 'such': [181], 'as': [182], 'the': [183, 190], 'need': [184], 'policy': [188], 'guidelines,': [189], 'responsibility-utility': [192], 'co-design,': [193], 'incentives': [195], 'compliance.': [197]}",2024,"['Computer science', 'Robustness (evolution)', 'Trustworthiness', 'Computer security', 'Distributed learning', 'Information privacy', 'Software deployment', 'Inference', 'Corporate governance', 'Incentive', 'Artificial intelligence', 'Software engineering', 'Psychology', 'Chemistry', 'Biochemistry', 'Pedagogy', 'Economics', 'Gene', 'Finance', 'Microeconomics']","Emerging Distributed AI systems are revolutionizing big data computing and data processing capabilities with growing economic and societal impact. However, recent studies have identified new attack surfaces and risks caused by security, privacy, and fairness issues in AI systems. In this article, we review representative techniques, algorithms, and theoretical foundations for trustworthy distributed AI through robustness guarantee, privacy protection, and fairness awareness in distributed learning. We first provide a brief overview of alternative architectures for distributed learning, discuss inherent vulnerabilities for security, privacy, and fairness of AI algorithms in distributed learning, and analyze why these problems are present in distributed learning regardless of specific architectures. Then, we provide a unique taxonomy of countermeasures for trustworthy distributed AI, covering (1) robustness to evasion attacks and irregular queries at inference, and robustness to poisoning attacks, Byzantine attacks, and irregular data distribution during training; (2) privacy protection during distributed learning and model inference at deployment; and (3) AI fairness and governance with respect to both data and models. We conclude with a discussion on open challenges and future research directions toward trustworthy distributed AI, such as the need for trustworthy AI policy guidelines, the AI responsibility-utility co-design, and incentives and compliance."
https://openalex.org/W4401713109,AI Privacy in Context: A Comparative Study of Public and Institutional Discourse on Conversational AI Privacy in the US and China,"{'The': [0], 'proliferation': [1], 'of': [2, 93, 110, 118], 'conversational': [3, 35], 'AI': [4, 36], 'systems,': [5], 'such': [6], 'as': [7], 'chatbots,': [8], 'has': [9], 'sparked': [10], 'widespreadprivacy': [11], 'concerns.': [12], 'Previous': [13], 'research': [14, 124], 'suggests': [15], 'that': [16], 'privacy': [17, 33, 60, 75, 85, 123], 'perceptions': [18], 'and': [19, 23, 29, 40, 44, 51, 62, 64, 87, 107], 'practices': [20], 'vary': [21], 'acrosscultures': [22], 'contexts.': [24], 'This': [25], 'study': [26, 115], 'examines': [27], 'public': [28, 79], 'institutional': [30, 97], 'discourses': [31], 'on': [32, 49, 84, 89], 'issuesregarding': [34], 'in': [37, 121], 'the': [38, 90, 104, 111], 'U.S.': [39], 'China.': [41], 'Semantic': [42], 'network': [43], 'discourse': [45, 70, 80], 'analyses': [46], 'ofprivacy-related': [47], 'discussions': [48], 'Twitter': [50], 'Weibo': [52], 'reveal': [53], 'divergent': [54], 'patterns.': [55], 'On': [56], 'Twitter,': [57], 'publicdiscourse': [58], 'emphasizes': [59], 'risks': [61, 86], 'concerns': [63], 'advocates': [65], 'for': [66], 'systemic': [67], 'changes,': [68], 'whileinstitutional': [69], 'promotes': [71], 'individualistic': [72], 'approaches': [73], 'to': [74, 125], 'protection.': [76], 'Conversely,': [77], 'onWeibo,': [78], 'is': [81], 'less': [82], 'focused': [83], 'more': [88], 'positive': [91], 'impacts': [92], 'AI,aligning': [94], 'closely': [95], 'with': [96, 103], 'narratives.': [98], 'These': [99], 'variations': [100], 'are': [101], 'intertwined': [102], 'cultural,political,': [105], 'economic,': [106], 'regulatory': [108], 'contexts': [109], 'two': [112], 'countries.': [113], 'Our': [114], 'underscores': [116], 'theimportance': [117], 'multi-level': [119], 'analysis': [120], 'comparative': [122], 'provide': [126], 'a': [127], 'holistic': [128], 'view': [129], 'ofprivacy': [130], 'dynamics.': [131]}",2024,"['China', 'Context (archaeology)', 'Information privacy', 'Internet privacy', 'Privacy policy', 'Public discourse', 'Political science', 'Public relations', 'Computer science', 'Law', 'Geography', 'Politics', 'Archaeology']","The proliferation of conversational AI systems, such as chatbots, has sparked widespreadprivacy concerns. Previous research suggests that privacy perceptions and practices vary acrosscultures and contexts. This study examines public and institutional discourses on privacy issuesregarding conversational AI in the U.S. and China. Semantic network and discourse analyses ofprivacy-related discussions on Twitter and Weibo reveal divergent patterns. On Twitter, publicdiscourse emphasizes privacy risks and concerns and advocates for systemic changes, whileinstitutional discourse promotes individualistic approaches to privacy protection. Conversely, onWeibo, public discourse is less focused on privacy risks and more on the positive impacts of AI,aligning closely with institutional narratives. These variations are intertwined with the cultural,political, economic, and regulatory contexts of the two countries. Our study underscores theimportance of multi-level analysis in comparative privacy research to provide a holistic view ofprivacy dynamics."
https://openalex.org/W4401305868,Navigating the nexus of AI and IoT: A comprehensive review of data analytics and privacy paradigms,"{'Integrating': [0], 'Artificial': [1], 'Intelligence': [2], '(AI)': [3], 'with': [4, 32, 132, 202], 'the': [5, 22, 79, 83, 101, 124, 129, 156, 161, 178, 251, 263], 'Internet': [6], 'of': [7, 28, 48, 82, 103, 128, 181, 266], 'Things': [8], '(IoT)': [9], 'has': [10, 56], 'propelled': [11], 'technological': [12], 'innovation': [13], 'across': [14], 'various': [15], 'industries.': [16], 'This': [17, 87, 139], 'systematic': [18, 137, 140], 'literature': [19, 98, 141], 'review': [20, 88, 142], 'explores': [21], 'current': [23, 157], 'state': [24], 'and': [25, 43, 99, 126, 151, 159, 170, 189, 209, 215, 223, 234, 240, 248, 257], 'future': [26, 164], 'trajectories': [27], 'AI': [29, 182, 201], 'in': [30, 39, 183, 192, 212], 'IoT,': [31, 184], 'a': [33, 109, 145, 173, 186], 'particular': [34], 'focus': [35], 'on': [36], 'emerging': [37], 'trends': [38, 169], 'intelligent': [40], 'data': [41, 54, 58, 232, 246, 258], 'analysis': [42, 197, 235], 'privacy': [44, 247], 'protection.': [45], 'The': [46, 106, 120, 167], 'proliferation': [47], 'IoT': [49, 85, 203, 231, 268], 'devices,': [50], 'marked': [51], 'by': [52, 94, 113, 236], 'voluminous': [53], 'generation,': [55], 'reshaped': [57], 'processing': [59, 233], 'methods,': [60], 'providing': [61], 'actionable': [62], 'insights': [63, 154], 'for': [64, 136, 148, 163, 176, 253], 'informed': [65], 'decision-making.': [66], 'While': [67], 'previous': [68], 'reviews': [69], 'have': [70], 'offered': [71], 'valuable': [72, 174], 'insights,': [73], 'they': [74], 'often': [75], 'must': [76], 'comprehensively': [77], 'address': [78], 'multifaceted': [80], 'dimensions': [81], 'AI-driven': [84, 267], 'landscape.': [86], 'aims': [89], 'to': [90, 116, 229, 261], 'bridge': [91], 'this': [92, 118, 193], 'gap': [93], 'systematically': [95], 'examining': [96], 'existing': [97], 'acknowledging': [100], 'limitations': [102], 'past': [104], 'studies.': [105], 'study': [107], 'uses': [108], 'meticulous': [110], 'approach': [111], 'guided': [112], 'established': [114], 'methodologies': [115], 'achieve': [117], 'aim.': [119], 'chosen': [121], 'methodology': [122], 'ensures': [123], 'rigour': [125], 'validity': [127], 'review,': [130], 'aligning': [131], 'PRISMA': [133], '2020': [134], 'guidelines': [135], 'reviews.': [138], 'serves': [143], 'as': [144], 'comprehensive': [146], 'guide': [147], 'researchers,': [149], 'practitioners,': [150], 'policymakers,': [152], 'offering': [153], 'into': [155], 'landscape': [158], 'paving': [160], 'way': [162], 'research': [165], 'directions.': [166], 'identified': [168], 'challenges': [171], 'provide': [172], 'resource': [175, 217], 'navigating': [177], 'evolving': [179], 'domain': [180], 'fostering': [185], 'balanced,': [187], 'secure,': [188], 'sustainable': [190], 'advancement': [191], 'dynamic': [194], 'field.': [195], 'Our': [196], 'shows': [198], 'that': [199], 'integrating': [200], 'improves': [204], 'operational': [205], 'efficiency,': [206], 'service': [207], 'personalisation,': [208], 'data-driven': [210], 'decisions': [211], 'healthcare,': [213], 'manufacturing,': [214], 'urban': [216], 'management.': [218], 'Real-time': [219], 'machine': [220], 'learning': [221], 'algorithms': [222], 'edge': [224], 'computing': [225], 'solutions': [226], 'are': [227], 'set': [228], 'revolutionise': [230], 'improving': [237], 'system': [238], 'responsiveness': [239], 'privacy.': [241], 'However,': [242], 'increasing': [243], 'concerns': [244], 'about': [245], 'security': [249], 'emphasise': [250], 'need': [252], 'new': [254], 'regulatory': [255], 'frameworks': [256], 'protection': [259], 'technologies': [260], 'ensure': [262], 'ethical': [264], 'adoption': [265], 'technologies.': [269]}",2024,"['Computer science', 'Data science', 'Big data', 'Analytics', 'Nexus (standard)', 'Field (mathematics)', 'Systematic review', 'Knowledge management', 'Data mining', 'Mathematics', 'Embedded system', 'Political science', 'MEDLINE', 'Pure mathematics', 'Law']","Integrating Artificial Intelligence (AI) with the Internet of Things (IoT) has propelled technological innovation across various industries. This systematic literature review explores the current state and future trajectories of AI in IoT, with a particular focus on emerging trends in intelligent data analysis and privacy protection. The proliferation of IoT devices, marked by voluminous data generation, has reshaped data processing methods, providing actionable insights for informed decision-making. While previous reviews have offered valuable insights, they often must comprehensively address the multifaceted dimensions of the AI-driven IoT landscape. This review aims to bridge this gap by systematically examining existing literature and acknowledging the limitations of past studies. The study uses a meticulous approach guided by established methodologies to achieve this aim. The chosen methodology ensures the rigour and validity of the review, aligning with PRISMA 2020 guidelines for systematic reviews. This systematic literature review serves as a comprehensive guide for researchers, practitioners, and policymakers, offering insights into the current landscape and paving the way for future research directions. The identified trends and challenges provide a valuable resource for navigating the evolving domain of AI in IoT, fostering a balanced, secure, and sustainable advancement in this dynamic field. Our analysis shows that integrating AI with IoT improves operational efficiency, service personalisation, and data-driven decisions in healthcare, manufacturing, and urban resource management. Real-time machine learning algorithms and edge computing solutions are set to revolutionise IoT data processing and analysis by improving system responsiveness and privacy. However, increasing concerns about data privacy and security emphasise the need for new regulatory frameworks and data protection technologies to ensure the ethical adoption of AI-driven IoT technologies."
https://openalex.org/W3008110138,Edge AI and Blockchain for Privacy-Critical and Data-Sensitive Applications,"{'The': [0], 'edge': [1, 72, 80], 'and': [2, 9, 20, 64, 84], 'fog': [3], 'computing': [4], 'paradigms': [5], 'enable': [6], 'more': [7, 55], 'responsive': [8], 'smarter': [10], 'systems': [11], 'without': [12], 'relying': [13], 'on': [14], 'cloud': [15], 'servers': [16], 'for': [17], 'data': [18, 77], 'processing': [19], 'storage.': [21], 'This': [22], 'reduces': [23], 'network': [24, 38, 83], 'load': [25], 'as': [26, 28], 'well': [27], 'latency.': [29], 'Nonetheless,': [30], 'the': [31, 37, 41, 49, 79, 82, 88, 92, 95], 'addition': [32], 'of': [33, 43, 51, 81, 87, 94], 'new': [34, 52], 'layers': [35], 'in': [36, 100], 'architecture': [39, 70], 'increases': [40], 'number': [42], 'security': [44], 'vulnerabilities.': [45], 'In': [46], 'privacy-critical': [47], 'systems,': [48], 'appearance': [50], 'vulnerabilities': [53], 'is': [54], 'significant.': [56], 'To': [57], 'cope': [58], 'with': [59, 71], 'this': [60], 'issue,': [61], 'we': [62], 'propose': [63], 'implement': [65], 'an': [66], 'Ethereum': [67], 'Blockchain': [68], 'based': [69], 'artificial': [73], 'intelligence': [74], 'to': [75], 'analyze': [76], 'at': [78], 'keep': [85], 'track': [86], 'parties': [89], 'that': [90], 'access': [91], 'results': [93], 'analysis,': [96], 'which': [97], 'are': [98], 'stored': [99], 'distributed': [101], 'databases.<br': [102], '/>': [103]}",2019,"['Blockchain', 'Computer science', 'Server', 'Edge computing', 'Enhanced Data Rates for GSM Evolution', 'Cloud computing', 'Architecture', 'Edge device', 'Computer network', 'Information privacy', 'Computer security', 'Latency (audio)', 'Distributed computing', 'Operating system', 'Artificial intelligence', 'Telecommunications', 'Visual arts', 'Art']","The edge and fog computing paradigms enable more responsive and smarter systems without relying on cloud servers for data processing and storage. This reduces network load as well as latency. Nonetheless, the addition of new layers in the network architecture increases the number of security vulnerabilities. In privacy-critical systems, the appearance of new vulnerabilities is more significant. To cope with this issue, we propose and implement an Ethereum Blockchain based architecture with edge artificial intelligence to analyze data at the edge of the network and keep track of the parties that access the results of the analysis, which are stored in distributed databases.<br />"
https://openalex.org/W4385154445,When AI Meets Information Privacy: The Adversarial Role of AI in Data Sharing Scenario,"{'Artificial': [0], 'intelligence': [1], '(AI)': [2], 'is': [3, 80, 90, 279], 'a': [4, 8, 41, 49, 166, 178, 233, 261, 277], 'transformative': [5], 'technology': [6], 'with': [7, 30, 63, 92, 177], 'substantial': [9], 'number': [10], 'of': [11, 73, 95, 105, 110, 131, 163, 193, 206, 211, 216, 223, 242, 269], 'practical': [12], 'applications': [13], 'in': [14, 153, 208, 271], 'commercial': [15], 'sectors': [16], 'such': [17, 118], 'as': [18, 40, 48, 119, 165, 186], 'healthcare,': [19], 'finance,': [20], 'aviation,': [21], 'and': [22, 47, 77, 98, 129, 220], 'smart': [23], 'cities.': [24], 'AI': [25, 59, 96, 164, 170, 270], 'also': [26], 'has': [27], 'strong': [28], 'synergy': [29], 'the': [31, 56, 64, 74, 84, 93, 103, 108, 132, 147, 161, 237, 240, 251, 267, 272], 'information': [32, 124, 202], 'privacy': [33, 79, 104, 125, 151, 194], '(IP)': [34], 'domain': [35], 'from': [36], 'two': [37], 'distinct': [38], 'aspects:': [39], 'protection': [42], 'tool': [43, 51, 168], '(i.e.,': [44, 52, 169], 'safeguarding': [45], 'privacy),': [46, 176], 'threat': [50, 167], 'compromising': [53], 'privacy).': [54], 'In': [55, 83, 156], 'former': [57], 'case,': [58, 86], 'techniques': [60, 67, 97], 'are': [61, 126], 'amalgamated': [62], 'traditional': [65], 'anonymization': [66, 134], 'to': [68, 101, 123, 146, 150, 172, 190, 236, 249, 265, 285], 'improve': [69], 'various': [70, 191], 'key': [71], 'components': [72], 'anonymity': [75], 'process,': [76], 'therefore,': [78], 'safeguarded': [81], 'effectively.': [82], 'latter': [85], 'some': [87, 154, 224], 'adversarial': [88], 'knowledge': [89, 117, 141, 188], 'aggregated': [91], 'help': [94], 'subsequently': [99, 247], 'used': [100, 171], 'compromise': [102, 173], 'individuals.': [106], 'To': [107], 'best': [109], 'our': [111], 'knowledge,': [112], 'threats': [113], 'posed': [114], 'by': [115], 'AI-generated': [116], 'synthetic': [120], 'data': [121, 229, 273], '(SD)': [122], 'often': [127], 'underestimated,': [128], 'most': [130], 'existing': [133], 'methods': [135], 'do': [136], 'not': [137], 'consider/model': [138], 'this': [139, 157], 'SD-based': [140], 'that': [142, 183, 230, 245], 'can': [143, 184, 199, 231, 246], 'be': [144], 'available': [145], 'adversary,': [148], 'leading': [149, 189], 'breaches': [152], 'cases.': [155], 'paper,': [158], 'we': [159], 'highlight': [160], 'role': [162], 'an': [174], 'individual&#x2019;s': [175], 'special': [179], 'focus': [180], 'on': [181, 260], 'SD': [182, 198], 'serve': [185], 'background': [187], 'kinds': [192], 'breaches.': [195], 'For': [196], 'instance,': [197], 'encompass': [200], 'pertinent': [201], '(e.g.,': [203], 'total': [204], '&#x0023;': [205], 'attributes': [207], 'data,': [209, 244], 'distributions': [210], 'sensitive': [212], 'information,': [213], 'category': [214], 'values': [215, 222], 'each': [217], 'attribute,': [218], 'minor': [219], 'major': [221], 'attributes,': [225], 'etc.)': [226], 'about': [227], 'real': [228], 'offer': [232], 'helpful': [234], 'hint': [235], 'adversary': [238], 'regarding': [239], 'composition': [241], 'anonymized': [243], 'lead': [248], 'uncovering': [250], 'identity': [252], 'or': [253, 282], 'private': [254], 'information.': [255], 'We': [256], 'perform': [257], 'reasonable': [258], 'experiments': [259], 'real-life': [262], 'benchmark': [263], 'dataset': [264], 'prove': [266], 'pitfalls': [268], 'publishing': [274], 'scenario': [275], '(when': [276], 'database': [278], 'either': [280], 'fully': [281], 'partially': [283], 'released': [284], 'public': [286], 'domains': [287], 'for': [288], 'conducting': [289], 'analytics).': [290]}",2023,"['Computer science', 'Adversary', 'Information privacy', 'Adversarial system', 'Compromise', 'Anonymity', 'Computer security', 'Information sensitivity', 'Privacy software', 'Internet privacy', 'Privacy by Design', 'Confidentiality', 'Domain knowledge', 'Data science', 'Artificial intelligence', 'Sociology', 'Social science']","Artificial intelligence (AI) is a transformative technology with a substantial number of practical applications in commercial sectors such as healthcare, finance, aviation, and smart cities. AI also has strong synergy with the information privacy (IP) domain from two distinct aspects: as a protection tool (i.e., safeguarding privacy), and as a threat tool (i.e., compromising privacy). In the former case, AI techniques are amalgamated with the traditional anonymization techniques to improve various key components of the anonymity process, and therefore, privacy is safeguarded effectively. In the latter case, some adversarial knowledge is aggregated with the help of AI techniques and subsequently used to compromise the privacy of individuals. To the best of our knowledge, threats posed by AI-generated knowledge such as synthetic data (SD) to information privacy are often underestimated, and most of the existing anonymization methods do not consider/model this SD-based knowledge that can be available to the adversary, leading to privacy breaches in some cases. In this paper, we highlight the role of AI as a threat tool (i.e., AI used to compromise an individual&#x2019;s privacy), with a special focus on SD that can serve as background knowledge leading to various kinds of privacy breaches. For instance, SD can encompass pertinent information (e.g., total &#x0023; of attributes in data, distributions of sensitive information, category values of each attribute, minor and major values of some attributes, etc.) about real data that can offer a helpful hint to the adversary regarding the composition of anonymized data, that can subsequently lead to uncovering the identity or private information. We perform reasonable experiments on a real-life benchmark dataset to prove the pitfalls of AI in the data publishing scenario (when a database is either fully or partially released to public domains for conducting analytics)."
https://openalex.org/W4200357198,Ciphertext-Policy Attribute-Based Encryption for Cloud Storage: Toward Data Privacy and Authentication in AI-Enabled IoT System,"{'People': [0], 'can': [1, 171], 'store': [2], 'their': [3], 'data': [4, 16, 18, 120], 'on': [5], 'servers': [6], 'in': [7, 106, 161, 183], 'cloud': [8, 44], 'computing': [9], 'and': [10, 92, 119, 141, 165], 'allow': [11], 'public': [12], 'users': [13], 'to': [14, 27, 40, 89], 'access': [15, 32, 47, 65, 95, 99, 135, 177], 'via': [17], 'centers.': [19], 'One': [20], 'of': [21, 34, 67, 71, 96, 163, 175, 186], 'the': [22, 31, 57, 64, 94, 107, 134, 173, 184, 201], 'most': [23], 'difficult': [24], 'tasks': [25], 'is': [26, 37, 83, 102, 155, 197], 'provide': [28, 61], 'security': [29, 62, 143, 190], 'for': [30, 63, 200], 'policy': [33, 66, 100, 136], 'data,': [35, 68], 'which': [36, 132], 'also': [38, 198], 'needed': [39], 'be': [41, 181], 'stored': [42], 'at': [43], 'servers.': [45], 'The': [46, 98, 152], 'structure': [48], '(policy)': [49], 'itself': [50], 'may': [51, 115], 'reveal': [52], 'partial': [53], 'information': [54], 'about': [55], 'what': [56], 'ciphertext': [58, 114, 195], 'contains.': [59], 'To': [60, 122], 'a': [69, 113, 129, 138, 148], 'number': [70], 'encryption': [72], 'schemes': [73, 160], 'are': [74], 'available.': [75], 'Among': [76], 'these,': [77], 'CP-ABE': [78, 109, 159], '(Ciphertext-Policy': [79], 'Attribute-Based': [80], 'Encryption)': [81], 'scheme': [82, 110], 'very': [84], 'significant': [85], 'because': [86], 'it': [87], 'helps': [88], 'protect,': [90], 'broadcast,': [91], 'control': [93, 178], 'information.': [97], 'that': [101, 179], 'sent': [103], 'as': [104], 'plaintext': [105], 'existing': [108, 158], 'along': [111], 'with': [112, 157], 'leak': [116], 'user': [117], 'privacy': [118], 'privacy.': [121], 'resolve': [123], 'this': [124], 'problem,': [125], 'we': [126, 170], 'hereby': [127], 'introduce': [128], 'new': [130], 'technique,': [131], 'hides': [133], 'using': [137, 147], 'hashing': [139], 'algorithm': [140], 'provides': [142], 'against': [144, 191], 'insider': [145], 'attack': [146], 'signature': [149], 'verification': [150], 'scheme.': [151], 'proposed': [153, 202], 'system': [154], 'compared': [156], 'terms': [162], 'computation': [164], 'expressive': [166], 'policies.': [167], 'In': [168], 'addition,': [169], 'test': [172], 'functioning': [174], 'any': [176], 'could': [180], 'implemented': [182], 'Internet': [185], 'Things': [187], '(IoT).': [188], 'Additionally,': [189], 'indistinguishable': [192], 'adaptive': [193], 'chosen': [194], 'attacks': [196], 'analyzed': [199], 'work.': [203]}",2021,"['Ciphertext', 'Attribute-based encryption', 'Computer science', 'Encryption', 'Access control', 'Cloud computing', 'Computer security', 'Semantic security', 'Access structure', 'Server', 'Plaintext', 'Client-side encryption', 'Computer network', 'On-the-fly encryption', 'Public-key cryptography', 'Cryptography', 'Secret sharing', 'Operating system']","People can store their data on servers in cloud computing and allow public users to access data via data centers. One of the most difficult tasks is to provide security for the access policy of data, which is also needed to be stored at cloud servers. The access structure (policy) itself may reveal partial information about what the ciphertext contains. To provide security for the access policy of data, a number of encryption schemes are available. Among these, CP-ABE (Ciphertext-Policy Attribute-Based Encryption) scheme is very significant because it helps to protect, broadcast, and control the access of information. The access policy that is sent as plaintext in the existing CP-ABE scheme along with a ciphertext may leak user privacy and data privacy. To resolve this problem, we hereby introduce a new technique, which hides the access policy using a hashing algorithm and provides security against insider attack using a signature verification scheme. The proposed system is compared with existing CP-ABE schemes in terms of computation and expressive policies. In addition, we can test the functioning of any access control that could be implemented in the Internet of Things (IoT). Additionally, security against indistinguishable adaptive chosen ciphertext attacks is also analyzed for the proposed work."
https://openalex.org/W4401976909,Data security and privacy concerns of AI-driven marketing in the context of economics and business field: an exploration into possible solutions,"{'Interest': [0], 'in': [1, 32, 88], 'artificial': [2], 'intelligence': [3], '(AI)': [4], 'is': [5], 'widespread': [6], 'across': [7], 'several': [8], 'industries,': [9], 'such': [10], 'as': [11], 'marketing,': [12], 'but': [13], 'worries': [14], 'about': [15], 'its': [16], 'ethical': [17], 'and': [18, 30, 35, 62, 77, 117], 'legal': [19], 'consequences': [20], 'are': [21], 'increasing.': [22], 'This': [23, 106], 'article': [24], 'examines': [25], 'concerns': [26, 66], 'regarding': [27], 'data': [28, 57, 104], 'security': [29, 75], 'privacy': [31, 69], 'AI-powered': [33], 'marketing': [34, 94], 'discusses': [36], 'possible': [37], 'remedies.': [38], 'The': [39, 51, 81], 'study': [40], 'compiles': [41], 'information': [42], 'from': [43], 'academic': [44], 'articles': [45], 'using': [46], 'a': [47], 'comprehensive': [48], 'literature': [49], 'review.': [50], 'key': [52], 'conclusions': [53], 'emphasise': [54], 'issues': [55], 'including': [56], 'confidentiality,': [58], 'distribution,': [59], 'cyberattacks,': [60], 'fraud,': [61], 'disinformation.': [63], 'Addressing': [64], 'these': [65], 'involves': [67], 'providing': [68], 'insurance,': [70], 'improving': [71], 'technology': [72], 'readiness,': [73], 'enforcing': [74], 'regulations,': [76], 'building': [78], 'regulatory': [79], 'frameworks.': [80], 'report': [82], 'emphasises': [83], 'the': [84, 89, 97, 109], 'need': [85, 98], 'for': [86, 111], 'transparency': [87], 'use': [90], 'of': [91, 103, 119], 'AI': [92], 'by': [93], 'professionals,': [95], 'highlighting': [96], 'to': [99], 'keep': [100], 'clients': [101], 'aware': [102], 'practices.': [105], 'research': [107], 'establishes': [108], 'foundation': [110], 'future': [112], 'investigation,': [113], 'encouraging': [114], 'continuous': [115], 'discussion': [116], 'examination': [118], 'this': [120], 'developing': [121], 'topic.': [122]}",2024,"['Context (archaeology)', 'Field (mathematics)', 'Information privacy', 'Marketing', 'Business', 'Consumer privacy', 'Data science', 'Computer science', 'Internet privacy', 'Biology', 'Pure mathematics', 'Mathematics', 'Paleontology']","Interest in artificial intelligence (AI) is widespread across several industries, such as marketing, but worries about its ethical and legal consequences are increasing. This article examines concerns regarding data security and privacy in AI-powered marketing and discusses possible remedies. The study compiles information from academic articles using a comprehensive literature review. The key conclusions emphasise issues including data confidentiality, distribution, cyberattacks, fraud, and disinformation. Addressing these concerns involves providing privacy insurance, improving technology readiness, enforcing security regulations, and building regulatory frameworks. The report emphasises the need for transparency in the use of AI by marketing professionals, highlighting the need to keep clients aware of data practices. This research establishes the foundation for future investigation, encouraging continuous discussion and examination of this developing topic."
https://openalex.org/W4315781024,"How AI encourages consumers to share their secrets? The role of anthropomorphism, personalisation, and privacy concerns and avenues for future research","{'Purpose': [0], 'This': [1, 40, 100, 139], 'paper': [2, 101, 124, 140], 'aims': [3], 'to': [4, 53, 82, 86, 142, 171, 179], 'explore': [5], 'the': [6, 44, 55, 129, 149], 'overall': [7], 'research': [8, 41, 56, 111, 165], 'question': [9, 57, 150], '“How': [10], 'can': [11, 62], 'artificial': [12], 'intelligence': [13], '(AI)': [14], 'influence': [15, 29, 63, 77], 'consumer': [16, 64, 78, 137, 152, 174], 'information': [17, 65, 85, 97, 153, 175], 'disclosure?”.': [18], 'It': [19, 67], 'considers': [20], 'how': [21, 60, 151], 'anthropomorphism': [22, 71], 'of': [23, 35, 72, 133], 'AI,': [24], 'personalisation': [25, 75], 'and': [26, 32, 48, 58, 74, 80, 96, 108, 121, 131, 163, 173], 'privacy': [27, 49, 91, 172], 'concerns': [28, 92], 'consumers’': [30], 'attitudes': [31, 79], 'encourage': [33], 'disclosure': [34, 154, 176], 'their': [36], 'private': [37], 'information.': [38], 'Design/methodology/approach': [39], 'draws': [42], 'upon': [43, 119, 147], 'personalisation-privacy': [45], 'paradox': [46], '(PPP)': [47], 'calculus': [50], 'theory': [51], '(PCT)': [52], 'address': [54], 'examine': [59], 'AI': [61, 73, 134], 'disclosure.': [66, 98], 'is': [68, 155], 'proposed': [69], 'that': [70], 'positively': [76], 'intentions': [81], 'disclose': [83], 'personal': [84], 'a': [87, 103, 126, 136], 'digital': [88], 'assistant,': [89], 'while': [90], 'negatively': [93], 'affect': [94], 'attitude': [95], 'Findings': [99], 'develops': [102], 'conceptual': [104], 'model': [105], 'based': [106], 'on': [107, 128, 148], 'presents': [109, 125], 'seven': [110, 161], 'propositions': [112], '(RPs)': [113], 'for': [114], 'future': [115, 164], 'research.': [116], 'Originality/value': [117], 'Building': [118], 'PPP': [120], 'PCT,': [122], 'this': [123], 'view': [127], 'benefits': [130], 'drawbacks': [132], 'from': [135], 'perspective.': [138], 'contributes': [141], 'literature': [143], 'by': [144, 157], 'critically': [145], 'reflecting': [146], 'influenced': [156], 'AI.': [158, 180], 'In': [159], 'addition,': [160], 'RPs': [162], 'areas': [166], 'are': [167], 'outlined': [168], 'in': [169, 177], 'relation': [170, 178]}",2023,"['Personalization', 'Relation (database)', 'Originality', 'Personally identifiable information', 'Perspective (graphical)', 'Private information retrieval', 'Internet privacy', 'Information privacy', 'Value (mathematics)', 'Affect (linguistics)', 'Psychology', 'Business', 'Social psychology', 'Marketing', 'Computer science', 'Computer security', 'Artificial intelligence', 'Communication', 'Creativity', 'Database', 'Machine learning']","Purpose This paper aims to explore the overall research question “How can artificial intelligence (AI) influence consumer information disclosure?”. It considers how anthropomorphism of AI, personalisation and privacy concerns influence consumers’ attitudes and encourage disclosure of their private information. Design/methodology/approach This research draws upon the personalisation-privacy paradox (PPP) and privacy calculus theory (PCT) to address the research question and examine how AI can influence consumer information disclosure. It is proposed that anthropomorphism of AI and personalisation positively influence consumer attitudes and intentions to disclose personal information to a digital assistant, while privacy concerns negatively affect attitude and information disclosure. Findings This paper develops a conceptual model based on and presents seven research propositions (RPs) for future research. Originality/value Building upon PPP and PCT, this paper presents a view on the benefits and drawbacks of AI from a consumer perspective. This paper contributes to literature by critically reflecting upon on the question how consumer information disclosure is influenced by AI. In addition, seven RPs and future research areas are outlined in relation to privacy and consumer information disclosure in relation to AI."
https://openalex.org/W3154716059,Distributed learning: a reliable privacy-preserving strategy to change multicenter collaborations using AI,"{'Distributed': [0, 33], 'learning': [1, 34], 'resulted': [2], 'in': [3], 'a': [4, 36], 'reliable': [5], 'strategy': [6], 'for': [7, 30, 39, 50], 'model': [8, 31], 'development;': [9], 'indeed,': [10], 'it': [11], 'performed': [12], 'equally': [13], 'to': [14], 'models': [15], 'trained': [16], 'on': [17], 'centralized': [18], 'datasets.': [19], 'Sensitive': [20], 'data': [21], 'can': [22], 'get': [23], 'preserved': [24], 'since': [25, 44], 'they': [26], 'are': [27, 48], 'not': [28], 'shared': [29], 'development.': [32], 'constitutes': [35], 'promising': [37], 'solution': [38], 'ML-based': [40], 'research': [41], 'and': [42], 'practice': [43], 'large,': [45], 'diverse': [46], 'datasets': [47], 'crucial': [49], 'success.': [51]}",2021,"['Machine learning', 'Computer science', 'Artificial intelligence', 'Distributed learning', 'MEDLINE', 'Classifier (UML)', 'Pedagogy', 'Political science', 'Psychology', 'Law']","Distributed learning resulted in a reliable strategy for model development; indeed, it performed equally to models trained on centralized datasets. Sensitive data can get preserved since they are not shared for model development. Distributed learning constitutes a promising solution for ML-based research and practice since large, diverse datasets are crucial for success."
https://openalex.org/W4386219844,Security and Privacy in Fog/Cloud-based IoT Systems for AI and Robotics,"{'Integration': [0], 'of': [1, 3, 30, 33, 44, 56, 102, 139, 156, 159, 165], 'Internet': [2, 158], 'Things': [4, 160], '(IoT)': [5], 'systems': [6, 66, 96, 161], 'based': [7, 69], 'on': [8], 'the': [9, 12, 22, 54, 71, 74, 89, 112, 143, 153, 163], 'fog': [10, 72], 'or': [11, 73], 'cloud': [13, 75], 'with': [14], 'Artificial': [15], 'Intelligence': [16], '(AI)': [17], 'and': [18, 47, 60, 76, 81, 107, 123, 134, 148, 168], 'Robotics': [19], 'has': [20], 'prepared': [21], 'way': [23], 'for': [24, 79, 145], 'breakthrough': [25], 'advancements': [26], 'in': [27, 42, 64, 70, 162], 'a': [28], 'variety': [29], 'different': [31], 'fields': [32], 'business.': [34], 'However,': [35], 'these': [36], 'cross-disciplinary': [37], 'technologies': [38], 'present': [39], 'significant': [40], 'difficulties': [41], 'terms': [43], 'maintaining': [45], 'confidentiality': [46], 'safeguarding': [48], 'data.': [49], 'This': [50, 84], 'article': [51], 'digs': [52], 'into': [53, 88], 'issues': [55], 'establishing': [57], 'robust': [58], 'security': [59, 104, 116, 147], 'protecting': [61], 'user': [62, 135], 'privacy': [63, 108, 149], 'IoT': [65], 'that': [67, 126], 'are': [68, 77], 'utilized': [78, 129], 'AI': [80], 'robotics': [82], 'applications.': [83], 'study': [85, 113, 141], 'gives': [86], 'insights': [87], 'possible': [90], 'hazards': [91], 'encountered': [92], 'by': [93, 97], 'such': [94], 'interconnected': [95], 'conducting': [98], 'an': [99], 'in-depth': [100], 'review': [101], 'existing': [103], 'threats,': [105], 'vulnerabilities,': [106], 'concerns.': [109], 'In': [110], 'addition,': [111], 'investigates': [114], 'cutting-edge': [115], 'mechanisms,': [117], 'encryption': [118], 'approaches,': [119], 'access': [120], 'control': [121], 'strategies,': [122], 'privacy-preserving': [124], 'solutions': [125, 150], 'can': [127], 'be': [128], 'to': [130, 151], 'safeguard': [131], 'data,': [132], 'communications,': [133], 'identities.': [136], 'The': [137], 'results': [138], 'this': [140], 'highlight': [142], 'demand': [144], 'comprehensive': [146], 'support': [152], 'mainstream': [154], 'deployment': [155], 'Fog/Cloud-based': [157], 'field': [164], 'artificial': [166], 'intelligence': [167], 'robotics.': [169]}",2023,"['Cloud computing', 'Computer security', 'Computer science', 'Software deployment', 'Robotics', 'Artificial intelligence', 'Confidentiality', 'Robot', 'Operating system']","Integration of Internet of Things (IoT) systems based on the fog or the cloud with Artificial Intelligence (AI) and Robotics has prepared the way for breakthrough advancements in a variety of different fields of business. However, these cross-disciplinary technologies present significant difficulties in terms of maintaining confidentiality and safeguarding data. This article digs into the issues of establishing robust security and protecting user privacy in IoT systems that are based in the fog or the cloud and are utilized for AI and robotics applications. This study gives insights into the possible hazards encountered by such interconnected systems by conducting an in-depth review of existing security threats, vulnerabilities, and privacy concerns. In addition, the study investigates cutting-edge security mechanisms, encryption approaches, access control strategies, and privacy-preserving solutions that can be utilized to safeguard data, communications, and user identities. The results of this study highlight the demand for comprehensive security and privacy solutions to support the mainstream deployment of Fog/Cloud-based Internet of Things systems in the field of artificial intelligence and robotics."
https://openalex.org/W3182941862,Consumer Privacy Protection With the Growth of AI-Empowered Online Shopping Based on the Evolutionary Game Model,"{'Social': [0], 'distancing': [1], 'due': [2], 'to': [3, 11, 70, 105, 177, 185, 192, 211], 'the': [4, 24, 45, 58, 81, 107, 125, 136, 138, 144, 183, 201, 219], 'COVID-19': [5], 'pandemic': [6, 17], 'has': [7], 'driven': [8], 'some': [9], 'consumers': [10, 38, 102], 'online': [12], 'shopping,': [13], 'and': [14, 19, 37, 85, 101, 115, 189, 196, 224], 'concerns': [15], 'about': [16], 'risks': [18], 'personal': [20, 160], 'hygiene': [21], 'have': [22, 66, 77], 'increased': [23], 'demand': [25], 'for': [26, 34, 167, 174], 'e-commerce.': [27], 'Providing': [28], 'personalized': [29, 42], 'recommendations': [30], 'seems': [31], 'quite': [32], 'profitable': [33, 173], 'e-commerce': [35, 99, 150, 163, 175, 222], 'platforms,': [36], 'also': [39], 'benefit': [40, 153], 'from': [41, 80, 121], 'content': [43], 'with': [44, 130, 162, 165], 'advancement': [46], 'of': [47, 83, 95, 146, 203, 206, 221], 'AI': [48, 147, 187], 'technologies.': [49], 'However,': [50], 'this': [51, 89], 'possible': [52], 'win-win': [53], 'situation': [54], 'is': [55, 103, 172], 'marred': [56], 'by': [57, 109, 181], 'increase': [59, 218], 'in': [60, 149], ""consumers'"": [61, 226], 'privacy': [62, 96], 'concerns.': [63], 'Technical': [64], 'solutions': [65], 'been': [67, 78], 'widely': [68], 'studied': [69], 'protect': [71, 225], 'consumer': [72, 213], 'privacy,': [73], 'while': [74], 'few': [75], 'analyses': [76], 'conducted': [79], 'perspective': [82], 'psychological': [84], 'behavioral': [86], 'implications.': [87], 'In': [88], 'paper,': [90], 'an': [91], 'evolutionary': [92, 116], 'game': [93], 'model': [94], 'protection': [97], 'between': [98], 'platforms': [100, 164, 176, 223], 'established': [104], 'determine': [106], 'mechanisms': [108], 'which': [110, 155, 215], 'various': [111], 'factors': [112], 'exert': [113], 'influence,': [114], 'stable': [117], 'strategies': [118], 'are': [119, 128, 141], 'obtained': [120], 'equilibrium': [122], 'points.': [123], 'Then,': [124], 'strategy': [126], 'selections': [127], 'simulated': [129], 'MATLAB': [131], '2020': [132], 'software.': [133], 'Based': [134], 'on': [135], 'results,': [137], 'following': [139], 'conclusions': [140], 'drawn:': [142], '(1)': [143], 'application': [145], 'technologies': [148, 188], 'will': [151], 'fundamentally': [152], 'consumers,': [154], 'makes': [156], 'them': [157], 'actively': [158], 'share': [159], 'information': [161], 'incentives': [166], 'generous': [168], 'rewards;': [169], '(2)': [170], 'it': [171], 'conduct': [178], 'data': [179], 'mining': [180], 'improving': [182], 'ability': [184], 'use': [186], 'making': [190], 'efforts': [191], 'reduce': [193], 'technical': [194], 'costs;': [195], '(3)': [197], 'regulators': [198], 'should': [199], 'improve': [200], 'level': [202], 'supervision': [204], 'instead': [205], 'imposing': [207], 'a': [208], 'large': [209], 'penalty': [210], 'enhance': [212], 'trust,': [214], 'could': [216], 'effectively': [217], 'profits': [220], 'privacy.': [227]}",2021,"['Cheating', 'Internet privacy', 'Incentive', 'E-commerce', 'Consumer privacy', 'Business', 'Computer science', 'Computer security', 'Information privacy', 'Economics', 'World Wide Web', 'Microeconomics', 'Social psychology', 'Psychology']","Social distancing due to the COVID-19 pandemic has driven some consumers to online shopping, and concerns about pandemic risks and personal hygiene have increased the demand for e-commerce. Providing personalized recommendations seems quite profitable for e-commerce platforms, and consumers also benefit from personalized content with the advancement of AI technologies. However, this possible win-win situation is marred by the increase in consumers' privacy concerns. Technical solutions have been widely studied to protect consumer privacy, while few analyses have been conducted from the perspective of psychological and behavioral implications. In this paper, an evolutionary game model of privacy protection between e-commerce platforms and consumers is established to determine the mechanisms by which various factors exert influence, and evolutionary stable strategies are obtained from equilibrium points. Then, the strategy selections are simulated with MATLAB 2020 software. Based on the results, the following conclusions are drawn: (1) the application of AI technologies in e-commerce will fundamentally benefit consumers, which makes them actively share personal information with e-commerce platforms with incentives for generous rewards; (2) it is profitable for e-commerce platforms to conduct data mining by improving the ability to use AI technologies and making efforts to reduce technical costs; and (3) regulators should improve the level of supervision instead of imposing a large penalty to enhance consumer trust, which could effectively increase the profits of e-commerce platforms and protect consumers' privacy."
https://openalex.org/W4392902292,Insights Into Privacy Protection Research in AI,"{'This': [0], 'paper': [1, 222], 'presents': [2], 'a': [3, 85, 150, 170, 191, 198], 'systematic': [4], 'bibliometric': [5, 39], 'analysis': [6, 58, 180], 'of': [7, 49, 107, 119, 138, 239], 'the': [8, 41, 47, 74, 81, 99, 108, 113, 120, 221, 232, 237], 'artificial': [9], 'intelligence': [10], '(AI)': [11], 'domain': [12], 'to': [13, 55, 149, 157, 182, 213], 'explore': [14], 'privacy': [15, 24, 139, 158, 216, 234], 'protection': [16], 'research': [17, 35, 141, 188, 195], 'as': [18, 71, 84], 'AI': [19, 240], 'technologies': [20], 'integrate': [21], 'and': [22, 30, 64, 67, 80, 112, 129, 155, 176, 186, 197, 202, 241], 'data': [23, 153], 'concerns': [25, 235], 'rise.': [26], 'Understanding': [27], 'evolutionary': [28], 'patterns': [29], 'current': [31], 'trends': [32], 'in': [33, 93, 127, 194, 200, 236], 'this': [34], 'is': [36, 142, 211], 'crucial.': [37], 'Leveraging': [38], 'techniques,': [40], 'authors': [42], 'analyze': [43], '8,322': [44], 'papers': [45], 'from': [46, 145], 'Web': [48], 'Science': [50], '(WoS)': [51], 'database,': [52], 'spanning': [53], '1990': [54], '2023.': [56], 'The': [57, 88, 136, 179], 'highlights': [59], 'IEEE': [60, 68], 'Transactions': [61], 'on': [62, 152], 'Knowledge': [63], 'Data': [65], 'Engineering': [66], 'Access': [69], 'journals': [70], 'highly': [72], 'influential,': [73], 'former': [75], 'being': [76], 'an': [77, 146], 'early': [78], 'contributor': [79], 'latter': [82], 'emerging': [83, 184], 'pivotal': [86, 228], 'source.': [87], 'study': [89], 'demonstrates': [90], 'substantial': [91], 'disparities': [92], 'scientific': [94, 134], 'productivity': [95], 'across': [96], 'countries.': [97], 'Specifically,': [98, 220], 'top': [100], '10': [101], 'countries': [102], 'collectively': [103], 'accounted': [104], 'for': [105, 218, 229], '74.8%': [106], 'articles,': [109], 'with': [110], 'China': [111], 'USA': [114], 'making': [115], 'up': [116], 'nearly': [117], 'half': [118], 'total': [121], 'contribution': [122], '(46.1%).': [123], 'In': [124, 164], 'contrast,': [125], 'regions': [126], 'Africa': [128], 'South': [130], 'America': [131], 'exhibited': [132], 'lower': [133], 'production.': [135], 'evolution': [137], 'preservation': [140], 'reflected,': [143], 'shifting': [144], 'algorithm-oriented': [147], 'approach': [148], 'focus': [151], 'orientation,': [154], 'subsequently,': [156], 'solutions': [159, 217], 'centered': [160], 'around': [161], 'Cloud': [162], 'Computing.': [163], 'recent': [165], 'years,': [166], 'there': [167], 'has': [168], 'been': [169], 'shift': [171], 'towards': [172], 'embracing': [173], 'Federated': [174], 'Learning': [175], 'Differential': [177], 'Privacy.': [178], 'brings': [181], 'light': [183], 'themes': [185], 'identifies': [187], 'gaps,': [189], 'notably': [190], 'global': [192], 'disparity': [193], 'output': [196], 'lag': [199], 'ethical': [201], 'legal': [203], 'inquiry.': [204], 'It': [205], 'asserts': [206], 'that': [207, 226], 'enhanced': [208], 'interdisciplinary': [209], 'collaboration': [210], 'imperative': [212], 'formulate': [214], 'comprehensive': [215], 'AI.': [219], 'imparts': [223], 'invaluable': [224], 'insights': [225], 'are': [227], 'effectively': [230], 'addressing': [231], 'evolving': [233], 'era': [238], 'big': [242], 'data.': [243]}",2024,"['Privacy protection', 'Computer science', 'Information privacy', 'Internet privacy', 'Computer security', 'Privacy software']","This paper presents a systematic bibliometric analysis of the artificial intelligence (AI) domain to explore privacy protection research as AI technologies integrate and data privacy concerns rise. Understanding evolutionary patterns and current trends in this research is crucial. Leveraging bibliometric techniques, the authors analyze 8,322 papers from the Web of Science (WoS) database, spanning 1990 to 2023. The analysis highlights IEEE Transactions on Knowledge and Data Engineering and IEEE Access journals as highly influential, the former being an early contributor and the latter emerging as a pivotal source. The study demonstrates substantial disparities in scientific productivity across countries. Specifically, the top 10 countries collectively accounted for 74.8% of the articles, with China and the USA making up nearly half of the total contribution (46.1%). In contrast, regions in Africa and South America exhibited lower scientific production. The evolution of privacy preservation research is reflected, shifting from an algorithm-oriented approach to a focus on data orientation, and subsequently, to privacy solutions centered around Cloud Computing. In recent years, there has been a shift towards embracing Federated Learning and Differential Privacy. The analysis brings to light emerging themes and identifies research gaps, notably a global disparity in research output and a lag in ethical and legal inquiry. It asserts that enhanced interdisciplinary collaboration is imperative to formulate comprehensive privacy solutions for AI. Specifically, the paper imparts invaluable insights that are pivotal for effectively addressing the evolving privacy concerns in the era of AI and big data."
https://openalex.org/W4399159256,AI-driven anonymization: Protecting personal data privacy while leveraging machine learning,"{'AbstractThe': [0], 'development': [1], 'of': [2, 25, 33, 45, 91, 109], 'artificial': [3], 'intelligence': [4, 58], 'has': [5, 12, 52], 'significantly': [6], 'transformed': [7], ""people's"": [8], 'lives.': [9], 'However,': [10], 'it': [11], 'also': [13, 118], 'posed': [14], 'a': [15, 54], 'significant': [16], 'threat': [17], 'to': [18, 41, 64, 126, 140], 'privacy': [19, 86, 102, 113, 127, 145], 'and': [20, 31, 36, 62, 67, 75, 88, 104, 128, 135, 147], 'security,': [21], 'with': [22], 'numerous': [23], 'instances': [24], 'personal': [26, 46, 69, 84, 100, 129, 143], 'information': [27, 47], 'being': [28], 'exposed': [29], 'online': [30], 'reports': [32], 'criminal': [34], 'attacks': [35], 'theft.': [37], 'Consequently,': [38], 'the': [39, 89, 107], 'need': [40], 'achieve': [42], 'intelligent': [43], 'protection': [44, 87, 103, 114], 'through': [48, 106], 'machine': [49, 110, 123], 'learning': [50, 124], 'algorithms': [51, 61], 'become': [53], 'paramount': [55], 'concern.': [56], 'Artificial': [57], 'leverages': [59], 'advanced': [60], 'technologies': [63], 'effectively': [65], 'encrypt': [66], 'anonymize': [68], 'data,': [70], 'enabling': [71], 'valuable': [72], 'data': [73, 85, 101, 130, 144], 'analysis': [74], 'utilization': [76], 'while': [77], 'safeguarding': [78], 'privacy.': [79], 'This': [80], 'paper': [81, 117], 'focuses': [82], 'on': [83], 'promotion': [90], 'anonymity': [92], 'as': [93], 'its': [94], 'core': [95], 'research': [96], 'objectives.': [97], 'It': [98], 'achieves': [99], 'detection': [105, 146], 'use': [108], ""learning's"": [111], 'differential': [112], 'algorithm.': [115], 'The': [116], 'addresses': [119], 'existing': [120], 'challenges': [121], 'in': [122], 'related': [125], 'protection,': [131], 'offers': [132], 'improvement': [133], 'suggestions,': [134], 'analyzes': [136], 'factors': [137], 'impacting': [138], 'datasets': [139], 'enable': [141], 'timely': [142], 'protection.': [148]}",2024,"['Personally identifiable information', 'Safeguarding', 'Computer science', 'Data Protection Act 1998', 'Internet privacy', 'Computer security', 'Information privacy', 'Encryption', 'Anonymity', 'Differential privacy', 'Privacy by Design', 'Privacy protection', 'Privacy software', 'Data mining', 'Nursing', 'Medicine']","AbstractThe development of artificial intelligence has significantly transformed people's lives. However, it has also posed a significant threat to privacy and security, with numerous instances of personal information being exposed online and reports of criminal attacks and theft. Consequently, the need to achieve intelligent protection of personal information through machine learning algorithms has become a paramount concern. Artificial intelligence leverages advanced algorithms and technologies to effectively encrypt and anonymize personal data, enabling valuable data analysis and utilization while safeguarding privacy. This paper focuses on personal data privacy protection and the promotion of anonymity as its core research objectives. It achieves personal data privacy protection and detection through the use of machine learning's differential privacy protection algorithm. The paper also addresses existing challenges in machine learning related to privacy and personal data protection, offers improvement suggestions, and analyzes factors impacting datasets to enable timely personal data privacy detection and protection."
https://openalex.org/W4401862241,The role of deep learning in ensuring privacy integrity and security: Applications in AI-driven cybersecurity solutions,"{'This': [0], 'article': [1, 49], 'explores': [2], 'the': [3, 52, 61, 80], 'critical': [4], 'role': [5], 'of': [6, 54, 66], 'deep': [7, 27, 89], 'learning': [8, 34, 90], 'in': [9, 45, 99], 'developing': [10], 'AI-driven': [11], 'cybersecurity': [12], 'solutions,': [13], 'with': [14], 'a': [15, 100], 'particular': [16], 'focus': [17], 'on': [18], 'privacy': [19, 97], 'integrity': [20, 98], 'and': [21, 31, 41, 64, 77, 96], 'information': [22], 'security.': [23], 'It': [24], 'investigates': [25], 'how': [26, 85], 'neural': [28], 'networks': [29], '(DNNs)': [30], 'advanced': [32], 'machine': [33], 'techniques': [35], 'are': [36], 'being': [37], 'used': [38], 'to': [39, 69, 92], 'detect': [40], 'neutralize': [42], 'cyber': [43], 'threats': [44], 'real': [46], 'time.': [47], 'The': [48], 'also': [50], 'considers': [51], 'implications': [53], 'these': [55], 'technologies': [56], 'for': [57], 'data': [58], 'privacy,': [59], 'discussing': [60], 'potential': [62], 'risks': [63], 'benefits': [65], 'using': [67], 'AI': [68], 'protect': [70], 'sensitive': [71], 'information.': [72], 'By': [73], 'examining': [74], 'case': [75], 'studies': [76], 'current': [78], 'research,': [79], 'piece': [81], 'provides': [82], 'insights': [83], 'into': [84], 'organizations': [86], 'can': [87], 'deploy': [88], 'models': [91], 'enhance': [93], 'both': [94], 'security': [95], 'digital': [101], 'world.': [102]}",2024,"['Computer security', 'Computer science', 'Data integrity', 'Internet privacy']","This article explores the critical role of deep learning in developing AI-driven cybersecurity solutions, with a particular focus on privacy integrity and information security. It investigates how deep neural networks (DNNs) and advanced machine learning techniques are being used to detect and neutralize cyber threats in real time. The article also considers the implications of these technologies for data privacy, discussing the potential risks and benefits of using AI to protect sensitive information. By examining case studies and current research, the piece provides insights into how organizations can deploy deep learning models to enhance both security and privacy integrity in a digital world."
https://openalex.org/W4388947060,"Open AI meets open notes: surveillance capitalism, patient privacy and online record access","{'Patient': [0], 'online': [1], 'record': [2], 'access': [3, 17, 24], '(ORA)': [4], 'is': [5, 18], 'spreading': [6], 'worldwide,': [7], 'and': [8, 14, 61, 78, 83, 119, 157, 194], 'in': [9, 122, 130], 'some': [10], 'countries,': [11], 'including': [12, 72, 88, 146], 'Sweden,': [13], 'the': [15, 30, 40, 117, 147, 154], 'USA,': [16], 'advanced': [19], 'with': [20, 128, 153, 189], 'patients': [21, 58], 'obtaining': [22], 'rapid': [23], 'to': [25, 54, 57, 103, 113, 137, 179], 'their': [26, 69, 80], 'full': [27], 'records.': [28], 'In': [29], 'UK': [31], 'context,': [32], 'from': [33, 67, 107], '31': [34], 'October': [35], '2023': [36], 'as': [37], 'part': [38], 'of': [39, 95, 116, 132, 150, 159, 163, 198], 'new': [41, 161], 'NHS': [42], 'England': [43], 'general': [44], 'practitioner': [45], '(GP)': [46], 'contract': [47], 'it': [48], 'will': [49], 'be': [50, 206], 'mandatory': [51], 'for': [52, 174, 201], 'GPs': [53], 'offer': [55], 'ORA': [56, 187], 'aged': [59], '16': [60], 'older.': [62], 'Patients': [63], 'report': [64], 'many': [65], 'benefits': [66, 100], 'reading': [68], 'clinical': [70], 'records': [71], 'feeling': [73], 'more': [74], 'empowered,': [75], 'better': [76, 207], 'understanding': [77], 'remembering': [79], 'treatment': [81], 'plan,': [82], 'greater': [84], 'awareness': [85], 'about': [86], 'medications': [87], 'possible': [89], 'adverse': [90], 'effects.': [91], 'However,': [92], 'a': [93, 160, 170, 196], 'variety': [94, 197], 'indirect': [96], 'evidence': [97], 'suggests': [98], 'these': [99, 203], 'are': [101], 'unlikely': [102], 'accrue': [104], 'without': [105], 'supplementation': [106], 'internet-based': [108], 'resources.': [109], 'Using': [110], 'such': [111], 'routes': [112], 'augment': [114], 'interpretation': [115], 'data': [118], 'notes': [120], 'housed': [121], 'electronic': [123], 'health': [124], 'records,': [125], 'however,': [126], 'comes': [127], 'trade-offs': [129], 'terms': [131], 'exposing': [133, 175], 'sensitive': [134, 176], 'patient': [135, 177], 'information': [136, 178], 'internet': [138, 190], 'corporations.': [139], 'Furthermore,': [140], 'increased': [141], 'work': [142], 'burdens': [143], 'on': [144], 'clinicians,': [145], 'unique': [148], 'demands': [149], 'ORA,': [151], 'combined': [152], 'easy': [155], 'availability': [156], 'capability': [158], 'generation': [162], 'large': [164], 'language': [165], 'model': [166], '(LLM)-powered': [167], 'chatbots,': [168], 'create': [169], 'perfect': [171], 'collision': [172], 'course': [173], 'private': [180], 'tech': [181], 'companies.': [182], 'This': [183], 'paper': [184], 'surveys': [185], 'how': [186, 202], 'intersects': [188], 'associated': [191], 'privacy': [192], 'risks': [193, 204], 'offers': [195], 'multilevel': [199], 'suggestions': [200], 'might': [205], 'mitigated.': [208]}",2023,"['Internet privacy', 'Variety (cybernetics)', 'Context (archaeology)', 'The Internet', 'Medicine', 'Reading (process)', 'Feeling', 'Patient portal', 'Business', 'Public relations', 'World Wide Web', 'Computer science', 'Health care', 'Psychology', 'Political science', 'Artificial intelligence', 'Law', 'Social psychology', 'Paleontology', 'Biology']","Patient online record access (ORA) is spreading worldwide, and in some countries, including Sweden, and the USA, access is advanced with patients obtaining rapid access to their full records. In the UK context, from 31 October 2023 as part of the new NHS England general practitioner (GP) contract it will be mandatory for GPs to offer ORA to patients aged 16 and older. Patients report many benefits from reading their clinical records including feeling more empowered, better understanding and remembering their treatment plan, and greater awareness about medications including possible adverse effects. However, a variety of indirect evidence suggests these benefits are unlikely to accrue without supplementation from internet-based resources. Using such routes to augment interpretation of the data and notes housed in electronic health records, however, comes with trade-offs in terms of exposing sensitive patient information to internet corporations. Furthermore, increased work burdens on clinicians, including the unique demands of ORA, combined with the easy availability and capability of a new generation of large language model (LLM)-powered chatbots, create a perfect collision course for exposing sensitive patient information to private tech companies. This paper surveys how ORA intersects with internet associated privacy risks and offers a variety of multilevel suggestions for how these risks might be better mitigated."
https://openalex.org/W4408256503,Recent Innovations in AI Privacy: Protecting Data in the Age of Machine Learning,"{'This': [0], 'comprehensive': [1], 'article': [2, 32, 52, 81], 'explores': [3], 'recent': [4], 'advancements': [5], 'in': [6, 41, 63, 71], 'privacy-preserving': [7, 24], 'technologies': [8, 36, 85], 'within': [9], 'artificial': [10], 'intelligence': [11], 'systems,': [12], 'focusing': [13], 'on': [14], 'five': [15], 'key': [16], 'approaches:': [17], 'federated': [18], 'learning,': [19], 'differential': [20], 'privacy,': [21], 'homomorphic': [22], 'encryption,': [23], 'machine': [25, 42, 77], 'learning': [26, 43, 78], '(PPML),': [27], 'and': [28, 49, 65], 'zero-knowledge': [29], 'proofs.': [30], 'The': [31, 51, 80], 'examines': [33], 'how': [34, 83], 'these': [35, 57, 84], 'address': [37], 'critical': [38], 'privacy': [39, 92], 'challenges': [40], 'environments': [44], 'while': [45, 95], 'maintaining': [46], 'model': [47], 'performance': [48], 'utility.': [50], 'highlights': [53], 'the': [54, 76, 100], 'implementation': [55], 'of': [56, 102], 'approaches': [58], 'across': [59], 'various': [60], 'domains,': [61], 'particularly': [62], 'healthcare': [64], 'financial': [66], 'services,': [67], 'demonstrating': [68], 'their': [69], 'effectiveness': [70], 'protecting': [72], 'sensitive': [73], 'data': [74, 106], 'throughout': [75], 'lifecycle.': [79], 'reveals': [82], 'complement': [86], 'each': [87], 'other': [88], 'to': [89, 98], 'create': [90], 'robust': [91], 'protection': [93], 'frameworks': [94], 'enabling': [96], 'organizations': [97], 'leverage': [99], 'power': [101], 'AI': [103], 'without': [104], 'compromising': [105], 'confidentiality.': [107]}",2025,"['Computer science', 'Internet privacy', 'Computer security', 'Information privacy', 'Data science', 'Artificial intelligence']","This comprehensive article explores recent advancements in privacy-preserving technologies within artificial intelligence systems, focusing on five key approaches: federated learning, differential privacy, homomorphic encryption, privacy-preserving machine learning (PPML), and zero-knowledge proofs. The article examines how these technologies address critical privacy challenges in machine learning environments while maintaining model performance and utility. The article highlights the implementation of these approaches across various domains, particularly in healthcare and financial services, demonstrating their effectiveness in protecting sensitive data throughout the machine learning lifecycle. The article reveals how these technologies complement each other to create robust privacy protection frameworks while enabling organizations to leverage the power of AI without compromising data confidentiality."
https://openalex.org/W4220703535,Privacy-preserving AI for future networks,"{'No': [0], 'abstract': [1], 'available.': [2]}",2022,"['Computer science', 'Computer security', 'Internet privacy', 'Artificial intelligence']",No abstract available.
https://openalex.org/W3198090163,IoT Solution for AI-Enabled PRIVACY-PREServing with Big Data Transferring: An Application for Healthcare Using Blockchain,"{'Internet': [0], 'of': [1, 36, 66, 85, 140, 188], 'Things': [2], '(IoT)': [3], 'performs': [4], 'a': [5, 120, 124], 'vital': [6], 'role': [7], 'in': [8, 44, 186], 'providing': [9], 'connectivity': [10], 'between': [11], 'computing': [12], 'devices,': [13], 'processes,': [14], 'and': [15, 23, 41, 54, 59, 76, 87, 126, 131, 147, 164, 183], 'things.': [16], 'It': [17], 'significantly': [18], 'increases': [19], 'the': [20, 31, 34, 63, 67, 92, 116, 138, 143, 152], 'communication': [21, 168], 'facilities': [22], 'giving': [24], 'up-to-date': [25], 'information': [26], 'to': [27, 56, 101, 122, 161], 'distributed': [28], 'networks.': [29], 'On': [30], 'other': [32], 'hand,': [33], 'techniques': [35], 'artificial': [37, 144], 'intelligence': [38, 145], 'offer': [39, 162], 'numerous': [40], 'valuable': [42], 'services': [43, 150], 'emerging': [45], 'fields.': [46], 'An': [47], 'IoT-based': [48], 'healthcare': [49, 153], 'solution': [50, 68, 105], 'facilitates': [51], 'patients,': [52], 'hospitals,': [53], 'professionals': [55], 'observe': [57], 'real-time': [58], 'critical': [60], 'data.': [61, 133], 'In': [62, 134], 'literature,': [64], 'most': [65], 'suffers': [69], 'from': [70], 'data': [71, 90, 111], 'intermission,': [72], 'high': [73], 'ethical': [74], 'standards,': [75], 'trustworthiness': [77], 'communication.': [78], 'Moreover,': [79], 'network': [80, 95], 'interruption': [81], 'with': [82, 109, 167, 177], 'recurrent': [83], 'expose': [84], 'sensitive': [86], 'personal': [88], 'health': [89], 'decreases': [91], 'reliance': [93], 'on': [94], 'systems.': [96], 'Therefore,': [97], 'this': [98], 'paper': [99], 'intends': [100], 'propose': [102], 'an': [103], 'IoT': [104], 'for': [106, 129, 151], 'AI-enabled': [107], 'privacy-preserving': [108], 'big': [110], 'transferring': [112], 'using': [113, 142, 170], 'blockchain.': [114, 171], 'Firstly,': [115], 'proposed': [117, 173], 'algorithm': [118, 174], 'uses': [119], 'graph-modeling': [121], 'develop': [123], 'scalable': [125], 'reliable': [127], 'system': [128], 'gathering': [130], 'transmitting': [132], 'addition,': [135], 'it': [136], 'extracts': [137], 'subset': [139], 'nodes': [141], 'approach': [146], 'achieves': [148], 'efficient': [149], 'system.': [154], 'Secondly,': [155], 'symmetric-based': [156], 'digital': [157], 'certificates': [158], 'are': [159], 'utilized': [160], 'authentic': [163], 'confidential': [165], 'transmission': [166], 'resources': [169], 'The': [172], 'is': [175], 'explored': [176], 'existing': [178], 'solutions': [179], 'through': [180], 'multiple': [181], 'simulations': [182], 'proved': [184], 'improvement': [185], 'terms': [187], 'realistic': [189], 'parameters.': [190]}",2021,"['Computer science', 'Scalability', 'Blockchain', 'Big data', 'Confidentiality', 'Internet of Things', 'Computer security', 'Distributed computing', 'Computer network', 'Data mining', 'Database']","Internet of Things (IoT) performs a vital role in providing connectivity between computing devices, processes, and things. It significantly increases the communication facilities and giving up-to-date information to distributed networks. On the other hand, the techniques of artificial intelligence offer numerous and valuable services in emerging fields. An IoT-based healthcare solution facilitates patients, hospitals, and professionals to observe real-time and critical data. In the literature, most of the solution suffers from data intermission, high ethical standards, and trustworthiness communication. Moreover, network interruption with recurrent expose of sensitive and personal health data decreases the reliance on network systems. Therefore, this paper intends to propose an IoT solution for AI-enabled privacy-preserving with big data transferring using blockchain. Firstly, the proposed algorithm uses a graph-modeling to develop a scalable and reliable system for gathering and transmitting data. In addition, it extracts the subset of nodes using the artificial intelligence approach and achieves efficient services for the healthcare system. Secondly, symmetric-based digital certificates are utilized to offer authentic and confidential transmission with communication resources using blockchain. The proposed algorithm is explored with existing solutions through multiple simulations and proved improvement in terms of realistic parameters."
https://openalex.org/W4402915134,Security and Privacy in E-Health Systems: A Review of AI and Machine Learning Techniques,"{'The': [0, 108, 188], 'adoption': [1], 'of': [2, 31, 35, 105, 132, 156, 190], 'electronic': [3], 'health': [4, 23, 83, 238], '(e-health)': [5], 'systems': [6, 160], 'has': [7], 'transformed': [8], 'healthcare': [9, 60, 231], 'delivery': [10], 'by': [11], 'harnessing': [12], 'digital': [13], 'technologies': [14], 'to': [15, 45, 168], 'enhance': [16], 'patient': [17, 179, 235], 'care,': [18], 'optimize': [19], 'operations,': [20], 'and': [21, 51, 56, 62, 98, 123, 130, 135, 144, 173, 199, 220, 229, 237], 'improve': [22], 'outcomes.': [24, 239], 'This': [25], 'paper': [26, 109, 139], 'provides': [27], 'a': [28], 'comprehensive': [29], 'overview': [30], 'the': [32, 53, 69, 102, 128, 138, 154, 223], 'current': [33], 'state': [34], 'e-health': [36, 106, 224], 'systems,': [37], 'tracing': [38], 'their': [39], 'evolution': [40], 'from': [41], 'traditional': [42], 'paper-based': [43], 'records': [44], 'advanced': [46, 90, 157], 'Electronic': [47], 'Health': [48], 'Record': [49], 'Systems(EHRs)': [50], 'examining': [52], 'diverse': [54], 'components': [55], 'applications': [57], 'that': [58, 161, 177], 'support': [59], 'providers': [61], 'patients.': [63], 'A': [64], 'key': [65], 'focus': [66], 'is': [67], 'on': [68], 'emerging': [70], 'trends': [71], 'in': [72, 87, 147], 'AI-driven': [73, 148], 'cybersecurity': [74, 149], 'for': [75, 80, 150, 186], 'e-health,': [76], 'which': [77], 'are': [78, 204], 'essential': [79], 'protecting': [81], 'sensitive': [82], 'data.': [84], 'AI&#x2019;s': [85], 'capabilities': [86], 'continuous': [88, 164], 'monitoring,': [89], 'pattern': [91], 'recognition,': [92], 'real-time': [93], 'threat': [94, 133, 158], 'response,': [95], 'predictive': [96], 'analytics,': [97], 'scalability': [99], 'fundamentally': [100], 'change': [101], 'security': [103, 115, 214], 'landscape': [104], 'systems.': [107], 'discusses': [110], 'how': [111], 'AI': [112, 175, 202], 'strengthens': [113], 'data': [114, 183, 195], 'through': [116, 163], 'techniques': [117, 176], 'like': [118], 'anomaly': [119], 'detection,': [120], 'automated': [121], 'countermeasures,': [122], 'adaptive': [124], 'learning': [125], 'algorithms,': [126], 'enhancing': [127, 234], 'efficiency': [129], 'accuracy': [131], 'detection': [134, 159], 'response.': [136], 'Furthermore,': [137], 'delves': [140], 'into': [141], 'future': [142, 171], 'directions': [143], 'research': [145, 209], 'opportunities': [146], 'e-health.': [151], 'These': [152], 'include': [153], 'development': [155, 203], 'adapt': [162], 'learning,': [165], 'quantum-resistant': [166], 'encryption': [167], 'safeguard': [169], 'against': [170], 'threats,': [172], 'privacy-preserving': [174], 'protect': [178], 'confidentiality': [180], 'while': [181], 'ensuring': [182], 'remains': [184], 'useful': [185], 'analysis.': [187], 'importance': [189], 'automating': [191], 'regulatory': [192], 'compliance,': [193], 'securing': [194], 'interoperability': [196], 'via': [197], 'blockchain,': [198], 'prioritizing': [200], 'ethical': [201, 221], 'also': [205], 'highlighted': [206], 'as': [207], 'critical': [208], 'areas.': [210], 'By': [211], 'emphasizing': [212], 'innovative': [213], 'solutions,': [215], 'collaborative': [216], 'efforts,': [217], 'ongoing': [218], 'research,': [219], 'practices,': [222], 'sector': [225], 'can': [226], 'build': [227], 'resilient': [228], 'secure': [230], 'infrastructures,': [232], 'ultimately': [233], 'care': [236]}",2024,"['Computer science', 'Computer security', 'Information privacy', 'Internet privacy']","The adoption of electronic health (e-health) systems has transformed healthcare delivery by harnessing digital technologies to enhance patient care, optimize operations, and improve health outcomes. This paper provides a comprehensive overview of the current state of e-health systems, tracing their evolution from traditional paper-based records to advanced Electronic Health Record Systems(EHRs) and examining the diverse components and applications that support healthcare providers and patients. A key focus is on the emerging trends in AI-driven cybersecurity for e-health, which are essential for protecting sensitive health data. AI&#x2019;s capabilities in continuous monitoring, advanced pattern recognition, real-time threat response, predictive analytics, and scalability fundamentally change the security landscape of e-health systems. The paper discusses how AI strengthens data security through techniques like anomaly detection, automated countermeasures, and adaptive learning algorithms, enhancing the efficiency and accuracy of threat detection and response. Furthermore, the paper delves into future directions and research opportunities in AI-driven cybersecurity for e-health. These include the development of advanced threat detection systems that adapt through continuous learning, quantum-resistant encryption to safeguard against future threats, and privacy-preserving AI techniques that protect patient confidentiality while ensuring data remains useful for analysis. The importance of automating regulatory compliance, securing data interoperability via blockchain, and prioritizing ethical AI development are also highlighted as critical research areas. By emphasizing innovative security solutions, collaborative efforts, ongoing research, and ethical practices, the e-health sector can build resilient and secure healthcare infrastructures, ultimately enhancing patient care and health outcomes."
https://openalex.org/W4283373744,Privacy-Preserving and Explainable AI in Industrial Applications,"{'The': [0], 'industrial': [1, 24, 33, 75, 156], 'environment': [2], 'has': [3, 48, 64, 94], 'gone': [4], 'through': [5], 'the': [6, 14, 32, 58, 66, 115, 124, 150, 155, 181, 184, 188], 'fourth': [7], 'revolution,': [8], 'also': [9, 123, 168], 'called': [10, 31], '“Industry': [11], '4.0”,': [12], 'where': [13], 'main': [15], 'aspect': [16], 'is': [17, 26, 106, 122], 'digitalization.': [18], 'Each': [19], 'device': [20], 'employed': [21], 'in': [22, 77, 187], 'an': [23], 'process': [25, 83], 'connected': [27], 'to': [28, 51, 73, 98, 126, 134, 149, 172], 'a': [29, 108], 'network': [30], 'Internet': [34], 'of': [35, 43, 61, 68, 101, 158], 'things': [36], '(IIOT).': [37], 'With': [38], 'IIOT': [39], 'manufacturers': [40], 'being': [41], 'capable': [42], 'tracking': [44], 'every': [45], 'device,': [46], 'it': [47, 112], 'become': [49], 'easier': [50], 'prevent': [52], 'or': [53], 'quickly': [54], 'solve': [55], 'failures.': [56], 'Specifically,': [57], 'large': [59], 'amount': [60], 'available': [62], 'data': [63, 89], 'allowed': [65], 'use': [67], 'artificial': [69], 'intelligence': [70], '(AI)': [71], 'algorithms': [72, 130], 'improve': [74], 'applications': [76], 'many': [78], 'ways': [79], '(e.g.,': [80], 'failure': [81], 'detection,': [82], 'optimization,': [84], 'and': [85, 161, 174, 178], 'abnormality': [86], 'detection).': [87], 'Although': [88], 'are': [90], 'abundant,': [91], 'their': [92], 'access': [93], 'raised': [95], 'problems': [96], 'due': [97], 'privacy': [99], 'concerns': [100], 'manufacturers.': [102], 'Censoring': [103], 'sensitive': [104], 'information': [105], 'not': [107], 'desired': [109], 'approach': [110], 'because': [111], 'negatively': [113], 'impacts': [114], 'AI': [116, 129, 176], 'performance.': [117], 'To': [118], 'increase': [119], 'trust,': [120], 'there': [121], 'need': [125], 'understand': [127], 'how': [128], 'make': [131], 'choices,': [132], 'i.e.,': [133], 'no': [135], 'longer': [136], 'regard': [137], 'them': [138], 'as': [139], 'black': [140], 'boxes.': [141], 'This': [142], 'paper': [143], 'focuses': [144], 'on': [145, 180], 'recent': [146], 'advancements': [147], 'related': [148, 171], 'challenges': [151, 163, 186], 'mentioned': [152], 'above,': [153], 'discusses': [154], 'impact': [157], 'proposed': [159], 'solutions,': [160, 177], 'identifies': [162], 'for': [164], 'future': [165], 'research.': [166], 'It': [167], 'presents': [169], 'examples': [170], 'privacy-preserving': [173], 'explainable': [175], 'comments': [179], 'interaction': [182], 'between': [183], 'identified': [185], 'conclusions.': [189]}",2022,"['Industrial Internet', 'Computer science', 'Industry 4.0', 'Process (computing)', 'Computer security', 'Risk analysis (engineering)', 'Data science', 'Internet of Things', 'Data mining', 'Business', 'Operating system']","The industrial environment has gone through the fourth revolution, also called “Industry 4.0”, where the main aspect is digitalization. Each device employed in an industrial process is connected to a network called the industrial Internet of things (IIOT). With IIOT manufacturers being capable of tracking every device, it has become easier to prevent or quickly solve failures. Specifically, the large amount of available data has allowed the use of artificial intelligence (AI) algorithms to improve industrial applications in many ways (e.g., failure detection, process optimization, and abnormality detection). Although data are abundant, their access has raised problems due to privacy concerns of manufacturers. Censoring sensitive information is not a desired approach because it negatively impacts the AI performance. To increase trust, there is also the need to understand how AI algorithms make choices, i.e., to no longer regard them as black boxes. This paper focuses on recent advancements related to the challenges mentioned above, discusses the industrial impact of proposed solutions, and identifies challenges for future research. It also presents examples related to privacy-preserving and explainable AI solutions, and comments on the interaction between the identified challenges in the conclusions."
https://openalex.org/W4200581430,Openness and privacy in born-digital archives: reflecting the role of AI development,"{'Abstract': [0], 'Galleries,': [1], 'libraries,': [2], 'archives': [3, 85, 119, 170, 219], 'and': [4, 55, 66, 94, 108, 125, 128, 138, 148, 175, 202], 'museums': [5], '(GLAMs)': [6], 'are': [7, 50, 80], 'striving': [8], 'to': [9, 13, 16, 82, 86, 89, 114, 133, 166, 193, 206, 220], 'retain': [10], 'audience': [11, 25], 'attention': [12], 'issues': [14, 109], 'related': [15], 'cultural': [17, 35], 'heritage,': [18], 'by': [19, 172], 'implementing': [20], 'various': [21], 'novel': [22], 'opportunities': [23], 'for': [24, 34, 196, 214], 'engagement': [26, 93], 'through': [27, 141], 'technological': [28], 'means': [29], 'online.': [30], 'Although': [31], 'born-digital': [32, 84, 118, 169, 218], 'assets': [33], 'heritage': [36], 'may': [37], 'have': [38], 'inundated': [39], 'the': [40, 47, 56, 59, 91, 97, 104, 115, 151, 180, 183, 187, 207, 215], 'Internet': [41], 'in': [42, 52, 164, 179], 'some': [43], 'areas,': [44], 'most': [45], 'of': [46, 58, 69, 99, 106, 110, 153, 158, 182, 210, 217], 'time': [48], 'they': [49], 'stored': [51], '“digital': [53], 'warehouses,”': [54], 'questions': [57], 'digital': [60], 'ecosystem’s': [61], 'sustainability,': [62], 'meaningful': [63], 'public': [64, 116], 'participation': [65], 'creative': [67], 'reuse': [68], 'data': [70, 107], 'still': [71], 'remain.': [72], 'Emerging': [73], 'technologies,': [74], 'such': [75], 'as': [76], 'artificial': [77], 'intelligence': [78], '(AI),': [79], 'used': [81], 'bring': [83], 'light,': [87], 'aiming': [88], 'enhance': [90], 'public’s': [92], 'participation.': [95], 'At': [96], 'core': [98], 'this': [100], 'debate': [101], 'lies': [102], 'both': [103], 'openness': [105, 137], 'privacy.': [111], 'How': [112], 'open': [113, 124], 'should': [117], 'be?': [120], 'Should': [121], 'everything': [122], 'be': [123], 'available': [126], 'online,': [127, 171], 'what': [129], 'does': [130], 'it': [131], 'take': [132], 'achieve': [134], 'balance': [135], 'between': [136], 'privacy,': [139], 'especially': [140], 'AI': [142, 159, 194], 'initiatives?': [143], 'The': [144, 156], 'study': [145], 'is': [146, 161], 'qualitative': [147], 'builds': [149], 'on': [150], 'rationale': [152], 'grounded': [154], 'theory.': [155], 'role': [157], 'development': [160, 195, 199], 'critically': [162], 'investigated': [163], 'relation': [165], 'opening': [167], 'up': [168], 'considering': [173], 'privacy': [174], 'ethics': [176], 'issues.': [177], 'Grounded': [178], 'context': [181], 'author’s': [184], 'PhD': [185], 'research,': [186], 'paper': [188], 'proposes': [189], 'a': [190], 'human-centred': [191], 'approach': [192], 'democratising': [197], 'its': [198], 'towards': [200], 'fairness': [201], 'social': [203], 'inclusion,': [204], 'contrary': [205], 'stereotypical': [208], 'cliché': [209], 'blackboxing,': [211], 'allowing': [212], 'space': [213], 'plurality': [216], 'flourish.': [221]}",2021,"['Sociology', 'Context (archaeology)', 'Internet privacy', 'Public relations', 'Grounded theory', 'Public participation', 'World Wide Web', 'Political science', 'Computer science', 'Qualitative research', 'Social science', 'Paleontology', 'Biology']","Abstract Galleries, libraries, archives and museums (GLAMs) are striving to retain audience attention to issues related to cultural heritage, by implementing various novel opportunities for audience engagement through technological means online. Although born-digital assets for cultural heritage may have inundated the Internet in some areas, most of the time they are stored in “digital warehouses,” and the questions of the digital ecosystem’s sustainability, meaningful public participation and creative reuse of data still remain. Emerging technologies, such as artificial intelligence (AI), are used to bring born-digital archives to light, aiming to enhance the public’s engagement and participation. At the core of this debate lies both the openness of data and issues of privacy. How open to the public should born-digital archives be? Should everything be open and available online, and what does it take to achieve balance between openness and privacy, especially through AI initiatives? The study is qualitative and builds on the rationale of grounded theory. The role of AI development is critically investigated in relation to opening up born-digital archives online, by considering privacy and ethics issues. Grounded in the context of the author’s PhD research, the paper proposes a human-centred approach to AI development for democratising its development towards fairness and social inclusion, contrary to the stereotypical cliché of blackboxing, allowing space for the plurality of born-digital archives to flourish."
https://openalex.org/W3186952419,Privacy-preserving AI-enabled video surveillance for social distancing: responsible design and deployment for public spaces,"{'Purpose': [0], 'The': [1, 19, 97, 113, 147], 'paper': [2, 20, 148], 'proposes': [3, 21, 154, 182], 'a': [4, 22, 67, 93, 103, 155, 167, 183, 202, 209], 'privacy-preserving': [5], 'artificial': [6, 40, 144, 189], 'intelligence-enabled': [7], 'video': [8, 192], 'surveillance': [9, 193], 'technology': [10], 'to': [11, 29, 47, 52, 71, 78, 135, 176, 186, 215], 'monitor': [12], 'social': [13, 108, 157], 'distancing': [14, 109, 158], 'in': [15, 126, 191, 205], 'public': [16], 'spaces.': [17], 'Design/methodology/approach': [18], 'new': [23], 'Responsible': [24], 'Artificial': [25], 'Intelligence': [26], 'Implementation': [27], 'Framework': [28], 'guide': [30], 'the': [31, 44, 54, 57, 63, 87, 117, 122, 136, 206, 217], 'proposed': [32, 64, 98, 218], ""solution's"": [33], 'design': [34, 184], 'and': [35, 49, 81, 85, 139, 173, 199, 222], 'development.': [36], 'It': [37], 'defines': [38], 'responsible': [39, 143, 188], 'intelligence': [41, 190], 'criteria': [42, 55], 'that': [43, 164], 'solution': [45], 'needs': [46], 'meet': [48], 'provides': [50], 'checklists': [51], 'enforce': [53], 'throughout': [56], 'process.': [58], 'To': [59], 'preserve': [60], 'data': [61, 83], 'privacy,': [62], 'system': [65, 99, 118, 161], 'incorporates': [66], 'federated': [68], 'learning': [69], 'approach': [70, 185], 'allow': [72], 'computation': [73], 'performed': [74], 'on': [75, 162], 'edge': [76, 163], 'devices': [77], 'limit': [79], 'sensitive': [80], 'identifiable': [82], 'movement': [84], 'eliminate': [86], 'dependency': [88], 'of': [89, 106, 128, 169, 208], 'cloud': [90], 'computing': [91], 'at': [92, 110, 212], 'central': [94], 'server.': [95], 'Findings': [96], 'is': [100], 'evaluated': [101], 'through': [102], 'case': [104, 123, 210], 'study': [105, 211], 'monitoring': [107], 'an': [111, 213], 'airport.': [112], 'results': [114, 198], 'discuss': [115], 'how': [116], 'can': [119], 'fully': [120], 'address': [121], ""study's"": [124], 'requirements': [125], 'terms': [127], 'its': [129, 131, 140], 'reliability,': [130], 'usefulness': [132], 'when': [133], 'deployed': [134], ""airport's"": [137], 'cameras,': [138], 'compliance': [141], 'with': [142], 'intelligence.': [145], 'Originality/value': [146], 'makes': [149], 'three': [150], 'contributions.': [151], 'First,': [152], 'it': [153, 181, 196], 'real-time': [156], 'breach': [159], 'detection': [160, 172], 'extends': [165], 'from': [166, 201], 'combination': [168], 'cutting-edge': [170], 'people': [171], 'tracking': [174], 'algorithms': [175], 'achieve': [177], 'robust': [178, 220], 'performance.': [179], 'Second,': [180], 'develop': [187], 'contexts.': [194], 'Third,': [195], 'presents': [197], 'discussion': [200], 'comprehensive': [203], 'evaluation': [204], 'context': [207], 'airport': [214], 'demonstrate': [216], ""system's"": [219], 'performance': [221], 'practical': [223], 'usefulness.': [224]}",2021,"['Computer science', 'Software deployment', 'Context (archaeology)', 'Cloud computing', 'Computer security', 'Social distance', 'Process (computing)', 'Artificial intelligence', 'Medicine', 'Pathology', 'Paleontology', 'Infectious disease (medical specialty)', 'Biology', 'Disease', 'Coronavirus disease 2019 (COVID-19)', 'Operating system']","Purpose The paper proposes a privacy-preserving artificial intelligence-enabled video surveillance technology to monitor social distancing in public spaces. Design/methodology/approach The paper proposes a new Responsible Artificial Intelligence Implementation Framework to guide the proposed solution's design and development. It defines responsible artificial intelligence criteria that the solution needs to meet and provides checklists to enforce the criteria throughout the process. To preserve data privacy, the proposed system incorporates a federated learning approach to allow computation performed on edge devices to limit sensitive and identifiable data movement and eliminate the dependency of cloud computing at a central server. Findings The proposed system is evaluated through a case study of monitoring social distancing at an airport. The results discuss how the system can fully address the case study's requirements in terms of its reliability, its usefulness when deployed to the airport's cameras, and its compliance with responsible artificial intelligence. Originality/value The paper makes three contributions. First, it proposes a real-time social distancing breach detection system on edge that extends from a combination of cutting-edge people detection and tracking algorithms to achieve robust performance. Second, it proposes a design approach to develop responsible artificial intelligence in video surveillance contexts. Third, it presents results and discussion from a comprehensive evaluation in the context of a case study at an airport to demonstrate the proposed system's robust performance and practical usefulness."
https://openalex.org/W4405021351,Generative AI model privacy: a survey,"{'Abstract': [0], 'The': [1], 'rapid': [2], 'progress': [3], 'of': [4, 17, 78, 89, 137], 'generative': [5, 60, 90, 119, 140], 'AI': [6, 61, 91, 120, 141], 'models': [7, 34], 'has': [8], 'yielded': [9], 'substantial': [10], 'breakthroughs': [11], 'in': [12, 59, 115, 134], 'AI,': [13], 'facilitating': [14], 'the': [15, 33, 79, 107, 127, 131, 135], 'generation': [16], 'realistic': [18], 'synthetic': [19], 'data': [20], 'across': [21], 'various': [22], 'modalities.': [23], 'However,': [24], 'these': [25], 'advancements': [26], 'also': [27], 'introduce': [28], 'significant': [29], 'privacy': [30, 52, 58, 138], 'risks,': [31], 'as': [32], 'may': [35], 'inadvertently': [36], 'expose': [37], 'sensitive': [38], 'information': [39], 'from': [40], 'their': [41, 102], 'training': [42], 'data.': [43], 'Currently,': [44], 'there': [45], 'is': [46], 'no': [47], 'comprehensive': [48], 'survey': [49, 84], 'work': [50], 'investigating': [51], 'issues,': [53], 'e.g.,': [54], 'attacking': [55], 'and': [56, 70, 73, 101, 113, 129, 139], 'defending': [57], 'models.': [62, 121, 142], 'We': [63], 'strive': [64], 'to': [65, 74], 'identify': [66], 'existing': [67], 'attack': [68], 'techniques': [69, 117], 'mitigation': [71], 'strategies': [72], 'offer': [75, 124], 'a': [76, 86], 'summary': [77], 'current': [80], 'research': [81, 112], 'landscape.': [82], 'Our': [83], 'encompasses': [85], 'wide': [87], 'array': [88], 'models,': [92, 95, 100], 'including': [93], 'language': [94], 'Generative': [96], 'Adversarial': [97], 'Networks,': [98], 'diffusion': [99], 'multi-modal': [103], 'counterparts.': [104], 'It': [105], 'indicates': [106], 'critical': [108], 'need': [109], 'for': [110, 118], 'continued': [111], 'development': [114], 'privacy-preserving': [116], 'Furthermore,': [122], 'we': [123], 'insights': [125], 'into': [126], 'challenges': [128], 'discuss': [130], 'open': [132], 'problems': [133], 'intersection': [136]}",2024,"['Generative grammar', 'Computer science', 'Intersection (aeronautics)', 'Generative model', 'Modalities', 'Adversarial system', 'Data science', 'Artificial intelligence', 'Machine learning', 'Sociology', 'Engineering', 'Aerospace engineering', 'Social science']","Abstract The rapid progress of generative AI models has yielded substantial breakthroughs in AI, facilitating the generation of realistic synthetic data across various modalities. However, these advancements also introduce significant privacy risks, as the models may inadvertently expose sensitive information from their training data. Currently, there is no comprehensive survey work investigating privacy issues, e.g., attacking and defending privacy in generative AI models. We strive to identify existing attack techniques and mitigation strategies and to offer a summary of the current research landscape. Our survey encompasses a wide array of generative AI models, including language models, Generative Adversarial Networks, diffusion models, and their multi-modal counterparts. It indicates the critical need for continued research and development in privacy-preserving techniques for generative AI models. Furthermore, we offer insights into the challenges and discuss the open problems in the intersection of privacy and generative AI models."
https://openalex.org/W4399530860,Privacy and Copyright Protection in Generative AI: A Lifecycle Perspective,"{'The': [0], 'advent': [1], 'of': [2, 73], 'Generative': [3, 129], 'AI': [4], 'has': [5], 'marked': [6], 'a': [7, 115], 'significant': [8], 'milestone': [9], 'in': [10, 16, 128], 'artificial': [11], 'intelligence,': [12], 'demonstrating': [13], 'remarkable': [14], 'capabilities': [15], 'generating': [17], 'realistic': [18], 'images,': [19], 'texts,': [20], 'and': [21, 34, 55, 75, 100, 118, 125], 'data': [22, 32, 56, 80, 123], 'patterns.': [23], 'However,': [24], 'these': [25, 63, 96], 'advancements': [26], 'come': [27], 'with': [28, 91], 'heightened': [29], 'concerns': [30, 97], 'over': [31], 'privacy': [33, 74, 124], 'copyright': [35, 76, 126], 'infringement,': [36], 'primarily': [37], 'due': [38], 'to': [39, 62, 113], 'the': [40, 70, 79, 107], 'reliance': [41], 'on': [42], 'vast': [43], 'datasets': [44], 'for': [45, 84], 'model': [46], 'training.': [47], 'Traditional': [48], 'approaches': [49, 86], 'like': [50], 'differential': [51], 'privacy,': [52], 'machine': [53], 'unlearning,': [54], 'poisoning': [57], 'only': [58], 'offer': [59], 'fragmented': [60], 'solutions': [61, 102], 'complex': [64], 'issues.': [65], 'Our': [66], 'paper': [67], 'delves': [68], 'into': [69], 'multifaceted': [71], 'challenges': [72], 'protection': [77], 'within': [78], 'lifecycle.': [81], 'We': [82], 'advocate': [83], 'integrated': [85], 'that': [87, 103], 'combines': [88], 'technical': [89], 'innovation': [90], 'ethical': [92], 'foresight,': [93], 'holistically': [94], 'addressing': [95], 'by': [98, 106], 'investigating': [99], 'devising': [101], 'are': [104], 'informed': [105], 'lifecycle': [108], 'perspective.': [109], 'This': [110], 'work': [111], 'aims': [112], 'catalyze': [114], 'broader': [116], 'discussion': [117], 'inspire': [119], 'concerted': [120], 'efforts': [121], 'towards': [122], 'integrity': [127], 'AI.': [130]}",2024,"['Generative grammar', 'Perspective (graphical)', 'Futures studies', 'Computer science', 'Differential privacy', 'Data Protection Act 1998', 'Milestone', 'Data science', 'Information privacy', 'Knowledge management', 'Computer security', 'Artificial intelligence', 'Data mining', 'History', 'Archaeology']","The advent of Generative AI has marked a significant milestone in artificial intelligence, demonstrating remarkable capabilities in generating realistic images, texts, and data patterns. However, these advancements come with heightened concerns over data privacy and copyright infringement, primarily due to the reliance on vast datasets for model training. Traditional approaches like differential privacy, machine unlearning, and data poisoning only offer fragmented solutions to these complex issues. Our paper delves into the multifaceted challenges of privacy and copyright protection within the data lifecycle. We advocate for integrated approaches that combines technical innovation with ethical foresight, holistically addressing these concerns by investigating and devising solutions that are informed by the lifecycle perspective. This work aims to catalyze a broader discussion and inspire concerted efforts towards data privacy and copyright integrity in Generative AI."
https://openalex.org/W4395480811,AI-powered malware detection with Differential Privacy for zero trust security in Internet of Things networks,"{'<p': [0], 'dir=""ltr"">The': [1], 'widespread': [2], 'usage': [3], 'of': [4, 10, 46, 50, 67, 122, 170, 189, 200, 248, 298, 310], 'Android-powered': [5], 'devices': [6, 22], 'in': [7, 23, 83, 182], 'the': [8, 44, 65, 129, 159, 168, 173, 187, 196, 201, 205, 291, 296, 308, 315], '<u>Internet': [9], 'Things</u>': [11], '(IoT)': [12], 'makes': [13], 'them': [14], 'susceptible': [15], 'to': [16, 98, 114, 139, 207, 235, 243, 251, 274, 289, 318], 'evolving': [17], 'cybersecurity': [18, 183], 'threats.': [19], 'Most': [20], 'healthcare': [21], 'IoT': [24, 68, 84, 156], 'networks,': [25, 85], 'such': [26], 'as': [27], 'smart': [28, 30], 'watches,': [29], 'thermometers,': [31], 'biosensors,': [32], 'and': [33, 63, 93, 191, 211, 215, 241, 301, 326], 'more,': [34], 'are': [35, 125, 261], 'powered': [36], 'by': [37, 293], 'the<u>': [38], 'Android</u>': [39], 'operating': [40], 'system,': [41], 'where': [42], 'preserving': [43], 'privacy': [45, 181, 222, 265], 'user-sensitive': [47], 'data': [48, 171], 'is': [49, 255, 314], '<u>utmost': [51], 'importance</u>.': [52], 'Detecting': [53], '<u>Android': [54, 75], 'malware': [55, 213, 256, 321], '</u>is': [56], 'thus': [57], 'vital': [58], 'for': [59, 78, 110, 155, 180, 245], 'protecting': [60], '<u>sensitive</u>': [61], 'information': [62], 'ensuring': [64], 'reliability': [66], 'networks.': [69], 'This': [70], 'article': [71, 345], 'focuses': [72], 'on': [73, 117, 323, 346], 'AI-enabled': [74], 'malware</u>': [76], 'detection': [77, 142, 174], 'improving': [79, 305], 'zero': [80, 102, 160, 192], 'trust': [81, 103, 161, 193], 'security': [82, 104, 194], 'which': [86], 'requires': [87, 106], '<u>Android</u><u>': [88], 'applications': [89, 250], '</u>to': [90], 'be': [91], 'verified': [92], 'authenticated': [94], 'before': [95], 'providing': [96], 'access': [97, 115], 'network': [99, 333], 'resources.': [100], 'The': [101], 'model': [105], 'strict': [107, 221], '<u>identity': [108], '</u>verification': [109], 'every': [111], 'entity': [112], 'trying': [113], 'resources': [116], 'a': [118, 149, 177, 330], 'private': [119], 'network,': [120], 'regardless': [121], 'whether': [123, 253], 'they': [124], 'inside': [126], 'or': [127, 257], 'outside': [128], '<u>network': [130], 'perimeter</u>.': [131], 'Our': [132], 'proposed': [133, 283], 'solution,': [134], 'DP-RFECV-FNN,': [135], 'an': [136, 230], 'innovative': [137], 'approach': [138], 'Android': [140, 249, 320], '<u>malware</u>': [141], 'that': [143], 'employs': [144], 'Differential': [145], 'Privacy': [146], '(<u>DP</u>)': [147], 'within': [148], 'Feedforward': [150], 'Neural': [151], 'Network': [152], '(<u>FNN</u>)': [153], 'designed': [154], 'networks': [157], 'under': [158, 263], 'model.': [162], 'By': [163, 185], 'integrating': [164], '<u>DP</u>,': [165], 'we': [166], 'ensure': [167], 'confidentiality': [169], 'during': [172], 'process,': [175], 'setting': [176], 'new': [178], 'standard': [179], 'solutions.': [184], 'combining': [186], 'strengths': [188], 'DP': [190], 'with': [195, 225], 'powerful': [197], 'learning': [198], 'capacity': [199], 'FNN,': [202], 'DP-RFECV-FNN': [203, 228], 'demonstrates': [204], 'ability': [206], 'identify': [208], 'both': [209, 324], 'known': [210], 'novel': [212], 'types': [214], 'achieves': [216, 229], 'higher': [217], 'accuracy': [218, 231], 'while': [219, 237, 304], 'maintaining': [220], 'controls': [223], 'compared': [224], 'recent': [226], 'papers.': [227], 'ranging': [232, 267], 'from': [233, 268], '97.78%': [234], '99.21%': [236], 'utilizing': [238], 'static': [239, 325], 'features': [240, 247, 300, 328], '93.49%': [242], '94.36%': [244], 'dynamic': [246, 327], 'detect': [252], 'it': [254], 'benign.': [258], 'These': [259], 'results': [260], 'achieved': [262], 'varying': [264], 'budgets,': [266], 'ϵ': [269, 275], '=': [270, 276], '0': [271, 279], '.': [272, 278, 280], '1': [273, 277], 'Furthermore,': [281], 'our': [282, 311], 'feature': [284], 'selection': [285], 'pipeline': [286], 'enables': [287], 'us': [288], 'outperform': [290], 'state-of-the-art': [292], 'significantly': [294], 'reducing': [295], 'number': [297], 'selected': [299], 'training': [302], 'time': [303], 'accuracy.': [306], 'To': [307], 'best': [309], 'knowledge,': [312], 'this': [313], 'first': [316], 'work': [317], 'categorize': [319], 'based': [322], 'through': [329], 'privacy-preserving': [331], '<u>neural': [332], 'model.</u>': [334], '<h2>Other': [335], 'Information</h2><p': [336], 'dir=""ltr"">Published': [337], 'in:': [338], 'Ad': [339], 'Hoc': [340], 'Networks<br>License:': [341], '<a': [342, 349], 'href=""http://creativecommons.org/licenses/by/4.0/""': [343], 'target=""_blank"">http://creativecommons.org/licenses/by/4.0/</a><br>See': [344], ""publisher's"": [347], 'website:': [348], 'href=""https://dx.doi.org/10.1016/j.adhoc.2024.103523""': [350], 'target=""_blank"">https://dx.doi.org/10.1016/j.adhoc.2024.103523</a>': [351]}",2024,"['Internet of Things', 'Computer security', 'Internet privacy', 'Malware', 'Zero (linguistics)', 'Computer science', 'Differential privacy', 'Zero-knowledge proof', 'The Internet', 'Cryptography', 'World Wide Web', 'Data mining', 'Philosophy', 'Linguistics']","<p dir=""ltr"">The widespread usage of Android-powered devices in the <u>Internet of Things</u> (IoT) makes them susceptible to evolving cybersecurity threats. Most healthcare devices in IoT networks, such as smart watches, smart thermometers, biosensors, and more, are powered by the<u> Android</u> operating system, where preserving the privacy of user-sensitive data is of <u>utmost importance</u>. Detecting <u>Android malware </u>is thus vital for protecting <u>sensitive</u> information and ensuring the reliability of IoT networks. This article focuses on AI-enabled <u>Android malware</u> detection for improving zero trust security in IoT networks, which requires <u>Android</u><u> applications </u>to be verified and authenticated before providing access to network resources. The zero trust security model requires strict <u>identity </u>verification for every entity trying to access resources on a private network, regardless of whether they are inside or outside the <u>network perimeter</u>. Our proposed solution, DP-RFECV-FNN, an innovative approach to Android <u>malware</u> detection that employs Differential Privacy (<u>DP</u>) within a Feedforward Neural Network (<u>FNN</u>) designed for IoT networks under the zero trust model. By integrating <u>DP</u>, we ensure the confidentiality of data during the detection process, setting a new standard for privacy in cybersecurity solutions. By combining the strengths of DP and zero trust security with the powerful learning capacity of the FNN, DP-RFECV-FNN demonstrates the ability to identify both known and novel malware types and achieves higher accuracy while maintaining strict privacy controls compared with recent papers. DP-RFECV-FNN achieves an accuracy ranging from 97.78% to 99.21% while utilizing static features and 93.49% to 94.36% for dynamic features of Android applications to detect whether it is malware or benign. These results are achieved under varying privacy budgets, ranging from ϵ = 0 . 1 to ϵ = 1 . 0 . Furthermore, our proposed feature selection pipeline enables us to outperform the state-of-the-art by significantly reducing the number of selected features and training time while improving accuracy. To the best of our knowledge, this is the first work to categorize Android malware based on both static and dynamic features through a privacy-preserving <u>neural network model.</u> <h2>Other Information</h2><p dir=""ltr"">Published in: Ad Hoc Networks<br>License: <a href=""http://creativecommons.org/licenses/by/4.0/"" target=""_blank"">http://creativecommons.org/licenses/by/4.0/</a><br>See article on publisher's website: <a href=""https://dx.doi.org/10.1016/j.adhoc.2024.103523"" target=""_blank"">https://dx.doi.org/10.1016/j.adhoc.2024.103523</a>"
https://openalex.org/W3138069867,How Blockchain and AI Enable Personal Data Privacy and Support Cybersecurity,"{'Recent': [0], 'increases': [1], 'in': [2, 22], 'security': [3], 'breaches': [4], 'and': [5, 14, 24, 33, 47, 65, 78, 84], 'digital': [6], 'surveillance': [7], 'highlight': [8], 'the': [9], 'need': [10], 'for': [11, 40, 75], 'improved': [12, 86], 'privacy': [13, 49], 'security,': [15, 80], 'particularly': [16], 'over': [17], 'users’': [18], 'personal': [19], 'data.': [20, 69], 'Advances': [21], 'cybersecurity': [23], 'new': [25], 'legislation': [26], 'promise': [27], 'to': [28, 63], 'improve': [29], 'data': [30, 43, 82], 'protection.': [31], 'Blockchain': [32], 'distributed': [34], 'ledger': [35], 'technologies': [36], 'provide': [37], 'novel': [38], 'opportunities': [39], 'protecting': [41], 'user': [42, 79], 'through': [44, 58], 'decentralized': [45], 'identity': [46], 'other': [48], 'mechanisms.': [50], 'These': [51], 'systems': [52], 'can': [53], 'allow': [54], 'users': [55], 'greater': [56], 'sovereignty': [57], 'tools': [59], 'that': [60], 'enable': [61], 'them': [62], 'own': [64, 68], 'control': [66], 'their': [67], 'Artificial': [70], 'intelligence': [71], 'provides': [72], 'further': [73], 'possibilities': [74], 'enhancing': [76], 'system': [77], 'enriching': [81], 'sets,': [83], 'supporting': [85], 'analytical': [87], 'models.': [88]}",2021,"['Blockchain', 'Computer security', 'Data Protection Act 1998', 'Data breach', 'Computer science', 'Information privacy', 'Internet privacy', 'Digital identity', 'Identity theft', 'Access control']","Recent increases in security breaches and digital surveillance highlight the need for improved privacy and security, particularly over users’ personal data. Advances in cybersecurity and new legislation promise to improve data protection. Blockchain and distributed ledger technologies provide novel opportunities for protecting user data through decentralized identity and other privacy mechanisms. These systems can allow users greater sovereignty through tools that enable them to own and control their own data. Artificial intelligence provides further possibilities for enhancing system and user security, enriching data sets, and supporting improved analytical models."
https://openalex.org/W4400042109,Privacy-Centric AI and IoT Solutions for Smart Rural Farm Monitoring and Control,"{'The': [0, 46, 132, 150], 'integration': [1], 'of': [2, 9, 22, 116, 142, 157, 186, 204, 212], 'artificial': [3], 'intelligence': [4], '(AI)': [5], 'and': [6, 29, 35, 43, 62, 93, 121, 124, 146, 160, 168, 178, 192], 'the': [7, 20, 87, 89, 94, 98, 101, 114, 117, 122, 126, 139, 155, 158], 'Internet': [8, 143], 'Things': [10], '(IoT)': [11], 'in': [12, 166, 207], 'agriculture': [13], 'has': [14, 25], 'significantly': [15], 'transformed': [16], 'rural': [17, 68, 171], 'farming.': [18], 'However,': [19], 'adoption': [21], 'these': [23, 50], 'technologies': [24], 'also': [26, 136], 'introduced': [27], 'privacy': [28], 'security': [30, 152], 'concerns,': [31], 'particularly': [32], 'unauthorized': [33], 'breaches': [34], 'cyber-attacks': [36], 'on': [37], 'data': [38, 84, 127], 'collected': [39], 'from': [40], 'IoT': [41, 63, 90, 118], 'devices': [42, 120], 'sensitive': [44], 'information.': [45], 'present': [47], 'study': [48], 'addresses': [49], 'concerns': [51], 'by': [52, 73, 112], 'developing': [53], 'a': [54, 75, 79, 108, 183, 193, 202, 208], 'comprehensive': [55], 'framework': [56, 76], 'that': [57, 77, 82], 'provides': [58], 'practical,': [59], 'privacy-centric': [60], 'AI': [61, 167], 'solutions': [64], 'for': [65, 106, 163, 189], 'monitoring': [66], 'smart': [67, 170], 'farms.': [69], 'This': [70], 'is': [71, 104, 135], 'performed': [72], 'designing': [74], 'includes': [78], 'three-phase': [80], 'protocol': [81, 134, 159], 'secures': [83], 'exchange': [85], 'between': [86], 'User,': [88], 'Sensor': [91, 119], 'Layer,': [92], 'Central': [95, 102], 'Server.': [96], 'In': [97], 'proposed': [99, 133], 'protocol,': [100], 'Server': [103], 'responsible': [105], 'establishing': [107], 'secure': [109], 'communication': [110], 'channel': [111], 'verifying': [113], 'legitimacy': [115], 'User': [123], 'securing': [125], 'using': [128, 138], 'rigorous': [129], 'cryptographic': [130], 'techniques.': [131], 'validated': [137], 'Automated': [140], 'Validation': [141], 'Security': [144], 'Protocols': [145], 'Applications': [147], '(AVISPA)': [148], 'tool.': [149], 'formal': [151], 'analysis': [153], 'confirms': [154], 'robustness': [156], 'its': [161], 'suitability': [162], 'real-time': [164], 'applications': [165], 'IoT-enabled': [169], 'farms,': [172], 'demonstrating': [173], 'resistance': [174], 'against': [175], 'various': [176], 'attacks': [177], 'enhanced': [179], 'performance': [180], 'metrics,': [181], 'including': [182], 'computation': [184], 'time': [185, 211], '0.04': [187], 's': [188], '11': [190], 'messages': [191], 'detailed': [194], 'search': [195, 210], 'where': [196], '119': [197], 'nodes': [198], 'were': [199], 'visited': [200], 'at': [201], 'depth': [203], '12': [205], 'plies': [206], 'mere': [209], '0.28': [213], 's.': [214]}",2024,"['Computer science', 'Computer security', 'Cryptographic protocol', 'Protocol (science)', 'Robustness (evolution)', 'Cryptography', 'Medicine', 'Gene', 'Pathology', 'Chemistry', 'Alternative medicine', 'Biochemistry']","The integration of artificial intelligence (AI) and the Internet of Things (IoT) in agriculture has significantly transformed rural farming. However, the adoption of these technologies has also introduced privacy and security concerns, particularly unauthorized breaches and cyber-attacks on data collected from IoT devices and sensitive information. The present study addresses these concerns by developing a comprehensive framework that provides practical, privacy-centric AI and IoT solutions for monitoring smart rural farms. This is performed by designing a framework that includes a three-phase protocol that secures data exchange between the User, the IoT Sensor Layer, and the Central Server. In the proposed protocol, the Central Server is responsible for establishing a secure communication channel by verifying the legitimacy of the IoT Sensor devices and the User and securing the data using rigorous cryptographic techniques. The proposed protocol is also validated using the Automated Validation of Internet Security Protocols and Applications (AVISPA) tool. The formal security analysis confirms the robustness of the protocol and its suitability for real-time applications in AI and IoT-enabled smart rural farms, demonstrating resistance against various attacks and enhanced performance metrics, including a computation time of 0.04 s for 11 messages and a detailed search where 119 nodes were visited at a depth of 12 plies in a mere search time of 0.28 s."
https://openalex.org/W4399732513,Responsible AI for cardiovascular disease detection: Towards a privacy-preserving and interpretable model,"{'Our': [0], 'study': [1], 'endorses': [2], 'a': [3, 54], 'novel': [4], 'approach': [5], 'in': [6, 42], 'predicting': [7], 'CD,': [8, 52], 'amalgamating': [9], 'data': [10], 'anonymization,': [11], 'privacy-preserving': [12], 'methods,': [13], 'interpretability': [14], 'tools': [15], 'SHAP,': [16], 'LIME,': [17], 'and': [18, 30, 38, 63], 'ethical': [19], 'considerations.': [20], 'This': [21], 'responsible': [22], 'AI': [23], 'framework': [24], 'ensures': [25], 'accurate': [26], 'predictions,': [27], 'privacy': [28], 'preservation,': [29], 'user': [31], 'trust,': [32], 'underscoring': [33], 'the': [34, 48], 'significance': [35], 'of': [36, 59], 'comprehensive': [37], 'transparent': [39], 'ML': [40], 'models': [41], 'healthcare.': [43], 'Therefore,': [44], 'this': [45], 'research': [46], 'empowers': [47], 'ability': [49], 'to': [50, 57], 'forecast': [51], 'providing': [53], 'vital': [55], 'lifeline': [56], 'millions': [58], 'CD': [60], 'patients': [61], 'globally': [62], 'potentially': [64], 'preventing': [65], 'numerous': [66], 'fatalities.': [67]}",2024,"['Computer science', 'Disease', 'Artificial intelligence', 'Patient privacy', 'Machine learning', 'Internet privacy', 'Data science', 'Medicine', 'Health care', 'Internal medicine', 'Economics', 'Economic growth']","Our study endorses a novel approach in predicting CD, amalgamating data anonymization, privacy-preserving methods, interpretability tools SHAP, LIME, and ethical considerations. This responsible AI framework ensures accurate predictions, privacy preservation, and user trust, underscoring the significance of comprehensive and transparent ML models in healthcare. Therefore, this research empowers the ability to forecast CD, providing a vital lifeline to millions of CD patients globally and potentially preventing numerous fatalities."
https://openalex.org/W4405213382,"The Ethical Implications of AI in Education: Privacy, Bias, and Accountability","{'As': [0], 'artificial': [1], 'intelligence': [2], '(AI)': [3], 'technologies': [4], 'become': [5], 'more': [6], 'prevalent': [7], 'in': [8, 29, 41], 'education,': [9], 'their': [10], 'influence': [11], 'on': [12], 'privacy,': [13, 37], 'fairness,': [14], 'and': [15, 44, 59, 74], 'responsibility': [16], 'is': [17], 'under': [18], 'increasing': [19], 'scrutiny.': [20], 'This': [21], 'paper': [22, 54], 'investigates': [23], 'the': [24, 45], 'ethical': [25, 63], 'implications': [26], 'of': [27], 'AI': [28, 42, 51, 67], 'educational': [30], 'settings,': [31], 'specifically': [32], 'examining': [33], 'concerns': [34], 'about': [35], 'student': [36], 'potential': [38], 'biases': [39], 'embedded': [40], 'systems,': [43], 'accountability': [46], 'structures': [47], 'necessary': [48], 'to': [49], 'manage': [50], 'responsibly.': [52], 'The': [53], 'advocates': [55], 'for': [56, 72], 'proactive': [57], 'policies': [58], 'practices': [60], 'that': [61, 81], 'prioritize': [62], 'standards,': [64], 'thereby': [65], 'ensuring': [66], 'serves': [68], 'as': [69], 'a': [70], 'tool': [71], 'equity': [73], 'improved': [75], 'learning': [76], 'outcomes': [77], 'rather': [78], 'than': [79], 'one': [80], 'exacerbates': [82], 'existing': [83], 'inequalities.': [84]}",2024,"['Accountability', 'Scrutiny', 'Equity (law)', 'Ethical issues', 'Engineering ethics', 'Psychology', 'Information privacy', 'Public relations', 'Political science', 'Internet privacy', 'Computer science', 'Law', 'Engineering']","As artificial intelligence (AI) technologies become more prevalent in education, their influence on privacy, fairness, and responsibility is under increasing scrutiny. This paper investigates the ethical implications of AI in educational settings, specifically examining concerns about student privacy, potential biases embedded in AI systems, and the accountability structures necessary to manage AI responsibly. The paper advocates for proactive policies and practices that prioritize ethical standards, thereby ensuring AI serves as a tool for equity and improved learning outcomes rather than one that exacerbates existing inequalities."
https://openalex.org/W4403485296,"Transparency, Privacy, and Accountability in AI-Enhanced HR Processes","{'The': [0, 70, 143], 'proliferation': [1], 'of': [2, 131, 148, 192], 'Artificial': [3], 'Intelligence': [4], '(AI)': [5], 'in': [6, 41, 82, 140, 152, 176, 194, 203, 215], 'Human': [7], 'Resource': [8], 'Management': [9], '(HRM)': [10], 'has': [11], 'transformed': [12], 'how': [13], 'organizations': [14], 'approach': [15], 'recruitment,': [16], 'performance': [17], 'evaluations,': [18], 'employee': [19], 'engagement,': [20], 'and': [21, 30, 47, 79, 86, 89, 92, 94, 115, 137, 161, 168], 'workforce': [22], 'planning.': [23], 'Despite': [24], 'AI’s': [25], 'potential': [26], 'to': [27, 64, 187, 207], 'improve': [28], 'efficiency': [29], 'reduce': [31], 'human': [32], 'biases,': [33], 'it': [34], 'also': [35, 97], 'introduces': [36], 'significant': [37], 'ethical': [38, 104, 132, 150, 190], 'challenges,': [39], 'particularly': [40], 'areas': [42], 'such': [43], 'as': [44], 'fairness,': [45], 'transparency,': [46], 'privacy.': [48], 'This': [49, 170], 'study': [50], 'develops': [51], 'a': [52, 124, 174], 'comprehensive': [53], 'theoretical': [54], 'framework': [55, 71, 202], 'that': [56, 154], 'equips': [57], 'HR': [58, 185], 'managers': [59, 186], 'with': [60, 117, 158], 'the': [61, 128, 146, 177, 189], 'competencies': [62, 105], 'necessary': [63], 'ethically': [65], 'govern': [66], 'AI-augmented': [67, 141], 'HRM': [68], 'processes.': [69], 'focuses': [72], 'on': [73, 134, 212], 'five': [74], 'key': [75], 'areas:': [76], 'bias': [77, 136], 'detection': [78], 'mitigation,': [80], 'fairness': [81, 139], 'AI-driven': [83], 'decisions,': [84], 'transparency': [85], 'explainability,': [87], 'privacy': [88], 'data': [90], 'protection,': [91], 'accountability': [93], 'oversight.': [95], 'It': [96], 'provides': [98], 'actionable': [99], 'strategies': [100], 'for': [101, 184], 'integrating': [102], 'these': [103], 'into': [106], 'organizational': [107, 159, 205], 'AI': [108, 118, 155, 193, 213], 'governance': [109, 133, 151, 214], 'through': [110], 'continuous': [111], 'training,': [112], 'policy': [113], 'development,': [114], 'collaboration': [116], 'specialists.': [119], 'Theoretical': [120], 'analysis,': [121], 'supported': [122], 'by': [123, 180], 'probability': [125], 'model,': [126], 'demonstrates': [127], 'positive': [129], 'impact': [130, 211], 'mitigating': [135], 'promoting': [138], 'decision-making.': [142], 'findings': [144], 'highlight': [145], 'importance': [147], 'proactive': [149], 'ensuring': [153], 'systems': [156], 'align': [157], 'values': [160], 'legal': [162], 'standards,': [163], 'fostering': [164], 'trust': [165], 'among': [166], 'employees': [167], 'stakeholders.': [169], 'paper’s': [171], 'contributions': [172], 'fill': [173], 'gap': [175], 'current': [178], 'literature': [179], 'offering': [181], 'practical': [182], 'guidance': [183], 'navigate': [188], 'complexities': [191], 'HRM.': [195, 216], 'Future': [196], 'research': [197], 'should': [198], 'empirically': [199], 'test': [200], 'this': [201], 'various': [204], 'contexts': [206], 'assess': [208], 'its': [209], 'long-term': [210]}",2024,"['Transparency (behavior)', 'Accountability', 'Internet privacy', 'Computer science', 'Information privacy', 'Business', 'Computer security', 'Political science', 'Law']","The proliferation of Artificial Intelligence (AI) in Human Resource Management (HRM) has transformed how organizations approach recruitment, performance evaluations, employee engagement, and workforce planning. Despite AI’s potential to improve efficiency and reduce human biases, it also introduces significant ethical challenges, particularly in areas such as fairness, transparency, and privacy. This study develops a comprehensive theoretical framework that equips HR managers with the competencies necessary to ethically govern AI-augmented HRM processes. The framework focuses on five key areas: bias detection and mitigation, fairness in AI-driven decisions, transparency and explainability, privacy and data protection, and accountability and oversight. It also provides actionable strategies for integrating these ethical competencies into organizational AI governance through continuous training, policy development, and collaboration with AI specialists. Theoretical analysis, supported by a probability model, demonstrates the positive impact of ethical governance on mitigating bias and promoting fairness in AI-augmented decision-making. The findings highlight the importance of proactive ethical governance in ensuring that AI systems align with organizational values and legal standards, fostering trust among employees and stakeholders. This paper’s contributions fill a gap in the current literature by offering practical guidance for HR managers to navigate the ethical complexities of AI in HRM. Future research should empirically test this framework in various organizational contexts to assess its long-term impact on AI governance in HRM."
https://openalex.org/W4392271008,AI-Driven Anonymization: Protecting Personal Data Privacy While Leveraging Machine Learning,"{'The': [0, 116], 'development': [1], 'of': [2, 25, 33, 45, 91, 109], 'artificial': [3], 'intelligence': [4, 58], 'has': [5, 12, 52], 'significantly': [6], 'transformed': [7], ""people's"": [8], 'lives.': [9], 'However,': [10], 'it': [11], 'also': [13, 118], 'posed': [14], 'a': [15, 54], 'significant': [16], 'threat': [17], 'to': [18, 41, 64, 126, 140], 'privacy': [19, 86, 102, 113, 127, 145], 'and': [20, 31, 36, 62, 67, 75, 88, 104, 128, 135, 147], 'security,': [21], 'with': [22], 'numerous': [23], 'instances': [24], 'personal': [26, 46, 69, 84, 100, 129, 143], 'information': [27, 47], 'being': [28], 'exposed': [29], 'online': [30], 'reports': [32], 'criminal': [34], 'attacks': [35], 'theft.': [37], 'Consequently,': [38], 'the': [39, 89, 107], 'need': [40], 'achieve': [42], 'intelligent': [43], 'protection': [44, 87, 103, 114], 'through': [48, 106], 'machine': [49, 110, 123], 'learning': [50, 124], 'algorithms': [51, 61], 'become': [53], 'paramount': [55], 'concern.': [56], 'Artificial': [57], 'leverages': [59], 'advanced': [60], 'technologies': [63], 'effectively': [65], 'encrypt': [66], 'anonymize': [68], 'data,': [70], 'enabling': [71], 'valuable': [72], 'data': [73, 85, 101, 130, 144], 'analysis': [74], 'utilization': [76], 'while': [77], 'safeguarding': [78], 'privacy.': [79], 'This': [80], 'paper': [81, 117], 'focuses': [82], 'on': [83], 'promotion': [90], 'anonymity': [92], 'as': [93], 'its': [94], 'core': [95], 'research': [96], 'objectives.': [97], 'It': [98], 'achieves': [99], 'detection': [105, 146], 'use': [108], ""learning's"": [111], 'differential': [112], 'algorithm.': [115], 'addresses': [119], 'existing': [120], 'challenges': [121], 'in': [122], 'related': [125], 'protection,': [131], 'offers': [132], 'improvement': [133], 'suggestions,': [134], 'analyzes': [136], 'factors': [137], 'impacting': [138], 'datasets': [139], 'enable': [141], 'timely': [142], 'protection.': [148]}",2024,"['Computer science', 'Internet privacy', 'Computer security', 'Data anonymization', 'Information privacy', 'Privacy protection']","The development of artificial intelligence has significantly transformed people's lives. However, it has also posed a significant threat to privacy and security, with numerous instances of personal information being exposed online and reports of criminal attacks and theft. Consequently, the need to achieve intelligent protection of personal information through machine learning algorithms has become a paramount concern. Artificial intelligence leverages advanced algorithms and technologies to effectively encrypt and anonymize personal data, enabling valuable data analysis and utilization while safeguarding privacy. This paper focuses on personal data privacy protection and the promotion of anonymity as its core research objectives. It achieves personal data privacy protection and detection through the use of machine learning's differential privacy protection algorithm. The paper also addresses existing challenges in machine learning related to privacy and personal data protection, offers improvement suggestions, and analyzes factors impacting datasets to enable timely personal data privacy detection and protection."
https://openalex.org/W4296349771,No secrets between the two of us: Privacy concerns over using AI agents.,"{'The': [0, 88, 116], 'diverse': [1], 'spread': [2], 'of': [3, 10, 30, 68, 136, 166], 'artificial': [4], 'intelligence': [5], '(AI)': [6], 'agents': [7, 21], 'provides': [8], 'evidence': [9], 'the': [11, 16, 43, 55, 63, 133, 143, 164], 'most': [12], 'notable': [13], 'changes': [14], 'in': [15, 163], 'current': [17], 'media': [18], 'landscape.': [19], 'AI': [20, 48, 105, 156], 'mostly': [22], 'function': [23], 'based': [24], 'on': [25, 142], 'voluntary': [26], 'and': [27, 73, 78, 113, 123, 139, 151], 'involuntary': [28], 'sharing': [29], 'users’': [31, 35, 127], 'personal': [32], 'information.': [33], 'Accordingly,': [34], 'privacy': [36, 76, 128, 152, 161], 'concerns': [37, 77, 153, 162], 'have': [38], 'become': [39], 'key': [40], 'to': [41, 61, 79, 102], 'understanding': [42], 'varied': [44], 'psychological': [45], 'responses': [46], 'towards': [47], 'agents.': [49, 157], 'In': [50], 'this': [51, 86, 99], 'study,': [52], 'we': [53], 'adopt': [54], '“computers': [56], 'are': [57, 169], 'social': [58, 74, 121, 149], 'actors”': [59], 'paradigm': [60], 'identify': [62], 'association': [64], 'between': [65, 145], 'a': [66, 82], 'set': [67], 'relational': [69], 'variables—intimacy,': [70], 'para-social': [71, 147], 'interactions,': [72], 'presence—and': [75], 'determine': [80], 'whether': [81], 'user’s': [83], 'motivations': [84], 'moderate': [85], 'relationship.': [87], 'results': [89, 117, 131], 'from': [90], 'an': [91], 'online': [92], 'survey': [93], '(N': [94], '=': [95], '562)': [96], 'revealed': [97], 'that': [98, 120], 'occurs': [100], 'primarily': [101], 'gratify': [103], 'three': [104], 'agent': [106], 'user': [107], 'needs:': [108], 'entertainment': [109, 138], 'motivation,': [110, 112], 'instrumental': [111, 140], 'passing': [114], 'time.': [115], 'also': [118], 'confirmed': [119], 'presence': [122], 'intimacy': [124], 'significantly': [125], 'influence': [126], 'concerns.': [129], 'These': [130], 'support': [132], 'moderating': [134], 'effect': [135], 'both': [137], 'motivation': [141], 'relationship': [144], 'intimacy,': [146], 'interaction,': [148], 'presence,': [150], 'about': [154], 'using': [155], 'Further': [158], 'implications': [159], 'for': [160], 'context': [165], 'AI-mediated': [167], 'communications': [168], 'discussed.': [170]}",2022,"['Internet privacy', 'Entertainment', 'Set (abstract data type)', 'Context (archaeology)', 'Psychology', 'Social media', 'Social psychology', 'Function (biology)', 'Computer science', 'World Wide Web', 'Political science', 'Evolutionary biology', 'Paleontology', 'Biology', 'Programming language', 'Law']","The diverse spread of artificial intelligence (AI) agents provides evidence of the most notable changes in the current media landscape. AI agents mostly function based on voluntary and involuntary sharing of users’ personal information. Accordingly, users’ privacy concerns have become key to understanding the varied psychological responses towards AI agents. In this study, we adopt the “computers are social actors” paradigm to identify the association between a set of relational variables—intimacy, para-social interactions, and social presence—and privacy concerns and to determine whether a user’s motivations moderate this relationship. The results from an online survey (N = 562) revealed that this occurs primarily to gratify three AI agent user needs: entertainment motivation, instrumental motivation, and passing time. The results also confirmed that social presence and intimacy significantly influence users’ privacy concerns. These results support the moderating effect of both entertainment and instrumental motivation on the relationship between intimacy, para-social interaction, social presence, and privacy concerns about using AI agents. Further implications for privacy concerns in the context of AI-mediated communications are discussed."
https://openalex.org/W4375957465,An Overview of AI and Blockchain Integration for Privacy-Preserving,"{'With': [0], 'the': [1, 76, 101, 132], 'widespread': [2], 'attention': [3], 'and': [4, 10, 36, 48, 72, 96, 103, 114, 124, 142, 148], 'application': [5, 63, 122], 'of': [6, 21, 29, 38, 46, 82, 135, 157], 'artificial': [7], 'intelligence': [8], '(AI)': [9], 'blockchain': [11, 143], 'technologies,': [12], 'privacy': [13, 28, 56, 84, 116, 136, 155], 'protection': [14, 57, 85, 117, 137, 156], 'techniques': [15, 32, 118], 'arising': [16], 'from': [17, 140], 'their': [18, 51, 104], 'integration': [19], 'are': [20], 'notable': [22], 'significance.': [23], 'In': [24, 127], 'addition': [25], 'to': [26, 150], 'protecting': [27], 'individuals,': [30], 'these': [31], 'also': [33, 112], 'guarantee': [34], 'security': [35, 149], 'dependability': [37], 'data.': [39], 'This': [40, 110], 'paper': [41, 77, 130], 'initially': [42], 'presents': [43], 'an': [44], 'overview': [45], 'AI': [47, 141], 'blockchain,': [49], 'summarizing': [50], 'combination': [52], 'along': [53], 'with': [54], 'derived': [55], 'technologies.': [58], 'It': [59], 'then': [60], 'explores': [61], 'specific': [62], 'scenarios': [64, 123], 'in': [65], 'data': [66, 92], 'encryption,': [67], 'de-identification,': [68], 'multi-tier': [69], 'distributed': [70], 'ledgers,': [71], 'k-anonymity': [73], 'methods.': [74], 'Moreover,': [75], 'evaluates': [78], 'five': [79], 'critical': [80], 'aspects': [81], 'AI-blockchain-integration': [83], 'systems,': [86], 'including': [87, 145], 'authorization': [88], 'management,': [89], 'access': [90], 'control,': [91], 'protection,': [93], 'network': [94], 'security,': [95], 'scalability.': [97], 'Furthermore,': [98], 'it': [99], 'analyzes': [100], 'deficiencies': [102], 'actual': [105], 'cause,': [106], 'offering': [107], 'corresponding': [108], 'suggestions.': [109], 'research': [111], 'classifies': [113], 'summarizes': [115], 'based': [119], 'on': [120], 'AI-blockchain': [121], 'technical': [125], 'schemes.': [126], 'conclusion,': [128], 'this': [129], 'outlines': [131], 'future': [133], 'directions': [134], 'technologies': [138], 'emerging': [139], 'integration,': [144], 'enhancing': [146], 'efficiency': [147], 'achieve': [151], 'a': [152], 'more': [153], 'comprehensive': [154], 'privacy.': [158]}",2023,"['Blockchain', 'Computer science', 'Computer security', 'Anonymity', 'Scalability', 'Dependability', 'Information privacy', 'Data Protection Act 1998', 'Privacy protection', 'Encryption', 'Access control', 'Database', 'Software engineering']","With the widespread attention and application of artificial intelligence (AI) and blockchain technologies, privacy protection techniques arising from their integration are of notable significance. In addition to protecting privacy of individuals, these techniques also guarantee security and dependability of data. This paper initially presents an overview of AI and blockchain, summarizing their combination along with derived privacy protection technologies. It then explores specific application scenarios in data encryption, de-identification, multi-tier distributed ledgers, and k-anonymity methods. Moreover, the paper evaluates five critical aspects of AI-blockchain-integration privacy protection systems, including authorization management, access control, data protection, network security, and scalability. Furthermore, it analyzes the deficiencies and their actual cause, offering corresponding suggestions. This research also classifies and summarizes privacy protection techniques based on AI-blockchain application scenarios and technical schemes. In conclusion, this paper outlines the future directions of privacy protection technologies emerging from AI and blockchain integration, including enhancing efficiency and security to achieve a more comprehensive privacy protection of privacy."
https://openalex.org/W4402354544,"Security, Trust and Privacy Challenges in AI-Driven 6G Networks","{'The': [0, 91], 'advent': [1], 'of': [2, 27, 41, 66, 72, 104], '6G': [3, 28, 58], 'networks': [4], 'promises': [5], 'unprecedented': [6], 'advancements': [7], 'in': [8, 57, 106], 'wireless': [9], 'communication,': [10], 'offering': [11], 'wider': [12], 'bandwidth': [13], 'and': [14, 38, 52, 55, 80, 98], 'lower': [15], 'latency': [16], 'compared': [17], 'to': [18, 63, 84, 101], 'its': [19, 77], 'predecessors.': [20], 'This': [21], 'article': [22], 'explores': [23, 48, 81], 'the': [24, 31, 39, 49, 64, 96, 102], 'evolving': [25], 'infrastructure': [26], 'networks,': [29, 59], 'emphasizing': [30], 'transition': [32], 'towards': [33], 'a': [34, 70, 108], 'more': [35], 'disaggregated': [36], 'structure': [37], 'integration': [40], 'artificial': [42], 'intelligence': [43], '(AI)': [44], 'technologies.': [45], 'Furthermore,': [46], 'it': [47], 'security,': [50], 'trust': [51], 'privacy': [53], 'challenges': [54], 'attacks': [56, 74], 'particularly': [60], 'those': [61], 'related': [62], 'use': [65], 'AI.': [67], 'It': [68], 'presents': [69], 'classification': [71], 'network': [73], 'stemming': [75], 'from': [76], 'AI-centric': [78], 'architecture': [79], 'technologies': [82], 'designed': [83], 'detect': [85], 'or': [86], 'mitigate': [87], 'these': [88], 'emerging': [89], 'threats.': [90], 'paper': [92], 'concludes': [93], 'by': [94], 'examining': [95], 'implications': [97], 'risks': [99], 'linked': [100], 'utilization': [103], 'AI': [105], 'ensuring': [107], 'robust': [109], 'network.': [110]}",2024,"['Computer science', 'Computer security', 'Architecture', 'Wireless network', 'Wireless', 'Emerging technologies', 'Telecommunications', 'Artificial intelligence', 'Art', 'Visual arts']","The advent of 6G networks promises unprecedented advancements in wireless communication, offering wider bandwidth and lower latency compared to its predecessors. This article explores the evolving infrastructure of 6G networks, emphasizing the transition towards a more disaggregated structure and the integration of artificial intelligence (AI) technologies. Furthermore, it explores the security, trust and privacy challenges and attacks in 6G networks, particularly those related to the use of AI. It presents a classification of network attacks stemming from its AI-centric architecture and explores technologies designed to detect or mitigate these emerging threats. The paper concludes by examining the implications and risks linked to the utilization of AI in ensuring a robust network."
https://openalex.org/W3088384496,Survey on Federated Learning Towards Privacy Preserving AI,"{'One': [0], 'of': [1, 5, 30, 72, 82, 97, 112, 126], 'the': [2, 28, 43, 51, 59, 104], 'significant': [3], 'challenges': [4], 'Artificial': [6], 'Intelligence': [7], '(AI)': [8], 'and': [9, 18, 108, 137], 'Machine': [10, 84, 138], 'learning': [11, 61], 'models': [12, 62], 'is': [13, 101, 122], 'to': [14, 19, 27, 48, 68, 102], 'preserve': [15], 'data': [16, 21, 37, 65], 'privacy': [17, 41, 66, 106], 'ensure': [20], 'security.': [22], 'Addressing': [23], 'this': [24, 75, 98], 'problem': [25], 'lead': [26], 'application': [29], 'Federated': [31, 83, 113, 120], 'Learning': [32, 114, 121], '(FL)': [33], 'mechanism': [34], 'towards': [35], 'preserving': [36, 64], 'privacy.': [38], 'Preserving': [39], 'user': [40], 'in': [42, 79, 135], 'European': [44], 'Union': [45], '(EU)': [46], 'has': [47, 67], 'abide': [49], 'by': [50], 'General': [52], 'Data': [53], 'Protection': [54], 'Regulation': [55], '(GDPR).': [56], 'Therefore,': [57], 'exploring': [58], 'machine': [60], 'for': [63], 'take': [69], 'into': [70], 'consideration': [71], 'GDPR.': [73], 'In': [74], 'paper,': [76], 'we': [77, 116], 'present': [78], 'detail': [80], 'understanding': [81], 'Learning,': [85], 'various': [86], 'federated': [87], 'architectures': [88], 'along': [89], 'with': [90], 'different': [91], 'privacy-preserving': [92], 'mechanisms.': [93], 'The': [94], 'main': [95], 'goal': [96], 'survey': [99], 'work': [100], 'highlight': [103], 'existing': [105], 'techniques': [107], 'also': [109, 117], 'propose': [110], 'applications': [111], 'inIndustries.Finally,': [115], 'depict': [118], 'how': [119], 'an': [123], 'emerging': [124], 'area': [125], 'future': [127], 'research': [128], 'that': [129], 'would': [130], 'bring': [131], 'a': [132], 'new': [133], 'era': [134], 'AI': [136], 'learning.': [139]}",2020,"['Computer science', 'Information privacy', 'Internet privacy', 'Data science']","One of the significant challenges of Artificial Intelligence (AI) and Machine learning models is to preserve data privacy and to ensure data security. Addressing this problem lead to the application of Federated Learning (FL) mechanism towards preserving data privacy. Preserving user privacy in the European Union (EU) has to abide by the General Data Protection Regulation (GDPR). Therefore, exploring the machine learning models for preserving data privacy has to take into consideration of GDPR. In this paper, we present in detail understanding of Federated Machine Learning, various federated architectures along with different privacy-preserving mechanisms. The main goal of this survey work is to highlight the existing privacy techniques and also propose applications of Federated Learning inIndustries.Finally, we also depict how Federated Learning is an emerging area of future research that would bring a new era in AI and Machine learning."
https://openalex.org/W3173155549,"AI in My Life: AI, Ethics &amp; Privacy Workshops for 15-16-Year-Olds","{'‘AI': [0], 'in': [1, 13, 28, 53, 84, 140, 149, 234, 248, 251, 288], 'My': [2], 'Life’': [3], 'project': [4, 112], 'will': [5, 42, 99, 162, 191, 205], 'engage': [6], '500': [7], 'Dublin': [8], 'teenagers': [9], 'from': [10, 81, 93, 102, 136], 'disadvantaged': [11], 'backgrounds': [12], 'a': [14, 29, 125, 160, 183, 193, 285], '15-week': [15], '(20-&#13;\\nhour)': [16], 'co-created,': [17], 'interactive': [18], 'workshop': [19], 'series': [20], 'encouraging': [21], 'them': [22], 'to': [23, 44, 56, 61, 113, 116, 131, 244, 258, 269], 'reflect': [24], 'on': [25, 221], 'their': [26, 54, 58], 'experiences': [27], 'world&#13;\\nshaped': [30], 'by': [31, 172], 'Artificial': [32], 'Intelligence': [33], '(AI),': [34], 'personal': [35], 'data': [36, 231, 239], 'processing': [37], 'and': [38, 48, 65, 86, 89, 108, 152, 170, 182, 198, 227, 241, 292], 'digital': [39, 59], 'transformation.': [40], 'Students': [41], 'be&#13;\\nempowered': [43], 'evaluate': [45], 'the': [46, 70, 94, 103, 109, 117, 164, 211, 276, 289], 'ethical': [47], 'privacy': [49, 240], 'implications': [50], 'of': [51, 105, 127, 157, 166, 210, 217, 225, 238, 267], 'AI': [52, 226], 'lives,': [55], 'protect': [57, 245], 'privacy&#13;\\nand': [60], 'activate': [62], 'STEM': [63, 260, 271], 'careers': [64], 'university': [66], 'awareness.': [67], 'It': [68, 204], 'extends': [69], '‘DCU': [71], 'TY’': [72], 'programme': [73, 115, 218], 'for': [74, 77, 134, 185, 200], 'innovative&#13;\\neducational': [75], 'opportunities': [76], 'Transition': [78], 'Year': [79], 'students': [80, 135], 'underrepresented': [82, 139], 'communities': [83], 'higher&#13;\\neducation.&#13;\\nPrivacy': [85], 'cybersecurity': [87], 'researchers': [88], 'public': [90, 252], 'engagement': [91], 'professionals': [92], 'SFI': [95], 'Centres': [96], 'ADAPT1&#13;\\nand': [97], 'Lero2': [98], 'join': [100], 'experts': [101], 'Future': [104], 'Privacy': [106], 'Forum3': [107], 'INTEGRITY': [110], 'H20204': [111], 'deliver&#13;\\nthe': [114], 'DCU': [118, 122, 177], 'Access5': [119], '22-school': [120], 'network.': [121], 'Access': [123], 'has': [124], 'mission': [126], 'creating': [128], 'equality': [129], 'of&#13;\\naccess': [130], 'third-level': [132], 'education': [133], 'groups': [137], 'currently': [138], 'higher': [141], 'education.': [142], 'Each': [143], 'partner': [144], 'brings': [145], 'proven': [146], 'training': [147], 'activities': [148], 'AI,': [150], 'ethics': [151], 'privacy.': [153], 'A': [154], 'novel': [155], 'blending': [156], 'material': [158, 174, 190, 212], 'into': [159], 'youthdriven&#13;\\nnarrative': [161], 'be': [163], 'subject': [165], 'initial': [167], 'co-creation': [168, 281], 'workshops': [169, 181, 282], 'supported': [171], 'pilot': [173], 'delivery&#13;\\nby': [175], 'undergraduate': [176], 'Student': [178], 'Ambassadors.': [179], 'Train-the-trainer': [180], 'toolkit': [184], 'teachers': [186, 268], 'will&#13;\\nenable': [187], 'delivery.': [188], 'The': [189], 'use': [192, 209], 'blended': [194], 'approach': [195], '(in': [196], 'person': [197], 'online)': [199], 'delivery': [201], 'during': [202], 'COVID-&#13;\\n19.': [203], 'also': [206], 'enable': [207], 'wider': [208], 'developed.': [213], 'An': [214], 'external': [215], 'study': [216], 'effectiveness': [219], 'will&#13;\\nreport': [220], 'participants’:': [222], 'enhanced': [223], 'understanding': [224, 237], 'its': [228], 'impact,': [229], 'improved': [230], 'literacy': [232], 'skills': [233], 'terms': [235], 'of&#13;\\ntheir': [236], 'security,': [242], 'empowerment': [243], 'privacy,': [246], 'growth': [247], 'confidence': [249], 'in&#13;\\nparticipating': [250], 'discourse': [253], 'about': [254, 280], 'STEM,': [255], 'increased': [256], 'propensity': [257], 'consider': [259], 'subjects': [261], 'at': [262], 'all': [263], 'levels,&#13;\\nand': [264], 'greater': [265], 'capacity': [266], 'facilitate': [270], 'interventions.': [272], 'This': [273], 'paper': [274], 'introduces': [275], 'project,': [277], 'presents&#13;\\nmore': [278], 'details': [279], 'that': [283], 'is': [284], 'particular': [286], 'step': [287], 'proposed': [290], 'methodology': [291], 'reports&#13;\\nsome': [293], 'preliminary': [294], 'results.': [295]}",2021,"['Disadvantaged', 'Psychology', 'Information privacy', 'Medical education', 'Internet privacy', 'Computer science', 'Political science', 'Medicine', 'Law']","‘AI in My Life’ project will engage 500 Dublin teenagers from disadvantaged backgrounds in a 15-week (20-&#13;\nhour) co-created, interactive workshop series encouraging them to reflect on their experiences in a world&#13;\nshaped by Artificial Intelligence (AI), personal data processing and digital transformation. Students will be&#13;\nempowered to evaluate the ethical and privacy implications of AI in their lives, to protect their digital privacy&#13;\nand to activate STEM careers and university awareness. It extends the ‘DCU TY’ programme for innovative&#13;\neducational opportunities for Transition Year students from underrepresented communities in higher&#13;\neducation.&#13;\nPrivacy and cybersecurity researchers and public engagement professionals from the SFI Centres ADAPT1&#13;\nand Lero2 will join experts from the Future of Privacy Forum3 and the INTEGRITY H20204 project to deliver&#13;\nthe programme to the DCU Access5 22-school network. DCU Access has a mission of creating equality of&#13;\naccess to third-level education for students from groups currently underrepresented in higher education. Each partner brings proven training activities in AI, ethics and privacy. A novel blending of material into a youthdriven&#13;\nnarrative will be the subject of initial co-creation workshops and supported by pilot material delivery&#13;\nby undergraduate DCU Student Ambassadors. Train-the-trainer workshops and a toolkit for teachers will&#13;\nenable delivery. The material will use a blended approach (in person and online) for delivery during COVID-&#13;\n19. It will also enable wider use of the material developed. An external study of programme effectiveness will&#13;\nreport on participants’: enhanced understanding of AI and its impact, improved data literacy skills in terms of&#13;\ntheir understanding of data privacy and security, empowerment to protect privacy, growth in confidence in&#13;\nparticipating in public discourse about STEM, increased propensity to consider STEM subjects at all levels,&#13;\nand greater capacity of teachers to facilitate STEM interventions. This paper introduces the project, presents&#13;\nmore details about co-creation workshops that is a particular step in the proposed methodology and reports&#13;\nsome preliminary results."
https://openalex.org/W4410040324,"AI-Driven Optimization of Blockchain Scalability, Security, and Privacy Protection","{'With': [0], 'the': [1, 53, 60, 65, 72, 84, 89, 109, 117, 195], 'continuous': [2], 'development': [3], 'of': [4, 16, 57, 74, 78, 83, 91, 112, 119, 127, 133, 140, 194], 'technology,': [5], 'blockchain': [6, 25, 75, 94, 128, 165, 210], 'has': [7], 'been': [8, 160], 'widely': [9], 'used': [10], 'in': [11, 76, 93, 123, 131], 'various': [12], 'fields': [13], 'by': [14], 'virtue': [15], 'its': [17, 39], 'decentralization,': [18], 'data': [19, 41], 'integrity,': [20], 'traceability,': [21], 'and': [22, 33, 47, 63, 80, 102, 136, 156, 173, 180, 186, 199, 209], 'anonymity.': [23], 'However,': [24], 'still': [26], 'faces': [27], 'many': [28], 'challenges,': [29], 'such': [30, 152], 'as': [31, 95, 153], 'scalability': [32, 79], 'security': [34, 61], 'issues.': [35], 'Artificial': [36], 'intelligence,': [37], 'with': [38], 'powerful': [40], 'processing': [42, 55], 'capability,': [43], 'pattern': [44], 'recognition': [45], 'ability,': [46], 'adaptive': [48], 'optimization': [49], 'algorithms,': [50, 167], 'can': [51, 107], 'improve': [52, 168], 'transaction': [54], 'efficiency': [56], 'blockchain,': [58], 'enhance': [59, 174], 'mechanism,': [62], 'optimize': [64, 164], 'privacy': [66, 137], 'protection': [67], 'strategy,': [68], 'thus': [69], 'effectively': [70, 161], 'alleviating': [71], 'limitations': [73], 'terms': [77, 132], 'security.': [81], 'Most': [82], 'existing': [85], 'related': [86], 'reviews': [87], 'explore': [88], 'application': [90, 118], 'AI': [92, 106, 150, 208], 'a': [96, 142, 191], 'whole': [97], 'but': [98], 'lack': [99], 'in-depth': [100], 'classification': [101, 185], 'discussion': [103], 'on': [104, 148], 'how': [105, 149], 'empower': [108], 'core': [110, 125], 'aspects': [111], 'blockchain.': [113], 'This': [114], 'paper': [115, 189], 'explores': [116], 'artificial': [120], 'intelligence': [121], 'technologies': [122], 'addressing': [124], 'challenges': [126], 'systems,': [129], 'specifically': [130], 'scalability,': [134], 'security,': [135], 'protection.': [138], 'Instead': [139], 'claiming': [141], 'deep': [143, 157], 'theoretical': [144], 'integration,': [145], 'we': [146], 'focus': [147], 'methods,': [151], 'machine': [154], 'learning': [155, 179], 'learning,': [158], 'have': [159], 'adopted': [162], 'to': [163], 'consensus': [166], 'smart': [169], 'contract': [170], 'vulnerability': [171], 'detection,': [172], 'privacy-preserving': [175], 'mechanisms': [176], 'like': [177], 'federated': [178], 'differential': [181], 'privacy.': [182], 'Through': [183], 'comprehensive': [184], 'discussion,': [187], 'this': [188], 'provides': [190], 'structured': [192], 'overview': [193], 'current': [196], 'research': [197], 'landscape': [198], 'identifies': [200], 'potential': [201], 'directions': [202], 'for': [203], 'further': [204], 'technical': [205], 'collaboration': [206], 'between': [207], 'technologies.': [211]}",2025,"['Blockchain', 'Scalability', 'Computer science', 'Privacy protection', 'Computer security', 'Distributed computing', 'Database']","With the continuous development of technology, blockchain has been widely used in various fields by virtue of its decentralization, data integrity, traceability, and anonymity. However, blockchain still faces many challenges, such as scalability and security issues. Artificial intelligence, with its powerful data processing capability, pattern recognition ability, and adaptive optimization algorithms, can improve the transaction processing efficiency of blockchain, enhance the security mechanism, and optimize the privacy protection strategy, thus effectively alleviating the limitations of blockchain in terms of scalability and security. Most of the existing related reviews explore the application of AI in blockchain as a whole but lack in-depth classification and discussion on how AI can empower the core aspects of blockchain. This paper explores the application of artificial intelligence technologies in addressing core challenges of blockchain systems, specifically in terms of scalability, security, and privacy protection. Instead of claiming a deep theoretical integration, we focus on how AI methods, such as machine learning and deep learning, have been effectively adopted to optimize blockchain consensus algorithms, improve smart contract vulnerability detection, and enhance privacy-preserving mechanisms like federated learning and differential privacy. Through comprehensive classification and discussion, this paper provides a structured overview of the current research landscape and identifies potential directions for further technical collaboration between AI and blockchain technologies."
https://openalex.org/W4404148466,Ethical AI in Retail: Consumer Privacy and Fairness,"{'The': [0, 202, 218], 'adoption': [1], 'of': [2, 24, 44, 99, 106, 119, 199], 'artificial': [3], 'intelligence': [4], '(AI)': [5], 'in': [6, 47, 121, 223, 235], 'retail': [7, 112], 'has': [8], 'significantly': [9], 'transformed': [10], 'the': [11, 21, 41, 104], 'industry,': [12], 'enabling': [13], 'more': [14], 'personalized': [15], 'services': [16], 'and': [17, 34, 60, 91, 159, 169, 173, 196, 211, 238], 'efficient': [18], 'operations.': [19], 'However,': [20], 'rapid': [22], 'implementation': [23], 'AI': [25, 45, 54, 65, 137, 154, 200, 216, 224, 236], 'technologies': [26, 55], 'raises': [27], 'ethical': [28, 42, 64, 163], 'concerns,': [29], 'particularly': [30], 'regarding': [31, 103], 'consumer': [32, 233, 240], 'privacy': [33, 168, 172], 'fairness.': [35, 170], 'This': [36], 'study': [37, 203, 219], 'aims': [38], 'to': [39, 73, 183, 229], 'analyze': [40], 'challenges': [43], 'applications': [46], 'retail,': [48], 'explore': [49], 'ways': [50], 'retailers': [51, 181, 206], 'can': [52, 155], 'implement': [53], 'ethically': [56], 'while': [57], 'remaining': [58], 'competitive,': [59], 'provide': [61], 'recommendations': [62], 'on': [63], 'practices.': [66], 'A': [67], 'descriptive': [68, 87], 'survey': [69], 'design': [70], 'was': [71, 150], 'used': [72], 'collect': [74], 'data': [75, 108, 124, 167, 193, 212, 241], 'from': [76], '300': [77], 'respondents': [78], 'across': [79], 'major': [80, 131], 'e-commerce': [81], 'platforms.': [82], 'Data': [83, 171], 'were': [84, 175], 'analyzed': [85], 'using': [86], 'statistics,': [88], 'including': [89], 'percentages': [90], 'mean': [92], 'scores.': [93], 'Findings': [94], 'shows': [95], 'a': [96, 117, 134, 188], 'high': [97], 'level': [98], 'concerns': [100, 145], 'among': [101], 'consumers': [102, 142], 'amount': [105], 'personal': [107], 'collected': [109], 'by': [110], 'AI-driven': [111], 'applications,': [113], 'with': [114], 'many': [115], 'expressing': [116], 'lack': [118], 'trust': [120], 'how': [122], 'their': [123, 185], 'is': [125, 129], 'managed.': [126], 'Also,': [127], 'fairness': [128], 'another': [130], 'issue,': [132], 'as': [133, 166, 177], 'majority': [135], 'believe': [136], 'systems': [138], 'do': [139], 'not': [140], 'treat': [141], 'equally,': [143], 'raising': [144], 'about': [146], 'algorithmic': [147], 'bias.': [148], 'It': [149], 'also': [151], 'found': [152], 'that': [153, 205], 'enhance': [156], 'business': [157], 'competitiveness': [158], 'efficiency': [160], 'without': [161], 'compromising': [162], 'principles,': [164], 'such': [165], 'transparency': [174, 222], 'highlighted': [176], 'critical': [178], 'areas': [179], 'where': [180], 'need': [182], 'focus': [184], 'efforts,': [186], 'indicating': [187], 'strong': [189], 'demand': [190], 'for': [191], 'stricter': [192], 'protection': [194, 213], 'protocols': [195], 'ongoing': [197], 'scrutiny': [198], 'systems.': [201, 217], 'concludes': [204], 'must': [207], 'prioritize': [208], 'transparency,': [209], 'fairness,': [210], 'when': [214], 'deploying': [215], 'recommends': [220], 'ensuring': [221], 'processes,': [225], 'conducting': [226], 'regular': [227], 'audits': [228], 'address': [230], 'biases,': [231], 'incorporating': [232], 'feedback': [234], 'development,': [237], 'emphasizing': [239], 'privacy.': [242]}",2024,"['Business', 'Consumer privacy', 'Internet privacy', 'Information privacy', 'Marketing', 'Computer science']","The adoption of artificial intelligence (AI) in retail has significantly transformed the industry, enabling more personalized services and efficient operations. However, the rapid implementation of AI technologies raises ethical concerns, particularly regarding consumer privacy and fairness. This study aims to analyze the ethical challenges of AI applications in retail, explore ways retailers can implement AI technologies ethically while remaining competitive, and provide recommendations on ethical AI practices. A descriptive survey design was used to collect data from 300 respondents across major e-commerce platforms. Data were analyzed using descriptive statistics, including percentages and mean scores. Findings shows a high level of concerns among consumers regarding the amount of personal data collected by AI-driven retail applications, with many expressing a lack of trust in how their data is managed. Also, fairness is another major issue, as a majority believe AI systems do not treat consumers equally, raising concerns about algorithmic bias. It was also found that AI can enhance business competitiveness and efficiency without compromising ethical principles, such as data privacy and fairness. Data privacy and transparency were highlighted as critical areas where retailers need to focus their efforts, indicating a strong demand for stricter data protection protocols and ongoing scrutiny of AI systems. The study concludes that retailers must prioritize transparency, fairness, and data protection when deploying AI systems. The study recommends ensuring transparency in AI processes, conducting regular audits to address biases, incorporating consumer feedback in AI development, and emphasizing consumer data privacy."
https://openalex.org/W2887202973,Privacy and DRM Requirements for Collaborative Development of AI Applications,"{'The': [0], 'use': [1], 'of': [2, 9, 37, 67], 'data': [3, 22, 30], 'is': [4, 55], 'essential': [5], 'for': [6], 'the': [7, 27, 82, 97, 105, 112, 121], 'capabilities': [8], 'Data-driven': [10], 'Artificial': [11], 'intelligence': [12], '(AI),': [13], 'Deep': [14], 'Learning': [15], 'and': [16, 71, 84, 101, 103, 125], 'Big': [17], 'Data': [18], 'analysis': [19], 'techniques.': [20], 'This': [21, 79], 'usage,': [23], 'however,': [24], 'raises': [25], 'intrinsically': [26], 'concerns': [28], 'on': [29, 123], 'privacy.': [31], 'In': [32], 'addition,': [33], 'supporting': [34], 'collaborative': [35, 88, 128], 'development': [36], 'AI': [38, 48, 89, 93, 129, 132], 'applications': [39], 'across': [40], 'organisations': [41], 'has': [42], 'become': [43], 'a': [44, 65], 'major': [45], 'need': [46], 'in': [47, 61, 87, 127], 'system': [49, 90], 'design.': [50], 'Digital': [51], 'Rights': [52], 'Management': [53], '(DRM)': [54], 'required': [56], 'to': [57, 118], 'protect': [58, 119], 'intellectual': [59], 'property': [60], 'such': [62], 'collaboration.': [63], 'As': [64], 'consequence': [66], 'DRM,': [68], 'privacy': [69, 83, 102, 126], 'threats': [70, 106, 122], 'privacy-enforcing': [72], 'mechanisms': [73], 'will': [74], 'interact': [75], 'with': [76], 'each': [77], 'other.': [78], 'paper': [80, 113], 'describes': [81, 96], 'DRM': [85, 100, 124], 'requirements': [86], 'design': [91, 130], 'using': [92, 131], 'pipelines.': [94, 133], 'It': [95], 'relationships': [98], 'between': [99], 'outlines': [104], 'against': [107, 120], 'these': [108], 'non-functional': [109], 'features.': [110], 'Finally,': [111], 'provides': [114], 'first': [115], 'security': [116], 'architecture': [117]}",2018,"['Intellectual property', 'Computer science', 'Information privacy', 'Digital rights management', 'Big data', 'Privacy by Design', 'Computer security', 'Internet privacy', 'Data science', 'Operating system']","The use of data is essential for the capabilities of Data-driven Artificial intelligence (AI), Deep Learning and Big Data analysis techniques. This data usage, however, raises intrinsically the concerns on data privacy. In addition, supporting collaborative development of AI applications across organisations has become a major need in AI system design. Digital Rights Management (DRM) is required to protect intellectual property in such collaboration. As a consequence of DRM, privacy threats and privacy-enforcing mechanisms will interact with each other. This paper describes the privacy and DRM requirements in collaborative AI system design using AI pipelines. It describes the relationships between DRM and privacy and outlines the threats against these non-functional features. Finally, the paper provides first security architecture to protect against the threats on DRM and privacy in collaborative AI design using AI pipelines."
https://openalex.org/W2803648454,Taking AI Personally: How the E.U. Must Learn to Balance the Interests of Personal Data Privacy & Artificial Intelligence,"{'Taking': [0], 'AI': [1], 'Personally:': [2], 'How': [3], 'the': [4, 10], 'E.U.': [5], 'Must': [6], 'Learn': [7], 'to': [8], 'Balance': [9], 'Interests': [11], 'of': [12], 'Personal': [13], 'Data': [14], 'Privacy': [15], '&': [16], 'Artificial': [17], 'Intelligence': [18]}",2018,"['Internet privacy', 'Balance (ability)', 'Computer science', 'Information privacy', 'Computer security', 'Psychology', 'Neuroscience']",Taking AI Personally: How the E.U. Must Learn to Balance the Interests of Personal Data Privacy & Artificial Intelligence
https://openalex.org/W4400654443,Data Privacy and Security Concerns in AI-Integrated Educational Platforms,"{'As': [0], 'educational': [1, 40, 124], 'institutions': [2], 'increasingly': [3], 'embrace': [4], 'AI': [5, 38, 73, 122, 147], 'technologies': [6], 'to': [7, 53, 63, 89, 107, 113, 133, 137, 153], 'enhance': [8], 'learning': [9], 'experiences,': [10], 'a': [11, 67], 'paramount': [12], 'concern': [13], 'arises': [14], 'regarding': [15], 'the': [16, 29, 35, 78, 90, 97, 115, 138, 143, 151, 155], 'privacy': [17, 46, 84, 156], 'and': [18, 31, 47, 60, 69, 83, 111, 117, 157], 'security': [19, 48, 158], 'of': [20, 37, 72, 80, 99, 119, 146, 159], 'sensitive': [21], 'student': [22], 'data.': [23], 'This': [24], 'research': [25, 87, 105], 'paper': [26], 'delves': [27], 'into': [28], 'challenges': [30], 'implications': [32], 'associated': [33], 'with': [34, 150], 'integration': [36], 'in': [39, 74, 96, 121, 148], 'platforms,': [41], 'focusing': [42], 'specifically': [43], 'on': [44, 93, 141], 'data': [45, 120], 'issues.': [49], 'The': [50], 'study': [51], 'aims': [52], 'identify': [54], 'potential': [55], 'risks,': [56], 'assess': [57], 'current': [58], 'safeguards,': [59], 'propose': [61, 108], 'strategies': [62, 112], 'mitigate': [64], 'threats,': [65], 'ensuring': [66], 'responsible': [68], 'secure': [70], 'implementation': [71], 'education.': [75], 'By': [76, 126], 'examining': [77], 'intersection': [79], 'technological': [81], 'advancement': [82], 'concerns,': [85], 'this': [86, 104], 'contributes': [88], 'ongoing': [91, 139], 'dialogue': [92], 'ethical': [94], 'considerations': [95], 'realm': [98], 'AI-driven': [100], 'education': [101, 149], 'transformation.': [102], 'Furthermore,': [103], 'endeavors': [106], 'robust': [109], 'frameworks': [110], 'safeguard': [114], 'integrity': [116], 'confidentiality': [118], 'driven': [123], 'environments.': [125], 'addressing': [127], 'these': [128], 'concerns': [129], 'head-on,': [130], 'we': [131], 'strive': [132], 'contribute': [134], 'valuable': [135], 'insights': [136], 'discourse': [140], 'balancing': [142], 'transformative': [144], 'benefits': [145], 'imperative': [152], 'protect': [154], 'all': [160], 'stakeholders': [161], 'involved.': [162]}",2024,"['Internet privacy', 'Computer security', 'Computer science', 'Information privacy']","As educational institutions increasingly embrace AI technologies to enhance learning experiences, a paramount concern arises regarding the privacy and security of sensitive student data. This research paper delves into the challenges and implications associated with the integration of AI in educational platforms, focusing specifically on data privacy and security issues. The study aims to identify potential risks, assess current safeguards, and propose strategies to mitigate threats, ensuring a responsible and secure implementation of AI in education. By examining the intersection of technological advancement and privacy concerns, this research contributes to the ongoing dialogue on ethical considerations in the realm of AI-driven education transformation. Furthermore, this research endeavors to propose robust frameworks and strategies to safeguard the integrity and confidentiality of data in AI driven educational environments. By addressing these concerns head-on, we strive to contribute valuable insights to the ongoing discourse on balancing the transformative benefits of AI in education with the imperative to protect the privacy and security of all stakeholders involved."
https://openalex.org/W4392916557,AI to V2X Privacy and Security Issues in Autonomous Vehicles: Survey,"{'Artificial': [0], 'Intelligence': [1], '(AI)': [2], 'is': [3, 174], 'transforming': [4], 'all': [5], 'of': [6, 23, 37, 42, 49, 105, 137, 166, 190], 'the': [7, 21, 40, 47, 54, 135, 164, 179], 'technologies': [8], 'we': [9, 16, 116], 'use': [10], 'every': [11], 'day.': [12], 'More': [13], 'than': [14], 'ever,': [15], 'are': [17, 33, 53, 78, 95], 'very': [18], 'near': [19], 'to': [20, 158, 161, 175, 186], 'objective': [22], 'vehicle': [24], 'autonomy,': [25], 'which': [26, 107], 'has': [27], 'long': [28], 'been': [29], 'desired.': [30], 'Large': [31], 'automakers': [32], 'also': [34, 79, 149], 'spending': [35], 'billions': [36], 'dollars': [38], 'on': [39, 145], 'development': [41], 'autonomous': [43], 'vehicles': [44, 94], '(AVs).': [45], 'Among': [46], 'advantages': [48], 'this': [50, 87, 114], 'new': [51, 80], 'technology': [52], 'possibility': [55], 'for': [56], 'increased': [57], 'passenger': [58], 'safety,': [59], 'less': [60, 70], 'congested': [61], 'roads,': [62], 'reduced': [63, 67], 'traffic,': [64, 66], 'optimized': [65], 'fuel': [68], 'consumption,': [69], 'pollution,': [71], 'and': [72, 82, 99, 120, 141, 153, 185], 'improved': [73], 'travel': [74], 'experiences.': [75], 'However,': [76], 'there': [77], 'security': [81, 121], 'privacy': [83, 118], 'problems': [84, 152], 'associated': [85], 'with': [86], 'paradigm': [88], 'change.': [89], 'Previously': [90], 'simple': [91], 'mechanical': [92], 'devices,': [93], 'today': [96], 'computerized,': [97], 'networked,': [98], 'intelligent.': [100], 'They': [101], 'gather': [102], 'vast': [103], 'amounts': [104], 'data,': [106], 'must': [108], 'be': [109, 159], 'shielded': [110], 'from': [111], 'intrusions.': [112], 'In': [113], 'paper,': [115], 'examine': [117], 'issues': [119, 182], 'hurdles': [122], 'in': [123, 168], 'AVs.': [124], 'We': [125], 'investigate': [126], 'several': [127], 'attacks': [128], 'using': [129], 'a': [130], 'layer-by-layer': [131], 'methodology.': [132], 'It': [133, 148], 'summarizes': [134], 'contributions': [136], 'these': [138], 'research': [139, 154, 181], 'works': [140], 'categorizes': [142], 'them': [143], 'based': [144], 'application': [146], 'domains.': [147], 'identifies': [150], 'open': [151], 'challenges': [155], 'that': [156], 'need': [157], 'addressed': [160], 'fully': [162], 'realize': [163], 'potential': [165], 'AI': [167], 'advancing': [169], 'V2X': [170], 'systems.': [171], 'Our': [172], 'intention': [173], 'provide': [176], 'insights': [177], 'into': [178], 'unresolved': [180], 'surrounding': [183], 'AVs': [184], 'suggest': [187], 'future': [188], 'lines': [189], 'inquiry.': [191]}",2024,"['Autonomy', 'Computer security', 'Computer science', 'Intelligent transportation system', 'Emerging technologies', 'Internet privacy', 'Transport engineering', 'Engineering', 'Artificial intelligence', 'Political science', 'Law']","Artificial Intelligence (AI) is transforming all of the technologies we use every day. More than ever, we are very near to the objective of vehicle autonomy, which has long been desired. Large automakers are also spending billions of dollars on the development of autonomous vehicles (AVs). Among the advantages of this new technology are the possibility for increased passenger safety, less congested roads, reduced traffic, optimized traffic, reduced fuel consumption, less pollution, and improved travel experiences. However, there are also new security and privacy problems associated with this paradigm change. Previously simple mechanical devices, vehicles are today computerized, networked, and intelligent. They gather vast amounts of data, which must be shielded from intrusions. In this paper, we examine privacy issues and security hurdles in AVs. We investigate several attacks using a layer-by-layer methodology. It summarizes the contributions of these research works and categorizes them based on application domains. It also identifies open problems and research challenges that need to be addressed to fully realize the potential of AI in advancing V2X systems. Our intention is to provide insights into the unresolved research issues surrounding AVs and to suggest future lines of inquiry."
https://openalex.org/W4387587548,Preserving Privacy in Arabic Judgments: AI-Powered Anonymization for Enhanced Legal Data Privacy,"{'Jurisprudence': [0], 'involves': [1, 118], 'studying,': [2], 'interpreting,': [3], 'and': [4, 101, 166, 171, 177], 'applying': [5], 'the': [6, 33, 40, 43, 51, 125, 130, 137, 153, 161, 187, 196], 'law': [7, 20], 'to': [8, 17, 90, 123, 208], 'comprehend': [9], 'its': [10, 59], 'societal': [11], 'impact.': [12], 'Judges': [13], 'annually': [14], 'review': [15], 'cases': [16], 'ensure': [18], 'accurate': [19], 'application,': [21], 'which': [22], 'raises': [23], 'privacy': [24], 'concerns': [25], 'when': [26, 149], 'accessing': [27], 'files': [28], 'from': [29, 39], 'other': [30], 'courts.': [31], 'While': [32], 'legal': [34, 113, 199], 'field': [35], 'has': [36], 'garnered': [37], 'interest': [38], 'research': [41, 65], 'community,': [42], 'challenge': [44], 'of': [45, 139, 147, 169, 175], 'masking': [46], 'personal': [47, 81, 126], 'data,': [48], 'particularly': [49], 'in': [50, 58, 152, 213], 'Arabic': [52, 75, 112, 155, 193, 198, 214], 'language': [53], 'with': [54, 164], 'limited': [55], 'resources,': [56], 'remains': [57], 'early': [60], 'stages.': [61], 'To': [62], 'address': [63], 'this': [64, 107], 'gap,': [66], 'we': [67], 'develop': [68], 'a': [69, 80, 110, 119, 202], 'two-component': [70], 'system': [71, 185], 'for': [72, 190, 205], 'generating': [73, 191], 'anonymous': [74, 140, 192], 'judgments.': [76, 141, 194], 'The': [77, 115], 'first': [78, 131], 'component,': [79], 'data': [82], 'extractor': [83], 'model,': [84], 'utilizes': [85], 'Named': [86], 'Entity': [87], 'Recognition': [88], '(NER)': [89], 'identify': [91], 'key': [92], 'individual': [93], 'entities': [94, 127, 151], 'like': [95], 'names,': [96], 'addresses,': [97], 'birthdays,': [98], 'case': [99], 'numbers,': [100], 'national': [102], 'identity': [103], 'codes.': [104], 'We': [105], 'train': [106], 'model': [108, 143], 'on': [109, 160], 'purpose-built': [111], 'corpus.': [114, 157], 'second': [116], 'component': [117], 'Python': [120], 'module': [121], 'designed': [122], 'mask': [124], 'extracted': [128], 'by': [129], 'component.': [132], 'Together,': [133], 'these': [134, 181], 'components': [135], 'enable': [136], 'generation': [138], 'Our': [142], 'achieves': [144], 'an': [145], 'F1-score': [146], '96.14&#x0025;': [148], 'detecting': [150], 'created': [154], 'Legal': [156], 'Additionally,': [158], 'experiments': [159], 'ANERCorp': [162], 'corpus,': [163], 'training': [165], 'testing': [167], 'splits': [168], '70&#x0025;-30&#x0025;': [170], '90&#x0025;-10&#x0025;,': [172], 'yield': [173], 'F1-scores': [174], '93.78&#x0025;': [176], '95.77&#x0025;,': [178], 'respectively.': [179], 'With': [180], 'results,': [182], 'our': [183], 'proposed': [184], 'demonstrates': [186], 'promising': [188], 'potential': [189], 'Furthermore,': [195], 'built': [197], 'corpus': [200], 'provides': [201], 'valuable': [203], 'resource': [204], 'researchers': [206], 'aiming': [207], 'enhance': [209], 'domain-specific': [210], 'NER': [211], 'models': [212], 'text.': [215]}",2023,"['Computer science', 'Component (thermodynamics)', 'Artificial intelligence', 'Natural language processing', 'Python (programming language)', 'Arabic', 'Information retrieval', 'Linguistics', 'Operating system', 'Thermodynamics', 'Physics', 'Philosophy']","Jurisprudence involves studying, interpreting, and applying the law to comprehend its societal impact. Judges annually review cases to ensure accurate law application, which raises privacy concerns when accessing files from other courts. While the legal field has garnered interest from the research community, the challenge of masking personal data, particularly in the Arabic language with limited resources, remains in its early stages. To address this research gap, we develop a two-component system for generating anonymous Arabic judgments. The first component, a personal data extractor model, utilizes Named Entity Recognition (NER) to identify key individual entities like names, addresses, birthdays, case numbers, and national identity codes. We train this model on a purpose-built Arabic legal corpus. The second component involves a Python module designed to mask the personal entities extracted by the first component. Together, these components enable the generation of anonymous judgments. Our model achieves an F1-score of 96.14&#x0025; when detecting entities in the created Arabic Legal corpus. Additionally, experiments on the ANERCorp corpus, with training and testing splits of 70&#x0025;-30&#x0025; and 90&#x0025;-10&#x0025;, yield F1-scores of 93.78&#x0025; and 95.77&#x0025;, respectively. With these results, our proposed system demonstrates the promising potential for generating anonymous Arabic judgments. Furthermore, the built Arabic legal corpus provides a valuable resource for researchers aiming to enhance domain-specific NER models in Arabic text."
https://openalex.org/W3174674735,Privacy-Preserving and Explainable AI for Cardiovascular Imaging,"{'Medical': [0], 'imaging': [1, 64], 'provides': [2, 153], 'valuable': [3], 'input': [4], 'for': [5, 108, 121, 155, 176], 'managing': [6], 'cardiovascular': [7], 'disease': [8], '(CVD),': [9], 'ranging': [10], 'from': [11], 'risk': [12], 'assessment': [13, 178], 'to': [14, 36, 48, 51, 81, 84, 103, 124, 141, 164, 184], 'diagnosis,': [15], 'therapy': [16], 'planning': [17, 189], 'and': [18, 42, 65, 74, 100, 115, 152, 158, 183, 187], 'follow-up.Artificial': [19], 'intelligence': [20], '(AI)': [21], 'based': [22, 57], 'medical': [23, 63], 'image': [24], 'analysis': [25], 'algorithms': [26, 88], 'provide': [27], 'nowadays': [28], 'state-of-the-art': [29], 'results': [30, 107], 'in': [31, 39, 59, 66], 'CVD': [32, 61], 'management,': [33], 'mainly': [34], 'due': [35, 83], 'the': [37, 53, 72, 127, 146, 165, 177, 185], 'increase': [38], 'computational': [40], 'power': [41], 'data': [43, 69, 78], 'storage': [44], 'capacities.Various': [45], 'challenges': [46], 'remain': [47], 'be': [49, 133], 'addressed': [50], 'speed-up': [52], 'adoption': [54], 'of': [55, 76, 149, 167, 179, 190], 'AI': [56, 87, 122], 'solutions': [58], 'routine': [60], 'management.Although': [62], 'general': [67], 'health': [68], 'are': [70, 89], 'abundant,': [71], 'access': [73], 'transfer': [75], 'such': [77], 'is': [79], 'difficult': [80], 'realize': [82], 'ethical': [85], 'considerations.Hence,': [86], 'often': [90], 'trained': [91], 'on': [92, 137], 'relatively': [93], 'small': [94], 'datasets,': [95], 'thus': [96], 'limiting': [97], 'their': [98], 'robustness,': [99], 'potentially': [101], 'leading': [102], 'biased': [104], 'or': [105, 111], 'skewed': [106], 'certain': [109], 'patient': [110], 'pathology': [112], 'sub-groups.Furthermore,': [113], 'explainability': [114], 'interpretability': [116], 'have': [117], 'become': [118], 'core': [119], 'requirements': [120], 'algorithms,': [123], 'ensure': [125], 'that': [126], 'rationale': [128], 'behind': [129], 'output': [130], 'inference': [131], 'can': [132], 'revealed.The': [134], 'paper': [135], 'focuses': [136], 'recent': [138], 'developments': [139], 'related': [140, 163], 'these': [142], 'two': [143], 'challenges,': [144], 'discusses': [145], 'clinical': [147], 'impact': [148], 'proposed': [150], 'solutions,': [151], 'conclusions': [154], 'further': [156], 'research': [157], 'development.It': [159], 'also': [160], 'presents': [161], 'examples': [162], 'diagnosis': [166, 186], 'stable': [168], 'coronary': [169], 'artery': [170], 'disease,': [171, 182], 'a': [172, 193], 'whole-body': [173], 'circulation': [174], 'model': [175], 'structural': [180], 'heart': [181, 195], 'treatment': [188], 'aortic': [191], 'coarctation,': [192], 'congenital': [194], 'disease.': [196]}",2021,"['Computer science', 'Artificial intelligence']","Medical imaging provides valuable input for managing cardiovascular disease (CVD), ranging from risk assessment to diagnosis, therapy planning and follow-up.Artificial intelligence (AI) based medical image analysis algorithms provide nowadays state-of-the-art results in CVD management, mainly due to the increase in computational power and data storage capacities.Various challenges remain to be addressed to speed-up the adoption of AI based solutions in routine CVD management.Although medical imaging and in general health data are abundant, the access and transfer of such data is difficult to realize due to ethical considerations.Hence, AI algorithms are often trained on relatively small datasets, thus limiting their robustness, and potentially leading to biased or skewed results for certain patient or pathology sub-groups.Furthermore, explainability and interpretability have become core requirements for AI algorithms, to ensure that the rationale behind output inference can be revealed.The paper focuses on recent developments related to these two challenges, discusses the clinical impact of proposed solutions, and provides conclusions for further research and development.It also presents examples related to the diagnosis of stable coronary artery disease, a whole-body circulation model for the assessment of structural heart disease, and to the diagnosis and treatment planning of aortic coarctation, a congenital heart disease."
https://openalex.org/W4392828253,Towards a Privacy and Security-Aware Framework for Ethical AI: Guiding the Development and Assessment of AI Systems,"{'As': [0], 'artificial': [1], 'intelligence': [2], 'continues': [3], 'its': [4], 'unprecedented': [5], 'global': [6], 'expansion,\\naccompanied': [7], 'by': [8, 54], 'a': [9, 39, 56, 80, 103, 113, 118, 144, 181, 194], 'proliferation': [10], 'of': [11, 21, 27, 89, 120, 136, 173, 230], 'benefits,': [12], 'an': [13, 186], 'increasing': [14], 'apprehension': [15], 'about\\nthe': [16], 'privacy': [17, 130, 211], 'and': [18, 34, 48, 93, 131, 164, 170, 192, 207, 212, 228], 'security': [19, 87, 213], 'implications': [20], 'AI-enabled': [22], 'systems': [23], 'emerges.': [24], 'The\\npivotal': [25], 'question': [26], 'effectively': [28], 'controlling': [29], 'AI': [30, 62, 66, 77, 91, 124, 151, 174, 189, 231], 'development': [31, 169], 'at': [32], 'both\\njurisdictional': [33], 'organizational': [35], 'levels': [36], 'has': [37], 'become': [38], 'prominent': [40], 'theme': [41], 'in\\ncontemporary': [42], 'discourse.': [43], 'While': [44], 'the': [45, 60, 64, 85, 128, 134, 168, 176, 202, 210, 226], 'European': [46], 'Parliament': [47], 'Council': [49], 'have': [50], 'taken': [51], 'a\\ndecisive': [52], 'step': [53], 'reaching': [55], 'political': [57], 'agreement': [58], 'on': [59, 116, 225], 'EU': [61], 'Act,': [63], 'first\\ncomprehensive': [65], 'law,': [67], 'organizations': [68], 'still': [69], 'find': [70], 'it': [71], 'challenging': [72], 'to': [73, 75, 97, 110, 157, 197, 222], 'adapt': [74], 'the\\nfast-evolving': [76], 'landscape,': [78], 'lacking': [79], 'universal': [81], 'tool': [82], 'for': [83, 148, 183, 217], 'evaluating': [84], 'privacy\\nand': [86], 'dimensions': [88], 'their': [90], 'models': [92], 'systems.': [94, 152], 'In': [95, 200], 'response': [96], 'this\\ncritical': [98], 'challenge,': [99], 'this': [100, 141], 'study': [101, 142, 203], 'conducts': [102], 'systematic': [104], 'literature': [105], 'review': [106], 'spanning\\nthe': [107], 'years': [108], '2020': [109], '2023,': [111], 'with': [112], 'primary': [114], 'focus': [115], 'establishing': [117], 'unified\\ndefinition': [119], 'key': [121, 205], 'concepts': [122], 'in': [123, 166], 'Ethics,': [125], 'particularly': [126], 'emphasizing': [127], 'domains\\nof': [129], 'security.': [132], 'Through': [133], 'synthesis': [135], 'knowledge': [137], 'extracted': [138], 'from': [139], 'the\\nSLR,': [140], 'presents': [143], 'conceptual': [145], 'framework': [146, 154, 178], 'tailored': [147], 'privacy-': [149], 'and\\nsecurity-aware': [150], 'This': [153], 'is': [155, 190], 'designed': [156], 'assist': [158], 'diverse\\nstakeholders,': [159], 'including': [160], 'organizations,': [161], 'academic': [162], 'institutions,': [163], 'governmental\\nbodies,': [165], 'both': [167], 'critical': [171], 'assessment': [172], 'systems.\\nEssentially,': [175], 'proposed': [177], 'serves': [179], 'as': [180], 'guide': [182], 'ethical\\ndecision-making,': [184], 'fostering': [185], 'environment': [187], 'wherein': [188], 'developed': [191], 'utilized\\nwith': [193], 'strong': [195], 'commitment': [196], 'ethical': [198], 'principles.': [199], 'addition,': [201], 'unravels\\nthe': [204], 'issues': [206], 'challenges': [208], 'surrounding': [209], 'dimensions,\\ndelineating': [214], 'promising': [215], 'avenues': [216], 'future': [218], 'research,': [219], 'thereby': [220], 'contributing': [221], 'the\\nongoing': [223], 'dialogue': [224], 'globalization': [227], 'democratization': [229], 'ethics.\\n': [232]}",2024,"['Computer security', 'Development (topology)', 'Computer science', 'Internet privacy', 'Business', 'Mathematical analysis', 'Mathematics']","As artificial intelligence continues its unprecedented global expansion,\naccompanied by a proliferation of benefits, an increasing apprehension about\nthe privacy and security implications of AI-enabled systems emerges. The\npivotal question of effectively controlling AI development at both\njurisdictional and organizational levels has become a prominent theme in\ncontemporary discourse. While the European Parliament and Council have taken a\ndecisive step by reaching a political agreement on the EU AI Act, the first\ncomprehensive AI law, organizations still find it challenging to adapt to the\nfast-evolving AI landscape, lacking a universal tool for evaluating the privacy\nand security dimensions of their AI models and systems. In response to this\ncritical challenge, this study conducts a systematic literature review spanning\nthe years 2020 to 2023, with a primary focus on establishing a unified\ndefinition of key concepts in AI Ethics, particularly emphasizing the domains\nof privacy and security. Through the synthesis of knowledge extracted from the\nSLR, this study presents a conceptual framework tailored for privacy- and\nsecurity-aware AI systems. This framework is designed to assist diverse\nstakeholders, including organizations, academic institutions, and governmental\nbodies, in both the development and critical assessment of AI systems.\nEssentially, the proposed framework serves as a guide for ethical\ndecision-making, fostering an environment wherein AI is developed and utilized\nwith a strong commitment to ethical principles. In addition, the study unravels\nthe key issues and challenges surrounding the privacy and security dimensions,\ndelineating promising avenues for future research, thereby contributing to the\nongoing dialogue on the globalization and democratization of AI ethics.\n"
https://openalex.org/W4229064268,Sixth‐Generation (6G) Mobile Cloud Security and Privacy Risks for AI System Using High‐Performance Computing Implementation,"{'The': [0, 22, 96, 247], 'exchange': [1], 'of': [2, 46, 89, 238, 335], 'information': [3], 'from': [4], 'one': [5], 'person': [6], 'to': [7, 77, 159, 166, 186, 234, 267, 279, 286, 309], 'another': [8], 'is': [9, 102, 119, 142, 251, 261, 276, 340], 'called': [10], 'communication.': [11], 'Telecommunication': [12], 'makes': [13], 'it': [14], 'possible': [15], 'with': [16, 136, 192, 245, 331], 'electronic': [17], 'devices': [18, 146], 'and': [19, 56, 163, 179, 184, 217, 240, 297, 318, 322, 345, 351], 'their': [20], 'tools.': [21], 'scientist': [23], 'Alexander': [24], 'Graham': [25], 'Bell': [26], 'has': [27, 256], 'invented': [28], 'the': [29, 35, 40, 44, 51, 72, 81, 90, 100, 107, 116, 167, 187, 199, 224, 232, 262, 287, 301, 327], 'basic': [30], 'telephone': [31], 'in': [32, 34, 43, 80, 99, 145, 147, 154, 181, 194, 198, 221, 243, 303], '1876': [33], 'USA.': [36], 'Telephones': [37], 'now': [38], 'have': [39], 'new': [41], 'format': [42], 'form': [45], 'mobile': [47, 63, 83, 130, 155, 182, 195, 249], 'phones,': [48], 'which': [49], 'are': [50, 60, 68, 75, 231], 'primary': [52], 'media': [53], 'for': [54, 71, 228, 283, 349], 'communicating': [55], 'transmitting': [57], 'data.': [58], 'We': [59], 'using': [61, 94, 271], '5th‐generation': [62], 'network': [64, 84, 156, 171, 174, 196, 250], 'standards.': [65, 85], 'Still,': [66], 'there': [67], 'some': [69], 'requirements': [70], 'users': [73], 'that': [74, 113, 265], 'believed': [76], 'be': [78, 93, 152, 268], 'solved': [79], '6th‐generation': [82], 'By': [86, 325], '2030,': [87], 'all': [88], 'people': [91], 'would': [92, 114, 202], '6G.': [95], 'computing': [97, 132, 282, 306], 'model': [98], 'cloud': [101, 131, 191], 'not': [103], 'dependent': [104], 'on': [105, 300], 'either': [106], 'location': [108], 'or': [109], 'any': [110], 'specific': [111], 'device': [112], 'provide': [115, 160], 'service.': [117], 'It': [118], 'an': [120], 'on‐demand': [121, 353], 'computational': [122], 'service‐oriented': [123], 'mechanism.': [124], 'Combining': [125, 190], 'these': [126], 'two': [127, 310], 'technologies': [128], 'as': [129, 170, 208, 314], 'provides': [133], 'customized': [134, 164], 'options': [135], 'more': [137, 161], 'flexible': [138], 'implementations.': [139], 'Artificial': [140], 'intelligence': [141], 'being': [143], 'used': [144, 153], 'many': [148, 257], 'fields.': [149], 'AI': [150, 193], 'can': [151], 'services': [157, 165, 197, 285], '(MNS)': [158], 'reliable': [162, 350], 'users,': [168], 'such': [169, 207, 313], 'operation': [172, 175], 'monitoring,': [173], 'management,': [176], 'fraud': [177], 'detection,': [178], 'reduction': [180], 'transactions': [183], 'security': [185], 'cyber': [188], 'devices.': [189], '6th': [200], 'generation': [201, 255], 'improve': [203], 'human': [204], 'beings’': [205], 'lives,': [206], 'zero': [209, 218], 'road': [210], 'accidents,': [211], 'advanced': [212], 'level': [213], 'special': [214], 'health': [215], 'care,': [216], 'crime': [219], 'rates': [220], 'society.': [222], 'However,': [223], 'most': [225], 'vital': [226], 'needs': [227, 266], 'sixth‐generation': [229, 248], 'standards': [230], 'capability': [233], 'manage': [235], 'large': [236], 'volumes': [237], 'records': [239], 'excessive‐statistics‐fee': [241], 'connectivity': [242], 'step': [244], 'gadgets.': [246], 'under': [252], 'development.': [253], 'This': [254], 'exciting': [258], 'features.': [259], 'Security': [260], 'central': [263], 'issue': [264], 'sorted': [269], 'out': [270], 'appropriate': [272], 'forensic': [273], 'mechanisms.': [274], 'There': [275], 'a': [277, 304, 332], 'need': [278], 'approach': [280], 'high‐performance': [281, 305], 'improved': [284], 'end‐user.': [288], 'Considering': [289], 'three‐dimensional': [290], 'research': [291], 'methodologies': [292], '(technical': [293], 'dimension,': [294, 296], 'organizational': [295], 'applications': [298], 'hosted': [299], 'cloud)': [302], 'environment': [307], 'leads': [308], 'different': [311], 'cases': [312], 'real‐time': [315], 'stream': [316], 'processing': [317], 'remote': [319], 'desktop': [320], 'connection': [321], 'performance': [323], 'test.': [324], '‘narrowing': [326], 'targeted': [328], 'worldwide': [329], 'audience': [330], 'wide': [333], 'range': [334], 'experiential': [336], 'opportunities,’': [337], 'this': [338], 'paper': [339], 'aimed': [341], 'at': [342], 'delivering': [343], 'dynamic': [344], 'varied': [346], 'resource': [347], 'allocation': [348], 'justified': [352], 'services.': [354]}",2022,"['Computer science', 'Cloud computing', 'Mobile cloud computing', 'Computer security', 'Implementation', 'Mobile device', 'Mobile computing', 'Service (business)', 'Mobile telephony', 'Telecommunications', 'World Wide Web', 'Operating system', 'Mobile radio', 'Programming language', 'Economy', 'Economics']","The exchange of information from one person to another is called communication. Telecommunication makes it possible with electronic devices and their tools. The scientist Alexander Graham Bell has invented the basic telephone in 1876 in the USA. Telephones now have the new format in the form of mobile phones, which are the primary media for communicating and transmitting data. We are using 5th‐generation mobile network standards. Still, there are some requirements for the users that are believed to be solved in the 6th‐generation mobile network standards. By 2030, all of the people would be using 6G. The computing model in the cloud is not dependent on either the location or any specific device that would provide the service. It is an on‐demand computational service‐oriented mechanism. Combining these two technologies as mobile cloud computing provides customized options with more flexible implementations. Artificial intelligence is being used in devices in many fields. AI can be used in mobile network services (MNS) to provide more reliable and customized services to the users, such as network operation monitoring, network operation management, fraud detection, and reduction in mobile transactions and security to the cyber devices. Combining cloud with AI in mobile network services in the 6th generation would improve human beings’ lives, such as zero road accidents, advanced level special health care, and zero crime rates in society. However, the most vital needs for sixth‐generation standards are the capability to manage large volumes of records and excessive‐statistics‐fee connectivity in step with gadgets. The sixth‐generation mobile network is under development. This generation has many exciting features. Security is the central issue that needs to be sorted out using appropriate forensic mechanisms. There is a need to approach high‐performance computing for improved services to the end‐user. Considering three‐dimensional research methodologies (technical dimension, organizational dimension, and applications hosted on the cloud) in a high‐performance computing environment leads to two different cases such as real‐time stream processing and remote desktop connection and performance test. By ‘narrowing the targeted worldwide audience with a wide range of experiential opportunities,’ this paper is aimed at delivering dynamic and varied resource allocation for reliable and justified on‐demand services."
https://openalex.org/W4323359493,The Right Not to Be Subjected to AI Profiling Based on Publicly Available Data—Privacy and the Exceptionalism of AI Profiling,"{'Abstract': [0], 'Social': [1], 'media': [2], 'data': [3, 57, 77, 110], 'hold': [4], 'considerable': [5], 'potential': [6], 'for': [7, 70, 124], 'predicting': [8], 'health-related': [9, 24], 'conditions.': [10], 'Recent': [11], 'studies': [12], 'suggest': [13], 'that': [14, 38, 89, 141, 151], 'machine-learning': [15], 'models': [16], 'may': [17], 'accurately': [18], 'predict': [19], 'depression': [20], 'and': [21, 30, 85, 104, 125, 137], 'other': [22, 107, 122], 'mental': [23], 'conditions': [25], 'based': [26, 53, 132, 161], 'on': [27, 54, 79, 133, 162], 'Instagram': [28], 'photos': [29], 'Tweets.': [31], 'In': [32], 'this': [33], 'article,': [34], 'it': [35], 'is': [36], 'argued': [37], 'individuals': [39, 98, 128, 152], 'should': [40], 'have': [41, 153], 'a': [42, 71, 90, 119, 154], 'sui': [43], 'generis': [44], 'right': [45, 72, 155], 'not': [46, 149, 156], 'to': [47, 50, 73, 101, 157], 'be': [48, 158], 'subjected': [49], 'AI': [51, 95, 115, 130, 159], 'profiling': [52, 96, 131], 'publicly': [55, 134, 163], 'available': [56, 135, 164], 'without': [58], 'their': [59], 'explicit': [60], 'informed': [61], 'consent.': [62], 'The': [63], 'article': [64], '(1)': [65], 'develops': [66], 'three': [67], 'basic': [68], 'arguments': [69], 'protection': [74], 'of': [75, 82, 92, 94, 109, 114, 121], 'personal': [76], 'trading': [78], 'the': [80, 142], 'notions': [81], 'social': [83, 102], 'control': [84, 103], 'stigmatization,': [86], '(2)': [87], 'argues': [88, 140], 'number': [91], 'features': [93], 'make': [97], 'more': [99], 'exposed': [100], 'stigmatization': [105], 'than': [106], 'types': [108], 'processing': [111], '(the': [112], 'exceptionalism': [113], 'profiling),': [116], '(3)': [117], 'considers': [118], 'series': [120], 'reasons': [123], 'against': [126, 129], 'protecting': [127], 'data,': [136], 'finally': [138], '(4)': [139], 'EU': [143], 'General': [144], 'Data': [145], 'Protection': [146], 'Regulation': [147], 'does': [148], 'ensure': [150], 'profiled': [160], 'data.': [165]}",2023,"['Profiling (computer programming)', 'Philosophy of technology', 'Exceptionalism', 'Internet privacy', 'Computer science', 'Political science', 'Law', 'Philosophy', 'Philosophy of science', 'Epistemology', 'Operating system', 'Politics']","Abstract Social media data hold considerable potential for predicting health-related conditions. Recent studies suggest that machine-learning models may accurately predict depression and other mental health-related conditions based on Instagram photos and Tweets. In this article, it is argued that individuals should have a sui generis right not to be subjected to AI profiling based on publicly available data without their explicit informed consent. The article (1) develops three basic arguments for a right to protection of personal data trading on the notions of social control and stigmatization, (2) argues that a number of features of AI profiling make individuals more exposed to social control and stigmatization than other types of data processing (the exceptionalism of AI profiling), (3) considers a series of other reasons for and against protecting individuals against AI profiling based on publicly available data, and finally (4) argues that the EU General Data Protection Regulation does not ensure that individuals have a right not to be AI profiled based on publicly available data."
https://openalex.org/W4308532266,Lost in translation? Conceptions of privacy and independence in the technical development of AI-based AAL,"{'Abstract': [0], 'AAL': [1, 186, 204], 'encompasses': [2], 'smart': [3], 'home': [4], 'technologies': [5], 'that': [6, 129, 143], 'are': [7, 110, 120, 134, 212], 'installed': [8], 'in': [9, 14, 38, 56, 113, 126, 151, 178], 'the': [10, 27, 53, 79, 90, 97, 101, 107, 114, 123, 127, 152, 155, 159, 165, 179, 190, 217], 'personal': [11], 'living': [12], 'environment': [13], 'order': [15], 'to': [16, 77, 163, 201], 'support': [17], 'older,': [18], 'disabled,': [19], 'as': [20, 22, 47, 136, 173], 'well': [21], 'chronically': [23], 'ill': [24], 'people': [25], 'with': [26, 214], 'goal': [28], 'of': [29, 67, 81, 88, 92, 104, 116, 168, 181, 192], 'delaying': [30], 'or': [31], 'reducing': [32], 'their': [33, 57], 'need': [34], 'for': [35, 51], 'nursing': [36], 'care': [37, 40], 'a': [39, 207], 'facility.': [41], 'Artificial': [42], 'intelligence': [43], '(AI)': [44], 'is': [45], 'seen': [46], 'an': [48, 85], 'important': [49, 137], 'tool': [50], 'assisting': [52], 'target': [54], 'group': [55], 'daily': [58], 'lives.': [59], 'A': [60], 'literature': [61], 'search': [62], 'and': [63, 73, 94, 100, 132, 149, 154, 171, 195], 'qualitative': [64], 'content': [65], 'analysis': [66], '255': [68], 'articles': [69], 'from': [70, 216], 'computer': [71], 'science': [72], 'engineering': [74], 'was': [75], 'conducted': [76], 'explore': [78], 'usage': [80], 'ethical': [82, 86, 153, 194, 218], 'concepts.': [83], 'From': [84], 'point': [87], 'view,': [89], 'concept': [91], 'independence': [93], 'self-determination': [95, 131, 170], 'on': [96, 106, 184, 220], 'one': [98], 'hand': [99, 109], 'possible': [102], 'loss': [103], 'privacy': [105, 133, 172], 'other': [108], 'widely': [111], 'discussed': [112], 'context': [115, 180], 'AAL.': [117], 'These': [118], 'concepts': [119, 145, 197, 215], 'adopted': [121], 'by': [122], 'technical': [124, 156], 'discourse': [125, 219], 'sense': [128], 'independence,': [130, 169], 'recognized': [135], 'values.': [138], 'Nevertheless,': [139], 'our': [140], 'research': [141, 183], 'shows': [142], 'these': [144, 193, 210], 'have': [146], 'different': [147, 166], 'usages': [148], 'meanings': [150, 167], 'discourses.': [157], 'In': [158, 206], 'paper,': [160], 'we': [161], 'aim': [162], 'map': [164], 'they': [174], 'can': [175], 'be': [176], 'found': [177], 'technological': [182], 'AI-based': [185, 221], 'systems.': [187, 205], 'It': [188], 'investigates': [189], 'interpretation': [191], 'social': [196], 'which': [198], 'technicians': [199], 'try': [200], 'build': [202], 'into': [203], 'second': [208], 'step,': [209], 'interpretations': [211], 'contextualized': [213], 'assistive': [222], 'technologies.': [223]}",2022,"['Philosophy of medicine', 'Independence (probability theory)', 'Context (archaeology)', 'Philosophy of biology', 'Medical law', 'Computer science', 'Interpretation (philosophy)', 'Internet privacy', 'Engineering ethics', 'Sociology', 'Psychology', 'Philosophy of science', 'Epistemology', 'Medicine', 'Engineering', 'Alternative medicine', 'Statistics', 'Mathematics', 'Biology', 'Programming language', 'Philosophy', 'Pathology', 'Paleontology', 'Psychiatry']","Abstract AAL encompasses smart home technologies that are installed in the personal living environment in order to support older, disabled, as well as chronically ill people with the goal of delaying or reducing their need for nursing care in a care facility. Artificial intelligence (AI) is seen as an important tool for assisting the target group in their daily lives. A literature search and qualitative content analysis of 255 articles from computer science and engineering was conducted to explore the usage of ethical concepts. From an ethical point of view, the concept of independence and self-determination on the one hand and the possible loss of privacy on the other hand are widely discussed in the context of AAL. These concepts are adopted by the technical discourse in the sense that independence, self-determination and privacy are recognized as important values. Nevertheless, our research shows that these concepts have different usages and meanings in the ethical and the technical discourses. In the paper, we aim to map the different meanings of independence, self-determination and privacy as they can be found in the context of technological research on AI-based AAL systems. It investigates the interpretation of these ethical and social concepts which technicians try to build into AAL systems. In a second step, these interpretations are contextualized with concepts from the ethical discourse on AI-based assistive technologies."
https://openalex.org/W4402576628,"Ethical AI in Information Technology: Navigating Bias, Privacy, Transparency, and Accountability","{'The': [0], 'rapid': [1], 'advancement': [2, 108], 'of': [3, 13, 34, 58, 65, 109], 'artificial': [4], 'intelligence': [5], '(AI)': [6], 'technologies': [7], 'has': [8], 'fundamentally': [9], 'transformed': [10], 'the': [11, 53, 74, 104], 'landscape': [12], 'information': [14], 'technology': [15], '(IT),': [16], 'offering': [17], 'unprecedented': [18], 'opportunities': [19], 'for': [20, 52], 'innovation': [21], 'and': [22, 38, 46, 56, 70, 88, 106], 'efficiency.': [23], 'However,': [24], 'these': [25, 43], 'advancements': [26], 'also': [27], 'bring': [28], 'significant': [29], 'ethical': [30, 44, 50, 96], 'challenges,': [31], 'including': [32], 'issues': [33], 'bias,': [35], 'privacy,': [36, 85], 'transparency,': [37, 87], 'accountability.': [39], 'This': [40], 'paper': [41], 'explores': [42], 'challenges': [45], 'proposes': [47], 'a': [48, 116], 'comprehensive': [49], 'framework': [51, 75, 100], 'responsible': [54], 'development': [55], 'deployment': [57], 'AI': [59, 92, 97, 110], 'in': [60, 91], 'IT.': [61], 'Through': [62], 'an': [63], 'examination': [64], 'historical': [66], 'context,': [67], 'current': [68], 'trends,': [69], 'detailed': [71], 'case': [72], 'studies,': [73], 'aims': [76], 'to': [77, 81, 102], 'provide': [78], 'actionable': [79], 'guidelines': [80], 'mitigate': [82], 'biases,': [83], 'protect': [84], 'enhance': [86], 'ensure': [89], 'accountability': [90], 'systems.': [93], 'By': [94], 'fostering': [95], 'practices,': [98], 'this': [99], 'aspires': [101], 'support': [103], 'sustainable': [105], 'equitable': [107], 'technologies,': [111], 'ultimately': [112], 'benefiting': [113], 'society': [114], 'as': [115], 'whole': [117]}",2024,"['Transparency (behavior)', 'Accountability', 'Internet privacy', 'Information privacy', 'Business', 'Public relations', 'Political science', 'Computer science', 'Computer security', 'Law']","The rapid advancement of artificial intelligence (AI) technologies has fundamentally transformed the landscape of information technology (IT), offering unprecedented opportunities for innovation and efficiency. However, these advancements also bring significant ethical challenges, including issues of bias, privacy, transparency, and accountability. This paper explores these ethical challenges and proposes a comprehensive ethical framework for the responsible development and deployment of AI in IT. Through an examination of historical context, current trends, and detailed case studies, the framework aims to provide actionable guidelines to mitigate biases, protect privacy, enhance transparency, and ensure accountability in AI systems. By fostering ethical AI practices, this framework aspires to support the sustainable and equitable advancement of AI technologies, ultimately benefiting society as a whole"
https://openalex.org/W4399354491,Fairness &amp; Privacy in an Age of Generative AI,"{'Generative': [0], 'AI': [1, 166, 208, 235], 'technologies': [2, 32], 'have': [3, 9], 'made': [4], 'tremendous': [5], 'strides': [6], 'recently': [7], 'and': [8, 40, 77, 102, 131, 174, 183, 189, 203, 210, 220, 238, 257], 'captured': [10], 'the': [11, 56, 178, 199, 211, 231, 249], 'public’s': [12], 'imagination': [13], 'with': [14], 'their': [15, 51, 99, 106], 'ability': [16], 'to': [17, 23, 36, 73, 96, 119, 223, 253], 'mimic': [18], 'what': [19, 243], 'was': [20], 'previously': [21], 'thought': [22], 'be': [24, 91, 151, 246, 263], 'a': [25, 162], 'fundamentally': [26], 'human': [27, 38], 'capability:': [28], 'creativity.': [29], 'While': [30], 'such': [31, 155, 255], 'hold': [33], 'great': [34], 'promise': [35], 'augment': [37], 'creativity': [39], 'automate': [41], 'tedious': [42], 'processes,': [43], 'they': [44], 'also': [45, 161], 'carry': [46], 'risks': [47], 'that': [48, 89, 206, 230], 'stem': [49], 'from': [50, 154], 'development': [52], 'process.': [53], 'In': [54], 'particular,': [55], 'reliance': [57], 'of': [58, 64, 122, 133, 172, 201, 214, 233, 269], 'foundation': [59], 'models': [60, 94, 115, 167], 'on': [61], 'vast': [62], 'amounts': [63, 171], 'typically': [65], 'uncurated,': [66], 'often': [67], 'web-scraped': [68], 'training': [69, 100, 179, 250], 'data': [70, 101, 251], 'has': [71], 'led': [72], 'concerns': [74, 85, 205], 'around': [75, 86, 147, 241, 248], 'fairness': [76, 80, 202], 'privacy.': [78], 'Algorithmic': [79], 'in': [81, 98, 105, 177, 266], 'this': [82], 'context': [83], 'encompasses': [84], 'potential': [87], 'biases': [88], 'can': [90, 168], 'learned': [92], 'by': [93], 'due': [95], 'skews': [97], 'then': [103], 'reflected': [104], 'generated': [107], 'outputs.': [108], 'For': [109], 'example,': [110], 'without': [111], 'intervention,': [112], 'image': [113, 187], 'generation': [114, 188], 'are': [116], 'more': [117], 'likely': [118], 'generate': [120], 'images': [121, 132], 'lighter': [123], 'skin': [124, 135], 'tone': [125, 136], 'male': [126], 'individuals': [127, 138], 'for': [128, 139, 186, 192], 'professional': [129], 'occupations': [130], 'darker': [134], 'female': [137], 'working': [140], 'class': [141], 'occupations.': [142], 'This': [143, 195, 227], 'further': [144], 'raises': [145, 209, 236], 'questions': [146, 240], 'whether': [148, 259], 'there': [149], 'should': [150, 245, 262], 'legal': [152, 215], 'protections': [153, 216, 244], 'pernicious': [156], 'stereotypical': [157], 'representations.': [158], 'Privacy': [159], 'is': [160], 'concern': [163], 'as': [164], 'generative': [165, 207, 234], 'ingest': [169], 'large': [170], 'personal': [173], 'biometric': [175], 'information': [176], 'process,': [180], 'including': [181], 'face': [182], 'body': [184], 'biometrics': [185, 191], 'voice': [190], 'speech': [193], 'generation.': [194], 'Essay': [196, 228], 'will': [197], 'discuss': [198], 'types': [200], 'privacy': [204, 221], 'existing': [212], 'landscape': [213], 'under': [217], 'anti-discrimination': [218], 'law': [219, 222], 'address': [224], 'these': [225], 'concerns.': [226], 'argues': [229], 'proliferation': [232], 'challenging': [237], 'novel': [239], '(i)': [242], 'offered': [247], 'used': [252], 'develop': [254], 'systems': [256], '(ii)': [258], 'representational': [260], 'harms': [261], 'protected': [264], 'against': [265], 'an': [267], 'age': [268], 'AI-generated': [270], 'content.': [271]}",2024,"['Generative grammar', 'Internet privacy', 'Psychology', 'Computer science', 'Artificial intelligence']","Generative AI technologies have made tremendous strides recently and have captured the public’s imagination with their ability to mimic what was previously thought to be a fundamentally human capability: creativity. While such technologies hold great promise to augment human creativity and automate tedious processes, they also carry risks that stem from their development process. In particular, the reliance of foundation models on vast amounts of typically uncurated, often web-scraped training data has led to concerns around fairness and privacy. Algorithmic fairness in this context encompasses concerns around potential biases that can be learned by models due to skews in their training data and then reflected in their generated outputs. For example, without intervention, image generation models are more likely to generate images of lighter skin tone male individuals for professional occupations and images of darker skin tone female individuals for working class occupations. This further raises questions around whether there should be legal protections from such pernicious stereotypical representations. Privacy is also a concern as generative AI models can ingest large amounts of personal and biometric information in the training process, including face and body biometrics for image generation and voice biometrics for speech generation. This Essay will discuss the types of fairness and privacy concerns that generative AI raises and the existing landscape of legal protections under anti-discrimination law and privacy law to address these concerns. This Essay argues that the proliferation of generative AI raises challenging and novel questions around (i) what protections should be offered around the training data used to develop such systems and (ii) whether representational harms should be protected against in an age of AI-generated content."
https://openalex.org/W3215435188,AI Model for Predicting Legal Judgments to Improve Accuracy and Explainability of Online Privacy Invasion Cases,"{'Since': [0, 74], 'there': [1], 'are': [2, 27, 68, 78], 'growing': [3], 'concerns': [4], 'regarding': [5], 'online': [6, 37, 45, 71], 'privacy,': [7, 38], 'firms': [8, 26, 149], 'may': [9], 'have': [10, 151], 'the': [11, 54, 104, 109, 132, 177, 197], 'risk': [12], 'of': [13, 29, 34, 36, 56, 116, 126, 155, 179], 'being': [14], 'involved': [15], 'in': [16, 22], 'various': [17, 61], 'privacy': [18, 46, 72, 135], 'infringement': [19, 136], 'cases': [20, 33, 66], 'resulting': [21], 'legal': [23, 75, 98, 189], 'causations.': [24], 'If': [25], 'aware': [28], 'consequences': [30], 'from': [31], 'possible': [32], 'invasion': [35], 'they': [39, 163], 'can': [40, 95], 'more': [41], 'actively': [42], 'prevent': [43], 'future': [44], 'infringements.': [47], 'Thus,': [48], 'this': [49, 87], 'study': [50, 88, 105], 'attempts': [51], 'to': [52, 70, 90, 171], 'predict': [53, 97], 'probability': [55], 'judgment': [57, 76, 99], 'types': [58, 115], 'caused': [59], 'by': [60, 81, 112, 140], 'invasions': [62], 'within': [63], 'US': [64], 'judicial': [65], 'that': [67, 94, 148], 'related': [69], 'invasions.': [73], 'results': [77, 146], 'significantly': [79], 'influenced': [80], 'societal': [82], 'factors': [83, 137], 'and': [84, 123, 138, 158, 183], 'technological': [85], 'development,': [86], 'tries': [89], 'identify': [91], 'a': [92, 152], 'model': [93], 'accurately': [96], 'with': [100], 'explainability.': [101], 'To': [102], 'archive': [103], 'objective,': [106], 'it': [107], 'compares': [108], 'prediction': [110], 'performance': [111], 'applying': [113, 141], 'five': [114], 'classification': [117], 'algorithms': [118], '(LDA,': [119], 'NNET,': [120], 'CART,': [121], 'SVM,': [122], 'random': [124], 'forest)': [125], 'machine': [127], 'learning.': [128], 'We': [129], 'also': [130], 'examined': [131], 'relationship': [133], 'between': [134], 'adjudications': [139], 'network': [142], 'text': [143], 'analysis.': [144], 'The': [145], 'indicate': [147], 'could': [150], 'high': [153], 'possibility': [154], 'both': [156, 181], 'civil': [157], 'criminal': [159], 'law': [160], 'responsibilities': [161], 'if': [162], 'distributed': [164], 'malware': [165], 'or': [166, 169], 'spyware,': [167], 'intentionally': [168], 'non-intentionally,': [170], 'collect': [172], 'unauthorized': [173], 'data.': [174], 'It': [175], 'addresses': [176], 'needs': [178], 'reflecting': [180], 'quantitative': [182], 'qualitative': [184], 'approach': [185], 'for': [186, 191], 'establishing': [187], 'automatic': [188], 'systems': [190], 'improving': [192], 'its': [193], 'accuracy': [194], 'based': [195], 'on': [196], 'socio-technical': [198], 'perspective.': [199]}",2021,"['Adjudication', 'Internet privacy', 'Perspective (graphical)', 'Computer science', 'Computer security', 'Data science', 'Political science', 'Artificial intelligence', 'Law']","Since there are growing concerns regarding online privacy, firms may have the risk of being involved in various privacy infringement cases resulting in legal causations. If firms are aware of consequences from possible cases of invasion of online privacy, they can more actively prevent future online privacy infringements. Thus, this study attempts to predict the probability of judgment types caused by various invasions within US judicial cases that are related to online privacy invasions. Since legal judgment results are significantly influenced by societal factors and technological development, this study tries to identify a model that can accurately predict legal judgment with explainability. To archive the study objective, it compares the prediction performance by applying five types of classification algorithms (LDA, NNET, CART, SVM, and random forest) of machine learning. We also examined the relationship between privacy infringement factors and adjudications by applying network text analysis. The results indicate that firms could have a high possibility of both civil and criminal law responsibilities if they distributed malware or spyware, intentionally or non-intentionally, to collect unauthorized data. It addresses the needs of reflecting both quantitative and qualitative approach for establishing automatic legal systems for improving its accuracy based on the socio-technical perspective."
https://openalex.org/W4411492716,A Review on Federated Learning Architectures for Privacy-Preserving AI: Lightweight and Secure Cloud–Edge–End Collaboration,"{'Federated': [0], 'learning': [1, 15], '(FL)': [2], 'has': [3], 'emerged': [4], 'as': [5], 'a': [6, 44, 58, 68, 110, 127], 'promising': [7], 'paradigm': [8], 'for': [9, 131], 'enabling': [10], 'collaborative': [11], 'training': [12], 'of': [13, 25, 47, 78, 96, 113, 120], 'machine': [14], 'models': [16], 'while': [17], 'preserving': [18], 'data': [19, 26], 'privacy.': [20], 'However,': [21], 'the': [22, 48, 76, 86, 94, 100, 118, 136, 157], 'massive': [23], 'heterogeneity': [24], 'and': [27, 31, 51, 81, 106, 116, 139, 148], 'devices,': [28, 134], 'communication': [29], 'constraints,': [30], 'security': [32], 'threats': [33], 'pose': [34], 'significant': [35], 'challenges': [36, 63], 'to': [37, 152], 'its': [38], 'practical': [39], 'implementation.': [40], 'This': [41], 'paper': [42], 'provides': [43], 'system': [45], 'review': [46], 'state-of-the-art': [49], 'techniques': [50], 'future': [52, 149], 'research': [53, 150], 'directions': [54, 151], 'in': [55, 64, 99], 'FL,': [56], 'with': [57], 'focus': [59], 'on': [60], 'addressing': [61], 'these': [62], 'resource-constrained': [65, 132], 'environments': [66], 'by': [67], 'cloud–edge–end': [69, 79], 'collaboration': [70, 80], 'FL': [71, 129], 'architecture.': [72], 'We': [73, 83, 108], 'first': [74], 'introduce': [75], 'foundations': [77, 119], 'FL.': [82], 'then': [84], 'discuss': [85], 'key': [87], 'technical': [88], 'challenges.': [89], 'Next,': [90], 'we': [91, 125, 144], 'delve': [92], 'into': [93, 156], 'pillars': [95], 'trustworthy': [97], 'AI': [98, 115], 'federated': [101], 'context,': [102], 'covering': [103], 'robustness,': [104], 'fairness,': [105], 'explainability.': [107], 'propose': [109], 'dimension': [111], 'reconstruction': [112], 'trusted': [114], 'analyze': [117], 'each': [121], 'trustworthiness': [122], 'pillar.': [123], 'Furthermore,': [124], 'present': [126], 'lightweight': [128], 'framework': [130], 'edge–end': [133], 'analyzing': [135], 'core': [137], 'contradictions': [138], 'proposing': [140], 'optimization': [141], 'paradigms.': [142], 'Finally,': [143], 'highlight': [145], 'advanced': [146], 'topics': [147], 'provide': [153], 'valuable': [154], 'insights': [155], 'field.': [158]}",2025,"['Computer science', 'Cloud computing', 'Robustness (evolution)', 'Data science', 'Context (archaeology)', 'Enhanced Data Rates for GSM Evolution', 'Architecture', 'Trustworthiness', 'Federated learning', 'Artificial intelligence', 'Distributed computing', 'Computer security', 'Biology', 'Chemistry', 'Art', 'Gene', 'Paleontology', 'Biochemistry', 'Operating system', 'Visual arts']","Federated learning (FL) has emerged as a promising paradigm for enabling collaborative training of machine learning models while preserving data privacy. However, the massive heterogeneity of data and devices, communication constraints, and security threats pose significant challenges to its practical implementation. This paper provides a system review of the state-of-the-art techniques and future research directions in FL, with a focus on addressing these challenges in resource-constrained environments by a cloud–edge–end collaboration FL architecture. We first introduce the foundations of cloud–edge–end collaboration and FL. We then discuss the key technical challenges. Next, we delve into the pillars of trustworthy AI in the federated context, covering robustness, fairness, and explainability. We propose a dimension reconstruction of trusted AI and analyze the foundations of each trustworthiness pillar. Furthermore, we present a lightweight FL framework for resource-constrained edge–end devices, analyzing the core contradictions and proposing optimization paradigms. Finally, we highlight advanced topics and future research directions to provide valuable insights into the field."
